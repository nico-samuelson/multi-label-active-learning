{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10801903,"sourceType":"datasetVersion","datasetId":6159439}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":5958.111278,"end_time":"2025-03-24T16:59:02.254236","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-03-24T15:19:44.142958","version":"2.6.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"01e7b30c336a47928473e1862bb448c2":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0ae847f059f8423e97ab244b410011a7":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_7af6612add0f480e87997233f70d01a2","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a470c528dd5844e38161ee11e4f16a96","tabbable":null,"tooltip":null,"value":2}},"15d114518f6142b09dd442a8d82e5049":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b6b0c4ec0714a7d98e5a88b403c8ac2":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26b36e942a38454c857903ca2456187f":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27f727edba144a8bbf2c130f16ffbe86":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"31b12e2d65644e5799abad997b61a401":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_bc76297e1e2d4bd8bf7b1e5314842178","placeholder":"​","style":"IPY_MODEL_38facb196c8a446a94704a601eb19f9e","tabbable":null,"tooltip":null,"value":"tokenizer_config.json: 100%"}},"31c18a927ea449e5b635ef2629412c58":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33c18730ea314f3c8d8eb818b290211e":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"342dd2780a9344e6a99e695291a85828":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"3847f56f17964e218f6c1f8ae7e59466":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38facb196c8a446a94704a601eb19f9e":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"3986d1e2613c4440bb121d8a92a5a066":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"40137daea81042d189d9fed8de9ec3d3":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_26b36e942a38454c857903ca2456187f","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3986d1e2613c4440bb121d8a92a5a066","tabbable":null,"tooltip":null,"value":112}},"41c3c2874ee341b9842f69fc958e73bd":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"495644571ff8454098476442a02017e7":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"592e6e8f5db64876accbadcd4dda367a":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_3847f56f17964e218f6c1f8ae7e59466","placeholder":"​","style":"IPY_MODEL_686577b03e0c4fb6817c01fa7db84bb0","tabbable":null,"tooltip":null,"value":" 229k/229k [00:00&lt;00:00, 5.82MB/s]"}},"686577b03e0c4fb6817c01fa7db84bb0":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"6fb88473eff742a98c9439f74bd09ed7":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e213443c983141ec83231e2030694297","IPY_MODEL_40137daea81042d189d9fed8de9ec3d3","IPY_MODEL_71d8a54d161441f29bda23fca8fcf127"],"layout":"IPY_MODEL_31c18a927ea449e5b635ef2629412c58","tabbable":null,"tooltip":null}},"71d8a54d161441f29bda23fca8fcf127":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_15d114518f6142b09dd442a8d82e5049","placeholder":"​","style":"IPY_MODEL_a0830cd4f71047899200cc9731d9468a","tabbable":null,"tooltip":null,"value":" 112/112 [00:00&lt;00:00, 10.1kB/s]"}},"723ea8b1a84b45d0982b0e2fd0b8d326":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76b8e3d7e6304b5fa91d10f5135a6da0":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78c790e03a7a4d76bbda51418277b684":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7af6612add0f480e87997233f70d01a2":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b07079c9cd74e3989e7ff56a84b9d89":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_76b8e3d7e6304b5fa91d10f5135a6da0","placeholder":"​","style":"IPY_MODEL_342dd2780a9344e6a99e695291a85828","tabbable":null,"tooltip":null,"value":" 1.53k/1.53k [00:00&lt;00:00, 132kB/s]"}},"7de96abcc2da45ec81cf6965503299aa":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_b047ab0b06ff402e9cf374ea4586aa24","max":1534,"min":0,"orientation":"horizontal","style":"IPY_MODEL_33c18730ea314f3c8d8eb818b290211e","tabbable":null,"tooltip":null,"value":1534}},"7f4a10481d8945d0bb53c3f1c3e933df":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_fd0dbfa0480c47b3985d858c1bf48a06","placeholder":"​","style":"IPY_MODEL_f363c9621bec4748805482d99d81bc98","tabbable":null,"tooltip":null,"value":"vocab.txt: 100%"}},"9653d7e8858c43999eba1b0f07c793ab":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_78c790e03a7a4d76bbda51418277b684","placeholder":"​","style":"IPY_MODEL_495644571ff8454098476442a02017e7","tabbable":null,"tooltip":null,"value":" 2.00/2.00 [00:00&lt;00:00, 147B/s]"}},"99b1d44a7613479bb598571084bff0d6":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d4a58fb1816546fa80256f1afa685adf","IPY_MODEL_7de96abcc2da45ec81cf6965503299aa","IPY_MODEL_7b07079c9cd74e3989e7ff56a84b9d89"],"layout":"IPY_MODEL_b215783384454b23940207d1f8af4ea1","tabbable":null,"tooltip":null}},"a0830cd4f71047899200cc9731d9468a":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"a470c528dd5844e38161ee11e4f16a96":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a5bfe1f98e6442a4ab4f8e9b2eecd332":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_b80c9c87cece4f1e8ddee1972a596752","max":229167,"min":0,"orientation":"horizontal","style":"IPY_MODEL_01e7b30c336a47928473e1862bb448c2","tabbable":null,"tooltip":null,"value":229167}},"b047ab0b06ff402e9cf374ea4586aa24":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b215783384454b23940207d1f8af4ea1":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2eb663f8ed24c0386c5bf5dadd2e9c0":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_31b12e2d65644e5799abad997b61a401","IPY_MODEL_0ae847f059f8423e97ab244b410011a7","IPY_MODEL_9653d7e8858c43999eba1b0f07c793ab"],"layout":"IPY_MODEL_723ea8b1a84b45d0982b0e2fd0b8d326","tabbable":null,"tooltip":null}},"b803286301e940b69dd9cf9770e18fa6":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b80c9c87cece4f1e8ddee1972a596752":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc76297e1e2d4bd8bf7b1e5314842178":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4a58fb1816546fa80256f1afa685adf":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_1b6b0c4ec0714a7d98e5a88b403c8ac2","placeholder":"​","style":"IPY_MODEL_27f727edba144a8bbf2c130f16ffbe86","tabbable":null,"tooltip":null,"value":"config.json: 100%"}},"e213443c983141ec83231e2030694297":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_41c3c2874ee341b9842f69fc958e73bd","placeholder":"​","style":"IPY_MODEL_e5f86bcd1279407a81d541243e1cfc51","tabbable":null,"tooltip":null,"value":"special_tokens_map.json: 100%"}},"e488b098f7a04d39819e4c49f2ef25a3":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7f4a10481d8945d0bb53c3f1c3e933df","IPY_MODEL_a5bfe1f98e6442a4ab4f8e9b2eecd332","IPY_MODEL_592e6e8f5db64876accbadcd4dda367a"],"layout":"IPY_MODEL_b803286301e940b69dd9cf9770e18fa6","tabbable":null,"tooltip":null}},"e5f86bcd1279407a81d541243e1cfc51":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"f363c9621bec4748805482d99d81bc98":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"fd0dbfa0480c47b3985d858c1bf48a06":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}},"version_major":2,"version_minor":0}}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"963c8eab","cell_type":"markdown","source":"# IMPORTS","metadata":{"papermill":{"duration":0.014318,"end_time":"2025-03-24T15:19:48.111392","exception":false,"start_time":"2025-03-24T15:19:48.097074","status":"completed"},"tags":[]}},{"id":"8b3c68f5","cell_type":"code","source":"import os\nimport math\nimport time\nimport torch\nimport random\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score, classification_report\nfrom accelerate import Accelerator, notebook_launcher\nfrom torch.multiprocessing import Manager\nfrom torch.utils.data import DataLoader, Dataset\nfrom transformers import BertTokenizer, BertModel, BertPreTrainedModel, BertConfig, BertForSequenceClassification","metadata":{"execution":{"iopub.status.busy":"2025-05-12T13:11:20.736432Z","iopub.execute_input":"2025-05-12T13:11:20.736834Z","iopub.status.idle":"2025-05-12T13:11:41.338075Z","shell.execute_reply.started":"2025-05-12T13:11:20.736796Z","shell.execute_reply":"2025-05-12T13:11:41.337394Z"},"papermill":{"duration":34.873979,"end_time":"2025-03-24T15:20:22.998840","exception":false,"start_time":"2025-03-24T15:19:48.124861","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":1},{"id":"d628fd5f","cell_type":"markdown","source":"# SETUP","metadata":{"papermill":{"duration":0.024131,"end_time":"2025-03-24T15:20:23.045054","exception":false,"start_time":"2025-03-24T15:20:23.020923","status":"completed"},"tags":[]}},{"id":"368f1a3f","cell_type":"code","source":"warnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2025-05-12T13:11:41.338984Z","iopub.execute_input":"2025-05-12T13:11:41.339673Z","iopub.status.idle":"2025-05-12T13:11:41.343207Z","shell.execute_reply.started":"2025-05-12T13:11:41.339638Z","shell.execute_reply":"2025-05-12T13:11:41.342602Z"},"papermill":{"duration":0.020599,"end_time":"2025-03-24T15:20:23.079611","exception":false,"start_time":"2025-03-24T15:20:23.059012","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":2},{"id":"ad347827","cell_type":"code","source":"if os.path.exists('/kaggle/working/results') == False:\n    os.mkdir('/kaggle/working/results')\n\nif os.path.exists('/kaggle/working/acquired_data') == False:\n    os.mkdir('/kaggle/working/acquired_data')","metadata":{"execution":{"iopub.status.busy":"2025-05-12T13:11:41.344360Z","iopub.execute_input":"2025-05-12T13:11:41.344555Z","iopub.status.idle":"2025-05-12T13:11:41.481817Z","shell.execute_reply.started":"2025-05-12T13:11:41.344539Z","shell.execute_reply":"2025-05-12T13:11:41.480898Z"},"papermill":{"duration":0.019999,"end_time":"2025-03-24T15:20:23.113044","exception":false,"start_time":"2025-03-24T15:20:23.093045","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":3},{"id":"3334aa7e","cell_type":"code","source":"def set_seed(seed):\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic=True\n    torch.backends.cudnn.benchmark=False\n\nset_seed(42)","metadata":{"execution":{"iopub.status.busy":"2025-05-12T13:11:41.483378Z","iopub.execute_input":"2025-05-12T13:11:41.483691Z","iopub.status.idle":"2025-05-12T13:11:41.496642Z","shell.execute_reply.started":"2025-05-12T13:11:41.483658Z","shell.execute_reply":"2025-05-12T13:11:41.495881Z"},"papermill":{"duration":0.029595,"end_time":"2025-03-24T15:20:23.156305","exception":false,"start_time":"2025-03-24T15:20:23.126710","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":4},{"id":"56cb1b78","cell_type":"markdown","source":"# GLOBAL VARIABLES","metadata":{"papermill":{"duration":0.013088,"end_time":"2025-03-24T15:20:23.183066","exception":false,"start_time":"2025-03-24T15:20:23.169978","status":"completed"},"tags":[]}},{"id":"b09221d1","cell_type":"code","source":"manager = Manager()\n\n# Shared resources\naspect_accuracies = manager.list()\naspect_f1_micros = manager.list()\naspect_f1_macros = manager.list()\nsentiment_accuracies = manager.list()\nsentiment_f1_micros = manager.list()\nsentiment_f1_macros = manager.list()\naccuracies = manager.list()\nf1_micros = manager.list()\nf1_macros = manager.list()\n\n# Non shared resources\nfilename = 'casa-lc-kmeans'\nepochs = 10\nbatch_size = 16\nsequence_length = 48\n\naspect_list = ['fuel', 'machine', 'others', 'part', 'price', 'service']\naspect_mapping = {'fuel': 0, 'machine': 1, 'others': 2, 'part': 3, 'price': 4, 'service': 5 }\nlabel_mapping = {\"negative\": 0, \"neutral\": 1, 'positive': 2}\nignored_keys = ['labels', 'ori_text', 'ori_label', 'ori_indices', 'aspect']","metadata":{"execution":{"iopub.status.busy":"2025-05-12T13:11:41.497403Z","iopub.execute_input":"2025-05-12T13:11:41.497682Z","iopub.status.idle":"2025-05-12T13:11:41.558605Z","shell.execute_reply.started":"2025-05-12T13:11:41.497655Z","shell.execute_reply":"2025-05-12T13:11:41.557007Z"},"papermill":{"duration":0.089178,"end_time":"2025-03-24T15:20:23.285459","exception":false,"start_time":"2025-03-24T15:20:23.196281","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":5},{"id":"2713a8fe","cell_type":"markdown","source":"# LOAD AND PREPROCESS DATA","metadata":{"papermill":{"duration":0.013318,"end_time":"2025-03-24T15:20:23.312384","exception":false,"start_time":"2025-03-24T15:20:23.299066","status":"completed"},"tags":[]}},{"id":"ed05f5de","cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/casa-dataset/train_preprocess.csv', encoding='latin-1')\nval_data = pd.read_csv('/kaggle/input/casa-dataset/valid_preprocess.csv', encoding='latin-1')\ntest_data = pd.read_csv('/kaggle/input/casa-dataset/test_preprocess.csv', encoding='latin-1')\n\ndata = pd.concat([train_data, val_data, test_data], ignore_index=True)\n\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2025-05-12T13:11:41.560308Z","iopub.execute_input":"2025-05-12T13:11:41.560645Z","iopub.status.idle":"2025-05-12T13:11:41.641517Z","shell.execute_reply.started":"2025-05-12T13:11:41.560617Z","shell.execute_reply":"2025-05-12T13:11:41.640522Z"},"papermill":{"duration":0.110834,"end_time":"2025-03-24T15:20:23.436806","exception":false,"start_time":"2025-03-24T15:20:23.325972","status":"completed"},"tags":[],"trusted":true},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                            sentence      fuel   machine  \\\n0  Saya memakai Honda Jazz GK5 tahun 2014 ( perta...   neutral   neutral   \n1  Avanza kenapa jadi boros bensin begini dah ah....  negative   neutral   \n2  saran ku dan pengalaman ku , mending beli mobi...  positive  positive   \n3  Dari segi harga juga pajero lebih mahal 30 jut...   neutral   neutral   \n4                     Kalo menurut gw enak pajero si   neutral   neutral   \n\n     others     part     price  service  \n0  positive  neutral   neutral  neutral  \n1   neutral  neutral   neutral  neutral  \n2   neutral  neutral   neutral  neutral  \n3   neutral  neutral  positive  neutral  \n4  positive  neutral   neutral  neutral  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence</th>\n      <th>fuel</th>\n      <th>machine</th>\n      <th>others</th>\n      <th>part</th>\n      <th>price</th>\n      <th>service</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Saya memakai Honda Jazz GK5 tahun 2014 ( perta...</td>\n      <td>neutral</td>\n      <td>neutral</td>\n      <td>positive</td>\n      <td>neutral</td>\n      <td>neutral</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Avanza kenapa jadi boros bensin begini dah ah....</td>\n      <td>negative</td>\n      <td>neutral</td>\n      <td>neutral</td>\n      <td>neutral</td>\n      <td>neutral</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>saran ku dan pengalaman ku , mending beli mobi...</td>\n      <td>positive</td>\n      <td>positive</td>\n      <td>neutral</td>\n      <td>neutral</td>\n      <td>neutral</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Dari segi harga juga pajero lebih mahal 30 jut...</td>\n      <td>neutral</td>\n      <td>neutral</td>\n      <td>neutral</td>\n      <td>neutral</td>\n      <td>positive</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Kalo menurut gw enak pajero si</td>\n      <td>neutral</td>\n      <td>neutral</td>\n      <td>positive</td>\n      <td>neutral</td>\n      <td>neutral</td>\n      <td>neutral</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"id":"2aa19306","cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2025-05-12T13:11:41.642727Z","iopub.execute_input":"2025-05-12T13:11:41.643086Z","iopub.status.idle":"2025-05-12T13:11:41.653114Z","shell.execute_reply.started":"2025-05-12T13:11:41.643055Z","shell.execute_reply":"2025-05-12T13:11:41.652287Z"},"papermill":{"duration":0.027962,"end_time":"2025-03-24T15:20:23.478224","exception":false,"start_time":"2025-03-24T15:20:23.450262","status":"completed"},"tags":[],"trusted":true},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                            sentence      fuel   machine  \\\n0  Saya memakai Honda Jazz GK5 tahun 2014 ( perta...   neutral   neutral   \n1  Avanza kenapa jadi boros bensin begini dah ah....  negative   neutral   \n2  saran ku dan pengalaman ku , mending beli mobi...  positive  positive   \n3  Dari segi harga juga pajero lebih mahal 30 jut...   neutral   neutral   \n4                     Kalo menurut gw enak pajero si   neutral   neutral   \n\n     others     part     price  service  \n0  positive  neutral   neutral  neutral  \n1   neutral  neutral   neutral  neutral  \n2   neutral  neutral   neutral  neutral  \n3   neutral  neutral  positive  neutral  \n4  positive  neutral   neutral  neutral  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence</th>\n      <th>fuel</th>\n      <th>machine</th>\n      <th>others</th>\n      <th>part</th>\n      <th>price</th>\n      <th>service</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Saya memakai Honda Jazz GK5 tahun 2014 ( perta...</td>\n      <td>neutral</td>\n      <td>neutral</td>\n      <td>positive</td>\n      <td>neutral</td>\n      <td>neutral</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Avanza kenapa jadi boros bensin begini dah ah....</td>\n      <td>negative</td>\n      <td>neutral</td>\n      <td>neutral</td>\n      <td>neutral</td>\n      <td>neutral</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>saran ku dan pengalaman ku , mending beli mobi...</td>\n      <td>positive</td>\n      <td>positive</td>\n      <td>neutral</td>\n      <td>neutral</td>\n      <td>neutral</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Dari segi harga juga pajero lebih mahal 30 jut...</td>\n      <td>neutral</td>\n      <td>neutral</td>\n      <td>neutral</td>\n      <td>neutral</td>\n      <td>positive</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Kalo menurut gw enak pajero si</td>\n      <td>neutral</td>\n      <td>neutral</td>\n      <td>positive</td>\n      <td>neutral</td>\n      <td>neutral</td>\n      <td>neutral</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"id":"0eca5881","cell_type":"code","source":"train_data, val_data = train_test_split(data, test_size=0.2, random_state=42, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2025-05-12T13:11:41.656361Z","iopub.execute_input":"2025-05-12T13:11:41.656570Z","iopub.status.idle":"2025-05-12T13:11:41.667849Z","shell.execute_reply.started":"2025-05-12T13:11:41.656553Z","shell.execute_reply":"2025-05-12T13:11:41.666846Z"},"papermill":{"duration":0.026442,"end_time":"2025-03-24T15:20:23.518284","exception":false,"start_time":"2025-03-24T15:20:23.491842","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":8},{"id":"5e6287f7","cell_type":"code","source":"train_labels = train_data.columns[1:]\nval_labels = val_data.columns[1:]\n\n# Extract features and labels for training and validation\nX_train = train_data['sentence'].values\ny_train = train_data[train_labels].values\nX_val = val_data['sentence'].values\ny_val = val_data[val_labels].values\n\nprint(X_train.shape, y_train.shape)\nprint(X_val.shape, y_val.shape)","metadata":{"execution":{"iopub.status.busy":"2025-05-12T13:11:41.669685Z","iopub.execute_input":"2025-05-12T13:11:41.669954Z","iopub.status.idle":"2025-05-12T13:11:41.681119Z","shell.execute_reply.started":"2025-05-12T13:11:41.669934Z","shell.execute_reply":"2025-05-12T13:11:41.680434Z"},"papermill":{"duration":0.031418,"end_time":"2025-03-24T15:20:23.563456","exception":false,"start_time":"2025-03-24T15:20:23.532038","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"(864,) (864, 6)\n(216,) (216, 6)\n","output_type":"stream"}],"execution_count":9},{"id":"bf4d1eeb","cell_type":"markdown","source":"# BUILD DATASET & DATALOADERS","metadata":{"papermill":{"duration":0.013325,"end_time":"2025-03-24T15:20:23.590779","exception":false,"start_time":"2025-03-24T15:20:23.577454","status":"completed"},"tags":[]}},{"id":"c514aa36","cell_type":"code","source":"class AspectDetectionDataset(Dataset):\n    def __init__(self, texts, labels, label_mapping, tokenizer, max_length=sequence_length, use_float=True):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n        self.use_float = use_float\n        self.label_mapping = label_mapping\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n        \n        original_labels = [self.label_mapping[label] for label in self.labels[idx]]\n        encoded_labels = [1 if label == 1 else 0 for label in original_labels]\n        \n        item = {key: val.squeeze() for key, val in encoding.items()}\n        item['ori_indices'] = idx\n        item['ori_text'] = self.texts[idx]\n        item['ori_label'] = torch.tensor(original_labels, dtype=torch.float)\n        item['labels'] = torch.tensor(encoded_labels, dtype=torch.float if self.use_float else torch.long)\n        \n        return item","metadata":{"execution":{"iopub.status.busy":"2025-05-12T13:11:41.681984Z","iopub.execute_input":"2025-05-12T13:11:41.682247Z","iopub.status.idle":"2025-05-12T13:11:41.693989Z","shell.execute_reply.started":"2025-05-12T13:11:41.682221Z","shell.execute_reply":"2025-05-12T13:11:41.693137Z"},"papermill":{"duration":0.024076,"end_time":"2025-03-24T15:20:23.628841","exception":false,"start_time":"2025-03-24T15:20:23.604765","status":"completed"},"scrolled":true,"tags":[],"trusted":true},"outputs":[],"execution_count":10},{"id":"e6dcb1ab","cell_type":"code","source":"class SentimentAnalysisDataset(Dataset):\n    def __init__(self, texts, labels, aspects, indices, label_mapping, tokenizer, max_length=96, use_float=True):\n        self.texts = texts\n        self.labels = labels\n        self.aspects = aspects\n        self.indices = indices\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n        self.use_float = use_float\n        self.label_mapping = label_mapping\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = aspect_token + ' ' + self.aspects[idx] + ' ' + review_token + ' ' + self.texts[idx] \n        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n\n        if isinstance(self.labels[idx], str):\n            self.labels[idx] = self.label_mapping[self.labels[idx]]\n        elif torch.is_tensor(self.labels[idx]):\n            self.labels[idx] = int(self.labels[idx].item())\n\n        encoded_label = 1 if self.labels[idx] == 2 else self.labels[idx]\n        one_hot_label = F.one_hot(torch.tensor(encoded_label, dtype=torch.long), num_classes=2).float()\n\n        item = {key: val.squeeze() for key, val in encoding.items()}\n        item['aspect'] = self.aspects[idx]\n        item['labels'] = one_hot_label\n        item['ori_indices'] = self.indices[idx]\n        item['ori_text'] = self.texts[idx]\n        item['ori_label'] = torch.tensor(self.labels[idx], dtype=torch.long)\n\n        return item","metadata":{"execution":{"iopub.status.busy":"2025-05-12T13:11:41.694950Z","iopub.execute_input":"2025-05-12T13:11:41.695289Z","iopub.status.idle":"2025-05-12T13:11:41.706412Z","shell.execute_reply.started":"2025-05-12T13:11:41.695257Z","shell.execute_reply":"2025-05-12T13:11:41.705612Z"},"papermill":{"duration":0.024518,"end_time":"2025-03-24T15:20:23.667573","exception":false,"start_time":"2025-03-24T15:20:23.643055","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":11},{"id":"c351bced","cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p1')\nreview_token = '[REVIEW]'\naspect_token = '[ASPECT]'\nspecial_tokens_dict = {'additional_special_tokens': [review_token, aspect_token]}\nnum_added_tokens = tokenizer.add_special_tokens(special_tokens_dict)","metadata":{"execution":{"iopub.status.busy":"2025-05-12T13:11:41.707330Z","iopub.execute_input":"2025-05-12T13:11:41.707561Z","iopub.status.idle":"2025-05-12T13:11:42.380685Z","shell.execute_reply.started":"2025-05-12T13:11:41.707537Z","shell.execute_reply":"2025-05-12T13:11:42.380067Z"},"papermill":{"duration":2.924985,"end_time":"2025-03-24T15:20:26.606002","exception":false,"start_time":"2025-03-24T15:20:23.681017","status":"completed"},"tags":[],"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2b8173b518b4ac686fe0b551fc525ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/229k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b8ee2dc529f49238d838e83f6a54657"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62174c24f53544a193ec8f1fdd1f4309"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e0515a2f0d64c40a0c8332299887a6e"}},"metadata":{}}],"execution_count":12},{"id":"5b424c8e","cell_type":"code","source":"def build_aspect_dataset(X_train, y_train, X_val, y_val, sequence_length, num_workers=4):\n    train_dataset = AspectDetectionDataset(X_train, y_train, label_mapping, tokenizer, max_length=sequence_length)\n    val_dataset = AspectDetectionDataset(X_val, y_val, label_mapping, tokenizer, max_length=sequence_length)\n    \n    train_loader = torch.utils.data.DataLoader(\n        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=num_workers,\n    )\n    val_loader = torch.utils.data.DataLoader(\n        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=num_workers, \n    )\n\n    return train_loader, val_loader, train_dataset, val_dataset","metadata":{"execution":{"iopub.status.busy":"2025-05-12T13:11:42.381395Z","iopub.execute_input":"2025-05-12T13:11:42.381591Z","iopub.status.idle":"2025-05-12T13:11:42.386403Z","shell.execute_reply.started":"2025-05-12T13:11:42.381575Z","shell.execute_reply":"2025-05-12T13:11:42.385661Z"},"papermill":{"duration":0.022587,"end_time":"2025-03-24T15:20:26.643619","exception":false,"start_time":"2025-03-24T15:20:26.621032","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":13},{"id":"4cac8e38","cell_type":"code","source":"def build_sentiment_dataset(device, train_dataset, val_dataset, aspect_detection_model, tokenizer, max_length=sequence_length):\n    train_loader = torch.utils.data.DataLoader(\n        train_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n    )\n    val_loader = torch.utils.data.DataLoader(\n        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n    )\n\n    aspect_detection_model.to(device)\n    aspect_detection_model.eval()\n\n    train_data = []\n    train_labels = []\n    train_aspects = []\n    train_indices = []\n\n    val_data = []\n    val_labels = []\n    val_aspects = []\n    val_indices = []\n\n    # Transform train set\n    start_time = time.time()\n    with torch.no_grad():\n        for batch in train_loader:\n            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n            labels = batch['labels'].to(device)\n            \n            outputs = aspect_detection_model(**inputs)\n            preds = torch.sigmoid(outputs.logits).round()\n\n            for i in range(len(preds)):\n                for j in range(len(preds[i])):\n                    if int(preds[i][j]) != 1:\n                        train_aspects.append(aspect_list[j])\n                        train_data.append(batch['ori_text'][i])\n                        train_labels.append(batch['ori_label'][i][j])\n                        train_indices.append(batch['ori_indices'][i])\n            \n        # Transform validation set\n        for batch in val_loader:\n            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n            labels = batch['labels'].to(device)\n            \n            outputs = aspect_detection_model(**inputs)\n            preds = torch.sigmoid(outputs.logits).round()\n\n            for i in range(len(preds)):\n                for j in range(len(preds[i])):\n                    if int(preds[i][j]) != 1:\n                        val_aspects.append(aspect_list[j])\n                        val_data.append(batch['ori_text'][i])\n                        val_labels.append(batch['ori_label'][i][j])\n                        val_indices.append(batch['ori_indices'][i])\n\n    train_dataset = SentimentAnalysisDataset(train_data, train_labels, train_aspects, train_indices, label_mapping, tokenizer, max_length=max_length)\n    val_dataset = SentimentAnalysisDataset(val_data, val_labels, val_aspects, val_indices, label_mapping, tokenizer, max_length=max_length)\n\n    train_loader = torch.utils.data.DataLoader(\n        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=4, \n    )\n    val_loader = torch.utils.data.DataLoader(\n        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n    )\n\n    return train_loader, val_loader, train_dataset, val_dataset","metadata":{"execution":{"iopub.status.busy":"2025-05-12T13:11:42.387081Z","iopub.execute_input":"2025-05-12T13:11:42.387312Z","iopub.status.idle":"2025-05-12T13:11:42.400117Z","shell.execute_reply.started":"2025-05-12T13:11:42.387294Z","shell.execute_reply":"2025-05-12T13:11:42.399344Z"},"papermill":{"duration":0.030303,"end_time":"2025-03-24T15:20:26.688888","exception":false,"start_time":"2025-03-24T15:20:26.658585","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":14},{"id":"bb25ba9a","cell_type":"markdown","source":"# TRAIN THE MODEL","metadata":{"papermill":{"duration":0.013915,"end_time":"2025-03-24T15:20:26.717298","exception":false,"start_time":"2025-03-24T15:20:26.703383","status":"completed"},"tags":[]}},{"id":"53fbbd85","cell_type":"code","source":"total_data = len(X_train) + len(X_val)\ninitial_train_size = int(0.05 * total_data)\ncheckpoints = [\n    int(0.5 * total_data), \n    int(0.6 * total_data), \n    int(0.7 * total_data),\n    len(X_train)\n]\nmin_increment = 25","metadata":{"execution":{"iopub.status.busy":"2025-05-12T13:11:42.401077Z","iopub.execute_input":"2025-05-12T13:11:42.401394Z","iopub.status.idle":"2025-05-12T13:11:42.417208Z","shell.execute_reply.started":"2025-05-12T13:11:42.401363Z","shell.execute_reply":"2025-05-12T13:11:42.416307Z"},"papermill":{"duration":0.022767,"end_time":"2025-03-24T15:20:26.754465","exception":false,"start_time":"2025-03-24T15:20:26.731698","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":15},{"id":"510ba2d8","cell_type":"code","source":"def compute_metrics(p, label, classes):\n    preds = torch.tensor(p.predictions) # Sigmoid and threshold for multi-label\n    labels = torch.tensor(p.label_ids)\n\n    # Hamming accuracy: proportion of correctly predicted labels over total labels\n    hamming_accuracy = (preds == labels).float().mean().item()\n\n    # Standard multi-label precision, recall, and F1 metrics\n    precision, recall, f1_micro, _ = precision_recall_fscore_support(labels, preds, average='micro', zero_division=0)\n    _, _, f1_macro, _ = precision_recall_fscore_support(labels, preds, average='macro', zero_division=0)\n\n    report = classification_report(\n        labels, \n        preds, \n        labels=label,\n        target_names=classes,\n        zero_division=0\n    ) \n\n    return {\n        'accuracy': hamming_accuracy,\n        'precision': precision,\n        'recall': recall,\n        'f1_micro': f1_micro,\n        'f1_macro': f1_macro,\n        'report': report\n    }","metadata":{"execution":{"iopub.status.busy":"2025-05-12T13:11:42.418236Z","iopub.execute_input":"2025-05-12T13:11:42.418537Z","iopub.status.idle":"2025-05-12T13:11:42.430691Z","shell.execute_reply.started":"2025-05-12T13:11:42.418506Z","shell.execute_reply":"2025-05-12T13:11:42.429799Z"},"papermill":{"duration":0.02222,"end_time":"2025-03-24T15:20:26.791060","exception":false,"start_time":"2025-03-24T15:20:26.768840","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":16},{"id":"0a99c405","cell_type":"code","source":"def compute_metrics_overall(p, classes):\n    preds = torch.tensor(p.predictions)\n    labels = torch.tensor(p.label_ids)\n\n    # Ensure it's in the correct shape\n    if preds.shape != labels.shape:\n        raise ValueError(\"Shape mismatch: predictions and labels must have the same shape.\")\n\n    # Hamming accuracy: proportion of correctly predicted labels over total labels\n    hamming_accuracy = (preds == labels).float().mean().item()\n\n    # Compute per-label (column-wise) precision, recall, F1\n    precision_list, recall_list, f1_micro_list, f1_macro_list = [], [], [], []\n    \n    for i in range(labels.shape[1]):  # Loop through each column (multi-output)\n        prec, rec, f1_micro, _ = precision_recall_fscore_support(\n            labels[:, i], preds[:, i], average='micro', zero_division=0\n        )\n        _, _, f1_macro, _ = precision_recall_fscore_support(\n            labels[:, i], preds[:, i], average='macro', zero_division=0\n        )\n\n        precision_list.append(prec)\n        recall_list.append(rec)\n        f1_micro_list.append(f1_micro)\n        f1_macro_list.append(f1_macro)\n\n    # Compute average metrics across all outputs\n    precision = sum(precision_list) / len(precision_list)\n    recall = sum(recall_list) / len(recall_list)\n    f1_micro = sum(f1_micro_list) / len(f1_micro_list)\n    f1_macro = sum(f1_macro_list) / len(f1_macro_list)\n\n    # Generate classification report per output\n    reports = [classification_report(labels[:, i], preds[:, i], target_names=classes, zero_division=0) for i in range(labels.shape[1])]\n\n    return {\n        'accuracy': hamming_accuracy,\n        'precision': precision,\n        'recall': recall,\n        'f1_micro': f1_micro,\n        'f1_macro': f1_macro,\n        'reports': reports  # Returns list of reports, one for each output label\n    }","metadata":{"execution":{"iopub.status.busy":"2025-05-12T13:11:42.431826Z","iopub.execute_input":"2025-05-12T13:11:42.432068Z","iopub.status.idle":"2025-05-12T13:11:42.446830Z","shell.execute_reply.started":"2025-05-12T13:11:42.432041Z","shell.execute_reply":"2025-05-12T13:11:42.446030Z"},"papermill":{"duration":0.023708,"end_time":"2025-03-24T15:20:26.829424","exception":false,"start_time":"2025-03-24T15:20:26.805716","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":17},{"id":"bfaf0971","cell_type":"code","source":"def train_model(current_train_size, train_indices, aspect_metrics, sentiment_metrics, metrics, trials, seed):\n    accelerator = Accelerator(mixed_precision='fp16')  # Initialize the accelerator\n    device = accelerator.device\n\n    aspect_model = BertForSequenceClassification.from_pretrained(\n        'indobenchmark/indobert-base-p1',\n        num_labels=len(train_labels),\n        problem_type=\"multi_label_classification\"\n    )\n\n    # Freeze the first few layers of the encoder\n    for name, param in aspect_model.named_parameters():\n        if \"encoder.layer\" in name:\n            layer_num = name.split(\".\")[3]\n            try:\n                if int(layer_num) < 6:\n                    param.requires_grad = False\n            except ValueError:\n                continue\n\n    # Define optimizer and loss function\n    aspect_optimizer = torch.optim.AdamW(aspect_model.parameters(), lr=2e-5, weight_decay=0.01)\n    loss_fn = torch.nn.BCEWithLogitsLoss()\n\n    # Define DataLoaders\n    current_X_train = [X_train[i] for i in train_indices]\n    current_y_train = [y_train[i] for i in train_indices]\n    aspect_train_loader, aspect_val_loader, aspect_train_dataset, aspect_val_dataset = build_aspect_dataset(current_X_train, current_y_train, X_val, y_val, sequence_length)\n\n    # Prepare everything with Accelerator\n    aspect_model, aspect_optimizer, aspect_train_loader, aspect_val_loader = accelerator.prepare(\n        aspect_model, aspect_optimizer, aspect_train_loader, aspect_val_loader\n    )\n\n    nearest_cp = current_train_size\n    if nearest_cp not in checkpoints:\n        for cp in checkpoints:\n            if cp > current_train_size:\n                nearest_cp = cp\n                break\n    percentage = math.ceil(nearest_cp / total_data * 100)\n\n    aspect_result = None\n    start_time = time.time()\n\n    # ASPECT DETECTION\n    accelerator.print(\"ASPECT DETECTION\")\n    for epoch in range(epochs):\n        aspect_model.train()\n        epoch_loss = 0\n\n        for batch in aspect_train_loader:\n            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n            labels = batch['labels']\n        \n            aspect_optimizer.zero_grad()\n            outputs = aspect_model(**inputs)\n            loss = loss_fn(outputs.logits, labels)\n            accelerator.backward(loss)\n            aspect_optimizer.step()\n        \n            epoch_loss += loss.item()\n            \n        aspect_model.eval()\n        all_preds = []\n        all_labels = []\n        \n        with torch.no_grad():\n            for batch in aspect_val_loader:\n                inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n                labels = batch['labels']\n                \n                outputs = aspect_model(**inputs)\n                preds = torch.sigmoid(outputs.logits).round()\n\n                # Gather predictions and labels from all devices\n                all_preds.append(accelerator.gather(preds))\n                all_labels.append(accelerator.gather(labels))\n\n        all_preds = torch.cat(all_preds).cpu().numpy()\n        all_labels = torch.cat(all_labels).cpu().numpy()\n\n        result = compute_metrics(\n            type('EvalOutput', (object,), {'predictions': all_preds, 'label_ids': all_labels}),\n            None,\n            ['fuel', 'machine', 'others', 'part', 'price', 'service']\n        )\n\n        if aspect_result is None or result['f1_micro'] >= aspect_result['f1_micro']:\n            accelerator.print(\"Higher F1 achieved, saving model\")\n            \n            accelerator.wait_for_everyone()\n            unwrapped_model = accelerator.unwrap_model(aspect_model)\n            unwrapped_model.save_pretrained(\n                f'{filename}-aspect-model-{percentage}',\n                is_main_process=accelerator.is_main_process,\n                save_function=accelerator.save,\n            )\n            aspect_result = result\n\n        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(aspect_train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n\n    accelerator.print(f\"\\nAspect detection accuracy: {round(aspect_result['accuracy'], 4)}, F1 Micro: {round(aspect_result['f1_micro'], 4)}, F1 Macro: {round(aspect_result['f1_macro'], 4)}\")\n    accelerator.print(aspect_result['report'])\n\n    best_aspect_model = BertForSequenceClassification.from_pretrained(f'{filename}-aspect-model-{percentage}')\n    best_aspect_model = accelerator.prepare(best_aspect_model)\n\n    # SENTIMENT ANALYSIS ON NON NEUTRAL ASPECTS\n    accelerator.print(\"--------------------------------------------------\")\n    accelerator.print(\"SENTIMENT ANALYSIS\")\n\n    sentiment_model = BertForSequenceClassification.from_pretrained(\n        'indobenchmark/indobert-base-p1',\n        num_labels=2,\n    )\n    sentiment_optimizer = torch.optim.AdamW(sentiment_model.parameters(), lr=2e-5, weight_decay=0.01)\n\n    for name, param in sentiment_model.named_parameters():\n        if \"encoder.layer\" in name:\n            layer_num = name.split(\".\")[3]\n            try:\n                if int(layer_num) < 6:\n                    param.requires_grad = False\n            except ValueError:\n                continue\n\n    accelerator.wait_for_everyone()\n    sentiment_train_loader, sentiment_val_loader, sentiment_train_dataset, sentiment_val_dataset = build_sentiment_dataset(\n        device, aspect_train_dataset, aspect_val_dataset, best_aspect_model, tokenizer, max_length=sequence_length\n    )\n    sentiment_model, sentiment_optimizer, sentiment_train_loader, sentiment_val_loader = accelerator.prepare(\n        sentiment_model, sentiment_optimizer, sentiment_train_loader, sentiment_val_loader\n    )\n    sentiment_result = None\n\n    for epoch in range(epochs):\n        sentiment_model.train()\n        epoch_loss = 0\n        \n        for batch in sentiment_train_loader:\n            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n            labels = batch['labels']\n        \n            sentiment_optimizer.zero_grad()\n            outputs = sentiment_model(**inputs)\n            loss = loss_fn(outputs.logits, labels)\n            accelerator.backward(loss)\n            sentiment_optimizer.step()\n        \n            epoch_loss += loss.item()\n\n        sentiment_model.eval()\n        sentiment_val_outputs = []\n        \n        with torch.no_grad():\n            for batch in sentiment_val_loader:\n                inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n                \n                outputs = sentiment_model(**inputs)\n                preds = torch.sigmoid(outputs.logits).round()\n\n                for i in range(len(preds)):\n                    val_output = {\n                        'label': batch['labels'][i],\n                        'aspect': batch['aspect'][i],\n                        'ori_indices': batch['ori_indices'][i],\n                        'pred': np.argmax(preds[i].cpu().numpy()),\n                    }\n                    sentiment_val_outputs.append(val_output)\n\n        sentiment_val_outputs = accelerator.gather_for_metrics(sentiment_val_outputs)\n        unique_val_outputs = {(x['ori_indices'].item(), x['aspect']): x for x in sentiment_val_outputs}\n        sentiment_val_outputs = list(unique_val_outputs.values())\n\n        result = compute_metrics(\n            type('EvalOutput', (object,), {'predictions': [item['pred'] for item in sentiment_val_outputs], 'label_ids': [np.argmax(item['label'].cpu().numpy()) for item in sentiment_val_outputs]}),\n            [0, 1],\n            ['negative', 'positive']\n        )\n\n        if sentiment_result is None or result['f1_micro'] >= sentiment_result['f1_micro']:\n            accelerator.print(\"Higher F1 achieved, saving model\")\n            sentiment_result = result\n            \n            accelerator.wait_for_everyone()\n            unwrapped_model = accelerator.unwrap_model(sentiment_model)\n            unwrapped_model.save_pretrained(\n                 f'{filename}-sentiment-model-{percentage}',\n                is_main_process=accelerator.is_main_process,\n                save_function=accelerator.save,\n            )\n\n        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(sentiment_train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n    \n    end_time = time.time()\n    duration = end_time - start_time\n\n    accelerator.print(f\"\\nSentiment analysis accuracy: {round(sentiment_result['accuracy'], 4)}, F1 Micro: {round(sentiment_result['f1_micro'], 4)}, F1 Macro: {round(sentiment_result['f1_macro'], 4)}\")\n    accelerator.print(sentiment_result['report'])\n\n    accelerator.wait_for_everyone()\n    best_sentiment_model = BertForSequenceClassification.from_pretrained( f'{filename}-sentiment-model-{percentage}')\n    best_sentiment_model = accelerator.prepare(best_sentiment_model)\n\n    # Compute overall metrics\n    aspect_labels = []\n    aspect_indices = []\n    aspect_preds = []\n\n    aspect_outputs = {}\n    sentiment_outputs = []\n    \n    best_aspect_model.eval()\n    best_sentiment_model.eval()\n\n    with torch.no_grad():\n        for batch in aspect_val_loader:\n            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n            outputs = best_aspect_model(**inputs)\n            preds = torch.sigmoid(outputs.logits).round()\n\n            aspect_indices.append(accelerator.gather(batch['ori_indices']))\n            aspect_labels.append(accelerator.gather(batch['ori_label']))\n            aspect_preds.append(accelerator.gather(preds))\n\n        aspect_indices = torch.cat(aspect_indices).cpu().numpy()\n        aspect_labels = torch.cat(aspect_labels).cpu().numpy()\n        aspect_preds = torch.cat(aspect_preds).cpu().numpy()\n\n        accelerator.wait_for_everyone()\n        aspect_outputs = [\n            {'ori_indices': aspect_indices[i], \n             'ori_labels': aspect_labels[i], \n             'pred': aspect_preds[i]}\n            for i in range(len(aspect_preds))\n        ]\n        aspect_outputs = {x['ori_indices'].item(): x for x in aspect_outputs}\n    \n        for batch in sentiment_val_loader:\n            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n            outputs = best_sentiment_model(**inputs)\n            preds = torch.sigmoid(outputs.logits).round()\n    \n            for i in range(len(preds)):\n                output = {\n                    'aspect': batch['aspect'][i],\n                    'ori_indices': batch['ori_indices'][i],\n                    'pred': np.argmax(preds[i].cpu().numpy()),\n                }\n                sentiment_outputs.append(output)\n\n        sentiment_outputs = accelerator.gather_for_metrics(sentiment_outputs)\n        sentiment_outputs = {(x['ori_indices'].item(), x['aspect']): x for x in sentiment_outputs}\n\n    # Replcae non neutral aspect to its predicted sentiment\n    accelerator.wait_for_everyone()\n    if accelerator.is_main_process:\n        i = -1\n        for (ori_index, aspect), value in sentiment_outputs.items():\n            aspect = aspect_mapping[aspect]\n            aspect_outputs[ori_index]['pred'][aspect] = 2 if value['pred'] == 1.0 else value['pred']\n\n        result = compute_metrics_overall(\n            type('EvalOutput', (object,), {'predictions': [output['pred'] for output in aspect_outputs.values()], 'label_ids': [output['ori_labels'] for output in aspect_outputs.values()]}),\n            ['negative', 'neutral', 'positive'],\n        )\n\n        accelerator.print(\"--------------------------------------------------\")\n        accelerator.print(f\"Iteration {current_train_size}: Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n        accelerator.print(\"--------------------------------------------------\")\n        for i in range(len(train_labels)):\n            accelerator.print(f\"Aspect {aspect_list[i]} report:\")\n            accelerator.print(result['reports'][i])\n       \n        \n        aspect_metrics[0].append(aspect_result['accuracy'])\n        aspect_metrics[1].append(aspect_result['f1_micro'])\n        aspect_metrics[2].append(aspect_result['f1_macro'])\n        sentiment_metrics[0].append(sentiment_result['accuracy'])\n        sentiment_metrics[1].append(sentiment_result['f1_micro'])\n        sentiment_metrics[2].append(sentiment_result['f1_macro'])\n        metrics[0].append(current_train_size)\n        metrics[1].append(result['accuracy'])\n        metrics[2].append(result['f1_micro'])\n        metrics[3].append(result['f1_macro'])\n        \n    accelerator.print(f\"Total train time: {duration} s\")\n    accelerator.end_training()\n    return","metadata":{"execution":{"iopub.status.busy":"2025-05-12T13:11:42.447728Z","iopub.execute_input":"2025-05-12T13:11:42.448002Z","iopub.status.idle":"2025-05-12T13:11:42.478043Z","shell.execute_reply.started":"2025-05-12T13:11:42.447975Z","shell.execute_reply":"2025-05-12T13:11:42.477176Z"},"papermill":{"duration":0.047501,"end_time":"2025-03-24T15:20:26.891727","exception":false,"start_time":"2025-03-24T15:20:26.844226","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":18},{"id":"ff34f396","cell_type":"markdown","source":"# PLOT THE RESULTS","metadata":{"papermill":{"duration":0.01389,"end_time":"2025-03-24T15:20:26.920194","exception":false,"start_time":"2025-03-24T15:20:26.906304","status":"completed"},"tags":[]}},{"id":"bae1112f","cell_type":"code","source":"def plot_result(data_used, accuracies, f1_micros, f1_macros):\n    fig, axs = plt.subplots(1, 3, figsize=(21, 5))\n    data_used = [round(data / total_data * 100, 1) for data in data_used]\n\n    # Plot for Accuracy\n    axs[0].plot(data_used, accuracies, label=\"Accuracy\", color=\"blue\")\n    axs[0].set_xlabel(\"Percentage of data used\")\n    axs[0].set_title(\"Accuracy\")\n    axs[0].set_xticks(data_used)\n\n    # Plot for F1 Micro\n    axs[1].plot(data_used, f1_micros, label=\"F1 Micro\", color=\"orange\")\n    axs[1].set_xlabel(\"Percentage of data used\")\n    axs[1].set_title(\"F1 Micro\")\n    axs[1].set_xticks(data_used)\n\n    # Plot for F1 Macro\n    axs[2].plot(data_used, f1_macros, label=\"F1 Macro\", color=\"green\")\n    axs[2].set_xlabel(\"Percentage of data used\")\n    axs[2].set_title(\"F1 Macro\")\n    axs[2].set_xticks(data_used)\n\n    # Adjust layout and show the plots\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2025-05-12T13:11:42.479016Z","iopub.execute_input":"2025-05-12T13:11:42.479308Z","iopub.status.idle":"2025-05-12T13:11:42.490910Z","shell.execute_reply.started":"2025-05-12T13:11:42.479280Z","shell.execute_reply":"2025-05-12T13:11:42.490185Z"},"papermill":{"duration":0.022534,"end_time":"2025-03-24T15:20:26.956877","exception":false,"start_time":"2025-03-24T15:20:26.934343","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":19},{"id":"841f1d61","cell_type":"markdown","source":"# QUERY STRATEGY","metadata":{"papermill":{"duration":0.013594,"end_time":"2025-03-24T15:20:26.984314","exception":false,"start_time":"2025-03-24T15:20:26.970720","status":"completed"},"tags":[]}},{"id":"a373681b-b07b-4a86-ab01-e64e1be79b23","cell_type":"code","source":"def combined_sampling(aspect_model, sentiment_model, X_pool, train_indices, remaining_indices, sampling_dur, new_samples, trials, n_samples=min_increment):\n    accelerator = Accelerator(mixed_precision=\"fp16\")\n    device = accelerator.device\n\n    aspect_model.to(device)\n    aspect_model.eval()\n    sentiment_model.to(device)\n    sentiment_model.eval()\n\n    current_train_size = len(train_indices)\n    \n    # Check nearest checkpoint\n    nearest_cp = 0\n    for cp in checkpoints:\n        if cp > current_train_size:\n            nearest_cp = cp\n            break\n\n    target_samples = math.ceil(0.1*len(remaining_indices))\n    if target_samples <= min_increment and min_increment < nearest_cp - current_train_size:\n        target_samples = min_increment\n    elif target_samples > min_increment and target_samples < nearest_cp - current_train_size:\n        target_samples = target_samples\n    else:\n        target_samples = nearest_cp - current_train_size\n\n    final_cp = False\n    if current_train_size >= checkpoints[-1] - target_samples:\n        final_cp = True\n\n        if accelerator.is_main_process:\n            temp = train_indices.copy()\n            temp.extend(remaining_indices)\n            \n            # Save acquired data up to checkpoint\n            acquired_data = pd.DataFrame({\n                'processed_text': [X_train[i] for i in temp],\n                'fuel': [y_train[i][0] for i in temp],\n                'machine': [y_train[i][1] for i in temp],\n                'others': [y_train[i][2] for i in temp],\n                'part': [y_train[i][3] for i in temp],\n                'price': [y_train[i][4] for i in temp],\n                'service': [y_train[i][5] for i in temp],\n            })\n            acquired_data.to_csv(f'acquired_data/{filename}-data-{nearest_cp}.csv', index=False)\n            \n            print(\"Nearest checkpoint:\", nearest_cp)\n            print(\"Acquired samples:\", len(remaining_indices))\n            \n            sampling_dur.append(0)\n            for i in remaining_indices:\n                new_samples.append(i)\n                \n    accelerator.wait_for_everyone()\n    if not final_cp:\n        aspect_dataset = AspectDetectionDataset(\n            X_pool, \n            [['neutral' for i in range(len(train_labels))] for x in range(len(X_pool))], \n            label_mapping, \n            tokenizer, \n            max_length=sequence_length\n        )\n        aspect_loader = DataLoader(\n            aspect_dataset,\n            batch_size=batch_size,\n            shuffle=False,\n            num_workers=4,\n            pin_memory=True,\n        )\n\n        start_time = time.time()\n\n        lc_indices = least_confidence_sampling(aspect_model, sentiment_model, aspect_loader, device, target_samples)\n        lc_indices = [remaining_indices[i] for i in lc_indices]\n        accelerator.print(f\"Got {len(lc_indices)} samples from lc\")\n\n        kmeans_indices = kmeans_clustering_sampling(aspect_model, sentiment_model, aspect_loader, device, target_samples)\n        kmeans_indices = [remaining_indices[i] for i in kmeans_indices]\n        accelerator.print(f\"Got {len(kmeans_indices)} samples from kmeans\")\n\n        if accelerator.is_main_process:\n            # Combine both methods' results\n            combined_indices = list(set(lc_indices).union(set(kmeans_indices)))\n            \n            # If we got more than we need, take only what we need\n            if len(combined_indices) > target_samples:\n                np.random.shuffle(combined_indices)\n                combined_indices = combined_indices[:target_samples]\n            \n            # Calculate duration\n            end_time = time.time()\n            duration = end_time - start_time\n            \n            # Check if we've reached a checkpoint\n            if current_train_size + len(combined_indices) >= nearest_cp:\n                temp = train_indices.copy()\n                temp.extend(combined_indices)\n                \n                # Save acquired data up to checkpoint\n                acquired_data = pd.DataFrame({\n                    'processed_text': [X_train[i] for i in temp],\n                    'fuel': [y_train[i][0] for i in temp],\n                    'machine': [y_train[i][1] for i in temp],\n                    'others': [y_train[i][2] for i in temp],\n                    'part': [y_train[i][3] for i in temp],\n                    'price': [y_train[i][4] for i in temp],\n                    'service': [y_train[i][5] for i in temp],\n                })\n                acquired_data.to_csv(f'acquired_data/{filename}-data-{nearest_cp}.csv', index=False)\n            \n            # Log results\n            print(\"Nearest checkpoint:\", nearest_cp)\n            print(f\"Acquired samples: {len(combined_indices)}\")\n            print(f\"Sampling duration: {duration} seconds\")\n            \n            sampling_dur.append(duration)\n            for i in combined_indices:\n                new_samples.append(i)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T13:11:42.491757Z","iopub.execute_input":"2025-05-12T13:11:42.491946Z","iopub.status.idle":"2025-05-12T13:11:42.504931Z","shell.execute_reply.started":"2025-05-12T13:11:42.491930Z","shell.execute_reply":"2025-05-12T13:11:42.504271Z"}},"outputs":[],"execution_count":20},{"id":"37931c5b","cell_type":"code","source":"def least_confidence_sampling(aspect_model, sentiment_model, aspect_loader, device, target_samples):\n    aspect_outputs = {}\n    sentiment_outputs = {}\n\n    aspects = []\n    data = []\n    labels = []\n    indices = []\n\n    # Pass through aspect detction model\n    for batch in aspect_loader:\n        token_type_ids = batch['token_type_ids'].to(device, non_blocking=True)\n        input_ids = batch['input_ids'].to(device, non_blocking=True)\n        attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n        \n        with torch.no_grad():\n            outputs = aspect_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n            preds = torch.sigmoid(outputs.logits)\n\n        for i in range(len(preds)):\n            aspect_outputs[batch['ori_indices'][i].item()] = np.max(preds[i].cpu().numpy())\n            \n            for j in range(len(preds[i])):\n                if int(preds[i][j].round()) != 1:\n                    aspects.append(aspect_list[j])\n                    data.append(batch['ori_text'][i])\n                    labels.append(batch['ori_label'][i][j])\n                    indices.append(batch['ori_indices'][i])\n    \n    sentiment_dataset = SentimentAnalysisDataset(data, labels, aspects, indices, label_mapping, tokenizer, max_length=sequence_length)\n    sentiment_loader = torch.utils.data.DataLoader(\n        sentiment_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4,\n    )\n\n    # Pass through sentiment analysis model\n    for batch in sentiment_loader:\n        token_type_ids = batch['token_type_ids'].to(device, non_blocking=True)\n        input_ids = batch['input_ids'].to(device, non_blocking=True)\n        attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n\n        with torch.no_grad():\n            outputs = sentiment_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n            preds = torch.sigmoid(outputs.logits)\n\n        for i in range(len(preds)):\n            ori_index = batch['ori_indices'][i].item()\n            if ori_index in sentiment_outputs.keys():\n                max_pred = np.max(preds[i].cpu().numpy())\n                sentiment_outputs[ori_index] = max_pred if max_pred > sentiment_outputs[ori_index] else sentiment_outputs[ori_index]\n            else:\n                sentiment_outputs[ori_index] = np.max(preds[i].cpu().numpy())\n\n    aspect_outputs = dict(sorted(aspect_outputs.items()))\n\n    # accelerator.print(aspect_outputs)\n    for key, val in sentiment_outputs.items():\n        aspect_outputs[key] = 1 - ((val + aspect_outputs[key]) / 2)\n\n    # accelerator.print(aspect_outputs)\n    uncertainties = np.array(list(aspect_outputs.values()))\n    sorted_unc = np.argsort(uncertainties)\n    sorted_unc = sorted_unc[::-1]\n\n    threshold = np.percentile(uncertainties, 90)\n    items_greater_than_average = uncertainties[uncertainties >= threshold]\n    least_confident_indices = sorted_unc[:target_samples]\n\n    return least_confident_indices","metadata":{"execution":{"iopub.status.busy":"2025-05-12T13:11:42.505818Z","iopub.execute_input":"2025-05-12T13:11:42.506074Z","iopub.status.idle":"2025-05-12T13:11:42.519602Z","shell.execute_reply.started":"2025-05-12T13:11:42.506044Z","shell.execute_reply":"2025-05-12T13:11:42.518850Z"},"papermill":{"duration":0.034321,"end_time":"2025-03-24T15:20:27.032394","exception":false,"start_time":"2025-03-24T15:20:26.998073","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":21},{"id":"b73b1ae6-4e10-41c3-b27f-668325315f6c","cell_type":"code","source":"def kmeans_clustering_sampling(aspect_model, sentiment_model, aspect_loader, device, target_samples, n_clusters=min_increment):\n    aspect_outputs = {}\n    sentiment_outputs = {}\n\n    aspects = []\n    data = []\n    labels = []\n    indices = []\n\n    # Pass through aspect detction model\n    for batch in aspect_loader:\n        token_type_ids = batch['token_type_ids'].to(device, non_blocking=True)\n        input_ids = batch['input_ids'].to(device, non_blocking=True)\n        attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n        \n        with torch.no_grad():\n            outputs = aspect_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids).logits\n            embeddings = aspect_model.base_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n\n        for i in range(len(outputs)):\n            aspect_outputs[batch['ori_indices'][i].item()] = embeddings.last_hidden_state[i].mean(dim=1).cpu().numpy()\n            \n            for j in range(len(outputs[i])):\n                if int(outputs[i][j].round()) != 1:\n                    aspects.append(aspect_list[j])\n                    data.append(batch['ori_text'][i])\n                    labels.append(batch['ori_label'][i][j])\n                    indices.append(batch['ori_indices'][i])\n\n    if len(data) > 0:\n        sentiment_dataset = SentimentAnalysisDataset(data, labels, aspects, indices, label_mapping, tokenizer, max_length=sequence_length)\n        sentiment_loader = torch.utils.data.DataLoader(\n            sentiment_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4,\n        )\n    \n        # Pass through sentiment analysis model\n        for batch in sentiment_loader:\n            token_type_ids = batch['token_type_ids'].to(device, non_blocking=True)\n            input_ids = batch['input_ids'].to(device, non_blocking=True)\n            attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n    \n            with torch.no_grad():\n                outputs = sentiment_model.base_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n    \n            for i in range(len(outputs.last_hidden_state)):\n                ori_index = batch['ori_indices'][i].item()\n                if ori_index in sentiment_outputs.keys():\n                    sentiment_outputs[ori_index].append(outputs.last_hidden_state[i].mean(dim=1).cpu().numpy())\n                else:\n                    sentiment_outputs[ori_index] = [outputs.last_hidden_state[i].mean(dim=1).cpu().numpy()]\n\n    for key, val in sentiment_outputs.items():\n        sentiment_outputs[key] = np.mean(val, axis=0)\n\n    collected_indices = set()  # Initialize set to store selected indices\n    thresholds = []\n\n    aspect_outputs = dict(sorted(aspect_outputs.items()))\n\n    if len(data) > 0:\n        for key, val in sentiment_outputs.items():\n            aspect_outputs[key] = np.mean([val, aspect_outputs[key]], axis=0)\n\n    embeddings = np.array(list(aspect_outputs.values()))\n\n    # Cluster the data based on its embeddings\n    kmeans=KMeans(n_clusters=n_clusters, n_init=1)\n    kmeans.fit(embeddings)\n    \n    for cluster_id in range(n_clusters):\n        # Cluster center and indices of samples in the current cluster\n        cluster_center = kmeans.cluster_centers_[cluster_id]\n        cluster_indices = np.where(kmeans.labels_ == cluster_id)[0]\n    \n        if cluster_indices.size == 0:\n            # Skip clusters with no members\n            print(f\"Cluster {cluster_id} has no members, skipping.\")\n            continue\n    \n        # Calculate distances of each point in the cluster from the cluster center\n        cluster_distances = np.linalg.norm(embeddings[cluster_indices] - cluster_center, axis=1)\n    \n        # Determine the local threshold (10th percentile of closest distances to cluster center)\n        local_threshold = np.percentile(cluster_distances, 90)\n        thresholds.append(local_threshold)\n    \n        below_threshold_indices = cluster_indices[cluster_distances >= local_threshold]\n        collected_indices.update(below_threshold_indices)\n\n    # To handle multiple points with same distance\n    if len(collected_indices) > target_samples:\n        collected_indices = np.array(list(collected_indices))\n        np.random.shuffle(collected_indices)\n        collected_indices = collected_indices[:target_samples]\n\n    return collected_indices[:target_samples]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T13:11:42.520475Z","iopub.execute_input":"2025-05-12T13:11:42.520703Z","iopub.status.idle":"2025-05-12T13:11:42.535508Z","shell.execute_reply.started":"2025-05-12T13:11:42.520679Z","shell.execute_reply":"2025-05-12T13:11:42.534848Z"}},"outputs":[],"execution_count":22},{"id":"7170cf1a","cell_type":"markdown","source":"# MAIN LOOP","metadata":{"papermill":{"duration":0.01387,"end_time":"2025-03-24T15:20:27.060491","exception":false,"start_time":"2025-03-24T15:20:27.046621","status":"completed"},"tags":[]}},{"id":"3c2d2fb5","cell_type":"code","source":"def active_learning(seed, i):\n    aspect_accuracies = manager.list()\n    aspect_f1_micros = manager.list()\n    aspect_f1_macros = manager.list()\n    sentiment_accuracies = manager.list()\n    sentiment_f1_micros = manager.list()\n    sentiment_f1_macros = manager.list()\n    accuracies = manager.list()\n    f1_micros = manager.list()\n    f1_macros = manager.list()\n    data_used = manager.list()\n    sampling_dur = manager.list()\n    new_samples = manager.list()\n\n    set_seed(seed)\n    \n    print(\"===============================================\")\n    print(\"TRIAL {}\".format(i+1))\n    print(\"Random seed:\", seed)\n    \n    train_indices = np.random.choice(range(len(X_train)), initial_train_size, replace=False).tolist()\n    remaining_indices = list(set(range(len(X_train))) - set(train_indices))\n    \n    current_train_size = initial_train_size\n    \n    start_time = time.time()\n    while current_train_size < checkpoints[len(checkpoints) - 1]:\n        # Train the model\n        args = (\n            current_train_size, \n            train_indices, \n            (aspect_accuracies, aspect_f1_micros, aspect_f1_macros), \n            (sentiment_accuracies, sentiment_f1_micros, sentiment_f1_macros),\n            (data_used, accuracies, f1_micros, f1_macros), \n            i,\n            seed\n        )\n        notebook_launcher(train_model, args, num_processes=2)\n\n        nearest_cp = current_train_size\n        if nearest_cp not in checkpoints:\n            for cp in checkpoints:\n                if cp > current_train_size:\n                    nearest_cp = cp\n                    break\n        percentage = math.ceil(nearest_cp / total_data * 100)\n\n        aspect_model = BertForSequenceClassification.from_pretrained(f'{filename}-aspect-model-{percentage}')\n        sentiment_model = BertForSequenceClassification.from_pretrained(f'{filename}-sentiment-model-{percentage}')\n    \n        # Perform query strategy to select new samples\n        new_samples = manager.list()\n        sampling_args = (\n            aspect_model, \n            sentiment_model, \n            [X_train[i] for i in remaining_indices], \n            train_indices, \n            remaining_indices, \n            sampling_dur, \n            new_samples, \n            i\n        )\n        notebook_launcher(combined_sampling, sampling_args, num_processes=2)\n        new_samples = list(new_samples)\n        train_indices.extend(new_samples)\n        remaining_indices = list(set(remaining_indices) - set(new_samples))\n    \n        # Update current training size\n        current_train_size = len(train_indices)\n        print(\"New train size: {}\".format(current_train_size))\n    \n    # Train last epoch\n    args = (\n        current_train_size, \n        train_indices, \n        (aspect_accuracies, aspect_f1_micros, aspect_f1_macros), \n        (sentiment_accuracies, sentiment_f1_micros, sentiment_f1_macros),\n        (data_used, accuracies, f1_micros, f1_macros), \n        i,\n        seed\n    )\n    notebook_launcher(train_model, args, num_processes=2)\n    data_used, accuracies, f1_micros, f1_macros, sampling_dur = list(data_used), list(accuracies), list(f1_micros), list(f1_macros), list(sampling_dur)\n    \n    end_time = time.time()\n    duration = end_time - start_time\n    \n    # print(f\"Total sampling time: {np.array(sampling_dur).sum().round(2)} seconds\")\n    print(f\"Total runtime: {duration} seconds\")\n    \n    plot_result(data_used, accuracies, f1_micros, f1_macros)\n    \n    results = pd.DataFrame({\n        'Data Used': data_used,\n        'Aspect Accuracy': aspect_accuracies,\n        'Aspect F1 Micro': aspect_f1_micros,\n        'Aspect F1 Macro': aspect_f1_macros,\n        'Sentiment Accuracy': sentiment_accuracies,\n        'Sentiment F1 Micro': sentiment_f1_micros,\n        'Sentiment F1 Macro': sentiment_f1_macros,\n        'Accuracy': accuracies,\n        'F1 Micro': f1_micros,\n        'F1 Macro': f1_macros,\n    })\n    \n    sampling_dur.insert(0, 0)\n    results['Sampling Duration'] = sampling_dur\n    results.to_csv(f'results/{filename}-{i+1}-results.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2025-05-12T13:11:42.538315Z","iopub.execute_input":"2025-05-12T13:11:42.538526Z","iopub.status.idle":"2025-05-12T13:11:42.555924Z","shell.execute_reply.started":"2025-05-12T13:11:42.538508Z","shell.execute_reply":"2025-05-12T13:11:42.555020Z"},"papermill":{"duration":0.02884,"end_time":"2025-03-24T15:20:27.104016","exception":false,"start_time":"2025-03-24T15:20:27.075176","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":23},{"id":"b4d83f20","cell_type":"code","source":"seeds = [50, 81, 14, 3, 94]","metadata":{"execution":{"iopub.status.busy":"2025-05-12T13:11:42.557412Z","iopub.execute_input":"2025-05-12T13:11:42.557603Z","iopub.status.idle":"2025-05-12T13:11:42.573265Z","shell.execute_reply.started":"2025-05-12T13:11:42.557586Z","shell.execute_reply":"2025-05-12T13:11:42.572051Z"},"papermill":{"duration":0.020516,"end_time":"2025-03-24T15:20:27.138969","exception":false,"start_time":"2025-03-24T15:20:27.118453","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":24},{"id":"042a3ef9","cell_type":"markdown","source":"## RUN 1","metadata":{"papermill":{"duration":0.014092,"end_time":"2025-03-24T15:20:27.167516","exception":false,"start_time":"2025-03-24T15:20:27.153424","status":"completed"},"tags":[]}},{"id":"17e8e234","cell_type":"code","source":"active_learning(seeds[0], 0)","metadata":{"execution":{"iopub.status.busy":"2025-05-12T13:11:42.574364Z","iopub.execute_input":"2025-05-12T13:11:42.574653Z","execution_failed":"2025-05-12T13:14:15.039Z"},"papermill":{"duration":2923.638644,"end_time":"2025-03-24T16:09:10.820612","exception":false,"start_time":"2025-03-24T15:20:27.181968","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"===============================================\nTRIAL 1\nRandom seed: 50\nLaunching training on 2 GPUs.\n","output_type":"stream"},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"ASPECT DETECTION\nHigher F1 achieved, saving model\nEpoch 1/10, Train Loss: 0.5319, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\nHigher F1 achieved, saving model\nEpoch 2/10, Train Loss: 0.4126, Accuracy: 0.9196, F1 Micro: 0.9508, F1 Macro: 0.949\nHigher F1 achieved, saving model\nEpoch 3/10, Train Loss: 0.2776, Accuracy: 0.9501, F1 Micro: 0.969, F1 Macro: 0.9676\nHigher F1 achieved, saving model\nEpoch 4/10, Train Loss: 0.1861, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9722\nHigher F1 achieved, saving model\nEpoch 5/10, Train Loss: 0.1304, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9763\nEpoch 6/10, Train Loss: 0.0981, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9724\nEpoch 7/10, Train Loss: 0.0789, Accuracy: 0.9583, F1 Micro: 0.9737, F1 Macro: 0.9719\nEpoch 8/10, Train Loss: 0.0669, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9752\nHigher F1 achieved, saving model\nEpoch 9/10, Train Loss: 0.0531, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9777\nEpoch 10/10, Train Loss: 0.0486, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9754\n\nAspect detection accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9777\n              precision    recall  f1-score   support\n\n        fuel       0.98      0.99      0.99       187\n     machine       0.96      0.98      0.97       175\n      others       0.93      0.94      0.94       158\n        part       0.98      0.98      0.98       158\n       price       0.99      0.99      0.99       192\n     service       1.00      1.00      1.00       191\n\n   micro avg       0.98      0.98      0.98      1061\n   macro avg       0.97      0.98      0.98      1061\nweighted avg       0.98      0.98      0.98      1061\n samples avg       0.97      0.98      0.97      1061\n\n--------------------------------------------------\nSENTIMENT ANALYSIS\n","output_type":"stream"},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Higher F1 achieved, saving model\nEpoch 1/10, Train Loss: 0.5074, Accuracy: 0.9104, F1 Micro: 0.9104, F1 Macro: 0.9002\nEpoch 2/10, Train Loss: 0.2298, Accuracy: 0.8918, F1 Micro: 0.8918, F1 Macro: 0.8841\nHigher F1 achieved, saving model\nEpoch 3/10, Train Loss: 0.1415, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.9283\nHigher F1 achieved, saving model\nEpoch 4/10, Train Loss: 0.1347, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.9298\nEpoch 5/10, Train Loss: 0.0975, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9255\nHigher F1 achieved, saving model\nEpoch 6/10, Train Loss: 0.0961, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9338\nEpoch 7/10, Train Loss: 0.0738, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9259\nHigher F1 achieved, saving model\nEpoch 8/10, Train Loss: 0.0919, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9374\nHigher F1 achieved, saving model\nEpoch 9/10, Train Loss: 0.0846, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9378\nEpoch 10/10, Train Loss: 0.0452, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.9298\n\nSentiment analysis accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9378\n              precision    recall  f1-score   support\n\n    negative       0.88      0.97      0.92        87\n    positive       0.98      0.93      0.96       181\n\n    accuracy                           0.94       268\n   macro avg       0.93      0.95      0.94       268\nweighted avg       0.95      0.94      0.94       268\n\n--------------------------------------------------\nIteration 745: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.9239\n--------------------------------------------------\nAspect fuel report:\n              precision    recall  f1-score   support\n\n    negative       0.92      1.00      0.96        11\n     neutral       0.99      0.99      0.99       181\n    positive       0.95      0.88      0.91        24\n\n    accuracy                           0.98       216\n   macro avg       0.95      0.96      0.95       216\nweighted avg       0.98      0.98      0.98       216\n\nAspect machine report:\n              precision    recall  f1-score   support\n\n    negative       0.88      0.88      0.88        16\n     neutral       0.96      0.98      0.97       167\n    positive       0.87      0.79      0.83        33\n\n    accuracy                           0.94       216\n   macro avg       0.90      0.88      0.89       216\nweighted avg       0.94      0.94      0.94       216\n\nAspect others report:\n              precision    recall  f1-score   support\n\n    negative       0.77      0.83      0.80        12\n     neutral       0.93      0.94      0.94       152\n    positive       0.82      0.79      0.80        52\n\n    accuracy                           0.90       216\n   macro avg       0.84      0.85      0.85       216\nweighted avg       0.90      0.90      0.90       216\n\nAspect part report:\n              precision    recall  f1-score   support\n\n    negative       0.82      1.00      0.90        23\n     neutral       0.98      0.98      0.98       152\n    positive       0.94      0.83      0.88        41\n\n    accuracy                           0.95       216\n   macro avg       0.92      0.94      0.92       216\nweighted avg       0.96      0.95      0.95       216\n\nAspect price report:\n              precision    recall  f1-score   support\n\n    negative       0.92      0.92      0.92        13\n     neutral       0.99      0.99      0.99       186\n    positive       0.88      0.88      0.88        17\n\n    accuracy                           0.98       216\n   macro avg       0.93      0.93      0.93       216\nweighted avg       0.98      0.98      0.98       216\n\nAspect service report:\n              precision    recall  f1-score   support\n\n    negative       1.00      1.00      1.00        14\n     neutral       1.00      1.00      1.00       185\n    positive       1.00      1.00      1.00        17\n\n    accuracy                           1.00       216\n   macro avg       1.00      1.00      1.00       216\nweighted avg       1.00      1.00      1.00       216\n\nTotal train time: 131.3169903755188 s\nLaunching training on 2 GPUs.\nGot 11 samples from lc\nGot 11 samples from kmeans\nNearest checkpoint: 756\nAcquired samples: 11\nSampling duration: 5.605010032653809 seconds\nNew train size: 756\nLaunching training on 2 GPUs.\n","output_type":"stream"},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"ASPECT DETECTION\nHigher F1 achieved, saving model","output_type":"stream"}],"execution_count":null}]}