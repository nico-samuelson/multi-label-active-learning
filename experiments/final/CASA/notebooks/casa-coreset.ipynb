{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dc3e7ca",
   "metadata": {
    "papermill": {
     "duration": 0.011403,
     "end_time": "2025-03-26T09:38:46.177084",
     "exception": false,
     "start_time": "2025-03-26T09:38:46.165681",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3d6e62c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T09:38:46.199504Z",
     "iopub.status.busy": "2025-03-26T09:38:46.199250Z",
     "iopub.status.idle": "2025-03-26T09:39:17.956456Z",
     "shell.execute_reply": "2025-03-26T09:39:17.955166Z"
    },
    "papermill": {
     "duration": 31.769863,
     "end_time": "2025-03-26T09:39:17.958296",
     "exception": false,
     "start_time": "2025-03-26T09:38:46.188433",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score, classification_report\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "from torch.multiprocessing import Manager\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel, BertPreTrainedModel, BertConfig, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e89b261",
   "metadata": {
    "papermill": {
     "duration": 0.01491,
     "end_time": "2025-03-26T09:39:17.987036",
     "exception": false,
     "start_time": "2025-03-26T09:39:17.972126",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab7168ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T09:39:18.014953Z",
     "iopub.status.busy": "2025-03-26T09:39:18.014393Z",
     "iopub.status.idle": "2025-03-26T09:39:18.018360Z",
     "shell.execute_reply": "2025-03-26T09:39:18.017424Z"
    },
    "papermill": {
     "duration": 0.02031,
     "end_time": "2025-03-26T09:39:18.019829",
     "exception": false,
     "start_time": "2025-03-26T09:39:17.999519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36fcb961",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T09:39:18.041755Z",
     "iopub.status.busy": "2025-03-26T09:39:18.041441Z",
     "iopub.status.idle": "2025-03-26T09:39:18.045929Z",
     "shell.execute_reply": "2025-03-26T09:39:18.045137Z"
    },
    "papermill": {
     "duration": 0.016975,
     "end_time": "2025-03-26T09:39:18.047415",
     "exception": false,
     "start_time": "2025-03-26T09:39:18.030440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists('/kaggle/working/results') == False:\n",
    "    os.mkdir('/kaggle/working/results')\n",
    "\n",
    "if os.path.exists('/kaggle/working/acquired_data') == False:\n",
    "    os.mkdir('/kaggle/working/acquired_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b29b9669",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T09:39:18.085527Z",
     "iopub.status.busy": "2025-03-26T09:39:18.085285Z",
     "iopub.status.idle": "2025-03-26T09:39:18.098324Z",
     "shell.execute_reply": "2025-03-26T09:39:18.097565Z"
    },
    "papermill": {
     "duration": 0.032998,
     "end_time": "2025-03-26T09:39:18.099743",
     "exception": false,
     "start_time": "2025-03-26T09:39:18.066745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "    torch.backends.cudnn.benchmark=False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0125723",
   "metadata": {
    "papermill": {
     "duration": 0.010362,
     "end_time": "2025-03-26T09:39:18.128825",
     "exception": false,
     "start_time": "2025-03-26T09:39:18.118463",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# GLOBAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12c2c936",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T09:39:18.151418Z",
     "iopub.status.busy": "2025-03-26T09:39:18.151090Z",
     "iopub.status.idle": "2025-03-26T09:39:18.227283Z",
     "shell.execute_reply": "2025-03-26T09:39:18.225434Z"
    },
    "papermill": {
     "duration": 0.089814,
     "end_time": "2025-03-26T09:39:18.229459",
     "exception": false,
     "start_time": "2025-03-26T09:39:18.139645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "\n",
    "# Shared resources\n",
    "aspect_accuracies = manager.list()\n",
    "aspect_f1_micros = manager.list()\n",
    "aspect_f1_macros = manager.list()\n",
    "sentiment_accuracies = manager.list()\n",
    "sentiment_f1_micros = manager.list()\n",
    "sentiment_f1_macros = manager.list()\n",
    "accuracies = manager.list()\n",
    "f1_micros = manager.list()\n",
    "f1_macros = manager.list()\n",
    "farthest_point = manager.Value(\"s\", \"test\")\n",
    "\n",
    "# Non shared resources\n",
    "filename = 'casa-coreset'\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "sequence_length = 48\n",
    "\n",
    "aspect_list = ['fuel', 'machine', 'others', 'part', 'price', 'service']\n",
    "aspect_mapping = {'fuel': 0, 'machine': 1, 'others': 2, 'part': 3, 'price': 4, 'service': 5 }\n",
    "label_mapping = {\"negative\": 0, \"neutral\": 1, 'positive': 2}\n",
    "ignored_keys = ['labels', 'ori_text', 'ori_label', 'ori_indices', 'aspect']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4e05b3",
   "metadata": {
    "papermill": {
     "duration": 0.010462,
     "end_time": "2025-03-26T09:39:18.257268",
     "exception": false,
     "start_time": "2025-03-26T09:39:18.246806",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LOAD AND PREPROCESS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9772f4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T09:39:18.279357Z",
     "iopub.status.busy": "2025-03-26T09:39:18.279060Z",
     "iopub.status.idle": "2025-03-26T09:39:18.384797Z",
     "shell.execute_reply": "2025-03-26T09:39:18.383846Z"
    },
    "papermill": {
     "duration": 0.118585,
     "end_time": "2025-03-26T09:39:18.386237",
     "exception": false,
     "start_time": "2025-03-26T09:39:18.267652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>fuel</th>\n",
       "      <th>machine</th>\n",
       "      <th>others</th>\n",
       "      <th>part</th>\n",
       "      <th>price</th>\n",
       "      <th>service</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saya memakai Honda Jazz GK5 tahun 2014 ( perta...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Avanza kenapa jadi boros bensin begini dah ah....</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saran ku dan pengalaman ku , mending beli mobi...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dari segi harga juga pajero lebih mahal 30 jut...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kalo menurut gw enak pajero si</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence      fuel   machine  \\\n",
       "0  Saya memakai Honda Jazz GK5 tahun 2014 ( perta...   neutral   neutral   \n",
       "1  Avanza kenapa jadi boros bensin begini dah ah....  negative   neutral   \n",
       "2  saran ku dan pengalaman ku , mending beli mobi...  positive  positive   \n",
       "3  Dari segi harga juga pajero lebih mahal 30 jut...   neutral   neutral   \n",
       "4                     Kalo menurut gw enak pajero si   neutral   neutral   \n",
       "\n",
       "     others     part     price  service  \n",
       "0  positive  neutral   neutral  neutral  \n",
       "1   neutral  neutral   neutral  neutral  \n",
       "2   neutral  neutral   neutral  neutral  \n",
       "3   neutral  neutral  positive  neutral  \n",
       "4  positive  neutral   neutral  neutral  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('/kaggle/input/casa-dataset/train_preprocess.csv', encoding='latin-1')\n",
    "val_data = pd.read_csv('/kaggle/input/casa-dataset/valid_preprocess.csv', encoding='latin-1')\n",
    "test_data = pd.read_csv('/kaggle/input/casa-dataset/test_preprocess.csv', encoding='latin-1')\n",
    "\n",
    "data = pd.concat([train_data, val_data, test_data], ignore_index=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9713ecb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T09:39:18.409135Z",
     "iopub.status.busy": "2025-03-26T09:39:18.408832Z",
     "iopub.status.idle": "2025-03-26T09:39:18.419995Z",
     "shell.execute_reply": "2025-03-26T09:39:18.418946Z"
    },
    "papermill": {
     "duration": 0.024245,
     "end_time": "2025-03-26T09:39:18.421640",
     "exception": false,
     "start_time": "2025-03-26T09:39:18.397395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26888a9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T09:39:18.451833Z",
     "iopub.status.busy": "2025-03-26T09:39:18.451410Z",
     "iopub.status.idle": "2025-03-26T09:39:18.466026Z",
     "shell.execute_reply": "2025-03-26T09:39:18.465218Z"
    },
    "papermill": {
     "duration": 0.032268,
     "end_time": "2025-03-26T09:39:18.467264",
     "exception": false,
     "start_time": "2025-03-26T09:39:18.434996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(864,) (864, 6)\n",
      "(216,) (216, 6)\n"
     ]
    }
   ],
   "source": [
    "train_labels = train_data.columns[1:]\n",
    "val_labels = val_data.columns[1:]\n",
    "\n",
    "# Extract features and labels for training and validation\n",
    "X_train = train_data['sentence'].values\n",
    "y_train = train_data[train_labels].values\n",
    "X_val = val_data['sentence'].values\n",
    "y_val = val_data[val_labels].values\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41e351c",
   "metadata": {
    "papermill": {
     "duration": 0.010707,
     "end_time": "2025-03-26T09:39:18.488890",
     "exception": false,
     "start_time": "2025-03-26T09:39:18.478183",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BUILD DATASET & DATALOADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4f82f4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T09:39:18.511147Z",
     "iopub.status.busy": "2025-03-26T09:39:18.510910Z",
     "iopub.status.idle": "2025-03-26T09:39:18.517084Z",
     "shell.execute_reply": "2025-03-26T09:39:18.516240Z"
    },
    "papermill": {
     "duration": 0.019017,
     "end_time": "2025-03-26T09:39:18.518506",
     "exception": false,
     "start_time": "2025-03-26T09:39:18.499489",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AspectDetectionDataset(Dataset):\n",
    "    def __init__(self, texts, labels, label_mapping, tokenizer, max_length=sequence_length, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.use_float = use_float\n",
    "        self.label_mapping = label_mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "        \n",
    "        original_labels = [self.label_mapping[label] for label in self.labels[idx]]\n",
    "        encoded_labels = [1 if label == 1 else 0 for label in original_labels]\n",
    "        \n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['ori_indices'] = idx\n",
    "        item['ori_text'] = self.texts[idx]\n",
    "        item['ori_label'] = torch.tensor(original_labels, dtype=torch.float)\n",
    "        item['labels'] = torch.tensor(encoded_labels, dtype=torch.float if self.use_float else torch.long)\n",
    "        \n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "437c0d50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T09:39:18.540975Z",
     "iopub.status.busy": "2025-03-26T09:39:18.540511Z",
     "iopub.status.idle": "2025-03-26T09:39:18.552400Z",
     "shell.execute_reply": "2025-03-26T09:39:18.551506Z"
    },
    "papermill": {
     "duration": 0.02452,
     "end_time": "2025-03-26T09:39:18.553663",
     "exception": false,
     "start_time": "2025-03-26T09:39:18.529143",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SentimentAnalysisDataset(Dataset):\n",
    "    def __init__(self, texts, labels, aspects, indices, label_mapping, tokenizer, max_length=96, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.aspects = aspects\n",
    "        self.indices = indices\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.use_float = use_float\n",
    "        self.label_mapping = label_mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = aspect_token + ' ' + self.aspects[idx] + ' ' + review_token + ' ' + self.texts[idx] \n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "\n",
    "        if isinstance(self.labels[idx], str):\n",
    "            self.labels[idx] = self.label_mapping[self.labels[idx]]\n",
    "        elif torch.is_tensor(self.labels[idx]):\n",
    "            self.labels[idx] = int(self.labels[idx].item())\n",
    "\n",
    "        encoded_label = 1 if self.labels[idx] == 2 else self.labels[idx]\n",
    "        one_hot_label = F.one_hot(torch.tensor(encoded_label, dtype=torch.long), num_classes=2).float()\n",
    "\n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['aspect'] = self.aspects[idx]\n",
    "        item['labels'] = one_hot_label\n",
    "        item['ori_indices'] = self.indices[idx]\n",
    "        item['ori_text'] = self.texts[idx]\n",
    "        item['ori_label'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ccd7447",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T09:39:18.575935Z",
     "iopub.status.busy": "2025-03-26T09:39:18.575711Z",
     "iopub.status.idle": "2025-03-26T09:39:19.821249Z",
     "shell.execute_reply": "2025-03-26T09:39:19.820355Z"
    },
    "papermill": {
     "duration": 1.258522,
     "end_time": "2025-03-26T09:39:19.822855",
     "exception": false,
     "start_time": "2025-03-26T09:39:18.564333",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26d725e875364ac48c888532189ae7da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7040a67c6a5c4d0b86fd5abeca634089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/229k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "252b664280be4046abb0568e8f93b775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "193a59acc8354659ba88d5583dcac19f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p1')\n",
    "review_token = '[REVIEW]'\n",
    "aspect_token = '[ASPECT]'\n",
    "special_tokens_dict = {'additional_special_tokens': [review_token, aspect_token]}\n",
    "num_added_tokens = tokenizer.add_special_tokens(special_tokens_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c01a3e06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T09:39:19.846491Z",
     "iopub.status.busy": "2025-03-26T09:39:19.846245Z",
     "iopub.status.idle": "2025-03-26T09:39:19.851018Z",
     "shell.execute_reply": "2025-03-26T09:39:19.850112Z"
    },
    "papermill": {
     "duration": 0.017614,
     "end_time": "2025-03-26T09:39:19.852202",
     "exception": false,
     "start_time": "2025-03-26T09:39:19.834588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_aspect_dataset(X_train, y_train, X_val, y_val, sequence_length, num_workers=4):\n",
    "    train_dataset = AspectDetectionDataset(X_train, y_train, label_mapping, tokenizer, max_length=sequence_length)\n",
    "    val_dataset = AspectDetectionDataset(X_val, y_val, label_mapping, tokenizer, max_length=sequence_length)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=num_workers,\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=num_workers, \n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46aeefe7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T09:39:19.875829Z",
     "iopub.status.busy": "2025-03-26T09:39:19.875590Z",
     "iopub.status.idle": "2025-03-26T09:39:19.885211Z",
     "shell.execute_reply": "2025-03-26T09:39:19.884431Z"
    },
    "papermill": {
     "duration": 0.022866,
     "end_time": "2025-03-26T09:39:19.886421",
     "exception": false,
     "start_time": "2025-03-26T09:39:19.863555",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_sentiment_dataset(device, train_dataset, val_dataset, aspect_detection_model, tokenizer, max_length=sequence_length):\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "\n",
    "    aspect_detection_model.to(device)\n",
    "    aspect_detection_model.eval()\n",
    "\n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "    train_aspects = []\n",
    "    train_indices = []\n",
    "\n",
    "    val_data = []\n",
    "    val_labels = []\n",
    "    val_aspects = []\n",
    "    val_indices = []\n",
    "\n",
    "    # Transform train set\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        for batch in train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = aspect_detection_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            for i in range(len(preds)):\n",
    "                for j in range(len(preds[i])):\n",
    "                    if int(preds[i][j]) != 1:\n",
    "                        train_aspects.append(aspect_list[j])\n",
    "                        train_data.append(batch['ori_text'][i])\n",
    "                        train_labels.append(batch['ori_label'][i][j])\n",
    "                        train_indices.append(batch['ori_indices'][i])\n",
    "            \n",
    "        # Transform validation set\n",
    "        for batch in val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = aspect_detection_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            for i in range(len(preds)):\n",
    "                for j in range(len(preds[i])):\n",
    "                    if int(preds[i][j]) != 1:\n",
    "                        val_aspects.append(aspect_list[j])\n",
    "                        val_data.append(batch['ori_text'][i])\n",
    "                        val_labels.append(batch['ori_label'][i][j])\n",
    "                        val_indices.append(batch['ori_indices'][i])\n",
    "\n",
    "    train_dataset = SentimentAnalysisDataset(train_data, train_labels, train_aspects, train_indices, label_mapping, tokenizer, max_length=max_length)\n",
    "    val_dataset = SentimentAnalysisDataset(val_data, val_labels, val_aspects, val_indices, label_mapping, tokenizer, max_length=max_length)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bcbcf7",
   "metadata": {
    "papermill": {
     "duration": 0.011197,
     "end_time": "2025-03-26T09:39:19.909156",
     "exception": false,
     "start_time": "2025-03-26T09:39:19.897959",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3eb07b23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T09:39:19.933656Z",
     "iopub.status.busy": "2025-03-26T09:39:19.933405Z",
     "iopub.status.idle": "2025-03-26T09:39:19.937136Z",
     "shell.execute_reply": "2025-03-26T09:39:19.936325Z"
    },
    "papermill": {
     "duration": 0.017365,
     "end_time": "2025-03-26T09:39:19.938284",
     "exception": false,
     "start_time": "2025-03-26T09:39:19.920919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_data = len(X_train) + len(X_val)\n",
    "initial_train_size = int(0.05 * total_data)\n",
    "checkpoints = [\n",
    "    int(0.5 * total_data), \n",
    "    int(0.6 * total_data), \n",
    "    int(0.7 * total_data),\n",
    "    len(X_train)\n",
    "]\n",
    "min_increment = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48e53ec8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T09:39:19.961070Z",
     "iopub.status.busy": "2025-03-26T09:39:19.960850Z",
     "iopub.status.idle": "2025-03-26T09:39:19.965390Z",
     "shell.execute_reply": "2025-03-26T09:39:19.964600Z"
    },
    "papermill": {
     "duration": 0.01722,
     "end_time": "2025-03-26T09:39:19.966613",
     "exception": false,
     "start_time": "2025-03-26T09:39:19.949393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p, label, classes):\n",
    "    preds = torch.tensor(p.predictions) # Sigmoid and threshold for multi-label\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Hamming accuracy: proportion of correctly predicted labels over total labels\n",
    "    hamming_accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Standard multi-label precision, recall, and F1 metrics\n",
    "    precision, recall, f1_micro, _ = precision_recall_fscore_support(labels, preds, average='micro', zero_division=0)\n",
    "    _, _, f1_macro, _ = precision_recall_fscore_support(labels, preds, average='macro', zero_division=0)\n",
    "\n",
    "    report = classification_report(\n",
    "        labels, \n",
    "        preds, \n",
    "        labels=label,\n",
    "        target_names=classes,\n",
    "        zero_division=0\n",
    "    ) \n",
    "\n",
    "    return {\n",
    "        'accuracy': hamming_accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'report': report\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1afa8526",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T09:39:19.989595Z",
     "iopub.status.busy": "2025-03-26T09:39:19.989362Z",
     "iopub.status.idle": "2025-03-26T09:39:19.995352Z",
     "shell.execute_reply": "2025-03-26T09:39:19.994753Z"
    },
    "papermill": {
     "duration": 0.018619,
     "end_time": "2025-03-26T09:39:19.996404",
     "exception": false,
     "start_time": "2025-03-26T09:39:19.977785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics_overall(p, classes):\n",
    "    preds = torch.tensor(p.predictions)\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Ensure it's in the correct shape\n",
    "    if preds.shape != labels.shape:\n",
    "        raise ValueError(\"Shape mismatch: predictions and labels must have the same shape.\")\n",
    "\n",
    "    # Hamming accuracy: proportion of correctly predicted labels over total labels\n",
    "    hamming_accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Compute per-label (column-wise) precision, recall, F1\n",
    "    precision_list, recall_list, f1_micro_list, f1_macro_list = [], [], [], []\n",
    "    \n",
    "    for i in range(labels.shape[1]):  # Loop through each column (multi-output)\n",
    "        prec, rec, f1_micro, _ = precision_recall_fscore_support(\n",
    "            labels[:, i], preds[:, i], average='micro', zero_division=0\n",
    "        )\n",
    "        _, _, f1_macro, _ = precision_recall_fscore_support(\n",
    "            labels[:, i], preds[:, i], average='macro', zero_division=0\n",
    "        )\n",
    "\n",
    "        precision_list.append(prec)\n",
    "        recall_list.append(rec)\n",
    "        f1_micro_list.append(f1_micro)\n",
    "        f1_macro_list.append(f1_macro)\n",
    "\n",
    "    # Compute average metrics across all outputs\n",
    "    precision = sum(precision_list) / len(precision_list)\n",
    "    recall = sum(recall_list) / len(recall_list)\n",
    "    f1_micro = sum(f1_micro_list) / len(f1_micro_list)\n",
    "    f1_macro = sum(f1_macro_list) / len(f1_macro_list)\n",
    "\n",
    "    # Generate classification report per output\n",
    "    reports = [classification_report(labels[:, i], preds[:, i], target_names=classes, zero_division=0) for i in range(labels.shape[1])]\n",
    "\n",
    "    return {\n",
    "        'accuracy': hamming_accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'reports': reports  # Returns list of reports, one for each output label\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee0ffabd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T09:39:20.019348Z",
     "iopub.status.busy": "2025-03-26T09:39:20.019151Z",
     "iopub.status.idle": "2025-03-26T09:39:20.044988Z",
     "shell.execute_reply": "2025-03-26T09:39:20.044176Z"
    },
    "papermill": {
     "duration": 0.038983,
     "end_time": "2025-03-26T09:39:20.046410",
     "exception": false,
     "start_time": "2025-03-26T09:39:20.007427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(current_train_size, train_indices, aspect_metrics, sentiment_metrics, metrics, trials, seed):\n",
    "    accelerator = Accelerator(mixed_precision='fp16')  # Initialize the accelerator\n",
    "    device = accelerator.device\n",
    "\n",
    "    aspect_model = BertForSequenceClassification.from_pretrained(\n",
    "        'indobenchmark/indobert-base-p1',\n",
    "        num_labels=len(train_labels),\n",
    "        problem_type=\"multi_label_classification\"\n",
    "    )\n",
    "\n",
    "    # Freeze the first few layers of the encoder\n",
    "    for name, param in aspect_model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    # Define optimizer and loss function\n",
    "    aspect_optimizer = torch.optim.AdamW(aspect_model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Define DataLoaders\n",
    "    current_X_train = [X_train[i] for i in train_indices]\n",
    "    current_y_train = [y_train[i] for i in train_indices]\n",
    "    aspect_train_loader, aspect_val_loader, aspect_train_dataset, aspect_val_dataset = build_aspect_dataset(current_X_train, current_y_train, X_val, y_val, sequence_length)\n",
    "\n",
    "    # Prepare everything with Accelerator\n",
    "    aspect_model, aspect_optimizer, aspect_train_loader, aspect_val_loader = accelerator.prepare(\n",
    "        aspect_model, aspect_optimizer, aspect_train_loader, aspect_val_loader\n",
    "    )\n",
    "\n",
    "    aspect_result = None\n",
    "    start_time = time.time()\n",
    "\n",
    "    # ASPECT DETECTION\n",
    "    accelerator.print(\"ASPECT DETECTION\")\n",
    "    for epoch in range(epochs):\n",
    "        aspect_model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for batch in aspect_train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels']\n",
    "        \n",
    "            aspect_optimizer.zero_grad()\n",
    "            outputs = aspect_model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            aspect_optimizer.step()\n",
    "        \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "        aspect_model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in aspect_val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "                labels = batch['labels']\n",
    "                \n",
    "                outputs = aspect_model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                # Gather predictions and labels from all devices\n",
    "                all_preds.append(accelerator.gather(preds))\n",
    "                all_labels.append(accelerator.gather(labels))\n",
    "\n",
    "        all_preds = torch.cat(all_preds).cpu().numpy()\n",
    "        all_labels = torch.cat(all_labels).cpu().numpy()\n",
    "\n",
    "        result = compute_metrics(\n",
    "            type('EvalOutput', (object,), {'predictions': all_preds, 'label_ids': all_labels}),\n",
    "            None,\n",
    "            ['fuel', 'machine', 'others', 'part', 'price', 'service']\n",
    "        )\n",
    "\n",
    "        if aspect_result is None or result['f1_micro'] >= aspect_result['f1_micro']:\n",
    "            accelerator.print(\"Higher F1 achieved, saving model\")\n",
    "            \n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(aspect_model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                f'{filename}-aspect-{trials + 1}-model',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "            aspect_result = result\n",
    "\n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(aspect_train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "\n",
    "    accelerator.print(f\"\\nAspect detection accuracy: {round(aspect_result['accuracy'], 4)}, F1 Micro: {round(aspect_result['f1_micro'], 4)}, F1 Macro: {round(aspect_result['f1_macro'], 4)}\")\n",
    "    accelerator.print(aspect_result['report'])\n",
    "\n",
    "    best_aspect_model = BertForSequenceClassification.from_pretrained(f'{filename}-aspect-{trials + 1}-model')\n",
    "    best_aspect_model = accelerator.prepare(best_aspect_model)\n",
    "\n",
    "    # SENTIMENT ANALYSIS ON NON NEUTRAL ASPECTS\n",
    "    accelerator.print(\"--------------------------------------------------\")\n",
    "    accelerator.print(\"SENTIMENT ANALYSIS\")\n",
    "\n",
    "    sentiment_model = BertForSequenceClassification.from_pretrained(\n",
    "        'indobenchmark/indobert-base-p1',\n",
    "        num_labels=2,\n",
    "    )\n",
    "    sentiment_optimizer = torch.optim.AdamW(sentiment_model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "\n",
    "    for name, param in sentiment_model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    sentiment_train_loader, sentiment_val_loader, sentiment_train_dataset, sentiment_val_dataset = build_sentiment_dataset(\n",
    "        device, aspect_train_dataset, aspect_val_dataset, best_aspect_model, tokenizer, max_length=sequence_length\n",
    "    )\n",
    "    sentiment_model, sentiment_optimizer, sentiment_train_loader, sentiment_val_loader = accelerator.prepare(\n",
    "        sentiment_model, sentiment_optimizer, sentiment_train_loader, sentiment_val_loader\n",
    "    )\n",
    "    sentiment_result = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        sentiment_model.train()\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for batch in sentiment_train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels']\n",
    "        \n",
    "            sentiment_optimizer.zero_grad()\n",
    "            outputs = sentiment_model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            sentiment_optimizer.step()\n",
    "        \n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        sentiment_model.eval()\n",
    "        sentiment_val_outputs = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in sentiment_val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "                \n",
    "                outputs = sentiment_model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                for i in range(len(preds)):\n",
    "                    val_output = {\n",
    "                        'label': batch['labels'][i],\n",
    "                        'aspect': batch['aspect'][i],\n",
    "                        'ori_indices': batch['ori_indices'][i],\n",
    "                        'pred': np.argmax(preds[i].cpu().numpy()),\n",
    "                    }\n",
    "                    sentiment_val_outputs.append(val_output)\n",
    "\n",
    "        sentiment_val_outputs = accelerator.gather_for_metrics(sentiment_val_outputs)\n",
    "        unique_val_outputs = {(x['ori_indices'].item(), x['aspect']): x for x in sentiment_val_outputs}\n",
    "        sentiment_val_outputs = list(unique_val_outputs.values())\n",
    "\n",
    "        result = compute_metrics(\n",
    "            type('EvalOutput', (object,), {'predictions': [item['pred'] for item in sentiment_val_outputs], 'label_ids': [np.argmax(item['label'].cpu().numpy()) for item in sentiment_val_outputs]}),\n",
    "            [0, 1],\n",
    "            ['negative', 'positive']\n",
    "        )\n",
    "\n",
    "        if sentiment_result is None or result['f1_micro'] >= sentiment_result['f1_micro']:\n",
    "            accelerator.print(\"Higher F1 achieved, saving model\")\n",
    "            sentiment_result = result\n",
    "            \n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(sentiment_model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                 f'{filename}-sentiment-{trials + 1}-model',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "\n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(sentiment_train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "\n",
    "    accelerator.print(f\"\\nSentiment analysis accuracy: {round(sentiment_result['accuracy'], 4)}, F1 Micro: {round(sentiment_result['f1_micro'], 4)}, F1 Macro: {round(sentiment_result['f1_macro'], 4)}\")\n",
    "    accelerator.print(sentiment_result['report'])\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    best_sentiment_model = BertForSequenceClassification.from_pretrained( f'{filename}-sentiment-{trials + 1}-model')\n",
    "    best_sentiment_model = accelerator.prepare(best_sentiment_model)\n",
    "\n",
    "    # Compute overall metrics\n",
    "    aspect_labels = []\n",
    "    aspect_indices = []\n",
    "    aspect_preds = []\n",
    "\n",
    "    aspect_outputs = {}\n",
    "    sentiment_outputs = []\n",
    "    \n",
    "    best_aspect_model.eval()\n",
    "    best_sentiment_model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in aspect_val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            outputs = best_aspect_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            aspect_indices.append(accelerator.gather(batch['ori_indices']))\n",
    "            aspect_labels.append(accelerator.gather(batch['ori_label']))\n",
    "            aspect_preds.append(accelerator.gather(preds))\n",
    "\n",
    "        aspect_indices = torch.cat(aspect_indices).cpu().numpy()\n",
    "        aspect_labels = torch.cat(aspect_labels).cpu().numpy()\n",
    "        aspect_preds = torch.cat(aspect_preds).cpu().numpy()\n",
    "\n",
    "        accelerator.wait_for_everyone()\n",
    "        aspect_outputs = [\n",
    "            {'ori_indices': aspect_indices[i], \n",
    "             'ori_labels': aspect_labels[i], \n",
    "             'pred': aspect_preds[i]}\n",
    "            for i in range(len(aspect_preds))\n",
    "        ]\n",
    "        aspect_outputs = {x['ori_indices'].item(): x for x in aspect_outputs}\n",
    "    \n",
    "        for batch in sentiment_val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            outputs = best_sentiment_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "    \n",
    "            for i in range(len(preds)):\n",
    "                output = {\n",
    "                    'aspect': batch['aspect'][i],\n",
    "                    'ori_indices': batch['ori_indices'][i],\n",
    "                    'pred': np.argmax(preds[i].cpu().numpy()),\n",
    "                }\n",
    "                sentiment_outputs.append(output)\n",
    "\n",
    "        sentiment_outputs = accelerator.gather_for_metrics(sentiment_outputs)\n",
    "        sentiment_outputs = {(x['ori_indices'].item(), x['aspect']): x for x in sentiment_outputs}\n",
    "\n",
    "    # Replcae non neutral aspect to its predicted sentiment\n",
    "    accelerator.wait_for_everyone()\n",
    "    if accelerator.is_main_process:\n",
    "        i = -1\n",
    "        for (ori_index, aspect), value in sentiment_outputs.items():\n",
    "            aspect = aspect_mapping[aspect]\n",
    "            aspect_outputs[ori_index]['pred'][aspect] = 2 if value['pred'] == 1.0 else value['pred']\n",
    "\n",
    "        result = compute_metrics_overall(\n",
    "            type('EvalOutput', (object,), {'predictions': [output['pred'] for output in aspect_outputs.values()], 'label_ids': [output['ori_labels'] for output in aspect_outputs.values()]}),\n",
    "            ['negative', 'neutral', 'positive'],\n",
    "        )\n",
    "\n",
    "        accelerator.print(\"--------------------------------------------------\")\n",
    "        accelerator.print(f\"Iteration {current_train_size}: Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "        accelerator.print(\"--------------------------------------------------\")\n",
    "        for i in range(len(train_labels)):\n",
    "            accelerator.print(f\"Aspect {aspect_list[i]} report:\")\n",
    "            accelerator.print(result['reports'][i])\n",
    "       \n",
    "        \n",
    "        aspect_metrics[0].append(aspect_result['accuracy'])\n",
    "        aspect_metrics[1].append(aspect_result['f1_micro'])\n",
    "        aspect_metrics[2].append(aspect_result['f1_macro'])\n",
    "        sentiment_metrics[0].append(sentiment_result['accuracy'])\n",
    "        sentiment_metrics[1].append(sentiment_result['f1_micro'])\n",
    "        sentiment_metrics[2].append(sentiment_result['f1_macro'])\n",
    "        metrics[0].append(current_train_size)\n",
    "        metrics[1].append(result['accuracy'])\n",
    "        metrics[2].append(result['f1_micro'])\n",
    "        metrics[3].append(result['f1_macro'])\n",
    "        \n",
    "    accelerator.print(f\"Total train time: {duration} s\")\n",
    "    accelerator.end_training()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6933b",
   "metadata": {
    "papermill": {
     "duration": 0.011018,
     "end_time": "2025-03-26T09:39:20.068855",
     "exception": false,
     "start_time": "2025-03-26T09:39:20.057837",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PLOT THE RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ddfa79fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T09:39:20.092162Z",
     "iopub.status.busy": "2025-03-26T09:39:20.091932Z",
     "iopub.status.idle": "2025-03-26T09:39:20.097273Z",
     "shell.execute_reply": "2025-03-26T09:39:20.096453Z"
    },
    "papermill": {
     "duration": 0.018271,
     "end_time": "2025-03-26T09:39:20.098412",
     "exception": false,
     "start_time": "2025-03-26T09:39:20.080141",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_result(data_used, accuracies, f1_micros, f1_macros):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(21, 5))\n",
    "    data_used = [round(data / total_data * 100, 1) for data in data_used]\n",
    "\n",
    "    # Plot for Accuracy\n",
    "    axs[0].plot(data_used, accuracies, label=\"Accuracy\", color=\"blue\")\n",
    "    axs[0].set_xlabel(\"Percentage of data used\")\n",
    "    axs[0].set_title(\"Accuracy\")\n",
    "    axs[0].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Micro\n",
    "    axs[1].plot(data_used, f1_micros, label=\"F1 Micro\", color=\"orange\")\n",
    "    axs[1].set_xlabel(\"Percentage of data used\")\n",
    "    axs[1].set_title(\"F1 Micro\")\n",
    "    axs[1].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Macro\n",
    "    axs[2].plot(data_used, f1_macros, label=\"F1 Macro\", color=\"green\")\n",
    "    axs[2].set_xlabel(\"Percentage of data used\")\n",
    "    axs[2].set_title(\"F1 Macro\")\n",
    "    axs[2].set_xticks(data_used)\n",
    "\n",
    "    # Adjust layout and show the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8ef78c",
   "metadata": {
    "papermill": {
     "duration": 0.011078,
     "end_time": "2025-03-26T09:39:20.120748",
     "exception": false,
     "start_time": "2025-03-26T09:39:20.109670",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# QUERY STRATEGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54ed2a30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T09:39:20.144017Z",
     "iopub.status.busy": "2025-03-26T09:39:20.143815Z",
     "iopub.status.idle": "2025-03-26T09:39:20.160011Z",
     "shell.execute_reply": "2025-03-26T09:39:20.159207Z"
    },
    "papermill": {
     "duration": 0.029277,
     "end_time": "2025-03-26T09:39:20.161213",
     "exception": false,
     "start_time": "2025-03-26T09:39:20.131936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def coreset_sampling(aspect_model, sentiment_model, farthest_point, X_pool, train_indices, remaining_indices, sampling_dur, new_samples, trials, n_samples=min_increment):\n",
    "    accelerator = Accelerator(mixed_precision=\"fp16\")\n",
    "    device = accelerator.device\n",
    "\n",
    "    aspect_model.to(device)\n",
    "    aspect_model.eval()\n",
    "    sentiment_model.to(device)\n",
    "    sentiment_model.eval()\n",
    "\n",
    "    farthest_data = farthest_point.value\n",
    "    if farthest_data is not None:\n",
    "        X_pool.append(farthest_data)\n",
    "        \n",
    "    current_train_size = len(train_indices)\n",
    "    aspect_dataset = AspectDetectionDataset(\n",
    "        X_pool,\n",
    "        [['neutral' for i in range(len(train_labels))] for x in range(len(X_pool))], \n",
    "        label_mapping, \n",
    "        tokenizer, \n",
    "        max_length=sequence_length\n",
    "    )\n",
    "    aspect_loader = DataLoader(\n",
    "        aspect_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    \n",
    "    aspect_outputs = {}\n",
    "    sentiment_outputs = {}\n",
    "\n",
    "    aspects = []\n",
    "    data = []\n",
    "    labels = []\n",
    "    indices = []\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Pass through aspect detction model\n",
    "    for batch in aspect_loader:\n",
    "        token_type_ids = batch['token_type_ids'].to(device, non_blocking=True)\n",
    "        input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "        attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = aspect_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids).logits\n",
    "            embeddings = aspect_model.base_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "\n",
    "        for i in range(len(outputs)):\n",
    "            aspect_outputs[batch['ori_indices'][i].item()] = embeddings.last_hidden_state[i].mean(dim=1).cpu().numpy()\n",
    "            \n",
    "            for j in range(len(outputs[i])):\n",
    "                if int(outputs[i][j].round()) != 1:\n",
    "                    aspects.append(aspect_list[j])\n",
    "                    data.append(batch['ori_text'][i])\n",
    "                    labels.append(batch['ori_label'][i][j])\n",
    "                    indices.append(batch['ori_indices'][i])\n",
    "\n",
    "    if len(data) > 0:\n",
    "        sentiment_dataset = SentimentAnalysisDataset(data, labels, aspects, indices, label_mapping, tokenizer, max_length=sequence_length)\n",
    "        sentiment_loader = torch.utils.data.DataLoader(\n",
    "            sentiment_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4,\n",
    "        )\n",
    "    \n",
    "        # Pass through sentiment analysis model\n",
    "        for batch in sentiment_loader:\n",
    "            token_type_ids = batch['token_type_ids'].to(device, non_blocking=True)\n",
    "            input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "            attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "    \n",
    "            with torch.no_grad():\n",
    "                outputs = sentiment_model.base_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "    \n",
    "            for i in range(len(outputs.last_hidden_state)):\n",
    "                ori_index = batch['ori_indices'][i].item()\n",
    "                if ori_index in sentiment_outputs.keys():\n",
    "                    sentiment_outputs[ori_index].append(outputs.last_hidden_state[i].mean(dim=1).cpu().numpy())\n",
    "                else:\n",
    "                    sentiment_outputs[ori_index] = [outputs.last_hidden_state[i].mean(dim=1).cpu().numpy()]\n",
    "\n",
    "    for key, val in sentiment_outputs.items():\n",
    "        sentiment_outputs[key] = np.mean(val, axis=0)\n",
    "\n",
    "    collected_indices = set()  # Initialize set to store selected indices\n",
    "    thresholds = []\n",
    "\n",
    "    if accelerator.is_main_process:\n",
    "        aspect_outputs = dict(sorted(aspect_outputs.items()))\n",
    "\n",
    "        if len(data) > 0:\n",
    "            for key, val in sentiment_outputs.items():\n",
    "                aspect_outputs[key] = np.mean([val, aspect_outputs[key]], axis=0)\n",
    "\n",
    "        embeddings = np.array(list(aspect_outputs.values()))\n",
    "        distance_matrix = pairwise_distances(embeddings)\n",
    "        selected_indices = distance_matrix.shape[0] - 1 if farthest_data is not None else 0\n",
    "\n",
    "        # Calculate the minimum distance from selected points to all other points\n",
    "        min_distances = distance_matrix[selected_indices]\n",
    "\n",
    "        sorted_dist = np.argsort(min_distances)\n",
    "        sorted_dist = sorted_dist[::-1]\n",
    "        farthest_point.value = aspect_dataset[sorted_dist[0]]['ori_text']\n",
    "\n",
    "        threshold = np.percentile(min_distances, 90)\n",
    "        candidates = np.where(min_distances >= threshold)[0]  # Select the point farthest from the current set\n",
    "        num_of_candidates = len(candidates)\n",
    "    \n",
    "        # Check nearest checkpoint\n",
    "        nearest_cp = 0\n",
    "        arrived_at_cp = False\n",
    "        for cp in checkpoints:\n",
    "            if cp > current_train_size:\n",
    "                nearest_cp = cp\n",
    "                break\n",
    "                \n",
    "        # Determine number of maximum samples to be acquired\n",
    "        if num_of_candidates <= n_samples and n_samples < nearest_cp - current_train_size:\n",
    "            selected_indices = sorted_dist[:n_samples]\n",
    "        elif num_of_candidates > n_samples and num_of_candidates < nearest_cp - current_train_size:\n",
    "             selected_indices = sorted_dist[:max(n_samples, min(math.ceil(0.1*len(sorted_dist)), num_of_candidates))]\n",
    "        else:\n",
    "            selected_indices = sorted_dist[:nearest_cp - current_train_size]\n",
    "            \n",
    "            temp = train_indices.copy()\n",
    "            temp.extend([remaining_indices[i] for i in selected_indices])\n",
    "            \n",
    "            # Save acquired data up to checkpoint\n",
    "            acquired_data = pd.DataFrame({\n",
    "                'processed_text': [X_train[i] for i in temp],\n",
    "                'fuel': [y_train[i][0] for i in temp],\n",
    "                'machine': [y_train[i][1] for i in temp],\n",
    "                'others': [y_train[i][2] for i in temp],\n",
    "                'part': [y_train[i][3] for i in temp],\n",
    "                'price': [y_train[i][4] for i in temp],\n",
    "                'service': [y_train[i][5] for i in temp],\n",
    "            })\n",
    "            acquired_data.to_csv(f'acquired_data/{filename}-{trials+1}-data-{nearest_cp}.csv', index=False)\n",
    "\n",
    "        end_time = time.time() \n",
    "        duration = end_time - start_time\n",
    "\n",
    "        sampling_dur.append(duration)\n",
    "        for i in selected_indices:\n",
    "            new_samples.append(remaining_indices[i])\n",
    "        \n",
    "        print(\"Nearest checkpoint:\", nearest_cp)\n",
    "        print(\"Threshold:\", threshold)\n",
    "        print(\"Acquired samples:\", len(selected_indices))\n",
    "        print(f\"Sampling duration: {duration} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411d4b2b",
   "metadata": {
    "papermill": {
     "duration": 0.010936,
     "end_time": "2025-03-26T09:39:20.183291",
     "exception": false,
     "start_time": "2025-03-26T09:39:20.172355",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MAIN LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc7ee449",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T09:39:20.206303Z",
     "iopub.status.busy": "2025-03-26T09:39:20.206102Z",
     "iopub.status.idle": "2025-03-26T09:39:20.215299Z",
     "shell.execute_reply": "2025-03-26T09:39:20.214726Z"
    },
    "papermill": {
     "duration": 0.021963,
     "end_time": "2025-03-26T09:39:20.216386",
     "exception": false,
     "start_time": "2025-03-26T09:39:20.194423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def active_learning(seed, i):\n",
    "    aspect_accuracies = manager.list()\n",
    "    aspect_f1_micros = manager.list()\n",
    "    aspect_f1_macros = manager.list()\n",
    "    sentiment_accuracies = manager.list()\n",
    "    sentiment_f1_micros = manager.list()\n",
    "    sentiment_f1_macros = manager.list()\n",
    "    accuracies = manager.list()\n",
    "    f1_micros = manager.list()\n",
    "    f1_macros = manager.list()\n",
    "    data_used = manager.list()\n",
    "    sampling_dur = manager.list()\n",
    "    new_samples = manager.list()\n",
    "\n",
    "    set_seed(seed)\n",
    "    \n",
    "    print(\"===============================================\")\n",
    "    print(\"TRIAL {}\".format(i+1))\n",
    "    print(\"Random seed:\", seed)\n",
    "    \n",
    "    train_indices = np.random.choice(range(len(X_train)), initial_train_size, replace=False).tolist()\n",
    "    remaining_indices = list(set(range(len(X_train))) - set(train_indices))\n",
    "    \n",
    "    current_train_size = initial_train_size\n",
    "    \n",
    "    start_time = time.time()\n",
    "    while current_train_size < checkpoints[len(checkpoints) - 1]:\n",
    "        # Train the model\n",
    "        args = (\n",
    "            current_train_size, \n",
    "            train_indices, \n",
    "            (aspect_accuracies, aspect_f1_micros, aspect_f1_macros), \n",
    "            (sentiment_accuracies, sentiment_f1_micros, sentiment_f1_macros),\n",
    "            (data_used, accuracies, f1_micros, f1_macros), \n",
    "            i,\n",
    "            seed\n",
    "        )\n",
    "        notebook_launcher(train_model, args, num_processes=2)\n",
    "\n",
    "        aspect_model = BertForSequenceClassification.from_pretrained(f'{filename}-aspect-{i+1}-model')\n",
    "        sentiment_model = BertForSequenceClassification.from_pretrained(f'{filename}-sentiment-{i+1}-model')\n",
    "    \n",
    "        # Perform query strategy to select new samples\n",
    "        new_samples = manager.list()\n",
    "        sampling_args = (\n",
    "            aspect_model, \n",
    "            sentiment_model, \n",
    "            farthest_point,\n",
    "            [X_train[i] for i in remaining_indices], \n",
    "            train_indices, \n",
    "            remaining_indices, \n",
    "            sampling_dur, \n",
    "            new_samples, \n",
    "            i\n",
    "        )\n",
    "        notebook_launcher(coreset_sampling, sampling_args, num_processes=2)\n",
    "        new_samples = list(new_samples)\n",
    "        train_indices.extend(new_samples)\n",
    "        remaining_indices = list(set(remaining_indices) - set(new_samples))\n",
    "    \n",
    "        # Update current training size\n",
    "        current_train_size = len(train_indices)\n",
    "        print(\"New train size: {}\".format(current_train_size))\n",
    "    \n",
    "    # Train last epoch\n",
    "    args = (\n",
    "        current_train_size, \n",
    "        train_indices, \n",
    "        (aspect_accuracies, aspect_f1_micros, aspect_f1_macros), \n",
    "        (sentiment_accuracies, sentiment_f1_micros, sentiment_f1_macros),\n",
    "        (data_used, accuracies, f1_micros, f1_macros), \n",
    "        i,\n",
    "        seed\n",
    "    )\n",
    "    notebook_launcher(train_model, args, num_processes=2)\n",
    "    data_used, accuracies, f1_micros, f1_macros, sampling_dur = list(data_used), list(accuracies), list(f1_micros), list(f1_macros), list(sampling_dur)\n",
    "    aspect_accuracies, aspect_f1_micros, aspect_f1_macros = list(aspect_accuracies), list(aspect_f1_micros), list(aspect_f1_macros)\n",
    "    sentiment_accuracies, sentiment_f1_micros, sentiment_f1_macros = list(sentiment_accuracies), list(sentiment_f1_micros), list(sentiment_f1_macros)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    # print(f\"Total sampling time: {np.array(sampling_dur).sum().round(2)} seconds\")\n",
    "    print(f\"Total runtime: {duration} seconds\")\n",
    "    \n",
    "    plot_result(data_used, accuracies, f1_micros, f1_macros)\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        'Data Used': data_used,\n",
    "        'Aspect Accuracy': aspect_accuracies,\n",
    "        'Aspect F1 Micro': aspect_f1_micros,\n",
    "        'Aspect F1 Macro': aspect_f1_macros,\n",
    "        'Sentiment Accuracy': sentiment_accuracies,\n",
    "        'Sentiment F1 Micro': sentiment_f1_micros,\n",
    "        'Sentiment F1 Macro': sentiment_f1_macros,\n",
    "        'Accuracy': accuracies,\n",
    "        'F1 Micro': f1_micros,\n",
    "        'F1 Macro': f1_macros,\n",
    "    })\n",
    "    \n",
    "    sampling_dur.insert(0, 0)\n",
    "    results['Sampling Duration'] = sampling_dur\n",
    "    results.to_csv(f'results/{filename}-{i+1}-results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc0457ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T09:39:20.240112Z",
     "iopub.status.busy": "2025-03-26T09:39:20.239900Z",
     "iopub.status.idle": "2025-03-26T09:39:20.243103Z",
     "shell.execute_reply": "2025-03-26T09:39:20.242329Z"
    },
    "papermill": {
     "duration": 0.016379,
     "end_time": "2025-03-26T09:39:20.244368",
     "exception": false,
     "start_time": "2025-03-26T09:39:20.227989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seeds = [50, 81, 14, 3, 94]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdcc0a0",
   "metadata": {
    "papermill": {
     "duration": 0.011214,
     "end_time": "2025-03-26T09:39:20.267184",
     "exception": false,
     "start_time": "2025-03-26T09:39:20.255970",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88094daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 1\n",
      "Random seed: 50\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6756, Accuracy: 0.7731, F1 Micro: 0.8711, F1 Macro: 0.8698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5958, Accuracy: 0.7887, F1 Micro: 0.8819, F1 Macro: 0.8804\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5785, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.513, Accuracy: 0.7939, F1 Micro: 0.8843, F1 Macro: 0.8828\n",
      "Epoch 5/10, Train Loss: 0.5006, Accuracy: 0.7924, F1 Micro: 0.8829, F1 Macro: 0.881\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4695, Accuracy: 0.7954, F1 Micro: 0.8846, F1 Macro: 0.8828\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4328, Accuracy: 0.7969, F1 Micro: 0.8857, F1 Macro: 0.8842\n",
      "Epoch 8/10, Train Loss: 0.4369, Accuracy: 0.7932, F1 Micro: 0.8832, F1 Macro: 0.8812\n",
      "Epoch 9/10, Train Loss: 0.415, Accuracy: 0.7917, F1 Micro: 0.8816, F1 Macro: 0.8789\n",
      "Epoch 10/10, Train Loss: 0.3884, Accuracy: 0.7894, F1 Micro: 0.88, F1 Macro: 0.8769\n",
      "\n",
      "Aspect detection accuracy: 0.7969, F1 Micro: 0.8857, F1 Macro: 0.8842\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.78      1.00      0.88       175\n",
      "      others       0.71      1.00      0.83       158\n",
      "        part       0.75      0.98      0.85       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.80      1.00      0.89      1061\n",
      "   macro avg       0.80      1.00      0.88      1061\n",
      "weighted avg       0.80      1.00      0.89      1061\n",
      " samples avg       0.80      1.00      0.88      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7162, Accuracy: 0.2857, F1 Micro: 0.2857, F1 Macro: 0.2222\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.6764, Accuracy: 0.5, F1 Micro: 0.5, F1 Macro: 0.4974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.6621, Accuracy: 0.7143, F1 Micro: 0.7143, F1 Macro: 0.65\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.6053, Accuracy: 0.7857, F1 Micro: 0.7857, F1 Macro: 0.7143\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.5803, Accuracy: 0.7857, F1 Micro: 0.7857, F1 Macro: 0.7143\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.5674, Accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.825\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4789, Accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.825\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4895, Accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.825\n",
      "Epoch 9/10, Train Loss: 0.4054, Accuracy: 0.7143, F1 Micro: 0.7143, F1 Macro: 0.6889\n",
      "Epoch 10/10, Train Loss: 0.3482, Accuracy: 0.5, F1 Micro: 0.5, F1 Macro: 0.4974\n",
      "\n",
      "Sentiment analysis accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.825\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75         4\n",
      "    positive       0.90      0.90      0.90        10\n",
      "\n",
      "    accuracy                           0.86        14\n",
      "   macro avg       0.82      0.82      0.82        14\n",
      "weighted avg       0.86      0.86      0.86        14\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.794, F1 Micro: 0.794, F1 Macro: 0.3199\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.77      1.00      0.87       167\n",
      "    positive       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.77       216\n",
      "   macro avg       0.26      0.33      0.29       216\n",
      "weighted avg       0.60      0.77      0.67       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.70      1.00      0.83       152\n",
      "    positive       0.00      0.00      0.00        52\n",
      "\n",
      "    accuracy                           0.70       216\n",
      "   macro avg       0.23      0.33      0.28       216\n",
      "weighted avg       0.50      0.70      0.58       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.13      0.22        23\n",
      "     neutral       0.74      0.98      0.84       152\n",
      "    positive       0.60      0.15      0.24        41\n",
      "\n",
      "    accuracy                           0.73       216\n",
      "   macro avg       0.70      0.42      0.43       216\n",
      "weighted avg       0.71      0.73      0.66       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 53.56539273262024 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.004588124807924032\n",
      "Acquired samples: 82\n",
      "Sampling duration: 9.929409980773926 seconds\n",
      "New train size: 136\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6434, Accuracy: 0.7894, F1 Micro: 0.8822, F1 Macro: 0.8808\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5617, Accuracy: 0.8013, F1 Micro: 0.8877, F1 Macro: 0.8861\n",
      "Epoch 3/10, Train Loss: 0.5271, Accuracy: 0.7939, F1 Micro: 0.8844, F1 Macro: 0.8829\n",
      "Epoch 4/10, Train Loss: 0.4906, Accuracy: 0.7954, F1 Micro: 0.8851, F1 Macro: 0.8835\n",
      "Epoch 5/10, Train Loss: 0.457, Accuracy: 0.7991, F1 Micro: 0.8859, F1 Macro: 0.884\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4262, Accuracy: 0.8028, F1 Micro: 0.8885, F1 Macro: 0.887\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4069, Accuracy: 0.8222, F1 Micro: 0.8968, F1 Macro: 0.8948\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3631, Accuracy: 0.8385, F1 Micro: 0.9053, F1 Macro: 0.9032\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3127, Accuracy: 0.8661, F1 Micro: 0.9204, F1 Macro: 0.9184\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2772, Accuracy: 0.8854, F1 Micro: 0.9296, F1 Macro: 0.9257\n",
      "\n",
      "Aspect detection accuracy: 0.8854, F1 Micro: 0.9296, F1 Macro: 0.9257\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.94      1.00      0.97       187\n",
      "     machine       0.88      0.95      0.91       175\n",
      "      others       0.88      0.82      0.85       158\n",
      "        part       0.84      0.97      0.90       158\n",
      "       price       0.91      0.99      0.95       192\n",
      "     service       0.95      0.99      0.97       191\n",
      "\n",
      "   micro avg       0.90      0.96      0.93      1061\n",
      "   macro avg       0.90      0.95      0.93      1061\n",
      "weighted avg       0.90      0.96      0.93      1061\n",
      " samples avg       0.91      0.95      0.92      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5818, Accuracy: 0.7381, F1 Micro: 0.7381, F1 Macro: 0.4247\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4505, Accuracy: 0.7381, F1 Micro: 0.7381, F1 Macro: 0.4247\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3807, Accuracy: 0.7571, F1 Micro: 0.7571, F1 Macro: 0.5109\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2778, Accuracy: 0.9, F1 Micro: 0.9, F1 Macro: 0.8683\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2564, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9157\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1753, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9175\n",
      "Epoch 7/10, Train Loss: 0.1665, Accuracy: 0.9143, F1 Micro: 0.9143, F1 Macro: 0.897\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1042, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9127\n",
      "Epoch 9/10, Train Loss: 0.1483, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9121\n",
      "Epoch 10/10, Train Loss: 0.0922, Accuracy: 0.9238, F1 Micro: 0.9238, F1 Macro: 0.9076\n",
      "\n",
      "Sentiment analysis accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9127\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87        55\n",
      "    positive       0.95      0.96      0.96       155\n",
      "\n",
      "    accuracy                           0.93       210\n",
      "   macro avg       0.92      0.91      0.91       210\n",
      "weighted avg       0.93      0.93      0.93       210\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 136: Accuracy: 0.8742, F1 Micro: 0.8742, F1 Macro: 0.7382\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.64      0.78        11\n",
      "     neutral       0.94      1.00      0.97       181\n",
      "    positive       1.00      0.67      0.80        24\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.98      0.77      0.85       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.31      0.48        16\n",
      "     neutral       0.88      0.95      0.91       167\n",
      "    positive       0.63      0.58      0.60        33\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.84      0.61      0.66       216\n",
      "weighted avg       0.85      0.85      0.83       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.57      0.67      0.62        12\n",
      "     neutral       0.88      0.81      0.85       152\n",
      "    positive       0.57      0.69      0.63        52\n",
      "\n",
      "    accuracy                           0.77       216\n",
      "   macro avg       0.68      0.72      0.70       216\n",
      "weighted avg       0.79      0.77      0.78       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.48      0.65        23\n",
      "     neutral       0.83      0.97      0.89       152\n",
      "    positive       0.71      0.49      0.58        41\n",
      "\n",
      "    accuracy                           0.82       216\n",
      "   macro avg       0.85      0.64      0.71       216\n",
      "weighted avg       0.83      0.82      0.81       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.38      0.56        13\n",
      "     neutral       0.91      0.99      0.95       186\n",
      "    positive       0.88      0.41      0.56        17\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.93      0.60      0.69       216\n",
      "weighted avg       0.91      0.91      0.90       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.95      0.99      0.97       185\n",
      "    positive       0.75      0.53      0.62        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.77      0.82       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Total train time: 71.33766627311707 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.00895455088466406\n",
      "Acquired samples: 73\n",
      "Sampling duration: 15.399619817733765 seconds\n",
      "New train size: 209\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6182, Accuracy: 0.7924, F1 Micro: 0.8837, F1 Macro: 0.8822\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.54, Accuracy: 0.7946, F1 Micro: 0.8849, F1 Macro: 0.8834\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4892, Accuracy: 0.7969, F1 Micro: 0.886, F1 Macro: 0.8846\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.463, Accuracy: 0.8103, F1 Micro: 0.8917, F1 Macro: 0.8905\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4277, Accuracy: 0.8341, F1 Micro: 0.9044, F1 Macro: 0.9035\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.368, Accuracy: 0.8839, F1 Micro: 0.9309, F1 Macro: 0.9299\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3155, Accuracy: 0.9115, F1 Micro: 0.9458, F1 Macro: 0.9439\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2558, Accuracy: 0.9256, F1 Micro: 0.9539, F1 Macro: 0.9518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2104, Accuracy: 0.9278, F1 Micro: 0.9553, F1 Macro: 0.953\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1803, Accuracy: 0.9382, F1 Micro: 0.9613, F1 Macro: 0.9586\n",
      "\n",
      "Aspect detection accuracy: 0.9382, F1 Micro: 0.9613, F1 Macro: 0.9586\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.97      0.96       175\n",
      "      others       0.90      0.92      0.91       158\n",
      "        part       0.93      0.92      0.93       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       0.97      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.95      0.97      0.96      1061\n",
      "   macro avg       0.95      0.97      0.96      1061\n",
      "weighted avg       0.95      0.97      0.96      1061\n",
      " samples avg       0.95      0.97      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.616, Accuracy: 0.6929, F1 Micro: 0.6929, F1 Macro: 0.4093\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5164, Accuracy: 0.748, F1 Micro: 0.748, F1 Macro: 0.6816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4152, Accuracy: 0.7598, F1 Micro: 0.7598, F1 Macro: 0.7489\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2975, Accuracy: 0.878, F1 Micro: 0.878, F1 Macro: 0.8591\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3045, Accuracy: 0.8819, F1 Micro: 0.8819, F1 Macro: 0.8681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2265, Accuracy: 0.8819, F1 Micro: 0.8819, F1 Macro: 0.8622\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2087, Accuracy: 0.8858, F1 Micro: 0.8858, F1 Macro: 0.8663\n",
      "Epoch 8/10, Train Loss: 0.0846, Accuracy: 0.8701, F1 Micro: 0.8701, F1 Macro: 0.8562\n",
      "Epoch 9/10, Train Loss: 0.1622, Accuracy: 0.874, F1 Micro: 0.874, F1 Macro: 0.853\n",
      "Epoch 10/10, Train Loss: 0.162, Accuracy: 0.8543, F1 Micro: 0.8543, F1 Macro: 0.8434\n",
      "\n",
      "Sentiment analysis accuracy: 0.8858, F1 Micro: 0.8858, F1 Macro: 0.8663\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.82      0.82        78\n",
      "    positive       0.92      0.91      0.92       176\n",
      "\n",
      "    accuracy                           0.89       254\n",
      "   macro avg       0.87      0.87      0.87       254\n",
      "weighted avg       0.89      0.89      0.89       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 209: Accuracy: 0.9205, F1 Micro: 0.9205, F1 Macro: 0.8368\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.98      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.56      0.67        16\n",
      "     neutral       0.95      0.96      0.96       167\n",
      "    positive       0.71      0.76      0.74        33\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.83      0.76      0.79       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.57      0.67      0.62        12\n",
      "     neutral       0.90      0.91      0.91       152\n",
      "    positive       0.74      0.67      0.71        52\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.74      0.75      0.74       216\n",
      "weighted avg       0.84      0.84      0.84       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.74      0.72        23\n",
      "     neutral       0.93      0.92      0.92       152\n",
      "    positive       0.76      0.76      0.76        41\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.80      0.81      0.80       216\n",
      "weighted avg       0.87      0.87      0.87       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.97      1.00      0.99       186\n",
      "    positive       0.86      0.71      0.77        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.85      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.71      0.83        14\n",
      "     neutral       0.97      1.00      0.98       185\n",
      "    positive       0.80      0.71      0.75        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.81      0.86       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Total train time: 88.4836061000824 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.006665317807346582\n",
      "Acquired samples: 66\n",
      "Sampling duration: 14.890658140182495 seconds\n",
      "New train size: 275\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6038, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5153, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4942, Accuracy: 0.7969, F1 Micro: 0.8859, F1 Macro: 0.8844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4571, Accuracy: 0.8244, F1 Micro: 0.8984, F1 Macro: 0.8967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3741, Accuracy: 0.8921, F1 Micro: 0.9347, F1 Macro: 0.933\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2996, Accuracy: 0.9196, F1 Micro: 0.95, F1 Macro: 0.9471\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2424, Accuracy: 0.9256, F1 Micro: 0.9537, F1 Macro: 0.9509\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1985, Accuracy: 0.9278, F1 Micro: 0.9552, F1 Macro: 0.9525\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1614, Accuracy: 0.9375, F1 Micro: 0.9607, F1 Macro: 0.9577\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1346, Accuracy: 0.9472, F1 Micro: 0.9671, F1 Macro: 0.9653\n",
      "\n",
      "Aspect detection accuracy: 0.9472, F1 Micro: 0.9671, F1 Macro: 0.9653\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.93      0.99      0.96       175\n",
      "      others       0.90      0.94      0.92       158\n",
      "        part       0.96      0.96      0.96       158\n",
      "       price       0.97      1.00      0.98       192\n",
      "     service       0.97      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.95      0.98      0.97      1061\n",
      "   macro avg       0.95      0.98      0.97      1061\n",
      "weighted avg       0.95      0.98      0.97      1061\n",
      " samples avg       0.95      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.572, Accuracy: 0.6777, F1 Micro: 0.6777, F1 Macro: 0.4039\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4231, Accuracy: 0.8554, F1 Micro: 0.8554, F1 Macro: 0.8316\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.25, Accuracy: 0.8926, F1 Micro: 0.8926, F1 Macro: 0.8839\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1845, Accuracy: 0.8967, F1 Micro: 0.8967, F1 Macro: 0.8881\n",
      "Epoch 5/10, Train Loss: 0.2062, Accuracy: 0.8926, F1 Micro: 0.8926, F1 Macro: 0.8808\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1158, Accuracy: 0.9008, F1 Micro: 0.9008, F1 Macro: 0.8918\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1324, Accuracy: 0.9008, F1 Micro: 0.9008, F1 Macro: 0.8918\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1019, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8979\n",
      "Epoch 9/10, Train Loss: 0.0765, Accuracy: 0.9008, F1 Micro: 0.9008, F1 Macro: 0.8887\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1066, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8997\n",
      "\n",
      "Sentiment analysis accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.94      0.87        78\n",
      "    positive       0.97      0.90      0.93       164\n",
      "\n",
      "    accuracy                           0.91       242\n",
      "   macro avg       0.89      0.92      0.90       242\n",
      "weighted avg       0.92      0.91      0.91       242\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 275: Accuracy: 0.9352, F1 Micro: 0.9352, F1 Macro: 0.87\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.69      0.73        16\n",
      "     neutral       0.93      0.99      0.96       167\n",
      "    positive       0.92      0.67      0.77        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.88      0.78      0.82       216\n",
      "weighted avg       0.91      0.92      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.75      0.72        12\n",
      "     neutral       0.90      0.93      0.92       152\n",
      "    positive       0.78      0.67      0.72        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.79      0.79      0.79       216\n",
      "weighted avg       0.86      0.86      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.87      0.77        23\n",
      "     neutral       0.95      0.95      0.95       152\n",
      "    positive       0.91      0.78      0.84        41\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.85      0.87      0.86       216\n",
      "weighted avg       0.92      0.91      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.97      1.00      0.98       186\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.83      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.97      1.00      0.98       185\n",
      "    positive       1.00      0.71      0.83        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.99      0.88      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 93.83508801460266 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.006366878328844905\n",
      "Acquired samples: 59\n",
      "Sampling duration: 13.85971212387085 seconds\n",
      "New train size: 334\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5845, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Epoch 2/10, Train Loss: 0.5161, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4739, Accuracy: 0.8095, F1 Micro: 0.8921, F1 Macro: 0.8909\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4056, Accuracy: 0.8847, F1 Micro: 0.931, F1 Macro: 0.9296\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3137, Accuracy: 0.9271, F1 Micro: 0.9553, F1 Macro: 0.9538\n",
      "Epoch 6/10, Train Loss: 0.2466, Accuracy: 0.9211, F1 Micro: 0.9506, F1 Macro: 0.9463\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1982, Accuracy: 0.9487, F1 Micro: 0.9681, F1 Macro: 0.9665\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1457, Accuracy: 0.9554, F1 Micro: 0.9722, F1 Macro: 0.9709\n",
      "Epoch 9/10, Train Loss: 0.1256, Accuracy: 0.9546, F1 Micro: 0.9717, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1026, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.972\n",
      "\n",
      "Aspect detection accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.972\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.91      0.93      0.92       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.97      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.563, Accuracy: 0.6786, F1 Micro: 0.6786, F1 Macro: 0.4043\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4059, Accuracy: 0.8849, F1 Micro: 0.8849, F1 Macro: 0.8649\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2422, Accuracy: 0.8968, F1 Micro: 0.8968, F1 Macro: 0.8882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1934, Accuracy: 0.8968, F1 Micro: 0.8968, F1 Macro: 0.8846\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.164, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8947\n",
      "Epoch 6/10, Train Loss: 0.1463, Accuracy: 0.8929, F1 Micro: 0.8929, F1 Macro: 0.8842\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1209, Accuracy: 0.9127, F1 Micro: 0.9127, F1 Macro: 0.9012\n",
      "Epoch 8/10, Train Loss: 0.0887, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8929\n",
      "Epoch 9/10, Train Loss: 0.1195, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8947\n",
      "Epoch 10/10, Train Loss: 0.0825, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.9009\n",
      "\n",
      "Sentiment analysis accuracy: 0.9127, F1 Micro: 0.9127, F1 Macro: 0.9012\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.89      0.87        81\n",
      "    positive       0.95      0.92      0.93       171\n",
      "\n",
      "    accuracy                           0.91       252\n",
      "   macro avg       0.90      0.91      0.90       252\n",
      "weighted avg       0.91      0.91      0.91       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 334: Accuracy: 0.9429, F1 Micro: 0.9429, F1 Macro: 0.8766\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.75      0.77        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.90      0.82      0.86        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.85      0.87       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.75      0.69        12\n",
      "     neutral       0.91      0.93      0.92       152\n",
      "    positive       0.77      0.69      0.73        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.77      0.79      0.78       216\n",
      "weighted avg       0.86      0.86      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.91      0.86        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.90      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.69      0.82        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.76      0.76      0.76        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.91      0.82      0.86       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.97      1.00      0.98       185\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.97      0.85      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 91.0615131855011 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0031618166249245405\n",
      "Acquired samples: 54\n",
      "Sampling duration: 12.884562492370605 seconds\n",
      "New train size: 388\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5699, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5004, Accuracy: 0.7939, F1 Micro: 0.8845, F1 Macro: 0.8831\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4453, Accuracy: 0.8259, F1 Micro: 0.9004, F1 Macro: 0.8993\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3519, Accuracy: 0.9211, F1 Micro: 0.9513, F1 Macro: 0.9495\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.27, Accuracy: 0.9338, F1 Micro: 0.9588, F1 Macro: 0.9563\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2068, Accuracy: 0.9472, F1 Micro: 0.967, F1 Macro: 0.9654\n",
      "Epoch 7/10, Train Loss: 0.1557, Accuracy: 0.9464, F1 Micro: 0.9663, F1 Macro: 0.9634\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1251, Accuracy: 0.9561, F1 Micro: 0.9724, F1 Macro: 0.9707\n",
      "Epoch 9/10, Train Loss: 0.1036, Accuracy: 0.9524, F1 Micro: 0.9701, F1 Macro: 0.9678\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0871, Accuracy: 0.9568, F1 Micro: 0.9728, F1 Macro: 0.9711\n",
      "\n",
      "Aspect detection accuracy: 0.9568, F1 Micro: 0.9728, F1 Macro: 0.9711\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.94      0.89      0.92       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.97      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5983, Accuracy: 0.678, F1 Micro: 0.678, F1 Macro: 0.4041\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.377, Accuracy: 0.8712, F1 Micro: 0.8712, F1 Macro: 0.8621\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2137, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9193\n",
      "Epoch 4/10, Train Loss: 0.1491, Accuracy: 0.9015, F1 Micro: 0.9015, F1 Macro: 0.8931\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1439, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9241\n",
      "Epoch 6/10, Train Loss: 0.1307, Accuracy: 0.9205, F1 Micro: 0.9205, F1 Macro: 0.908\n",
      "Epoch 7/10, Train Loss: 0.1227, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.9087\n",
      "Epoch 8/10, Train Loss: 0.1217, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.9048\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1125, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9326\n",
      "Epoch 10/10, Train Loss: 0.0894, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9237\n",
      "\n",
      "Sentiment analysis accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9326\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.98      0.91        84\n",
      "    positive       0.99      0.92      0.95       180\n",
      "\n",
      "    accuracy                           0.94       264\n",
      "   macro avg       0.92      0.95      0.93       264\n",
      "weighted avg       0.95      0.94      0.94       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 388: Accuracy: 0.9483, F1 Micro: 0.9483, F1 Macro: 0.9019\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.88      0.82        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.92      0.70      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.85      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.83      0.74        12\n",
      "     neutral       0.94      0.89      0.92       152\n",
      "    positive       0.74      0.81      0.77        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.78      0.85      0.81       216\n",
      "weighted avg       0.88      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.89      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.97      1.00      0.98       185\n",
      "    positive       1.00      0.76      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.99      0.87      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 99.50179553031921 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.003674876969307661\n",
      "Acquired samples: 48\n",
      "Sampling duration: 11.745205879211426 seconds\n",
      "New train size: 436\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5738, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5003, Accuracy: 0.7946, F1 Micro: 0.8849, F1 Macro: 0.8834\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4353, Accuracy: 0.8609, F1 Micro: 0.9182, F1 Macro: 0.9173\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3324, Accuracy: 0.9323, F1 Micro: 0.9582, F1 Macro: 0.9564\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2532, Accuracy: 0.9509, F1 Micro: 0.9693, F1 Macro: 0.9678\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1766, Accuracy: 0.9561, F1 Micro: 0.9726, F1 Macro: 0.9711\n",
      "Epoch 7/10, Train Loss: 0.1467, Accuracy: 0.9554, F1 Micro: 0.972, F1 Macro: 0.9701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1244, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.094, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9752\n",
      "Epoch 10/10, Train Loss: 0.0807, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9752\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.94      0.92      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5625, Accuracy: 0.7954, F1 Micro: 0.7954, F1 Macro: 0.7292\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3453, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9244\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2539, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9304\n",
      "Epoch 4/10, Train Loss: 0.15, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9253\n",
      "Epoch 5/10, Train Loss: 0.1523, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9207\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1289, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9304\n",
      "Epoch 7/10, Train Loss: 0.1586, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9266\n",
      "Epoch 8/10, Train Loss: 0.1368, Accuracy: 0.888, F1 Micro: 0.888, F1 Macro: 0.8792\n",
      "Epoch 9/10, Train Loss: 0.09, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9225\n",
      "Epoch 10/10, Train Loss: 0.0617, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9176\n",
      "\n",
      "Sentiment analysis accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9304\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.95      0.91        82\n",
      "    positive       0.98      0.93      0.95       177\n",
      "\n",
      "    accuracy                           0.94       259\n",
      "   macro avg       0.92      0.94      0.93       259\n",
      "weighted avg       0.94      0.94      0.94       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 436: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9038\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.94      0.99      0.97       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.84      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.56      0.75      0.64        12\n",
      "     neutral       0.94      0.91      0.93       152\n",
      "    positive       0.77      0.77      0.77        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.76      0.81      0.78       216\n",
      "weighted avg       0.88      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.83      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.98      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 100.35674524307251 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.003985429648309946\n",
      "Acquired samples: 43\n",
      "Sampling duration: 10.587526559829712 seconds\n",
      "New train size: 479\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5747, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4994, Accuracy: 0.7946, F1 Micro: 0.8849, F1 Macro: 0.8834\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4344, Accuracy: 0.881, F1 Micro: 0.9296, F1 Macro: 0.9282\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3215, Accuracy: 0.9375, F1 Micro: 0.9611, F1 Macro: 0.9588\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.235, Accuracy: 0.9546, F1 Micro: 0.9716, F1 Macro: 0.9699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1669, Accuracy: 0.9583, F1 Micro: 0.974, F1 Macro: 0.9723\n",
      "Epoch 7/10, Train Loss: 0.1264, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1089, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9745\n",
      "Epoch 9/10, Train Loss: 0.0925, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0778, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9746\n",
      "\n",
      "Aspect detection accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9746\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.94      0.92      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.57, Accuracy: 0.7893, F1 Micro: 0.7893, F1 Macro: 0.7138\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3453, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9269\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2002, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9273\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2222, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9247\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2008, Accuracy: 0.9425, F1 Micro: 0.9425, F1 Macro: 0.9348\n",
      "Epoch 6/10, Train Loss: 0.1458, Accuracy: 0.9195, F1 Micro: 0.9195, F1 Macro: 0.9044\n",
      "Epoch 7/10, Train Loss: 0.1182, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9281\n",
      "Epoch 8/10, Train Loss: 0.1107, Accuracy: 0.9387, F1 Micro: 0.9387, F1 Macro: 0.9306\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1059, Accuracy: 0.9425, F1 Micro: 0.9425, F1 Macro: 0.9352\n",
      "Epoch 10/10, Train Loss: 0.0793, Accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.9077\n",
      "\n",
      "Sentiment analysis accuracy: 0.9425, F1 Micro: 0.9425, F1 Macro: 0.9352\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.94      0.91        84\n",
      "    positive       0.97      0.94      0.96       177\n",
      "\n",
      "    accuracy                           0.94       261\n",
      "   macro avg       0.93      0.94      0.94       261\n",
      "weighted avg       0.94      0.94      0.94       261\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 479: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9092\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.93      0.79      0.85        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.86      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.94      0.92      0.93       152\n",
      "    positive       0.77      0.79      0.78        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.81      0.85      0.83       216\n",
      "weighted avg       0.89      0.88      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.89      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 107.27729535102844 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.003367098863236606\n",
      "Acquired samples: 39\n",
      "Sampling duration: 9.633131742477417 seconds\n",
      "New train size: 518\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5499, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4911, Accuracy: 0.8192, F1 Micro: 0.897, F1 Macro: 0.8967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3914, Accuracy: 0.9167, F1 Micro: 0.9493, F1 Macro: 0.9478\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2805, Accuracy: 0.9524, F1 Micro: 0.9703, F1 Macro: 0.9689\n",
      "Epoch 5/10, Train Loss: 0.1958, Accuracy: 0.9516, F1 Micro: 0.9697, F1 Macro: 0.9683\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1558, Accuracy: 0.9561, F1 Micro: 0.9723, F1 Macro: 0.9699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.12, Accuracy: 0.9591, F1 Micro: 0.9741, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0942, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9761\n",
      "Epoch 9/10, Train Loss: 0.0815, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.975\n",
      "Epoch 10/10, Train Loss: 0.0701, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.973\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9761\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5325, Accuracy: 0.8294, F1 Micro: 0.8294, F1 Macro: 0.7782\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2601, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.9018\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2297, Accuracy: 0.9524, F1 Micro: 0.9524, F1 Macro: 0.9467\n",
      "Epoch 4/10, Train Loss: 0.1374, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.9099\n",
      "Epoch 5/10, Train Loss: 0.1379, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9343\n",
      "Epoch 6/10, Train Loss: 0.1062, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9343\n",
      "Epoch 7/10, Train Loss: 0.1042, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8878\n",
      "Epoch 8/10, Train Loss: 0.1086, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9332\n",
      "Epoch 9/10, Train Loss: 0.0947, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9264\n",
      "Epoch 10/10, Train Loss: 0.0629, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.8993\n",
      "\n",
      "Sentiment analysis accuracy: 0.9524, F1 Micro: 0.9524, F1 Macro: 0.9467\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93        83\n",
      "    positive       0.98      0.95      0.96       169\n",
      "\n",
      "    accuracy                           0.95       252\n",
      "   macro avg       0.94      0.95      0.95       252\n",
      "weighted avg       0.95      0.95      0.95       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 518: Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9148\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.94      0.99      0.97       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.84      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.85      0.77      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.84      0.82      0.83       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.92      0.93       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.96      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 105.37334966659546 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.004608967062085868\n",
      "Acquired samples: 22\n",
      "Sampling duration: 8.810038328170776 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5603, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4787, Accuracy: 0.8088, F1 Micro: 0.8919, F1 Macro: 0.8908\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3917, Accuracy: 0.9152, F1 Micro: 0.9478, F1 Macro: 0.9459\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2852, Accuracy: 0.936, F1 Micro: 0.9599, F1 Macro: 0.958\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2012, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9713\n",
      "Epoch 6/10, Train Loss: 0.1488, Accuracy: 0.9546, F1 Micro: 0.9715, F1 Macro: 0.9695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.122, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9738\n",
      "Epoch 8/10, Train Loss: 0.0976, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9728\n",
      "Epoch 9/10, Train Loss: 0.0814, Accuracy: 0.9554, F1 Micro: 0.9718, F1 Macro: 0.9696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.071, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9765\n",
      "\n",
      "Aspect detection accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.93      0.95      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5011, Accuracy: 0.888, F1 Micro: 0.888, F1 Macro: 0.8702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2445, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.8993\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2037, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9189\n",
      "Epoch 4/10, Train Loss: 0.1625, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9153\n",
      "Epoch 5/10, Train Loss: 0.153, Accuracy: 0.9112, F1 Micro: 0.9112, F1 Macro: 0.9028\n",
      "Epoch 6/10, Train Loss: 0.1439, Accuracy: 0.8996, F1 Micro: 0.8996, F1 Macro: 0.8915\n",
      "Epoch 7/10, Train Loss: 0.137, Accuracy: 0.8996, F1 Micro: 0.8996, F1 Macro: 0.8915\n",
      "Epoch 8/10, Train Loss: 0.0903, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.8989\n",
      "Epoch 9/10, Train Loss: 0.0947, Accuracy: 0.8764, F1 Micro: 0.8764, F1 Macro: 0.8687\n",
      "Epoch 10/10, Train Loss: 0.0915, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.9068\n",
      "\n",
      "Sentiment analysis accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9189\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.96      0.89        83\n",
      "    positive       0.98      0.91      0.94       176\n",
      "\n",
      "    accuracy                           0.93       259\n",
      "   macro avg       0.91      0.94      0.92       259\n",
      "weighted avg       0.93      0.93      0.93       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9018\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.84      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.75      0.67        12\n",
      "     neutral       0.93      0.95      0.94       152\n",
      "    positive       0.83      0.73      0.78        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.79      0.81      0.79       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.92      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 107.29326844215393 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.004187841434031725\n",
      "Acquired samples: 33\n",
      "Sampling duration: 8.316493034362793 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5479, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4701, Accuracy: 0.8311, F1 Micro: 0.9031, F1 Macro: 0.9023\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3713, Accuracy: 0.9308, F1 Micro: 0.9574, F1 Macro: 0.9557\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2557, Accuracy: 0.9539, F1 Micro: 0.9713, F1 Macro: 0.9699\n",
      "Epoch 5/10, Train Loss: 0.1855, Accuracy: 0.9494, F1 Micro: 0.968, F1 Macro: 0.965\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1453, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1156, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0931, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.076, Accuracy: 0.9613, F1 Micro: 0.9755, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0636, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9762\n",
      "\n",
      "Aspect detection accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.93      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5133, Accuracy: 0.8977, F1 Micro: 0.8977, F1 Macro: 0.8776\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2894, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9168\n",
      "Epoch 3/10, Train Loss: 0.2023, Accuracy: 0.9242, F1 Micro: 0.9242, F1 Macro: 0.9162\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1531, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9322\n",
      "Epoch 5/10, Train Loss: 0.1083, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.9004\n",
      "Epoch 6/10, Train Loss: 0.1103, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9241\n",
      "Epoch 7/10, Train Loss: 0.1214, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.9004\n",
      "Epoch 8/10, Train Loss: 0.0869, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9173\n",
      "Epoch 9/10, Train Loss: 0.0927, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9229\n",
      "Epoch 10/10, Train Loss: 0.0842, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9197\n",
      "\n",
      "Sentiment analysis accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9322\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.96      0.91        84\n",
      "    positive       0.98      0.93      0.95       180\n",
      "\n",
      "    accuracy                           0.94       264\n",
      "   macro avg       0.92      0.95      0.93       264\n",
      "weighted avg       0.94      0.94      0.94       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9109\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.81      0.81      0.81        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.83      0.83      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 115.90142607688904 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.0038413401460275056\n",
      "Acquired samples: 30\n",
      "Sampling duration: 7.5698487758636475 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5433, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4723, Accuracy: 0.817, F1 Micro: 0.8959, F1 Macro: 0.8949\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.36, Accuracy: 0.9412, F1 Micro: 0.9636, F1 Macro: 0.9619\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2425, Accuracy: 0.9554, F1 Micro: 0.9721, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1817, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9765\n",
      "Epoch 6/10, Train Loss: 0.1317, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9753\n",
      "Epoch 7/10, Train Loss: 0.1034, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0865, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9781\n",
      "Epoch 9/10, Train Loss: 0.0703, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9767\n",
      "Epoch 10/10, Train Loss: 0.0601, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9758\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.91      0.97      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.52, Accuracy: 0.874, F1 Micro: 0.874, F1 Macro: 0.8449\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2286, Accuracy: 0.8898, F1 Micro: 0.8898, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1692, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.9063\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1497, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9144\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1378, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9179\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1114, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9204\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.083, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9327\n",
      "Epoch 8/10, Train Loss: 0.0924, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9308\n",
      "Epoch 9/10, Train Loss: 0.0574, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9147\n",
      "Epoch 10/10, Train Loss: 0.0567, Accuracy: 0.9055, F1 Micro: 0.9055, F1 Macro: 0.8973\n",
      "\n",
      "Sentiment analysis accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9327\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.90      0.91        83\n",
      "    positive       0.95      0.96      0.96       171\n",
      "\n",
      "    accuracy                           0.94       254\n",
      "   macro avg       0.93      0.93      0.93       254\n",
      "weighted avg       0.94      0.94      0.94       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.9073\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.96      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.89      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.83      0.85       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.91      0.97      0.94       152\n",
      "    positive       0.91      0.75      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.88      0.82      0.85       216\n",
      "weighted avg       0.91      0.91      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.90      0.94        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.93      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 118.34148788452148 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.00330640256870538\n",
      "Acquired samples: 27\n",
      "Sampling duration: 6.964231491088867 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5596, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4745, Accuracy: 0.8192, F1 Micro: 0.897, F1 Macro: 0.8956\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3462, Accuracy: 0.939, F1 Micro: 0.9624, F1 Macro: 0.9607\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2413, Accuracy: 0.9546, F1 Micro: 0.9718, F1 Macro: 0.9703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1749, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9754\n",
      "Epoch 6/10, Train Loss: 0.1273, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1007, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9777\n",
      "Epoch 8/10, Train Loss: 0.0854, Accuracy: 0.965, F1 Micro: 0.9778, F1 Macro: 0.9759\n",
      "Epoch 9/10, Train Loss: 0.0708, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9748\n",
      "Epoch 10/10, Train Loss: 0.0603, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9774\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9777\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5054, Accuracy: 0.8803, F1 Micro: 0.8803, F1 Macro: 0.854\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2502, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9193\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.181, Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9484\n",
      "Epoch 4/10, Train Loss: 0.1414, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9401\n",
      "Epoch 5/10, Train Loss: 0.1146, Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9439\n",
      "Epoch 6/10, Train Loss: 0.1057, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9391\n",
      "Epoch 7/10, Train Loss: 0.096, Accuracy: 0.9112, F1 Micro: 0.9112, F1 Macro: 0.9042\n",
      "Epoch 8/10, Train Loss: 0.0883, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.936\n",
      "Epoch 9/10, Train Loss: 0.0698, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9274\n",
      "Epoch 10/10, Train Loss: 0.045, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9398\n",
      "\n",
      "Sentiment analysis accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9484\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.93        84\n",
      "    positive       0.99      0.94      0.96       175\n",
      "\n",
      "    accuracy                           0.95       259\n",
      "   macro avg       0.94      0.96      0.95       259\n",
      "weighted avg       0.96      0.95      0.95       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9272\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.88      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.93      0.95      0.94       152\n",
      "    positive       0.85      0.77      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.83      0.85      0.84       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.89      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 116.28146481513977 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.0046526392921805385\n",
      "Acquired samples: 18\n",
      "Sampling duration: 6.293374538421631 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5367, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4643, Accuracy: 0.8542, F1 Micro: 0.9149, F1 Macro: 0.9145\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3323, Accuracy: 0.942, F1 Micro: 0.964, F1 Macro: 0.9625\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2287, Accuracy: 0.9598, F1 Micro: 0.975, F1 Macro: 0.9738\n",
      "Epoch 5/10, Train Loss: 0.1603, Accuracy: 0.9539, F1 Micro: 0.971, F1 Macro: 0.9686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1199, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0974, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0773, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9766\n",
      "Epoch 9/10, Train Loss: 0.0631, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0536, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9792\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9792\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.95      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5411, Accuracy: 0.8943, F1 Micro: 0.8943, F1 Macro: 0.8772\n",
      "Epoch 2/10, Train Loss: 0.2852, Accuracy: 0.8906, F1 Micro: 0.8906, F1 Macro: 0.8829\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1842, Accuracy: 0.8981, F1 Micro: 0.8981, F1 Macro: 0.89\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1607, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9327\n",
      "Epoch 5/10, Train Loss: 0.1384, Accuracy: 0.9321, F1 Micro: 0.9321, F1 Macro: 0.923\n",
      "Epoch 6/10, Train Loss: 0.1162, Accuracy: 0.9358, F1 Micro: 0.9358, F1 Macro: 0.9275\n",
      "Epoch 7/10, Train Loss: 0.0872, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.9175\n",
      "Epoch 8/10, Train Loss: 0.0752, Accuracy: 0.9358, F1 Micro: 0.9358, F1 Macro: 0.9271\n",
      "Epoch 9/10, Train Loss: 0.0703, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.9194\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.043, Accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.9356\n",
      "\n",
      "Sentiment analysis accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.9356\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.93      0.91        85\n",
      "    positive       0.97      0.95      0.96       180\n",
      "\n",
      "    accuracy                           0.94       265\n",
      "   macro avg       0.93      0.94      0.94       265\n",
      "weighted avg       0.94      0.94      0.94       265\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9192\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.69      0.76        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.81      0.79      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.82      0.84       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.75      0.86        12\n",
      "     neutral       0.94      0.95      0.94       152\n",
      "    positive       0.83      0.85      0.84        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.92      0.85      0.88       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.95      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 124.78835797309875 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.003136814711615443\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.8860673904418945 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5358, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4465, Accuracy: 0.8527, F1 Micro: 0.9144, F1 Macro: 0.9144\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3254, Accuracy: 0.9397, F1 Micro: 0.9626, F1 Macro: 0.9608\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2088, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1509, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9748\n",
      "Epoch 6/10, Train Loss: 0.1157, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9743\n",
      "Epoch 7/10, Train Loss: 0.0925, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9734\n",
      "Epoch 8/10, Train Loss: 0.0777, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0607, Accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9783\n",
      "Epoch 10/10, Train Loss: 0.0535, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.978\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9783\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4997, Accuracy: 0.902, F1 Micro: 0.902, F1 Macro: 0.8929\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2537, Accuracy: 0.9059, F1 Micro: 0.9059, F1 Macro: 0.8892\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.204, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9154\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.146, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9272\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1462, Accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.9435\n",
      "Epoch 6/10, Train Loss: 0.1292, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9252\n",
      "Epoch 7/10, Train Loss: 0.1048, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9231\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0668, Accuracy: 0.9569, F1 Micro: 0.9569, F1 Macro: 0.9507\n",
      "Epoch 9/10, Train Loss: 0.0659, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9141\n",
      "Epoch 10/10, Train Loss: 0.0676, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9313\n",
      "\n",
      "Sentiment analysis accuracy: 0.9569, F1 Micro: 0.9569, F1 Macro: 0.9507\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.91      0.93        85\n",
      "    positive       0.95      0.98      0.97       170\n",
      "\n",
      "    accuracy                           0.96       255\n",
      "   macro avg       0.96      0.94      0.95       255\n",
      "weighted avg       0.96      0.96      0.96       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.92\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.96      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.89      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.92      0.96      0.94       152\n",
      "    positive       0.85      0.79      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.89      0.83      0.86       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      1.00      0.98        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.88      0.92        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.89      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 126.45430397987366 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.0031768945045769215\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.374568462371826 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5265, Accuracy: 0.7939, F1 Micro: 0.8845, F1 Macro: 0.8831\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.431, Accuracy: 0.8943, F1 Micro: 0.9364, F1 Macro: 0.9356\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2967, Accuracy: 0.9531, F1 Micro: 0.9708, F1 Macro: 0.9695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1986, Accuracy: 0.9598, F1 Micro: 0.975, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1408, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1167, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0884, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.977\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0749, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9771\n",
      "Epoch 9/10, Train Loss: 0.0604, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9771\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0557, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9778\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.95      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5311, Accuracy: 0.9, F1 Micro: 0.9, F1 Macro: 0.889\n",
      "Epoch 2/10, Train Loss: 0.2516, Accuracy: 0.8846, F1 Micro: 0.8846, F1 Macro: 0.8767\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1785, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9167\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1801, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.928\n",
      "Epoch 5/10, Train Loss: 0.1565, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9159\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1123, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.928\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.133, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.928\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.088, Accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.944\n",
      "Epoch 9/10, Train Loss: 0.072, Accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9402\n",
      "Epoch 10/10, Train Loss: 0.0688, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.932\n",
      "\n",
      "Sentiment analysis accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.944\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.96      0.93        84\n",
      "    positive       0.98      0.94      0.96       176\n",
      "\n",
      "    accuracy                           0.95       260\n",
      "   macro avg       0.94      0.95      0.94       260\n",
      "weighted avg       0.95      0.95      0.95       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9185\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.86      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.84      0.79      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.86      0.83      0.84       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.88      0.92        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.95      0.95       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.89      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 132.90043592453003 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.00341047877445817\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.7965874671936035 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5405, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4294, Accuracy: 0.9234, F1 Micro: 0.9532, F1 Macro: 0.9522\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2881, Accuracy: 0.9509, F1 Micro: 0.9694, F1 Macro: 0.9676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.198, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1396, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1068, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "Epoch 7/10, Train Loss: 0.0863, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0696, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.977\n",
      "Epoch 9/10, Train Loss: 0.0597, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0505, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9778\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.95      0.92      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5255, Accuracy: 0.9044, F1 Micro: 0.9044, F1 Macro: 0.8958\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.219, Accuracy: 0.9265, F1 Micro: 0.9265, F1 Macro: 0.916\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1512, Accuracy: 0.9301, F1 Micro: 0.9301, F1 Macro: 0.9226\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1276, Accuracy: 0.9338, F1 Micro: 0.9338, F1 Macro: 0.9265\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.113, Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9449\n",
      "Epoch 6/10, Train Loss: 0.0871, Accuracy: 0.9485, F1 Micro: 0.9485, F1 Macro: 0.9419\n",
      "Epoch 7/10, Train Loss: 0.0671, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9343\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0567, Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9459\n",
      "Epoch 9/10, Train Loss: 0.0535, Accuracy: 0.9265, F1 Micro: 0.9265, F1 Macro: 0.9187\n",
      "Epoch 10/10, Train Loss: 0.076, Accuracy: 0.9265, F1 Micro: 0.9265, F1 Macro: 0.9187\n",
      "\n",
      "Sentiment analysis accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9459\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.93        87\n",
      "    positive       0.98      0.95      0.96       185\n",
      "\n",
      "    accuracy                           0.95       272\n",
      "   macro avg       0.94      0.95      0.95       272\n",
      "weighted avg       0.95      0.95      0.95       272\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9293\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.95      0.92      0.94       152\n",
      "    positive       0.78      0.87      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.88      0.87      0.87       216\n",
      "weighted avg       0.91      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.95      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 135.52405619621277 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.0031994540244340897\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.421073913574219 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5308, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4261, Accuracy: 0.9263, F1 Micro: 0.9544, F1 Macro: 0.9524\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2807, Accuracy: 0.9531, F1 Micro: 0.9708, F1 Macro: 0.9694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1897, Accuracy: 0.9621, F1 Micro: 0.9764, F1 Macro: 0.9753\n",
      "Epoch 5/10, Train Loss: 0.1383, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1001, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9763\n",
      "Epoch 7/10, Train Loss: 0.0875, Accuracy: 0.9613, F1 Micro: 0.9755, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.069, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0572, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0509, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9779\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9779\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.93      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4749, Accuracy: 0.9071, F1 Micro: 0.9071, F1 Macro: 0.8985\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2211, Accuracy: 0.9071, F1 Micro: 0.9071, F1 Macro: 0.8876\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1807, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.932\n",
      "Epoch 4/10, Train Loss: 0.147, Accuracy: 0.9257, F1 Micro: 0.9257, F1 Macro: 0.9178\n",
      "Epoch 5/10, Train Loss: 0.1343, Accuracy: 0.9368, F1 Micro: 0.9368, F1 Macro: 0.9271\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0945, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9328\n",
      "Epoch 7/10, Train Loss: 0.0893, Accuracy: 0.9257, F1 Micro: 0.9257, F1 Macro: 0.9178\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0602, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9332\n",
      "Epoch 9/10, Train Loss: 0.0501, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9244\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0561, Accuracy: 0.948, F1 Micro: 0.948, F1 Macro: 0.9416\n",
      "\n",
      "Sentiment analysis accuracy: 0.948, F1 Micro: 0.948, F1 Macro: 0.9416\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.97      0.92        86\n",
      "    positive       0.98      0.94      0.96       183\n",
      "\n",
      "    accuracy                           0.95       269\n",
      "   macro avg       0.93      0.95      0.94       269\n",
      "weighted avg       0.95      0.95      0.95       269\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9259\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.78      0.81      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.87      0.86      0.86       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 138.62809658050537 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.0046424539759755135\n",
      "Acquired samples: 8\n",
      "Sampling duration: 3.682630777359009 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5318, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.42, Accuracy: 0.9196, F1 Micro: 0.9511, F1 Macro: 0.9498\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2727, Accuracy: 0.9494, F1 Micro: 0.9686, F1 Macro: 0.967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1882, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1394, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.977\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1055, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9784\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0869, Accuracy: 0.9717, F1 Micro: 0.9822, F1 Macro: 0.9813\n",
      "Epoch 8/10, Train Loss: 0.0681, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9742\n",
      "Epoch 9/10, Train Loss: 0.0553, Accuracy: 0.9658, F1 Micro: 0.9783, F1 Macro: 0.9766\n",
      "Epoch 10/10, Train Loss: 0.0506, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9781\n",
      "\n",
      "Aspect detection accuracy: 0.9717, F1 Micro: 0.9822, F1 Macro: 0.9813\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.94      0.96      0.95       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5306, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9262\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2324, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9322\n",
      "Epoch 3/10, Train Loss: 0.1905, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9262\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1359, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9353\n",
      "Epoch 5/10, Train Loss: 0.133, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9229\n",
      "Epoch 6/10, Train Loss: 0.1112, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9157\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0854, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9401\n",
      "Epoch 8/10, Train Loss: 0.0859, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.936\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0605, Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9481\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0589, Accuracy: 0.9575, F1 Micro: 0.9575, F1 Macro: 0.9523\n",
      "\n",
      "Sentiment analysis accuracy: 0.9575, F1 Micro: 0.9575, F1 Macro: 0.9523\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.95      0.94        85\n",
      "    positive       0.98      0.96      0.97       174\n",
      "\n",
      "    accuracy                           0.96       259\n",
      "   macro avg       0.95      0.96      0.95       259\n",
      "weighted avg       0.96      0.96      0.96       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9645, F1 Micro: 0.9645, F1 Macro: 0.9326\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.86      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.83      0.91        12\n",
      "     neutral       0.94      0.96      0.95       152\n",
      "    positive       0.86      0.85      0.85        52\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.93      0.88      0.90       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.89      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 137.0125036239624 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.002753984648734331\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.335637092590332 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5311, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4151, Accuracy: 0.9249, F1 Micro: 0.9542, F1 Macro: 0.953\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2706, Accuracy: 0.9524, F1 Micro: 0.9703, F1 Macro: 0.9685\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1741, Accuracy: 0.9554, F1 Micro: 0.9719, F1 Macro: 0.97\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1264, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9782\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1016, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9787\n",
      "Epoch 7/10, Train Loss: 0.0798, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9757\n",
      "Epoch 8/10, Train Loss: 0.0657, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9747\n",
      "Epoch 9/10, Train Loss: 0.0538, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9781\n",
      "Epoch 10/10, Train Loss: 0.0482, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9779\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9787\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.93      0.94      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5174, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9272\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2205, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9358\n",
      "Epoch 3/10, Train Loss: 0.1504, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9239\n",
      "Epoch 4/10, Train Loss: 0.1316, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9268\n",
      "Epoch 5/10, Train Loss: 0.1304, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9084\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1074, Accuracy: 0.9577, F1 Micro: 0.9577, F1 Macro: 0.9524\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0751, Accuracy: 0.9577, F1 Micro: 0.9577, F1 Macro: 0.9524\n",
      "Epoch 8/10, Train Loss: 0.064, Accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9399\n",
      "Epoch 9/10, Train Loss: 0.0658, Accuracy: 0.9538, F1 Micro: 0.9538, F1 Macro: 0.9476\n",
      "Epoch 10/10, Train Loss: 0.0452, Accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.9427\n",
      "\n",
      "Sentiment analysis accuracy: 0.9577, F1 Micro: 0.9577, F1 Macro: 0.9524\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        84\n",
      "    positive       0.98      0.95      0.97       176\n",
      "\n",
      "    accuracy                           0.96       260\n",
      "   macro avg       0.95      0.96      0.95       260\n",
      "weighted avg       0.96      0.96      0.96       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9243\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.85      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.93      0.94      0.94       152\n",
      "    positive       0.80      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.83      0.83      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.88      0.92        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.95      0.95       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.93      0.89      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 133.714457988739 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0030179068446159365\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.8140249252319336 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5316, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4155, Accuracy: 0.9211, F1 Micro: 0.9519, F1 Macro: 0.9509\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2665, Accuracy: 0.9509, F1 Micro: 0.9696, F1 Macro: 0.968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1776, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9755\n",
      "Epoch 5/10, Train Loss: 0.1233, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9747\n",
      "Epoch 6/10, Train Loss: 0.0951, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0802, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "Epoch 8/10, Train Loss: 0.0656, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0557, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9779\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0464, Accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9794\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9794\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.93      0.95      0.94       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.99      1.00      1.00       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4716, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9104\n",
      "Epoch 2/10, Train Loss: 0.2554, Accuracy: 0.8955, F1 Micro: 0.8955, F1 Macro: 0.8869\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2155, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9367\n",
      "Epoch 4/10, Train Loss: 0.1457, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9319\n",
      "Epoch 5/10, Train Loss: 0.1015, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9255\n",
      "Epoch 6/10, Train Loss: 0.1382, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9334\n",
      "Epoch 7/10, Train Loss: 0.0904, Accuracy: 0.9179, F1 Micro: 0.9179, F1 Macro: 0.9027\n",
      "Epoch 8/10, Train Loss: 0.0691, Accuracy: 0.9179, F1 Micro: 0.9179, F1 Macro: 0.9085\n",
      "Epoch 9/10, Train Loss: 0.0486, Accuracy: 0.9254, F1 Micro: 0.9254, F1 Macro: 0.9159\n",
      "Epoch 10/10, Train Loss: 0.0495, Accuracy: 0.9104, F1 Micro: 0.9104, F1 Macro: 0.9017\n",
      "\n",
      "Sentiment analysis accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9367\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.95      0.92        85\n",
      "    positive       0.98      0.94      0.96       183\n",
      "\n",
      "    accuracy                           0.94       268\n",
      "   macro avg       0.93      0.95      0.94       268\n",
      "weighted avg       0.95      0.94      0.94       268\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9614, F1 Micro: 0.9614, F1 Macro: 0.9275\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.89      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.75      0.72        12\n",
      "     neutral       0.93      0.95      0.94       152\n",
      "    positive       0.85      0.79      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.83      0.83      0.83       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.92      0.85      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.99      1.00      1.00       186\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 135.714537858963 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0027790669817477466\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.2160379886627197 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.532, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4177, Accuracy: 0.9196, F1 Micro: 0.9512, F1 Macro: 0.9498\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2664, Accuracy: 0.9501, F1 Micro: 0.969, F1 Macro: 0.9675\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.178, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1275, Accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9784\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1025, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9789\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0815, Accuracy: 0.9717, F1 Micro: 0.9822, F1 Macro: 0.9813\n",
      "Epoch 8/10, Train Loss: 0.0631, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9772\n",
      "Epoch 9/10, Train Loss: 0.0543, Accuracy: 0.9702, F1 Micro: 0.9812, F1 Macro: 0.9799\n",
      "Epoch 10/10, Train Loss: 0.0471, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9791\n",
      "\n",
      "Aspect detection accuracy: 0.9717, F1 Micro: 0.9822, F1 Macro: 0.9813\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.93      0.97      0.95       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4841, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.9077\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2501, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9194\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1582, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9234\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1446, Accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9388\n",
      "Epoch 5/10, Train Loss: 0.1289, Accuracy: 0.9416, F1 Micro: 0.9416, F1 Macro: 0.935\n",
      "Epoch 6/10, Train Loss: 0.1171, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9251\n",
      "Epoch 7/10, Train Loss: 0.0892, Accuracy: 0.9183, F1 Micro: 0.9183, F1 Macro: 0.9113\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0785, Accuracy: 0.9494, F1 Micro: 0.9494, F1 Macro: 0.9434\n",
      "Epoch 9/10, Train Loss: 0.0747, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9246\n",
      "Epoch 10/10, Train Loss: 0.0841, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9186\n",
      "\n",
      "Sentiment analysis accuracy: 0.9494, F1 Micro: 0.9494, F1 Macro: 0.9434\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.94      0.92        85\n",
      "    positive       0.97      0.95      0.96       172\n",
      "\n",
      "    accuracy                           0.95       257\n",
      "   macro avg       0.94      0.95      0.94       257\n",
      "weighted avg       0.95      0.95      0.95       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9637, F1 Micro: 0.9637, F1 Macro: 0.9288\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.93      0.97      0.95       152\n",
      "    positive       0.89      0.79      0.84        52\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.88      0.84      0.86       216\n",
      "weighted avg       0.92      0.92      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.92      0.85      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.93      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 140.5248293876648 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0029140385100618004\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.7830967903137207 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.53, Accuracy: 0.8006, F1 Micro: 0.8879, F1 Macro: 0.8865\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.396, Accuracy: 0.9375, F1 Micro: 0.9614, F1 Macro: 0.96\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2483, Accuracy: 0.9524, F1 Micro: 0.9704, F1 Macro: 0.9691\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.168, Accuracy: 0.9643, F1 Micro: 0.9777, F1 Macro: 0.9768\n",
      "Epoch 5/10, Train Loss: 0.1284, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.094, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.978\n",
      "Epoch 7/10, Train Loss: 0.0774, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9745\n",
      "Epoch 8/10, Train Loss: 0.064, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0525, Accuracy: 0.9732, F1 Micro: 0.9831, F1 Macro: 0.9822\n",
      "Epoch 10/10, Train Loss: 0.0457, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9783\n",
      "\n",
      "Aspect detection accuracy: 0.9732, F1 Micro: 0.9831, F1 Macro: 0.9822\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.93      0.97      0.95       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.98      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.98      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4724, Accuracy: 0.9278, F1 Micro: 0.9278, F1 Macro: 0.9186\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2238, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9288\n",
      "Epoch 3/10, Train Loss: 0.1677, Accuracy: 0.9278, F1 Micro: 0.9278, F1 Macro: 0.9208\n",
      "Epoch 4/10, Train Loss: 0.1451, Accuracy: 0.9011, F1 Micro: 0.9011, F1 Macro: 0.8938\n",
      "Epoch 5/10, Train Loss: 0.1292, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.8998\n",
      "Epoch 6/10, Train Loss: 0.096, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9168\n",
      "Epoch 7/10, Train Loss: 0.0757, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9164\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0596, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9313\n",
      "Epoch 9/10, Train Loss: 0.052, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9164\n",
      "Epoch 10/10, Train Loss: 0.0569, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.916\n",
      "\n",
      "Sentiment analysis accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9313\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.92      0.91        86\n",
      "    positive       0.96      0.95      0.95       177\n",
      "\n",
      "    accuracy                           0.94       263\n",
      "   macro avg       0.93      0.93      0.93       263\n",
      "weighted avg       0.94      0.94      0.94       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9637, F1 Micro: 0.9637, F1 Macro: 0.9231\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.96      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.90      0.82      0.86        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.93      0.97      0.95       152\n",
      "    positive       0.89      0.79      0.84        52\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.88      0.84      0.86       216\n",
      "weighted avg       0.92      0.92      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.92      0.88      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 141.34671902656555 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0017317894846200943\n",
      "Acquired samples: 8\n",
      "Sampling duration: 1.0182008743286133 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5303, Accuracy: 0.8058, F1 Micro: 0.8905, F1 Macro: 0.8893\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3796, Accuracy: 0.9234, F1 Micro: 0.9527, F1 Macro: 0.9507\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2411, Accuracy: 0.9576, F1 Micro: 0.9737, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1627, Accuracy: 0.9665, F1 Micro: 0.9791, F1 Macro: 0.9783\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1203, Accuracy: 0.9695, F1 Micro: 0.9809, F1 Macro: 0.98\n",
      "Epoch 6/10, Train Loss: 0.0981, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.979\n",
      "Epoch 7/10, Train Loss: 0.0738, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9775\n",
      "Epoch 8/10, Train Loss: 0.0626, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9759\n",
      "Epoch 9/10, Train Loss: 0.0529, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9772\n",
      "Epoch 10/10, Train Loss: 0.0454, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9784\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9809, F1 Macro: 0.98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.93      0.97      0.95       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4927, Accuracy: 0.8906, F1 Micro: 0.8906, F1 Macro: 0.8843\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.244, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9397\n",
      "Epoch 3/10, Train Loss: 0.1756, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9352\n",
      "Epoch 4/10, Train Loss: 0.1364, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9352\n",
      "Epoch 5/10, Train Loss: 0.123, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9274\n",
      "Epoch 6/10, Train Loss: 0.0921, Accuracy: 0.9258, F1 Micro: 0.9258, F1 Macro: 0.9196\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.083, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9397\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0456, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9397\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.057, Accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9439\n",
      "Epoch 10/10, Train Loss: 0.0848, Accuracy: 0.9219, F1 Micro: 0.9219, F1 Macro: 0.9152\n",
      "\n",
      "Sentiment analysis accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9439\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.93        86\n",
      "    positive       0.98      0.95      0.96       170\n",
      "\n",
      "    accuracy                           0.95       256\n",
      "   macro avg       0.94      0.95      0.94       256\n",
      "weighted avg       0.95      0.95      0.95       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9614, F1 Micro: 0.9614, F1 Macro: 0.9215\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.87      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.94      0.97      0.95       152\n",
      "    positive       0.88      0.83      0.85        52\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.90      0.85      0.87       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 141.89449739456177 s\n",
      "Total runtime: 3076.1313710212708 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[0], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580b9a21",
   "metadata": {
    "papermill": {
     "duration": 0.011291,
     "end_time": "2025-03-26T09:39:20.317316",
     "exception": false,
     "start_time": "2025-03-26T09:39:20.306025",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5dd481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 2\n",
      "Random seed: 81\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.647, Accuracy: 0.7054, F1 Micro: 0.8127, F1 Macro: 0.7262\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5731, Accuracy: 0.7374, F1 Micro: 0.8408, F1 Macro: 0.7949\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5493, Accuracy: 0.7917, F1 Micro: 0.8824, F1 Macro: 0.8802\n",
      "Epoch 4/10, Train Loss: 0.5049, Accuracy: 0.7894, F1 Micro: 0.8822, F1 Macro: 0.8807\n",
      "Epoch 5/10, Train Loss: 0.4781, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 6/10, Train Loss: 0.4364, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4061, Accuracy: 0.7902, F1 Micro: 0.8826, F1 Macro: 0.8811\n",
      "Epoch 8/10, Train Loss: 0.4421, Accuracy: 0.7902, F1 Micro: 0.8825, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.4208, Accuracy: 0.7939, F1 Micro: 0.8842, F1 Macro: 0.8826\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3864, Accuracy: 0.8036, F1 Micro: 0.8886, F1 Macro: 0.8869\n",
      "\n",
      "Aspect detection accuracy: 0.8036, F1 Micro: 0.8886, F1 Macro: 0.8869\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.79      1.00      0.88       175\n",
      "      others       0.78      0.95      0.86       158\n",
      "        part       0.71      1.00      0.83       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.80      0.99      0.89      1061\n",
      "   macro avg       0.80      0.99      0.89      1061\n",
      "weighted avg       0.81      0.99      0.89      1061\n",
      " samples avg       0.81      0.99      0.89      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6351, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5577, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5004, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4905, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4593, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4341, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4188, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2323, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2613, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2353, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "\n",
      "Sentiment analysis accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         3\n",
      "    positive       0.91      1.00      0.95        31\n",
      "\n",
      "    accuracy                           0.91        34\n",
      "   macro avg       0.46      0.50      0.48        34\n",
      "weighted avg       0.83      0.91      0.87        34\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.8009, F1 Micro: 0.8009, F1 Macro: 0.3313\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.78      1.00      0.88       167\n",
      "    positive       1.00      0.06      0.11        33\n",
      "\n",
      "    accuracy                           0.78       216\n",
      "   macro avg       0.59      0.35      0.33       216\n",
      "weighted avg       0.76      0.78      0.70       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.78      0.95      0.85       152\n",
      "    positive       0.65      0.38      0.48        52\n",
      "\n",
      "    accuracy                           0.76       216\n",
      "   macro avg       0.47      0.44      0.45       216\n",
      "weighted avg       0.70      0.76      0.72       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        23\n",
      "     neutral       0.71      1.00      0.83       152\n",
      "    positive       1.00      0.02      0.05        41\n",
      "\n",
      "    accuracy                           0.71       216\n",
      "   macro avg       0.57      0.34      0.29       216\n",
      "weighted avg       0.69      0.71      0.59       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 58.44408416748047 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.004604773595929146\n",
      "Acquired samples: 82\n",
      "Sampling duration: 15.037182092666626 seconds\n",
      "New train size: 136\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.617, Accuracy: 0.7939, F1 Micro: 0.8834, F1 Macro: 0.8812\n",
      "Epoch 2/10, Train Loss: 0.5421, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4897, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4548, Accuracy: 0.8013, F1 Micro: 0.8875, F1 Macro: 0.8858\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4595, Accuracy: 0.814, F1 Micro: 0.8933, F1 Macro: 0.8916\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4321, Accuracy: 0.8385, F1 Micro: 0.9057, F1 Macro: 0.9043\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3553, Accuracy: 0.8638, F1 Micro: 0.9177, F1 Macro: 0.9152\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3278, Accuracy: 0.8795, F1 Micro: 0.9268, F1 Macro: 0.9246\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2775, Accuracy: 0.9025, F1 Micro: 0.9398, F1 Macro: 0.9374\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2455, Accuracy: 0.9092, F1 Micro: 0.9438, F1 Macro: 0.9414\n",
      "\n",
      "Aspect detection accuracy: 0.9092, F1 Micro: 0.9438, F1 Macro: 0.9414\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.97      1.00      0.99       187\n",
      "     machine       0.94      0.95      0.94       175\n",
      "      others       0.87      0.91      0.89       158\n",
      "        part       0.87      0.94      0.90       158\n",
      "       price       0.94      0.99      0.96       192\n",
      "     service       0.93      0.99      0.96       191\n",
      "\n",
      "   micro avg       0.92      0.97      0.94      1061\n",
      "   macro avg       0.92      0.96      0.94      1061\n",
      "weighted avg       0.92      0.97      0.94      1061\n",
      " samples avg       0.93      0.97      0.94      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5424, Accuracy: 0.7232, F1 Micro: 0.7232, F1 Macro: 0.4197\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.45, Accuracy: 0.7232, F1 Micro: 0.7232, F1 Macro: 0.4197\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4465, Accuracy: 0.7232, F1 Micro: 0.7232, F1 Macro: 0.4197\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3448, Accuracy: 0.808, F1 Micro: 0.808, F1 Macro: 0.736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2488, Accuracy: 0.875, F1 Micro: 0.875, F1 Macro: 0.8496\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1347, Accuracy: 0.8884, F1 Micro: 0.8884, F1 Macro: 0.8686\n",
      "Epoch 7/10, Train Loss: 0.1182, Accuracy: 0.8839, F1 Micro: 0.8839, F1 Macro: 0.8578\n",
      "Epoch 8/10, Train Loss: 0.1289, Accuracy: 0.875, F1 Micro: 0.875, F1 Macro: 0.8496\n",
      "Epoch 9/10, Train Loss: 0.0495, Accuracy: 0.8661, F1 Micro: 0.8661, F1 Macro: 0.8327\n",
      "Epoch 10/10, Train Loss: 0.0643, Accuracy: 0.8705, F1 Micro: 0.8705, F1 Macro: 0.8375\n",
      "\n",
      "Sentiment analysis accuracy: 0.8884, F1 Micro: 0.8884, F1 Macro: 0.8686\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.90      0.82        62\n",
      "    positive       0.96      0.88      0.92       162\n",
      "\n",
      "    accuracy                           0.89       224\n",
      "   macro avg       0.85      0.89      0.87       224\n",
      "weighted avg       0.90      0.89      0.89       224\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 136: Accuracy: 0.8958, F1 Micro: 0.8958, F1 Macro: 0.7807\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       1.00      0.83      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.62      0.71        16\n",
      "     neutral       0.93      0.95      0.94       167\n",
      "    positive       0.71      0.76      0.74        33\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.83      0.78      0.80       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.38      0.67      0.48        12\n",
      "     neutral       0.87      0.91      0.89       152\n",
      "    positive       0.75      0.52      0.61        52\n",
      "\n",
      "    accuracy                           0.81       216\n",
      "   macro avg       0.67      0.70      0.66       216\n",
      "weighted avg       0.82      0.81      0.80       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.57      0.68        23\n",
      "     neutral       0.87      0.94      0.90       152\n",
      "    positive       0.72      0.63      0.68        41\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.82      0.71      0.75       216\n",
      "weighted avg       0.84      0.84      0.84       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.54      0.70        13\n",
      "     neutral       0.94      0.99      0.96       186\n",
      "    positive       0.77      0.59      0.67        17\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.71      0.78       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.57      0.70        14\n",
      "     neutral       0.93      0.99      0.96       185\n",
      "    positive       0.89      0.47      0.62        17\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.68      0.76       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Total train time: 76.12160873413086 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.009672479890286923\n",
      "Acquired samples: 73\n",
      "Sampling duration: 16.113519191741943 seconds\n",
      "New train size: 209\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5978, Accuracy: 0.7924, F1 Micro: 0.8837, F1 Macro: 0.8822\n",
      "Epoch 2/10, Train Loss: 0.506, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4632, Accuracy: 0.7954, F1 Micro: 0.8852, F1 Macro: 0.8837\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4416, Accuracy: 0.8244, F1 Micro: 0.8985, F1 Macro: 0.897\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3754, Accuracy: 0.843, F1 Micro: 0.9074, F1 Macro: 0.9061\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3292, Accuracy: 0.8847, F1 Micro: 0.9291, F1 Macro: 0.9267\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2853, Accuracy: 0.8936, F1 Micro: 0.9343, F1 Macro: 0.9315\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2328, Accuracy: 0.9174, F1 Micro: 0.9485, F1 Macro: 0.9456\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1883, Accuracy: 0.9196, F1 Micro: 0.9498, F1 Macro: 0.9464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1692, Accuracy: 0.9315, F1 Micro: 0.9573, F1 Macro: 0.9552\n",
      "\n",
      "Aspect detection accuracy: 0.9315, F1 Micro: 0.9573, F1 Macro: 0.9552\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.95      0.95       175\n",
      "      others       0.89      0.94      0.91       158\n",
      "        part       0.91      0.94      0.93       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.95      1.00      0.97       191\n",
      "\n",
      "   micro avg       0.94      0.97      0.96      1061\n",
      "   macro avg       0.94      0.97      0.96      1061\n",
      "weighted avg       0.94      0.97      0.96      1061\n",
      " samples avg       0.94      0.97      0.95      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6558, Accuracy: 0.6983, F1 Micro: 0.6983, F1 Macro: 0.4112\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5011, Accuracy: 0.781, F1 Micro: 0.781, F1 Macro: 0.743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3911, Accuracy: 0.8843, F1 Micro: 0.8843, F1 Macro: 0.8676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2807, Accuracy: 0.9174, F1 Micro: 0.9174, F1 Macro: 0.9054\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1587, Accuracy: 0.9215, F1 Micro: 0.9215, F1 Macro: 0.9086\n",
      "Epoch 6/10, Train Loss: 0.1511, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8904\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1395, Accuracy: 0.9215, F1 Micro: 0.9215, F1 Macro: 0.9098\n",
      "Epoch 8/10, Train Loss: 0.1167, Accuracy: 0.9132, F1 Micro: 0.9132, F1 Macro: 0.8966\n",
      "Epoch 9/10, Train Loss: 0.1224, Accuracy: 0.9174, F1 Micro: 0.9174, F1 Macro: 0.9054\n",
      "Epoch 10/10, Train Loss: 0.0705, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8937\n",
      "\n",
      "Sentiment analysis accuracy: 0.9215, F1 Micro: 0.9215, F1 Macro: 0.9098\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.93      0.88        73\n",
      "    positive       0.97      0.92      0.94       169\n",
      "\n",
      "    accuracy                           0.92       242\n",
      "   macro avg       0.90      0.92      0.91       242\n",
      "weighted avg       0.93      0.92      0.92       242\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 209: Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.8471\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.94      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.95      0.95      0.95       167\n",
      "    positive       0.73      0.73      0.73        33\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.83      0.85      0.84       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.75      0.67        12\n",
      "     neutral       0.89      0.94      0.92       152\n",
      "    positive       0.85      0.67      0.75        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.78      0.79      0.78       216\n",
      "weighted avg       0.87      0.87      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.74      0.76        23\n",
      "     neutral       0.91      0.94      0.92       152\n",
      "    positive       0.83      0.73      0.78        41\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.84      0.80      0.82       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.69      0.82        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.76      0.76      0.76        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.82      0.85       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.64      0.78        14\n",
      "     neutral       0.94      1.00      0.97       185\n",
      "    positive       0.91      0.59      0.71        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.95      0.74      0.82       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Total train time: 83.69093084335327 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.008265296928584576\n",
      "Acquired samples: 66\n",
      "Sampling duration: 14.925677299499512 seconds\n",
      "New train size: 275\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5831, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5164, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4649, Accuracy: 0.8185, F1 Micro: 0.8959, F1 Macro: 0.8943\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3976, Accuracy: 0.881, F1 Micro: 0.9288, F1 Macro: 0.9279\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3395, Accuracy: 0.9077, F1 Micro: 0.9429, F1 Macro: 0.9406\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2686, Accuracy: 0.9226, F1 Micro: 0.9519, F1 Macro: 0.949\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2239, Accuracy: 0.9308, F1 Micro: 0.9567, F1 Macro: 0.9541\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1813, Accuracy: 0.9449, F1 Micro: 0.9656, F1 Macro: 0.9636\n",
      "Epoch 9/10, Train Loss: 0.1532, Accuracy: 0.9442, F1 Micro: 0.965, F1 Macro: 0.9628\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1228, Accuracy: 0.9457, F1 Micro: 0.9659, F1 Macro: 0.9637\n",
      "\n",
      "Aspect detection accuracy: 0.9457, F1 Micro: 0.9659, F1 Macro: 0.9637\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.93      0.97      0.95       175\n",
      "      others       0.91      0.89      0.90       158\n",
      "        part       0.94      0.99      0.97       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.95      0.97      0.96      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.97      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5078, Accuracy: 0.6917, F1 Micro: 0.6917, F1 Macro: 0.4089\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3734, Accuracy: 0.8142, F1 Micro: 0.8142, F1 Macro: 0.7798\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.252, Accuracy: 0.8933, F1 Micro: 0.8933, F1 Macro: 0.8808\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1582, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8978\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1439, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1137, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8952\n",
      "Epoch 7/10, Train Loss: 0.1161, Accuracy: 0.8893, F1 Micro: 0.8893, F1 Macro: 0.8767\n",
      "Epoch 8/10, Train Loss: 0.0986, Accuracy: 0.8972, F1 Micro: 0.8972, F1 Macro: 0.882\n",
      "Epoch 9/10, Train Loss: 0.1117, Accuracy: 0.8854, F1 Micro: 0.8854, F1 Macro: 0.874\n",
      "Epoch 10/10, Train Loss: 0.0807, Accuracy: 0.8814, F1 Micro: 0.8814, F1 Macro: 0.87\n",
      "\n",
      "Sentiment analysis accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8952\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.88      0.86        78\n",
      "    positive       0.95      0.92      0.93       175\n",
      "\n",
      "    accuracy                           0.91       253\n",
      "   macro avg       0.89      0.90      0.90       253\n",
      "weighted avg       0.91      0.91      0.91       253\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 275: Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.868\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.96      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.93      0.97      0.95       167\n",
      "    positive       0.79      0.67      0.72        33\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.86      0.80      0.82       216\n",
      "weighted avg       0.90      0.91      0.90       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.56      0.83      0.67        12\n",
      "     neutral       0.91      0.89      0.90       152\n",
      "    positive       0.78      0.75      0.76        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.75      0.82      0.78       216\n",
      "weighted avg       0.86      0.85      0.85       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.78      0.80        23\n",
      "     neutral       0.94      0.99      0.96       152\n",
      "    positive       0.94      0.76      0.84        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.84      0.87       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.69      0.82        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.84      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.89      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 92.1862223148346 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.010147236287593842\n",
      "Acquired samples: 59\n",
      "Sampling duration: 14.092841625213623 seconds\n",
      "New train size: 334\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5872, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4988, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4383, Accuracy: 0.8475, F1 Micro: 0.9111, F1 Macro: 0.9101\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3595, Accuracy: 0.904, F1 Micro: 0.9414, F1 Macro: 0.9395\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2924, Accuracy: 0.9301, F1 Micro: 0.9564, F1 Macro: 0.9543\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2269, Accuracy: 0.939, F1 Micro: 0.9618, F1 Macro: 0.9599\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1805, Accuracy: 0.9494, F1 Micro: 0.9683, F1 Macro: 0.9665\n",
      "Epoch 8/10, Train Loss: 0.1478, Accuracy: 0.9308, F1 Micro: 0.9562, F1 Macro: 0.9511\n",
      "Epoch 9/10, Train Loss: 0.1192, Accuracy: 0.9464, F1 Micro: 0.9665, F1 Macro: 0.9645\n",
      "Epoch 10/10, Train Loss: 0.1005, Accuracy: 0.9494, F1 Micro: 0.9682, F1 Macro: 0.9662\n",
      "\n",
      "Aspect detection accuracy: 0.9494, F1 Micro: 0.9683, F1 Macro: 0.9665\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      0.98      0.96       175\n",
      "      others       0.93      0.90      0.91       158\n",
      "        part       0.95      0.99      0.97       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.97      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5896, Accuracy: 0.7817, F1 Micro: 0.7817, F1 Macro: 0.7191\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3368, Accuracy: 0.869, F1 Micro: 0.869, F1 Macro: 0.8584\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.225, Accuracy: 0.9127, F1 Micro: 0.9127, F1 Macro: 0.8964\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1386, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9306\n",
      "Epoch 5/10, Train Loss: 0.1426, Accuracy: 0.9206, F1 Micro: 0.9206, F1 Macro: 0.9107\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1363, Accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9403\n",
      "Epoch 7/10, Train Loss: 0.1018, Accuracy: 0.9206, F1 Micro: 0.9206, F1 Macro: 0.9117\n",
      "Epoch 8/10, Train Loss: 0.0897, Accuracy: 0.9365, F1 Micro: 0.9365, F1 Macro: 0.9281\n",
      "Epoch 9/10, Train Loss: 0.0897, Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9359\n",
      "Epoch 10/10, Train Loss: 0.078, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9324\n",
      "\n",
      "Sentiment analysis accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9403\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        78\n",
      "    positive       0.97      0.95      0.96       174\n",
      "\n",
      "    accuracy                           0.95       252\n",
      "   macro avg       0.94      0.94      0.94       252\n",
      "weighted avg       0.95      0.95      0.95       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 334: Accuracy: 0.9437, F1 Micro: 0.9437, F1 Macro: 0.8886\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.83      0.86       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.93      0.90      0.92       152\n",
      "    positive       0.80      0.85      0.82        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.82      0.86      0.84       216\n",
      "weighted avg       0.89      0.88      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.91      0.89        23\n",
      "     neutral       0.94      0.99      0.97       152\n",
      "    positive       0.97      0.76      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.89      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.95      0.84      0.89       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.71      0.83        14\n",
      "     neutral       0.97      1.00      0.98       185\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.95      0.83      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Total train time: 93.56687068939209 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.008623111993074417\n",
      "Acquired samples: 54\n",
      "Sampling duration: 12.425356149673462 seconds\n",
      "New train size: 388\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5718, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4971, Accuracy: 0.8006, F1 Micro: 0.8877, F1 Macro: 0.8861\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4165, Accuracy: 0.8787, F1 Micro: 0.9282, F1 Macro: 0.9269\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3208, Accuracy: 0.9204, F1 Micro: 0.9504, F1 Macro: 0.9475\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.251, Accuracy: 0.9412, F1 Micro: 0.9632, F1 Macro: 0.9613\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1989, Accuracy: 0.9457, F1 Micro: 0.966, F1 Macro: 0.9639\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1545, Accuracy: 0.9524, F1 Micro: 0.9703, F1 Macro: 0.9688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1308, Accuracy: 0.9531, F1 Micro: 0.9707, F1 Macro: 0.9691\n",
      "Epoch 9/10, Train Loss: 0.1052, Accuracy: 0.9479, F1 Micro: 0.9674, F1 Macro: 0.9659\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0908, Accuracy: 0.9539, F1 Micro: 0.9711, F1 Macro: 0.9697\n",
      "\n",
      "Aspect detection accuracy: 0.9539, F1 Micro: 0.9711, F1 Macro: 0.9697\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.94      0.99      0.96       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.97      0.95      0.96       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.96      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5634, Accuracy: 0.6905, F1 Micro: 0.6905, F1 Macro: 0.4725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3566, Accuracy: 0.8889, F1 Micro: 0.8889, F1 Macro: 0.8726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1797, Accuracy: 0.9127, F1 Micro: 0.9127, F1 Macro: 0.8971\n",
      "Epoch 4/10, Train Loss: 0.1312, Accuracy: 0.8968, F1 Micro: 0.8968, F1 Macro: 0.8859\n",
      "Epoch 5/10, Train Loss: 0.1318, Accuracy: 0.8929, F1 Micro: 0.8929, F1 Macro: 0.8824\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1474, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9176\n",
      "Epoch 7/10, Train Loss: 0.1249, Accuracy: 0.9246, F1 Micro: 0.9246, F1 Macro: 0.9144\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0818, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9219\n",
      "Epoch 9/10, Train Loss: 0.0519, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.8982\n",
      "Epoch 10/10, Train Loss: 0.0868, Accuracy: 0.8849, F1 Micro: 0.8849, F1 Macro: 0.8744\n",
      "\n",
      "Sentiment analysis accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9219\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.91      0.89        78\n",
      "    positive       0.96      0.94      0.95       174\n",
      "\n",
      "    accuracy                           0.93       252\n",
      "   macro avg       0.92      0.93      0.92       252\n",
      "weighted avg       0.93      0.93      0.93       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 388: Accuracy: 0.9452, F1 Micro: 0.9452, F1 Macro: 0.8873\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.69      0.79        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.80      0.84       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.93      0.95      0.94       152\n",
      "    positive       0.86      0.81      0.83        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.87      0.86      0.87       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.91      0.82        23\n",
      "     neutral       0.97      0.95      0.96       152\n",
      "    positive       0.85      0.83      0.84        41\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.86      0.90      0.87       216\n",
      "weighted avg       0.93      0.92      0.92       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.95      0.84      0.89       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.64      0.78        14\n",
      "     neutral       0.96      1.00      0.98       185\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.97      0.82      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Total train time: 103.84093618392944 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.00518269594758749\n",
      "Acquired samples: 48\n",
      "Sampling duration: 11.793808937072754 seconds\n",
      "New train size: 436\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5719, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4766, Accuracy: 0.8103, F1 Micro: 0.8926, F1 Macro: 0.8914\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3967, Accuracy: 0.904, F1 Micro: 0.941, F1 Macro: 0.939\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3077, Accuracy: 0.9293, F1 Micro: 0.956, F1 Macro: 0.9538\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2308, Accuracy: 0.9457, F1 Micro: 0.9659, F1 Macro: 0.9637\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.18, Accuracy: 0.9524, F1 Micro: 0.9702, F1 Macro: 0.9686\n",
      "Epoch 7/10, Train Loss: 0.1434, Accuracy: 0.9501, F1 Micro: 0.9686, F1 Macro: 0.9662\n",
      "Epoch 8/10, Train Loss: 0.1237, Accuracy: 0.9472, F1 Micro: 0.9665, F1 Macro: 0.963\n",
      "Epoch 9/10, Train Loss: 0.0951, Accuracy: 0.9524, F1 Micro: 0.97, F1 Macro: 0.9675\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0789, Accuracy: 0.9554, F1 Micro: 0.9719, F1 Macro: 0.9696\n",
      "\n",
      "Aspect detection accuracy: 0.9554, F1 Micro: 0.9719, F1 Macro: 0.9696\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.94      0.88      0.91       158\n",
      "        part       0.95      0.99      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5779, Accuracy: 0.7824, F1 Micro: 0.7824, F1 Macro: 0.7682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3135, Accuracy: 0.8893, F1 Micro: 0.8893, F1 Macro: 0.8794\n",
      "Epoch 3/10, Train Loss: 0.1734, Accuracy: 0.8664, F1 Micro: 0.8664, F1 Macro: 0.8588\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1943, Accuracy: 0.9198, F1 Micro: 0.9198, F1 Macro: 0.9094\n",
      "Epoch 5/10, Train Loss: 0.1667, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.8995\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1332, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9267\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1127, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9267\n",
      "Epoch 8/10, Train Loss: 0.1087, Accuracy: 0.9198, F1 Micro: 0.9198, F1 Macro: 0.9065\n",
      "Epoch 9/10, Train Loss: 0.0905, Accuracy: 0.9237, F1 Micro: 0.9237, F1 Macro: 0.9144\n",
      "Epoch 10/10, Train Loss: 0.0817, Accuracy: 0.9275, F1 Micro: 0.9275, F1 Macro: 0.9194\n",
      "\n",
      "Sentiment analysis accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9267\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.93      0.90        84\n",
      "    positive       0.97      0.94      0.95       178\n",
      "\n",
      "    accuracy                           0.94       262\n",
      "   macro avg       0.92      0.93      0.93       262\n",
      "weighted avg       0.94      0.94      0.94       262\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 436: Accuracy: 0.9475, F1 Micro: 0.9475, F1 Macro: 0.9019\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.83      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.92      0.76        12\n",
      "     neutral       0.94      0.88      0.91       152\n",
      "    positive       0.77      0.85      0.81        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.79      0.88      0.83       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.94      0.99      0.97       152\n",
      "    positive       0.97      0.71      0.82        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.89      0.89       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.89      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.93      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 105.59571552276611 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0054802150465548035\n",
      "Acquired samples: 43\n",
      "Sampling duration: 10.956072807312012 seconds\n",
      "New train size: 479\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5568, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4942, Accuracy: 0.8207, F1 Micro: 0.898, F1 Macro: 0.8969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3792, Accuracy: 0.9129, F1 Micro: 0.9461, F1 Macro: 0.9434\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.294, Accuracy: 0.9278, F1 Micro: 0.9551, F1 Macro: 0.9523\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2275, Accuracy: 0.9501, F1 Micro: 0.969, F1 Macro: 0.9676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1805, Accuracy: 0.9539, F1 Micro: 0.9711, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1371, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9723\n",
      "Epoch 8/10, Train Loss: 0.1036, Accuracy: 0.9568, F1 Micro: 0.9727, F1 Macro: 0.9708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0946, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0775, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9753\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9753\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.96      0.99      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5457, Accuracy: 0.7677, F1 Micro: 0.7677, F1 Macro: 0.687\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2984, Accuracy: 0.9094, F1 Micro: 0.9094, F1 Macro: 0.9003\n",
      "Epoch 3/10, Train Loss: 0.2194, Accuracy: 0.9055, F1 Micro: 0.9055, F1 Macro: 0.8962\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1639, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9377\n",
      "Epoch 5/10, Train Loss: 0.1652, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.9063\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1328, Accuracy: 0.9528, F1 Micro: 0.9528, F1 Macro: 0.946\n",
      "Epoch 7/10, Train Loss: 0.1018, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9124\n",
      "Epoch 8/10, Train Loss: 0.1208, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9144\n",
      "Epoch 9/10, Train Loss: 0.0972, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9339\n",
      "Epoch 10/10, Train Loss: 0.0731, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9346\n",
      "\n",
      "Sentiment analysis accuracy: 0.9528, F1 Micro: 0.9528, F1 Macro: 0.946\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.92      0.93        83\n",
      "    positive       0.96      0.97      0.97       171\n",
      "\n",
      "    accuracy                           0.95       254\n",
      "   macro avg       0.95      0.94      0.95       254\n",
      "weighted avg       0.95      0.95      0.95       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 479: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9121\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.93      0.94      0.94       152\n",
      "    positive       0.83      0.83      0.83        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.89      0.87      0.88       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.96      0.99      0.97       152\n",
      "    positive       0.94      0.78      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.91      0.91       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.64      0.78        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       0.89      1.00      0.94        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.88      0.91       216\n",
      "weighted avg       0.98      0.98      0.97       216\n",
      "\n",
      "Total train time: 110.12418246269226 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.006545739714056253\n",
      "Acquired samples: 39\n",
      "Sampling duration: 9.784183025360107 seconds\n",
      "New train size: 518\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5638, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.454, Accuracy: 0.8452, F1 Micro: 0.9105, F1 Macro: 0.9101\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3541, Accuracy: 0.9189, F1 Micro: 0.9497, F1 Macro: 0.9475\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2569, Accuracy: 0.9375, F1 Micro: 0.9608, F1 Macro: 0.9584\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1942, Accuracy: 0.9472, F1 Micro: 0.9671, F1 Macro: 0.9655\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1539, Accuracy: 0.9546, F1 Micro: 0.9715, F1 Macro: 0.9699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1239, Accuracy: 0.9568, F1 Micro: 0.9727, F1 Macro: 0.971\n",
      "Epoch 8/10, Train Loss: 0.0949, Accuracy: 0.9561, F1 Micro: 0.9723, F1 Macro: 0.9703\n",
      "Epoch 9/10, Train Loss: 0.0829, Accuracy: 0.9561, F1 Micro: 0.9723, F1 Macro: 0.9704\n",
      "Epoch 10/10, Train Loss: 0.0674, Accuracy: 0.9531, F1 Micro: 0.9704, F1 Macro: 0.9682\n",
      "\n",
      "Aspect detection accuracy: 0.9568, F1 Micro: 0.9727, F1 Macro: 0.971\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.90      0.93      0.92       158\n",
      "        part       0.98      0.95      0.96       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      1061\n",
      "   macro avg       0.97      0.97      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.97      0.97      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5624, Accuracy: 0.8284, F1 Micro: 0.8284, F1 Macro: 0.7888\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2941, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9184\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1726, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.9275\n",
      "Epoch 4/10, Train Loss: 0.154, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9234\n",
      "Epoch 5/10, Train Loss: 0.1154, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9162\n",
      "Epoch 6/10, Train Loss: 0.1124, Accuracy: 0.9254, F1 Micro: 0.9254, F1 Macro: 0.9149\n",
      "Epoch 7/10, Train Loss: 0.1011, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9087\n",
      "Epoch 8/10, Train Loss: 0.0914, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9074\n",
      "Epoch 9/10, Train Loss: 0.0978, Accuracy: 0.9179, F1 Micro: 0.9179, F1 Macro: 0.902\n",
      "Epoch 10/10, Train Loss: 0.0883, Accuracy: 0.9179, F1 Micro: 0.9179, F1 Macro: 0.908\n",
      "\n",
      "Sentiment analysis accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.9275\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.95      0.90        82\n",
      "    positive       0.98      0.93      0.95       186\n",
      "\n",
      "    accuracy                           0.94       268\n",
      "   macro avg       0.92      0.94      0.93       268\n",
      "weighted avg       0.94      0.94      0.94       268\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 518: Accuracy: 0.9491, F1 Micro: 0.9491, F1 Macro: 0.9061\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.82      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.90      0.93      0.92       152\n",
      "    positive       0.81      0.75      0.78        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.85      0.81      0.83       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.96      0.81        23\n",
      "     neutral       0.98      0.95      0.96       152\n",
      "    positive       0.89      0.83      0.86        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.86      0.91      0.88       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.71      0.83        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.98      0.90      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 109.9073703289032 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0036260992288589477\n",
      "Acquired samples: 22\n",
      "Sampling duration: 8.820141315460205 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5462, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4605, Accuracy: 0.8557, F1 Micro: 0.9159, F1 Macro: 0.9155\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3511, Accuracy: 0.9211, F1 Micro: 0.9513, F1 Macro: 0.949\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.262, Accuracy: 0.9323, F1 Micro: 0.9578, F1 Macro: 0.9554\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.195, Accuracy: 0.9524, F1 Micro: 0.9702, F1 Macro: 0.9687\n",
      "Epoch 6/10, Train Loss: 0.1543, Accuracy: 0.9516, F1 Micro: 0.9696, F1 Macro: 0.9677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1274, Accuracy: 0.9546, F1 Micro: 0.9716, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0977, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9714\n",
      "Epoch 9/10, Train Loss: 0.0836, Accuracy: 0.9531, F1 Micro: 0.9705, F1 Macro: 0.9683\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.069, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9725\n",
      "\n",
      "Aspect detection accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9725\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.94      0.92      0.93       158\n",
      "        part       0.96      0.97      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5557, Accuracy: 0.711, F1 Micro: 0.711, F1 Macro: 0.5378\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3117, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9151\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.175, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9276\n",
      "Epoch 4/10, Train Loss: 0.1469, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.9002\n",
      "Epoch 5/10, Train Loss: 0.1628, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.9076\n",
      "Epoch 6/10, Train Loss: 0.1694, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9236\n",
      "Epoch 7/10, Train Loss: 0.1159, Accuracy: 0.9278, F1 Micro: 0.9278, F1 Macro: 0.9186\n",
      "Epoch 8/10, Train Loss: 0.1042, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9231\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.078, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9317\n",
      "Epoch 10/10, Train Loss: 0.0795, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9236\n",
      "\n",
      "Sentiment analysis accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9317\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.95      0.91        84\n",
      "    positive       0.98      0.93      0.95       179\n",
      "\n",
      "    accuracy                           0.94       263\n",
      "   macro avg       0.92      0.94      0.93       263\n",
      "weighted avg       0.94      0.94      0.94       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.9104\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.86      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.92      0.85        12\n",
      "     neutral       0.94      0.92      0.93       152\n",
      "    positive       0.79      0.81      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.84      0.88      0.86       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.96      0.86        23\n",
      "     neutral       0.96      0.97      0.96       152\n",
      "    positive       0.91      0.78      0.84        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.90      0.89       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.86      0.71      0.77        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.93      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 115.35070395469666 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.0033403500448912385\n",
      "Acquired samples: 33\n",
      "Sampling duration: 8.434500694274902 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5467, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.459, Accuracy: 0.8638, F1 Micro: 0.9203, F1 Macro: 0.9199\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3434, Accuracy: 0.9249, F1 Micro: 0.9531, F1 Macro: 0.9505\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2357, Accuracy: 0.9487, F1 Micro: 0.9681, F1 Macro: 0.9664\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1881, Accuracy: 0.9554, F1 Micro: 0.972, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1335, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9728\n",
      "Epoch 7/10, Train Loss: 0.1104, Accuracy: 0.9539, F1 Micro: 0.9708, F1 Macro: 0.9683\n",
      "Epoch 8/10, Train Loss: 0.0886, Accuracy: 0.9576, F1 Micro: 0.9732, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0736, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0634, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9745\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9745\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.93      0.95      0.94       158\n",
      "        part       0.97      0.97      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5471, Accuracy: 0.8353, F1 Micro: 0.8353, F1 Macro: 0.8113\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.314, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.921\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.17, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9206\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1599, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9324\n",
      "Epoch 5/10, Train Loss: 0.1197, Accuracy: 0.9059, F1 Micro: 0.9059, F1 Macro: 0.898\n",
      "Epoch 6/10, Train Loss: 0.111, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9306\n",
      "Epoch 7/10, Train Loss: 0.1169, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9286\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0878, Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9464\n",
      "Epoch 9/10, Train Loss: 0.092, Accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.9425\n",
      "Epoch 10/10, Train Loss: 0.0753, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9175\n",
      "\n",
      "Sentiment analysis accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9464\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.94      0.93        82\n",
      "    positive       0.97      0.96      0.97       173\n",
      "\n",
      "    accuracy                           0.95       255\n",
      "   macro avg       0.94      0.95      0.95       255\n",
      "weighted avg       0.95      0.95      0.95       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9132\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.84      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.93      0.95      0.94       152\n",
      "    positive       0.84      0.81      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.89      0.86      0.88       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.92      0.91       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.89      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.71      0.83        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.98      0.90      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 120.76085424423218 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.002320724120363593\n",
      "Acquired samples: 30\n",
      "Sampling duration: 7.7296929359436035 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5589, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4472, Accuracy: 0.869, F1 Micro: 0.923, F1 Macro: 0.9225\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3276, Accuracy: 0.9293, F1 Micro: 0.956, F1 Macro: 0.9535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2302, Accuracy: 0.9457, F1 Micro: 0.966, F1 Macro: 0.9637\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1769, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1304, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1062, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0861, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0699, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9752\n",
      "Epoch 10/10, Train Loss: 0.0623, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.973\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9752\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.91      0.95      0.93       158\n",
      "        part       0.98      0.96      0.97       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5767, Accuracy: 0.8405, F1 Micro: 0.8405, F1 Macro: 0.8031\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3212, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9152\n",
      "Epoch 3/10, Train Loss: 0.2081, Accuracy: 0.9105, F1 Micro: 0.9105, F1 Macro: 0.9024\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1508, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9135\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1188, Accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9385\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1172, Accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9388\n",
      "Epoch 7/10, Train Loss: 0.0836, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9264\n",
      "Epoch 8/10, Train Loss: 0.095, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9305\n",
      "Epoch 9/10, Train Loss: 0.0652, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9181\n",
      "Epoch 10/10, Train Loss: 0.0734, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9181\n",
      "\n",
      "Sentiment analysis accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9388\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        82\n",
      "    positive       0.98      0.94      0.96       175\n",
      "\n",
      "    accuracy                           0.95       257\n",
      "   macro avg       0.93      0.95      0.94       257\n",
      "weighted avg       0.95      0.95      0.95       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9192\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.86      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.92      0.95      0.93       152\n",
      "    positive       0.83      0.77      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.86      0.82      0.84       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      1.00      0.85        23\n",
      "     neutral       0.98      0.96      0.97       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.93      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.93      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 125.57401323318481 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.0033016569213941693\n",
      "Acquired samples: 27\n",
      "Sampling duration: 7.013679504394531 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5486, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4376, Accuracy: 0.8676, F1 Micro: 0.9218, F1 Macro: 0.9209\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3132, Accuracy: 0.9286, F1 Micro: 0.9554, F1 Macro: 0.9522\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2209, Accuracy: 0.9509, F1 Micro: 0.9695, F1 Macro: 0.9678\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1667, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9718\n",
      "Epoch 6/10, Train Loss: 0.1298, Accuracy: 0.9576, F1 Micro: 0.9732, F1 Macro: 0.9708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1028, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9751\n",
      "Epoch 8/10, Train Loss: 0.0849, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0731, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9753\n",
      "Epoch 10/10, Train Loss: 0.0618, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9742\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9753\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.92      0.92      0.92       158\n",
      "        part       0.96      0.99      0.97       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5596, Accuracy: 0.8859, F1 Micro: 0.8859, F1 Macro: 0.8719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2485, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9354\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1856, Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9412\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1665, Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9399\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.142, Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9402\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1036, Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9412\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0863, Accuracy: 0.9544, F1 Micro: 0.9544, F1 Macro: 0.9485\n",
      "Epoch 8/10, Train Loss: 0.0775, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9259\n",
      "Epoch 9/10, Train Loss: 0.0721, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9372\n",
      "Epoch 10/10, Train Loss: 0.0717, Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9409\n",
      "\n",
      "Sentiment analysis accuracy: 0.9544, F1 Micro: 0.9544, F1 Macro: 0.9485\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        87\n",
      "    positive       0.97      0.97      0.97       176\n",
      "\n",
      "    accuracy                           0.95       263\n",
      "   macro avg       0.95      0.95      0.95       263\n",
      "weighted avg       0.95      0.95      0.95       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9258\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.82      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.87      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        12\n",
      "     neutral       0.93      0.92      0.92       152\n",
      "    positive       0.77      0.79      0.78        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.87      0.88      0.87       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.96      0.99      0.97       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.92      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 129.4052062034607 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.0030665238853543994\n",
      "Acquired samples: 18\n",
      "Sampling duration: 6.376741170883179 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5542, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4314, Accuracy: 0.9159, F1 Micro: 0.9486, F1 Macro: 0.9467\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2948, Accuracy: 0.9353, F1 Micro: 0.9596, F1 Macro: 0.9569\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2119, Accuracy: 0.9568, F1 Micro: 0.9732, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1571, Accuracy: 0.9643, F1 Micro: 0.9777, F1 Macro: 0.9766\n",
      "Epoch 6/10, Train Loss: 0.1152, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9763\n",
      "Epoch 7/10, Train Loss: 0.0955, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9736\n",
      "Epoch 8/10, Train Loss: 0.0788, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9746\n",
      "Epoch 9/10, Train Loss: 0.0646, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0543, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9796\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9796\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.99      0.98       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.97      0.98      0.97       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5503, Accuracy: 0.8953, F1 Micro: 0.8953, F1 Macro: 0.8845\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.239, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.931\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1513, Accuracy: 0.9457, F1 Micro: 0.9457, F1 Macro: 0.9393\n",
      "Epoch 4/10, Train Loss: 0.143, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9257\n",
      "Epoch 5/10, Train Loss: 0.1078, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9302\n",
      "Epoch 6/10, Train Loss: 0.1026, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.9236\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0845, Accuracy: 0.9535, F1 Micro: 0.9535, F1 Macro: 0.9483\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0865, Accuracy: 0.9535, F1 Micro: 0.9535, F1 Macro: 0.948\n",
      "Epoch 9/10, Train Loss: 0.0629, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.928\n",
      "Epoch 10/10, Train Loss: 0.0467, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9348\n",
      "\n",
      "Sentiment analysis accuracy: 0.9535, F1 Micro: 0.9535, F1 Macro: 0.948\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.94      0.93        86\n",
      "    positive       0.97      0.96      0.96       172\n",
      "\n",
      "    accuracy                           0.95       258\n",
      "   macro avg       0.95      0.95      0.95       258\n",
      "weighted avg       0.95      0.95      0.95       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9622, F1 Micro: 0.9622, F1 Macro: 0.9271\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.99      0.98       167\n",
      "    positive       0.90      0.82      0.86        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.89      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.75      0.86        12\n",
      "     neutral       0.92      0.96      0.94       152\n",
      "    positive       0.85      0.79      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.92      0.83      0.87       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.98      0.97       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 125.60332226753235 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.0023111365269869568\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.979887962341309 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5343, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4149, Accuracy: 0.9159, F1 Micro: 0.9486, F1 Macro: 0.9469\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2868, Accuracy: 0.9494, F1 Micro: 0.9687, F1 Macro: 0.9672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1983, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1406, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1139, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.977\n",
      "Epoch 7/10, Train Loss: 0.0876, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9741\n",
      "Epoch 8/10, Train Loss: 0.0711, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9756\n",
      "Epoch 9/10, Train Loss: 0.0565, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.052, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.91      0.95      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5383, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.901\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.258, Accuracy: 0.9255, F1 Micro: 0.9255, F1 Macro: 0.9194\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1889, Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9477\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1433, Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9474\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1167, Accuracy: 0.9608, F1 Micro: 0.9608, F1 Macro: 0.9561\n",
      "Epoch 6/10, Train Loss: 0.0973, Accuracy: 0.9569, F1 Micro: 0.9569, F1 Macro: 0.9519\n",
      "Epoch 7/10, Train Loss: 0.0971, Accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.9421\n",
      "Epoch 8/10, Train Loss: 0.102, Accuracy: 0.9569, F1 Micro: 0.9569, F1 Macro: 0.9513\n",
      "Epoch 9/10, Train Loss: 0.0585, Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9471\n",
      "Epoch 10/10, Train Loss: 0.0694, Accuracy: 0.9569, F1 Micro: 0.9569, F1 Macro: 0.9522\n",
      "\n",
      "Sentiment analysis accuracy: 0.9608, F1 Micro: 0.9608, F1 Macro: 0.9561\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.95      0.94        85\n",
      "    positive       0.98      0.96      0.97       170\n",
      "\n",
      "    accuracy                           0.96       255\n",
      "   macro avg       0.95      0.96      0.96       255\n",
      "weighted avg       0.96      0.96      0.96       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9258\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.89      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.92      0.95      0.93       152\n",
      "    positive       0.83      0.77      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.86      0.82      0.84       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.83      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.95      0.94      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.97      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.97      0.87      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 130.80575585365295 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.003250432340428233\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.5060341358184814 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5326, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4065, Accuracy: 0.91, F1 Micro: 0.9447, F1 Macro: 0.9429\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2836, Accuracy: 0.9494, F1 Micro: 0.9687, F1 Macro: 0.9675\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1989, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9737\n",
      "Epoch 5/10, Train Loss: 0.1445, Accuracy: 0.9531, F1 Micro: 0.9704, F1 Macro: 0.9672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1151, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0876, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9784\n",
      "Epoch 8/10, Train Loss: 0.0731, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9746\n",
      "Epoch 9/10, Train Loss: 0.0648, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9777\n",
      "Epoch 10/10, Train Loss: 0.0556, Accuracy: 0.968, F1 Micro: 0.9797, F1 Macro: 0.9781\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9784\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.95      0.92      0.94       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5005, Accuracy: 0.9026, F1 Micro: 0.9026, F1 Macro: 0.8933\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2231, Accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.9097\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1606, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.925\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1305, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9258\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.128, Accuracy: 0.9401, F1 Micro: 0.9401, F1 Macro: 0.933\n",
      "Epoch 6/10, Train Loss: 0.0968, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9113\n",
      "Epoch 7/10, Train Loss: 0.0927, Accuracy: 0.9288, F1 Micro: 0.9288, F1 Macro: 0.9206\n",
      "Epoch 8/10, Train Loss: 0.0542, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.925\n",
      "Epoch 9/10, Train Loss: 0.0557, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9246\n",
      "Epoch 10/10, Train Loss: 0.0623, Accuracy: 0.9251, F1 Micro: 0.9251, F1 Macro: 0.9166\n",
      "\n",
      "Sentiment analysis accuracy: 0.9401, F1 Micro: 0.9401, F1 Macro: 0.933\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.94      0.91        87\n",
      "    positive       0.97      0.94      0.95       180\n",
      "\n",
      "    accuracy                           0.94       267\n",
      "   macro avg       0.93      0.94      0.93       267\n",
      "weighted avg       0.94      0.94      0.94       267\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9238\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.99      0.97       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.88      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.92      0.81        12\n",
      "     neutral       0.95      0.93      0.94       152\n",
      "    positive       0.81      0.83      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.83      0.89      0.86       216\n",
      "weighted avg       0.91      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.90      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 131.35335612297058 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.0025154244620352985\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.79081654548645 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5318, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4141, Accuracy: 0.9189, F1 Micro: 0.9503, F1 Macro: 0.9486\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2685, Accuracy: 0.9487, F1 Micro: 0.9681, F1 Macro: 0.9669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1848, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1448, Accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9776\n",
      "Epoch 6/10, Train Loss: 0.1161, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0864, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9779\n",
      "Epoch 8/10, Train Loss: 0.073, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9755\n",
      "Epoch 9/10, Train Loss: 0.06, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9738\n",
      "Epoch 10/10, Train Loss: 0.0519, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9773\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9779\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4987, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.9027\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2688, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9385\n",
      "Epoch 3/10, Train Loss: 0.1803, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9246\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1592, Accuracy: 0.9488, F1 Micro: 0.9488, F1 Macro: 0.9424\n",
      "Epoch 5/10, Train Loss: 0.1283, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9297\n",
      "Epoch 6/10, Train Loss: 0.1307, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9232\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0961, Accuracy: 0.9488, F1 Micro: 0.9488, F1 Macro: 0.9427\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0887, Accuracy: 0.9567, F1 Micro: 0.9567, F1 Macro: 0.9515\n",
      "Epoch 9/10, Train Loss: 0.087, Accuracy: 0.9488, F1 Micro: 0.9488, F1 Macro: 0.942\n",
      "Epoch 10/10, Train Loss: 0.0718, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9251\n",
      "\n",
      "Sentiment analysis accuracy: 0.9567, F1 Micro: 0.9567, F1 Macro: 0.9515\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.95      0.94        84\n",
      "    positive       0.98      0.96      0.97       170\n",
      "\n",
      "    accuracy                           0.96       254\n",
      "   macro avg       0.95      0.96      0.95       254\n",
      "weighted avg       0.96      0.96      0.96       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9231\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.84      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.83      0.77      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.86      0.82      0.84       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.89      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 131.51704931259155 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.0020570639055222275\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.306429862976074 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5332, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4077, Accuracy: 0.9182, F1 Micro: 0.949, F1 Macro: 0.9458\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2632, Accuracy: 0.9561, F1 Micro: 0.9727, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1905, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1343, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9769\n",
      "Epoch 6/10, Train Loss: 0.1058, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9745\n",
      "Epoch 7/10, Train Loss: 0.0869, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0698, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9776\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0578, Accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9802\n",
      "Epoch 10/10, Train Loss: 0.0486, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9795\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9802\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.96      0.95       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.537, Accuracy: 0.9035, F1 Micro: 0.9035, F1 Macro: 0.8938\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2428, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9238\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1431, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9404\n",
      "Epoch 4/10, Train Loss: 0.1234, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9244\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0866, Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9486\n",
      "Epoch 6/10, Train Loss: 0.0908, Accuracy: 0.9189, F1 Micro: 0.9189, F1 Macro: 0.9121\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0909, Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9484\n",
      "Epoch 8/10, Train Loss: 0.0948, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9319\n",
      "Epoch 9/10, Train Loss: 0.072, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9304\n",
      "Epoch 10/10, Train Loss: 0.0599, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.9063\n",
      "\n",
      "Sentiment analysis accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9484\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93        86\n",
      "    positive       0.98      0.95      0.96       173\n",
      "\n",
      "    accuracy                           0.95       259\n",
      "   macro avg       0.94      0.95      0.95       259\n",
      "weighted avg       0.95      0.95      0.95       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.963, F1 Micro: 0.963, F1 Macro: 0.9298\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.86      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.94      0.96      0.95       152\n",
      "    positive       0.85      0.79      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.87      0.86      0.87       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.83      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.95      0.94      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 137.13217163085938 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.002039209147915244\n",
      "Acquired samples: 8\n",
      "Sampling duration: 3.6132304668426514 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5272, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4003, Accuracy: 0.9196, F1 Micro: 0.9499, F1 Macro: 0.9469\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2695, Accuracy: 0.9531, F1 Micro: 0.9709, F1 Macro: 0.9695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1813, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1377, Accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9775\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1053, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.979\n",
      "Epoch 7/10, Train Loss: 0.0846, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.976\n",
      "Epoch 8/10, Train Loss: 0.0668, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9783\n",
      "Epoch 9/10, Train Loss: 0.0529, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0481, Accuracy: 0.971, F1 Micro: 0.9817, F1 Macro: 0.9805\n",
      "\n",
      "Aspect detection accuracy: 0.971, F1 Micro: 0.9817, F1 Macro: 0.9805\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.95      0.94      0.95       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5093, Accuracy: 0.8914, F1 Micro: 0.8914, F1 Macro: 0.8813\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2419, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.93\n",
      "Epoch 3/10, Train Loss: 0.1849, Accuracy: 0.9101, F1 Micro: 0.9101, F1 Macro: 0.8958\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1431, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9293\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1002, Accuracy: 0.9401, F1 Micro: 0.9401, F1 Macro: 0.9337\n",
      "Epoch 6/10, Train Loss: 0.0955, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9254\n",
      "Epoch 7/10, Train Loss: 0.076, Accuracy: 0.9251, F1 Micro: 0.9251, F1 Macro: 0.9183\n",
      "Epoch 8/10, Train Loss: 0.0795, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9293\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.053, Accuracy: 0.9401, F1 Micro: 0.9401, F1 Macro: 0.9314\n",
      "Epoch 10/10, Train Loss: 0.0585, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9258\n",
      "\n",
      "Sentiment analysis accuracy: 0.9401, F1 Micro: 0.9401, F1 Macro: 0.9314\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.89      0.91        88\n",
      "    positive       0.95      0.97      0.96       179\n",
      "\n",
      "    accuracy                           0.94       267\n",
      "   macro avg       0.94      0.93      0.93       267\n",
      "weighted avg       0.94      0.94      0.94       267\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9614, F1 Micro: 0.9614, F1 Macro: 0.9191\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.96      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.82      0.82      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.85      0.86       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        12\n",
      "     neutral       0.95      0.95      0.95       152\n",
      "    positive       0.83      0.87      0.85        52\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.83      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.95      0.94      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.86      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 136.85037183761597 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0029356244951486594\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.5868186950683594 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5199, Accuracy: 0.8028, F1 Micro: 0.889, F1 Macro: 0.8877\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3812, Accuracy: 0.9219, F1 Micro: 0.9513, F1 Macro: 0.9487\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2594, Accuracy: 0.9516, F1 Micro: 0.97, F1 Macro: 0.9686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1722, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9746\n",
      "Epoch 5/10, Train Loss: 0.1319, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1007, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9792\n",
      "Epoch 7/10, Train Loss: 0.0797, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0609, Accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9802\n",
      "Epoch 9/10, Train Loss: 0.0544, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9785\n",
      "Epoch 10/10, Train Loss: 0.0455, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9788\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9802\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.97      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5105, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.902\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1916, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9252\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1685, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9358\n",
      "Epoch 4/10, Train Loss: 0.133, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9294\n",
      "Epoch 5/10, Train Loss: 0.1359, Accuracy: 0.9255, F1 Micro: 0.9255, F1 Macro: 0.919\n",
      "Epoch 6/10, Train Loss: 0.0775, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9276\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0883, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9389\n",
      "Epoch 8/10, Train Loss: 0.0519, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9231\n",
      "Epoch 9/10, Train Loss: 0.058, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9298\n",
      "Epoch 10/10, Train Loss: 0.0433, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9351\n",
      "\n",
      "Sentiment analysis accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9389\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        85\n",
      "    positive       0.97      0.95      0.96       170\n",
      "\n",
      "    accuracy                           0.95       255\n",
      "   macro avg       0.93      0.94      0.94       255\n",
      "weighted avg       0.95      0.95      0.95       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9614, F1 Micro: 0.9614, F1 Macro: 0.9198\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.97      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.92      0.97      0.94       152\n",
      "    positive       0.89      0.75      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.85      0.82      0.83       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.83      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.95      0.94      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.89      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 133.90813422203064 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.00275310087017715\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.904665946960449 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5199, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3847, Accuracy: 0.9256, F1 Micro: 0.9537, F1 Macro: 0.951\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2499, Accuracy: 0.9561, F1 Micro: 0.9727, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.171, Accuracy: 0.9628, F1 Micro: 0.9768, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1245, Accuracy: 0.968, F1 Micro: 0.98, F1 Macro: 0.979\n",
      "Epoch 6/10, Train Loss: 0.0977, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9738\n",
      "Epoch 7/10, Train Loss: 0.0753, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9785\n",
      "Epoch 8/10, Train Loss: 0.0641, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.978\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.054, Accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9793\n",
      "Epoch 10/10, Train Loss: 0.0435, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9784\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.97      0.97       175\n",
      "      others       0.94      0.93      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4893, Accuracy: 0.8897, F1 Micro: 0.8897, F1 Macro: 0.8787\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1852, Accuracy: 0.9338, F1 Micro: 0.9338, F1 Macro: 0.9268\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1769, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9307\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1414, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9376\n",
      "Epoch 5/10, Train Loss: 0.1137, Accuracy: 0.9301, F1 Micro: 0.9301, F1 Macro: 0.923\n",
      "Epoch 6/10, Train Loss: 0.083, Accuracy: 0.9301, F1 Micro: 0.9301, F1 Macro: 0.9185\n",
      "Epoch 7/10, Train Loss: 0.081, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9149\n",
      "Epoch 8/10, Train Loss: 0.083, Accuracy: 0.9338, F1 Micro: 0.9338, F1 Macro: 0.9253\n",
      "Epoch 9/10, Train Loss: 0.0376, Accuracy: 0.9265, F1 Micro: 0.9265, F1 Macro: 0.9127\n",
      "Epoch 10/10, Train Loss: 0.0403, Accuracy: 0.9191, F1 Micro: 0.9191, F1 Macro: 0.9081\n",
      "\n",
      "Sentiment analysis accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9376\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.93      0.92        88\n",
      "    positive       0.97      0.95      0.96       184\n",
      "\n",
      "    accuracy                           0.94       272\n",
      "   macro avg       0.93      0.94      0.94       272\n",
      "weighted avg       0.95      0.94      0.95       272\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.925\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.97      0.97      0.97       167\n",
      "    positive       0.85      0.85      0.85        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.90      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.92      0.85        12\n",
      "     neutral       0.94      0.93      0.93       152\n",
      "    positive       0.79      0.79      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.84      0.88      0.86       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.88      0.92        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.95      0.95       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.89      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 138.12401700019836 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0021311200223863127\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.2951102256774902 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5231, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3825, Accuracy: 0.9204, F1 Micro: 0.9507, F1 Macro: 0.9485\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.246, Accuracy: 0.9546, F1 Micro: 0.9719, F1 Macro: 0.9707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1688, Accuracy: 0.9628, F1 Micro: 0.9768, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1303, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.976\n",
      "Epoch 6/10, Train Loss: 0.0995, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0835, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9768\n",
      "Epoch 8/10, Train Loss: 0.066, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0518, Accuracy: 0.971, F1 Micro: 0.9818, F1 Macro: 0.9806\n",
      "Epoch 10/10, Train Loss: 0.0461, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9776\n",
      "\n",
      "Aspect detection accuracy: 0.971, F1 Micro: 0.9818, F1 Macro: 0.9806\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.93      0.97      0.95       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4967, Accuracy: 0.9038, F1 Micro: 0.9038, F1 Macro: 0.897\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2628, Accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.9055\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1908, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9371\n",
      "Epoch 4/10, Train Loss: 0.1549, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.925\n",
      "Epoch 5/10, Train Loss: 0.1032, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9213\n",
      "Epoch 6/10, Train Loss: 0.0814, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.932\n",
      "Epoch 7/10, Train Loss: 0.0961, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9247\n",
      "Epoch 8/10, Train Loss: 0.0723, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.9025\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0671, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9343\n",
      "Epoch 10/10, Train Loss: 0.055, Accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.9119\n",
      "\n",
      "Sentiment analysis accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9343\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.89      0.91        87\n",
      "    positive       0.94      0.97      0.96       173\n",
      "\n",
      "    accuracy                           0.94       260\n",
      "   macro avg       0.94      0.93      0.93       260\n",
      "weighted avg       0.94      0.94      0.94       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9614, F1 Micro: 0.9614, F1 Macro: 0.9202\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.96      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.89      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.89      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.93      0.97      0.95       152\n",
      "    positive       0.87      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.88      0.86      0.87       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.91      0.93        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.92      0.88      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 146.3695569038391 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0022163694258779286\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.801619291305542 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5183, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3607, Accuracy: 0.933, F1 Micro: 0.9586, F1 Macro: 0.9567\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.236, Accuracy: 0.9561, F1 Micro: 0.9727, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1737, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9774\n",
      "Epoch 5/10, Train Loss: 0.114, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0966, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9768\n",
      "Epoch 7/10, Train Loss: 0.0716, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9754\n",
      "Epoch 8/10, Train Loss: 0.0588, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.975\n",
      "Epoch 9/10, Train Loss: 0.0533, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.977\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.046, Accuracy: 0.971, F1 Micro: 0.9818, F1 Macro: 0.9807\n",
      "\n",
      "Aspect detection accuracy: 0.971, F1 Micro: 0.9818, F1 Macro: 0.9807\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.97      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4889, Accuracy: 0.8984, F1 Micro: 0.8984, F1 Macro: 0.8897\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.218, Accuracy: 0.9102, F1 Micro: 0.9102, F1 Macro: 0.904\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.165, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9311\n",
      "Epoch 4/10, Train Loss: 0.1577, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9262\n",
      "Epoch 5/10, Train Loss: 0.1189, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9258\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1012, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9387\n",
      "Epoch 7/10, Train Loss: 0.0987, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9318\n",
      "Epoch 8/10, Train Loss: 0.0862, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9352\n",
      "Epoch 9/10, Train Loss: 0.054, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.927\n",
      "Epoch 10/10, Train Loss: 0.043, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9315\n",
      "\n",
      "Sentiment analysis accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9387\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        86\n",
      "    positive       0.96      0.96      0.96       170\n",
      "\n",
      "    accuracy                           0.95       256\n",
      "   macro avg       0.94      0.94      0.94       256\n",
      "weighted avg       0.95      0.95      0.95       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9622, F1 Micro: 0.9622, F1 Macro: 0.9233\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.96      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.86      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.92      0.97      0.94       152\n",
      "    positive       0.87      0.75      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.87      0.82      0.84       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.85      0.92        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.95      0.95       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 144.751638174057 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0017865214496850968\n",
      "Acquired samples: 8\n",
      "Sampling duration: 1.1082508563995361 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5173, Accuracy: 0.7954, F1 Micro: 0.8853, F1 Macro: 0.8838\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.364, Accuracy: 0.9144, F1 Micro: 0.9462, F1 Macro: 0.9429\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2451, Accuracy: 0.9554, F1 Micro: 0.9722, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1691, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.123, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9766\n",
      "Epoch 6/10, Train Loss: 0.0946, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0709, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "Epoch 8/10, Train Loss: 0.0592, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.975\n",
      "Epoch 9/10, Train Loss: 0.0514, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0445, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9772\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9772\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.97      0.97       175\n",
      "      others       0.94      0.92      0.93       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.97      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5259, Accuracy: 0.8832, F1 Micro: 0.8832, F1 Macro: 0.8691\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2302, Accuracy: 0.9526, F1 Micro: 0.9526, F1 Macro: 0.9458\n",
      "Epoch 3/10, Train Loss: 0.1799, Accuracy: 0.9343, F1 Micro: 0.9343, F1 Macro: 0.926\n",
      "Epoch 4/10, Train Loss: 0.1515, Accuracy: 0.9307, F1 Micro: 0.9307, F1 Macro: 0.9212\n",
      "Epoch 5/10, Train Loss: 0.1308, Accuracy: 0.9161, F1 Micro: 0.9161, F1 Macro: 0.9076\n",
      "Epoch 6/10, Train Loss: 0.1084, Accuracy: 0.9307, F1 Micro: 0.9307, F1 Macro: 0.9202\n",
      "Epoch 7/10, Train Loss: 0.1023, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9286\n",
      "Epoch 8/10, Train Loss: 0.0603, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9291\n",
      "Epoch 9/10, Train Loss: 0.0805, Accuracy: 0.9343, F1 Micro: 0.9343, F1 Macro: 0.9217\n",
      "Epoch 10/10, Train Loss: 0.0759, Accuracy: 0.9343, F1 Micro: 0.9343, F1 Macro: 0.9268\n",
      "\n",
      "Sentiment analysis accuracy: 0.9526, F1 Micro: 0.9526, F1 Macro: 0.9458\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.94      0.93        87\n",
      "    positive       0.97      0.96      0.96       187\n",
      "\n",
      "    accuracy                           0.95       274\n",
      "   macro avg       0.94      0.95      0.95       274\n",
      "weighted avg       0.95      0.95      0.95       274\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.928\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.97      0.97       167\n",
      "    positive       0.82      0.82      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.95      0.91      0.93       152\n",
      "    positive       0.77      0.85      0.81        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.85      0.86      0.86       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.95      0.88      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 143.17401814460754 s\n",
      "Total runtime: 3149.3645277023315 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd220c05",
   "metadata": {
    "papermill": {
     "duration": 0.011123,
     "end_time": "2025-03-26T09:39:20.367830",
     "exception": false,
     "start_time": "2025-03-26T09:39:20.356707",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "341e9605",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T09:39:20.428289Z",
     "iopub.status.busy": "2025-03-26T09:39:20.428019Z",
     "iopub.status.idle": "2025-03-26T10:31:01.927414Z",
     "shell.execute_reply": "2025-03-26T10:31:01.926402Z"
    },
    "papermill": {
     "duration": 3101.550071,
     "end_time": "2025-03-26T10:31:01.929124",
     "exception": false,
     "start_time": "2025-03-26T09:39:20.379053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 3\n",
      "Random seed: 14\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6791, Accuracy: 0.7746, F1 Micro: 0.8722, F1 Macro: 0.8703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5752, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.512, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4609, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4635, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4127, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3898, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4151, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.396, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3746, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "\n",
      "Aspect detection accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.78      1.00      0.88       175\n",
      "      others       0.71      1.00      0.83       158\n",
      "        part       0.71      1.00      0.83       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.79      1.00      0.88      1061\n",
      "   macro avg       0.79      1.00      0.88      1061\n",
      "weighted avg       0.80      1.00      0.89      1061\n",
      " samples avg       0.79      1.00      0.88      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.8159, Accuracy: 0.3333, F1 Micro: 0.3333, F1 Macro: 0.25\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.6264, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5442, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5154, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4038, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3617, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3192, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2942, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3391, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2952, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "\n",
      "Sentiment analysis accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         1\n",
      "    positive       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.67         3\n",
      "   macro avg       0.33      0.50      0.40         3\n",
      "weighted avg       0.44      0.67      0.53         3\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.7909, F1 Micro: 0.7909, F1 Macro: 0.298\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.77      1.00      0.87       167\n",
      "    positive       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.77       216\n",
      "   macro avg       0.26      0.33      0.29       216\n",
      "weighted avg       0.60      0.77      0.67       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.71      1.00      0.83       152\n",
      "    positive       0.67      0.04      0.07        52\n",
      "\n",
      "    accuracy                           0.71       216\n",
      "   macro avg       0.46      0.35      0.30       216\n",
      "weighted avg       0.66      0.71      0.60       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        23\n",
      "     neutral       0.70      1.00      0.83       152\n",
      "    positive       0.00      0.00      0.00        41\n",
      "\n",
      "    accuracy                           0.70       216\n",
      "   macro avg       0.23      0.33      0.28       216\n",
      "weighted avg       0.50      0.70      0.58       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 64.32427954673767 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.004887192044407129\n",
      "Acquired samples: 82\n",
      "Sampling duration: 12.159208536148071 seconds\n",
      "New train size: 136\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.624, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4937, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.491, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4548, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4271, Accuracy: 0.7961, F1 Micro: 0.8855, F1 Macro: 0.8841\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3768, Accuracy: 0.8028, F1 Micro: 0.8883, F1 Macro: 0.8868\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3466, Accuracy: 0.8445, F1 Micro: 0.9092, F1 Macro: 0.9077\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2986, Accuracy: 0.8683, F1 Micro: 0.9219, F1 Macro: 0.9202\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2597, Accuracy: 0.8847, F1 Micro: 0.9305, F1 Macro: 0.9286\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2144, Accuracy: 0.904, F1 Micro: 0.9418, F1 Macro: 0.9401\n",
      "\n",
      "Aspect detection accuracy: 0.904, F1 Micro: 0.9418, F1 Macro: 0.9401\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.92      0.94      0.93       175\n",
      "      others       0.84      0.97      0.90       158\n",
      "        part       0.81      0.99      0.89       158\n",
      "       price       0.95      0.99      0.97       192\n",
      "     service       0.92      1.00      0.96       191\n",
      "\n",
      "   micro avg       0.90      0.98      0.94      1061\n",
      "   macro avg       0.90      0.98      0.94      1061\n",
      "weighted avg       0.91      0.98      0.94      1061\n",
      " samples avg       0.91      0.98      0.94      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.665, Accuracy: 0.676, F1 Micro: 0.676, F1 Macro: 0.4033\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.6114, Accuracy: 0.6927, F1 Micro: 0.6927, F1 Macro: 0.4566\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.561, Accuracy: 0.7207, F1 Micro: 0.7207, F1 Macro: 0.5654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5134, Accuracy: 0.8212, F1 Micro: 0.8212, F1 Macro: 0.7625\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4102, Accuracy: 0.8883, F1 Micro: 0.8883, F1 Macro: 0.8688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3159, Accuracy: 0.8939, F1 Micro: 0.8939, F1 Macro: 0.8734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2019, Accuracy: 0.905, F1 Micro: 0.905, F1 Macro: 0.889\n",
      "Epoch 8/10, Train Loss: 0.1706, Accuracy: 0.8994, F1 Micro: 0.8994, F1 Macro: 0.8831\n",
      "Epoch 9/10, Train Loss: 0.1707, Accuracy: 0.8994, F1 Micro: 0.8994, F1 Macro: 0.8807\n",
      "Epoch 10/10, Train Loss: 0.1205, Accuracy: 0.8827, F1 Micro: 0.8827, F1 Macro: 0.8719\n",
      "\n",
      "Sentiment analysis accuracy: 0.905, F1 Micro: 0.905, F1 Macro: 0.889\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.81      0.85        58\n",
      "    positive       0.91      0.95      0.93       121\n",
      "\n",
      "    accuracy                           0.91       179\n",
      "   macro avg       0.90      0.88      0.89       179\n",
      "weighted avg       0.90      0.91      0.90       179\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 136: Accuracy: 0.892, F1 Micro: 0.892, F1 Macro: 0.7533\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.69      0.81        16\n",
      "     neutral       0.91      0.95      0.93       167\n",
      "    positive       0.68      0.64      0.66        33\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.86      0.76      0.80       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.67      0.67        12\n",
      "     neutral       0.84      0.97      0.90       152\n",
      "    positive       0.85      0.44      0.58        52\n",
      "\n",
      "    accuracy                           0.83       216\n",
      "   macro avg       0.78      0.69      0.72       216\n",
      "weighted avg       0.83      0.83      0.81       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.26      0.39        23\n",
      "     neutral       0.80      0.99      0.88       152\n",
      "    positive       0.86      0.44      0.58        41\n",
      "\n",
      "    accuracy                           0.81       216\n",
      "   macro avg       0.80      0.56      0.62       216\n",
      "weighted avg       0.81      0.81      0.77       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.62      0.76        13\n",
      "     neutral       0.95      0.99      0.97       186\n",
      "    positive       0.57      0.47      0.52        17\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.84      0.69      0.75       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.21      0.35        14\n",
      "     neutral       0.92      1.00      0.96       185\n",
      "    positive       0.82      0.53      0.64        17\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.91      0.58      0.65       216\n",
      "weighted avg       0.91      0.91      0.89       216\n",
      "\n",
      "Total train time: 73.07578015327454 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.012399231269955638\n",
      "Acquired samples: 73\n",
      "Sampling duration: 13.350688695907593 seconds\n",
      "New train size: 209\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6065, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5179, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5036, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4734, Accuracy: 0.8036, F1 Micro: 0.8892, F1 Macro: 0.8876\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4309, Accuracy: 0.8177, F1 Micro: 0.8949, F1 Macro: 0.893\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3432, Accuracy: 0.8542, F1 Micro: 0.9127, F1 Macro: 0.9096\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3135, Accuracy: 0.8936, F1 Micro: 0.935, F1 Macro: 0.9325\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2625, Accuracy: 0.9092, F1 Micro: 0.9444, F1 Macro: 0.9421\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2118, Accuracy: 0.9263, F1 Micro: 0.9544, F1 Macro: 0.952\n",
      "Epoch 10/10, Train Loss: 0.1804, Accuracy: 0.9144, F1 Micro: 0.9469, F1 Macro: 0.9433\n",
      "\n",
      "Aspect detection accuracy: 0.9263, F1 Micro: 0.9544, F1 Macro: 0.952\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.93      0.96      0.94       175\n",
      "      others       0.89      0.90      0.90       158\n",
      "        part       0.87      0.99      0.93       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.95      0.99      0.97       191\n",
      "\n",
      "   micro avg       0.93      0.98      0.95      1061\n",
      "   macro avg       0.93      0.97      0.95      1061\n",
      "weighted avg       0.94      0.98      0.95      1061\n",
      " samples avg       0.94      0.98      0.95      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5792, Accuracy: 0.6947, F1 Micro: 0.6947, F1 Macro: 0.4099\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4216, Accuracy: 0.6947, F1 Micro: 0.6947, F1 Macro: 0.4099\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3337, Accuracy: 0.8451, F1 Micro: 0.8451, F1 Macro: 0.7982\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2261, Accuracy: 0.8982, F1 Micro: 0.8982, F1 Macro: 0.8741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1694, Accuracy: 0.9071, F1 Micro: 0.9071, F1 Macro: 0.8918\n",
      "Epoch 6/10, Train Loss: 0.128, Accuracy: 0.8938, F1 Micro: 0.8938, F1 Macro: 0.8738\n",
      "Epoch 7/10, Train Loss: 0.1296, Accuracy: 0.885, F1 Micro: 0.885, F1 Macro: 0.8569\n",
      "Epoch 8/10, Train Loss: 0.0858, Accuracy: 0.8982, F1 Micro: 0.8982, F1 Macro: 0.8764\n",
      "Epoch 9/10, Train Loss: 0.0916, Accuracy: 0.8938, F1 Micro: 0.8938, F1 Macro: 0.8727\n",
      "Epoch 10/10, Train Loss: 0.0597, Accuracy: 0.885, F1 Micro: 0.885, F1 Macro: 0.8609\n",
      "\n",
      "Sentiment analysis accuracy: 0.9071, F1 Micro: 0.9071, F1 Macro: 0.8918\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.87      0.85        69\n",
      "    positive       0.94      0.92      0.93       157\n",
      "\n",
      "    accuracy                           0.91       226\n",
      "   macro avg       0.89      0.90      0.89       226\n",
      "weighted avg       0.91      0.91      0.91       226\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 209: Accuracy: 0.9128, F1 Micro: 0.9128, F1 Macro: 0.8204\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.69      0.76        16\n",
      "     neutral       0.93      0.96      0.94       167\n",
      "    positive       0.76      0.67      0.71        33\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.84      0.77      0.80       216\n",
      "weighted avg       0.89      0.90      0.89       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.53      0.67      0.59        12\n",
      "     neutral       0.90      0.90      0.90       152\n",
      "    positive       0.71      0.65      0.68        52\n",
      "\n",
      "    accuracy                           0.83       216\n",
      "   macro avg       0.71      0.74      0.72       216\n",
      "weighted avg       0.83      0.83      0.83       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.48      0.61        23\n",
      "     neutral       0.86      0.99      0.92       152\n",
      "    positive       0.86      0.59      0.70        41\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.86      0.69      0.74       216\n",
      "weighted avg       0.86      0.86      0.85       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.69      0.82        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.76      0.76      0.76        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.91      0.82      0.86       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.71      0.80        14\n",
      "     neutral       0.94      0.99      0.97       185\n",
      "    positive       0.90      0.53      0.67        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.75      0.81       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Total train time: 79.56908917427063 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.010192002169787884\n",
      "Acquired samples: 66\n",
      "Sampling duration: 14.067980527877808 seconds\n",
      "New train size: 275\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5964, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4979, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4847, Accuracy: 0.7984, F1 Micro: 0.8867, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4199, Accuracy: 0.8289, F1 Micro: 0.9001, F1 Macro: 0.8979\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.356, Accuracy: 0.8757, F1 Micro: 0.9251, F1 Macro: 0.9223\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2886, Accuracy: 0.9129, F1 Micro: 0.946, F1 Macro: 0.9431\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2408, Accuracy: 0.9278, F1 Micro: 0.9552, F1 Macro: 0.9526\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1896, Accuracy: 0.9368, F1 Micro: 0.9606, F1 Macro: 0.9582\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1536, Accuracy: 0.9412, F1 Micro: 0.9633, F1 Macro: 0.9612\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1284, Accuracy: 0.9427, F1 Micro: 0.9642, F1 Macro: 0.9623\n",
      "\n",
      "Aspect detection accuracy: 0.9427, F1 Micro: 0.9642, F1 Macro: 0.9623\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.96      0.95       175\n",
      "      others       0.88      0.92      0.90       158\n",
      "        part       0.93      0.98      0.96       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.96      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.95      0.98      0.96      1061\n",
      "   macro avg       0.95      0.98      0.96      1061\n",
      "weighted avg       0.95      0.98      0.96      1061\n",
      " samples avg       0.95      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5565, Accuracy: 0.7449, F1 Micro: 0.7449, F1 Macro: 0.6776\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4151, Accuracy: 0.8519, F1 Micro: 0.8519, F1 Macro: 0.8333\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2812, Accuracy: 0.9012, F1 Micro: 0.9012, F1 Macro: 0.8914\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2309, Accuracy: 0.9177, F1 Micro: 0.9177, F1 Macro: 0.908\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1845, Accuracy: 0.9177, F1 Micro: 0.9177, F1 Macro: 0.9043\n",
      "Epoch 6/10, Train Loss: 0.1197, Accuracy: 0.9136, F1 Micro: 0.9136, F1 Macro: 0.9042\n",
      "Epoch 7/10, Train Loss: 0.141, Accuracy: 0.9136, F1 Micro: 0.9136, F1 Macro: 0.9025\n",
      "Epoch 8/10, Train Loss: 0.1598, Accuracy: 0.9053, F1 Micro: 0.9053, F1 Macro: 0.8938\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1302, Accuracy: 0.9177, F1 Micro: 0.9177, F1 Macro: 0.9074\n",
      "Epoch 10/10, Train Loss: 0.1159, Accuracy: 0.893, F1 Micro: 0.893, F1 Macro: 0.8853\n",
      "\n",
      "Sentiment analysis accuracy: 0.9177, F1 Micro: 0.9177, F1 Macro: 0.9074\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.90      0.88        79\n",
      "    positive       0.95      0.93      0.94       164\n",
      "\n",
      "    accuracy                           0.92       243\n",
      "   macro avg       0.90      0.91      0.91       243\n",
      "weighted avg       0.92      0.92      0.92       243\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 275: Accuracy: 0.9306, F1 Micro: 0.9306, F1 Macro: 0.8612\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.88      0.80        16\n",
      "     neutral       0.95      0.96      0.96       167\n",
      "    positive       0.85      0.70      0.77        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.85      0.85      0.84       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.57      0.67      0.62        12\n",
      "     neutral       0.88      0.92      0.90       152\n",
      "    positive       0.74      0.62      0.67        52\n",
      "\n",
      "    accuracy                           0.83       216\n",
      "   macro avg       0.73      0.73      0.73       216\n",
      "weighted avg       0.83      0.83      0.83       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.78      0.86        23\n",
      "     neutral       0.93      0.98      0.96       152\n",
      "    positive       0.86      0.78      0.82        41\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.91      0.85      0.88       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.89      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.71      0.83        14\n",
      "     neutral       0.96      1.00      0.98       185\n",
      "    positive       0.85      0.65      0.73        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.79      0.85       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Total train time: 92.17750644683838 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.007692150212824345\n",
      "Acquired samples: 59\n",
      "Sampling duration: 13.097772359848022 seconds\n",
      "New train size: 334\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5747, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4925, Accuracy: 0.7917, F1 Micro: 0.8833, F1 Macro: 0.8818\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4558, Accuracy: 0.8147, F1 Micro: 0.8935, F1 Macro: 0.8913\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3822, Accuracy: 0.875, F1 Micro: 0.9244, F1 Macro: 0.9218\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3108, Accuracy: 0.9048, F1 Micro: 0.9413, F1 Macro: 0.9381\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2403, Accuracy: 0.936, F1 Micro: 0.9601, F1 Macro: 0.9579\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1859, Accuracy: 0.939, F1 Micro: 0.9619, F1 Macro: 0.9597\n",
      "Epoch 8/10, Train Loss: 0.152, Accuracy: 0.939, F1 Micro: 0.9615, F1 Macro: 0.9581\n",
      "Epoch 9/10, Train Loss: 0.1232, Accuracy: 0.9301, F1 Micro: 0.9558, F1 Macro: 0.9512\n",
      "Epoch 10/10, Train Loss: 0.0984, Accuracy: 0.9345, F1 Micro: 0.959, F1 Macro: 0.9555\n",
      "\n",
      "Aspect detection accuracy: 0.939, F1 Micro: 0.9619, F1 Macro: 0.9597\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.94      0.96      0.95       175\n",
      "      others       0.89      0.91      0.90       158\n",
      "        part       0.92      0.97      0.95       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.95      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.95      0.98      0.96      1061\n",
      "   macro avg       0.95      0.97      0.96      1061\n",
      "weighted avg       0.95      0.98      0.96      1061\n",
      " samples avg       0.95      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5779, Accuracy: 0.6749, F1 Micro: 0.6749, F1 Macro: 0.4029\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3653, Accuracy: 0.8807, F1 Micro: 0.8807, F1 Macro: 0.8626\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2394, Accuracy: 0.9012, F1 Micro: 0.9012, F1 Macro: 0.8936\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.137, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9229\n",
      "Epoch 5/10, Train Loss: 0.154, Accuracy: 0.9177, F1 Micro: 0.9177, F1 Macro: 0.9056\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1153, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9215\n",
      "Epoch 7/10, Train Loss: 0.1328, Accuracy: 0.9095, F1 Micro: 0.9095, F1 Macro: 0.8931\n",
      "Epoch 8/10, Train Loss: 0.1184, Accuracy: 0.9259, F1 Micro: 0.9259, F1 Macro: 0.9161\n",
      "Epoch 9/10, Train Loss: 0.0626, Accuracy: 0.8971, F1 Micro: 0.8971, F1 Macro: 0.8761\n",
      "Epoch 10/10, Train Loss: 0.0794, Accuracy: 0.9177, F1 Micro: 0.9177, F1 Macro: 0.9049\n",
      "\n",
      "Sentiment analysis accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9215\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.92      0.90        79\n",
      "    positive       0.96      0.93      0.95       164\n",
      "\n",
      "    accuracy                           0.93       243\n",
      "   macro avg       0.92      0.93      0.92       243\n",
      "weighted avg       0.93      0.93      0.93       243\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 334: Accuracy: 0.929, F1 Micro: 0.929, F1 Macro: 0.8666\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.94      0.96      0.95       167\n",
      "    positive       0.79      0.67      0.72        33\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.85      0.84      0.84       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.90      0.91      0.91       152\n",
      "    positive       0.73      0.69      0.71        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.79      0.79      0.79       216\n",
      "weighted avg       0.85      0.85      0.85       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.83      0.81        23\n",
      "     neutral       0.92      0.97      0.95       152\n",
      "    positive       0.87      0.66      0.75        41\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.86      0.82      0.83       216\n",
      "weighted avg       0.90      0.90      0.89       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.89      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.71      0.83        14\n",
      "     neutral       0.95      1.00      0.98       185\n",
      "    positive       0.92      0.65      0.76        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.96      0.79      0.86       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Total train time: 88.36371755599976 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.008384198881685734\n",
      "Acquired samples: 54\n",
      "Sampling duration: 11.549848794937134 seconds\n",
      "New train size: 388\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5535, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.488, Accuracy: 0.7999, F1 Micro: 0.8875, F1 Macro: 0.886\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4226, Accuracy: 0.8259, F1 Micro: 0.8979, F1 Macro: 0.8946\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3509, Accuracy: 0.9033, F1 Micro: 0.9403, F1 Macro: 0.9373\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2549, Accuracy: 0.9375, F1 Micro: 0.9612, F1 Macro: 0.9596\n",
      "Epoch 6/10, Train Loss: 0.1947, Accuracy: 0.936, F1 Micro: 0.9598, F1 Macro: 0.957\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.152, Accuracy: 0.942, F1 Micro: 0.9632, F1 Macro: 0.9598\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1121, Accuracy: 0.9509, F1 Micro: 0.9692, F1 Macro: 0.9672\n",
      "Epoch 9/10, Train Loss: 0.0989, Accuracy: 0.9509, F1 Micro: 0.969, F1 Macro: 0.9664\n",
      "Epoch 10/10, Train Loss: 0.0814, Accuracy: 0.9487, F1 Micro: 0.9675, F1 Macro: 0.9647\n",
      "\n",
      "Aspect detection accuracy: 0.9509, F1 Micro: 0.9692, F1 Macro: 0.9672\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.97      0.96       175\n",
      "      others       0.92      0.91      0.92       158\n",
      "        part       0.92      0.99      0.95       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5692, Accuracy: 0.8386, F1 Micro: 0.8386, F1 Macro: 0.8182\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3537, Accuracy: 0.9016, F1 Micro: 0.9016, F1 Macro: 0.8922\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1878, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.9044\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2055, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9126\n",
      "Epoch 5/10, Train Loss: 0.103, Accuracy: 0.8898, F1 Micro: 0.8898, F1 Macro: 0.8813\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1209, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9176\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1222, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9136\n",
      "Epoch 8/10, Train Loss: 0.0743, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9105\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1025, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9213\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0596, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9293\n",
      "\n",
      "Sentiment analysis accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9293\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.94      0.91        82\n",
      "    positive       0.97      0.94      0.95       172\n",
      "\n",
      "    accuracy                           0.94       254\n",
      "   macro avg       0.92      0.94      0.93       254\n",
      "weighted avg       0.94      0.94      0.94       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 388: Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.8943\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.95      0.96      0.96       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.87      0.87       216\n",
      "weighted avg       0.92      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.93      0.91      0.92       152\n",
      "    positive       0.77      0.77      0.77        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.80      0.84      0.82       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.87      0.85        23\n",
      "     neutral       0.92      0.99      0.95       152\n",
      "    positive       0.96      0.63      0.76        41\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.90      0.83      0.86       216\n",
      "weighted avg       0.92      0.91      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.89      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.89      0.94      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 99.3792634010315 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.006748074386268854\n",
      "Acquired samples: 48\n",
      "Sampling duration: 11.016859769821167 seconds\n",
      "New train size: 436\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5465, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.483, Accuracy: 0.8021, F1 Micro: 0.8886, F1 Macro: 0.8872\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4272, Accuracy: 0.8542, F1 Micro: 0.9134, F1 Macro: 0.911\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3314, Accuracy: 0.9137, F1 Micro: 0.9462, F1 Macro: 0.9428\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2484, Accuracy: 0.9397, F1 Micro: 0.9623, F1 Macro: 0.9604\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1914, Accuracy: 0.9479, F1 Micro: 0.9675, F1 Macro: 0.9658\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1524, Accuracy: 0.9561, F1 Micro: 0.9724, F1 Macro: 0.9709\n",
      "Epoch 8/10, Train Loss: 0.1132, Accuracy: 0.9479, F1 Micro: 0.967, F1 Macro: 0.9636\n",
      "Epoch 9/10, Train Loss: 0.0972, Accuracy: 0.9546, F1 Micro: 0.9713, F1 Macro: 0.969\n",
      "Epoch 10/10, Train Loss: 0.0767, Accuracy: 0.9539, F1 Micro: 0.9709, F1 Macro: 0.9684\n",
      "\n",
      "Aspect detection accuracy: 0.9561, F1 Micro: 0.9724, F1 Macro: 0.9709\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.97      0.97       175\n",
      "      others       0.90      0.95      0.93       158\n",
      "        part       0.97      0.96      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5657, Accuracy: 0.821, F1 Micro: 0.821, F1 Macro: 0.78\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3212, Accuracy: 0.8833, F1 Micro: 0.8833, F1 Macro: 0.8736\n",
      "Epoch 3/10, Train Loss: 0.2192, Accuracy: 0.8599, F1 Micro: 0.8599, F1 Macro: 0.8497\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1276, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9204\n",
      "Epoch 5/10, Train Loss: 0.1569, Accuracy: 0.8872, F1 Micro: 0.8872, F1 Macro: 0.877\n",
      "Epoch 6/10, Train Loss: 0.1207, Accuracy: 0.9105, F1 Micro: 0.9105, F1 Macro: 0.8953\n",
      "Epoch 7/10, Train Loss: 0.1211, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.9039\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.08, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9172\n",
      "Epoch 9/10, Train Loss: 0.0778, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9141\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0701, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9204\n",
      "\n",
      "Sentiment analysis accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9204\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.94      0.89        80\n",
      "    positive       0.97      0.93      0.95       177\n",
      "\n",
      "    accuracy                           0.93       257\n",
      "   macro avg       0.91      0.93      0.92       257\n",
      "weighted avg       0.93      0.93      0.93       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 436: Accuracy: 0.9475, F1 Micro: 0.9475, F1 Macro: 0.8944\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.98      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.96      0.97      0.96       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.87      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.91      0.95      0.93       152\n",
      "    positive       0.85      0.75      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.88      0.82      0.85       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.91      0.82        23\n",
      "     neutral       0.97      0.96      0.96       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.91      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.71      0.83        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       0.89      0.94      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.89      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 100.43882846832275 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.005115563608705997\n",
      "Acquired samples: 43\n",
      "Sampling duration: 9.84351921081543 seconds\n",
      "New train size: 479\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.562, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.485, Accuracy: 0.8058, F1 Micro: 0.8905, F1 Macro: 0.889\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4114, Accuracy: 0.8571, F1 Micro: 0.9125, F1 Macro: 0.9066\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3068, Accuracy: 0.9249, F1 Micro: 0.9531, F1 Macro: 0.9506\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2165, Accuracy: 0.942, F1 Micro: 0.964, F1 Macro: 0.9621\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1784, Accuracy: 0.9449, F1 Micro: 0.9656, F1 Macro: 0.9635\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1307, Accuracy: 0.9531, F1 Micro: 0.9704, F1 Macro: 0.9681\n",
      "Epoch 8/10, Train Loss: 0.1078, Accuracy: 0.9524, F1 Micro: 0.9701, F1 Macro: 0.968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0906, Accuracy: 0.9554, F1 Micro: 0.972, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0701, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9721\n",
      "\n",
      "Aspect detection accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9721\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.90      0.95      0.92       158\n",
      "        part       0.97      0.97      0.97       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5626, Accuracy: 0.8071, F1 Micro: 0.8071, F1 Macro: 0.7551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2761, Accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.9069\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1936, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9195\n",
      "Epoch 4/10, Train Loss: 0.1685, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9135\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1222, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9237\n",
      "Epoch 6/10, Train Loss: 0.1278, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9126\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1139, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9275\n",
      "Epoch 8/10, Train Loss: 0.079, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9213\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0757, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9377\n",
      "Epoch 10/10, Train Loss: 0.0536, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9322\n",
      "\n",
      "Sentiment analysis accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9377\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.95      0.92        81\n",
      "    positive       0.98      0.94      0.96       173\n",
      "\n",
      "    accuracy                           0.94       254\n",
      "   macro avg       0.93      0.95      0.94       254\n",
      "weighted avg       0.95      0.94      0.95       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 479: Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.9041\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.98      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.88      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.67      0.73        12\n",
      "     neutral       0.90      0.95      0.92       152\n",
      "    positive       0.85      0.75      0.80        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.85      0.79      0.82       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.92      0.91       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.87      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.93      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 109.5307309627533 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.004992398200556636\n",
      "Acquired samples: 39\n",
      "Sampling duration: 9.33883547782898 seconds\n",
      "New train size: 518\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5456, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4733, Accuracy: 0.8147, F1 Micro: 0.8937, F1 Macro: 0.8918\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3808, Accuracy: 0.8958, F1 Micro: 0.936, F1 Macro: 0.9327\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2702, Accuracy: 0.9338, F1 Micro: 0.9586, F1 Macro: 0.9564\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1966, Accuracy: 0.9442, F1 Micro: 0.9651, F1 Macro: 0.9628\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1484, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9742\n",
      "Epoch 7/10, Train Loss: 0.1169, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9713\n",
      "Epoch 8/10, Train Loss: 0.0954, Accuracy: 0.9554, F1 Micro: 0.9719, F1 Macro: 0.9695\n",
      "Epoch 9/10, Train Loss: 0.0805, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.972\n",
      "Epoch 10/10, Train Loss: 0.0654, Accuracy: 0.9561, F1 Micro: 0.9724, F1 Macro: 0.9705\n",
      "\n",
      "Aspect detection accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9742\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.91      0.96      0.94       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.97      1061\n",
      "weighted avg       0.96      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5433, Accuracy: 0.8664, F1 Micro: 0.8664, F1 Macro: 0.8414\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2871, Accuracy: 0.8988, F1 Micro: 0.8988, F1 Macro: 0.8899\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1722, Accuracy: 0.9312, F1 Micro: 0.9312, F1 Macro: 0.9195\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1291, Accuracy: 0.9393, F1 Micro: 0.9393, F1 Macro: 0.9322\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0781, Accuracy: 0.9433, F1 Micro: 0.9433, F1 Macro: 0.9349\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1112, Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.9452\n",
      "Epoch 7/10, Train Loss: 0.0693, Accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9408\n",
      "Epoch 8/10, Train Loss: 0.0806, Accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9405\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0505, Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.9445\n",
      "Epoch 10/10, Train Loss: 0.0428, Accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9405\n",
      "\n",
      "Sentiment analysis accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.9445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.94      0.92        79\n",
      "    positive       0.97      0.96      0.96       168\n",
      "\n",
      "    accuracy                           0.95       247\n",
      "   macro avg       0.94      0.95      0.94       247\n",
      "weighted avg       0.95      0.95      0.95       247\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 518: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9056\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.98      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.86      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.67      0.76        12\n",
      "     neutral       0.91      0.97      0.94       152\n",
      "    positive       0.89      0.79      0.84        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.90      0.81      0.85       216\n",
      "weighted avg       0.91      0.91      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87        23\n",
      "     neutral       0.96      0.99      0.97       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.89      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.89      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 109.17125582695007 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.004527782835066319\n",
      "Acquired samples: 22\n",
      "Sampling duration: 8.30434513092041 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5481, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4598, Accuracy: 0.8147, F1 Micro: 0.8926, F1 Macro: 0.8899\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3711, Accuracy: 0.8988, F1 Micro: 0.9373, F1 Macro: 0.9342\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2713, Accuracy: 0.9382, F1 Micro: 0.9613, F1 Macro: 0.9597\n",
      "Epoch 5/10, Train Loss: 0.2031, Accuracy: 0.936, F1 Micro: 0.9595, F1 Macro: 0.954\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1486, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1143, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.973\n",
      "Epoch 8/10, Train Loss: 0.0987, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0771, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9745\n",
      "Epoch 10/10, Train Loss: 0.0674, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9729\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9745\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.97      0.97       175\n",
      "      others       0.90      0.95      0.92       158\n",
      "        part       0.96      1.00      0.98       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.97      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5571, Accuracy: 0.88, F1 Micro: 0.88, F1 Macro: 0.8663\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2589, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9383\n",
      "Epoch 3/10, Train Loss: 0.1976, Accuracy: 0.916, F1 Micro: 0.916, F1 Macro: 0.9095\n",
      "Epoch 4/10, Train Loss: 0.1282, Accuracy: 0.916, F1 Micro: 0.916, F1 Macro: 0.9095\n",
      "Epoch 5/10, Train Loss: 0.1247, Accuracy: 0.932, F1 Micro: 0.932, F1 Macro: 0.926\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1021, Accuracy: 0.952, F1 Micro: 0.952, F1 Macro: 0.9471\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0954, Accuracy: 0.952, F1 Micro: 0.952, F1 Macro: 0.9465\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0864, Accuracy: 0.952, F1 Micro: 0.952, F1 Macro: 0.9465\n",
      "Epoch 9/10, Train Loss: 0.0636, Accuracy: 0.948, F1 Micro: 0.948, F1 Macro: 0.9405\n",
      "Epoch 10/10, Train Loss: 0.066, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9361\n",
      "\n",
      "Sentiment analysis accuracy: 0.952, F1 Micro: 0.952, F1 Macro: 0.9465\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93        83\n",
      "    positive       0.98      0.95      0.96       167\n",
      "\n",
      "    accuracy                           0.95       250\n",
      "   macro avg       0.94      0.95      0.95       250\n",
      "weighted avg       0.95      0.95      0.95       250\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9134\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.97      0.97      0.97       167\n",
      "    positive       0.85      0.85      0.85        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.90      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.90      0.95      0.93       152\n",
      "    positive       0.86      0.71      0.78        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.84      0.81      0.82       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.96      1.00      0.98       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.94      0.91      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.97      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.97      0.87      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.96      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 109.68286633491516 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.0029448454733937983\n",
      "Acquired samples: 33\n",
      "Sampling duration: 8.010636329650879 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5366, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4634, Accuracy: 0.8207, F1 Micro: 0.8964, F1 Macro: 0.8946\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.373, Accuracy: 0.904, F1 Micro: 0.94, F1 Macro: 0.936\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2663, Accuracy: 0.9427, F1 Micro: 0.9641, F1 Macro: 0.9624\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1995, Accuracy: 0.9546, F1 Micro: 0.9717, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1488, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9732\n",
      "Epoch 7/10, Train Loss: 0.1169, Accuracy: 0.9554, F1 Micro: 0.9721, F1 Macro: 0.9703\n",
      "Epoch 8/10, Train Loss: 0.0985, Accuracy: 0.9576, F1 Micro: 0.9732, F1 Macro: 0.9712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0773, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "Epoch 10/10, Train Loss: 0.0677, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9723\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.93      0.94      0.94       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5369, Accuracy: 0.8828, F1 Micro: 0.8828, F1 Macro: 0.8715\n",
      "Epoch 2/10, Train Loss: 0.2648, Accuracy: 0.8789, F1 Micro: 0.8789, F1 Macro: 0.8721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2026, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8956\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.132, Accuracy: 0.9141, F1 Micro: 0.9141, F1 Macro: 0.9071\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1532, Accuracy: 0.9141, F1 Micro: 0.9141, F1 Macro: 0.9067\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1363, Accuracy: 0.9258, F1 Micro: 0.9258, F1 Macro: 0.9175\n",
      "Epoch 7/10, Train Loss: 0.1071, Accuracy: 0.918, F1 Micro: 0.918, F1 Macro: 0.9093\n",
      "Epoch 8/10, Train Loss: 0.0813, Accuracy: 0.9102, F1 Micro: 0.9102, F1 Macro: 0.9031\n",
      "Epoch 9/10, Train Loss: 0.0845, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8952\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0833, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9249\n",
      "\n",
      "Sentiment analysis accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9249\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.89      0.90        85\n",
      "    positive       0.95      0.95      0.95       171\n",
      "\n",
      "    accuracy                           0.93       256\n",
      "   macro avg       0.93      0.92      0.92       256\n",
      "weighted avg       0.93      0.93      0.93       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9014\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.73      0.80        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.84      0.88      0.86        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.87      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.85      0.70      0.77        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.83      0.86       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.93      0.94      0.94       152\n",
      "    positive       0.82      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.84      0.85      0.85       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.91      0.93        23\n",
      "     neutral       0.96      0.99      0.98       152\n",
      "    positive       0.92      0.83      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.95      0.91      0.93       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 115.13608145713806 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.00426389086060226\n",
      "Acquired samples: 30\n",
      "Sampling duration: 7.328610181808472 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5454, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4536, Accuracy: 0.8251, F1 Micro: 0.8988, F1 Macro: 0.8968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3422, Accuracy: 0.9278, F1 Micro: 0.9556, F1 Macro: 0.9536\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2394, Accuracy: 0.9501, F1 Micro: 0.9688, F1 Macro: 0.9671\n",
      "Epoch 5/10, Train Loss: 0.1726, Accuracy: 0.9494, F1 Micro: 0.9683, F1 Macro: 0.9662\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1356, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1102, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.975\n",
      "Epoch 8/10, Train Loss: 0.0911, Accuracy: 0.9554, F1 Micro: 0.9719, F1 Macro: 0.9699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0737, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0602, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.96      0.99      0.97       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4984, Accuracy: 0.8906, F1 Micro: 0.8906, F1 Macro: 0.8818\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2587, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.93\n",
      "Epoch 3/10, Train Loss: 0.1661, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8947\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1225, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9387\n",
      "Epoch 5/10, Train Loss: 0.1428, Accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.8991\n",
      "Epoch 6/10, Train Loss: 0.105, Accuracy: 0.9258, F1 Micro: 0.9258, F1 Macro: 0.9139\n",
      "Epoch 7/10, Train Loss: 0.0861, Accuracy: 0.9297, F1 Micro: 0.9297, F1 Macro: 0.9212\n",
      "Epoch 8/10, Train Loss: 0.0724, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9287\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0683, Accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9433\n",
      "Epoch 10/10, Train Loss: 0.0463, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9249\n",
      "\n",
      "Sentiment analysis accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9433\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.96      0.92        83\n",
      "    positive       0.98      0.94      0.96       173\n",
      "\n",
      "    accuracy                           0.95       256\n",
      "   macro avg       0.94      0.95      0.94       256\n",
      "weighted avg       0.95      0.95      0.95       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.9199\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.88      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.85      0.79      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.87      0.83      0.85       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.96      0.99      0.97       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.91      0.91       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 117.00154256820679 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.003615477913990617\n",
      "Acquired samples: 27\n",
      "Sampling duration: 6.8869898319244385 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5448, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.448, Accuracy: 0.8244, F1 Micro: 0.8982, F1 Macro: 0.8964\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3288, Accuracy: 0.9226, F1 Micro: 0.9518, F1 Macro: 0.9487\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2343, Accuracy: 0.9494, F1 Micro: 0.9686, F1 Macro: 0.9671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1746, Accuracy: 0.9568, F1 Micro: 0.9731, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1321, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0998, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9756\n",
      "Epoch 8/10, Train Loss: 0.0728, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0617, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0568, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.976\n",
      "\n",
      "Aspect detection accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.93      0.92      0.93       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5247, Accuracy: 0.9035, F1 Micro: 0.9035, F1 Macro: 0.8933\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2576, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9353\n",
      "Epoch 3/10, Train Loss: 0.1943, Accuracy: 0.9035, F1 Micro: 0.9035, F1 Macro: 0.8968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1302, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9401\n",
      "Epoch 5/10, Train Loss: 0.1157, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9241\n",
      "Epoch 6/10, Train Loss: 0.1446, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9366\n",
      "Epoch 7/10, Train Loss: 0.084, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9312\n",
      "Epoch 8/10, Train Loss: 0.0948, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.936\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0657, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9398\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0503, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9398\n",
      "\n",
      "Sentiment analysis accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9398\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        86\n",
      "    positive       0.97      0.95      0.96       173\n",
      "\n",
      "    accuracy                           0.95       259\n",
      "   macro avg       0.94      0.94      0.94       259\n",
      "weighted avg       0.95      0.95      0.95       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9122\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.99      0.97       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.88      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.93      0.92      0.93       152\n",
      "    positive       0.77      0.79      0.78        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.83      0.85      0.84       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.96      0.99      0.97       152\n",
      "    positive       0.97      0.76      0.85        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.94      0.92      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.88      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 125.36361289024353 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.003935916163027286\n",
      "Acquired samples: 18\n",
      "Sampling duration: 6.059016227722168 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5379, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.441, Accuracy: 0.846, F1 Micro: 0.9089, F1 Macro: 0.9068\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3227, Accuracy: 0.9301, F1 Micro: 0.9566, F1 Macro: 0.9542\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2167, Accuracy: 0.9561, F1 Micro: 0.9728, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.156, Accuracy: 0.9583, F1 Micro: 0.974, F1 Macro: 0.9726\n",
      "Epoch 6/10, Train Loss: 0.1127, Accuracy: 0.9539, F1 Micro: 0.9709, F1 Macro: 0.9688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0952, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9754\n",
      "Epoch 8/10, Train Loss: 0.0748, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.975\n",
      "Epoch 9/10, Train Loss: 0.0638, Accuracy: 0.9613, F1 Micro: 0.9755, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.051, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9765\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.94      0.92      0.93       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5314, Accuracy: 0.8958, F1 Micro: 0.8958, F1 Macro: 0.8875\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2838, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9304\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.173, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9326\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.13, Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9445\n",
      "Epoch 5/10, Train Loss: 0.1087, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9391\n",
      "Epoch 6/10, Train Loss: 0.0933, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9315\n",
      "Epoch 7/10, Train Loss: 0.0936, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9353\n",
      "Epoch 8/10, Train Loss: 0.0644, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9262\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0812, Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9445\n",
      "Epoch 10/10, Train Loss: 0.0582, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9333\n",
      "\n",
      "Sentiment analysis accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.97      0.93        86\n",
      "    positive       0.98      0.94      0.96       173\n",
      "\n",
      "    accuracy                           0.95       259\n",
      "   macro avg       0.94      0.95      0.94       259\n",
      "weighted avg       0.95      0.95      0.95       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9173\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.87      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.94      0.93      0.93       152\n",
      "    positive       0.79      0.81      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.83      0.86      0.84       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.96      0.99      0.98       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.94      0.92      0.93       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.88      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 125.49230575561523 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.002108126599341631\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.7199811935424805 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.533, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4261, Accuracy: 0.8631, F1 Micro: 0.9184, F1 Macro: 0.9158\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2923, Accuracy: 0.9353, F1 Micro: 0.9597, F1 Macro: 0.9577\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2008, Accuracy: 0.9568, F1 Micro: 0.9731, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1477, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9721\n",
      "Epoch 6/10, Train Loss: 0.1158, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0906, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0689, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0576, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.977\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0534, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9772\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9772\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.96      0.98      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5146, Accuracy: 0.8803, F1 Micro: 0.8803, F1 Macro: 0.8677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2509, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9274\n",
      "Epoch 3/10, Train Loss: 0.2055, Accuracy: 0.8996, F1 Micro: 0.8996, F1 Macro: 0.8808\n",
      "Epoch 4/10, Train Loss: 0.1359, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9201\n",
      "Epoch 5/10, Train Loss: 0.1326, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9205\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1291, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9308\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0555, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9398\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0721, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9398\n",
      "Epoch 9/10, Train Loss: 0.0643, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9345\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0682, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9404\n",
      "\n",
      "Sentiment analysis accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9404\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.97      0.92        86\n",
      "    positive       0.98      0.94      0.96       173\n",
      "\n",
      "    accuracy                           0.95       259\n",
      "   macro avg       0.93      0.95      0.94       259\n",
      "weighted avg       0.95      0.95      0.95       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.9237\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.90      0.82      0.86        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.83      0.77      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.89      0.85      0.87       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.96      0.98      0.97       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.92      0.91       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 133.95169043540955 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.0023875507060438397\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.139517545700073 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5263, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4495, Accuracy: 0.8668, F1 Micro: 0.9203, F1 Macro: 0.9178\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3115, Accuracy: 0.9427, F1 Micro: 0.9646, F1 Macro: 0.9631\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2164, Accuracy: 0.9554, F1 Micro: 0.9721, F1 Macro: 0.9708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1536, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1188, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0908, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0737, Accuracy: 0.9665, F1 Micro: 0.9791, F1 Macro: 0.9781\n",
      "Epoch 9/10, Train Loss: 0.0662, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9746\n",
      "Epoch 10/10, Train Loss: 0.0536, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9765\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9791, F1 Macro: 0.9781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.98       175\n",
      "      others       0.90      0.99      0.94       158\n",
      "        part       0.96      0.99      0.97       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5093, Accuracy: 0.9024, F1 Micro: 0.9024, F1 Macro: 0.8963\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.231, Accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.9417\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1719, Accuracy: 0.9553, F1 Micro: 0.9553, F1 Macro: 0.9504\n",
      "Epoch 4/10, Train Loss: 0.1373, Accuracy: 0.9512, F1 Micro: 0.9512, F1 Macro: 0.9458\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1041, Accuracy: 0.9593, F1 Micro: 0.9593, F1 Macro: 0.9551\n",
      "Epoch 6/10, Train Loss: 0.1018, Accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.9421\n",
      "Epoch 7/10, Train Loss: 0.074, Accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.9421\n",
      "Epoch 8/10, Train Loss: 0.0779, Accuracy: 0.939, F1 Micro: 0.939, F1 Macro: 0.9331\n",
      "Epoch 9/10, Train Loss: 0.0616, Accuracy: 0.9512, F1 Micro: 0.9512, F1 Macro: 0.9461\n",
      "Epoch 10/10, Train Loss: 0.0671, Accuracy: 0.9553, F1 Micro: 0.9553, F1 Macro: 0.9507\n",
      "\n",
      "Sentiment analysis accuracy: 0.9593, F1 Micro: 0.9593, F1 Macro: 0.9551\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94        82\n",
      "    positive       0.99      0.95      0.97       164\n",
      "\n",
      "    accuracy                           0.96       246\n",
      "   macro avg       0.95      0.96      0.96       246\n",
      "weighted avg       0.96      0.96      0.96       246\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.921\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.97      0.98      0.98       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.67      0.76        12\n",
      "     neutral       0.90      0.99      0.94       152\n",
      "    positive       0.95      0.73      0.83        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.91      0.79      0.84       216\n",
      "weighted avg       0.91      0.91      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.96      0.99      0.97       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.92      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.87      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 127.94582223892212 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.0022491718642413615\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.56548285484314 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5245, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4184, Accuracy: 0.8884, F1 Micro: 0.9328, F1 Macro: 0.9304\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2795, Accuracy: 0.9524, F1 Micro: 0.9705, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1938, Accuracy: 0.9576, F1 Micro: 0.9736, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1414, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9765\n",
      "Epoch 6/10, Train Loss: 0.1046, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9743\n",
      "Epoch 7/10, Train Loss: 0.0821, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9748\n",
      "Epoch 8/10, Train Loss: 0.0712, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9717\n",
      "Epoch 9/10, Train Loss: 0.057, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0483, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9791\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9791\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.93      0.96      0.94       158\n",
      "        part       0.96      0.99      0.97       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4804, Accuracy: 0.898, F1 Micro: 0.898, F1 Macro: 0.891\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2723, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9238\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1851, Accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.9435\n",
      "Epoch 4/10, Train Loss: 0.1647, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9358\n",
      "Epoch 5/10, Train Loss: 0.0977, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.934\n",
      "Epoch 6/10, Train Loss: 0.0703, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9344\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0778, Accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.9438\n",
      "Epoch 8/10, Train Loss: 0.0635, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9332\n",
      "Epoch 9/10, Train Loss: 0.0711, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9306\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0603, Accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.944\n",
      "\n",
      "Sentiment analysis accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.944\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.97      0.93        86\n",
      "    positive       0.98      0.94      0.96       169\n",
      "\n",
      "    accuracy                           0.95       255\n",
      "   macro avg       0.94      0.95      0.94       255\n",
      "weighted avg       0.95      0.95      0.95       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9216\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.99      0.97       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.88      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.93      0.96      0.94       152\n",
      "    positive       0.85      0.79      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.87      0.83      0.85       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.96      0.99      0.97       152\n",
      "    positive       0.97      0.76      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.91      0.91       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 130.23424172401428 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.002762408694252372\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.26221227645874 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5381, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4217, Accuracy: 0.8936, F1 Micro: 0.9361, F1 Macro: 0.9344\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.284, Accuracy: 0.9368, F1 Micro: 0.9609, F1 Macro: 0.9588\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1821, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1422, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1081, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.978\n",
      "Epoch 7/10, Train Loss: 0.0808, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0713, Accuracy: 0.9695, F1 Micro: 0.9809, F1 Macro: 0.9798\n",
      "Epoch 9/10, Train Loss: 0.0587, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.977\n",
      "Epoch 10/10, Train Loss: 0.0498, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9775\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9809, F1 Macro: 0.9798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.91      0.98      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5122, Accuracy: 0.881, F1 Micro: 0.881, F1 Macro: 0.8757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2179, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9274\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1592, Accuracy: 0.9603, F1 Micro: 0.9603, F1 Macro: 0.9563\n",
      "Epoch 4/10, Train Loss: 0.1561, Accuracy: 0.8929, F1 Micro: 0.8929, F1 Macro: 0.8875\n",
      "Epoch 5/10, Train Loss: 0.1152, Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9382\n",
      "Epoch 6/10, Train Loss: 0.1053, Accuracy: 0.9524, F1 Micro: 0.9524, F1 Macro: 0.9479\n",
      "Epoch 7/10, Train Loss: 0.085, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9271\n",
      "Epoch 8/10, Train Loss: 0.0797, Accuracy: 0.9524, F1 Micro: 0.9524, F1 Macro: 0.9473\n",
      "Epoch 9/10, Train Loss: 0.0708, Accuracy: 0.9524, F1 Micro: 0.9524, F1 Macro: 0.9467\n",
      "Epoch 10/10, Train Loss: 0.0536, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.923\n",
      "\n",
      "Sentiment analysis accuracy: 0.9603, F1 Micro: 0.9603, F1 Macro: 0.9563\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.97      0.94        86\n",
      "    positive       0.98      0.96      0.97       166\n",
      "\n",
      "    accuracy                           0.96       252\n",
      "   macro avg       0.95      0.96      0.96       252\n",
      "weighted avg       0.96      0.96      0.96       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9637, F1 Micro: 0.9637, F1 Macro: 0.9338\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.89      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.91      0.98      0.94       152\n",
      "    positive       0.93      0.75      0.83        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.91      0.83      0.86       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 130.55770826339722 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.002411093469709158\n",
      "Acquired samples: 8\n",
      "Sampling duration: 3.497143268585205 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5355, Accuracy: 0.7946, F1 Micro: 0.8849, F1 Macro: 0.8834\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4164, Accuracy: 0.8862, F1 Micro: 0.9307, F1 Macro: 0.928\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2757, Accuracy: 0.9568, F1 Micro: 0.9732, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1913, Accuracy: 0.9613, F1 Micro: 0.9759, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1333, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9795\n",
      "Epoch 6/10, Train Loss: 0.1008, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9758\n",
      "Epoch 7/10, Train Loss: 0.0849, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9732\n",
      "Epoch 8/10, Train Loss: 0.0658, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9792\n",
      "Epoch 9/10, Train Loss: 0.0602, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0517, Accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9794\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9794\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.98       175\n",
      "      others       0.93      0.94      0.94       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5089, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9208\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2491, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9259\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1713, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9263\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1513, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9374\n",
      "Epoch 5/10, Train Loss: 0.1302, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.9298\n",
      "Epoch 6/10, Train Loss: 0.0965, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9334\n",
      "Epoch 7/10, Train Loss: 0.1044, Accuracy: 0.9254, F1 Micro: 0.9254, F1 Macro: 0.9172\n",
      "Epoch 8/10, Train Loss: 0.0899, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9255\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0608, Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9498\n",
      "Epoch 10/10, Train Loss: 0.0418, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9259\n",
      "\n",
      "Sentiment analysis accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9498\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.93        87\n",
      "    positive       0.98      0.95      0.97       181\n",
      "\n",
      "    accuracy                           0.96       268\n",
      "   macro avg       0.94      0.96      0.95       268\n",
      "weighted avg       0.96      0.96      0.96       268\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9622, F1 Micro: 0.9622, F1 Macro: 0.9356\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.97      0.98      0.98       167\n",
      "    positive       0.88      0.85      0.86        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.83      0.91        12\n",
      "     neutral       0.93      0.94      0.94       152\n",
      "    positive       0.81      0.83      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.93      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 134.62875318527222 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0021861907560378315\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.394146680831909 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5248, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.408, Accuracy: 0.9129, F1 Micro: 0.9467, F1 Macro: 0.9444\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2681, Accuracy: 0.9524, F1 Micro: 0.9705, F1 Macro: 0.9688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1771, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.126, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0918, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9786\n",
      "Epoch 7/10, Train Loss: 0.0815, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9775\n",
      "Epoch 8/10, Train Loss: 0.0651, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0548, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9796\n",
      "Epoch 10/10, Train Loss: 0.0442, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9778\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9796\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4753, Accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.9106\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2368, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9265\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1646, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9306\n",
      "Epoch 4/10, Train Loss: 0.151, Accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.9167\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1063, Accuracy: 0.9535, F1 Micro: 0.9535, F1 Macro: 0.9477\n",
      "Epoch 6/10, Train Loss: 0.0876, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9358\n",
      "Epoch 7/10, Train Loss: 0.0683, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9314\n",
      "Epoch 8/10, Train Loss: 0.0712, Accuracy: 0.9457, F1 Micro: 0.9457, F1 Macro: 0.9396\n",
      "Epoch 9/10, Train Loss: 0.0723, Accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.9148\n",
      "Epoch 10/10, Train Loss: 0.0476, Accuracy: 0.907, F1 Micro: 0.907, F1 Macro: 0.8976\n",
      "\n",
      "Sentiment analysis accuracy: 0.9535, F1 Micro: 0.9535, F1 Macro: 0.9477\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        86\n",
      "    positive       0.97      0.97      0.97       172\n",
      "\n",
      "    accuracy                           0.95       258\n",
      "   macro avg       0.95      0.95      0.95       258\n",
      "weighted avg       0.95      0.95      0.95       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9622, F1 Micro: 0.9622, F1 Macro: 0.9264\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.87      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.85      0.79      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.87      0.83      0.85       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.96      0.94        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.95      0.88      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.95      0.94      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 136.13481044769287 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.002631179336458445\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.7190802097320557 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.526, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4046, Accuracy: 0.8988, F1 Micro: 0.9385, F1 Macro: 0.9364\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.261, Accuracy: 0.9568, F1 Micro: 0.9732, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1745, Accuracy: 0.9583, F1 Micro: 0.9741, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1242, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1074, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9771\n",
      "Epoch 7/10, Train Loss: 0.0828, Accuracy: 0.9591, F1 Micro: 0.9741, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0648, Accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9796\n",
      "Epoch 9/10, Train Loss: 0.0547, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9763\n",
      "Epoch 10/10, Train Loss: 0.0463, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9771\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9796\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.97      0.97       175\n",
      "      others       0.94      0.95      0.95       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4839, Accuracy: 0.9101, F1 Micro: 0.9101, F1 Macro: 0.902\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2031, Accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.9078\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1558, Accuracy: 0.9288, F1 Micro: 0.9288, F1 Macro: 0.9222\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1288, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9246\n",
      "Epoch 5/10, Train Loss: 0.1281, Accuracy: 0.9288, F1 Micro: 0.9288, F1 Macro: 0.921\n",
      "Epoch 6/10, Train Loss: 0.0716, Accuracy: 0.9251, F1 Micro: 0.9251, F1 Macro: 0.9137\n",
      "Epoch 7/10, Train Loss: 0.0922, Accuracy: 0.9288, F1 Micro: 0.9288, F1 Macro: 0.921\n",
      "Epoch 8/10, Train Loss: 0.0452, Accuracy: 0.9288, F1 Micro: 0.9288, F1 Macro: 0.9206\n",
      "Epoch 9/10, Train Loss: 0.0631, Accuracy: 0.9288, F1 Micro: 0.9288, F1 Macro: 0.9218\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0517, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9258\n",
      "\n",
      "Sentiment analysis accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9258\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.97      0.90        87\n",
      "    positive       0.98      0.92      0.95       180\n",
      "\n",
      "    accuracy                           0.93       267\n",
      "   macro avg       0.92      0.94      0.93       267\n",
      "weighted avg       0.94      0.93      0.93       267\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9176\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.97      0.97      0.97       167\n",
      "    positive       0.84      0.82      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.89      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.95      0.95      0.95       152\n",
      "    positive       0.84      0.81      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.85      0.86      0.86       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 143.3653380870819 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0017409669933840636\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.201920509338379 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5297, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4046, Accuracy: 0.9234, F1 Micro: 0.9528, F1 Macro: 0.9509\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2558, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9735\n",
      "Epoch 4/10, Train Loss: 0.17, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1255, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9769\n",
      "Epoch 6/10, Train Loss: 0.1032, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9757\n",
      "Epoch 7/10, Train Loss: 0.0749, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0635, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9788\n",
      "Epoch 9/10, Train Loss: 0.0524, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9764\n",
      "Epoch 10/10, Train Loss: 0.0472, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9745\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9788\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.93      0.96      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4799, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9323\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2032, Accuracy: 0.9416, F1 Micro: 0.9416, F1 Macro: 0.9357\n",
      "Epoch 3/10, Train Loss: 0.1621, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9251\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1251, Accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9395\n",
      "Epoch 5/10, Train Loss: 0.1046, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9201\n",
      "Epoch 6/10, Train Loss: 0.0825, Accuracy: 0.9222, F1 Micro: 0.9222, F1 Macro: 0.9161\n",
      "Epoch 7/10, Train Loss: 0.0676, Accuracy: 0.9183, F1 Micro: 0.9183, F1 Macro: 0.9117\n",
      "Epoch 8/10, Train Loss: 0.095, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9268\n",
      "Epoch 9/10, Train Loss: 0.0854, Accuracy: 0.9183, F1 Micro: 0.9183, F1 Macro: 0.9117\n",
      "Epoch 10/10, Train Loss: 0.0609, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9275\n",
      "\n",
      "Sentiment analysis accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9395\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        86\n",
      "    positive       0.97      0.95      0.96       171\n",
      "\n",
      "    accuracy                           0.95       257\n",
      "   macro avg       0.94      0.94      0.94       257\n",
      "weighted avg       0.95      0.95      0.95       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9232\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.86      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.93      0.96      0.94       152\n",
      "    positive       0.87      0.79      0.83        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.88      0.86      0.87       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.92      0.83      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.90      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.89      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 136.79281854629517 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0024054209934547544\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.629202127456665 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5171, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.39, Accuracy: 0.9308, F1 Micro: 0.9575, F1 Macro: 0.9561\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2463, Accuracy: 0.9546, F1 Micro: 0.9717, F1 Macro: 0.97\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1635, Accuracy: 0.9621, F1 Micro: 0.9764, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1248, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9776\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0902, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9776\n",
      "Epoch 7/10, Train Loss: 0.0772, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0619, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9787\n",
      "Epoch 9/10, Train Loss: 0.0489, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9767\n",
      "Epoch 10/10, Train Loss: 0.0414, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9781\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9787\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4854, Accuracy: 0.9186, F1 Micro: 0.9186, F1 Macro: 0.9102\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2521, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9314\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1872, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9306\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.124, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9321\n",
      "Epoch 5/10, Train Loss: 0.0935, Accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.9192\n",
      "Epoch 6/10, Train Loss: 0.0834, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9277\n",
      "Epoch 7/10, Train Loss: 0.0632, Accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.9196\n",
      "Epoch 8/10, Train Loss: 0.0632, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.9232\n",
      "Epoch 9/10, Train Loss: 0.0712, Accuracy: 0.9109, F1 Micro: 0.9109, F1 Macro: 0.8994\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0522, Accuracy: 0.9457, F1 Micro: 0.9457, F1 Macro: 0.9393\n",
      "\n",
      "Sentiment analysis accuracy: 0.9457, F1 Micro: 0.9457, F1 Macro: 0.9393\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        85\n",
      "    positive       0.97      0.95      0.96       173\n",
      "\n",
      "    accuracy                           0.95       258\n",
      "   macro avg       0.93      0.94      0.94       258\n",
      "weighted avg       0.95      0.95      0.95       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.9199\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.82      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.83      0.75      0.79        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.86      0.85      0.85       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.93      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.89      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 146.26512241363525 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0017806049203500153\n",
      "Acquired samples: 8\n",
      "Sampling duration: 1.0372412204742432 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5253, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.403, Accuracy: 0.9211, F1 Micro: 0.9517, F1 Macro: 0.9503\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2553, Accuracy: 0.9546, F1 Micro: 0.9718, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1604, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1282, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "Epoch 6/10, Train Loss: 0.0908, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0772, Accuracy: 0.9702, F1 Micro: 0.9814, F1 Macro: 0.9803\n",
      "Epoch 8/10, Train Loss: 0.0602, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0534, Accuracy: 0.971, F1 Micro: 0.9818, F1 Macro: 0.9808\n",
      "Epoch 10/10, Train Loss: 0.0442, Accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9801\n",
      "\n",
      "Aspect detection accuracy: 0.971, F1 Micro: 0.9818, F1 Macro: 0.9808\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.93      0.96      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5131, Accuracy: 0.8962, F1 Micro: 0.8962, F1 Macro: 0.8888\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.243, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9324\n",
      "Epoch 3/10, Train Loss: 0.1529, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9203\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1252, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9361\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1247, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9364\n",
      "Epoch 6/10, Train Loss: 0.098, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.9084\n",
      "Epoch 7/10, Train Loss: 0.0844, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9203\n",
      "Epoch 8/10, Train Loss: 0.0881, Accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.9131\n",
      "Epoch 9/10, Train Loss: 0.0811, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9268\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0528, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.935\n",
      "\n",
      "Sentiment analysis accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.935\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.92      0.91        86\n",
      "    positive       0.96      0.95      0.96       174\n",
      "\n",
      "    accuracy                           0.94       260\n",
      "   macro avg       0.93      0.94      0.94       260\n",
      "weighted avg       0.94      0.94      0.94       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9614, F1 Micro: 0.9614, F1 Macro: 0.918\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.92      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.88      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.99      0.97       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.88      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.93      0.96      0.94       152\n",
      "    positive       0.89      0.79      0.84        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.86      0.86      0.86       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.95      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 145.262277841568 s\n",
      "Total runtime: 3100.4551017284393 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAACCoAAAHqCAYAAADInz0eAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAADbZklEQVR4nOzdeXiU5d328e9kJyxhD1sEAQVFFmUJu/qI4kbdQa2iuD2iWB/RqihutZX62lKtxdJF1CoorlRFrYq7bIoCUmVX9gTCFgjZZ94/BgKRoAmETJbv5zjmyMw998z8bupRT4cz1xUIhUIhJEmSJEmSJEmSJEmSKkBUpAeQJEmSJEmSJEmSJEk1h0UFSZIkSZIkSZIkSZJUYSwqSJIkSZIkSZIkSZKkCmNRQZIkSZIkSZIkSZIkVRiLCpIkSZIkSZIkSZIkqcJYVJAkSZIkSZIkSZIkSRXGooIkSZIkSZIkSZIkSaowFhUkSZIkSZIkSZIkSVKFsaggSZIkSZIkSZIkSZIqjEUFSZIkSZJU5Vx55ZW0adMm0mNIkiRJkqSDYFFBksrRE088QSAQIDU1NdKjSJIkSYfk6aefJhAIlHi78847i8579913ufrqqznuuOOIjo4uc3lgz3tec801JT5/9913F52TkZFxKJckSZKkGsQ8K0mVW0ykB5Ck6mTy5Mm0adOGuXPnsnz5ctq3bx/pkSRJkqRD8pvf/IYjjzyy2LHjjjuu6P6UKVOYOnUqJ5xwAi1atDioz0hISOCVV17hiSeeIC4urthzzz//PAkJCeTk5BQ7/o9//INgMHhQnydJkqSao7LmWUmq6VxRQZLKyffff8/MmTMZP348TZo0YfLkyZEeqURZWVmRHkGSJElVyBlnnMFll11W7NatW7ei5x966CEyMzP5/PPP6dq160F9xumnn05mZiZvv/12seMzZ87k+++/56yzztrvNbGxscTHxx/U5+0rGAz6pbEkSVI1Vlnz7OHm98CSKjuLCpJUTiZPnkyDBg0466yzuPDCC0ssKmzbto1bbrmFNm3aEB8fT6tWrRg+fHixJb9ycnK4//77Ofroo0lISKB58+acf/75rFixAoCPPvqIQCDARx99VOy9f/jhBwKBAE8//XTRsSuvvJI6deqwYsUKzjzzTOrWrcsvf/lLAD799FMuuugijjjiCOLj40lJSeGWW24hOzt7v7kXL17M0KFDadKkCbVq1aJDhw7cfffdAHz44YcEAgFee+21/V43ZcoUAoEAs2bNKvOfpyRJkqqGFi1aEBsbe0jv0bJlSwYOHMiUKVOKHZ88eTKdO3cu9htve1x55ZX7LcsbDAZ57LHH6Ny5MwkJCTRp0oTTTz+dL7/8suicQCDAqFGjmDx5Mp06dSI+Pp533nkHgK+//pozzjiDevXqUadOHU455RRmz559SNcmSZKkyi1Seba8vp8FuP/++wkEAnz77bdceumlNGjQgP79+wNQUFDAgw8+SLt27YiPj6dNmzbcdddd5ObmHtI1S9KhcusHSSonkydP5vzzzycuLo5LLrmEv/71r3zxxRf07NkTgJ07dzJgwAC+++47rrrqKk444QQyMjJ4/fXXWbt2LY0bN6awsJCzzz6bGTNmcPHFF3PzzTezY8cO3nvvPRYtWkS7du3KPFdBQQGDBw+mf//+/OEPfyAxMRGAl156iV27djFy5EgaNWrE3Llzefzxx1m7di0vvfRS0esXLlzIgAEDiI2N5brrrqNNmzasWLGCN954g9/97necdNJJpKSkMHnyZM4777z9/kzatWtHnz59DuFPVpIkSZG0ffv2/fbSbdy4cbl/zqWXXsrNN9/Mzp07qVOnDgUFBbz00kuMHj261CseXH311Tz99NOcccYZXHPNNRQUFPDpp58ye/ZsevToUXTeBx98wIsvvsioUaNo3Lgxbdq04b///S8DBgygXr163H777cTGxvK3v/2Nk046iY8//pjU1NRyv2ZJkiQdfpU1z5bX97P7uuiiizjqqKN46KGHCIVCAFxzzTU888wzXHjhhdx6663MmTOHcePG8d1335X4y2eSVFEsKkhSOZg3bx6LFy/m8ccfB6B///60atWKyZMnFxUVHnnkERYtWsSrr75a7C/0x44dWxQa//WvfzFjxgzGjx/PLbfcUnTOnXfeWXROWeXm5nLRRRcxbty4YscffvhhatWqVfT4uuuuo3379tx1112sXr2aI444AoCbbrqJUCjEV199VXQM4Pe//z0Q/o20yy67jPHjx7N9+3aSkpIA2LRpE++++26xZq8kSZKqnkGDBu137GCz6U+58MILGTVqFNOmTeOyyy7j3XffJSMjg0suuYSnnnrqZ1//4Ycf8vTTT/OrX/2Kxx57rOj4rbfeut+8S5Ys4ZtvvuHYY48tOnbeeeeRn5/PZ599Rtu2bQEYPnw4HTp04Pbbb+fjjz8upyuVJElSRaqseba8vp/dV9euXYut6rBgwQKeeeYZrrnmGv7xj38AcMMNN9C0aVP+8Ic/8OGHH3LyySeX25+BJJWFWz9IUjmYPHkyycnJRaEuEAgwbNgwXnjhBQoLCwF45ZVX6Nq1636rDuw5f885jRs35qabbjrgOQdj5MiR+x3bNwRnZWWRkZFB3759CYVCfP3110C4bPDJJ59w1VVXFQvBP55n+PDh5Obm8vLLLxcdmzp1KgUFBVx22WUHPbckSZIib8KECbz33nvFbodDgwYNOP3003n++eeB8DZiffv2pXXr1qV6/SuvvEIgEOC+++7b77kfZ+kTTzyxWEmhsLCQd999l3PPPbeopADQvHlzLr30Uj777DMyMzMP5rIkSZIUYZU1z5bn97N7XH/99cUev/XWWwCMHj262PFbb70VgOnTp5flEiWpXLmigiQdosLCQl544QVOPvlkvv/++6Ljqamp/PGPf2TGjBmcdtpprFixggsuuOAn32vFihV06NCBmJjy+7/nmJgYWrVqtd/x1atXc++99/L666+zdevWYs9t374dgJUrVwKUuIfavjp27EjPnj2ZPHkyV199NRAub/Tu3Zv27duXx2VIkiQpQnr16lVs24TD6dJLL+Xyyy9n9erVTJs2jf/3//5fqV+7YsUKWrRoQcOGDX/23COPPLLY402bNrFr1y46dOiw37nHHHMMwWCQNWvW0KlTp1LPI0mSpMqhsubZ8vx+do8f59xVq1YRFRW133e0zZo1o379+qxatapU7ytJh4NFBUk6RB988AEbNmzghRde4IUXXtjv+cmTJ3PaaaeV2+cdaGWFPSs3/Fh8fDxRUVH7nXvqqaeyZcsW7rjjDjp27Ejt2rVZt24dV155JcFgsMxzDR8+nJtvvpm1a9eSm5vL7Nmz+ctf/lLm95EkSVLN9Ytf/IL4+HiuuOIKcnNzGTp06GH5nH1/e02SJEkqL6XNs4fj+1k4cM49lNV6JelwsaggSYdo8uTJNG3alAkTJuz33Kuvvsprr73GxIkTadeuHYsWLfrJ92rXrh1z5swhPz+f2NjYEs9p0KABANu2bSt2vCzt12+++YalS5fyzDPPMHz48KLjP172bM+ytz83N8DFF1/M6NGjef7558nOziY2NpZhw4aVeiZJkiSpVq1anHvuuTz33HOcccYZNG7cuNSvbdeuHf/5z3/YsmVLqVZV2FeTJk1ITExkyZIl+z23ePFioqKiSElJKdN7SpIkqeYpbZ49HN/PlqR169YEg0GWLVvGMcccU3Q8PT2dbdu2lXqbNUk6HKJ+/hRJ0oFkZ2fz6quvcvbZZ3PhhRfudxs1ahQ7duzg9ddf54ILLmDBggW89tpr+71PKBQC4IILLiAjI6PElQj2nNO6dWuio6P55JNPij3/xBNPlHru6OjoYu+55/5jjz1W7LwmTZowcOBAJk2axOrVq0ucZ4/GjRtzxhln8NxzzzF58mROP/30Mn2xLEmSJAHcdttt3Hfffdxzzz1let0FF1xAKBTigQce2O+5H2fXH4uOjua0007j3//+Nz/88EPR8fT0dKZMmUL//v2pV69emeaRJElSzVSaPHs4vp8tyZlnngnAo48+Wuz4+PHjATjrrLN+9j0k6XBxRQVJOgSvv/46O3bs4Be/+EWJz/fu3ZsmTZowefJkpkyZwssvv8xFF13EVVddRffu3dmyZQuvv/46EydOpGvXrgwfPpx//etfjB49mrlz5zJgwACysrJ4//33ueGGGzjnnHNISkrioosu4vHHHycQCNCuXTvefPNNNm7cWOq5O3bsSLt27bjttttYt24d9erV45VXXtlvLzSAP//5z/Tv358TTjiB6667jiOPPJIffviB6dOnM3/+/GLnDh8+nAsvvBCABx98sPR/kJIkSaqyFi5cyOuvvw7A8uXL2b59O7/97W8B6Nq1K0OGDCnT+3Xt2pWuXbuWeY6TTz6Zyy+/nD//+c8sW7aM008/nWAwyKeffsrJJ5/MqFGjfvL1v/3tb3nvvffo378/N9xwAzExMfztb38jNzf3J/cWliRJUtUWiTx7uL6fLWmWK664gr///e9s27aNE088kblz5/LMM89w7rnncvLJJ5fp2iSpPFlUkKRDMHnyZBISEjj11FNLfD4qKoqzzjqLyZMnk5uby6effsp9993Ha6+9xjPPPEPTpk055ZRTaNWqFRBu0r711lv87ne/Y8qUKbzyyis0atSI/v3707lz56L3ffzxx8nPz2fixInEx8czdOhQHnnkEY477rhSzR0bG8sbb7zBr371K8aNG0dCQgLnnXceo0aN2i9Ed+3aldmzZ3PPPffw17/+lZycHFq3bl3i/mpDhgyhQYMGBIPBA5Y3JEmSVL189dVX+/222J7HV1xxRZm/2D0UTz31FF26dOHJJ5/k17/+NUlJSfTo0YO+ffv+7Gs7derEp59+ypgxYxg3bhzBYJDU1FSee+45UlNTK2B6SZIkRUIk8uzh+n62JP/85z9p27YtTz/9NK+99hrNmjVjzJgx3HfffeV+XZJUFoFQadaGkSSpFAoKCmjRogVDhgzhySefjPQ4kiRJkiRJkiRJqoSiIj2AJKn6mDZtGps2bWL48OGRHkWSJEmSJEmSJEmVlCsqSJIO2Zw5c1i4cCEPPvggjRs35quvvor0SJIkSZIkSZIkSaqkXFFBknTI/vrXvzJy5EiaNm3Kv/71r0iPI0mSJEmSJEmSpErMFRUkSZIkSZIkSZIkSVKFcUUFSZIkSZIkSZIkSZJUYSwqSJIkSZIkSZIkSZKkChMT6QEqSjAYZP369dStW5dAIBDpcSRJknQIQqEQO3bsoEWLFkRF1bzurdlWkiSp+jDbmm0lSZKqi7Jk2xpTVFi/fj0pKSmRHkOSJEnlaM2aNbRq1SrSY1Q4s60kSVL1Y7aVJElSdVGabFtjigp169YFwn8o9erVi/A0kiRJOhSZmZmkpKQUZbyaxmwrSZJUfZhtzbaSJEnVRVmybY0pKuxZNqxevXoGXkmSpGqipi4Na7aVJEmqfsy2ZltJkqTqojTZtuZteiZJkiRJkiRJkiRJkiLGooIkSZIkSZIkSZIkSaowFhUkSZIkSZIkSZIkSVKFsaggSZIkSZIkSZIkSZIqjEUFSZIkSZIkSZIkSZJUYSwqSJIkSZIkSZIkSZKkCmNRQZIkSZIkSZIkSZIkVRiLCpIkSZIkSZIkSZIkqcJYVJAkSZIkSZIkSZIkSRXGooIkSZIkSZIkSZIkSaowFhUkSZIkSZIkSZIkSVKFsaggSZIkSZIkSZIkSZIqjEUFSZIkSZIkSZIkSZJUYSwqSJIkSZIkSZIkSZKkCmNRQZIk1VhZWfD++7BrV6QnkSRJkg5RQRakvQ8FhltJkiRVP+k703l/5fssSFtAKBSK9DgqBzGRHkCSJKmirV8Pjz8Of/sbbN0KbdrAX/4CZ50V6ckkSZKkMtq1HpY+Dsv/BnlboXYb6PEXaGm4lSRJUtW0I3cH/1nxH77a8BXz0+YzP20+G3ZuKHo+pV4KQ44ewpAOQzipzUkkxCREcFodLIsKkiSpxpg/H8aPhxdegPz88LGYGPjhBzj7bDjvPHjsMUhJieSUkiRJUilsnQ/fjYfVL0Bwd7gNxEDWD/Dx2dDqPOj+GNQ23EqSJKnyC4VCzFwzkye/fpIX//siWflZxZ4PEKBdw3asy1zHmsw1PPHlEzzx5RPUjq3Nae1OY8jRQzjr6LNoWrtphK5AZWVRQZIkVWvBILzzDvzxj/DBB3uPDxgAt94KJ58MDz4If/oTvPYavPsu3H8/XHcdREcf2mfHxEB8/KG9hyRJklQkFIT178DiP0L6PuG2yQA45lZIPhkWPQiL/wRrX4O0d6Hz/dD+OggcYrgNxEC04VaSJEnlK21nGv9a8C8mfT2JJZuXFB0/quFRnNzmZLo168bxzY+nc9PO1I6rTXZ+Nh98/wFvLH2DN5a+wfod63lt8Wu8tvg1AgRIbZUaXm3h6CEc1/Q4AoFABK9OPyUQqiGbeGRmZpKUlMT27dupV69epMeRJEmHWXY2PPdceAWFxYvDx6Kj4aKLYPRo6Nmz+PnffAMjR8Lnn5ffDIEAnHIKXHlleLWGxMTye++arqZnu5p+/ZIk1TgF2fDDc7B4PGTuDreBaDjiIug4Ghr9KNxu+wa+GAmbyjHcEoBmp8CRV0LKeRBjuC0vNT3b1fTrlySpJsovzOetZW8xaf4kpi+dTmGoEIDasbUZ2mkoVx9/NX1T+v5sySAUCvHVhq+KSgtfbfiq2PNt6rcpKi2c2OZE4qLjDts1Kaws2c6igiRJqlY2boQnngjfNm0KH6tXD669Fn71KzjiiAO/NhiEp5+GMWPC71Oe6taFoUPDpYV+/cIlhupiyRKYNAl+97vwKhIVoaZnu5p+/ZIk1Rg5G2HpE7DsCcjdHW5j60G7a6HDr6D2T4TbUBBWPg0LxoTfpzzF1IXWQ8OlhSbVLNxmLoEVk6Dr7yCqYsJtTc92Nf36JUmqSRZnLOapr5/imQXPkJ6VXnS8T6s+XH381QztNJS68XUP+v3XZa7jzaVv8sbSN5jx/QxyCnKKnqsbV5fB7Qcz5OghnHnUmTRObHxI16KSWVQogYFXkqTq7dtvw6snPPcc5OaGj7VuDTffDFdfHS4rlFYwCDk5P3/ez1m/HiZPhmeege+/33u8XTu44goYPjw8Y1W2bRukpsLSpXDbbfDIIxXzuTU929X065ckqdrb/m149YTvn4Pg7nBbuzV0uBnaXR0uK5RWKAiF5RBus9fDD5Nh5TOQtU+4rdMOjrwC2g4Pz1iV5W2D/6TCjqVwzG1wfMWE25qe7Wr69UuSVN3tzNvJi/99kUlfT+LzNXtX/GpauynDuwznquOv4pgmx5T752blZfH+yvd5Y+kbvLn0zWLFiKhAFKktUznzqDM586gz6dasG1GBqHKfoSayqFACA68kSdVPKAQzZsAf/wjvvLP3eGoq3HpreLuFivoN/58SDMKnn4YLCy++CFlZe587+eTwKgsXXAC1a0dsxINSWAhnnx3+s09JgS+/hKZNK+aza3q2q+nXL0lStRQKQfoM+O6PsGGfcNsoFY65FVqdV2G/4f+TQkHY+Cl8/wysfhEK9gm3ySeHV1k44gKIqWLhNlgIH58d/rNPTIHTv4SEigm3NT3b1fTrlyTpYOUX5rNo4yLmrptLVn4WTWs3Jbl2cvhnnWQaJzYmJkL5MRQKMWvtLCZ9PYmp/53KzrydAEQHojnzqDO56virOOuos4iNjq2QeYKhIF+u/5I3loS3iFiQvqDY883qNOOM9mdw5lFncmrbU0lKSKqQufIL8/l+2/fUjatL09pNiY6KrpDPPZwsKpTAwCtJUuSFQrBhA+TnH/r7fPxxeAWFhQvDxwKBcDHh1luhT5/Ku/psVha8+mp4i4kPPth7vE4duPDCcGlhwACIKscCb24ubN4cLhGUZ3Hj9tvDKyjUqgWffw7HH19+7/1zanq2q+nXL0lSpRAKQfYGCJVDuN34cXgFhW27wy0BSDkPOt4KjStxuC3IgjWvhreYSN8n3MbUgSMuDJcWmg6A8vzttMJcyN0cLhGU5xfvX98O3z0C0bXg1M+hYcWF25qe7Wr69UuSVBqhUIjvt33P3HVzmbtuLnPWzeGrDV8V29rgxwIEaJTYiOTaySTXSS4qMuxbZtj3fkJMwn6fmR/MpyBYQH5hfqnvz1k7h0nzJ7E4Y3HRex3V8CiuPv5qLu96OS3qtjhsf06ltWb7Gt5e/jZvLXuL91e+T1b+3vJtdCCa/kf0LyouHNf0OALlkMc379rMgvQFLEhbEP6ZvoBvN31LXmFe0ec2q9OMFnVb0LJeS1rUaUGLui32Pt59v0FCg3KZ53CxqFACA68kSRUrNze8HcP8+eHbggXhn9u3l+/n1K4NV10V3uKhXbvyfe/DbdUqePbZcGlhxYq9x9u02bs1RNu2Jb+2sBAyMiAtLXxLT997/8e3rVvDr4mPh2OPhS5dwrfOncM/k5PLPvvkyXDZZeH7L7wAw4aV/T0ORU3PdjX9+iVJqnCFueHtGLbOD9+2LQj/zC/ncBtTG9peFd7ioW4VC7dZq+D7Z8OlhZ37hNvabfZuDVHnAOE2WAi5GZCTBtlpkJO+z/204vfzdofbqHhIOhbqd9l96xz+Wesgwu33k2HW7nDb7wVoXbHhtqZnu5p+/ZKkyNmes53FGYvp1LQTdeLqRHqcYjJ2ZfDFui+KSglz181lc/bm/c5Lik+iV8teNE5szMasjaRnpZO+M52MXRmEKNtfAdeOrU0gECC/MFw8KAwVHtI1JMYmMrTTUK7qdhX9j+hfaf9yPbcgl89Wf8Zby97ireVvFStYALSq14oz24e3iDil7Sk/+89KYbCQpZuXFpUSFm5cyIK0Bazbsa7E82vF1CK3MJdgKFiqeRNiEopKCy3qtqBl3b0lhqMaHkWX5C7Ex8SX7uIPA4sKJTDwSpJ0+GzevLeIsOf23XdQULD/udHREBd36J+ZnAzXXw/XXQcNGhz6+0VSKAQzZ4YLC1Onwo4de58bOBB694aNG4uXDzZuDG8pUR6aNt1bXthTYDj2WEhIKPn8L78Mr/qQkwNjxsBDD5XPHGVR07NdTb9+SZIOq9zNuwsJu8sI2+bD9u8gVEK4DURDVDmE24RkOOp6aH8dxFWDcJsxM1xYWDUVCvYJt00HQqPekLtxb/EgOy38uJRfzP6shKb7lBd2FxiSjoXoA4TbzV/C+wOgMAeOHQPdKj7c1vRsV9OvX5JU8Xbk7uCxOY/xh5l/YHvudqID0XRt1pX+Kf3pf0R/+h3Rr0J/6z87P5uv074utlrCyq0r9zsvLjqObs260atFL3q17EVqq1TaN2xPVAmrVxUGC8nYlVGsvLDnfknH9vxW/8+JCkQRExVDbFQssdGxJd5vVqcZl3W5jKGdhlIvvur9u33l1pW8vext3lr+Fh98/0GxVSviouMY2HpgUXEhuU4yC9MXFlslYdHGRQdc6aJtg7Z0Te5K1+SudEnuQtdmXWlTvw3BUJD0nems37Ge9TvWs27HuhLvb8ne8rPzx0XH0TW5Kz1b9KRny570atmLDo06VNi2EhYVSmDglSTp0AWDsHLl/qWEtWtLPr9hQ+jWDbp2Df/s1g06diyfokJ1tWsXTJsWLi28/374e94DCQSgSRNo1mzvLTm5+OM9t6Qk+OEH+Oab8HYZe27Ll5f8GdHRcPTR+6++EBcHPXvCunVw9tnw73+X7zYVpVXTs11Nv35JkspFKAg7V+5dJWHrgnApYdcBwm1cQ2jQDep3Df9s0A3qdYRow+0BFeyCtdPCpYW09+Enf6svAAlNIKFZ+FarWbjAUXR/n5+xSZD1A2z7Jrxdxp7bjuUlf0YgGuoeHS4uNOgCSZ3DP6Pi4J2ekL0OWpwNJ/67fLepKKWanu1q+vVLkipOdn42T3zxBL///Pdk7MoAoF58PTJzM/c798j6R4ZLCyn96H9Ef45pckyJhYCy2rOFw6w1s5i5Ziaz181mYfpCCoL7l2I7NOpAr5a9im5dk7selt+UD4VCZOZmsmnXJgIEiI2OJTZqd/HgR/fL48+gKsnOz+ajHz7i7eVvM33Z9BILJCVJjE2kc9PO4VJCs3AxoXNy50MubuQU5BSVFtbvWM+6zN0lhp3h+4s2Lipx5Y2HBz3M7f1uP6TPLi2LCiUw8EqSVDbZ2bBoUfFSwoIFsHNnyee3a7e3jLCnmNCqVeXdTrcqWLMGnn8e1q/fv3iQnBwuKcQc4ra8WVnhLTr2FBe++Sb8v/OWA5Rzo6PD204ccwzMng2RilU1PdvV9OuXJKnMCrJh+6J9Sgnzw3+xXXCAcFun3d4ywp5iQqLh9pBkrYFVz0P2+hLKB8kQ3wSiDjHcFmSFt+jYthC2LoTt34QLKHkHCLeBaAgVQr1jYPBsiI1Mrqrp2a6mX78k6fDLK8zjn1/9k99+8ls27NwAwFENj+KBkx5g2HHDWJe5js/XfM7nqz/nszWfsTB94X7L8DdIaEDflL5F5YWeLXuSEHOAFZv2kVOQw7z185i1NlxMmLlmJulZ6fudl1w7mdRWqUWrJfRs2ZP6CfXL5fpVPkKhEMu2LAtvEbHsLT5e9TF5hXkckXTE3hUSdhcT2jVoV2ErGPx4xu+3fc8X677gi/XhrUPmbZjH6xe/ziltT6mQGSwqlMDAK0mKlNxc2LQJWrasvN9rbtxYvIwwfz4sXlzy1gLx8eHfrt+3lNClS+T+wlrlLxSCDRv2Fhf2lBi++w7y88NbbcyZA0cdFbkZa3q2q+nXL0mKoMJcyN0EtSpxuM1Oh20LipcSdiwpeWuBqPjw1gDFSgldIvYX1joMQiHI3rB71YV9VmDI/A6C+eGtNk6bA/UiF25rerar6dcvSdVBKBRi6eal/GfFf4iJiuH09qfTtkHbSI9FQbCAZxc8ywMfP8Cq7asAaJ3UmvtOvI/Lu15OzAFKkpm5mcxeO5vPVn/G52s+Z/ba2ezK31XsnLjoOHq06FG04kLflL40TmzM+h3rmblmZnjFhLUzmbd+HvnB/GKvjY2K5YTmJ9A3pS99WvUhtVUqKfVSCFTWfK0S7crfRV5hXqUvlBQGCwkROuA/7+XNokIJDLySpIq2YwdMnAjjx0NaGnToAMOGwcUXh38bPRIKC8NL/e+7bcOCBeG/lC5JkyZ7Cwl7SgkdOhz6b/GrasrLg2XLoHHj8IoOkVTTs11Nv35JUgTk74BlE2HxeMhJg3od4Ihh0PpiSIpQuA0Wws7lxQsJW+eH5ytJfJO9hYQ9pYR6HQ79t/hVNRXmwY5lEN8YakU23Nb0bFfTr1+Sqqrcglw+WfUJby59k+nLprNi64piz3ds3JGzjjqLs446i/5H9Cc2OrbCZguGgkxdNJX7PrqPZVuWAdCsTjPGDhjLNSdcU+btE/IL85mfNp/P13xeVF5I27l/5myc2LhoS4l9Na3dlL4pfenbqi99U/pyQvMTqBVb6+AuTqrkLCqUwMArSaoomzfDn/8Mjz8OW7eWfE6XLuHCwrBh0PYwlosLCuC99+D11+Hrr8O/Hb9r1/7nBQLh347/cSmhefPK+4tyqtlqerar6dcvSapAuZthyZ9h6eOQd4BwW79LuLDQehjUOYzhNlgAae/B2tdh69fh344vLCHcEoC6R+1fSqhluFXlVNOzXU2/fkmqSjbs2MBby97izWVv8t6K98jKzyp6Li46jhNbn0heYR6frf6MwlBh0XP14utxWrvTOOuoszij/Rkk1zk8JcFQKMS/l/ybez68h0UbFwHQqFYj7ux/Jzf0vIHE2MRy+5yVW1cWFRc+W/0Z32V8B0BUIIouyV3o06pPuJyQ0pcj6x/pagmqMSwqlMDAK0k63NavD6+eMHEiZO3O6EcfDXfeCb/4Bbz9NrzwAvznP+ECwR69eoVLC0OHhreHKA9LlsBTT8Gzz4bn2ldiYvGtG7p1Cz+uXbt8PluqCDU929X065ckVYBd68OrJyyfCAW7w23do+HYO6HVL2D927DqBdjwHwjtE24b9QqXFo4YConlFG4zl8DKp+D7ZyH7R+E2OrH41g0NuoUfxxhuVXXU9GxX069fkiqzYCjIl+u/ZPrS6UxfNp15G+YVe755nebhVROOPotBbQdRJ64OANtytvHuineZvmw6by97m027NhV7XY8WPYpWW+jeojtRgahDmjMUCvHuincZ++FYvlz/JQBJ8Unc1vc2bk69mbrxdQ/p/Utj867NrNi6gmMaH1MhnydVVhYVSmDglSQdLitXwv/7f+FiQF5e+Fi3bnDXXXD++RAdXfz8LVvgtdfCpYUPPoDg7q1yAwEYMCC8ysKFF0LTpmWbIzMTpk4NzzFr1t7jjRqFixADBoTnat9+/5mkqqamZ7uafv2SpMNo50r49v+FiwHB3eG2QTfodBe0Oh+ifhQkc7fA2tfCpYX0DyC0O9wSgKYDwttDHHEhJJQx3OZnwqqp4Tky9gm38Y3giIvD792gG9Rpv/9MUhVT07NdTb9+SapMQqEQ23K2MeP7GUxfNp23lr3FxqyNxc7p1bIXZx11FmcffTbdmnX72ZLBz5Udkmsnc8ZRZ3DWUWdxWrvTqBdftn8XfLLqE8Z+MJZPV38KQO3Y2tycejO39r2VhrUalum9JB06iwolMPBKksrbokXw+9+HCweFu1cy69cP7r4bTj+9dKvKpqfDyy+H3+Ozz/Yej4qCU04JFwzOOw8aNCj59cEgfPRRuJzwyiuQnb339WecASNGwJAhEBd3SJcqVTo1PdvV9OuXJB0G2xbBt78PFw72LNPbpB90uhualzLcZqfDmpfD77Fpn3AbiILkU8IrLaScB3EHCLehIKR/FC4nrHkFCrP3vr75GdB2BLQcAtGGW1UvlS3bTZgwgUceeYS0tDS6du3K448/Tq9evUo8Nz8/n3HjxvHMM8+wbt06OnTowMMPP8zpp59e6s+rbNcvSZXNluwtrM1cS05BTqlv2fnZ4fuFpX/NntuP1Y2ry2ntTuPso88ul20bNuzYwNvL32b6sum8u+JddubtLHouJiqGAUcMKFqloUOjDgfcMmHuurnc8+E9vLviXQDio+O5oecN3Nn/TprWLmNJVlK5sahQAgOvJKm8zJ0L48bBtGl7jw0eHC4oDBhw8O+7Zg28+GK4tPDll3uPx8aGiw8XXxzeQqJOHfjhB3j6aXjmmfD9PTp2DJcTLr8cmjc/+Fmkyq6mZ7uafv2SpHKUMRe+HQdrp+091nxwuKDQ9BDCbdYaWP1iuLSwZZ9wGxUbLj60vhha/gJi68DOH2Dl0/D9M5D1w95z63UMlxOOvBxqGW5VfVWmbDd16lSGDx/OxIkTSU1N5dFHH+Wll15iyZIlNC1h2b877riD5557jn/84x907NiR//znP4wePZqZM2dy/PHHl+ozK9P1S1IkFQYLWbp5KQvTF7IgfUHRz7WZayt8lqMaHsXZR5/NWUedxYDWA4g7TEXRvMI8Pl31KdOXhVdbWLp5abHn2zZoW7RFxIltTiQhJoGF6Qu558N7eH3J60C43HDN8dcwduBYWtYrp63HJB00iwolMPBKUtWUmQlr18K6deHbnvuxseEtDNq1C/9s0wbi4w/fHKFQeOWChx6C998PHwsEwls7jBkD3buX7+ctX763tPDNN3uP16oFxx4L8/ZZIa1evXCJYcQISE0t3S+7SVVdTc92Nf36JanKys+EXWth1zrIXrf3flQs1G0PddqFf9ZuA9GHOdxu/Aj++xCk7Q63BCDlfOg0BhqWc7jdsXxvaWHbPuE2uhYkHQtb9gm3sfXCJYa2I6CR4VY1Q2XKdqmpqfTs2ZO//OUvAASDQVJSUrjpppu488479zu/RYsW3H333dx4441Fxy644AJq1arFc889V6rPrEzXL0kVZWv21qIiwoK0BSzcuJBFGxeVuKIBQJPEJiTGJpIQk1CqW62YWqU/N7bWfq+tG1+3gv9EwpZvWV60RcTHqz4mrzCv6LnE2ES6JHdh9trZAEQFori8y+Xce+K9tG3QNiLzStpfWbJdTAXNJElSMcEgbNpUvHxQ0s+dO3/+vSD8/eURR+wtLuz7s1278CoEByMUgjffDBcUZoczMNHRcNllcMcdcMwxB/e+P6d9e7jrrvDtv/+FqVPh+efDBYZ588LXe8op4XLCuedCYuLhmUOSJEmlEApCzqa95YN9Swj7Pi4oZbglALWP2Ftc2PdnnXbhVQgOas4QrHszXFDYvDvcBqKhzWVw7B2QdJjCbd320Omu8G3bf2H1VPjhedi5fHdJIQDNTgmXE1qdCzGGWykS8vLymDdvHmPGjCk6FhUVxaBBg5g1a1aJr8nNzSUhIaHYsVq1avHZvnsblvCa3NzcoseZmZmHOLkkVV6FwUKWbVkWLiWkLShaKWFN5poSz0+MTaRz0850Te5Kl+QudG3Wlc5NO5OUkFTBk0dG+4btubn3zdzc+2Z25u3k/ZXvM33pdN5a/hbrd6wvKikM7TSUB056gI6NO0Z4YkmHwhUVJEkVYscOmDULPv00fJs7F7KzS/fa+vWhVSto2XLvz5wcWLEi/Bf3K1b8fKEhObnkEkP79tCw4f6/qFVYGF7RYNy4vSsaxMfDNdfAbbeFV3CoaKEQfP01LFgA//M/0Lp1xc8gVRY1PdvV9OuXpIjL3wEZs2Djp7DpU9g8FwpLGW5j60NiK0hsGf5ZqyUU5sDOFeGVB3au+PlCQ0JyySWGuu0hroRwGywMr2jw7bi9KxpExUO7a+CY26BOm7L+CRy6UAi2fg1bF0Cz/4HahlvVXJUl261fv56WLVsyc+ZM+vTpU3T89ttv5+OPP2bOnDn7vebSSy9lwYIFTJs2jXbt2jFjxgzOOeccCgsLi5UR9nX//ffzwAMP7Hc80tcvSYdqW862/QoJizYuIrug5JzYOqk1XZt1pUvTcCGha3JX2jZoS3RUdAVPXvmFQiEWpC9gzto59G7Vm67NukZ6JEkH4IoKkqSI27Rpbynh009h/vzwX/7vKxCAZs2KFxB+/LNlS6hd+6c/KxSCjRuLFxf2vZ+RAenp4dvMmfu/PimpeHkhKQn++c/w6yG8GsMNN8Att4TnjZRAAE44IXyTJElSBcrZFC4k7CkmbJ0PoR+FWwJQq1m4eLCngPDjQkJiS4gpRbjN2Vi8uLDv/dwMyEkP3zJKCLexScXLC3FJsPyf4dULAGLqwFE3QMdbwvNGSiAADU8I3yRVWY899hjXXnstHTt2JBAI0K5dO0aMGMGkSZMO+JoxY8YwevTooseZmZmkpKRUxLiSVC4Kg4Us37J879YNu0sJq7evLvH8WjG16Jy8zyoJyV3pnNyZ+gn1K3bwKiwQCNCtWTe6NesW6VEklSOLCpKkQxYKwapVxYsJixfvf17r1jBgQPjWvz8cdRTExh765wcC4RUTkpOhb9/9n9++vXhxYd+f69aFn//qq/BtXw0bwv/9H4waBQ0aHPqckiRJqgJCIchaVbyYkFlCuK3dGpoMgKYDoEl/qHsURJVTuK2VHL41KSHc5m0vXlzY92f2OsjfDlu/Ct/2FdcQOvwfdBgFcYZbSftr3Lgx0dHRpKenFzuenp5OswO09ps0acK0adPIyclh8+bNtGjRgjvvvJO2bQ+8V3h8fDzx8fHlOruk6qkgWMBby95iftp8gqEgexYIDxEiFAoRYvfj3fdLev5gXnOg53MKcvgu4zsWbVzErvxdJc7cOql1URlhz9YN7Rq0c5UESSqBRQVJUpkFg/Dtt8WLCWvX7n9ep057iwkDBkCkfkEiKenAKxFkZ8PKlcVXYVi3DgYOhOuuC6+mIEmSpGosFITt3xYvJuwqIdwmddqnmDAAakco3MYlHXglgoJs2Lmy+CoM2eugyUBofx3EGm4lHVhcXBzdu3dnxowZnHvuuQAEg0FmzJjBqFGjfvK1CQkJtGzZkvz8fF555RWGDh1aARNLqq42Zm3kn1/9k4lfTmRN5ppIj1OiWjG1OK7pcXRN7hreviG5C12Su7hKgiSVwUEVFSZMmMAjjzxCWloaXbt25fHHH6dXr14lnpufn8+4ceN45plnWLduHR06dODhhx/m9NNPLzqnpH3JOnTowOJ9fh03JyeHW2+9lRdeeIHc3FwGDx7ME088QXJy8sFcgiSpDPLzYd68vaWEzz+HLVuKnxMTA9277y0l9OsHjRpFZt6yqFUrXKjo1CnSk0iKFLOtJNUwwXzYMm9vKWHT55D3o3AbiIGG3feWEpr0g/gqEG5jakH9TuGbJB2E0aNHc8UVV9CjRw969erFo48+SlZWFiNGjABg+PDhtGzZknHjxgEwZ84c1q1bR7du3Vi3bh33338/wWCQ22+/PZKXIakKCoVCzF47mwlfTOClb18irzAPgEa1GvGLDr8gISaBAAECgQBA0f0Aux/vvl8ezx/oNTFRMRzV8Ci6JHehfcP2rpIgSYeozEWFqVOnMnr0aCZOnEhqaiqPPvoogwcPZsmSJTRt2nS/88eOHctzzz3HP/7xDzp27Mh//vMfzjvvPGbOnMnxxx9fdF6nTp14//339w4WU3y0W265henTp/PSSy+RlJTEqFGjOP/88/n888/LegmSpJ+RlQWzZu0tJsyeHV55YF+JidCnz95iQmoq1P6Z7XYlqbIx20pSDVCQBRmz9hYTMmZD4Y/CbXQiNO6zt5jQOBViDLeSap5hw4axadMm7r33XtLS0ujWrRvvvPNOUaF29erVREVFFZ2fk5PD2LFjWblyJXXq1OHMM8/k2WefpX79+hG6AklVza78XUz5ZgpPfPEEX6d9XXQ8tWUqN/S8gaGdhpIQkxDBCSVJh0sgtGeDnVJKTU2lZ8+e/OUvfwHCy3+lpKRw0003ceedd+53fosWLbj77ru58cYbi45dcMEF1KpVi+eeew4I/9bZtGnTmD9/fomfuX37dpo0acKUKVO48MILAVi8eDHHHHMMs2bNonfv3j87d2ZmJklJSWzfvp169eqV5ZIlqdpbtw7mzIGZM8PFhK++goKC4uc0agT9++8tJhx/PMSWwxa8knQwyivbmW0lqRratQ42z4FNM8PFhC1fQehH4Ta+ETTpv3u1hAHQ8HiIMtxKioyanu1q+vVLNdXyLct54osneGr+U2zL2QZAQkwClxx3CTf2vJHuLbpHdkBJ0kEpS7Yr04oKeXl5zJs3jzFjxhQdi4qKYtCgQcyaNavE1+Tm5pKQULztVqtWLT777LNix5YtW0aLFi1ISEigT58+jBs3jiOOOAKAefPmkZ+fz6BBg4rO79ixI0cccUSpv8yVJIXt3BnexmHOnL23dev2Py8lZW8pYeBA6NgR9vmlCUmq8sy2klQN5O8Mb+OweU74ljEHsksIt4kp4UJC0wHQdCDU6wgBw60kSVJFKgwW8tayt5jwxQT+s+I/RcfbNmjLyB4jGdFtBI0Sq8B2W5KkclGmokJGRgaFhYX77Z2bnJxcbM/dfQ0ePJjx48czcOBA2rVrx4wZM3j11VcpLCwsOic1NZWnn36aDh06sGHDBh544AEGDBjAokWLqFu3LmlpacTFxe23ZFhycjJpaWklfm5ubi65ublFjzMzM8tyqZJULRQWwnffFS8lLFoEwWDx86Ki4LjjoHfvveWE1q0jM7MkVRSzrSRVMcFCyPxubyFh8xzYvghCPwq3gShIOg4a995bTqhtuJUkSYqUjF0ZPPnVk0ycN5Eftv0AQIAAZxx1Bjf2vJHT259OlCVSSapxylRUOBiPPfYY1157LR07diQQCNCuXTtGjBjBpEmTis4544wziu536dKF1NRUWrduzYsvvsjVV199UJ87btw4HnjggUOeX5Kqkg0bipcSvvgivILCj7VqBampe28nnAB16lT8vJJU1ZhtJakCZW/YW0jYPAc2fwEFJYTbxFbQKDV8a5wKDU6AWMOtJElSpM1dN5cJX0xg6qKp5BaGy/cNazXkqm5XMbLnSNo2aBvhCSVJkVSmokLjxo2Jjo4mPT292PH09HSaNWtW4muaNGnCtGnTyMnJYfPmzbRo0YI777yTtm0P/C+g+vXrc/TRR7N8+XIAmjVrRl5eHtu2bSv2m2c/9bljxoxh9OjRRY8zMzNJSUkp7aVKUqWXlVV8C4e5c2HNmv3Pq10bevYsXkxo0aLi55WkysZsK0mVSEFWeAuHomLCXNhVQriNqQ0Ne4YLCXvKCYmGW0mSpMoiOz+bFxa9wBNfPsGX678sOt6jRQ9u7HkjwzoNo1ZsrQhOKEmqLMpUVIiLi6N79+7MmDGDc889F4BgMMiMGTMYNWrUT742ISGBli1bkp+fzyuvvMLQoUMPeO7OnTtZsWIFl19+OQDdu3cnNjaWGTNmcMEFFwCwZMkSVq9eTZ8+fUp8j/j4eOLj48tyeZJUaQWDJW/hsM9K40B4C4dOnYqXEo49FqKjIzO3JFVmZltJipBQELZ/t3elhIw9Wzj8KNwGoiCpU/HVEuodC1GGW0mSpMpm5daV/PWLvzJp/iS2ZG8BID46nmHHDePGnjfSq2WvCE8oSapsyrz1w+jRo7niiivo0aMHvXr14tFHHyUrK4sRI0YAMHz4cFq2bMm4ceMAmDNnDuvWraNbt26sW7eO+++/n2AwyO233170nrfddhtDhgyhdevWrF+/nvvuu4/o6GguueQSAJKSkrj66qsZPXo0DRs2pF69etx000306dOH3r17l8efgyRVKmlp+2/hsGPH/ue1aFG8lNC9O9StW/HzSlJVZbaVpAqQnba3kFC0hUMJ4bZWi72FhEap0LA7xBpuJUmSKqtgKMg7y99hwhcTeHvZ24QIAdA6qTUje4zk6hOupnFi4whPKUmqrMpcVBg2bBibNm3i3nvvJS0tjW7duvHOO++QnJwMwOrVq4mKiio6Pycnh7Fjx7Jy5Urq1KnDmWeeybPPPltsmdu1a9dyySWXsHnzZpo0aUL//v2ZPXs2TZo0KTrnT3/6E1FRUVxwwQXk5uYyePBgnnjiiUO4dEmqPIJBmDkTXnwR3ngDfvhh/3MSE6FHj+LFhFatKnxUSapWzLaSdBiEgrBpJqx+Eda9AVk/7H9OdCI06lF8tYREw60kSVJVsCV7C5O+nsRfv/wrK7euLDo+uN1gbux5I2cedSbRroIlSfoZgVAoFIr0EBUhMzOTpKQktm/fTr169SI9jiQVlRNeeglefhnWr9/7XCAQ3rJh31JCp04QU+Z6mSRVTzU929X065dUCRWVE16CNS9D9j7hlgAkHVt8tYSkThBluJUkMNvV9OuXqpJ56+cx4YsJPL/oeXIKcgCon1CfEd1GMLLHSI5qdFSEJ5QkRVpZsp3fCkhSBfqpckK9enDuuXDhhXDiieHHkiRJUqX1U+WE2HrQ6lxIuRCSTww/liRJUpWTU5DDi/99kQlfTGDuurlFx49vdjw39ryRSzpfQmJsYgQnlCRVVRYVJOkwCwZh1qzwtg6vvALr1u19rl49OOccGDoUTj0V4uMjN6ckSZL0s0JByJgFq16ENa9A9j7hNrYetDwHWg+FZqdCtOFWkiSpqvph2w9M/HIiT379JBm7MgCIjYplaKeh3NjzRnq36k0gEIjwlJKkqsyigiQdBnvKCXtWTiipnHDRRXDaaZYTJEmSVMntKSesfglWv1xyOeGIi6D5aZYTJEmSqrBgKMh7K95jwhcTeHPpm4QI7xyeUi+F63tczzUnXEPT2k0jPKUkqbqwqCBJ5SQYhNmzwysnWE6QJElSlRYKQsZsWP2i5QRJkqRqIhQKkZmbyebszWzetbnYz/Sd6bz47Yss37K86PxBbQdxY88bOfvos4mJ8q+TJEnly3+zSNIh2FNOeOml8G3fckLdusXLCQkJkZtTkiRJ+llF5YSXwrd9ywkxdaHVvuUEw60kSVIk5RfmsyV7S4mlg6Kf2ZvJ2JVR9HhL9hYKggU/+b714utxZdcruaHnDXRo3KGCrkaSVBNZVJCkMgoGYc6cvSsnrF279znLCZIkSapSQkHImBNeOWHNy7Brn3BrOUGSJOmwC4VC7Mzb+bOFgx8fy8zNPOjPrBVTi0aJjWhUq9Hen7UacULzE7ik8yXUiatTjlcoSVLJLCpIUinsKSfsWTnhx+WEX/wChg61nCBJkqQqoKic8BKseamEcsIv4IihlhMkSZLKwZbsLUz5ZgprM9cesHiQH8w/qPcOEKB+Qv0SSwf7HdvnZ2JsYjlfpSRJZWdRQZIOYN9ywssvw5o1e5+rU2fvygmDB1tOkCRJUiVXrJzwMuzaJ9zG1Nln5YTBlhMkSZLKwdbsrYyfNZ7H5jzGjrwdP3t+fHR8mQsHDRIaEB0VXQFXI0lS+bOoIEn7CIWKr5zw43LCnpUTLCdIkiSp0guFYPPucsLql/YvJ7T8BbQeajlBkiSpHG3L2cajsx/lT7P/VLQ9Q5fkLpzc5uSfLB4kxiYSCAQiPL0kSRXHooIkAYsXwz/+EV45YfXqvcf3lBP2rJxQq1bkZpQkSZJKZftiWPEPWP0y7Non3O4pJ+xZOSHGcCtJklRetuds57E5j/Gn2X9iW842ADo37cz9J93PuR3PJSoQFdkBJUmqZCwqSKrRQiGYMAFuuw1yc8PHLCdIkiSpSgqFYOkE+Po2CO4Ot5YTJEmSDqsduTv485w/88dZf2RrzlYAOjXpxH0n3scFx15gQUGSpAOwqCCpxtq8Ga6+Gv797/DjU0+FkSPh9NMtJ0iSJKmKyd0Mc66GtbvDbbNT4aiR0Px0ywmSJEmHwc68nTw+53H+MOsPbMneAsAxjY/hvhPv46JOF1lQkCTpZ1hUkFQjffIJ/PKXsHYtxMXBI4/ATTeB28BJkiSpytn4Ccz8JexaC1FxcPwjcLThVpIk6XDIystiwhcTeGTmI2TsygCgQ6MO3HvivQzrNIzoqOgITyhJUtVgUUFSjVJQAL/9LTz4IASDcPTR8MILcPzxkZ5MkiRJKqNgASz6Lfz3QQgFoe7R0O8FaGi4lSRJKm+78nfx1y/+ysOfP8ymXZsAaN+wPfedeB+XHHeJBQVJksrIooKkGmPNmvAqCp9+Gn585ZXw+ONQp05Ex5IkSZLKLmtNeBWFTbvDbdsrofvjEGu4lSRJKk/Z+dn8bd7f+P1nvyc9Kx2Atg3acu/Ae/lll18SE+Vfs0iSdDD8N6ikGuG11+Dqq2HrVqhbFyZOhEsvjfRUkiRJ0kFY8xrMuRrytkJMXeg1EdoYbiVJkspTTkEOf5/3d37/2e/ZsHMDAG3qt+GegfdweZfLiY2OjfCEkiRVbRYVJFVr2dlw223wxBPhxz17wvPPQ7t2kZ1LkiRJKrOCbPj6Nli2O9w27An9noe6hltJkqTykluQyz+/+icPffYQ63esB+CIpCO4Z+A9XNH1CgsKkiSVE4sKkqqtb7+Fiy+Gb74JP/71r+G3v4W4uMjOJUmSJJXZ9m/h84th2+5we8yvoctvIdpwK0mSVB5yC3KZ9PUkHvrsIdZmrgUgpV4Kdw+4mxHHjyDO3CVJUrmyqCCp2gmF4J//hJtvDq+o0LQp/OtfMHhwpCeTJEmSyigUghX/hHk3Q2E2JDSF3v+CFoZbSZKk8pBXmMfT85/mt5/8ljWZawBoWbcldw+4m6uOv4r4mPgITyhJUvVkUUFStbJtG1x3Hbz0UvjxqaeGSwrNmkV0LEmSJKns8rbB3Otg9e5w2+xU6PMvqGW4lSRJOlT5hfn8a8G/ePCTB1m1fRUAzes0564Bd3HNCdeQEJMQ4QklSareLCpIqjZmzYJLLoFVqyAmBh56CG69FaKiIj2ZJEmSVEabZsHMSyBrFQRioOtDcMytEDDcSpIkHYqCYAHPLniW3376W1ZuXQlAszrNuLPfnVzX/TpqxdaK8ISSJNUMFhUkVXnBIDz8MNxzDxQWQtu28Pzz0KtXpCeTJEmSyigUhG8fhoX3QKgQ6rSFvs9DY8OtJEnSoSgIFjDlmyn85uPfsGLrCgCa1m7Knf3u5H97/C+JsYkRnlCSpJrFooKkKm39ehg+HGbMCD++5BKYOBHq1YvsXJIkSVKZ7VoPs4ZD+u5w2/oS6DURYg23kiRJB6swWMjzi57nNx//hmVblgHQJLEJt/e7nZE9RlI7rnaEJ5QkqWayqCCpynrrLbjiCsjIgMRE+Mtf4MorIRCI9GSSJElSGa17C2ZfAbkZEJ0IPf4Cba803EqSJB2kwmAhL/73RX7zyW9YnLEYgEa1GvHrvr/mxl43UieuToQnlCSpZrOoIKnKyc2FMWPgT38KP+7aFV54ATp2jOxckiRJUpkV5sL8MbBkd7it3xX6vQBJhltJkqSDEQwFefnbl7n/o/v5LuM7ABokNOC2vrdxU6+bqBtfN8ITSpIksKggqYpZtgwuvhi++ir8+Fe/gocfhoSEyM4lSZIklVnmMvj8Yti6O9we/Ss4/mGINtxKkiSVVTAU5NXvXuWBjx9g0cZFANRPqM+tfW7lV6m/ol6822lJklSZWFSQVGU8+yzccAPs3AmNGsFTT8GQIZGeSpIkSToI3z8LX9wABTshvhGkPgWtDLeSJEllFQqFmLZ4Gvd/fD8L0xcCkBSfxC29b+H/ev8fSQlJEZ5QkiSVxKKCpEpvx45wQeG558KPTzwRJk+Gli0jO5ckSZJUZvk7wgWFH3aH26YnQt/JkGi4lSRJKotQKMTrS17n/o/vZ37afADqxtXllt63cEufW6ifUD+i80mSpJ9mUUFSpTZvXnirh+XLISoK7r8f7roLoqMjPZkkSZJURlvmwWcXw87lEIiC4+6HTndBlOFWkiSptEKhENOXTef+j+5n3oZ5ANSJq8PNqTczus9oGtZqGOEJJUlSaVhUkFQpBYPwpz/BmDGQnw9HHAFTpkC/fpGeTJIkSSqjUBAW/wkWjIFgPiQeAf2mQBPDrSRJUmmFQiHeXv429390P1+s/wKA2rG1uanXTdza91YaJzaO8ISSJKksLCpIqnQ2boQrroB33gk/Pv98+Oc/oUGDyM4lSZIklVnORph1BWzYHW5TzofUf0Kc4VaSJKm0Vm1bxfBpw/lk1ScAJMYmMqrnKG7rextNajeJ8HSSJOlgWFSQVKm8/z5cfjmkpUFCQnhVhf/9XwgEIj2ZJEmSVEZp78PMyyEnDaIT4IQ/QXvDrSRJUllMWzyNEf8ewbacbdSKqcUNPW/g9n6307R200iPJkmSDoFFBUmVQn4+3HsvPPwwhEJw7LEwdSocd1ykJ5MkSZLKKJgPC++Fbx8GQpB0LPSbCvUNt5IkSaWVW5DLHe/fwWNzHgOgV8tevHDBCxzZ4MgITyZJksqDRQVJEff993DJJTBnTvjx//4vjB8PiYmRnUuSJEkqs53fw+eXwObd4bb9/8IJ4yHGcCtJklRaK7asYNjLw5i3YR4At/a5lYdOeYi46LgITyZJksqLRQWpmliwAB58EPLyoEkTaNw4fNtzf99j9epVntVmp06F666DzEyoXx/+8Q+48MJITyVJkqSI2roAFj0IwTyIbwLxjcO3hD339zkWW4nC7aqpMPc6yM+E2PqQ+g84wnArSZJUFi/+90WufeNaMnMzaVirIU+f8zRDOgyJ9FiSJKmcWVSQqoEXX4QRI2DXrtKdHxu7f5HhQKWGJk2gUSOIjy/fmbOy4Oab4cknw4/79oUpU6B16/L9HEmSJFUxq16E2SOgsJThNip2b2lh3wLDnvsJPz7WCKLLOdwWZMG8m2HF7nDbuC/0mwK1DbeSJEmllZ2fzej/jGbivIkA9Evpx/MXPE9KUkqEJ5MkSYeDRQWpCisshHvugXHjwo9POw0uuAAyMsK3TZv2v5+VBfn5sGFD+FZadeuWrtSw5379+hAVVfJ7LVwIw4bB4sXhX3676y64/36I8f+RJEmSaq5gISy8B77dHW6bnQZHXAC5GZCTAbmbwvdz97lfkAXBfMjeEL6VVkzdEgoMJZUadt+Pqw+BA4TbrQvh82GQuRgIQKe7oPP9EGW4lSRJKq0lGUsY+vJQFqYvBGBM/zE8cNIDxEbHRngySZJ0uPjNiVRFbd8Ol14Kb70VfvzrX4cLC9HRP/267OyfLjL8+H5GRrgQsWNH+LZyZenmi44Or8Tw41JDbCz8/e+QmwvNm8Nzz8H//M+h/VlIkiSpisvbDjMvhfW7w+0xv4au4yDqZ8JtQfb+5YXcDMgpodSw5xYqhIIdsHMH7CxluA1Eh1diKFZgaBJezWH53yGYC7WaQ5/noJnhVpIkqSyeW/gc1795PVn5WTRJbMKz5z3L4PaDIz2WJEk6zCwqSFXQ4sVwzjmwdCkkJIS3T7j00tK9tlYtSEkJ30ojGAyXIvYtMPxcwSEzM1xu2LgxfCvJ2WfDU0+FCwySJEmqwbYvhk/OgR1LIToBUp+ENqUMtzG1ICYFapcy3IaCkL/9Rys0/EzBIT8zXG7I2Ri+laTF2dD7KUgw3EqSqr4JEybwyCOPkJaWRteuXXn88cfp1avXAc9/9NFH+etf/8rq1atp3LgxF154IePGjSMhIaECp1ZVtCt/Fze9dROT5k8C4KQ2JzH5/Mm0qNsiwpNJkqSKYFFBqmLefBN++ctwGSAlBV57Dbp3P3yfFxUFDRqEb0cdVbrX5OUVX5Hhxys09OgBw4eHt32QJElSDbbuTZj5y3AZIDEFBr4GDQ9juA1EQVyD8I1ShtvCvOIrMvx4hYaGPeBIw60kqXqYOnUqo0ePZuLEiaSmpvLoo48yePBglixZQtOmTfc7f8qUKdx5551MmjSJvn37snTpUq688koCgQDjx4+PwBWoqvjvxv8y9OWhfLvpWwIEuPfEe7ln4D1E/9yKWpIkqdqwqCBVEaFQeGuHsWPD9wcMgJdfhhL+GzHi4uKgRYvwTZIkSdpPKATfjoMFY4EQNBkAA16GhEoYbqPjILFF+CZJUjU3fvx4rr32WkaMGAHAxIkTmT59OpMmTeLOO+/c7/yZM2fSr18/Lt291GebNm245JJLmDNnToXOraojFArx1PynGPXWKLILsmlWpxmTz5/M/xzp9lmSJNU0UZEeQNLPy8qCYcPg7rvD3+mOHAnvv185SwqSJEnSTyrIgs+HwYK7gRAcNRL+5/3KWVKQJKkGycvLY968eQwaNKjoWFRUFIMGDWLWrFklvqZv377MmzePuXPnArBy5UreeustzjzzzAqZWVXLjtwdXP7a5Vz9+tVkF2RzattTmf+/8y0pSJJUQ7miglTJff89nHsuLFwIsbEwYQJce22kp5IkSZIOws7v4ZNzYdtCiIqFHhOgveFWkqTKICMjg8LCQpKTk4sdT05OZvHixSW+5tJLLyUjI4P+/fsTCoUoKCjg+uuv56677jrg5+Tm5pKbm1v0ODMzs3wuQJXagrQFDH15KEs3LyU6EM2DJz/IHf3vICrg71JKklRTHVQKmDBhAm3atCEhIYHU1NSixmxJ8vPz+c1vfkO7du1ISEiga9euvPPOO8XOGTduHD179qRu3bo0bdqUc889lyVLlhQ756STTiIQCBS7XX/99QczvlRlfPAB9OwZLikkJ8OHH1pSkCSpvJltpQqS9gH8p2e4pJCQDKd8aElBkqQq7qOPPuKhhx7iiSee4KuvvuLVV19l+vTpPPjggwd8zbhx40hKSiq6paSkVODEqmihUIiJX04k9Z+pLN28lJZ1W/LRlR8xZsAYSwqSJNVwZU4CU6dOZfTo0dx333189dVXdO3alcGDB7Nx48YSzx87dix/+9vfePzxx/n222+5/vrrOe+88/j666+Lzvn444+58cYbmT17Nu+99x75+fmcdtppZGVlFXuva6+9lg0bNhTd/t//+39lHV+qEkIh+POf4bTTYPNm6NEDvvwS+vWL9GSSJFUvZlupAoRCsOTP8OFpkLsZGvaA07+EJoZbSZIqk8aNGxMdHU16enqx4+np6TRr1qzE19xzzz1cfvnlXHPNNXTu3JnzzjuPhx56iHHjxhEMBkt8zZgxY9i+fXvRbc2aNeV+Laoctuds5+JXLmbk9JHkFuZy1lFnMf/6+fQ/on+kR5MkSZVAmYsK48eP59prr2XEiBEce+yxTJw4kcTERCZNmlTi+c8++yx33XUXZ555Jm3btmXkyJGceeaZ/PGPfyw655133uHKK6+kU6dOdO3alaeffprVq1czb968Yu+VmJhIs2bNim716tUr6/hSpZeTA1ddBTffDIWFcPnl8Mkn0KpVpCeTJKn6MdtKh1lhDsy5CubdDKFCaHM5DPoEEg23kiRVNnFxcXTv3p0ZM2YUHQsGg8yYMYM+ffqU+Jpdu3YRFVX8K+bo6Ggg/Jv0JYmPj6devXrFbqp+vlz/JSf8/QRe/O+LxETF8IdT/8Drl7xO48TGkR5NkiRVEmUqKuTl5TFv3jwGDRq09w2iohg0aBCzZs0q8TW5ubkkJCQUO1arVi0+++yzA37O9u3bAWjYsGGx45MnT6Zx48Ycd9xxjBkzhl27dh3wPXJzc8nMzCx2kyq79evhpJPg6achKgrGj4dnnoFatSI9mSRJ1Y/ZVjrMdq2H90+ClU9DIApOGA99noEYw60kSZXV6NGj+cc//sEzzzzDd999x8iRI8nKymLEiBEADB8+nDFjxhSdP2TIEP7617/ywgsv8P333/Pee+9xzz33MGTIkKLCgmqWUCjEn+f8mb5P9mXl1pW0TmrNpyM+5da+t7rVgyRJKiamLCdnZGRQWFhIcnJysePJycksXry4xNcMHjyY8ePHM3DgQNq1a8eMGTN49dVXKSwsLPH8YDDI//3f/9GvXz+OO+64ouOXXnoprVu3pkWLFixcuJA77riDJUuW8Oqrr5b4PuPGjeOBBx4oy+VJETVrFpx/PqSlQYMGMHUqnHpqpKeSJKn6MttKh9GmWfDp+ZCTBnENoN9UaG64lSSpshs2bBibNm3i3nvvJS0tjW7duvHOO+8UZebVq1cXW0Fh7NixBAIBxo4dy7p162jSpAlDhgzhd7/7XaQuQRG0JXsLV/37Kv695N8AnNfxPJ78xZM0qNUgwpNJkqTKKBA60BpcJVi/fj0tW7Zk5syZxZb7uv322/n444+ZM2fOfq/ZtGkT1157LW+88QaBQIB27doxaNAgJk2aRHZ29n7njxw5krfffpvPPvuMVj+x1v0HH3zAKaecwvLly2nXrt1+z+fm5pKbm1v0ODMzk5SUFLZv3+5yYqp0Jk2CkSMhLw+OOw6mTYMS/rGWJEm7ZWZmkpSUdEjZzmwrHSYrJsEXIyGYB0nHwcBpUNdwK0nSgZRHtq3Kavr1Vxez185m2MvDWL19NXHRcfzxtD9yY88bCQQCkR5NkiRVoLJkuzKttdS4cWOio6NJT08vdjw9PZ1mzZqV+JomTZowbdo0srKyWLVqFYsXL6ZOnTq0bdt2v3NHjRrFm2++yYcffviTX+QCpKamArB8+fISn3evM1UF+flw001w9dXhksL554dXVrCkIEnS4We2lcpZMB++vAnmXB0uKaScD6fNsqQgSZJUjQVDQR75/BEGPDWA1dtX065BO2ZeNZNRvUZZUpAkST+pTEWFuLg4unfvzowZM4qOBYNBZsyYUey30EqSkJBAy5YtKSgo4JVXXuGcc84pei4UCjFq1Chee+01PvjgA4488sifnWX+/PkANG/evCyXIFUamzbBaafBX/4Sfvyb38BLL0GdOpGdS5KkmsJsK5WjnE3wwWmwdHe47fwb6P8SxBpuJUmSqquMXRkMeX4It79/OwXBAoZ1GsZX//sV3Vt0j/RokiSpCogp6wtGjx7NFVdcQY8ePejVqxePPvooWVlZjBgxAoDhw4fTsmVLxo0bB8CcOXNYt24d3bp1Y926ddx///0Eg0Fuv/32ove88cYbmTJlCv/+97+pW7cuaWlpACQlJVGrVi1WrFjBlClTOPPMM2nUqBELFy7klltuYeDAgXTp0qU8/hykCjV/Ppx7LqxaFS4mPPcc7PP3G5IkqYKYbaVysHU+fHIuZK2CmDrQ9zloZbiVJEmqzj5Z9QmXvnIp63asIz46nj+f8WeuPeFaV1GQJEmlVuaiwrBhw9i0aRP33nsvaWlpdOvWjXfeeYfk5GQAVq9eTVTU3oUacnJyGDt2LCtXrqROnTqceeaZPPvss9SvX7/onL/+9a8AnHTSScU+66mnnuLKK68kLi6O999/v+iL45SUFC644ALGjh17EJcsRdbUqTBiBGRnQ/v28O9/w7HHRnoqSZJqJrOtdIhWTYXZI6AwG+q0hxP/DUmGW0mSpOqqMFjIuM/Gcd9H9xEMBenQqAMvXvQiXZItXUuSpLIJhEKhUKSHqAiZmZkkJSWxfft29/RVRBQWwtix8Pvfhx8PHgzPPw8NGkR2LkmSqqKanu1q+vWrEggWwsKx8O3ucNt8MPR7HuIMt5IklVVNz3Y1/fqrkvSd6Vz22mW8v/J9AC7vcjlPnPUEdeLc7kuSJIWVJduVeUUFSWW3bRtceim8/Xb48a9/DePGQXR0RMeSJEmSyi5vG3x+KWzYHW6P+TV0HQdRhltJkqTqasbKGfzy1V+SnpVOYmwiE86cwJXdroz0WJIkqQqzqCAdZt99B+eeC0uXQkICPPlkuLQgSZIkVTnbv4NPzoUdSyE6AVKfhDaGW0mSpOqqMFjIbz7+DQ9+8iAhQnRq0okXL3qRY5u43ZckSTo0FhWkw+iNN+CXv4QdOyAlBaZNgxNOiPRUkiRJ0kFY+wbM/CUU7IDEFBg4DRoabiVJkqqr9TvWc+krl/Lxqo8BuOb4a3jsjMdIjE2M8GSSJKk6sKggHQahEDz0ENxzT/j+gAHw8svQtGmkJ5MkSZLKKBSC/z4EC+8BQtBkAAx4GRIMt5IkSdXVO8vf4fLXLidjVwZ14urwt7P/xqWdXUlLkiSVH4sKUjnbuRNGjAgXEwBGjoRHH4W4uIiOJUmSJJVd/k6YPQLW7A63R42EEx6FaMOtJElSdZRfmM89H97Dw58/DEC3Zt2YeuFUjm50dIQnkyRJ1Y1FBakcff89nHMOfPMNxMbChAlw7bWRnkqSJEk6CDu/h0/OgW3fQFQs9JgA7Q23kiRJ1dXq7au55JVLmLlmJgA39LiBPw7+IwkxCRGeTJIkVUcWFaRyMmMGDB0KW7ZAcjK88gr06xfpqSRJkqSDkDYDPhsKeVsgIRkGvAJNDLeSJEnV1etLXufKaVeyNWcr9eLr8eQvnuTCYy+M9FiSJKkas6ggHaJQCP78Z7j1VigshB494LXXoFWrSE8mSZIklVEoBEv+DF/fCqFCaNgDBr4GiYZbSZKk6iivMI8737+TP83+EwA9WvRg6oVTadugbYQnkyRJ1Z1FBekQ5OTA9dfDM8+EH19+Ofztb1CrVmTnkiRJksqsMAfmXg/f7w63bS6HXn+DGMOtJElSdfT91u8Z9vIwvlj/BQD/l/p/PHzqw8RFx0V4MkmSVBNYVJAO0rp1cP75MHcuREXBH/4A//d/EAhEejJJkiSpjHatg0/Ph81zIRAFx/8BOvyf4VaSJKmaevnbl7nm9WvYnrudBgkNePrcp/lFh19EeixJklSDWFSQDsKsWeGSQloaNGgAL74IgwZFeipJkiTpIGyaFS4p5KRBXAPo/yI0M9xKkiRVRzkFOdz6n1t54ssnAOjTqg8vXPgCRyQdEeHJJElSTWNRQSqjJ5+EG26AvDw47jiYNg3atYv0VJIkSdJBWPEkfHEDBPMg6TgYOA3qGm4lSZKqo2WblzH05aHMT5sPwB397uDBkx8kNjo2soNJkqQayaKCVEr5+XDLLTBhQvjx+efDM89AnTqRnUuSJEkqs2A+zLsFlu0OtynnQ+9nINZwK0mSVB09/83zXPfmdezM20njxMY8e96znN7+9EiPJUmSajCLClIpbNoEF10EH38cfvyb38Ddd0NUVGTnkiRJksosZxN8dhFs3B1uO/8GjrsbAoZbSZKk6mZX/i5ufvtm/vn1PwEY2HogU86fQst6LSM8mSRJquksKkg/4+uv4dxzYfVqqFsXnnsOfvGLSE8lSZIkHYQtX8Mn58Ku1RBTF/o+B60Mt5IkSdXRd5u+Y+jLQ1m0cREBAowdOJZ7T7yXmCj/WkCSJEWeiUT6CS+8AFddBdnZ0L49/PvfcOyxkZ5KkiRJOgg/vABzroLCbKjTHk78NyQZbiVJkqqj3IJcTvnXKWzYuYHk2slMPn8yp7Q9JdJjSZIkFbGoIJWgsDC8tcPDD4cfn346TJkCDRpEdi5JkiSpzIKFsPBu+HZ3uG1+OvSbAnGGW0mSpOrq67Sv2bBzAw1rNWT+9fNpVqdZpEeSJEkqxqKC9CPbtsGll8Lbb4cf3347PPQQREdHdCxJkiSp7PK2weeXwobd4faY26HrQxBluJUkSarOZq2ZBUC/lH6WFCRJUqVkUUHax7JlcPbZsHQpJCTApElwySWRnkqSJEk6CJnL4OOzYcdSiE6A1EnQxnArSZJUE8xaGy4q9GnVJ8KTSJIklcyigrTbJ5/AeefBli2QkgLTpsEJJ0R6KkmSJOkgbPwEPjkP8rZAYgoMnAYNDbeSJEk1xey1swHok2JRQZIkVU5RkR5Aqgz+9S8YNChcUujZE+bOtaQgSZKkKmrlv+CDQeGSQsOeMHiuJQVJkqQaZF3mOtZkriEqEEWPFj0iPY4kSVKJLCqoRgsG4Z574IorID8fLrwQPvoImrltmyRJkqqaUBAW3AOzr4BgPqRcCIM+glqGW0mSpJpkz7YPXZK7UCeuToSnkSRJKplbP6jGysmBK6+EqVPDj++8E373O4iyviNJkqSqpjAHZl0Jq3eH22PvhK6/g4DhVpIkqaYp2vahlds+SJKkysuigmqkjRvh3HNh1iyIiYG//Q2uuirSU0mSJEkHIWcjfHIuZMyCQAz0+hu0M9xKkiTVVHtWVOjdqneEJ5EkSTowiwqqcb79Fs46C374AerXh1dfhZNPjvRUkiRJ0kHY/i18dBZk/QCx9WHgq5BsuJUkSaqp8grzmLd+HuCKCpIkqXKzqKAa5b334MILITMT2rWD6dOhQ4dITyVJkiQdhA3vwWcXQn4m1GkHJ02HeoZbSZKkmmx+2nxyC3NpVKsR7Ru2j/Q4kiRJB+SGpaox/v53OOOMcEmhXz+YPduSgiRJkqqo5X+Hj84IlxSa9IPTZltSkCRJErPW7N32IRAIRHgaSZKkA7OooGqvsBBuuw3+93/D93/5S5gxAxo3jvRkkiRJUhkFC+Gr22Du/0KoENr8Ev5nBiQYbiVJkgSz1oaLCm77IEmSKju3flC1lpUFl10G06aFHz/wANxzD1gmliRJUpVTkAUzL4O108KPOz8AxxluJUmStNfstbMB6JNiUUGSJFVuFhVUba1fD0OGwFdfQVwcPPUUXHpppKeSJEmSDsKu9fDxENj6FUTFQe+noI3hVpIkSXtt2LGBVdtXERWIomeLnpEeR5Ik6SdZVFC1NH8+nH02rFsX3uJh2jTo1y/SU0mSJEkHYet8+OhsyF4H8Y1h4DRoYriVJElScXu2fTiu6XHUja8b4WkkSZJ+mkUFVTvTp8OwYeFtHzp2hDffhHbtIj2VJEmSdBDWTYfPh4W3fajXEU58E+oabiVJkrS/om0fWrntgyRJqvyiIj2AVF5CIfjzn+EXvwiXFP7nf2DmTEsKkiRJqoJCIVjyZ/jkF+GSQvL/wGkzLSlIkiTpgPasqNC7Ve8ITyJJkvTzLCqoWigogJtugptvhmAQrr4a3nkHGjSI9GSSJElSGQUL4MubYN7NEApCu6vh5HcgznArSZKkkuUV5vHl+i8BV1SQJElVg1s/qMrLzISLL4a334ZAAB5+GG67LXxfkiRJqlLyM+Gzi2HD20AAuj0MxxhuJUmS9NMWpi8kpyCHBgkNOLrR0ZEeR5Ik6WdZVFCVtno1nH02fPMN1KoFzz0H558f6akkSZKkg5C1Gj4+G7Z9A9G1oO9zkGK4lSRJ0s+btWbvtg8BS66SJKkKsKigKuuLL2DIEEhPh2bN4PXXoWfPSE8lSZIkHYTNX8DHQyAnHRKawYmvQyPDrSRJkkpn1tpwUcFtHyRJUlURFekBpIPxyitw4onhkkLnzjBnjiUFSZIkVVGrX4H3TwyXFOp3hsFzLClIkiSpTGavnQ1AnxSLCpIkqWqwqKAqJRSChx+GCy+E7Gw44wz4/HM44ohITyZJkiSVUSgE3z4Mn10IhdnQ/Aw49XOobbiVJElS6aXvTOf7bd8TIECvlr0iPY4kSVKpuPWDqoy8PLjhBnjyyfDjUaPgT3+CGP8pliRJUlVTmAdf3gArdofbo0fBCX+CKMOtJEmSymbPtg+dmnaiXny9CE8jSZJUOn4Lpiph61a44AL48EOIioJHH4Wbbor0VJIkSdJByNsKn14A6R9CIApOeBQ6GG4lSZJ0cIq2fWjltg+SJKnqsKigSm/FCjjrLFiyBOrUgRdeCD+WJEmSqpwdK+DjsyBzCcTUgX4vQEvDrSRJkg7enhUVerfqHeFJJEmSSi/qYF40YcIE2rRpQ0JCAqmpqcydO/eA5+bn5/Ob3/yGdu3akZCQQNeuXXnnnXfK/J45OTnceOONNGrUiDp16nDBBReQnp5+MOOrCvnsM0hNDZcUWrUKP7akIEmSypPZVhVm42fwbmq4pJDYCk79zJKCJEmqdMqSj0866SQCgcB+t7P8Aq/C5Bfm88W6LwBXVJAkSVVLmYsKU6dOZfTo0dx333189dVXdO3alcGDB7Nx48YSzx87dix/+9vfePzxx/n222+5/vrrOe+88/j666/L9J633HILb7zxBi+99BIff/wx69ev5/zzzz+IS1ZVMXkynHIKbN4M3bvD3LnQtWukp5IkSdWJ2VYV5vvJ8MEpkLsZGnaHwXOhgeFWkiRVLmXNx6+++iobNmwoui1atIjo6GguuuiiCp685vpm4zdkF2RTP6E+HRp3iPQ4kiRJpRYIhUKhsrwgNTWVnj178pe//AWAYDBISkoKN910E3feeed+57do0YK7776bG2+8sejYBRdcQK1atXjuuedK9Z7bt2+nSZMmTJkyhQsvvBCAxYsXc8wxxzBr1ix69/75Ja0yMzNJSkpi+/bt1KtXryyXrAoWCsEDD4RvAOedB88+C7VrR3YuSZJUeZRXtjPb6rALheCbB2DR7nDb6jzo+yzEGG4lSVJYZcp2Zc3HP/boo49y7733smHDBmqX8su8ynT9VdGEuRMY9fYoBrcbzDuX7b/amyRJUkUqS7Yr04oKeXl5zJs3j0GDBu19g6goBg0axKxZs0p8TW5uLgkJCcWO1apVi88++6zU7zlv3jzy8/OLndOxY0eOOOKIn/zczMzMYjdVfjk5cNlle0sKt98OL79sSUGSJJU/s60Ou8IcmHnZ3pLCMbfDgJctKUiSpErpYPLxjz355JNcfPHFpS4p6NDNWhv+38ZtHyRJUlVTpqJCRkYGhYWFJCcnFzuenJxMWlpaia8ZPHgw48ePZ9myZQSDQd57772iJcFK+55paWnExcVRv379Un/uuHHjSEpKKrqlpKSU5VIVAZs2waBBMGUKxMTA3/8ODz8MUWXeoESSJOnnmW11WOVsgg8GwaopEIiBXn+H4x+GgOFWkiRVTgeTj/c1d+5cFi1axDXXXPOT51nCLV+z184GoE+KRQVJklS1HPZvyR577DGOOuooOnbsSFxcHKNGjWLEiBFEHea/fR4zZgzbt28vuq1Zs+awfp4OzeLF0Ls3fP45JCXB22/DtddGeipJkqTizLYqle2L4d3esOlziE2Ck9+G9oZbSZJUvT355JN07tyZXr16/eR5lnDLz8asjazYugKAXi1/+s9dkiSpsinTN6qNGzcmOjqa9PT0YsfT09Np1qxZia9p0qQJ06ZNIysri1WrVrF48WLq1KlD27ZtS/2ezZo1Iy8vj23btpX6c+Pj46lXr16xmyqnDz6APn1g5Uo48kiYNSu8soIkSdLhZLbVYZH2AbzbB3auhNpHwmmzoJnhVpIkVX4Hk4/3yMrK4oUXXuDqq6/+2c+xhFt+9qymcGyTY6mfUD+yw0iSJJVRmYoKcXFxdO/enRkzZhQdCwaDzJgxgz59fnppqYSEBFq2bElBQQGvvPIK55xzTqnfs3v37sTGxhY7Z8mSJaxevfpnP1eV25NPwuDBsG0b9O0Lc+bAMcdEeipJklQTmG1V7lY8CR8Ohvxt0LgvDJ4DSYZbSZJUNRxKPn7ppZfIzc3lsssu+9nPsYRbfoq2fWjlf0dIkqSqJ6asLxg9ejRXXHEFPXr0oFevXjz66KNkZWUxYsQIAIYPH07Lli0ZN24cAHPmzGHdunV069aNdevWcf/99xMMBrn99ttL/Z5JSUlcffXVjB49moYNG1KvXj1uuukm+vTpQ+/evcvjz0EVLBiEu+6Chx8OP77kEpg0CRISIjuXJEmqWcy2KhehICy4C77dHW5bXwK9J0G04VaSJFUtZc3Hezz55JOce+65NGrUKBJj11iz1s4CoHcr/ztCkiRVPWUuKgwbNoxNmzZx7733kpaWRrdu3XjnnXdITk4GYPXq1cX26M3JyWHs2LGsXLmSOnXqcOaZZ/Lss89Sv379Ur8nwJ/+9CeioqK44IILyM3NZfDgwTzxxBOHcOmKlF27YPhweOWV8ON774X774dAIKJjSZKkGshsq0NWsAtmDYc1u8PtcfdC5/sNt5IkqUoqaz6G8Opgn332Ge+++24kRq6xCoIFzF03F3BFBUmSVDUFQqFQKNJDVITMzEySkpLYvn27y4lF0IYNcM458MUXEBcX3vqhFCvCSZIkFVPTs11Nv/5KI3sDfHwObPkCouIg9Uk40nArSZLKpqZnu5p+/Qdrftp8jv/b8dSLr8fWO7YSFSjTLs+SJEmHRVmyXZlXVJAO1jffwFlnwZo10KgRvPYaDBgQ6akkSZKkg7DtG/joLNi1BuIbwYDXoKnhVpIkSRVj1prwtg+pLVMtKUiSpCrJooIqxNtvw7BhsGMHHH00TJ8O7dtHeipJkiTpIKx/Gz4bBgU7oO7RcNJ0qGu4lSRJUsWZtTZcVHDbB0mSVFVZtdRhN2ECnH12uKRw8skwa5YlBUmSJFVRSyfAx2eHSwrJJ8NpsywpSJIkqcLNXjsbgD4pFhUkSVLVZFFBh01hIdx8M4waBcEgjBgB77wDDRtGejJJkiSpjIKF8OXN8OUoCAWh7Qg46R2IN9xKkiSpYmXsymDZlmVAeOsHSZKkqsitH3RY7NgBl1wS3uIBYNw4uOMOCAQiO5ckSZJUZvk74PNLYP3ucNt1HBxruJUkSVJk7FlNoWPjjjSo1SDC00iSJB0ciwoqd2vWwJAhsGABJCTAs8/ChRdGeipJkiTpIGStgY+HwLYFEJ0AfZ6FIwy3kiRJipyibR9aue2DJEmquiwqqFzNmxcuKWzYAMnJ8Prr0KtXpKeSJEmSDsKWeeGSQvYGSEiGga9DY8OtJEmSImvW2lkA9G7VO8KTSJIkHbyoSA+g6mPaNBg4MFxS6NQJ5syxpCBJkqQqas00eG9guKSQ1AkGz7GkIEmSpIgrDBYyd91cwBUVJElS1WZRQYcsFII//AHOPx927YLBg+Hzz6F160hPJkmSJJVRKATf/QE+PR8Kd0HzwXDq51DbcCtJkqTI+++m/7Izbyd14+pybJNjIz2OJEnSQbOooEM2ejT8+tfh73RHjoQ334SkpEhPJUmSJB2Er0bD178GQnDUSDjxTYgz3EqSJKlymLUmvO1Dr5a9iI6KjvA0kiRJBy8m0gOoavvhB3j0UQgE4E9/gl/9KnxfkiRJqnJ2/gBLHgUCcMKfoIPhVpIkSZXLrLXhooLbPkiSpKrOooIOyXvvhX/27Qs33xzZWSRJkqRDkrY73DbpCx0Nt5IkSap8Zq+dDUCfFIsKkiSpanPrBx2SPUWFU0+N7BySJEnSIdtTVGhmuJUkSVLlsyV7C0s2LwEgtWVqhKeRJEk6NBYVdNAKC2HGjPB9iwqSJEmq0oKFkLY73FpUkCRJUiW0ZzWFoxsdTaPERhGeRpIk6dBYVNBB+/pr2LIF6tWDXr0iPY0kSZJ0CLZ+DXlbILYeNDLcSpIkqfIp2vahlds+SJKkqs+igg7anm0fTj4ZYmIiO4skSZJ0SPZs+5B8MkQZbiVJklT5zFo7C4DerXpHeBJJkqRDZ1FBB+3dd8M/3fZBkiRJVd6G3eHWbR8kSZJUCRUGC5mzdg7gigqSJKl6sKigg5KVBZ9/Hr5/2mmRnUWSJEk6JAVZkLE73DYz3EqSJKny+S7jO3bk7aB2bG06Ne0U6XEkSZIOmUUFHZRPPoH8fGjdGtq3j/Q0kiRJ0iHY+AkE86F2a6hruJUkSVLlM2tNeNuHXi17EeNWZZIkqRqwqKCD8t7uLXxPPRUCgcjOIkmSJB2SDbvDbTPDrSRJkiqnWWvDRQW3fZAkSdWFRQUdlH2LCpIkSVKVlrZPUUGSJEmqhGavnQ1A71a9IzyJJElS+bCooDLbsAEWLQr/stkpp0R6GkmSJOkQZG+A7YuAADQz3EqSJKny2Zq9le8yvgMsKkiSpOrDooLKbM9qCt27Q6NGkZ1FkiRJOiR7tn1o2B3iDbeSJEmqfOaumwtA+4btaVK7SYSnkSRJKh8WFVRmbvsgSZKkasNtHyRJklTJzVo7C3A1BUmSVL1YVFCZhELw/vvh+xYVJEmSVKWFQpC2O9w2N9xKkiSpctpTVOjTqk+EJ5EkSSo/FhVUJosWQVoaJCZC376RnkaSJEk6BNsXQU4aRCdCY8OtJEmSKp9gKMictXMAiwqSJKl6saigMtmz7cPAgRAfH9lZJEmSpEOyYXe4bToQog23kiRJqnwWZyxme+52EmMT6ZzcOdLjSJIklRuLCiqTd98N/zzttMjOIUmSJB2ytN3htrnhVpIkSZXTrDXhbR96tuhJTFRMhKeRJEkqPxYVVGo5OfDJJ+H7p7qFryRJkqqywhzYuDvcNjPcSpIkqXKavXY24LYPkiSp+rGooFKbOROys6F5c+jUKdLTSJIkSYdg00wozIZazSHJcCtJkqTKadba8IoKvVv1jvAkkiRJ5cuigkrtvd1b+A4aBIFAZGeRJEmSDkna7nCbbLiVJElS5bQ9ZzvfbvoWgD4prqggSZKqF4sKKrU9RQW3fZAkSVKVt6eo0NxwK0mSpMpp7rq5hAjRtkFbmtZuGulxJEmSypVFBZVKRgZ89VX4/qBBkZ1FkiRJOiQ5GbBld7htZriVJElS5eS2D5IkqTqzqKBSmTEDQiHo3BmaN4/0NJIkSdIhSJ8BhKB+Z6hluJUkSVLltKeo0KeV2z5IkqTqx6KCSsVtHyRJklRt7Nn2oZnhVpIkSZVTMBRkzto5gEUFSZJUPVlU0M8KhSwqSJIkqZoIhWCDRQVJkiRVbks3L2VrzlZqxdSiS3KXSI8jSZJU7iwq6GctWwarV0NcHAwcGOlpJEmSpEOwYxnsWg1RcdDUcCtJkqTKadaa8LYPPVr0IDY6NsLTSJIklT+LCvpZe1ZT6NcPEhMjO4skSZJ0SPZs+9CkH8QYbiVJklQ5zV47G3DbB0mSVH1ZVNDPevfd8M/TTovsHJIkSdIh27A73DYz3EqSJKnymrU2vKJC71a9IzyJJEnS4WFRQT8pPx8+/DB8/1S38JUkSVJVFsyH9N3htrnhVpIkSZVTZm4mizYuAqBPiisqSJKk6smign7S3LmwYwc0agTHHx/paSRJkqRDsHkuFOyA+EbQwHArSZKkyumLdV8QIkSb+m1oVqdZpMeRJEk6LCwq6Ce9t3sL31NOgSj/aZEkSVJVtmF3uE0+BQKGW0mSJFVObvsgSZJqgoP6dm7ChAm0adOGhIQEUlNTmTt37k+e/+ijj9KhQwdq1apFSkoKt9xyCzk5OUXPt2nThkAgsN/txhtvLDrnpJNO2u/566+//mDGVxnsKSq47YMkSaquzLY1SNrucNvMcCtJkqTKa09RoU8rt32QJEnVV0xZXzB16lRGjx7NxIkTSU1N5dFHH2Xw4MEsWbKEpk2b7nf+lClTuPPOO5k0aRJ9+/Zl6dKlXHnllQQCAcaPHw/AF198QWFhYdFrFi1axKmnnspFF11U7L2uvfZafvOb3xQ9TkxMLOv4KoPt22HOnPB9iwqSJKk6MtvWIHnbYfPucNvccCtJkqTKKRQKMXvtbMCigiRJqt7KXFQYP3481157LSNGjABg4sSJTJ8+nUmTJnHnnXfud/7MmTPp168fl156KRD+DbNLLrmEOXv+Bhxo0qRJsdf8/ve/p127dpx44onFjicmJtKsmXtyVZQPP4TCQjj6aGjdOtLTSJIklT+zbQ2S/iGECqHu0VDbcCtJkqTKadmWZWzJ3kJCTAJdm3WN9DiSJEmHTZm2fsjLy2PevHkMGjRo7xtERTFo0CBmzZpV4mv69u3LvHnzipbQXblyJW+99RZnnnnmAT/jueee46qrriIQCBR7bvLkyTRu3JjjjjuOMWPGsGvXrgPOmpubS2ZmZrGbysZtHyRJUnVmtq1h3PZBkiRJVcCsNeH/FunevDtx0XERnkaSJOnwKdOKChkZGRQWFpKcnFzseHJyMosXLy7xNZdeeikZGRn079+fUChEQUEB119/PXfddVeJ50+bNo1t27Zx5ZVX7vc+rVu3pkWLFixcuJA77riDJUuW8Oqrr5b4PuPGjeOBBx4oy+XpRywqSJKk6sxsW8PsKSq47YMkSZIqMbd9kCRJNUWZVlQ4GB999BEPPfQQTzzxBF999RWvvvoq06dP58EHHyzx/CeffJIzzjiDFi1aFDt+3XXXMXjwYDp37swvf/lL/vWvf/Haa6+xYsWKEt9nzJgxbN++vei2Zs2acr+26uyHH2DZMoiOhpNOivQ0kiRJlYPZtora+QPsWAaBaGh6UqSnkSRJqtQmTJhAmzZtSEhIIDU1tWg1sQPZtm0bN954I82bNyc+Pp6jjz6at956q4KmrX5mrQ2vqNC7Ve8ITyJJknR4lWlFhcaNGxMdHU16enqx4+np6QfcX/eee+7h8ssv55prrgGgc+fOZGVlcd1113H33XcTFbW3K7Fq1Sref//9A/4m2b5SU1MBWL58Oe3atdvv+fj4eOLj40t9bSpuz2oKvXtDUlJkZ5EkSToczLY1yJ7VFBr3hjjDrSRJ0oFMnTqV0aNHM3HiRFJTU3n00UcZPHgwS5YsoWnTpvudn5eXx6mnnkrTpk15+eWXadmyJatWraJ+/foVP3w1sCN3B99s/AaAPimuqCBJkqq3Mq2oEBcXR/fu3ZkxY0bRsWAwyIwZM+jTp+TgtGvXrmJf2AJER0cDEAqFih1/6qmnaNq0KWedddbPzjJ//nwAmjdvXpZLUCm57YMkSaruzLY1yJ6iQjPDrSRJ0k8ZP3481157LSNGjODYY49l4sSJJCYmMmnSpBLPnzRpElu2bGHatGn069ePNm3acOKJJ9K1a9cKnrx6+HL9lwRDQY5IOoIWdVv8/AskSZKqsDKtqAAwevRorrjiCnr06EGvXr149NFHycrKYsSIEQAMHz6cli1bMm7cOACGDBnC+PHjOf7440lNTWX58uXcc889DBkypOhLXQh/KfzUU09xxRVXEBNTfKwVK1YwZcoUzjzzTBo1asTChQu55ZZbGDhwIF26dDmU61cJCgthz/f1FhUkSVJ1ZratAYKFkLY73FpUkCRJOqC8vDzmzZvHmDFjio5FRUUxaNAgZs2aVeJrXn/9dfr06cONN97Iv//9b5o0acKll17KHXfcUSwf7ys3N5fc3Nyix5mZmeV7IVWY2z5IkqSapMxFhWHDhrFp0ybuvfde0tLS6NatG++88w7JyckArF69uthvmY0dO5ZAIMDYsWNZt24dTZo0YciQIfzud78r9r7vv/8+q1ev5qqrrtrvM+Pi4nj//feLvjhOSUnhggsuYOzYsWUdX6Xw9dewZQvUqwe9ekV6GkmSpMPHbFsDbP0a8rZAbD1oZLiVJEk6kIyMDAoLC4uy8B7JycksXry4xNesXLmSDz74gF/+8pe89dZbLF++nBtuuIH8/Hzuu+++El8zbtw4HnjggXKfvzrYU1To08ptHyRJUvUXCP14jdpqKjMzk6SkJLZv3069evUiPU6lNm4c3HUXnHMOTJsW6WkkSZL2V9OzXU2//jL57zhYcBe0OgcGTov0NJIkSfupLNlu/fr1tGzZkpkzZxbbCu3222/n448/Zs6cOfu95uijjyYnJ4fvv/++aAWF8ePH88gjj7Bhw4YSP6ekFRVSUlIifv2RFgqFaPqHpmTsymD21bNJbZUa6ZEkSZLKrCzZtswrKqj6e/fd8E+3fZAkSVKVt2F3uHXbB0mSpJ/UuHFjoqOjSU9PL3Y8PT2dZs2alfia5s2bExsbW2ybh2OOOYa0tDTy8vKIi4vb7zXx8fHEx8eX7/DVwIqtK8jYlUFcdBzdmnWL9DiSJEmHXdTPn6KaJCsLPv88fP+00yI7iyRJknRICrIgY3e4bWa4lSRJ+ilxcXF0796dGTNmFB0LBoPMmDGj2AoL++rXrx/Lly8nGAwWHVu6dCnNmzcvsaSgA5u1JrztQ/fm3YmPscghSZKqP4sKKuaTTyA/H1q3hvbtIz2NJEmSdAg2fgLBfKjdGuoabiVJkn7O6NGj+cc//sEzzzzDd999x8iRI8nKymLEiBEADB8+nDFjxhSdP3LkSLZs2cLNN9/M0qVLmT59Og899BA33nhjpC6hypq9djYAfVqVXAqRJEmqbtz6QcW8917456mnQiAQ2VkkSZKkQ7Jhd7htZriVJEkqjWHDhrFp0ybuvfde0tLS6NatG++88w7JyckArF69mqiovb/7lpKSwn/+8x9uueUWunTpQsuWLbn55pu54447InUJVdasteEVFXq36h3hSSRJkiqGRQUVs29RQZIkSarS0vYpKkiSJKlURo0axahRo0p87qOPPtrvWJ8+fZg9e/Zhnqp6y8rLYmH6QgD6pLiigiRJqhnc+kFFNmyARYvCv2x2yimRnkaSJEk6BNkbYPsiIADNDLeSJEmqvL5c/yWFoUJa1WtFq3qtIj2OJElShbCooCJ7VlPo3h0aNYrsLJIkSdIh2bPtQ8PuEG+4lSRJUuXltg+S/n97dx4eVXm/f/yeyZ5AAgSykRBQBFzCDiGgCBICqFHQIhULiAr6LdQFbQUL4vIraV0Qa1G0VWirKFrXFopABKwStgAiihAQDEsS9rBmIXl+fyQzMmQhISRnJnm/ritXJmfmPOdzzpw5ucVPzgMADRGNCnBi2gcAAADUG0z7AAAAAA/haFRIiGbaBwAA0HDQqABJkjHSsmUlj2lUAAAAgEczRsouDbeRhFsAAAC4L2OMVu9dLYlGBQAA0LDQqABJ0pYtUna2FBgo9e5tdTUAAABADeRukfKyJa9AqTnhFgAAAO5r17FdOnDqgHzsPuoS2cXqcgAAAOoMjQqQ9PO0D337Sn5+1tYCAAAA1EhWabgN6yt5EW4BAADgvtL2lEz70DWyq/y9/S2uBgAAoO7QqABJ0pIlJd+TkqytAwAAAKix7NJwG0m4BQAAgHtj2gcAANBQ0agA5eVJX35Z8nggU/gCAADAkxXlSQdKw20E4RYAAADuLW1vyR0VekX3srgSAACAukWjArRqlXTmjBQZKV19tdXVAAAAADVwcJVUdEYKiJRCCLcAAABwX6cLT+ubnG8kSQkx3FEBAAA0LDQqQEtLp/BNTJRsNmtrAQAAAGokuzTchhNuAQAA4N7S96frbPFZRTWOUkxwjNXlAAAA1CkaFeBsVGDaBwAAAHg8R6NCJOEWAAAA7u3caR9sNNkCAIAGhkaFBu7QIWnDhpLHiYnW1gIAAADUSN4h6UhpuI0g3AIAAMC9ORoVEqKZ9gEAADQ8NCo0cKmpkjFSXJwUGWl1NQAAAEAN5KRKMlKTOCmAcAsAAAD3ZYzR6r2rJZXcUQEAAKChoVGhgWPaBwAAANQbjmkfIgi3AAAAcG8/5f6k7JPZ8rZ7q1tkN6vLAQAAqHM0KjRgxtCoAAAAgHrCGCmLRgUAAAB4hrQ9JdM+dInoogCfAIurAQAAqHs0KjRgGRlSZqbk6yv17Wt1NQAAAEANnMiQTmdKdl8pjHALAAAA98a0DwAAoKGjUaEBW7Kk5HufPlJgoLW1AAAAADWSVRpuW/SRvAm3AAAAcG9pe0vuqJAQnWBxJQAAANagUaEBc0z7kJRkbR0AAABAjWU7pn0g3AIAAMC9nSk8o43ZGyVJCTE0KgAAgIaJRoUGqrBQWr685PFApvAFAACAJysulHJKw20k4RYAAADubUPWBp0tPqvwoHDFhsRaXQ4AAIAlaFRooNaulU6ckEJDpS5drK4GAAAAqIHDa6WzJyS/UKkp4RYAAADuzTntQ0yCbDabxdUAAABYg0aFBsox7cOAAZKdswAAAACeLKs03IYPkGyEWwAAALg3Z6NCNNM+AACAhot/xWugHI0KTPsAAAAAj5ddGm4jCLcAAABwb8YYpe0paVToFd3L4moAAACsQ6NCA5SbK61ZU/KYRgUAAAB4tIJc6XBpuI0k3AIAAMC97Tm+R1kns+Rt91b3qO5WlwMAAGAZGhUaoOXLpaIiqV07KTbW6moAAACAGshZLpkiqXE7KYhwCwAAAPfmuJtCp/BOCvQJtLgaAAAA69Co0AAx7QMAAADqDaZ9AAAAgAdZvXe1JKZ9AAAAoFGhAaJRAQAAAPWGo1GBaR8AAADgAdL2ltxRISE6weJKAAAArEWjQgOze7eUkSF5eUn9+lldDQAAAFADJ3dLJzIkm5cU1s/qagAAAIBK5Z3N04asDZKkhBgaFQAAQMNGo0ID47ibQny8FBJibS0AAABAjTjuphAaL/kSbgEAAODeNmZtVGFxoVoEtlCbJm2sLgcAAMBSNCo0MI5GhaQka+sAAAAAasw57QPhFgAAAO7POe1DTIJsNpvF1QAAAFiLRoUGpKhISk0teTyQKXwBAADgyYqLpOzScBtBuAUAAID7czYqRDPtAwAAAI0KDcjGjdKRI1JwsNSzp9XVAAAAADVwdKNUcETyCZZCCbcAAABwf6v3rpYk9YruZXElAAAA1qNRoQFxTPvQv7/k7W1tLQAAAECNOKZ9CO8v2Qm3AAAAcG97j+/V3uN75WXzUo+oHlaXAwAAYDkaFRqQJUtKvjPtAwAAADxeVmm4ZdoHAAAAeIC0PSXTPnQM76gg3yCLqwEAALAejQoNxKlT0tdflzxOSrK2FgAAAKBGzp6SDpWG2wjCLQAAANwf0z4AAAC4olGhgfjyS6mwUIqNldq2tboaAAAAoAYOfCkVF0pBsVJjwi0AAADcX9rekjsqJEQnWFwJAACAe6BRoYFYWjqF78CBks1mbS0AAABAjWSVhtsIwi0AAADcX/7ZfKVnpUuSEmJoVAAAAJBoVGgwzm1UAAAAADxa9jmNCgAAAICb25S9SQVFBWoe2FyXN73c6nIAAADcwkU1KsyePVutW7eWv7+/4uPjtXbt2kpfP2vWLLVv314BAQGKiYnRI488ory8POfzTz31lGw2m8tXhw4dXMbIy8vThAkTFBoaqkaNGun2229XTk7OxZTf4GRlSVu2lPyx2YABVlcDAADgXsi2HuZMlpS7RZJNiiDcAgAAwP05pn3oFd1LNu4IBgAAIOkiGhUWLFigSZMmafr06dqwYYM6deqkQYMG6cCBA+W+fv78+Zo8ebKmT5+urVu36s0339SCBQv0xBNPuLzu6quvVlZWlvPrq6++cnn+kUce0b///W998MEHWrlypfbv36/bbrutuuU3SI67KXTrJoWGWlsLAACAOyHbeiDHtA/Nukl+hFsAAAC4P0ejQkI00z4AAAA4eFd3hZkzZ2rcuHEaO3asJGnOnDlauHCh3nrrLU2ePLnM61etWqU+ffpo5MiRkqTWrVvrzjvv1Jo1a1wL8fZWREREudvMzc3Vm2++qfnz5+uGG26QJM2dO1dXXnmlVq9erV69elV3NxoUpn0AAAAoH9nWAzHtAwAAADzM6r2rJZXcUQEAAAAlqnVHhYKCAqWnpysxMfHnAex2JSYmKi0trdx1evfurfT0dOctdH/88UctWrRIN954o8vrMjIyFBUVpcsuu0x33XWXMjMznc+lp6ersLDQZbsdOnRQq1atKtwuShgjLVtW8phGBQAAgJ+RbT2QMVJ2abiNJNwCAADA/e0/sV+ZuZmy2+zq2bKn1eUAAAC4jWrdUeHQoUMqKipSeHi4y/Lw8HD98MMP5a4zcuRIHTp0SNdee62MMTp79qweeOABl9vjxsfHa968eWrfvr2ysrL09NNP67rrrtOWLVvUuHFjZWdny9fXV02aNCmz3ezs7HK3m5+fr/z8fOfPx48fr86u1htbtkjZ2VJgoNS7t9XVAAAAuA+yrQfK3SLlZUtegVJzwi0AAADcX9qekmbkuLA4NfJtZHE1AAAA7qNad1S4GCtWrNCMGTP06quvasOGDfroo4+0cOFCPfvss87XDBkyRMOHD1fHjh01aNAgLVq0SMeOHdP7779/0dtNSUlRSEiI8ysmJuZS7I7HcUz70Lev5OdnbS0AAACejmxrsazScBvWV/Ii3AIAAMD9Me0DAABA+arVqNC8eXN5eXkpJyfHZXlOTk6Fc/BOmzZNo0aN0n333ae4uDgNGzZMM2bMUEpKioqLi8tdp0mTJmrXrp127NghSYqIiFBBQYGOHTtW5e1OmTJFubm5zq89e/ZUZ1frjSVLSr4z7QMAAIArsq0Hyi4NtxGEWwAAAHiGtL0ld1RIiE6wuBIAAAD3Uq1GBV9fX3Xr1k2pqanOZcXFxUpNTVVCQvlB6/Tp07LbXTfj5eUlSTLGlLvOyZMntXPnTkVGRkqSunXrJh8fH5ftbtu2TZmZmRVu18/PT8HBwS5fDU1envTllyWPk5KsrQUAAMDdkG09TFGedKA03EYSbgEAAOD+CooKlJ6VLklKiKFRAQAA4Fze1V1h0qRJGjNmjLp3766ePXtq1qxZOnXqlMaOHStJGj16tFq2bKmUlBRJUnJysmbOnKkuXbooPj5eO3bs0LRp05ScnOz8R93HHntMycnJio2N1f79+zV9+nR5eXnpzjvvlCSFhITo3nvv1aRJk9SsWTMFBwfrN7/5jRISEtSrF7fMqsiqVdKZM1JkpHT11VZXAwAA4H7Ith7k4Cqp6IwUECmFEG4BAADg/r7J/kZ5Z/PULKCZrmh2hdXlAAAAuJVqNyqMGDFCBw8e1JNPPqns7Gx17txZixcvVnh4uCQpMzPT5a/Mpk6dKpvNpqlTp2rfvn1q0aKFkpOT9Yc//MH5mr179+rOO+/U4cOH1aJFC1177bVavXq1WrRo4XzNSy+9JLvdrttvv135+fkaNGiQXn311Zrse723tHQK38REyWazthYAAAB3RLb1INml4TaccAsAAFCbZs+ereeff17Z2dnq1KmTXnnlFfXs2bPc186bN8/Z5Ovg5+envLy8uijV7TmmfegV3Us2MiwAAIALm6noHrX1zPHjxxUSEqLc3NwGc6vc7t2l9HTpH/+QRo2yuhoAAIBLpyFmu3M1yP1f3F06ki4l/ENqQ7gFAAD1hztluwULFmj06NGaM2eO4uPjNWvWLH3wwQfatm2bwsLCyrx+3rx5euihh7Rt2zbnMpvN5mz8rQp32v9LbeSHI/Xulnf1bP9nNbXvVKvLAQAAqHXVyXb2Sp+Fxzp0SNqwoeRxYqK1tQAAAAA1kndIOlIabiMItwAAALVl5syZGjdunMaOHaurrrpKc+bMUWBgoN56660K17HZbIqIiHB+VadJob47944KAAAAcEWjQj2VmioZI8XFSZGRVlcDAAAA1EBOqiQjNYmTAgi3AAAAtaGgoEDp6elKPOevnux2uxITE5WWllbheidPnlRsbKxiYmJ066236rvvvquLct1e9sls7T62WzbZ1LNl+VNnAAAANGQ0KtRTS0un8B040No6AAAAgBrLLg23EYRbAACA2nLo0CEVFRWVuSNCeHi4srOzy12nffv2euutt/Tpp5/q7bffVnFxsXr37q29e/dWuJ38/HwdP37c5as+Wr13tSTpmrBrFOxXv6a0AAAAuBRoVKiHjKFRAQAAAPWEMVIWjQoAAADuKCEhQaNHj1bnzp11/fXX66OPPlKLFi30+uuvV7hOSkqKQkJCnF8xMTF1WHHdSdvDtA8AAACVoVGhHsrIkDIzJV9fqW9fq6sBAAAAauBEhnQ6U7L7SmGEWwAAgNrSvHlzeXl5KScnx2V5Tk6OIiIiqjSGj4+PunTpoh07dlT4milTpig3N9f5tWfPnhrV7a7S9pY0KiREJ1hcCQAAgHuiUaEeWrKk5HufPlJgoLW1AAAAADWSVRpuW/SRvAm3AAAAtcXX11fdunVTamqqc1lxcbFSU1OVkFC1/9leVFSkb7/9VpGRkRW+xs/PT8HBwS5f9U1hUaHW718vSUqIoVEBAACgPN5WF4BLzzHtQ1KStXUAAAAANZbtmPaBcAsAAFDbJk2apDFjxqh79+7q2bOnZs2apVOnTmns2LGSpNGjR6tly5ZKSUmRJD3zzDPq1auX2rZtq2PHjun555/XTz/9pPvuu8/K3bDc5pzNOnP2jJr4N1G70HZWlwMAAOCWaFSoZwoLpeXLSx4PZApfAAAAeLLiQimnNNxGEm4BAABq24gRI3Tw4EE9+eSTys7OVufOnbV48WKFh4dLkjIzM2W3/3yT3qNHj2rcuHHKzs5W06ZN1a1bN61atUpXXXWVVbvgFhzTPvSK7iW7jZsaAwAAlIdGhXpm7VrpxAkpNFTq0sXqagAAAIAaOLxWOntC8guVmhJuAQAA6sLEiRM1ceLEcp9bsWKFy88vvfSSXnrppTqoyrOs3rtakpQQzbQPAAAAFaGds55xTPswYIBk590FAACAJ8sqDbfhAyT+Eg0AAAAe4tw7KgAAAKB8/GtfPeNoVGDaBwAAAHi87NJwG0G4BQAAgGc4cOqAfjz6o2yyKb5lvNXlAAAAuC0aFeqR3FxpzZqSxzQqAAAAwKMV5EqHS8NtJOEWAAAAnsEx7cNVLa5SiH+IxdUAAAC4LxoV6pHly6WiIqldOyk21upqAAAAgBrIWS6ZIqlxOymIcAsAAADPkLaHaR8AAACqgkaFeoRpHwAAAFBvMO0DAAAAPFDa3pJGhYToBIsrAQAAcG80KtQjNCoAAACg3nA0KjDtAwAAADzE2eKzWrd/nSQpIYZGBQAAgMrQqFBP7N4tZWRIXl5Sv35WVwMAAADUwMnd0okMyeYlhfWzuhoAAACgSr7N+VanC08rxC9EHZp3sLocAAAAt0ajQj3huJtCfLwUEmJtLQAAAECNOO6mEBov+RJuAQAA4Bkc0z7ER8fLbuOf3gEAACpDWqonHI0KSUnW1gEAAADUmHPaB8ItAAAAPMfqvaslSb1a9rK4EgAAAPdHo0I9UFQkpaaWPB7IFL4AAADwZMVFUnZpuI0g3AIAAMBzOO6okBCTYHElAAAA7o9GhXpg40bpyBEpOFjq2dPqagAAAIAaOLpRKjgi+QRLoYRbAAAAeIaDpw5qx5EdkqT4lvEWVwMAAOD+aFSoBxzTPvTvL3l7W1sLAAAAUCOOaR/C+0t2wi0AAAA8w5p9ayRJHZp3UNOAphZXAwAA4P5oVKgHliwp+c60DwAAAPB4WaXhlmkfAAAA4EHS9pRO+xDNtA8AAABVQaOChzt1Svr665LHSUnW1gIAAADUyNlT0qHScBtBuAUAAIDnSNtLowIAAEB10Kjg4b78UioslGJjpbZtra4GAAAAqIEDX0rFhVJQrNSYcAsAAADPUFRcpLX71kqSekX3srgaAAAAz0CjgodbWjqF78CBks1mbS0AAABAjWSVhtsIwi0AAAA8x5YDW3Sq8JQa+zbWVS2usrocAAAAj0Cjgoc7t1EBAAAA8GjZ5zQqAAAAAB7CMe1DfHS8vOxeFlcDAADgGWhU8GD790tbtpT8sdmAAVZXAwAAANTA6f1S7hZJNimCcAsAAADPsXrvaklSr5ZM+wAAAFBVNCp4sGXLSr537SqFhlpbCwAAAFAj2aXhtllXyY9wCwAAAM/huKNCQkyCxZUAAAB4DhoVPJhj2oekJGvrAAAAAGrMOe0D4RYAAACe4/Dpw9p+eLskKb5lvMXVAAAAeA4aFTyUMT/fUWEgU/gCAADAkxnz8x0VIgm3AAAA8Bxr9q2RJLULbafQQO4MBgAAUFU0KnioLVuk7GwpMFDq3dvqagAAAIAayN0i5WVLXoFSc8ItAAAAPEfantJpH6KZ9gEAAKA6aFTwUI5pH/r2lfz8rK0FAAAAqJGs0nAb1lfyItwCAADAc6TtpVEBAADgYtCo4KGWLCn5zrQPAAAA8HjZpeE2gnALAAAAz1FUXKS1+9ZKknpF97K4GgAAAM9Co4IHysuTvvyy5HFSkrW1AAAAADVSlCcdKA23kYRbAAAAeI7vD36vEwUn1Mi3ka4Ju8bqcgAAADwKjQoeaNUq6cwZKTJSuvpqq6sBAAAAauDgKqnojBQQKYUQbgEAAOA5HNM+9GzZU152L4urAQAA8Cw0KnigpaVT+CYmSjabtbUAAAAANZJdGm7DCbcAAADwLKv3rpYk9WrJtA8AAADVRaOCB3I0KgxkCl8AAAB4OkejQiThFgAAAJ7FcUeFhJgEiysBAADwPDQqeJhDh6QNG0oeJyZaWwsAAABQI3mHpCOl4TaCcAsAAADPceTMEf1w6AdJUq9o7qgAAABQXTQqeJjUVMkYKS5Oioy0uhoAAACgBnJSJRmpSZwUQLgFAACA51i7b60kqW2ztmoe2NziagAAADwPjQoehmkfAAAAUG84pn2IINwCAADAs6TtKZ32IZppHwAAAC4GjQoexBgaFQAAAFBPGCNl0agAAAAAz5S2l0YFAACAmqBRwYNkZEiZmZKvr9S3r9XVAAAAADVwIkM6nSnZfaUwwi0AAAA8R7Ep1pp9ayRJvaJ7WVwNAACAZ7qoRoXZs2erdevW8vf3V3x8vNauXVvp62fNmqX27dsrICBAMTExeuSRR5SXl+d8PiUlRT169FDjxo0VFhamoUOHatu2bS5j9OvXTzabzeXrgQceuJjyPdaSJSXf+/SRAgOtrQUAAKC+INtaJKs03LboI3kTbgEAAOA5th7cquP5xxXkE6S48DirywEAAPBI1W5UWLBggSZNmqTp06drw4YN6tSpkwYNGqQDBw6U+/r58+dr8uTJmj59urZu3ao333xTCxYs0BNPPOF8zcqVKzVhwgStXr1aS5cuVWFhoZKSknTq1CmXscaNG6esrCzn13PPPVfd8j2aY9qHpCRr6wAAAKgvyLYWynZM+0C4BQAAgGdxTPvQo2UPedu9La4GAADAM1U7Rc2cOVPjxo3T2LFjJUlz5szRwoUL9dZbb2ny5MllXr9q1Sr16dNHI0eOlCS1bt1ad955p9asWeN8zeLFi13WmTdvnsLCwpSenq6+58xxEBgYqIiIiOqWXC8UFkrLl5c8HsgUvgAAAJcE2dYixYVSTmm4jSTcAgAAwLOs3rtaktSrJdM+AAAAXKxq3VGhoKBA6enpSkxM/HkAu12JiYlKS0srd53evXsrPT3deQvdH3/8UYsWLdKNN95Y4XZyc3MlSc2aNXNZ/s4776h58+a65pprNGXKFJ0+fbo65Xu0tWulEyek0FCpSxerqwEAAPB8ZFsLHV4rnT0h+YVKTQm3AAAA8CyOOyokxCRYXAkAAIDnqtYdFQ4dOqSioiKFh4e7LA8PD9cPP/xQ7jojR47UoUOHdO2118oYo7Nnz+qBBx5wuT3uuYqLi/Xwww+rT58+uuaaa1zGiY2NVVRUlDZv3qzHH39c27Zt00cffVTuOPn5+crPz3f+fPz48ersqttxTPswYIBkr/aEHQAAADgf2dZCWaXhNnyAZCPcAgAAwHMcyzum7w9+L0nqFc0dFQAAAC5WrU+gtWLFCs2YMUOvvvqq4uPjtWPHDj300EN69tlnNW3atDKvnzBhgrZs2aKvvvrKZfn48eOdj+Pi4hQZGakBAwZo586duvzyy8uMk5KSoqeffvrS75BFliwp+c60DwAAANYh214i2aXhNoJwCwAAAM+ydl/J3dUua3qZwoLCLK4GAADAc1Xrz5eaN28uLy8v5eTkuCzPycmpcH7dadOmadSoUbrvvvsUFxenYcOGacaMGUpJSVFxcbHLaydOnKj//Oc/Wr58uaKjoyutJT4+XpK0Y8eOcp+fMmWKcnNznV979uyp6m66ndzckqkfJBoVAAAALhWyrUUKckumfpCkSMItAAAAPEvantJpH6KZ9gEAAKAmqtWo4Ovrq27duik1NdW5rLi4WKmpqUpIKD+YnT59Wvbz5irw8vKSJBljnN8nTpyojz/+WF988YXatGlzwVo2bdokSYqMjCz3eT8/PwUHB7t8early6WiIqldOyk21upqAAAA6geyrUVylkumSGrcTgoi3AIAAMCzpO2lUQEAAOBSqPbUD5MmTdKYMWPUvXt39ezZU7NmzdKpU6c0duxYSdLo0aPVsmVLpaSkSJKSk5M1c+ZMdenSxXl73GnTpik5Odn5j7oTJkzQ/Pnz9emnn6px48bKzs6WJIWEhCggIEA7d+7U/PnzdeONNyo0NFSbN2/WI488or59+6pjx46X6li4raWlU/hyNwUAAIBLi2xrgezScMu0DwAAAPAwxaZYa/atkST1iu5lcTUAAACerdqNCiNGjNDBgwf15JNPKjs7W507d9bixYsVHh4uScrMzHT5K7OpU6fKZrNp6tSp2rdvn1q0aKHk5GT94Q9/cL7mtddekyT169fPZVtz587V3XffLV9fXy1btsz5D8cxMTG6/fbbNXXq1IvZZ49DowIAAEDtINtawNGowLQPAAAA8DDbDm3TsbxjCvAOUMfwBtBkDAAAUItsxnGP2nru+PHjCgkJUW5urkfdKnf3bqlNG8nLSzp8WAoJsboiAAAA63lqtrtUPHb/T+6WPmsj2byk2w9LvoRbAAAAj812l4gn7f9bG9/SvZ/dq76xfbXy7pVWlwMAAOB2qpPt7JU+C8s57qYQH0+TAgAAADyc424KofE0KQAAAMDjrN67WpLUqyXTPgAAANQUjQpuztGokJRkbR0AAABAjTmnfSDcAgAAwPOk7U2TJCXEJFhcCQAAgOejUcGNFRVJqakljwcyhS8AAAA8WXGRlF0abiMItwAAAPAsuXm5+u7Ad5KkXtHcUQEAAKCmaFRwYxs3SkeOSMHBUs+eVlcDAAAA1MDRjVLBEcknWAol3AIAALir2bNnq3Xr1vL391d8fLzWrl1bpfXee+892Ww2DR06tHYLtMi6/etkZNS6SWtFNIqwuhwAAACPR6OCG3NM+9C/v+TtbW0tAAAAQI04pn0I7y/ZCbcAAADuaMGCBZo0aZKmT5+uDRs2qFOnTho0aJAOHDhQ6Xq7d+/WY489puuuu66OKq17aXtKp32IZtoHAACAS4FGBTe2ZEnJd6Z9AAAAgMfLKg23TPsAAADgtmbOnKlx48Zp7NixuuqqqzRnzhwFBgbqrbfeqnCdoqIi3XXXXXr66ad12WWX1WG1dSttL40KAAAAlxKNCm7q1Cnp669LHiclWVsLAAAAUCNnT0mHSsNtBOEWAADAHRUUFCg9PV2JiYnOZXa7XYmJiUpLS6twvWeeeUZhYWG6995766JMSxhjtHrvaklSr+heFlcDAABQP3DPVTf15ZdSYaEUGyu1bWt1NQAAAEANHPhSKi6UgmKlxoRbAAAAd3To0CEVFRUpPDzcZXl4eLh++OGHctf56quv9Oabb2rTpk1V3k5+fr7y8/OdPx8/fvyi6q1L2w9v19G8o/L39leniE5WlwMAAFAvcEcFN7W0dArfgQMlm83aWgAAAIAaySoNtxGEWwAAgPrixIkTGjVqlP7617+qefPmVV4vJSVFISEhzq+YmJharPLScEz70D2qu3y9fC2uBgAAoH7gjgpu6txGBQAAAMCjZZ/TqAAAAAC31Lx5c3l5eSknJ8dleU5OjiIiIsq8fufOndq9e7eSk5Ody4qLiyVJ3t7e2rZtmy6//PIy602ZMkWTJk1y/nz8+HG3b1ZwTvvQkmkfAAAALhUaFdzQ/v3Sli0lf2w2YIDV1QAAAAA1cHq/lLtFkk2KINwCAAC4K19fX3Xr1k2pqakaOnSopJLGg9TUVE2cOLHM6zt06KBvv/3WZdnUqVN14sQJvfzyyxU2H/j5+cnPz++S11+bHHdUSIhJsLgSAACA+oNGBTe0bFnJ965dpdBQa2sBAAAAaiS7NNw26yr5EW4BAADc2aRJkzRmzBh1795dPXv21KxZs3Tq1CmNHTtWkjR69Gi1bNlSKSkp8vf31zXXXOOyfpMmTSSpzHJPdiL/hLYc2CJJ6hXNHRUAAAAuFRoV3JBj2oekJGvrAAAAAGrMOe0D4RYAAMDdjRgxQgcPHtSTTz6p7Oxsde7cWYsXL1Z4eLgkKTMzU3a73eIq69a6/etUbIrVKqSVohpHWV0OAABAvUGjgpsx5uc7KgxkCl8AAAB4MmN+vqNCJOEWAADAE0ycOLHcqR4kacWKFZWuO2/evEtfkMXS9pRO+xDNtA8AAACXUsNqf/UAW7ZI2dlSYKDUu7fV1QAAAAA1kLtFysuWvAKl5oRbAAAAeJ60vTQqAAAA1AYaFdyMY9qHvn0lPz9rawEAAABqJKs03Ib1lbwItwAAAPAsxhit3rtaktQrupfF1QAAANQvNCq4mSVLSr4z7QMAAAA8XnZpuI0g3AIAAMDz7DiyQ4fPHJafl5+6RHaxuhwAAIB6hUYFN5KXJ335ZcnjpCRrawEAAABqpChPOlAabiMJtwAAAPA8jmkfukZ2la+Xr8XVAAAA1C80KriRVaukM2ekyEjp6qutrgYAAACogYOrpKIzUkCkFEK4BQAAgOdxTPuQEJ1gcSUAAAD1D40KbmRp6RS+iYmSzWZtLQAAAECNZJeG23DCLQAAADyT444KCTE0KgAAAFxqNCq4EUejwkCm8AUAAICnczQqRBJuAQAA4HlOFpzU5pzNkqRe0b0srgYAAKD+oVHBTRw6JG3YUPI4MdHaWgAAAIAayTskHSkNtxGEWwAAAHie9fvXq9gUKzo4WtHB0VaXAwAAUO/QqOAmUlMlY6S4OCky0upqAAAAgBrISZVkpCZxUgDhFgAAAJ4nbU/ptA/RTPsAAABQG2hUcBNM+wAAAIB6wzHtQwThFgAAAJ5p9b7Vkpj2AQAAoLbQqOAGjKFRAQAAAPWEMVIWjQoAAADwXMYY7qgAAABQy2hUcAMZGVJmpuTrK/Xta3U1AAAAQA2cyJBOZ0p2XymMcAsAAADP8+PRH3Xw9EH5evmqa2RXq8sBAACol2hUcANLlpR879NHCgy0thYAAACgRrJKw22LPpI34RYAAACeZ/XekmkfukR0kZ+3n8XVAAAA1E80KrgBpn0AAABAvZHNtA8AAADwbGl7mfYBAACgttGoYLHCQmn58pLHSUnW1gIAAADUSHGhlFMabiMJtwAAAPBMzkaFGBoVAAAAaguNChZbu1Y6cUIKDZW6dLG6GgAAAKAGDq+Vzp6Q/EKlpoRbAAAAeJ7Thaf1TfY3kqRe0b0srgYAAKD+olHBYo5pHwYMkOy8GwAAAPBkWaXhNnyAZCPcAgAAwPOs379eRaZIUY2jFBMcY3U5AAAA9Rb/emixJUtKvg9kCl8AAAB4uuzScBtBuAUAAIBnSttTOu1DdIJsNpvF1QAAANRfNCpYKDe3ZOoHiUYFAAAAeLiC3JKpHyQpknALAAAAz7R632pJTPsAAABQ22hUsNDy5VJRkdSunRQba3U1AAAAQA3kLJdMkdS4nRREuAUAAIDnMca43FEBAAAAtYdGBQstLZ3Cl7spAAAAwONll4Zbpn0AAACAh9p9bLdyTuXIx+6jrpFdrS4HAACgXqNRwUI0KgAAAKDecDQqMO0DAAAAPNTqvSXTPnSO6KwAnwCLqwEAAKjfaFSwyO7dUkaG5OUl9etndTUAAABADZzcLZ3IkGxeUlg/q6sBAAAALkraXqZ9AAAAqCs0KljEcTeF+HgpJMTaWgAAAIAacdxNITRe8iXcAgAAwDM5GxViaFQAAACobTQqWMTRqJCUZG0dAAAAQI05p30g3AIAAMAznSk8o03ZmyRJvaJ7WVsMAABAA0CjggWKiqTU1JLHA5nCFwAAAJ6suEjKLg23EYRbAAAAeKb0rHSdLT6riEYRig2JtbocAACAeo9GBQts3CgdOSIFB0s9e1pdDQAAAFADRzdKBUckn2AplHALAAAAz5S2p3Tah+gE2Ww2i6sBAACo/2hUsIBj2of+/SVvb2trAQAAAGrEMe1DeH/JTrgFAACAZ1q9b7Ukpn0AAACoKxfVqDB79my1bt1a/v7+io+P19q1ayt9/axZs9S+fXsFBAQoJiZGjzzyiPLy8qo1Zl5eniZMmKDQ0FA1atRIt99+u3Jyci6mfMstWVLynWkfAAAArEe2raGs0nDLtA8AAADwUMYYlzsqAAAAoPZVu1FhwYIFmjRpkqZPn64NGzaoU6dOGjRokA4cOFDu6+fPn6/Jkydr+vTp2rp1q958800tWLBATzzxRLXGfOSRR/Tvf/9bH3zwgVauXKn9+/frtttuu4hdttapU9LXX5c8plEBAADAWmTbGjp7SjpUGm5pVAAAAICHyszNVNbJLHnbvdUtqpvV5QAAADQINmOMqc4K8fHx6tGjh/7yl79IkoqLixUTE6Pf/OY3mjx5cpnXT5w4UVu3blVqaqpz2aOPPqo1a9boq6++qtKYubm5atGihebPn69f/OIXkqQffvhBV155pdLS0tSr14Vvx3X8+HGFhIQoNzdXwcHB1dnlS+q//5VuvFGKjZV27ZKY7gwAAKD6LlW2I9vW0P7/SitulIJipVsItwAAABfDbbKdRdxh/xdsWaBffvhLdYvspvXj11tSAwAAQH1QnWxXrTsqFBQUKD09XYmJiT8PYLcrMTFRaWlp5a7Tu3dvpaenO293++OPP2rRokW68cYbqzxmenq6CgsLXV7ToUMHtWrVqsLtuqulpVP4DhzIv+MCAABYiWx7CWSVhtsIwi0AAAA8V9pepn0AAACoa97VefGhQ4dUVFSk8PBwl+Xh4eH64Ycfyl1n5MiROnTokK699loZY3T27Fk98MADztvjVmXM7Oxs+fr6qkmTJmVek52dXe528/PzlZ+f7/z5+PHj1dnVWnNuowIAAACsQ7a9BLLPaVQAAAAAPJSzUSGGRgUAAIC6Uq07KlyMFStWaMaMGXr11Ve1YcMGffTRR1q4cKGeffbZWt1uSkqKQkJCnF8xMTG1ur2q2L9f2rKl5I/NBgywuhoAAABUF9n2HKf3S7lbJNmkCMItAAAAPFPe2TxtzNooSeoVfeFp2AAAAHBpVKtRoXnz5vLy8lJOTo7L8pycHEVERJS7zrRp0zRq1Cjdd999iouL07BhwzRjxgylpKSouLi4SmNGRESooKBAx44dq/J2p0yZotzcXOfXnj17qrOrtWLZspLvXbtKoaHW1gIAANDQkW1rKLs03DbrKvkRbgEAAOCZNmRtUGFxocKCwtSmSRurywEAAGgwqtWo4Ovrq27duik1NdW5rLi4WKmpqUpIKP+2WKdPn5bd7roZLy8vSZIxpkpjduvWTT4+Pi6v2bZtmzIzMyvcrp+fn4KDg12+rOaY9iEpydo6AAAAQLatMee0D4RbAAAAeK60PaXTPkQnyGazWVwNAABAw+Fd3RUmTZqkMWPGqHv37urZs6dmzZqlU6dOaezYsZKk0aNHq2XLlkpJSZEkJScna+bMmerSpYvi4+O1Y8cOTZs2TcnJyc5/1L3QmCEhIbr33ns1adIkNWvWTMHBwfrNb36jhIQE9erlGbfjMubnOyoMZApfAAAAt0C2vUjG/HxHhUjCLQAAADzX6n2rJTHtAwAAQF2rdqPCiBEjdPDgQT355JPKzs5W586dtXjxYoWHh0uSMjMzXf7KbOrUqbLZbJo6dar27dunFi1aKDk5WX/4wx+qPKYkvfTSS7Lb7br99tuVn5+vQYMG6dVXX63JvtepLVuk7GwpMFDq3dvqagAAACCRbS9a7hYpL1vyCpSaE24BAADguc69owIAAADqjs0YY6wuoi4cP35cISEhys3NteRWuS++KD32mDR4sPTf/9b55gEAAOoVq7Od1Szf/60vShsfkyIHS/0JtwAAADVhebazmJX7vyd3j1rNaiUvm5dyJ+cqyDeoTrcPAABQ31Qn29krfRaXzNLSKXyZ9gEAAAAeL7s03EYQbgEAAOC5Vu8tmfahY3hHmhQAAADqGI0KdSAvT/ryy5LHSUnW1gIAAADUSFGedKA03EYSbgEAAOC50vYy7QMAAIBVaFSoA6tWSWfOSJGR0tVXW10NAAAAUAMHV0lFZ6SASCmEcAsAAADP5WxUiKFRAQAAoK7RqFAHHNM+JCZKNpu1tQAAAAA14pj2IZxwCwAAAM+VfzZfG7I2SJJ6RfeyuBoAAICGh0aFOuBoVBjIFL4AAADwdI5GhUjCLQAAADzXxuyNKigqUPPA5rq86eVWlwMAANDg0KhQyw4dkjaUNOYqMdHaWgAAAIAayTskHSkNtxGEWwAAAHiutD2l0z5EJ8jGncIAAADqHI0KtSw1VTJGuuYaKTLS6moAAACAGshJlWSkkGukAMItAAAAPNfqfaslMe0DAACAVWhUqGWOaR+SkqytAwAAAKgx57QPhFsAAAB4tnPvqAAAAIC6R6NCLTLm50aFgUzhCwAAAE9mjJRVGm4jCLcAAAD11ezZs9W6dWv5+/srPj5ea9eurfC1H330kbp3764mTZooKChInTt31j//+c86rPbi7Du+T3uO75HdZlePlj2sLgcAAKBBolGhFmVkSJmZkq+v1Lev1dUAAAAANXAiQzqdKdl9pTDCLQAAQH20YMECTZo0SdOnT9eGDRvUqVMnDRo0SAcOHCj39c2aNdPvf/97paWlafPmzRo7dqzGjh2rzz//vI4rr57Ve0umfYgLi1Mj30YWVwMAANAw0ahQi5YsKfnep48UGGhtLQAAAECNZJWG2xZ9JG/CLQAAQH00c+ZMjRs3TmPHjtVVV12lOXPmKDAwUG+99Va5r+/Xr5+GDRumK6+8UpdffrkeeughdezYUV999VUdV149aXuZ9gEAAMBqNCrUIqZ9AAAAQL2RzbQPAAAA9VlBQYHS09OVmJjoXGa325WYmKi0tLQLrm+MUWpqqrZt26a+ldxeNj8/X8ePH3f5qmvORoUYGhUAAACsQqNCLSkslJYvL3mclGRtLQAAAECNFBdKOaXhNpJwCwAAUB8dOnRIRUVFCg8Pd1keHh6u7OzsCtfLzc1Vo0aN5Ovrq5tuukmvvPKKBlbyl1spKSkKCQlxfsXExFyyfaiKgqICpe9PlyT1iu5Vp9sGAADAz2hUqCVr10onTkihoVKXLlZXAwAAANTA4bXS2ROSX6jUlHALAACAnzVu3FibNm3SunXr9Ic//EGTJk3SihUrKnz9lClTlJub6/zas2dP3RUraVP2JuUX5Ss0IFRXNLuiTrcNAACAn3lbXUB91bGj9PHH0uHDkp12EAAAAHiyJh2l6z6WCg5LNsItAABAfdS8eXN5eXkpJyfHZXlOTo4iIiIqXM9ut6tt27aSpM6dO2vr1q1KSUlRv379yn29n5+f/Pz8Llnd1dU+tL0+vONDHT1zVDabzbI6AAAAGjoaFWpJ48bS0KFWVwEAAABcAj6NpZihVlcBAACAWuTr66tu3bopNTVVQ0v/YbO4uFipqamaOHFilccpLi5Wfn5+LVVZcyH+IbrtytusLgMAAKDBo1EBAAAAAAAAAKBJkyZpzJgx6t69u3r27KlZs2bp1KlTGjt2rCRp9OjRatmypVJSUiRJKSkp6t69uy6//HLl5+dr0aJF+uc//6nXXnvNyt0AAACAB6BRAQAAAAAAAACgESNG6ODBg3ryySeVnZ2tzp07a/HixQoPD5ckZWZmyn7OPLenTp3Sr3/9a+3du1cBAQHq0KGD3n77bY0YMcKqXQAAAICHsBljjNVF1IXjx48rJCREubm5Cg4OtrocAAAA1EBDz3YNff8BAADqk4ae7Rr6/gMAANQn1cl29kqfBQAAAAAAAAAAAAAAuIRoVAAAAAAAAAAAAAAAAHWGRgUAAAAAAAAAAAAAAFBnaFQAAAAAAAAAAAAAAAB1hkYFAAAAAAAAAAAAAABQZ2hUAAAAAAAAAAAAAAAAdYZGBQAAAAAAAAAAAAAAUGdoVAAAAAAAAAAAAAAAAHWGRgUAAAAAAAAAAAAAAFBnaFQAAAAAAAAAAAAAAAB1hkYFAAAAAAAAAAAAAABQZ2hUAAAAAAAAAAAAAAAAdcbb6gLqijFGknT8+HGLKwEAAEBNOTKdI+M1NGRbAACA+oNsS7YFAACoL6qTbRtMo8KJEyckSTExMRZXAgAAgEvlxIkTCgkJsbqMOke2BQAAqH/ItmRbAACA+qIq2dZmGkirbnFxsfbv36/GjRvLZrPVyTaPHz+umJgY7dmzR8HBwXWyTSvUt/305P3xhNrdtUZ3qsuqWup6uzXZXm3XeqnHv5TjXcxYl2r77jRObR9Td6rRE8ax4rpljNGJEycUFRUlu73hzWZGtq099W0/PXl/PKF2d63Rneoi29buulaMT7a99OOQbd1rHLJt3SPb1p76tp+evD+eULu71uhOdZFta3ddK8Yn2176cci27jWOu2fbBnNHBbvdrujoaEu2HRwcbPkv0LpQ3/bTk/fHE2p31xrdqS6raqnr7dZke7Vd66Ue/1KOdzFjXartu9M4tX1M3alGTxinrq8fDfGvzRzItrWvvu2nJ++PJ9TurjW6U11k29pd14rxybaXfhyyrXuNQ7atO2Tb2lff9tOT98cTanfXGt2pLrJt7a5rxfhk20s/DtnWvcZx12zb8Fp0AQAAAAAAAAAAAACAZWhUAAAAAAAAAAAAAAAAdYZGhVrk5+en6dOny8/Pz+pSalV9209P3h9PqN1da3Snuqyqpa63W5Pt1Xatl3r8SznexYx1qbbvTuPU9jF1pxo9YRx3uoai9jSU97m+7acn748n1O6uNbpTXWTb2l3XivHJtpd+HLKte43jTtdQ1J6G8j7Xt/305P3xhNrdtUZ3qotsW7vrWjE+2fbSj0O2da9x3OkaWh6bMcZYXQQAAAAAAAAAAAAAAGgYuKMCAAAAAAAAAAAAAACoMzQqAAAAAAAAAAAAAACAOkOjAgAAAAAAAAAAAAAAqDM0Klykp556SjabzeWrQ4cOla7zwQcfqEOHDvL391dcXJwWLVpUR9VW3Zdffqnk5GRFRUXJZrPpk08+cT5XWFioxx9/XHFxcQoKClJUVJRGjx6t/fv3X3Dcffv26Ve/+pVCQ0MVEBCguLg4rV+/vhb3pERl+yNJOTk5uvvuuxUVFaXAwEANHjxYGRkZVR7/vffek81m09ChQy9p3SkpKerRo4caN26ssLAwDR06VNu2bXN5Tb9+/cqcgw888ECl4959991l1hk8ePBF1/naa6+pY8eOCg4OVnBwsBISEvTf//7X+XxeXp4mTJig0NBQNWrUSLfffrtycnIqHbOm70lV6rqYY3cp6vrjH/8om82mhx9+2LnsYo7RuR544AHZbDbNmjWr2tt2MMZoyJAh5X5GLmbb5W0rOztbo0aNUkREhIKCgtS1a1d9+OGHkiq/ns6ePVuxsbHy8vKSt7e3AgMDq3SMjDF68skn1ahRo0qv1ffff78uv/xyBQQEqEWLFrr11lv1ww8/VDr2iBEjKh2zOudXeftut9t11VVXac6cORUet8quqa+99pri4uLk5+cnu90uu92uLl26lHu+nj9OVFSUIiMj5e/vrx49emj06NEXvOafP0bLli3Vtm3bcj9/lZ2v54/ToUMHDRkyxGUfP/jgA91yyy0KCQlRUFCQevTooczMzErHCQ8Pl7e3d5njbLPZ5O3trcGDB2vLli2Vfg4/+ugj+fn5lTtGUFCQ/P39FRMTo8suu0wBAQFq1aqVHnzwQeXm5pbZz9atW5c7jp+fnxITE7VmzRpJlX8uKxqjTZs2zmNz5ZVXqnfv3goKClJwcLD69u2rM2fOVLmeRo0aKSoqSv7+/goKClJQUJAaN26sO+64Qzk5Oc7PWGRkpAICApSYmOg8xyq7Bs+ePVutW7eWv7+/4uPjtXbt2jI1wRpkW7KtRLYl25JtybZkW7It2ZZsWz+Qbcm2EtmWbEu2JduSbcm2ZFtPyLY0KtTA1VdfraysLOfXV199VeFrV61apTvvvFP33nuvNm7cqKFDh2ro0KHasmVLHVZ8YadOnVKnTp00e/bsMs+dPn1aGzZs0LRp07RhwwZ99NFH2rZtm2655ZZKxzx69Kj69OkjHx8f/fe//9X333+vF198UU2bNq2t3XCqbH+MMRo6dKh+/PFHffrpp9q4caNiY2OVmJioU6dOXXDs3bt367HHHtN11113yeteuXKlJkyYoNWrV2vp0qUqLCxUUlJSmbrGjRvncg4+99xzFxx78ODBLuu8++67F11ndHS0/vjHPyo9PV3r16/XDTfcoFtvvVXfffedJOmRRx7Rv//9b33wwQdauXKl9u/fr9tuu63C8Wr6nlS1Lql6x+5S1LVu3Tq9/vrr6tixo8vy6h6jc3388cdavXq1oqKiLmrbDrNmzZLNZqvSNi+07Yq2NXr0aG3btk2fffaZvv32W91222264447tHHjRknlX08XLFigSZMm6bLLLlNYWJgGDRokLy8v/fTTTxc8Rs8995z+/Oc/6+abb9bll1+upKQkxcTEaNeuXS7X6m7dumnu3LnaunWrPv/8cxljlJSUpKKiogrHLigoUFhYmF544QVJ0tKlS8tc/6tzfl199dW66667FBsbqw8//FDr16/Xww8/rIkTJ2rIkCFljtvw4cPVo0ePCq+p0dHR6t69u/z8/PSXv/xF9957r7755hvdcMMNysvLc273/Gvzc889p4MHD+rhhx/Whg0bdPXVV+vdd9/Vgw8+WOE1v7zr+/33368pU6aU+fy9/PLLFZ6v54+Tlpamo0ePKjAw0Dnuo48+qvHjx6tDhw5asWKFNm/erGnTpsnf37/CcUaPHq2zZ8/qhRde0OrVqzVjxgxJ0uWXXy5JeuuttxQbG6uEhAR99tlnFX4OmzVrptdff10rV65UWlqannnmGedzU6ZM0TvvvKOioiKdPn1a6enpmjdvnhYvXqx77723zL6uW7fOeV7Mnj1bf/rTnyRJc+bMUevWrZWUlKSDBw9W+rk8d4ysrCz9/e9/lyTFx8drxYoVmjdvnjIzM3XDDTdo7dq1WrdunSZOnCi7vWzsc4yVnJysdu3a6cUXX5QknT17VseOHVPz5s11zTXXSJImTJiggoICJScn609/+pP+/Oc/a86cOVqzZo2CgoI0aNAg5eXlVXgNfuGFFzRp0iRNnz5dGzZsUKdOnTRo0CAdOHCg3P1E3SPbkm3JtmRbsi3ZlmxLtiXbkm3rC7It2ZZsS7Yl25JtybZkW7KtB2Rbg4syffp006lTpyq//o477jA33XSTy7L4+Hhz//33X+LKLh1J5uOPP670NWvXrjWSzE8//VThax5//HFz7bXXXuLqqu/8/dm2bZuRZLZs2eJcVlRUZFq0aGH++te/VjrW2bNnTe/evc3f/vY3M2bMGHPrrbfWUtUlDhw4YCSZlStXOpddf/315qGHHqrWOHVRa9OmTc3f/vY3c+zYMePj42M++OAD53Nbt241kkxaWlq569bkPalqXcZU/9jVtK4TJ06YK664wixdutRl2xdzjBz27t1rWrZsabZs2WJiY2PNSy+9VK1tO2zcuNG0bNnSZGVlVekzX9m2K9tWUFCQ+cc//uEyTrNmzcxf//rXCq+nPXv2NPfdd5/zGBUVFZmoqCjzyCOPVHqMiouLTUREhHn++eedYx87dsz4+fmZd999t9J9++abb4wks2PHjgpf4xhz165dRpLZuHGjy/PVOb8cY1199dXmmWeecXmua9euxsfHp8xx8/f3N23btq1wzHP336FJkybG29vbZf/Pvzb37NnTTJgwwfmz43inpKQ4l51/za/q9T0kJMQ0bdq0wvP1/HHKG3fEiBHmV7/6VaXbOX+9yMhI85e//MX5s+Oz3Lp1a3P55Zeb4uJic+TIESPJPPDAA87XXehzWFxcbGw2mwkICDDFxcXGGFPmHHv//feNr6+vKSwsrLTmhx56yFlLbm6ukWTmzJlTrc/lFVdcYRo1auSsJT4+3kydOrXSdc51+vRp4+XlZf7zn/+Yhx56yAQGBpqxY8eatm3bGpvNZnJzc81tt91m7rrrLnPs2DEjyTRr1szlHLvQZ6xp06amTZs2FzzHYB2ybQmyLdn2fGTbssi2ZNsLjUW2JduSbWE1sm0Jsi3Z9nxk27LItmTbC41FtiXbkm1rF3dUqIGMjAxFRUXpsssu01133VXmNibnSktLU2JiosuyQYMGKS0trbbLrFW5ubmy2Wxq0qRJha/57LPP1L17dw0fPlxhYWHq0qWL/vrXv9ZdkRXIz8+XJJeuLrvdLj8/v0q7rCXpmWeeUVhYWLldV7XBcRuaZs2auSx/5513nF1TU6ZM0enTpy841ooVKxQWFqb27dvr//7v/3T48OFLUmNRUZHee+89nTp1SgkJCUpPT1dhYaHLed+hQwe1atWqwvO+Ju9JVetyqM6xq2ldEyZM0E033VTmGnAxx0iSiouLNWrUKP32t7/V1VdffVHblkq67UeOHKnZs2crIiLigvtxoW1Xtq3evXtrwYIFOnLkiIqLi/Xee+8pLy9P/fr1k1T2erpjxw6lp6crJibGeYzsdrsSExO1c+fOSo/Rrl27lJ2d7awjIyNDV155pWw2m5566qkKr9WnTp3S3Llz1aZNG8XExFR6HDIyMhQfHy9JeuKJJ8qMWZ3zKyMjQ7t27dL/+3//T8OGDdNPP/2k5cuXa/v27erUqVOZ45afn69rr722wmvqufvvOP9Pnz6tzp07uxyz86/Na9euVXFxsfN5x/E+d53zr/kXur4XFRVp/vz5On78uO6///4Kz9fzx5k1a5b8/PycP3fu3FmffPKJ2rVrp0GDBiksLEzx8fFlbq11/jgHDhxwuUWV47OcmZmpe+65Rzabzdkdfu7tvir7HBpjNG/ePBljNHDgQGf3bEhIiOLj453r5ObmKjg4WN7e3uXus1TS5f3222/rnnvuUWFhod544w0FBwdr5syZVf5c5uXlOc/HwYMHq3nz5lqzZo2ys7PVu3dvhYeH6/rrr6/0WnX27FkVFRXJy8tLb7/9tvr06aMvvvhCxcXFMsZo27Zt+uqrrzRkyBD5+/vLbrfryJEjLp/18/ffwXEOnjx5UpmZmS7rlHeOwVpkW7It2fZnZNuKkW3JtmRbsm15yLZkW3dDtiXbkm1/RratGNmWbEu2JduWh2xbh9m21lsh6qlFixaZ999/33zzzTdm8eLFJiEhwbRq1cocP3683Nf7+PiY+fPnuyybPXu2CQsLq4tyL4ou0A105swZ07VrVzNy5MhKx/Hz8zN+fn5mypQpZsOGDeb11183/v7+Zt68eZe44sqdvz8FBQWmVatWZvjw4ebIkSMmPz/f/PGPfzSSTFJSUoXj/O9//zMtW7Y0Bw8eNMbUfrdrUVGRuemmm0yfPn1clr/++utm8eLFZvPmzebtt982LVu2NMOGDat0rHfffdd8+umnZvPmzebjjz82V155penRo4c5e/bsRde3efNmExQUZLy8vExISIhZuHChMcaYd955x/j6+pZ5fY8ePczvfve7cse62PekOnUZU/1jV5O63n33XXPNNdeYM2fOGGNcuzYv5hgZY8yMGTPMwIEDnV14FXXmVrZtY4wZP368uffee50/X+gzX9m2L7Sto0ePmqSkJCPJeHt7m+DgYPP5558bY8q/nrZs2dJIMk899ZTLMfrtb39revbsWekx+vrrr40ks3//fpexr7vuOhMaGlrmWj179mwTFBRkJJn27dtX2pV7br2LFi0ykkzHjh1dxqzO+eUYa926dWbAgAFGkpFkfHx8zN///vdyj5uPj0+l11TH/gcEBLic/8OHDzd33HGHc9vnXps///xzI8n4+vq6XJsdx9uY8q/5FV3fn332Wefnz8/Pz3Tp0qXS8/X8cby9vY0kc9NNN5kNGzaY5557zlnfzJkzzcaNG01KSoqx2WxmxYoVFY7To0cPY7PZzB//+EdTVFTkfM8kme+++87k5+ebX/7yl+V+ls8/x44dO2aCgoKMt7e38fLyMpLMhg0bXNZxHOODBw+aVq1amSeeeKLSc2nBggXGbrebgIAAY7PZTFRUlBk2bFi1Ppevv/66kWT8/f3NzJkzzd///nfnPj7++ONmw4YN5uGHHza+vr5m+/btFY6TkJBgrrzySuPl5WV2795tbr75Zuc4js/iyZMnzcSJE53L9u/fX+7+G1P2GvyPf/zDSDKrVq1yWefccwzWItuSbcm2Jci2ZFuyLdmWbFuCbEu29WRkW7It2bYE2ZZsS7Yl25JtS5Bt3Tfb0qhwiRw9etQEBwc7b1F0vvoWeAsKCkxycrLp0qWLyc3NrXQcHx8fk5CQ4LLsN7/5jenVq9elKrVKytuf9evXm06dOhlJxsvLywwaNMgMGTLEDB48uNwxjh8/blq3bm0WLVrkXFbbgfeBBx4wsbGxZs+ePZW+LjU19YK3Pjrfzp07jSSzbNmyi64vPz/fZGRkmPXr15vJkyeb5s2bm+++++6iw1x135Pq1lWeqhy7i6krMzPThIWFmW+++ca5rKaBd/369SY8PNzs27fPuay8AHGhbX/66aembdu25sSJE87nL/SLtaJtP/nkk5VuyxhjJk6caHr27GmWLVtmNm3aZJ566ikTEhJiNm/eXGY7R48eNY0bN74kgfdcw4cPN0OHDi1zrT527JjZvn27WblypUlOTjZdu3Z1BvfKOG4h9uWXX1Z6/a/K+fX888+bdu3amfnz55tGjRqZkSNHmkaNGplbb721zHGTVOaWa+deUx37//XXX7uc/4MGDXIJvOdem/ft22ckmV/84hcu12bH8a7oml/R9T0+Pt5kZGSYf/7znyYoKMg0bdrU+fkr73w9fxwfHx8TERHhrMVRX2hoqMt6ycnJ5pe//GWF4xw4cMC0adPG+blt166dCQ8PdwY2Ly8vExcXZ2w2W5nP8vnnWFFRkcnIyDAbN240MTExRpL517/+5bLO8OHDzbBhw0zPnj3N4MGDTUFBgalMUlKSGTJkiMnIyDBpaWkmMTHReHt7mx9//NH5mgt9Lq+//nojydx5553GmJ/f/7Zt27ocm7i4ODN58uQKx9mxY4dp2rSpkWRsNpvx8fExffr0MeHh4aZFixbO5b/61a9Mu3btLhh4z78GO8bmH3M9B9m2YmTbmiHbkm3Pr4NsS7Yl25Yg25JtUXvIthUj29YM2ZZse34dZFuyLdm2BNmWbFtVNCpcQt27d6/wZIqJiSnzAX/yySdNx44d66Cyi1PRh6ygoMAMHTrUdOzY0Rw6dOiC47Rq1cqly8gYY1599VUTFRV1qUqtksouGseOHTMHDhwwxpTM9/PrX/+63Ndt3LjReZF0fNlsNmOz2YyXl1e1wmZVTJgwwURHR7tc/Cpy8uRJI8ksXry4Wtto3ry5mTNnzsWWWMaAAQPM+PHjnb/kjx496vJ8q1atzMyZMy84TlXfk+rWVZ7qHLvq1PXxxx+XOV8cvzS8vLzMsmXLqn2MXnrpJef6545pt9tNbGxslbc9ceLECse5/vrrq7Vtm81W6bZ27NhhJNe54owpeU8qmu+xW7duxmazmaefftrlGI0ePdrccsstlR4jx3/InT8HWd++fc2DDz5Y6bU6Pz/fBAYGlvkHivKcO9dZZWNe6Pw6ffq08fHxMf/5z3+MMT//Lhk+fHi5x83f39906NDBZdm519Ty9n/AgAEmMjLSPPjgg85l516b8/PzjZeXl7n//vtdrs2jR482N998c4XX/Atd3x3nzLnXyfLO1/PHadWqlendu7dznPz8fGO3203jxo1dtvW73/3O9O7d+4L1REZGmr1795pdu3YZm81mYmJinJ9lx7Xq/PUqOsd2795t7Ha7kVTmH2569+5tIiIizIABAy74H02OcT755BPnsoceesh5fKryuXSMYbfbzbPPPmuMMebHH390djWfe2zuuOOOSv+SxjHWe++955wj7o477jA33nijMcaYyZMnmyuuuMIYY0xoaGiln7Hy9O/f39hstjK/hx2fabgnsm35yLYXj2xLtj0f2ZZsS7b9GdmWbIvaRbYtH9n24pFtybbnI9uSbcm2PyPbkm2ryi5cEidPntTOnTsVGRlZ7vMJCQlKTU11WbZ06VKXuZc8QWFhoe644w5lZGRo2bJlCg0NveA6ffr00bZt21yWbd++XbGxsbVVZrWFhISoRYsWysjI0Pr163XrrbeW+7oOHTro22+/1aZNm5xft9xyi/r3769NmzZdcH6kqjLGaOLEifr444/1xRdfqE2bNhdcZ9OmTZJU4TlYnr179+rw4cPVWudCiouLlZ+fr27dusnHx8flvN+2bZsyMzOrdN5X9T2pbl3lqc6xq05dAwYMKHO+dO/eXXfddZfzcXWP0ahRo7R582aXMaOiovTb3/5Wn3/+eZW3/fvf/77MOJL00ksvae7cudXa9kMPPaTPPvuswm055vmy211/5Xh5ebnMreVw8uRJ/fjjj4qJidHevXudx6i4uFipqalq27ZtpceoTZs2ioiIcDmux48f15o1a9SlS5dKr9WmpIGvwnOlPKdPn650zAudX4WFhSosLJTdbnf5XWKMkVT2uDVp0kRHjx51WXbuNbW8/S8oKFBOTo7LMTv32uzr66tu3bpp9erVznGKi4u1bNky/fjjjxVe8y90fXecM927d1dycnKF5+v54/Tp00e7d+92juPr66vw8HD5+flVuK3K6mndurVatmypN998U3a7XSNHjnR+lh3ztp37/lT2OZw7d67CwsLk7++vAwcOOJfv3btXaWlpatq0qT777DOXuRHL4xjnpptuci6bPHmyoqOjdf/991fpc+kYo2fPns79bt26taKiopSRkeFybC70e9cx1u233678/Hzl5eXp888/d17jgoODJUlffPGFDh8+rBYtWpT7Gavs+h4aGuqyjuMz7WlZqKEg21aMbFt9ZFuyLdmWbEu2JduSbWElsm3FyLbVR7Yl25JtybZkW7It2fYSqvVWiHrq0UcfNStWrDC7du0yX3/9tUlMTDTNmzd3duyNGjXKpUvr66+/Nt7e3uaFF14wW7duNdOnTzc+Pj7m22+/tWoXynXixAmzceNGZweqY06Zn376yRQUFJhbbrnFREdHm02bNpmsrCznV35+vnOMG264wbzyyivOn9euXWu8vb3NH/7wB5ORkWHeeecdExgYaN5++21L98cYY95//32zfPlys3PnTvPJJ5+Y2NhYc9ttt7mMcf57eb7auIXY//3f/5mQkBCzYsUKl+N8+vRpY0zJrV6eeeYZs379erNr1y7z6aefmssuu8z07dvXZZz27dubjz76yBhTciwee+wxk5aWZnbt2mWWLVtmunbtaq644gqTl5d3UXVOnjzZrFy50uzatcts3rzZTJ482dhsNrNkyRJjTMntz1q1amW++OILs379epOQkFDmdkPn1mhM1d6TmtR1McfuUtVlTNlba13MMTpfRXOdXWjb51M53esXu+1zt1VQUGDatm1rrrvuOrNmzRqzY8cO88ILLxibzWYWLlzovJ4mJCSYRx55xHk9feONN4yfn5/p37+/iYyMNDfffLNp1KiR6d69+wWP0R//+EfTpEkTM3ToUPPWW2+ZgQMHmsjISHPDDTc4r9U7d+40M2bMMOvXrzc//fST+frrr01ycrJp1qyZycnJqXDsCRMmmL/+9a/mrbfeMpJMXFycadKkifn222+rfX459j0+Pt60adPGdOvWzTRr1sy8/PLLxs/Pz7Ro0aLMcVNpF7TjmnrVVVcZX19f5zV18uTJ5v777zfBwcHm5ZdfNvfcc4+RZCIiIly6Rbt3727sdrtzHMccVuPHjzfff/+9ue+++4y3t7eJioqq8Jq/du1aY7PZzM033+y8vvv4+JipU6dWeF0o75w5v5ZnnnnGSDLDhw93juvr62u8vLzMG2+8YTIyMswrr7xivLy8zP/+9z/nOEOGDHEZ5+mnnzZ+fn5m5syZZsWKFcbPz88EBgaaf//73y6f5TZt2rh8Dlu0aGFatmzpHHfGjBkmOjra/OUvfzGRkZGmf//+xm63m8DAQPPpp5+aVatWmaZNmxofHx/z3XffuRyrc+eSdLzvRUVFJiYmxvTq1cukpaWZ3bt3m/Xr15uxY8caPz8/l27sij6X//rXv0yrVq3M448/bj766CPj4+PjPDa33XabkWSeeeYZk5GRYaZOnWr8/f1d/nrk3N/VRUVFJiwszAwfPtz8+OOPZuDAgcbHx8e0a9fOpKSkmJSUFNO0aVNz0003mWbNmplJkyY5P2Offvqp6dmzp4mLizNt2rQxZ86ccV6De/fubaZMmeI8B5544gnj5+dn5s2bZ77//nszfvx406RJE5OdnW1gPbIt2daBbEu2rQ6yLdn23DHJtuXXQrYl26LukW3Jtg5kW7JtdZBtybbnjkm2Lb8Wsi3Z9lKjUeEijRgxwkRGRhpfX1/TsmVLM2LECJcT6frrrzdjxoxxWef999837dq1M76+vubqq682CxcurOOqL2z58uVGUpmvMWPGOG+XU97X8uXLnWPExsaa6dOnu4z773//21xzzTXGz8/PdOjQwbzxxhuW748xxrz88ssmOjra+Pj4mFatWpmpU6e6hHdjyn8vz1Ubgbei4zx37lxjTMk8Vn379jXNmjUzfn5+pm3btua3v/1tmXnnzl3n9OnTJikpybRo0cL4+PiY2NhYM27cuBpdaO655x4TGxtrfH19TYsWLcyAAQOcv9SMMebMmTPm17/+tWnatKkJDAw0w4YNM1lZWRXWaEzV3pOa1HUxx+5S1WVM2dB5McfofLUZeC922+dva/v27ea2224zYWFhJjAw0HTs2NH84x//MMb8fD2VZBo3buxyPX3llVdMTEyM85ZK/v7+VTpGxcXFZtq0acbPz895O7Pw8HCXsfft22eGDBliwsLCjI+Pj4mOjjYjR440P/zwQ6Vj9+zZs9zP5/Tp06t9fp37uyQwMND4+/sbX19f0759e/Piiy+abdu2lXvczr2ment7m5tvvtk59j333GNatWpl7Ha7sdlsxm63my5dupht27aVee/uvPNOl2vzL3/5S9OqVSvj6+vrnNvvQtf8Fi1amLCwMOcYffr0qfS6UN45U14tEydOLPN748033zRt27Y1/v7+plOnTi6333KcdzfccINzvVatWpmIiAjj5+fnnD/vwQcfLPNZzs3NdfkcNm/e3GVeuN///vfOW3lJMp07dzbvvvuumTZtmgkPDzc+Pj4VHqtdu3aVed8///xzI8kkJiaaqKgo4+vrayIjI80tt9xi1q5dW+ZcKe9z+eijjxpJzvf1/GMzatQoEx0dbQIDA01CQoLLfxg4jrnjd7WjnujoaOPr62vCwsJMx44dTXR0tPH29jZeXl7Gbrebtm3bmhdffNEUFxc7P2OOuePatGnjrMVxDZZkAgMDXc6BV155xXmO9ezZ06xevdrAPZBtybYOZFuybXWQbcm2545Jtq24FrLtz+uQbVEXyLZkWweyLdm2Osi2ZNtzxyTbVlwL2fbndci2NWcrPXAAAAAAAAAAAAAAAAC1zn7hlwAAAAAAAAAAAAAAAFwaNCoAAAAAAAAAAAAAAIA6Q6MCAAAAAAAAAAAAAACoMzQqAAAAAAAAAAAAAACAOkOjAgAAAAAAAAAAAAAAqDM0KgAAAAAAAAAAAAAAgDpDowIAAAAAAAAAAAAAAKgzNCoAAAAAAAAAAAAAAIA6Q6MCADRATz31lMLDw2Wz2fTJJ59UaZ0VK1bIZrPp2LFjtVqbO2ndurVmzZpldRkAAACoBNm2asi2AAAA7o9sWzVkW6B+oFEBgFu4++67ZbPZZLPZ5Ovrq7Zt2+qZZ57R2bNnrS7tgqoTGt3B1q1b9fTTT+v1119XVlaWhgwZUmvb6tevnx5++OFaGx8AAMAdkW3rDtkWAACgdpFt6w7ZFkBD4211AQDgMHjwYM2dO1f5+flatGiRJkyYIB8fH02ZMqXaYxUVFclms8lupx/rfDt37pQk3XrrrbLZbBZXAwAAUD+RbesG2RYAAKD2kW3rBtkWQEPDbwIAbsPPz08RERGKjY3V//3f/ykxMVGfffaZJCk/P1+PPfaYWrZsqaCgIMXHx2vFihXOdefNm6cmTZros88+01VXXSU/Pz9lZmYqPz9fjz/+uGJiYuTn56e2bdvqzTffdK63ZcsWDRkyRI0aNVJ4eLhGjRqlQ4cOOZ/v16+fHnzwQf3ud79Ts2bNFBERoaeeesr5fOvWrSVJw4YNk81mc/68c+dO3XrrrQoPD1ejRo3Uo0cPLVu2zGV/s7KydNNNNykgIEBt2rTR/Pnzy9yy6tixY7rvvvvUokULBQcH64YbbtA333xT6XH89ttvdcMNNyggIEChoaEaP368Tp48Kank1mHJycmSJLvdXmngXbRokdq1a6eAgAD1799fu3fvdnn+8OHDuvPOO9WyZUsFBgYqLi5O7777rvP5u+++WytXrtTLL7/s7LrevXu3ioqKdO+996pNmzYKCAhQ+/bt9fLLL1e6T47391yffPKJS/3ffPON+vfvr8aNGys4OFjdunXT+vXrnc9/9dVXuu666xQQEKCYmBg9+OCDOnXqlPP5AwcOKDk52fl+vPPOO5XWBAAAUBmyLdm2ImRbAADgaci2ZNuKkG0B1ASNCgDcVkBAgAoKCiRJEydOVFpamt577z1t3rxZw4cP1+DBg5WRkeF8/enTp/WnP/1Jf/vb3/Tdd98pLCxMo0eP1rvvvqs///nP2rp1q15//XU1atRIUkmYvOGGG9SlSxetX79eixcvVk5Oju644w6XOv7+978rKChIa9as0XPPPadnnnlGS5culSStW7dOkjR37lxlZWU5fz558qRuvPFGpaamauPGjRo8eLCSk5OVmZnpHHf06NHav3+/VqxYoQ8//FBvvPGGDhw44LLt4cOH68CBA/rvf/+r9PR0de3aVQMGDNCRI0fKPWanTp3SoEGD1LRpU61bt04ffPCBli1bpokTJ0qSHnvsMc2dO1dSSeDOysoqd5w9e/botttuU3JysjZt2qT77rtPkydPdnlNXl6eunXrpoULF2rLli0aP368Ro0apbVr10qSXn75ZSUkJGjcuHHObcXExKi4uFjR0dH64IMP9P333+vJJ5/UE088offff7/cWqrqrrvuUnR0tNatW6f09HRNnjxZPj4+kkr+A2Tw4MG6/fbbtXnzZi1YsEBfffWV87hIJQF9z549Wr58uf71r3/p1VdfLfN+AAAAXCyyLdm2Osi2AADAnZFtybbVQbYFUCEDAG5gzJgx5tZbbzXGGFNcXGyWLl1q/Pz8zGOPPWZ++ukn4+XlZfbt2+eyzoABA8yUKVOMMcbMnTvXSDKbNm1yPr9t2zYjySxdurTcbT777LMmKSnJZdmePXuMJLNt2zZjjDHXX3+9ufbaa11e06NHD/P44487f5ZkPv744wvu49VXX21eeeUVY4wxW7duNZLMunXrnM9nZGQYSeall14yxhjzv//9zwQHB5u8vDyXcS6//HLz+uuvl7uNN954wzRt2tScPHnSuWzhwoXGbreb7OxsY4wxH3/8sbnQ5X/KlCnmqquucln2+OOPG0nm6NGjFa530003mUcffdT58/XXX28eeuihSrdljDETJkwwt99+e4XPz50714SEhLgsO38/GjdubObNm1fu+vfee68ZP368y7L//e9/xm63mzNnzjjPlbVr1zqfd7xHjvcDAACgqsi2ZFuyLQAAqC/ItmRbsi2A2uJd650QAFBF//nPf9SoUSMVFhaquLhYI0eO1FNPPaUVK1aoqKhI7dq1c3l9fn6+QkNDnT/7+vqqY8eOzp83bdokLy8vXX/99eVu75tvvtHy5cudnbrn2rlzp3N7544pSZGRkRfs2Dx58qSeeuopLVy4UFlZWTp79qzOnDnj7Mzdtm2bvL291bVrV+c6bdu2VdOmTV3qO3nypMs+StKZM2ec85Wdb+vWrerUqZOCgoKcy/r06aPi4mJt27ZN4eHhldZ97jjx8fEuyxISElx+Lioq0owZM/T+++9r3759KigoUH5+vgIDAy84/uzZs/XWW28pMzNTZ86cUUFBgTp37lyl2ioyadIk3XffffrnP/+pxMREDR8+XJdffrmkkmO5efNml9uCGWNUXFysXbt2afv27fL29la3bt2cz3fo0KHMbcsAAACqimxLtq0Jsi0AAHAnZFuybU2QbQFUhEYFAG6jf//+eu211+Tr66uoqCh5e5dcok6ePCkvLy+lp6fLy8vLZZ1zw2pAQIDL3FcBAQGVbu/kyZNKTk7Wn/70pzLPRUZGOh87bkPlYLPZVFxcXOnYjz32mJYuXaoXXnhBbdu2VUBAgH7xi184b4lWFSdPnlRkZKTLnG4O7hDEnn/+eb388suaNWuW4uLiFBQUpIcffviC+/jee+/pscce04svvqiEhAQ1btxYzz//vNasWVPhOna7XcYYl2WFhYUuPz/11FMaOXKkFi5cqP/+97+aPn263nvvPQ0bNkwnT57U/fffrwcffLDM2K1atdL27dursecAAAAXRrYtWx/ZtgTZFgAAeBqybdn6yLYlyLYAaoJGBQBuIygoSG3bti2zvEuXLioqKtKBAwd03XXXVXm8uLg4FRcXa+XKlUpMTCzzfNeuXfXhhx+qdevWznB9MXx8fFRUVOSy7Ouvv9bdd9+tYcOGSSoJr7t373Y+3759e509e1YbN250doPu2LFDR48edakvOztb3t7eat26dZVqufLKKzVv3jydOnXK2Z379ddfy263q3379lXepyuvvFKfffaZy7LVq1eX2cdbb71Vv/rVryRJxcXF2r59u6666irna3x9fcs9Nr1799avf/1r57KKOo0dWrRooRMnTrjs16ZNm8q8rl27dmrXrp0eeeQR3XnnnZo7d66GDRumrl276vvvvy/3/JJKunDPnj2r9PR09ejRQ1JJ9/SxY8cqrQsAAKAiZFuybUXItgAAwNOQbcm2FSHbAqgJu9UFAMCFtGvXTnfddZdGjx6tjz76SLt27dLatWuVkpKihQsXVrhe69atNWbMGN1zzz365JNPtGvXLq1YsULvv/++JGnChAk6cuSI7rzzTq1bt047d+7U559/rrFjx5YJaZVp3bq1UlNTlZ2d7QysV1xxhT766CNt2rRJ33zzjUaOHOnSzduhQwclJiZq/PjxWrt2rTZu3Kjx48e7dBcnJiYqISFBQ4cO1ZIlS7R7926tWrVKv//977V+/fpya7nrrrvk7++vMWPGaMuWLVq+fLl+85vfaNSoUVW+fZgkPfDAA8rIyNBvf/tbbdu2TfPnz9e8efNcXnPFFVdo6dKlWrVqlbZu3ar7779fOTk5ZY7NmjVrtHv3bh06dEjFxcW64oortH79en3++efavn27pk2bpnXr1lVaT3x8vAIDA/XEE09o586dZeo5c+aMJk6cqBUrVuinn37S119/rXXr1unKK6+UJD3++ONatWqVJk6cqE2bNikjI0OffvqpJk6cKKnkP0AGDx6s+++/X2vWrFF6erruu+++C3Z3AwAAVBfZlmxLtgUAAPUF2ZZsS7YFUBM0KgDwCHPnztXo0aP16KOPqn379ho6dKjWrVunVq1aVbrea6+9pl/84hf69a9/rQ4dOmjcuHE6deqUJCkqKkpff/21ioqKlJSUpLi4OD388MNq0qSJ7PaqXx5ffPFFLV26VDExMerSpYskaebMmWratKl69+6t5ORkDRo0yGVeM0n6xz/+ofDwcPXt21fDhg3TuHHj1LhxY/n7+0squVXZokWL1LdvX40dO1bt2rXTL3/5S/30008VhtfAwEB9/vnnOnLkiHr06KFf/OIXGjBggP7yl79UeX+kkttqffjhh/rkk0/UqVMnzZkzRzNmzHB5zdSpU9W1a1cNGjRI/fr1U0REhIYOHerymscee0xeXl666qqr1KJFC2VmZur+++/XbbfdphEjRig+Pl6HDx926dItT7NmzfT2229r0aJFiouL07vvvqunnnrK+byXl5cOHz6s0aNHq127drrjjjs0ZMgQPf3005JK5qtbuXKltm/fruuuu05dunTRk08+qaioKOcYc+fOVVRUlK6//nrddtttGj9+vMLCwqp13AAAAKqCbEu2JdsCAID6gmxLtiXbArhYNnP+5DEAAEvs3btXMTExWrZsmQYMGGB1OQAAAMBFI9sCAACgviDbAkDtoFEBACzyxRdf6OTJk4qLi1NWVpZ+97vfad++fdq+fbt8fHysLg8AAACoMrItAAAA6guyLQDUDW+rCwCAhqqwsFBPPPGEfvzxRzVu3Fi9e/fWO++8Q9gFAACAxyHbAgAAoL4g2wJA3eCOCgAAAAAAAAAAAAAAoM7YrS4AAAAAAAAAAAAAAAA0HDQqAAAAAAAAAAAAAACAOkOjAgAAAAAAAAAAAAAAqDM0KgAAAAAAAAAAAAAAgDpDowIAAAAAAAAAAAAAAKgzNCoAAAAAAAAAAAAAAIA6Q6MCAAAAAAAAAAAAAACoMzQqAAAAAAAAAAAAAACAOkOjAgAAAAAAAAAAAAAAqDP/H87JFlE0CT2cAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[2], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707d8c63",
   "metadata": {
    "papermill": {
     "duration": 0.146157,
     "end_time": "2025-03-26T10:31:02.223996",
     "exception": false,
     "start_time": "2025-03-26T10:31:02.077839",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5d8601a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T10:31:02.516642Z",
     "iopub.status.busy": "2025-03-26T10:31:02.516280Z",
     "iopub.status.idle": "2025-03-26T11:23:00.473448Z",
     "shell.execute_reply": "2025-03-26T11:23:00.472615Z"
    },
    "papermill": {
     "duration": 3118.104454,
     "end_time": "2025-03-26T11:23:00.475018",
     "exception": false,
     "start_time": "2025-03-26T10:31:02.370564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 4\n",
      "Random seed: 3\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6456, Accuracy: 0.7865, F1 Micro: 0.8804, F1 Macro: 0.8788\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5639, Accuracy: 0.7894, F1 Micro: 0.8822, F1 Macro: 0.8807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5346, Accuracy: 0.7894, F1 Micro: 0.8822, F1 Macro: 0.8807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5259, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4788, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Epoch 6/10, Train Loss: 0.477, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 7/10, Train Loss: 0.4707, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4588, Accuracy: 0.7909, F1 Micro: 0.883, F1 Macro: 0.8814\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.4215, Accuracy: 0.7932, F1 Micro: 0.8839, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3936, Accuracy: 0.7976, F1 Micro: 0.8857, F1 Macro: 0.884\n",
      "\n",
      "Aspect detection accuracy: 0.7976, F1 Micro: 0.8857, F1 Macro: 0.884\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.78      1.00      0.88       175\n",
      "      others       0.76      0.96      0.84       158\n",
      "        part       0.71      1.00      0.83       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.80      0.99      0.89      1061\n",
      "   macro avg       0.80      0.99      0.88      1061\n",
      "weighted avg       0.80      0.99      0.89      1061\n",
      " samples avg       0.80      0.99      0.88      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7056, Accuracy: 0.44, F1 Micro: 0.44, F1 Macro: 0.4318\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5997, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5241, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5185, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.494, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4806, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4617, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.422, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3873, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2944, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "\n",
      "Sentiment analysis accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         4\n",
      "    positive       0.84      1.00      0.91        21\n",
      "\n",
      "    accuracy                           0.84        25\n",
      "   macro avg       0.42      0.50      0.46        25\n",
      "weighted avg       0.71      0.84      0.77        25\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.7948, F1 Micro: 0.7948, F1 Macro: 0.3169\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.78      1.00      0.87       167\n",
      "    positive       1.00      0.03      0.06        33\n",
      "\n",
      "    accuracy                           0.78       216\n",
      "   macro avg       0.59      0.34      0.31       216\n",
      "weighted avg       0.75      0.78      0.68       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.76      0.95      0.84       152\n",
      "    positive       0.54      0.25      0.34        52\n",
      "\n",
      "    accuracy                           0.73       216\n",
      "   macro avg       0.43      0.40      0.40       216\n",
      "weighted avg       0.66      0.73      0.68       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        23\n",
      "     neutral       0.70      1.00      0.83       152\n",
      "    positive       0.00      0.00      0.00        41\n",
      "\n",
      "    accuracy                           0.70       216\n",
      "   macro avg       0.23      0.33      0.28       216\n",
      "weighted avg       0.50      0.70      0.58       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 61.6584358215332 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.004583974834531546\n",
      "Acquired samples: 82\n",
      "Sampling duration: 11.933347940444946 seconds\n",
      "New train size: 136\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6153, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5348, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5414, Accuracy: 0.7917, F1 Micro: 0.8831, F1 Macro: 0.8815\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4788, Accuracy: 0.7932, F1 Micro: 0.8837, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4659, Accuracy: 0.7984, F1 Micro: 0.8838, F1 Macro: 0.8818\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4186, Accuracy: 0.7991, F1 Micro: 0.8849, F1 Macro: 0.883\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3801, Accuracy: 0.8162, F1 Micro: 0.8939, F1 Macro: 0.892\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3471, Accuracy: 0.8423, F1 Micro: 0.9072, F1 Macro: 0.9052\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3055, Accuracy: 0.8661, F1 Micro: 0.9194, F1 Macro: 0.9175\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2636, Accuracy: 0.8884, F1 Micro: 0.9321, F1 Macro: 0.93\n",
      "\n",
      "Aspect detection accuracy: 0.8884, F1 Micro: 0.9321, F1 Macro: 0.93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.96      0.98      0.97       187\n",
      "     machine       0.90      0.92      0.91       175\n",
      "      others       0.84      0.97      0.90       158\n",
      "        part       0.84      0.94      0.89       158\n",
      "       price       0.92      1.00      0.96       192\n",
      "     service       0.90      1.00      0.95       191\n",
      "\n",
      "   micro avg       0.90      0.97      0.93      1061\n",
      "   macro avg       0.90      0.97      0.93      1061\n",
      "weighted avg       0.90      0.97      0.93      1061\n",
      " samples avg       0.90      0.97      0.93      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4978, Accuracy: 0.7316, F1 Micro: 0.7316, F1 Macro: 0.4225\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3169, Accuracy: 0.7316, F1 Micro: 0.7316, F1 Macro: 0.4225\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.365, Accuracy: 0.7316, F1 Micro: 0.7316, F1 Macro: 0.4225\n",
      "Epoch 4/10, Train Loss: 0.316, Accuracy: 0.7211, F1 Micro: 0.7211, F1 Macro: 0.4366\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2623, Accuracy: 0.8211, F1 Micro: 0.8211, F1 Macro: 0.7356\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1749, Accuracy: 0.8842, F1 Micro: 0.8842, F1 Macro: 0.8561\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0848, Accuracy: 0.8947, F1 Micro: 0.8947, F1 Macro: 0.8643\n",
      "Epoch 8/10, Train Loss: 0.0578, Accuracy: 0.8737, F1 Micro: 0.8737, F1 Macro: 0.8448\n",
      "Epoch 9/10, Train Loss: 0.0887, Accuracy: 0.8789, F1 Micro: 0.8789, F1 Macro: 0.8504\n",
      "Epoch 10/10, Train Loss: 0.0397, Accuracy: 0.8263, F1 Micro: 0.8263, F1 Macro: 0.7363\n",
      "\n",
      "Sentiment analysis accuracy: 0.8947, F1 Micro: 0.8947, F1 Macro: 0.8643\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.78      0.80        51\n",
      "    positive       0.92      0.94      0.93       139\n",
      "\n",
      "    accuracy                           0.89       190\n",
      "   macro avg       0.87      0.86      0.86       190\n",
      "weighted avg       0.89      0.89      0.89       190\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 136: Accuracy: 0.8758, F1 Micro: 0.8758, F1 Macro: 0.7039\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.97      0.98      0.98       181\n",
      "    positive       0.83      0.83      0.83        24\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.85      0.88       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.50      0.59        16\n",
      "     neutral       0.90      0.92      0.91       167\n",
      "    positive       0.63      0.67      0.65        33\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.75      0.69      0.72       216\n",
      "weighted avg       0.85      0.85      0.84       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.40      0.33      0.36        12\n",
      "     neutral       0.84      0.97      0.90       152\n",
      "    positive       0.88      0.54      0.67        52\n",
      "\n",
      "    accuracy                           0.83       216\n",
      "   macro avg       0.71      0.61      0.64       216\n",
      "weighted avg       0.83      0.83      0.82       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.39      0.56        23\n",
      "     neutral       0.84      0.94      0.89       152\n",
      "    positive       0.61      0.54      0.57        41\n",
      "\n",
      "    accuracy                           0.81       216\n",
      "   macro avg       0.82      0.62      0.67       216\n",
      "weighted avg       0.81      0.81      0.79       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.38      0.56        13\n",
      "     neutral       0.93      1.00      0.96       186\n",
      "    positive       0.90      0.53      0.67        17\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.94      0.64      0.73       216\n",
      "weighted avg       0.93      0.93      0.91       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.43      0.60        14\n",
      "     neutral       0.90      1.00      0.95       185\n",
      "    positive       0.50      0.12      0.19        17\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.80      0.52      0.58       216\n",
      "weighted avg       0.87      0.89      0.86       216\n",
      "\n",
      "Total train time: 73.66679954528809 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.013268014416098595\n",
      "Acquired samples: 73\n",
      "Sampling duration: 15.145131826400757 seconds\n",
      "New train size: 209\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6074, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5185, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5029, Accuracy: 0.7932, F1 Micro: 0.8841, F1 Macro: 0.8825\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4546, Accuracy: 0.8021, F1 Micro: 0.8869, F1 Macro: 0.8849\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4157, Accuracy: 0.817, F1 Micro: 0.8943, F1 Macro: 0.8924\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3683, Accuracy: 0.8504, F1 Micro: 0.9116, F1 Macro: 0.9096\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3175, Accuracy: 0.8876, F1 Micro: 0.9317, F1 Macro: 0.9293\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2691, Accuracy: 0.9048, F1 Micro: 0.9416, F1 Macro: 0.9392\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2204, Accuracy: 0.9159, F1 Micro: 0.9478, F1 Macro: 0.9444\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1784, Accuracy: 0.9256, F1 Micro: 0.9542, F1 Macro: 0.9518\n",
      "\n",
      "Aspect detection accuracy: 0.9256, F1 Micro: 0.9542, F1 Macro: 0.9518\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.89      0.98      0.93       175\n",
      "      others       0.89      0.91      0.90       158\n",
      "        part       0.87      0.98      0.92       158\n",
      "       price       0.96      1.00      0.98       192\n",
      "     service       0.97      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.93      0.98      0.95      1061\n",
      "   macro avg       0.93      0.98      0.95      1061\n",
      "weighted avg       0.93      0.98      0.95      1061\n",
      " samples avg       0.93      0.98      0.95      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5923, Accuracy: 0.7023, F1 Micro: 0.7023, F1 Macro: 0.5266\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4121, Accuracy: 0.7674, F1 Micro: 0.7674, F1 Macro: 0.7485\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2347, Accuracy: 0.8558, F1 Micro: 0.8558, F1 Macro: 0.8408\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1629, Accuracy: 0.8651, F1 Micro: 0.8651, F1 Macro: 0.8537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1278, Accuracy: 0.8791, F1 Micro: 0.8791, F1 Macro: 0.8602\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0837, Accuracy: 0.8837, F1 Micro: 0.8837, F1 Macro: 0.8716\n",
      "Epoch 7/10, Train Loss: 0.0739, Accuracy: 0.8791, F1 Micro: 0.8791, F1 Macro: 0.8669\n",
      "Epoch 8/10, Train Loss: 0.0654, Accuracy: 0.8791, F1 Micro: 0.8791, F1 Macro: 0.8652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0576, Accuracy: 0.8837, F1 Micro: 0.8837, F1 Macro: 0.8708\n",
      "Epoch 10/10, Train Loss: 0.0426, Accuracy: 0.8605, F1 Micro: 0.8605, F1 Macro: 0.8491\n",
      "\n",
      "Sentiment analysis accuracy: 0.8837, F1 Micro: 0.8837, F1 Macro: 0.8708\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.91      0.83        67\n",
      "    positive       0.96      0.87      0.91       148\n",
      "\n",
      "    accuracy                           0.88       215\n",
      "   macro avg       0.86      0.89      0.87       215\n",
      "weighted avg       0.90      0.88      0.89       215\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 209: Accuracy: 0.9082, F1 Micro: 0.9082, F1 Macro: 0.8079\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.98      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.44      0.58        16\n",
      "     neutral       0.89      0.98      0.93       167\n",
      "    positive       0.78      0.55      0.64        33\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.85      0.65      0.72       216\n",
      "weighted avg       0.87      0.88      0.86       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.36      0.75      0.49        12\n",
      "     neutral       0.90      0.91      0.90       152\n",
      "    positive       0.70      0.50      0.58        52\n",
      "\n",
      "    accuracy                           0.80       216\n",
      "   macro avg       0.65      0.72      0.66       216\n",
      "weighted avg       0.82      0.80      0.80       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.61      0.74        23\n",
      "     neutral       0.86      0.98      0.92       152\n",
      "    positive       0.89      0.61      0.72        41\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.90      0.73      0.79       216\n",
      "weighted avg       0.87      0.87      0.86       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.62      0.76        13\n",
      "     neutral       0.96      1.00      0.98       186\n",
      "    positive       0.86      0.71      0.77        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.94      0.77      0.84       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       0.97      1.00      0.98       185\n",
      "    positive       1.00      0.59      0.74        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.97      0.86      0.90       216\n",
      "weighted avg       0.97      0.97      0.96       216\n",
      "\n",
      "Total train time: 85.09667634963989 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.011933714151382446\n",
      "Acquired samples: 66\n",
      "Sampling duration: 14.714749813079834 seconds\n",
      "New train size: 275\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5913, Accuracy: 0.7879, F1 Micro: 0.8812, F1 Macro: 0.8795\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5126, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4885, Accuracy: 0.8006, F1 Micro: 0.8858, F1 Macro: 0.8833\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.438, Accuracy: 0.808, F1 Micro: 0.8903, F1 Macro: 0.8884\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3894, Accuracy: 0.8504, F1 Micro: 0.9107, F1 Macro: 0.9084\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3263, Accuracy: 0.8936, F1 Micro: 0.9337, F1 Macro: 0.9299\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2697, Accuracy: 0.9144, F1 Micro: 0.9473, F1 Macro: 0.9448\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2127, Accuracy: 0.9338, F1 Micro: 0.9587, F1 Macro: 0.9564\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1691, Accuracy: 0.9427, F1 Micro: 0.9641, F1 Macro: 0.962\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1388, Accuracy: 0.9509, F1 Micro: 0.9694, F1 Macro: 0.968\n",
      "\n",
      "Aspect detection accuracy: 0.9509, F1 Micro: 0.9694, F1 Macro: 0.968\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.90      0.94      0.92       158\n",
      "        part       0.95      0.99      0.97       158\n",
      "       price       0.96      1.00      0.98       192\n",
      "     service       0.96      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.95      0.99      0.97      1061\n",
      "   macro avg       0.95      0.98      0.97      1061\n",
      "weighted avg       0.95      0.99      0.97      1061\n",
      " samples avg       0.95      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5611, Accuracy: 0.6778, F1 Micro: 0.6778, F1 Macro: 0.404\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4104, Accuracy: 0.8243, F1 Micro: 0.8243, F1 Macro: 0.7913\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1865, Accuracy: 0.887, F1 Micro: 0.887, F1 Macro: 0.8743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1344, Accuracy: 0.9079, F1 Micro: 0.9079, F1 Macro: 0.8967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1217, Accuracy: 0.9079, F1 Micro: 0.9079, F1 Macro: 0.8915\n",
      "Epoch 6/10, Train Loss: 0.0852, Accuracy: 0.887, F1 Micro: 0.887, F1 Macro: 0.8777\n",
      "Epoch 7/10, Train Loss: 0.055, Accuracy: 0.8828, F1 Micro: 0.8828, F1 Macro: 0.8649\n",
      "Epoch 8/10, Train Loss: 0.0602, Accuracy: 0.8912, F1 Micro: 0.8912, F1 Macro: 0.8771\n",
      "Epoch 9/10, Train Loss: 0.0415, Accuracy: 0.887, F1 Micro: 0.887, F1 Macro: 0.8728\n",
      "Epoch 10/10, Train Loss: 0.052, Accuracy: 0.8912, F1 Micro: 0.8912, F1 Macro: 0.8807\n",
      "\n",
      "Sentiment analysis accuracy: 0.9079, F1 Micro: 0.9079, F1 Macro: 0.8915\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.81      0.85        77\n",
      "    positive       0.91      0.96      0.93       162\n",
      "\n",
      "    accuracy                           0.91       239\n",
      "   macro avg       0.91      0.88      0.89       239\n",
      "weighted avg       0.91      0.91      0.91       239\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 275: Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.8548\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.98      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.56      0.72        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.78      0.85      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.91      0.80      0.83       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.56      0.75      0.64        12\n",
      "     neutral       0.90      0.94      0.92       152\n",
      "    positive       0.80      0.63      0.71        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.76      0.78      0.76       216\n",
      "weighted avg       0.86      0.86      0.85       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.65      0.79        23\n",
      "     neutral       0.94      0.99      0.96       152\n",
      "    positive       0.81      0.83      0.82        41\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.92      0.82      0.86       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.69      0.82        13\n",
      "     neutral       0.96      1.00      0.98       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.96      0.82      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.96      1.00      0.98       185\n",
      "    positive       0.85      0.65      0.73        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.81      0.86       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Total train time: 92.18461465835571 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.010881591401994229\n",
      "Acquired samples: 59\n",
      "Sampling duration: 13.455919981002808 seconds\n",
      "New train size: 334\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5733, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4944, Accuracy: 0.7976, F1 Micro: 0.8853, F1 Macro: 0.8834\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4463, Accuracy: 0.8147, F1 Micro: 0.8924, F1 Macro: 0.8901\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3781, Accuracy: 0.8497, F1 Micro: 0.9097, F1 Macro: 0.9071\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3113, Accuracy: 0.9062, F1 Micro: 0.9417, F1 Macro: 0.9383\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2498, Accuracy: 0.9308, F1 Micro: 0.9568, F1 Macro: 0.9533\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.194, Accuracy: 0.9427, F1 Micro: 0.964, F1 Macro: 0.9617\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.154, Accuracy: 0.9479, F1 Micro: 0.9676, F1 Macro: 0.9656\n",
      "Epoch 9/10, Train Loss: 0.13, Accuracy: 0.9472, F1 Micro: 0.9667, F1 Macro: 0.964\n",
      "Epoch 10/10, Train Loss: 0.1071, Accuracy: 0.9479, F1 Micro: 0.967, F1 Macro: 0.9637\n",
      "\n",
      "Aspect detection accuracy: 0.9479, F1 Micro: 0.9676, F1 Macro: 0.9656\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.94      0.99      0.96       175\n",
      "      others       0.91      0.91      0.91       158\n",
      "        part       0.93      0.99      0.96       158\n",
      "       price       0.96      1.00      0.98       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.95      0.98      0.97      1061\n",
      "   macro avg       0.95      0.98      0.97      1061\n",
      "weighted avg       0.95      0.98      0.97      1061\n",
      " samples avg       0.95      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5925, Accuracy: 0.6527, F1 Micro: 0.6527, F1 Macro: 0.513\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3382, Accuracy: 0.8117, F1 Micro: 0.8117, F1 Macro: 0.8031\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.208, Accuracy: 0.8912, F1 Micro: 0.8912, F1 Macro: 0.88\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1746, Accuracy: 0.8954, F1 Micro: 0.8954, F1 Macro: 0.8732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1323, Accuracy: 0.8996, F1 Micro: 0.8996, F1 Macro: 0.8834\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1105, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9262\n",
      "Epoch 7/10, Train Loss: 0.1082, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.9042\n",
      "Epoch 8/10, Train Loss: 0.0559, Accuracy: 0.9289, F1 Micro: 0.9289, F1 Macro: 0.9213\n",
      "Epoch 9/10, Train Loss: 0.0419, Accuracy: 0.9289, F1 Micro: 0.9289, F1 Macro: 0.9199\n",
      "Epoch 10/10, Train Loss: 0.0521, Accuracy: 0.9289, F1 Micro: 0.9289, F1 Macro: 0.9199\n",
      "\n",
      "Sentiment analysis accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9262\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.95      0.90        79\n",
      "    positive       0.97      0.93      0.95       160\n",
      "\n",
      "    accuracy                           0.93       239\n",
      "   macro avg       0.92      0.94      0.93       239\n",
      "weighted avg       0.94      0.93      0.93       239\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 334: Accuracy: 0.9367, F1 Micro: 0.9367, F1 Macro: 0.8766\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.94      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.88      0.70      0.78        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.92      0.83      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.83      0.71        12\n",
      "     neutral       0.91      0.91      0.91       152\n",
      "    positive       0.75      0.69      0.72        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.76      0.81      0.78       216\n",
      "weighted avg       0.85      0.85      0.85       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.78      0.82        23\n",
      "     neutral       0.93      0.99      0.96       152\n",
      "    positive       0.91      0.71      0.79        41\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.90      0.83      0.86       216\n",
      "weighted avg       0.92      0.92      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.96      1.00      0.98       186\n",
      "    positive       0.92      0.65      0.76        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.81      0.86       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.71      0.83        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.90      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 93.30573916435242 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.009536482393741608\n",
      "Acquired samples: 54\n",
      "Sampling duration: 12.002360820770264 seconds\n",
      "New train size: 388\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5726, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4894, Accuracy: 0.7984, F1 Micro: 0.886, F1 Macro: 0.8842\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4479, Accuracy: 0.8214, F1 Micro: 0.8956, F1 Macro: 0.8927\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3578, Accuracy: 0.8802, F1 Micro: 0.9283, F1 Macro: 0.9257\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2776, Accuracy: 0.9338, F1 Micro: 0.959, F1 Macro: 0.9574\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2264, Accuracy: 0.9435, F1 Micro: 0.9645, F1 Macro: 0.9625\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1661, Accuracy: 0.9442, F1 Micro: 0.9648, F1 Macro: 0.9614\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1398, Accuracy: 0.9487, F1 Micro: 0.9677, F1 Macro: 0.9649\n",
      "Epoch 9/10, Train Loss: 0.1171, Accuracy: 0.9449, F1 Micro: 0.9652, F1 Macro: 0.9617\n",
      "Epoch 10/10, Train Loss: 0.0824, Accuracy: 0.9464, F1 Micro: 0.9663, F1 Macro: 0.9635\n",
      "\n",
      "Aspect detection accuracy: 0.9487, F1 Micro: 0.9677, F1 Macro: 0.9649\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.94      0.85      0.89       158\n",
      "        part       0.93      0.99      0.96       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.97      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.97      0.97      1061\n",
      "   macro avg       0.96      0.97      0.96      1061\n",
      "weighted avg       0.96      0.97      0.97      1061\n",
      " samples avg       0.96      0.97      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5233, Accuracy: 0.8206, F1 Micro: 0.8206, F1 Macro: 0.7814\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.228, Accuracy: 0.8511, F1 Micro: 0.8511, F1 Macro: 0.8386\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.152, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.8928\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0961, Accuracy: 0.9122, F1 Micro: 0.9122, F1 Macro: 0.8969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0785, Accuracy: 0.9237, F1 Micro: 0.9237, F1 Macro: 0.91\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0454, Accuracy: 0.9237, F1 Micro: 0.9237, F1 Macro: 0.9094\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0618, Accuracy: 0.9275, F1 Micro: 0.9275, F1 Macro: 0.9148\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0573, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9248\n",
      "Epoch 9/10, Train Loss: 0.0272, Accuracy: 0.9237, F1 Micro: 0.9237, F1 Macro: 0.9124\n",
      "Epoch 10/10, Train Loss: 0.0293, Accuracy: 0.9275, F1 Micro: 0.9275, F1 Macro: 0.916\n",
      "\n",
      "Sentiment analysis accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9248\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.91      0.90        81\n",
      "    positive       0.96      0.94      0.95       181\n",
      "\n",
      "    accuracy                           0.94       262\n",
      "   macro avg       0.92      0.93      0.92       262\n",
      "weighted avg       0.94      0.94      0.94       262\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 388: Accuracy: 0.9367, F1 Micro: 0.9367, F1 Macro: 0.8834\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.83      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.59      0.83      0.69        12\n",
      "     neutral       0.94      0.85      0.89       152\n",
      "    positive       0.66      0.79      0.72        52\n",
      "\n",
      "    accuracy                           0.83       216\n",
      "   macro avg       0.73      0.82      0.77       216\n",
      "weighted avg       0.85      0.83      0.84       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.78      0.86        23\n",
      "     neutral       0.93      0.99      0.96       152\n",
      "    positive       0.89      0.76      0.82        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.92      0.84      0.88       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.84      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.97      1.00      0.99       185\n",
      "    positive       1.00      0.76      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.99      0.90      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 104.14241981506348 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.01041125413030386\n",
      "Acquired samples: 48\n",
      "Sampling duration: 11.19733214378357 seconds\n",
      "New train size: 436\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.558, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4933, Accuracy: 0.7946, F1 Micro: 0.8828, F1 Macro: 0.8801\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4259, Accuracy: 0.8408, F1 Micro: 0.9068, F1 Macro: 0.905\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.343, Accuracy: 0.9129, F1 Micro: 0.9471, F1 Macro: 0.9454\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2488, Accuracy: 0.9397, F1 Micro: 0.9626, F1 Macro: 0.9603\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1928, Accuracy: 0.9449, F1 Micro: 0.9655, F1 Macro: 0.9629\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1487, Accuracy: 0.9494, F1 Micro: 0.9683, F1 Macro: 0.966\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1154, Accuracy: 0.9516, F1 Micro: 0.9696, F1 Macro: 0.967\n",
      "Epoch 9/10, Train Loss: 0.0981, Accuracy: 0.9494, F1 Micro: 0.9682, F1 Macro: 0.9658\n",
      "Epoch 10/10, Train Loss: 0.0801, Accuracy: 0.9509, F1 Micro: 0.969, F1 Macro: 0.9665\n",
      "\n",
      "Aspect detection accuracy: 0.9516, F1 Micro: 0.9696, F1 Macro: 0.967\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.93      0.87      0.90       158\n",
      "        part       0.94      0.99      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.97      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.97      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5468, Accuracy: 0.8053, F1 Micro: 0.8053, F1 Macro: 0.7836\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2362, Accuracy: 0.874, F1 Micro: 0.874, F1 Macro: 0.8614\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1285, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.8961\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1074, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.8961\n",
      "Epoch 5/10, Train Loss: 0.0635, Accuracy: 0.9008, F1 Micro: 0.9008, F1 Macro: 0.8838\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0706, Accuracy: 0.916, F1 Micro: 0.916, F1 Macro: 0.901\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0424, Accuracy: 0.9198, F1 Micro: 0.9198, F1 Macro: 0.9045\n",
      "Epoch 8/10, Train Loss: 0.0455, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.8967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0383, Accuracy: 0.9198, F1 Micro: 0.9198, F1 Macro: 0.9077\n",
      "Epoch 10/10, Train Loss: 0.0383, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.8955\n",
      "\n",
      "Sentiment analysis accuracy: 0.9198, F1 Micro: 0.9198, F1 Macro: 0.9077\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.90      0.87        81\n",
      "    positive       0.95      0.93      0.94       181\n",
      "\n",
      "    accuracy                           0.92       262\n",
      "   macro avg       0.90      0.91      0.91       262\n",
      "weighted avg       0.92      0.92      0.92       262\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 436: Accuracy: 0.939, F1 Micro: 0.939, F1 Macro: 0.885\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.62      0.74        16\n",
      "     neutral       0.94      0.99      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.79      0.84       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.53      0.83      0.65        12\n",
      "     neutral       0.93      0.86      0.89       152\n",
      "    positive       0.70      0.75      0.72        52\n",
      "\n",
      "    accuracy                           0.83       216\n",
      "   macro avg       0.72      0.82      0.75       216\n",
      "weighted avg       0.85      0.83      0.84       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.78      0.84        23\n",
      "     neutral       0.94      0.99      0.96       152\n",
      "    positive       0.89      0.76      0.82        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.91      0.84      0.87       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.89      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 105.90310549736023 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.009925566799938678\n",
      "Acquired samples: 43\n",
      "Sampling duration: 10.12532901763916 seconds\n",
      "New train size: 479\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5559, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4768, Accuracy: 0.8021, F1 Micro: 0.8865, F1 Macro: 0.8841\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.403, Accuracy: 0.8571, F1 Micro: 0.9159, F1 Macro: 0.9144\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3193, Accuracy: 0.9338, F1 Micro: 0.9593, F1 Macro: 0.958\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.243, Accuracy: 0.9449, F1 Micro: 0.9656, F1 Macro: 0.9634\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1739, Accuracy: 0.9509, F1 Micro: 0.9693, F1 Macro: 0.9672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1379, Accuracy: 0.9554, F1 Micro: 0.972, F1 Macro: 0.9706\n",
      "Epoch 8/10, Train Loss: 0.1152, Accuracy: 0.9524, F1 Micro: 0.9699, F1 Macro: 0.9675\n",
      "Epoch 9/10, Train Loss: 0.0948, Accuracy: 0.9509, F1 Micro: 0.9691, F1 Macro: 0.9669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0792, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9721\n",
      "\n",
      "Aspect detection accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9721\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.92      0.93      0.93       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.98      0.99      0.98       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5202, Accuracy: 0.8465, F1 Micro: 0.8465, F1 Macro: 0.8238\n",
      "Epoch 2/10, Train Loss: 0.2467, Accuracy: 0.8189, F1 Micro: 0.8189, F1 Macro: 0.8128\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1432, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.9049\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1172, Accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.9063\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0805, Accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.909\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0613, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9246\n",
      "Epoch 7/10, Train Loss: 0.0544, Accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.9069\n",
      "Epoch 8/10, Train Loss: 0.0459, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9167\n",
      "Epoch 9/10, Train Loss: 0.0495, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9176\n",
      "Epoch 10/10, Train Loss: 0.0375, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9131\n",
      "\n",
      "Sentiment analysis accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9246\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.93      0.90        82\n",
      "    positive       0.96      0.94      0.95       172\n",
      "\n",
      "    accuracy                           0.93       254\n",
      "   macro avg       0.92      0.93      0.92       254\n",
      "weighted avg       0.93      0.93      0.93       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 479: Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.8965\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.69      0.79        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.81      0.85       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.83      0.71        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.81      0.75      0.78        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.79      0.84      0.81       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87        23\n",
      "     neutral       0.96      0.99      0.98       152\n",
      "    positive       0.89      0.78      0.83        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.88      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.98       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.99      0.92      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 106.32359790802002 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.007467305054888129\n",
      "Acquired samples: 39\n",
      "Sampling duration: 9.39028811454773 seconds\n",
      "New train size: 518\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5287, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4697, Accuracy: 0.8043, F1 Micro: 0.8874, F1 Macro: 0.8847\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3849, Accuracy: 0.8966, F1 Micro: 0.9371, F1 Macro: 0.9345\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2838, Accuracy: 0.9397, F1 Micro: 0.9628, F1 Macro: 0.9617\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2082, Accuracy: 0.9568, F1 Micro: 0.9732, F1 Macro: 0.9723\n",
      "Epoch 6/10, Train Loss: 0.1504, Accuracy: 0.9568, F1 Micro: 0.9731, F1 Macro: 0.972\n",
      "Epoch 7/10, Train Loss: 0.1218, Accuracy: 0.9435, F1 Micro: 0.9643, F1 Macro: 0.9611\n",
      "Epoch 8/10, Train Loss: 0.0988, Accuracy: 0.9554, F1 Micro: 0.972, F1 Macro: 0.9704\n",
      "Epoch 9/10, Train Loss: 0.0758, Accuracy: 0.9561, F1 Micro: 0.9724, F1 Macro: 0.9708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0656, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9718\n",
      "\n",
      "Aspect detection accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9718\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.92      0.92      0.92       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5622, Accuracy: 0.8423, F1 Micro: 0.8423, F1 Macro: 0.8056\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2569, Accuracy: 0.8731, F1 Micro: 0.8731, F1 Macro: 0.8635\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1791, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9182\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1098, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9127\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0944, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9231\n",
      "Epoch 6/10, Train Loss: 0.1003, Accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.911\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0685, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9268\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0341, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9272\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0517, Accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9381\n",
      "Epoch 10/10, Train Loss: 0.0483, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9338\n",
      "\n",
      "Sentiment analysis accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9381\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.93      0.92        82\n",
      "    positive       0.97      0.96      0.96       178\n",
      "\n",
      "    accuracy                           0.95       260\n",
      "   macro avg       0.94      0.94      0.94       260\n",
      "weighted avg       0.95      0.95      0.95       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 518: Accuracy: 0.9491, F1 Micro: 0.9491, F1 Macro: 0.9011\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.84      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.75      0.72        12\n",
      "     neutral       0.92      0.91      0.92       152\n",
      "    positive       0.79      0.79      0.79        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.80      0.82      0.81       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.90      0.85      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.92      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.84      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.96      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 114.46987700462341 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0034715426620095967\n",
      "Acquired samples: 22\n",
      "Sampling duration: 8.77057695388794 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5356, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4787, Accuracy: 0.8103, F1 Micro: 0.8906, F1 Macro: 0.8881\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3853, Accuracy: 0.9092, F1 Micro: 0.9445, F1 Macro: 0.9418\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2802, Accuracy: 0.9472, F1 Micro: 0.9674, F1 Macro: 0.9664\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.207, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9732\n",
      "Epoch 6/10, Train Loss: 0.1541, Accuracy: 0.9457, F1 Micro: 0.9657, F1 Macro: 0.9629\n",
      "Epoch 7/10, Train Loss: 0.119, Accuracy: 0.9539, F1 Micro: 0.9711, F1 Macro: 0.9698\n",
      "Epoch 8/10, Train Loss: 0.0948, Accuracy: 0.9561, F1 Micro: 0.9724, F1 Macro: 0.9706\n",
      "Epoch 9/10, Train Loss: 0.0809, Accuracy: 0.9568, F1 Micro: 0.9728, F1 Macro: 0.9713\n",
      "Epoch 10/10, Train Loss: 0.0691, Accuracy: 0.9546, F1 Micro: 0.9714, F1 Macro: 0.9696\n",
      "\n",
      "Aspect detection accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9732\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.91      0.96      0.93       158\n",
      "        part       0.95      0.99      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.97      1061\n",
      "   macro avg       0.96      0.99      0.97      1061\n",
      "weighted avg       0.96      0.99      0.97      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5201, Accuracy: 0.8361, F1 Micro: 0.8361, F1 Macro: 0.8262\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2293, Accuracy: 0.9262, F1 Micro: 0.9262, F1 Macro: 0.9158\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1412, Accuracy: 0.9467, F1 Micro: 0.9467, F1 Macro: 0.9394\n",
      "Epoch 4/10, Train Loss: 0.1132, Accuracy: 0.9221, F1 Micro: 0.9221, F1 Macro: 0.9149\n",
      "Epoch 5/10, Train Loss: 0.0979, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9274\n",
      "Epoch 6/10, Train Loss: 0.067, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9274\n",
      "Epoch 7/10, Train Loss: 0.07, Accuracy: 0.9221, F1 Micro: 0.9221, F1 Macro: 0.913\n",
      "Epoch 8/10, Train Loss: 0.066, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.93\n",
      "Epoch 9/10, Train Loss: 0.051, Accuracy: 0.9221, F1 Micro: 0.9221, F1 Macro: 0.9149\n",
      "Epoch 10/10, Train Loss: 0.034, Accuracy: 0.9303, F1 Micro: 0.9303, F1 Macro: 0.9217\n",
      "\n",
      "Sentiment analysis accuracy: 0.9467, F1 Micro: 0.9467, F1 Macro: 0.9394\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.92      0.92        79\n",
      "    positive       0.96      0.96      0.96       165\n",
      "\n",
      "    accuracy                           0.95       244\n",
      "   macro avg       0.94      0.94      0.94       244\n",
      "weighted avg       0.95      0.95      0.95       244\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.901\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.94      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.67      0.73        12\n",
      "     neutral       0.91      0.95      0.93       152\n",
      "    positive       0.85      0.77      0.81        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.85      0.80      0.82       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.74      0.79        23\n",
      "     neutral       0.95      0.99      0.97       152\n",
      "    positive       0.86      0.78      0.82        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.84      0.86       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.99      0.92      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 102.21245288848877 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.00647987388074398\n",
      "Acquired samples: 33\n",
      "Sampling duration: 7.745713472366333 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5457, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4756, Accuracy: 0.8177, F1 Micro: 0.8946, F1 Macro: 0.8924\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3848, Accuracy: 0.9152, F1 Micro: 0.9486, F1 Macro: 0.947\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2755, Accuracy: 0.9479, F1 Micro: 0.9674, F1 Macro: 0.9656\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1864, Accuracy: 0.9501, F1 Micro: 0.9689, F1 Macro: 0.9669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1441, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1129, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9736\n",
      "Epoch 8/10, Train Loss: 0.0997, Accuracy: 0.9524, F1 Micro: 0.9699, F1 Macro: 0.9676\n",
      "Epoch 9/10, Train Loss: 0.0748, Accuracy: 0.9457, F1 Micro: 0.9657, F1 Macro: 0.9625\n",
      "Epoch 10/10, Train Loss: 0.0642, Accuracy: 0.9583, F1 Micro: 0.9737, F1 Macro: 0.9721\n",
      "\n",
      "Aspect detection accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9736\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.97      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5129, Accuracy: 0.8696, F1 Micro: 0.8696, F1 Macro: 0.8588\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1933, Accuracy: 0.917, F1 Micro: 0.917, F1 Macro: 0.9097\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1805, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9348\n",
      "Epoch 4/10, Train Loss: 0.1027, Accuracy: 0.9209, F1 Micro: 0.9209, F1 Macro: 0.9142\n",
      "Epoch 5/10, Train Loss: 0.0826, Accuracy: 0.9249, F1 Micro: 0.9249, F1 Macro: 0.9183\n",
      "Epoch 6/10, Train Loss: 0.0765, Accuracy: 0.9249, F1 Micro: 0.9249, F1 Macro: 0.9183\n",
      "Epoch 7/10, Train Loss: 0.0766, Accuracy: 0.9249, F1 Micro: 0.9249, F1 Macro: 0.917\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0644, Accuracy: 0.9486, F1 Micro: 0.9486, F1 Macro: 0.9432\n",
      "Epoch 9/10, Train Loss: 0.0385, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9257\n",
      "Epoch 10/10, Train Loss: 0.0402, Accuracy: 0.9447, F1 Micro: 0.9447, F1 Macro: 0.939\n",
      "\n",
      "Sentiment analysis accuracy: 0.9486, F1 Micro: 0.9486, F1 Macro: 0.9432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.98      0.93        83\n",
      "    positive       0.99      0.94      0.96       170\n",
      "\n",
      "    accuracy                           0.95       253\n",
      "   macro avg       0.93      0.96      0.94       253\n",
      "weighted avg       0.95      0.95      0.95       253\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.9058\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.85      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.82      0.77      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.82      0.85      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.92      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.97      1.00      0.99       185\n",
      "    positive       1.00      0.76      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.99      0.90      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 112.32171702384949 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.004701798129826784\n",
      "Acquired samples: 30\n",
      "Sampling duration: 7.2984232902526855 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5372, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4703, Accuracy: 0.8177, F1 Micro: 0.8952, F1 Macro: 0.8933\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3737, Accuracy: 0.9122, F1 Micro: 0.9451, F1 Macro: 0.9415\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2666, Accuracy: 0.9375, F1 Micro: 0.9609, F1 Macro: 0.9578\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1981, Accuracy: 0.9554, F1 Micro: 0.9722, F1 Macro: 0.9713\n",
      "Epoch 6/10, Train Loss: 0.1544, Accuracy: 0.9554, F1 Micro: 0.9719, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1165, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9753\n",
      "Epoch 8/10, Train Loss: 0.0898, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9742\n",
      "Epoch 9/10, Train Loss: 0.0735, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9722\n",
      "Epoch 10/10, Train Loss: 0.0666, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9721\n",
      "\n",
      "Aspect detection accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9753\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.98       192\n",
      "     service       0.97      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5234, Accuracy: 0.874, F1 Micro: 0.874, F1 Macro: 0.852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2522, Accuracy: 0.9016, F1 Micro: 0.9016, F1 Macro: 0.8942\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1693, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.9058\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1266, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9226\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0984, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9226\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0686, Accuracy: 0.9528, F1 Micro: 0.9528, F1 Macro: 0.947\n",
      "Epoch 7/10, Train Loss: 0.0627, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.935\n",
      "Epoch 8/10, Train Loss: 0.043, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.9063\n",
      "Epoch 9/10, Train Loss: 0.048, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9343\n",
      "Epoch 10/10, Train Loss: 0.05, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9218\n",
      "\n",
      "Sentiment analysis accuracy: 0.9528, F1 Micro: 0.9528, F1 Macro: 0.947\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93        83\n",
      "    positive       0.98      0.95      0.96       171\n",
      "\n",
      "    accuracy                           0.95       254\n",
      "   macro avg       0.94      0.95      0.95       254\n",
      "weighted avg       0.95      0.95      0.95       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9076\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.97      0.98      0.97       167\n",
      "    positive       0.85      0.88      0.87        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.89      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.92      0.96      0.94       152\n",
      "    positive       0.87      0.75      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.84      0.82      0.83       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.92      0.80      0.86        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.92      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.98       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       0.97      1.00      0.99       185\n",
      "    positive       1.00      0.71      0.83        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.99      0.90      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 119.868976354599 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.004004768049344421\n",
      "Acquired samples: 27\n",
      "Sampling duration: 6.687666416168213 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.539, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4558, Accuracy: 0.8214, F1 Micro: 0.8973, F1 Macro: 0.8954\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3627, Accuracy: 0.9323, F1 Micro: 0.9584, F1 Macro: 0.9569\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2493, Accuracy: 0.9524, F1 Micro: 0.9703, F1 Macro: 0.9689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1793, Accuracy: 0.9531, F1 Micro: 0.9706, F1 Macro: 0.969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1327, Accuracy: 0.9583, F1 Micro: 0.974, F1 Macro: 0.9729\n",
      "Epoch 7/10, Train Loss: 0.105, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9711\n",
      "Epoch 8/10, Train Loss: 0.0867, Accuracy: 0.9561, F1 Micro: 0.9722, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0694, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9738\n",
      "Epoch 10/10, Train Loss: 0.0585, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9724\n",
      "\n",
      "Aspect detection accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9738\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.91      0.94      0.93       158\n",
      "        part       0.96      1.00      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.97      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.97      1061\n",
      "   macro avg       0.96      0.99      0.97      1061\n",
      "weighted avg       0.96      0.99      0.97      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5104, Accuracy: 0.8735, F1 Micro: 0.8735, F1 Macro: 0.8592\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2429, Accuracy: 0.9306, F1 Micro: 0.9306, F1 Macro: 0.9252\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1536, Accuracy: 0.9469, F1 Micro: 0.9469, F1 Macro: 0.9422\n",
      "Epoch 4/10, Train Loss: 0.1325, Accuracy: 0.9429, F1 Micro: 0.9429, F1 Macro: 0.9373\n",
      "Epoch 5/10, Train Loss: 0.09, Accuracy: 0.9429, F1 Micro: 0.9429, F1 Macro: 0.9354\n",
      "Epoch 6/10, Train Loss: 0.078, Accuracy: 0.9347, F1 Micro: 0.9347, F1 Macro: 0.9287\n",
      "Epoch 7/10, Train Loss: 0.0514, Accuracy: 0.9429, F1 Micro: 0.9429, F1 Macro: 0.9379\n",
      "Epoch 8/10, Train Loss: 0.0599, Accuracy: 0.9429, F1 Micro: 0.9429, F1 Macro: 0.9379\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0531, Accuracy: 0.951, F1 Micro: 0.951, F1 Macro: 0.9465\n",
      "Epoch 10/10, Train Loss: 0.0437, Accuracy: 0.9429, F1 Micro: 0.9429, F1 Macro: 0.9337\n",
      "\n",
      "Sentiment analysis accuracy: 0.951, F1 Micro: 0.951, F1 Macro: 0.9465\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.93        83\n",
      "    positive       0.99      0.94      0.96       162\n",
      "\n",
      "    accuracy                           0.95       245\n",
      "   macro avg       0.94      0.96      0.95       245\n",
      "weighted avg       0.95      0.95      0.95       245\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.9049\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.85      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.92      0.94      0.93       152\n",
      "    positive       0.83      0.73      0.78        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.82      0.83      0.82       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.96      1.00      0.98       152\n",
      "    positive       1.00      0.76      0.86        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.94      0.92      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.97      1.00      0.98       185\n",
      "    positive       1.00      0.71      0.83        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.99      0.88      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 120.81195402145386 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.004896873701363802\n",
      "Acquired samples: 18\n",
      "Sampling duration: 6.26512885093689 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5244, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4421, Accuracy: 0.8281, F1 Micro: 0.9, F1 Macro: 0.8981\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3414, Accuracy: 0.9345, F1 Micro: 0.9596, F1 Macro: 0.9579\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2347, Accuracy: 0.9561, F1 Micro: 0.9728, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1645, Accuracy: 0.9606, F1 Micro: 0.9754, F1 Macro: 0.9742\n",
      "Epoch 6/10, Train Loss: 0.1207, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0971, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9759\n",
      "Epoch 8/10, Train Loss: 0.082, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9749\n",
      "Epoch 9/10, Train Loss: 0.0641, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9747\n",
      "Epoch 10/10, Train Loss: 0.0589, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9759\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.91      0.95      0.93       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5201, Accuracy: 0.8765, F1 Micro: 0.8765, F1 Macro: 0.864\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2518, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9292\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1624, Accuracy: 0.9402, F1 Micro: 0.9402, F1 Macro: 0.9346\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1133, Accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9388\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0936, Accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9374\n",
      "Epoch 6/10, Train Loss: 0.0659, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9304\n",
      "Epoch 7/10, Train Loss: 0.0802, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.9016\n",
      "Epoch 8/10, Train Loss: 0.0568, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9254\n",
      "Epoch 9/10, Train Loss: 0.0318, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9242\n",
      "Epoch 10/10, Train Loss: 0.0502, Accuracy: 0.9243, F1 Micro: 0.9243, F1 Macro: 0.9148\n",
      "\n",
      "Sentiment analysis accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9374\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        84\n",
      "    positive       0.96      0.96      0.96       167\n",
      "\n",
      "    accuracy                           0.94       251\n",
      "   macro avg       0.94      0.94      0.94       251\n",
      "weighted avg       0.94      0.94      0.94       251\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9066\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       0.88      0.96      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.90      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.83      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.85      0.75      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.84      0.82      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        23\n",
      "     neutral       0.96      0.99      0.98       152\n",
      "    positive       1.00      0.83      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.96      0.94      0.95       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.93      0.89      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.96      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 121.61849904060364 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.00303198229521513\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.6871960163116455 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5381, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4436, Accuracy: 0.8549, F1 Micro: 0.9131, F1 Macro: 0.9111\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3191, Accuracy: 0.9382, F1 Micro: 0.9616, F1 Macro: 0.9597\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2234, Accuracy: 0.9516, F1 Micro: 0.9699, F1 Macro: 0.9689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1609, Accuracy: 0.9598, F1 Micro: 0.975, F1 Macro: 0.9741\n",
      "Epoch 6/10, Train Loss: 0.1181, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0903, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.975\n",
      "Epoch 8/10, Train Loss: 0.0779, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0611, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0527, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9756\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9756\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.92      0.93      0.93       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5642, Accuracy: 0.891, F1 Micro: 0.891, F1 Macro: 0.8779\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2959, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9256\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1526, Accuracy: 0.9361, F1 Micro: 0.9361, F1 Macro: 0.9296\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1456, Accuracy: 0.9436, F1 Micro: 0.9436, F1 Macro: 0.9372\n",
      "Epoch 5/10, Train Loss: 0.0906, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9325\n",
      "Epoch 6/10, Train Loss: 0.0794, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9304\n",
      "Epoch 7/10, Train Loss: 0.0549, Accuracy: 0.9211, F1 Micro: 0.9211, F1 Macro: 0.913\n",
      "Epoch 8/10, Train Loss: 0.069, Accuracy: 0.9361, F1 Micro: 0.9361, F1 Macro: 0.9263\n",
      "Epoch 9/10, Train Loss: 0.0607, Accuracy: 0.8947, F1 Micro: 0.8947, F1 Macro: 0.8864\n",
      "Epoch 10/10, Train Loss: 0.0558, Accuracy: 0.9135, F1 Micro: 0.9135, F1 Macro: 0.9052\n",
      "\n",
      "Sentiment analysis accuracy: 0.9436, F1 Micro: 0.9436, F1 Macro: 0.9372\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.97      0.92        86\n",
      "    positive       0.98      0.93      0.96       180\n",
      "\n",
      "    accuracy                           0.94       266\n",
      "   macro avg       0.93      0.95      0.94       266\n",
      "weighted avg       0.95      0.94      0.94       266\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9185\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.85      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.92      0.81        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.78      0.73      0.75        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.81      0.86      0.83       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.94      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 129.06756067276 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.0024244199274107816\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.14699125289917 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5303, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4425, Accuracy: 0.8385, F1 Micro: 0.9054, F1 Macro: 0.9033\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3286, Accuracy: 0.9382, F1 Micro: 0.9619, F1 Macro: 0.9605\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2208, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1537, Accuracy: 0.9628, F1 Micro: 0.9768, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.116, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.097, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "Epoch 8/10, Train Loss: 0.0777, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9765\n",
      "Epoch 9/10, Train Loss: 0.0631, Accuracy: 0.9583, F1 Micro: 0.9737, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0558, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9781\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.97      0.97       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.98      1.00      0.99       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5005, Accuracy: 0.8943, F1 Micro: 0.8943, F1 Macro: 0.8802\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2069, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9341\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1323, Accuracy: 0.9585, F1 Micro: 0.9585, F1 Macro: 0.9536\n",
      "Epoch 4/10, Train Loss: 0.1358, Accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.9414\n",
      "Epoch 5/10, Train Loss: 0.0904, Accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.9414\n",
      "Epoch 6/10, Train Loss: 0.1019, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9337\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0761, Accuracy: 0.9585, F1 Micro: 0.9585, F1 Macro: 0.9539\n",
      "Epoch 8/10, Train Loss: 0.0584, Accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.9344\n",
      "Epoch 9/10, Train Loss: 0.051, Accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.9367\n",
      "Epoch 10/10, Train Loss: 0.0453, Accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.9414\n",
      "\n",
      "Sentiment analysis accuracy: 0.9585, F1 Micro: 0.9585, F1 Macro: 0.9539\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94        88\n",
      "    positive       0.98      0.95      0.97       177\n",
      "\n",
      "    accuracy                           0.96       265\n",
      "   macro avg       0.95      0.96      0.95       265\n",
      "weighted avg       0.96      0.96      0.96       265\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9314\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.97      0.96       167\n",
      "    positive       0.81      0.76      0.78        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.87      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.92      0.88        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.80      0.77      0.78        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.86      0.87      0.87       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.97      1.00      0.99       152\n",
      "    positive       1.00      0.83      0.91        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.94      0.94       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 131.24462389945984 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.0031228512059897186\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.183412313461304 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5228, Accuracy: 0.7902, F1 Micro: 0.8824, F1 Macro: 0.8808\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4374, Accuracy: 0.8527, F1 Micro: 0.9125, F1 Macro: 0.9106\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3108, Accuracy: 0.942, F1 Micro: 0.9642, F1 Macro: 0.9627\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.214, Accuracy: 0.9509, F1 Micro: 0.9692, F1 Macro: 0.9673\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1487, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1143, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9755\n",
      "Epoch 7/10, Train Loss: 0.0873, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0734, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9768\n",
      "Epoch 9/10, Train Loss: 0.0639, Accuracy: 0.9606, F1 Micro: 0.975, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0531, Accuracy: 0.971, F1 Micro: 0.9818, F1 Macro: 0.9809\n",
      "\n",
      "Aspect detection accuracy: 0.971, F1 Micro: 0.9818, F1 Macro: 0.9809\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.98       175\n",
      "      others       0.92      0.97      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5278, Accuracy: 0.8858, F1 Micro: 0.8858, F1 Macro: 0.8743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2564, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9203\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1276, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9362\n",
      "Epoch 4/10, Train Loss: 0.135, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9321\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1104, Accuracy: 0.9488, F1 Micro: 0.9488, F1 Macro: 0.9442\n",
      "Epoch 6/10, Train Loss: 0.0819, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9293\n",
      "Epoch 7/10, Train Loss: 0.0809, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9404\n",
      "Epoch 8/10, Train Loss: 0.0793, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9243\n",
      "Epoch 9/10, Train Loss: 0.0509, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9321\n",
      "Epoch 10/10, Train Loss: 0.0505, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9359\n",
      "\n",
      "Sentiment analysis accuracy: 0.9488, F1 Micro: 0.9488, F1 Macro: 0.9442\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.93        88\n",
      "    positive       0.98      0.95      0.96       166\n",
      "\n",
      "    accuracy                           0.95       254\n",
      "   macro avg       0.94      0.95      0.94       254\n",
      "weighted avg       0.95      0.95      0.95       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9622, F1 Micro: 0.9622, F1 Macro: 0.9268\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.97      0.98      0.98       167\n",
      "    positive       0.85      0.85      0.85        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.88      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.92      0.85        12\n",
      "     neutral       0.92      0.97      0.95       152\n",
      "    positive       0.88      0.69      0.77        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.86      0.86      0.86       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.85      0.92        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.95      0.95       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.96      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 131.68068289756775 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.0067005225922912364\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.056689023971558 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5189, Accuracy: 0.7909, F1 Micro: 0.8828, F1 Macro: 0.8811\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4309, Accuracy: 0.8743, F1 Micro: 0.9252, F1 Macro: 0.9241\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2874, Accuracy: 0.9494, F1 Micro: 0.9686, F1 Macro: 0.9677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1871, Accuracy: 0.9576, F1 Micro: 0.9736, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1368, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1069, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.978\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0827, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.978\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0654, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9784\n",
      "Epoch 9/10, Train Loss: 0.0545, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9775\n",
      "Epoch 10/10, Train Loss: 0.0498, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.978\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9784\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.95      0.92      0.93       158\n",
      "        part       0.97      1.00      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.506, Accuracy: 0.8973, F1 Micro: 0.8973, F1 Macro: 0.8904\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2559, Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.9452\n",
      "Epoch 3/10, Train Loss: 0.1581, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9365\n",
      "Epoch 4/10, Train Loss: 0.1415, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9309\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1114, Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.945\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0868, Accuracy: 0.9544, F1 Micro: 0.9544, F1 Macro: 0.9488\n",
      "Epoch 7/10, Train Loss: 0.0612, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9172\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0763, Accuracy: 0.9582, F1 Micro: 0.9582, F1 Macro: 0.9534\n",
      "Epoch 9/10, Train Loss: 0.0666, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9276\n",
      "Epoch 10/10, Train Loss: 0.0372, Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9406\n",
      "\n",
      "Sentiment analysis accuracy: 0.9582, F1 Micro: 0.9582, F1 Macro: 0.9534\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94        87\n",
      "    positive       0.98      0.95      0.97       176\n",
      "\n",
      "    accuracy                           0.96       263\n",
      "   macro avg       0.95      0.96      0.95       263\n",
      "weighted avg       0.96      0.96      0.96       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9305\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.87      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.92      0.85        12\n",
      "     neutral       0.95      0.92      0.94       152\n",
      "    positive       0.76      0.81      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.83      0.88      0.86       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.97      1.00      0.98       152\n",
      "    positive       1.00      0.80      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.96      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 138.2159457206726 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.003317292546853423\n",
      "Acquired samples: 8\n",
      "Sampling duration: 3.6136741638183594 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5237, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4284, Accuracy: 0.8869, F1 Micro: 0.9319, F1 Macro: 0.9301\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2826, Accuracy: 0.9494, F1 Micro: 0.9688, F1 Macro: 0.9678\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1803, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1361, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1038, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9751\n",
      "Epoch 7/10, Train Loss: 0.0814, Accuracy: 0.9628, F1 Micro: 0.9764, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0639, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0518, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9773\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0463, Accuracy: 0.9673, F1 Micro: 0.9792, F1 Macro: 0.9772\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9792, F1 Macro: 0.9772\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.98      0.98      0.98       175\n",
      "      others       0.94      0.89      0.92       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      1.00      1.00       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.97      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.97      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5066, Accuracy: 0.9071, F1 Micro: 0.9071, F1 Macro: 0.8942\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2329, Accuracy: 0.9143, F1 Micro: 0.9143, F1 Macro: 0.9054\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1753, Accuracy: 0.9429, F1 Micro: 0.9429, F1 Macro: 0.9356\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1373, Accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.9423\n",
      "Epoch 5/10, Train Loss: 0.1243, Accuracy: 0.9321, F1 Micro: 0.9321, F1 Macro: 0.9241\n",
      "Epoch 6/10, Train Loss: 0.1055, Accuracy: 0.9393, F1 Micro: 0.9393, F1 Macro: 0.9302\n",
      "Epoch 7/10, Train Loss: 0.0588, Accuracy: 0.9357, F1 Micro: 0.9357, F1 Macro: 0.9275\n",
      "Epoch 8/10, Train Loss: 0.0712, Accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.9384\n",
      "Epoch 9/10, Train Loss: 0.0645, Accuracy: 0.9393, F1 Micro: 0.9393, F1 Macro: 0.9306\n",
      "Epoch 10/10, Train Loss: 0.0437, Accuracy: 0.9429, F1 Micro: 0.9429, F1 Macro: 0.9356\n",
      "\n",
      "Sentiment analysis accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.9423\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.93      0.92        88\n",
      "    positive       0.97      0.96      0.96       192\n",
      "\n",
      "    accuracy                           0.95       280\n",
      "   macro avg       0.94      0.95      0.94       280\n",
      "weighted avg       0.95      0.95      0.95       280\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9295\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.96      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.98      0.98      0.98       167\n",
      "    positive       0.88      0.88      0.88        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.92      0.85        12\n",
      "     neutral       0.94      0.89      0.92       152\n",
      "    positive       0.72      0.81      0.76        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.82      0.87      0.84       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.95      0.88      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.95      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.99      1.00      1.00       186\n",
      "    positive       0.89      0.94      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.93      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 138.8963634967804 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.002847030479460955\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.44850492477417 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5197, Accuracy: 0.7939, F1 Micro: 0.8841, F1 Macro: 0.8824\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4282, Accuracy: 0.8862, F1 Micro: 0.932, F1 Macro: 0.9307\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2778, Accuracy: 0.9501, F1 Micro: 0.9692, F1 Macro: 0.9679\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1821, Accuracy: 0.9606, F1 Micro: 0.9754, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.131, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0944, Accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9777\n",
      "Epoch 7/10, Train Loss: 0.078, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9776\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0652, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9787\n",
      "Epoch 9/10, Train Loss: 0.0516, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0447, Accuracy: 0.971, F1 Micro: 0.9817, F1 Macro: 0.9804\n",
      "\n",
      "Aspect detection accuracy: 0.971, F1 Micro: 0.9817, F1 Macro: 0.9804\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.98       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.519, Accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.903\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2568, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.9291\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1445, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.9305\n",
      "Epoch 4/10, Train Loss: 0.1287, Accuracy: 0.903, F1 Micro: 0.903, F1 Macro: 0.8959\n",
      "Epoch 5/10, Train Loss: 0.1173, Accuracy: 0.9254, F1 Micro: 0.9254, F1 Macro: 0.9188\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1133, Accuracy: 0.9478, F1 Micro: 0.9478, F1 Macro: 0.9408\n",
      "Epoch 7/10, Train Loss: 0.0981, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.9283\n",
      "Epoch 8/10, Train Loss: 0.0577, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.9283\n",
      "Epoch 9/10, Train Loss: 0.0503, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9327\n",
      "Epoch 10/10, Train Loss: 0.0372, Accuracy: 0.9254, F1 Micro: 0.9254, F1 Macro: 0.9181\n",
      "\n",
      "Sentiment analysis accuracy: 0.9478, F1 Micro: 0.9478, F1 Macro: 0.9408\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        88\n",
      "    positive       0.96      0.96      0.96       180\n",
      "\n",
      "    accuracy                           0.95       268\n",
      "   macro avg       0.94      0.94      0.94       268\n",
      "weighted avg       0.95      0.95      0.95       268\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9622, F1 Micro: 0.9622, F1 Macro: 0.9262\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.96      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.89      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.97      0.98      0.98       167\n",
      "    positive       0.88      0.85      0.86        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.92      0.88        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.78      0.75      0.76        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.85      0.87      0.86       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        23\n",
      "     neutral       0.98      0.99      0.99       152\n",
      "    positive       1.00      0.90      0.95        41\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.97      0.96       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 138.97196197509766 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0042436508461833\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.766599655151367 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5196, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4225, Accuracy: 0.91, F1 Micro: 0.9446, F1 Macro: 0.9418\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2631, Accuracy: 0.9531, F1 Micro: 0.9709, F1 Macro: 0.9696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.174, Accuracy: 0.9643, F1 Micro: 0.9777, F1 Macro: 0.9768\n",
      "Epoch 5/10, Train Loss: 0.1285, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9755\n",
      "Epoch 6/10, Train Loss: 0.0965, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9755\n",
      "Epoch 7/10, Train Loss: 0.072, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0613, Accuracy: 0.971, F1 Micro: 0.9817, F1 Macro: 0.9803\n",
      "Epoch 9/10, Train Loss: 0.0517, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9761\n",
      "Epoch 10/10, Train Loss: 0.0458, Accuracy: 0.971, F1 Micro: 0.9816, F1 Macro: 0.9803\n",
      "\n",
      "Aspect detection accuracy: 0.971, F1 Micro: 0.9817, F1 Macro: 0.9803\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.98      0.98      0.98       175\n",
      "      others       0.93      0.94      0.94       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5178, Accuracy: 0.9179, F1 Micro: 0.9179, F1 Macro: 0.9064\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.242, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9345\n",
      "Epoch 3/10, Train Loss: 0.1698, Accuracy: 0.9254, F1 Micro: 0.9254, F1 Macro: 0.9144\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1334, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9327\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1219, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9338\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.095, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9319\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0727, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9378\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0587, Accuracy: 0.9515, F1 Micro: 0.9515, F1 Macro: 0.9461\n",
      "Epoch 9/10, Train Loss: 0.0593, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9374\n",
      "Epoch 10/10, Train Loss: 0.0434, Accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.906\n",
      "\n",
      "Sentiment analysis accuracy: 0.9515, F1 Micro: 0.9515, F1 Macro: 0.9461\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.97      0.93        88\n",
      "    positive       0.98      0.94      0.96       180\n",
      "\n",
      "    accuracy                           0.95       268\n",
      "   macro avg       0.94      0.96      0.95       268\n",
      "weighted avg       0.95      0.95      0.95       268\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9622, F1 Micro: 0.9622, F1 Macro: 0.9318\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.98      0.98      0.98       167\n",
      "    positive       0.88      0.88      0.88        33\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.92      0.85        12\n",
      "     neutral       0.93      0.94      0.94       152\n",
      "    positive       0.80      0.75      0.77        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.84      0.87      0.85       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 141.50130558013916 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0019046194152906536\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.214083671569824 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5261, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4344, Accuracy: 0.8929, F1 Micro: 0.935, F1 Macro: 0.9328\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2771, Accuracy: 0.9487, F1 Micro: 0.9681, F1 Macro: 0.9668\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1733, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1388, Accuracy: 0.9628, F1 Micro: 0.9764, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0991, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.979\n",
      "Epoch 7/10, Train Loss: 0.0769, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0657, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9791\n",
      "Epoch 9/10, Train Loss: 0.0506, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9757\n",
      "Epoch 10/10, Train Loss: 0.0463, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.979\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9791\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.95      0.93      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4878, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9119\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2508, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.922\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.158, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.9295\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1169, Accuracy: 0.9478, F1 Micro: 0.9478, F1 Macro: 0.9411\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1055, Accuracy: 0.9478, F1 Micro: 0.9478, F1 Macro: 0.9404\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0751, Accuracy: 0.9478, F1 Micro: 0.9478, F1 Macro: 0.9411\n",
      "Epoch 7/10, Train Loss: 0.0988, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9138\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0737, Accuracy: 0.9478, F1 Micro: 0.9478, F1 Macro: 0.9408\n",
      "Epoch 9/10, Train Loss: 0.0437, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9371\n",
      "Epoch 10/10, Train Loss: 0.051, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9364\n",
      "\n",
      "Sentiment analysis accuracy: 0.9478, F1 Micro: 0.9478, F1 Macro: 0.9408\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        86\n",
      "    positive       0.97      0.95      0.96       182\n",
      "\n",
      "    accuracy                           0.95       268\n",
      "   macro avg       0.94      0.95      0.94       268\n",
      "weighted avg       0.95      0.95      0.95       268\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9265\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.84      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.92      0.88        12\n",
      "     neutral       0.96      0.93      0.95       152\n",
      "    positive       0.80      0.85      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.87      0.90      0.88       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 146.47193884849548 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0016653588623739778\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.6725883483886719 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5135, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3976, Accuracy: 0.9196, F1 Micro: 0.951, F1 Macro: 0.9492\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2429, Accuracy: 0.9568, F1 Micro: 0.9732, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1596, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9735\n",
      "Epoch 5/10, Train Loss: 0.1204, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0925, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.978\n",
      "Epoch 7/10, Train Loss: 0.0698, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9777\n",
      "Epoch 8/10, Train Loss: 0.0604, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0514, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9791\n",
      "Epoch 10/10, Train Loss: 0.042, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9786\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9791\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.94      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4336, Accuracy: 0.9251, F1 Micro: 0.9251, F1 Macro: 0.9179\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2219, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9258\n",
      "Epoch 3/10, Train Loss: 0.1495, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9066\n",
      "Epoch 4/10, Train Loss: 0.1326, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9102\n",
      "Epoch 5/10, Train Loss: 0.1104, Accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.9101\n",
      "Epoch 6/10, Train Loss: 0.101, Accuracy: 0.9288, F1 Micro: 0.9288, F1 Macro: 0.9202\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0778, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9233\n",
      "Epoch 8/10, Train Loss: 0.0704, Accuracy: 0.9288, F1 Micro: 0.9288, F1 Macro: 0.9218\n",
      "Epoch 9/10, Train Loss: 0.0664, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9127\n",
      "Epoch 10/10, Train Loss: 0.0485, Accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.9097\n",
      "\n",
      "Sentiment analysis accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9233\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.90      0.90        87\n",
      "    positive       0.95      0.95      0.95       180\n",
      "\n",
      "    accuracy                           0.93       267\n",
      "   macro avg       0.92      0.92      0.92       267\n",
      "weighted avg       0.93      0.93      0.93       267\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.9125\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.96      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.89      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.86      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.93      0.94      0.94       152\n",
      "    positive       0.80      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.86      0.85      0.86       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.95      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 140.70331716537476 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0023709454108029604\n",
      "Acquired samples: 8\n",
      "Sampling duration: 1.0276901721954346 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5229, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4041, Accuracy: 0.9129, F1 Micro: 0.9468, F1 Macro: 0.9446\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2432, Accuracy: 0.9568, F1 Micro: 0.9732, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1663, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1198, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9787\n",
      "Epoch 6/10, Train Loss: 0.091, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9773\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0679, Accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9802\n",
      "Epoch 8/10, Train Loss: 0.0624, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9774\n",
      "Epoch 9/10, Train Loss: 0.0475, Accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9801\n",
      "Epoch 10/10, Train Loss: 0.0415, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.979\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9802\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.93      0.96      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4542, Accuracy: 0.9189, F1 Micro: 0.9189, F1 Macro: 0.9117\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2189, Accuracy: 0.9575, F1 Micro: 0.9575, F1 Macro: 0.952\n",
      "Epoch 3/10, Train Loss: 0.1673, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9356\n",
      "Epoch 4/10, Train Loss: 0.1243, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9315\n",
      "Epoch 5/10, Train Loss: 0.1172, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9239\n",
      "Epoch 6/10, Train Loss: 0.0815, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9197\n",
      "Epoch 7/10, Train Loss: 0.084, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9356\n",
      "Epoch 8/10, Train Loss: 0.0679, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9266\n",
      "Epoch 9/10, Train Loss: 0.0629, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9149\n",
      "Epoch 10/10, Train Loss: 0.0634, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9262\n",
      "\n",
      "Sentiment analysis accuracy: 0.9575, F1 Micro: 0.9575, F1 Macro: 0.952\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        85\n",
      "    positive       0.97      0.97      0.97       174\n",
      "\n",
      "    accuracy                           0.96       259\n",
      "   macro avg       0.95      0.95      0.95       259\n",
      "weighted avg       0.96      0.96      0.96       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9637, F1 Micro: 0.9637, F1 Macro: 0.9314\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.86      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.94      0.95      0.94       152\n",
      "    positive       0.85      0.79      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.85      0.86      0.85       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.96      0.94        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.95      0.90      0.92        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.95      0.95       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 139.89929747581482 s\n",
      "Total runtime: 3117.2292263507843 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[3], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7fe541",
   "metadata": {
    "papermill": {
     "duration": 0.284232,
     "end_time": "2025-03-26T11:23:01.041949",
     "exception": false,
     "start_time": "2025-03-26T11:23:00.757717",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dadb00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 5\n",
      "Random seed: 94\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6298, Accuracy: 0.7522, F1 Micro: 0.854, F1 Macro: 0.8362\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5654, Accuracy: 0.7887, F1 Micro: 0.8819, F1 Macro: 0.8803\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5262, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4783, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4582, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4326, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4132, Accuracy: 0.7924, F1 Micro: 0.8837, F1 Macro: 0.8822\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4395, Accuracy: 0.7939, F1 Micro: 0.8842, F1 Macro: 0.8826\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.4306, Accuracy: 0.7999, F1 Micro: 0.887, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3956, Accuracy: 0.8036, F1 Micro: 0.8888, F1 Macro: 0.8871\n",
      "\n",
      "Aspect detection accuracy: 0.8036, F1 Micro: 0.8888, F1 Macro: 0.8871\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.78      1.00      0.88       175\n",
      "      others       0.75      0.99      0.85       158\n",
      "        part       0.74      0.97      0.84       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.80      0.99      0.89      1061\n",
      "   macro avg       0.80      0.99      0.89      1061\n",
      "weighted avg       0.81      0.99      0.89      1061\n",
      " samples avg       0.81      0.99      0.89      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7142, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5719, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.6151, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5677, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.5123, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.5138, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4932, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3579, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3098, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2431, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "\n",
      "Sentiment analysis accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         6\n",
      "    positive       0.81      1.00      0.89        25\n",
      "\n",
      "    accuracy                           0.81        31\n",
      "   macro avg       0.40      0.50      0.45        31\n",
      "weighted avg       0.65      0.81      0.72        31\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.7994, F1 Micro: 0.7994, F1 Macro: 0.3298\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.77      1.00      0.87       167\n",
      "    positive       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.77       216\n",
      "   macro avg       0.26      0.33      0.29       216\n",
      "weighted avg       0.60      0.77      0.67       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.75      0.99      0.85       152\n",
      "    positive       0.67      0.19      0.30        52\n",
      "\n",
      "    accuracy                           0.74       216\n",
      "   macro avg       0.47      0.39      0.38       216\n",
      "weighted avg       0.69      0.74      0.67       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        23\n",
      "     neutral       0.74      0.97      0.84       152\n",
      "    positive       0.56      0.22      0.32        41\n",
      "\n",
      "    accuracy                           0.73       216\n",
      "   macro avg       0.43      0.40      0.39       216\n",
      "weighted avg       0.63      0.73      0.65       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 64.97156977653503 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.004518020898103714\n",
      "Acquired samples: 82\n",
      "Sampling duration: 13.825844764709473 seconds\n",
      "New train size: 136\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6205, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5585, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5256, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4961, Accuracy: 0.8028, F1 Micro: 0.8881, F1 Macro: 0.8863\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.483, Accuracy: 0.8058, F1 Micro: 0.8897, F1 Macro: 0.888\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4131, Accuracy: 0.814, F1 Micro: 0.8935, F1 Macro: 0.8916\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3886, Accuracy: 0.8266, F1 Micro: 0.8994, F1 Macro: 0.8975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3387, Accuracy: 0.8438, F1 Micro: 0.9077, F1 Macro: 0.9055\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2886, Accuracy: 0.8579, F1 Micro: 0.9159, F1 Macro: 0.9144\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2587, Accuracy: 0.872, F1 Micro: 0.9227, F1 Macro: 0.9205\n",
      "\n",
      "Aspect detection accuracy: 0.872, F1 Micro: 0.9227, F1 Macro: 0.9205\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.92      0.99      0.95       187\n",
      "     machine       0.82      0.99      0.89       175\n",
      "      others       0.88      0.84      0.86       158\n",
      "        part       0.87      0.97      0.92       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.96      0.99      0.97       191\n",
      "\n",
      "   micro avg       0.88      0.97      0.92      1061\n",
      "   macro avg       0.88      0.96      0.92      1061\n",
      "weighted avg       0.88      0.97      0.92      1061\n",
      " samples avg       0.89      0.97      0.92      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.551, Accuracy: 0.7701, F1 Micro: 0.7701, F1 Macro: 0.4351\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4534, Accuracy: 0.7701, F1 Micro: 0.7701, F1 Macro: 0.4351\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4111, Accuracy: 0.7701, F1 Micro: 0.7701, F1 Macro: 0.4351\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3035, Accuracy: 0.7816, F1 Micro: 0.7816, F1 Macro: 0.4855\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2234, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8655\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1284, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0868, Accuracy: 0.931, F1 Micro: 0.931, F1 Macro: 0.9058\n",
      "Epoch 8/10, Train Loss: 0.0842, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.8818\n",
      "Epoch 9/10, Train Loss: 0.0854, Accuracy: 0.9195, F1 Micro: 0.9195, F1 Macro: 0.8902\n",
      "Epoch 10/10, Train Loss: 0.0161, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.8818\n",
      "\n",
      "Sentiment analysis accuracy: 0.931, F1 Micro: 0.931, F1 Macro: 0.9058\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.90      0.86        40\n",
      "    positive       0.97      0.94      0.95       134\n",
      "\n",
      "    accuracy                           0.93       174\n",
      "   macro avg       0.89      0.92      0.91       174\n",
      "weighted avg       0.93      0.93      0.93       174\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 136: Accuracy: 0.8657, F1 Micro: 0.8657, F1 Macro: 0.643\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.36      0.53        11\n",
      "     neutral       0.92      0.99      0.95       181\n",
      "    positive       0.88      0.62      0.73        24\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.93      0.66      0.74       216\n",
      "weighted avg       0.92      0.92      0.91       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.12      0.22        16\n",
      "     neutral       0.81      0.99      0.89       167\n",
      "    positive       0.80      0.24      0.37        33\n",
      "\n",
      "    accuracy                           0.81       216\n",
      "   macro avg       0.87      0.45      0.49       216\n",
      "weighted avg       0.82      0.81      0.76       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.67      0.64        12\n",
      "     neutral       0.88      0.84      0.86       152\n",
      "    positive       0.63      0.71      0.67        52\n",
      "\n",
      "    accuracy                           0.80       216\n",
      "   macro avg       0.71      0.74      0.72       216\n",
      "weighted avg       0.81      0.80      0.80       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.43      0.59        23\n",
      "     neutral       0.87      0.98      0.92       152\n",
      "    positive       0.82      0.66      0.73        41\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.86      0.69      0.75       216\n",
      "weighted avg       0.86      0.86      0.85       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.86      0.86        14\n",
      "     neutral       0.96      0.99      0.97       185\n",
      "    positive       0.91      0.59      0.71        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.81      0.85       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Total train time: 74.44868469238281 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.008940141089260579\n",
      "Acquired samples: 73\n",
      "Sampling duration: 13.23454236984253 seconds\n",
      "New train size: 209\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.595, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5147, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4887, Accuracy: 0.8006, F1 Micro: 0.8879, F1 Macro: 0.8864\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4587, Accuracy: 0.8058, F1 Micro: 0.89, F1 Macro: 0.8884\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4261, Accuracy: 0.8207, F1 Micro: 0.8968, F1 Macro: 0.8951\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3735, Accuracy: 0.8438, F1 Micro: 0.9082, F1 Macro: 0.9067\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2986, Accuracy: 0.8862, F1 Micro: 0.9316, F1 Macro: 0.93\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2613, Accuracy: 0.907, F1 Micro: 0.9428, F1 Macro: 0.9401\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1996, Accuracy: 0.9174, F1 Micro: 0.9488, F1 Macro: 0.9449\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1656, Accuracy: 0.9308, F1 Micro: 0.9572, F1 Macro: 0.9551\n",
      "\n",
      "Aspect detection accuracy: 0.9308, F1 Micro: 0.9572, F1 Macro: 0.9551\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.97      1.00      0.99       187\n",
      "     machine       0.93      0.97      0.95       175\n",
      "      others       0.89      0.92      0.91       158\n",
      "        part       0.89      0.98      0.93       158\n",
      "       price       0.95      1.00      0.97       192\n",
      "     service       0.97      0.99      0.98       191\n",
      "\n",
      "   micro avg       0.94      0.98      0.96      1061\n",
      "   macro avg       0.93      0.98      0.96      1061\n",
      "weighted avg       0.94      0.98      0.96      1061\n",
      " samples avg       0.94      0.98      0.95      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6172, Accuracy: 0.7022, F1 Micro: 0.7022, F1 Macro: 0.4125\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4545, Accuracy: 0.8267, F1 Micro: 0.8267, F1 Macro: 0.8043\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3328, Accuracy: 0.8889, F1 Micro: 0.8889, F1 Macro: 0.877\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.203, Accuracy: 0.9156, F1 Micro: 0.9156, F1 Macro: 0.9026\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1267, Accuracy: 0.9244, F1 Micro: 0.9244, F1 Macro: 0.9108\n",
      "Epoch 6/10, Train Loss: 0.1258, Accuracy: 0.92, F1 Micro: 0.92, F1 Macro: 0.9088\n",
      "Epoch 7/10, Train Loss: 0.1122, Accuracy: 0.9156, F1 Micro: 0.9156, F1 Macro: 0.9003\n",
      "Epoch 8/10, Train Loss: 0.1046, Accuracy: 0.92, F1 Micro: 0.92, F1 Macro: 0.9067\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1107, Accuracy: 0.9244, F1 Micro: 0.9244, F1 Macro: 0.9122\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1046, Accuracy: 0.9244, F1 Micro: 0.9244, F1 Macro: 0.9108\n",
      "\n",
      "Sentiment analysis accuracy: 0.9244, F1 Micro: 0.9244, F1 Macro: 0.9108\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.90      0.88        67\n",
      "    positive       0.95      0.94      0.95       158\n",
      "\n",
      "    accuracy                           0.92       225\n",
      "   macro avg       0.91      0.92      0.91       225\n",
      "weighted avg       0.93      0.92      0.92       225\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 209: Accuracy: 0.9198, F1 Micro: 0.9198, F1 Macro: 0.8269\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       1.00      0.88      0.93        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.99      0.93      0.96       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.93      0.96      0.94       167\n",
      "    positive       0.78      0.64      0.70        33\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.86      0.80      0.83       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.56      0.42      0.48        12\n",
      "     neutral       0.89      0.92      0.91       152\n",
      "    positive       0.74      0.71      0.73        52\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.73      0.68      0.70       216\n",
      "weighted avg       0.84      0.84      0.84       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.65      0.75        23\n",
      "     neutral       0.89      0.99      0.93       152\n",
      "    positive       0.90      0.66      0.76        41\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.89      0.77      0.82       216\n",
      "weighted avg       0.89      0.89      0.88       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.46      0.60        13\n",
      "     neutral       0.95      1.00      0.97       186\n",
      "    positive       0.85      0.65      0.73        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.70      0.77       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.79      0.85        14\n",
      "     neutral       0.97      0.99      0.98       185\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.85      0.89       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Total train time: 87.3658800125122 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.006170511245727539\n",
      "Acquired samples: 66\n",
      "Sampling duration: 14.050046682357788 seconds\n",
      "New train size: 275\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5744, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 2/10, Train Loss: 0.5009, Accuracy: 0.7894, F1 Micro: 0.8804, F1 Macro: 0.8777\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4685, Accuracy: 0.8028, F1 Micro: 0.8878, F1 Macro: 0.8856\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4321, Accuracy: 0.814, F1 Micro: 0.8921, F1 Macro: 0.8893\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3679, Accuracy: 0.8542, F1 Micro: 0.9132, F1 Macro: 0.9108\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2984, Accuracy: 0.8981, F1 Micro: 0.9365, F1 Macro: 0.9314\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2436, Accuracy: 0.9174, F1 Micro: 0.9488, F1 Macro: 0.9454\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1861, Accuracy: 0.9315, F1 Micro: 0.9575, F1 Macro: 0.9548\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1476, Accuracy: 0.9323, F1 Micro: 0.9575, F1 Macro: 0.9536\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1285, Accuracy: 0.9338, F1 Micro: 0.9582, F1 Macro: 0.9541\n",
      "\n",
      "Aspect detection accuracy: 0.9338, F1 Micro: 0.9582, F1 Macro: 0.9541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.97      0.96       175\n",
      "      others       0.91      0.80      0.86       158\n",
      "        part       0.92      0.98      0.95       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       0.97      0.99      0.98       191\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      1061\n",
      "   macro avg       0.95      0.96      0.95      1061\n",
      "weighted avg       0.95      0.96      0.96      1061\n",
      " samples avg       0.96      0.96      0.95      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6142, Accuracy: 0.7068, F1 Micro: 0.7068, F1 Macro: 0.4141\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4114, Accuracy: 0.8797, F1 Micro: 0.8797, F1 Macro: 0.8549\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.226, Accuracy: 0.906, F1 Micro: 0.906, F1 Macro: 0.8879\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.16, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.8969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1025, Accuracy: 0.9211, F1 Micro: 0.9211, F1 Macro: 0.9013\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1443, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9165\n",
      "Epoch 7/10, Train Loss: 0.103, Accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.903\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0799, Accuracy: 0.9361, F1 Micro: 0.9361, F1 Macro: 0.9232\n",
      "Epoch 9/10, Train Loss: 0.1134, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9154\n",
      "Epoch 10/10, Train Loss: 0.0627, Accuracy: 0.9248, F1 Micro: 0.9248, F1 Macro: 0.9064\n",
      "\n",
      "Sentiment analysis accuracy: 0.9361, F1 Micro: 0.9361, F1 Macro: 0.9232\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.90      0.89        78\n",
      "    positive       0.96      0.95      0.95       188\n",
      "\n",
      "    accuracy                           0.94       266\n",
      "   macro avg       0.92      0.92      0.92       266\n",
      "weighted avg       0.94      0.94      0.94       266\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 275: Accuracy: 0.9259, F1 Micro: 0.9259, F1 Macro: 0.866\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.98      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.96      0.96       167\n",
      "    positive       0.81      0.79      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.85      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.75      0.69        12\n",
      "     neutral       0.92      0.81      0.86       152\n",
      "    positive       0.62      0.81      0.70        52\n",
      "\n",
      "    accuracy                           0.81       216\n",
      "   macro avg       0.73      0.79      0.75       216\n",
      "weighted avg       0.83      0.81      0.81       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.83      0.86        23\n",
      "     neutral       0.92      0.98      0.95       152\n",
      "    positive       0.88      0.71      0.78        41\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.90      0.84      0.87       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.62      0.76        13\n",
      "     neutral       0.97      1.00      0.99       186\n",
      "    positive       0.76      0.76      0.76        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.91      0.79      0.84       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89        14\n",
      "     neutral       0.97      0.99      0.98       185\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.97      0.89      0.93       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 92.25546431541443 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.008447544369846582\n",
      "Acquired samples: 59\n",
      "Sampling duration: 12.912368774414062 seconds\n",
      "New train size: 334\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5899, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5165, Accuracy: 0.7946, F1 Micro: 0.8834, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4603, Accuracy: 0.8095, F1 Micro: 0.89, F1 Macro: 0.8872\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.41, Accuracy: 0.8586, F1 Micro: 0.917, F1 Macro: 0.9161\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.318, Accuracy: 0.9115, F1 Micro: 0.9447, F1 Macro: 0.9407\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2452, Accuracy: 0.9219, F1 Micro: 0.9507, F1 Macro: 0.9464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1849, Accuracy: 0.9353, F1 Micro: 0.9591, F1 Macro: 0.9551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1447, Accuracy: 0.9435, F1 Micro: 0.9645, F1 Macro: 0.9617\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1172, Accuracy: 0.9472, F1 Micro: 0.9667, F1 Macro: 0.964\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.097, Accuracy: 0.9509, F1 Micro: 0.9691, F1 Macro: 0.9666\n",
      "\n",
      "Aspect detection accuracy: 0.9509, F1 Micro: 0.9691, F1 Macro: 0.9666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.91      0.89      0.90       158\n",
      "        part       0.93      0.98      0.96       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.97      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6263, Accuracy: 0.6873, F1 Micro: 0.6873, F1 Macro: 0.4073\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4418, Accuracy: 0.8726, F1 Micro: 0.8726, F1 Macro: 0.8568\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2793, Accuracy: 0.9189, F1 Micro: 0.9189, F1 Macro: 0.9094\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1958, Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9422\n",
      "Epoch 5/10, Train Loss: 0.1369, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9225\n",
      "Epoch 6/10, Train Loss: 0.1126, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9217\n",
      "Epoch 7/10, Train Loss: 0.1089, Accuracy: 0.9189, F1 Micro: 0.9189, F1 Macro: 0.9072\n",
      "Epoch 8/10, Train Loss: 0.1162, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9221\n",
      "Epoch 9/10, Train Loss: 0.109, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.918\n",
      "Epoch 10/10, Train Loss: 0.0617, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9221\n",
      "\n",
      "Sentiment analysis accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9422\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        81\n",
      "    positive       0.97      0.96      0.96       178\n",
      "\n",
      "    accuracy                           0.95       259\n",
      "   macro avg       0.94      0.95      0.94       259\n",
      "weighted avg       0.95      0.95      0.95       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 334: Accuracy: 0.9429, F1 Micro: 0.9429, F1 Macro: 0.9012\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.91      0.88      0.90       152\n",
      "    positive       0.70      0.77      0.73        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.79      0.80      0.79       216\n",
      "weighted avg       0.85      0.85      0.85       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        23\n",
      "     neutral       0.93      0.98      0.96       152\n",
      "    positive       0.91      0.73      0.81        41\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.89      0.85      0.86       216\n",
      "weighted avg       0.92      0.92      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.89      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 93.1765341758728 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.006231543608009815\n",
      "Acquired samples: 54\n",
      "Sampling duration: 11.85944390296936 seconds\n",
      "New train size: 388\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5583, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5122, Accuracy: 0.7999, F1 Micro: 0.8863, F1 Macro: 0.8843\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4483, Accuracy: 0.8229, F1 Micro: 0.8963, F1 Macro: 0.8931\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3585, Accuracy: 0.8884, F1 Micro: 0.9325, F1 Macro: 0.9302\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2664, Accuracy: 0.9256, F1 Micro: 0.9539, F1 Macro: 0.9504\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2052, Accuracy: 0.9531, F1 Micro: 0.9709, F1 Macro: 0.9696\n",
      "Epoch 7/10, Train Loss: 0.1569, Accuracy: 0.9524, F1 Micro: 0.9701, F1 Macro: 0.9681\n",
      "Epoch 8/10, Train Loss: 0.1272, Accuracy: 0.9501, F1 Micro: 0.9686, F1 Macro: 0.9662\n",
      "Epoch 9/10, Train Loss: 0.0992, Accuracy: 0.9531, F1 Micro: 0.9705, F1 Macro: 0.9685\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0806, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9711\n",
      "\n",
      "Aspect detection accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9711\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.90      0.92      0.91       158\n",
      "        part       0.97      0.98      0.97       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      0.99      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5854, Accuracy: 0.6834, F1 Micro: 0.6834, F1 Macro: 0.406\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4026, Accuracy: 0.8996, F1 Micro: 0.8996, F1 Macro: 0.8904\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.191, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9185\n",
      "Epoch 4/10, Train Loss: 0.1608, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.8993\n",
      "Epoch 5/10, Train Loss: 0.1391, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.9025\n",
      "Epoch 6/10, Train Loss: 0.1166, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.9053\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0745, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9262\n",
      "Epoch 8/10, Train Loss: 0.0848, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9139\n",
      "Epoch 9/10, Train Loss: 0.0761, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9185\n",
      "Epoch 10/10, Train Loss: 0.0642, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9185\n",
      "\n",
      "Sentiment analysis accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9262\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.95      0.90        82\n",
      "    positive       0.98      0.93      0.95       177\n",
      "\n",
      "    accuracy                           0.93       259\n",
      "   macro avg       0.92      0.94      0.93       259\n",
      "weighted avg       0.94      0.93      0.94       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 388: Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.8999\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.81      0.79        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.85      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.90      0.91      0.91       152\n",
      "    positive       0.74      0.71      0.73        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.80      0.79      0.79       216\n",
      "weighted avg       0.85      0.86      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.91      0.87        23\n",
      "     neutral       0.97      0.98      0.97       152\n",
      "    positive       0.92      0.83      0.87        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.87      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       0.99      0.99      0.99       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 94.69864416122437 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.003477677144110203\n",
      "Acquired samples: 48\n",
      "Sampling duration: 10.887608051300049 seconds\n",
      "New train size: 436\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5568, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5212, Accuracy: 0.8043, F1 Micro: 0.8885, F1 Macro: 0.8865\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4344, Accuracy: 0.8668, F1 Micro: 0.9215, F1 Macro: 0.9206\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3155, Accuracy: 0.9263, F1 Micro: 0.9546, F1 Macro: 0.9529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2295, Accuracy: 0.9405, F1 Micro: 0.9625, F1 Macro: 0.9593\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1677, Accuracy: 0.9509, F1 Micro: 0.9692, F1 Macro: 0.9671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1368, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9711\n",
      "Epoch 8/10, Train Loss: 0.1081, Accuracy: 0.9554, F1 Micro: 0.972, F1 Macro: 0.9701\n",
      "Epoch 9/10, Train Loss: 0.089, Accuracy: 0.9509, F1 Micro: 0.9689, F1 Macro: 0.9655\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0801, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9742\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9742\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.93      0.93      0.93       158\n",
      "        part       0.97      0.98      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5756, Accuracy: 0.6962, F1 Micro: 0.6962, F1 Macro: 0.4828\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3281, Accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.9115\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2042, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9155\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1275, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9235\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1404, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9245\n",
      "Epoch 6/10, Train Loss: 0.127, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9109\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1193, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9305\n",
      "Epoch 8/10, Train Loss: 0.0946, Accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.9115\n",
      "Epoch 9/10, Train Loss: 0.0751, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9209\n",
      "Epoch 10/10, Train Loss: 0.0493, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9223\n",
      "\n",
      "Sentiment analysis accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9305\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.93      0.91        84\n",
      "    positive       0.97      0.94      0.95       176\n",
      "\n",
      "    accuracy                           0.94       260\n",
      "   macro avg       0.93      0.94      0.93       260\n",
      "weighted avg       0.94      0.94      0.94       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 436: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9112\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.85      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.81      0.83      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.88      0.86      0.87       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.87      0.85        23\n",
      "     neutral       0.97      0.98      0.97       152\n",
      "    positive       0.87      0.80      0.84        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.88      0.89       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 110.62154197692871 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.004586305283010006\n",
      "Acquired samples: 43\n",
      "Sampling duration: 9.981134176254272 seconds\n",
      "New train size: 479\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5464, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4781, Accuracy: 0.808, F1 Micro: 0.8912, F1 Macro: 0.8896\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4095, Accuracy: 0.881, F1 Micro: 0.9288, F1 Macro: 0.9281\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3016, Accuracy: 0.9263, F1 Micro: 0.9542, F1 Macro: 0.952\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2229, Accuracy: 0.9435, F1 Micro: 0.9647, F1 Macro: 0.9621\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1692, Accuracy: 0.9524, F1 Micro: 0.9702, F1 Macro: 0.9683\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1203, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1037, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9736\n",
      "Epoch 9/10, Train Loss: 0.0938, Accuracy: 0.9472, F1 Micro: 0.9665, F1 Macro: 0.9627\n",
      "Epoch 10/10, Train Loss: 0.0776, Accuracy: 0.9576, F1 Micro: 0.9732, F1 Macro: 0.9711\n",
      "\n",
      "Aspect detection accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9736\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.94      0.98      0.96       175\n",
      "      others       0.92      0.92      0.92       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5622, Accuracy: 0.6769, F1 Micro: 0.6769, F1 Macro: 0.4037\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3184, Accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.8991\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.158, Accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.9119\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1508, Accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.9119\n",
      "Epoch 5/10, Train Loss: 0.1534, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.8992\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1427, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9218\n",
      "Epoch 7/10, Train Loss: 0.115, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9191\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0917, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9272\n",
      "Epoch 9/10, Train Loss: 0.0895, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.9084\n",
      "Epoch 10/10, Train Loss: 0.0735, Accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.908\n",
      "\n",
      "Sentiment analysis accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9272\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.95      0.90        84\n",
      "    positive       0.98      0.93      0.95       176\n",
      "\n",
      "    accuracy                           0.93       260\n",
      "   macro avg       0.92      0.94      0.93       260\n",
      "weighted avg       0.94      0.93      0.94       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 479: Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.9077\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.85      0.70      0.77        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.88      0.81      0.84       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.75      0.69        12\n",
      "     neutral       0.92      0.92      0.92       152\n",
      "    positive       0.80      0.77      0.78        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.79      0.81      0.80       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.92      0.83      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.92      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.89      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 108.91342329978943 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.004337621154263616\n",
      "Acquired samples: 39\n",
      "Sampling duration: 8.940228462219238 seconds\n",
      "New train size: 518\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5408, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4878, Accuracy: 0.8251, F1 Micro: 0.8997, F1 Macro: 0.8984\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3716, Accuracy: 0.9077, F1 Micro: 0.944, F1 Macro: 0.9433\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2628, Accuracy: 0.9397, F1 Micro: 0.9623, F1 Macro: 0.9593\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1843, Accuracy: 0.9494, F1 Micro: 0.9684, F1 Macro: 0.9663\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1384, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9713\n",
      "Epoch 7/10, Train Loss: 0.1162, Accuracy: 0.9546, F1 Micro: 0.9713, F1 Macro: 0.9692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0888, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0757, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0685, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9754\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9754\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.97      0.96       175\n",
      "      others       0.90      0.96      0.93       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5355, Accuracy: 0.8599, F1 Micro: 0.8599, F1 Macro: 0.8292\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2718, Accuracy: 0.9066, F1 Micro: 0.9066, F1 Macro: 0.8974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1921, Accuracy: 0.9105, F1 Micro: 0.9105, F1 Macro: 0.9019\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1508, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9177\n",
      "Epoch 5/10, Train Loss: 0.1047, Accuracy: 0.9066, F1 Micro: 0.9066, F1 Macro: 0.8979\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1143, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9264\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.099, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9297\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0901, Accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9385\n",
      "Epoch 9/10, Train Loss: 0.062, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9241\n",
      "Epoch 10/10, Train Loss: 0.0851, Accuracy: 0.9222, F1 Micro: 0.9222, F1 Macro: 0.9131\n",
      "\n",
      "Sentiment analysis accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9385\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.95      0.92        82\n",
      "    positive       0.98      0.94      0.96       175\n",
      "\n",
      "    accuracy                           0.95       257\n",
      "   macro avg       0.93      0.95      0.94       257\n",
      "weighted avg       0.95      0.95      0.95       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 518: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9128\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.97      0.96       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.86      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.67      0.76        12\n",
      "     neutral       0.90      0.96      0.93       152\n",
      "    positive       0.87      0.75      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.89      0.79      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.91      0.87        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.89      0.83      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.91      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.85      0.81        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 117.67476177215576 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.005141957476735116\n",
      "Acquired samples: 22\n",
      "Sampling duration: 8.269057989120483 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5503, Accuracy: 0.7961, F1 Micro: 0.8849, F1 Macro: 0.883\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4798, Accuracy: 0.8125, F1 Micro: 0.8933, F1 Macro: 0.8918\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3821, Accuracy: 0.9107, F1 Micro: 0.9457, F1 Macro: 0.9448\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2674, Accuracy: 0.9412, F1 Micro: 0.9632, F1 Macro: 0.9603\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1886, Accuracy: 0.9554, F1 Micro: 0.9722, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1485, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9713\n",
      "Epoch 7/10, Train Loss: 0.1193, Accuracy: 0.9531, F1 Micro: 0.9704, F1 Macro: 0.9679\n",
      "Epoch 8/10, Train Loss: 0.0846, Accuracy: 0.9561, F1 Micro: 0.9722, F1 Macro: 0.9696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0731, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9751\n",
      "Epoch 10/10, Train Loss: 0.0653, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9737\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9751\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.94      0.93       158\n",
      "        part       0.98      0.97      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5882, Accuracy: 0.8008, F1 Micro: 0.8008, F1 Macro: 0.725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2773, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.8998\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1734, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9152\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1552, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9261\n",
      "Epoch 5/10, Train Loss: 0.1373, Accuracy: 0.9195, F1 Micro: 0.9195, F1 Macro: 0.9121\n",
      "Epoch 6/10, Train Loss: 0.1119, Accuracy: 0.9272, F1 Micro: 0.9272, F1 Macro: 0.9174\n",
      "Epoch 7/10, Train Loss: 0.1015, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9105\n",
      "Epoch 8/10, Train Loss: 0.1039, Accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.9035\n",
      "Epoch 9/10, Train Loss: 0.0625, Accuracy: 0.931, F1 Micro: 0.931, F1 Macro: 0.922\n",
      "Epoch 10/10, Train Loss: 0.053, Accuracy: 0.9195, F1 Micro: 0.9195, F1 Macro: 0.9112\n",
      "\n",
      "Sentiment analysis accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9261\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.92      0.90        84\n",
      "    positive       0.96      0.94      0.95       177\n",
      "\n",
      "    accuracy                           0.93       261\n",
      "   macro avg       0.92      0.93      0.93       261\n",
      "weighted avg       0.94      0.93      0.94       261\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.9065\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.91      0.82      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.92      0.93      0.93       152\n",
      "    positive       0.78      0.75      0.76        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.82      0.81      0.81       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.91      0.87        23\n",
      "     neutral       0.98      0.97      0.97       152\n",
      "    positive       0.85      0.85      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.91      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 108.85206151008606 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.004025315213948488\n",
      "Acquired samples: 33\n",
      "Sampling duration: 7.733389139175415 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5388, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4722, Accuracy: 0.8318, F1 Micro: 0.9031, F1 Macro: 0.902\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3693, Accuracy: 0.91, F1 Micro: 0.9451, F1 Macro: 0.9437\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2451, Accuracy: 0.942, F1 Micro: 0.9639, F1 Macro: 0.9615\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1735, Accuracy: 0.9524, F1 Micro: 0.9701, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1382, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9748\n",
      "Epoch 7/10, Train Loss: 0.1102, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0894, Accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9775\n",
      "Epoch 9/10, Train Loss: 0.0693, Accuracy: 0.9591, F1 Micro: 0.9741, F1 Macro: 0.9716\n",
      "Epoch 10/10, Train Loss: 0.0659, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9768\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9775\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.91      0.97      0.94       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5317, Accuracy: 0.8725, F1 Micro: 0.8725, F1 Macro: 0.86\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2708, Accuracy: 0.9124, F1 Micro: 0.9124, F1 Macro: 0.9056\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2113, Accuracy: 0.9402, F1 Micro: 0.9402, F1 Macro: 0.9339\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1631, Accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.937\n",
      "Epoch 5/10, Train Loss: 0.126, Accuracy: 0.9402, F1 Micro: 0.9402, F1 Macro: 0.9342\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0963, Accuracy: 0.9482, F1 Micro: 0.9482, F1 Macro: 0.942\n",
      "Epoch 7/10, Train Loss: 0.103, Accuracy: 0.9402, F1 Micro: 0.9402, F1 Macro: 0.9327\n",
      "Epoch 8/10, Train Loss: 0.0848, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9262\n",
      "Epoch 9/10, Train Loss: 0.0577, Accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9377\n",
      "Epoch 10/10, Train Loss: 0.0532, Accuracy: 0.9124, F1 Micro: 0.9124, F1 Macro: 0.8977\n",
      "\n",
      "Sentiment analysis accuracy: 0.9482, F1 Micro: 0.9482, F1 Macro: 0.942\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.94      0.92        83\n",
      "    positive       0.97      0.95      0.96       168\n",
      "\n",
      "    accuracy                           0.95       251\n",
      "   macro avg       0.94      0.95      0.94       251\n",
      "weighted avg       0.95      0.95      0.95       251\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.9152\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.84      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.91      0.97      0.94       152\n",
      "    positive       0.89      0.75      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.87      0.82      0.84       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.90      0.88      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.92      0.93       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 114.18914294242859 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.0034467535791918645\n",
      "Acquired samples: 30\n",
      "Sampling duration: 7.061600923538208 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5435, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4614, Accuracy: 0.8393, F1 Micro: 0.9072, F1 Macro: 0.9061\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3401, Accuracy: 0.9293, F1 Micro: 0.9565, F1 Macro: 0.9548\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2411, Accuracy: 0.9561, F1 Micro: 0.9727, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1689, Accuracy: 0.9583, F1 Micro: 0.9741, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1293, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0934, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9763\n",
      "Epoch 8/10, Train Loss: 0.0863, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.975\n",
      "Epoch 9/10, Train Loss: 0.0681, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9759\n",
      "Epoch 10/10, Train Loss: 0.0561, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.975\n",
      "\n",
      "Aspect detection accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9763\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.91      0.95      0.93       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4993, Accuracy: 0.8824, F1 Micro: 0.8824, F1 Macro: 0.8684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2775, Accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.9047\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2009, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9386\n",
      "Epoch 4/10, Train Loss: 0.1295, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.915\n",
      "Epoch 5/10, Train Loss: 0.1506, Accuracy: 0.902, F1 Micro: 0.902, F1 Macro: 0.8954\n",
      "Epoch 6/10, Train Loss: 0.1277, Accuracy: 0.9059, F1 Micro: 0.9059, F1 Macro: 0.8993\n",
      "Epoch 7/10, Train Loss: 0.1241, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9265\n",
      "Epoch 8/10, Train Loss: 0.0689, Accuracy: 0.9137, F1 Micro: 0.9137, F1 Macro: 0.906\n",
      "Epoch 9/10, Train Loss: 0.0657, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9348\n",
      "Epoch 10/10, Train Loss: 0.0508, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9219\n",
      "\n",
      "Sentiment analysis accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9386\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        84\n",
      "    positive       0.97      0.95      0.96       171\n",
      "\n",
      "    accuracy                           0.95       255\n",
      "   macro avg       0.93      0.94      0.94       255\n",
      "weighted avg       0.95      0.95      0.95       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9145\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.94      0.99      0.97       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.84      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.92      0.95      0.93       152\n",
      "    positive       0.81      0.75      0.78        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.85      0.82      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.92      0.83      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.92      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 113.41866111755371 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.0028634088113903998\n",
      "Acquired samples: 27\n",
      "Sampling duration: 6.427138328552246 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5448, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4601, Accuracy: 0.8289, F1 Micro: 0.9007, F1 Macro: 0.8992\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3469, Accuracy: 0.9405, F1 Micro: 0.9632, F1 Macro: 0.9617\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2305, Accuracy: 0.9524, F1 Micro: 0.9704, F1 Macro: 0.9691\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1607, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1263, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0963, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9768\n",
      "Epoch 8/10, Train Loss: 0.0803, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.975\n",
      "Epoch 9/10, Train Loss: 0.0655, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0568, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9783\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9783\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.93      0.95      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5171, Accuracy: 0.8803, F1 Micro: 0.8803, F1 Macro: 0.8703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2611, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9353\n",
      "Epoch 3/10, Train Loss: 0.1914, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9315\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.129, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.936\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1345, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.936\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1151, Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9439\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0836, Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9481\n",
      "Epoch 8/10, Train Loss: 0.0793, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9387\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0739, Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9475\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0847, Accuracy: 0.9575, F1 Micro: 0.9575, F1 Macro: 0.9525\n",
      "\n",
      "Sentiment analysis accuracy: 0.9575, F1 Micro: 0.9575, F1 Macro: 0.9525\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94        84\n",
      "    positive       0.99      0.95      0.97       175\n",
      "\n",
      "    accuracy                           0.96       259\n",
      "   macro avg       0.94      0.96      0.95       259\n",
      "weighted avg       0.96      0.96      0.96       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9276\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.84      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.93      0.95      0.94       152\n",
      "    positive       0.84      0.79      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.84      0.83      0.83       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.95      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 126.53861594200134 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.003475978272035718\n",
      "Acquired samples: 18\n",
      "Sampling duration: 5.98459529876709 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5367, Accuracy: 0.8006, F1 Micro: 0.887, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4586, Accuracy: 0.84, F1 Micro: 0.9071, F1 Macro: 0.9062\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.329, Accuracy: 0.9397, F1 Micro: 0.9629, F1 Macro: 0.9613\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2203, Accuracy: 0.9598, F1 Micro: 0.975, F1 Macro: 0.9738\n",
      "Epoch 5/10, Train Loss: 0.1537, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1274, Accuracy: 0.968, F1 Micro: 0.98, F1 Macro: 0.979\n",
      "Epoch 7/10, Train Loss: 0.0989, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9774\n",
      "Epoch 8/10, Train Loss: 0.0753, Accuracy: 0.9613, F1 Micro: 0.9755, F1 Macro: 0.9737\n",
      "Epoch 9/10, Train Loss: 0.0639, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9757\n",
      "Epoch 10/10, Train Loss: 0.052, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9771\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.98, F1 Macro: 0.979\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.97      0.94       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.551, Accuracy: 0.873, F1 Micro: 0.873, F1 Macro: 0.8661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2113, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9335\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1521, Accuracy: 0.9508, F1 Micro: 0.9508, F1 Macro: 0.9464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1655, Accuracy: 0.9549, F1 Micro: 0.9549, F1 Macro: 0.9493\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.116, Accuracy: 0.959, F1 Micro: 0.959, F1 Macro: 0.9549\n",
      "Epoch 6/10, Train Loss: 0.0973, Accuracy: 0.9549, F1 Micro: 0.9549, F1 Macro: 0.9507\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0705, Accuracy: 0.9631, F1 Micro: 0.9631, F1 Macro: 0.9588\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0678, Accuracy: 0.9672, F1 Micro: 0.9672, F1 Macro: 0.9637\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0568, Accuracy: 0.9672, F1 Micro: 0.9672, F1 Macro: 0.9635\n",
      "Epoch 10/10, Train Loss: 0.0649, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9305\n",
      "\n",
      "Sentiment analysis accuracy: 0.9672, F1 Micro: 0.9672, F1 Macro: 0.9635\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.95      0.95        83\n",
      "    positive       0.98      0.98      0.98       161\n",
      "\n",
      "    accuracy                           0.97       244\n",
      "   macro avg       0.96      0.96      0.96       244\n",
      "weighted avg       0.97      0.97      0.97       244\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.963, F1 Micro: 0.963, F1 Macro: 0.9322\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.94      0.99      0.97       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.84      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.75      0.86        12\n",
      "     neutral       0.92      0.97      0.95       152\n",
      "    positive       0.91      0.81      0.86        52\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.94      0.84      0.89       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.91      0.89        23\n",
      "     neutral       0.96      0.99      0.98       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.89      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 122.89655590057373 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.0027802006341516973\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.513049602508545 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5359, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4373, Accuracy: 0.8683, F1 Micro: 0.9221, F1 Macro: 0.921\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.298, Accuracy: 0.9457, F1 Micro: 0.9659, F1 Macro: 0.9633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1995, Accuracy: 0.9568, F1 Micro: 0.9731, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1347, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1046, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9768\n",
      "Epoch 7/10, Train Loss: 0.0817, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9743\n",
      "Epoch 8/10, Train Loss: 0.068, Accuracy: 0.9628, F1 Micro: 0.9768, F1 Macro: 0.9758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0583, Accuracy: 0.9695, F1 Micro: 0.9809, F1 Macro: 0.9799\n",
      "Epoch 10/10, Train Loss: 0.0507, Accuracy: 0.9613, F1 Micro: 0.9755, F1 Macro: 0.9735\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9809, F1 Macro: 0.9799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.93      0.96      0.95       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5399, Accuracy: 0.8945, F1 Micro: 0.8945, F1 Macro: 0.8846\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2708, Accuracy: 0.8984, F1 Micro: 0.8984, F1 Macro: 0.8774\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1909, Accuracy: 0.9609, F1 Micro: 0.9609, F1 Macro: 0.9562\n",
      "Epoch 4/10, Train Loss: 0.1523, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9391\n",
      "Epoch 5/10, Train Loss: 0.1193, Accuracy: 0.9531, F1 Micro: 0.9531, F1 Macro: 0.9475\n",
      "Epoch 6/10, Train Loss: 0.1096, Accuracy: 0.9531, F1 Micro: 0.9531, F1 Macro: 0.9478\n",
      "Epoch 7/10, Train Loss: 0.0912, Accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9436\n",
      "Epoch 8/10, Train Loss: 0.0564, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.938\n",
      "Epoch 9/10, Train Loss: 0.0758, Accuracy: 0.9297, F1 Micro: 0.9297, F1 Macro: 0.9233\n",
      "Epoch 10/10, Train Loss: 0.0472, Accuracy: 0.9297, F1 Micro: 0.9297, F1 Macro: 0.9233\n",
      "\n",
      "Sentiment analysis accuracy: 0.9609, F1 Micro: 0.9609, F1 Macro: 0.9562\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.96      0.94        84\n",
      "    positive       0.98      0.96      0.97       172\n",
      "\n",
      "    accuracy                           0.96       256\n",
      "   macro avg       0.95      0.96      0.96       256\n",
      "weighted avg       0.96      0.96      0.96       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.9637, F1 Micro: 0.9637, F1 Macro: 0.9307\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.94      0.99      0.97       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.84      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.94      0.96      0.95       152\n",
      "    positive       0.88      0.81      0.84        52\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.88      0.87      0.87       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.96      0.94        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.95      0.90      0.92        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.95      0.95       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 122.51760649681091 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.0027804297162219885\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.005880832672119 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5322, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4511, Accuracy: 0.8594, F1 Micro: 0.9177, F1 Macro: 0.9176\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.306, Accuracy: 0.9397, F1 Micro: 0.9628, F1 Macro: 0.9611\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2065, Accuracy: 0.9531, F1 Micro: 0.9707, F1 Macro: 0.9691\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1463, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1162, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9779\n",
      "Epoch 7/10, Train Loss: 0.0925, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9771\n",
      "Epoch 8/10, Train Loss: 0.0762, Accuracy: 0.9613, F1 Micro: 0.9754, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0585, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9789\n",
      "Epoch 10/10, Train Loss: 0.0519, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9776\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.97      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.533, Accuracy: 0.8867, F1 Micro: 0.8867, F1 Macro: 0.8686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2676, Accuracy: 0.9297, F1 Micro: 0.9297, F1 Macro: 0.9216\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1848, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9352\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1294, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9349\n",
      "Epoch 5/10, Train Loss: 0.1095, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9311\n",
      "Epoch 6/10, Train Loss: 0.1043, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9307\n",
      "Epoch 7/10, Train Loss: 0.0769, Accuracy: 0.9102, F1 Micro: 0.9102, F1 Macro: 0.9027\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0601, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9345\n",
      "Epoch 9/10, Train Loss: 0.0686, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9258\n",
      "Epoch 10/10, Train Loss: 0.0641, Accuracy: 0.9297, F1 Micro: 0.9297, F1 Macro: 0.9207\n",
      "\n",
      "Sentiment analysis accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9345\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.95      0.91        83\n",
      "    positive       0.98      0.94      0.96       173\n",
      "\n",
      "    accuracy                           0.94       256\n",
      "   macro avg       0.93      0.94      0.93       256\n",
      "weighted avg       0.94      0.94      0.94       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9165\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.92      0.97      0.95       152\n",
      "    positive       0.89      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.85      0.83      0.84       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.92      0.85      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.93      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 129.62758088111877 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.0022877593524754047\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.5411248207092285 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5491, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4431, Accuracy: 0.8772, F1 Micro: 0.9266, F1 Macro: 0.9261\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2909, Accuracy: 0.9457, F1 Micro: 0.9663, F1 Macro: 0.9646\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.192, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1362, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9757\n",
      "Epoch 6/10, Train Loss: 0.112, Accuracy: 0.9591, F1 Micro: 0.974, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0847, Accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9786\n",
      "Epoch 8/10, Train Loss: 0.0681, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9784\n",
      "Epoch 9/10, Train Loss: 0.0597, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0497, Accuracy: 0.9695, F1 Micro: 0.9809, F1 Macro: 0.9799\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9809, F1 Macro: 0.9799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.97      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4726, Accuracy: 0.8867, F1 Micro: 0.8867, F1 Macro: 0.8794\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2504, Accuracy: 0.9219, F1 Micro: 0.9219, F1 Macro: 0.9148\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1697, Accuracy: 0.9258, F1 Micro: 0.9258, F1 Macro: 0.9188\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1765, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9245\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1294, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9287\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1123, Accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9429\n",
      "Epoch 7/10, Train Loss: 0.0928, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9352\n",
      "Epoch 8/10, Train Loss: 0.0696, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.927\n",
      "Epoch 9/10, Train Loss: 0.068, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9391\n",
      "Epoch 10/10, Train Loss: 0.0484, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.938\n",
      "\n",
      "Sentiment analysis accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9429\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.92        83\n",
      "    positive       0.98      0.95      0.96       173\n",
      "\n",
      "    accuracy                           0.95       256\n",
      "   macro avg       0.94      0.95      0.94       256\n",
      "weighted avg       0.95      0.95      0.95       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9614, F1 Micro: 0.9614, F1 Macro: 0.9233\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.84      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.92      0.97      0.95       152\n",
      "    positive       0.91      0.75      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.86      0.82      0.84       216\n",
      "weighted avg       0.91      0.91      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.95      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.93      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 133.7758665084839 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.002551960968412459\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.115813493728638 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5291, Accuracy: 0.7954, F1 Micro: 0.8853, F1 Macro: 0.8838\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.426, Accuracy: 0.8906, F1 Micro: 0.9349, F1 Macro: 0.9342\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2829, Accuracy: 0.9509, F1 Micro: 0.9694, F1 Macro: 0.968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1792, Accuracy: 0.9561, F1 Micro: 0.9726, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1259, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1029, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.081, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.978\n",
      "Epoch 8/10, Train Loss: 0.0639, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9766\n",
      "Epoch 9/10, Train Loss: 0.0568, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "Epoch 10/10, Train Loss: 0.0456, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9766\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.93      0.97      0.95       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5626, Accuracy: 0.8906, F1 Micro: 0.8906, F1 Macro: 0.8781\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2999, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9274\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2034, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.93\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1571, Accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9439\n",
      "Epoch 5/10, Train Loss: 0.1432, Accuracy: 0.918, F1 Micro: 0.918, F1 Macro: 0.9111\n",
      "Epoch 6/10, Train Loss: 0.1322, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9356\n",
      "Epoch 7/10, Train Loss: 0.092, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9394\n",
      "Epoch 8/10, Train Loss: 0.0706, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9356\n",
      "Epoch 9/10, Train Loss: 0.0683, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9315\n",
      "Epoch 10/10, Train Loss: 0.0676, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9345\n",
      "\n",
      "Sentiment analysis accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9439\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.96      0.93        85\n",
      "    positive       0.98      0.94      0.96       171\n",
      "\n",
      "    accuracy                           0.95       256\n",
      "   macro avg       0.94      0.95      0.94       256\n",
      "weighted avg       0.95      0.95      0.95       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9234\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.86      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.93      0.97      0.95       152\n",
      "    positive       0.87      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.85      0.83      0.84       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 130.51337480545044 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.0027540032751858234\n",
      "Acquired samples: 8\n",
      "Sampling duration: 3.4379618167877197 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5188, Accuracy: 0.8006, F1 Micro: 0.8879, F1 Macro: 0.8864\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4271, Accuracy: 0.8958, F1 Micro: 0.9373, F1 Macro: 0.9362\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2916, Accuracy: 0.9457, F1 Micro: 0.9662, F1 Macro: 0.9646\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1871, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1385, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1071, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.082, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0675, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9785\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0567, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.979\n",
      "Epoch 10/10, Train Loss: 0.046, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9758\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.979\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      0.98      0.96       175\n",
      "      others       0.94      0.96      0.95       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5323, Accuracy: 0.9, F1 Micro: 0.9, F1 Macro: 0.8912\n",
      "Epoch 2/10, Train Loss: 0.3023, Accuracy: 0.8923, F1 Micro: 0.8923, F1 Macro: 0.8854\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1983, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9218\n",
      "Epoch 4/10, Train Loss: 0.1504, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.9079\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1481, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9305\n",
      "Epoch 6/10, Train Loss: 0.1064, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9276\n",
      "Epoch 7/10, Train Loss: 0.1152, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.928\n",
      "Epoch 8/10, Train Loss: 0.0746, Accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.9068\n",
      "Epoch 9/10, Train Loss: 0.0765, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.907\n",
      "Epoch 10/10, Train Loss: 0.0528, Accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.8991\n",
      "\n",
      "Sentiment analysis accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9305\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.92      0.91        85\n",
      "    positive       0.96      0.95      0.95       175\n",
      "\n",
      "    accuracy                           0.94       260\n",
      "   macro avg       0.93      0.93      0.93       260\n",
      "weighted avg       0.94      0.94      0.94       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.9148\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.83      0.73      0.77        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.88      0.82      0.84       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.94      0.96      0.95       152\n",
      "    positive       0.85      0.79      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.86      0.86      0.86       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.93      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 135.66757035255432 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.002132221544161439\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.2532877922058105 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5233, Accuracy: 0.7984, F1 Micro: 0.8868, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4283, Accuracy: 0.8876, F1 Micro: 0.9329, F1 Macro: 0.9324\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2773, Accuracy: 0.9524, F1 Micro: 0.9705, F1 Macro: 0.9692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1781, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1287, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9754\n",
      "Epoch 6/10, Train Loss: 0.1008, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0741, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0686, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9785\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.056, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9797\n",
      "Epoch 10/10, Train Loss: 0.048, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9797\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.96      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5038, Accuracy: 0.9046, F1 Micro: 0.9046, F1 Macro: 0.895\n",
      "Epoch 2/10, Train Loss: 0.2833, Accuracy: 0.8969, F1 Micro: 0.8969, F1 Macro: 0.8906\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1828, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.9327\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1617, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.933\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1164, Accuracy: 0.9427, F1 Micro: 0.9427, F1 Macro: 0.9367\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1153, Accuracy: 0.9466, F1 Micro: 0.9466, F1 Macro: 0.9401\n",
      "Epoch 7/10, Train Loss: 0.0767, Accuracy: 0.9427, F1 Micro: 0.9427, F1 Macro: 0.9364\n",
      "Epoch 8/10, Train Loss: 0.0778, Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.9226\n",
      "Epoch 9/10, Train Loss: 0.0746, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.9323\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0575, Accuracy: 0.9466, F1 Micro: 0.9466, F1 Macro: 0.9404\n",
      "\n",
      "Sentiment analysis accuracy: 0.9466, F1 Micro: 0.9466, F1 Macro: 0.9404\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.95      0.92        86\n",
      "    positive       0.98      0.94      0.96       176\n",
      "\n",
      "    accuracy                           0.95       262\n",
      "   macro avg       0.93      0.95      0.94       262\n",
      "weighted avg       0.95      0.95      0.95       262\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9614, F1 Micro: 0.9614, F1 Macro: 0.9243\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.86      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.93      0.96      0.94       152\n",
      "    positive       0.87      0.79      0.83        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.88      0.86      0.87       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.95      0.88      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.95      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 140.8253903388977 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0019699406111612916\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.748911142349243 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5327, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.417, Accuracy: 0.9077, F1 Micro: 0.9441, F1 Macro: 0.943\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.263, Accuracy: 0.9509, F1 Micro: 0.9697, F1 Macro: 0.9685\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1713, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1272, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9765\n",
      "Epoch 6/10, Train Loss: 0.0962, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9726\n",
      "Epoch 7/10, Train Loss: 0.0798, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0587, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9779\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0554, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9778\n",
      "Epoch 10/10, Train Loss: 0.0462, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9772\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.93      0.96      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4722, Accuracy: 0.8992, F1 Micro: 0.8992, F1 Macro: 0.8917\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2341, Accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.9169\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2009, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9269\n",
      "Epoch 4/10, Train Loss: 0.1577, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.921\n",
      "Epoch 5/10, Train Loss: 0.1333, Accuracy: 0.9147, F1 Micro: 0.9147, F1 Macro: 0.901\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1062, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9269\n",
      "Epoch 7/10, Train Loss: 0.097, Accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.9196\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0707, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9314\n",
      "Epoch 9/10, Train Loss: 0.0603, Accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.9151\n",
      "Epoch 10/10, Train Loss: 0.0403, Accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.9187\n",
      "\n",
      "Sentiment analysis accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9314\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.95      0.91        85\n",
      "    positive       0.98      0.93      0.95       173\n",
      "\n",
      "    accuracy                           0.94       258\n",
      "   macro avg       0.92      0.94      0.93       258\n",
      "weighted avg       0.94      0.94      0.94       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9151\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.84      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.93      0.95      0.94       152\n",
      "    positive       0.83      0.77      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.84      0.82      0.83       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.93      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 140.45392894744873 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0019307264126837255\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.549332618713379 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5293, Accuracy: 0.7939, F1 Micro: 0.8809, F1 Macro: 0.8763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4053, Accuracy: 0.9196, F1 Micro: 0.9513, F1 Macro: 0.9503\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2562, Accuracy: 0.9524, F1 Micro: 0.9705, F1 Macro: 0.9695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1706, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1249, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0971, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.978\n",
      "Epoch 7/10, Train Loss: 0.0723, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9751\n",
      "Epoch 8/10, Train Loss: 0.0642, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.977\n",
      "Epoch 9/10, Train Loss: 0.0536, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9742\n",
      "Epoch 10/10, Train Loss: 0.0457, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9768\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      0.99      0.96       175\n",
      "      others       0.93      0.97      0.95       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5123, Accuracy: 0.8984, F1 Micro: 0.8984, F1 Macro: 0.8897\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2636, Accuracy: 0.918, F1 Micro: 0.918, F1 Macro: 0.9111\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1873, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9349\n",
      "Epoch 4/10, Train Loss: 0.1372, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.924\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0873, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9352\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0986, Accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9436\n",
      "Epoch 7/10, Train Loss: 0.0669, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9311\n",
      "Epoch 8/10, Train Loss: 0.0652, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9352\n",
      "Epoch 9/10, Train Loss: 0.08, Accuracy: 0.9258, F1 Micro: 0.9258, F1 Macro: 0.9188\n",
      "Epoch 10/10, Train Loss: 0.0449, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.927\n",
      "\n",
      "Sentiment analysis accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9436\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.96      0.93        84\n",
      "    positive       0.98      0.94      0.96       172\n",
      "\n",
      "    accuracy                           0.95       256\n",
      "   macro avg       0.94      0.95      0.94       256\n",
      "weighted avg       0.95      0.95      0.95       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9217\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.75      0.77        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.92      0.70      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.81      0.84       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.93      0.97      0.95       152\n",
      "    positive       0.87      0.79      0.83        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.87      0.84      0.85       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 137.63046956062317 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0017135688452981413\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.697113275527954 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5252, Accuracy: 0.7969, F1 Micro: 0.886, F1 Macro: 0.8846\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4134, Accuracy: 0.9211, F1 Micro: 0.9523, F1 Macro: 0.9513\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2573, Accuracy: 0.9546, F1 Micro: 0.972, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1643, Accuracy: 0.9621, F1 Micro: 0.9763, F1 Macro: 0.9752\n",
      "Epoch 5/10, Train Loss: 0.1213, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1005, Accuracy: 0.9688, F1 Micro: 0.9805, F1 Macro: 0.9794\n",
      "Epoch 7/10, Train Loss: 0.0703, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9789\n",
      "Epoch 8/10, Train Loss: 0.0628, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "Epoch 9/10, Train Loss: 0.0541, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9764\n",
      "Epoch 10/10, Train Loss: 0.0439, Accuracy: 0.9613, F1 Micro: 0.9754, F1 Macro: 0.9733\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9805, F1 Macro: 0.9794\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.97      0.94       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4608, Accuracy: 0.9393, F1 Micro: 0.9393, F1 Macro: 0.9336\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2322, Accuracy: 0.9433, F1 Micro: 0.9433, F1 Macro: 0.9376\n",
      "Epoch 3/10, Train Loss: 0.1437, Accuracy: 0.9312, F1 Micro: 0.9312, F1 Macro: 0.9252\n",
      "Epoch 4/10, Train Loss: 0.0975, Accuracy: 0.9352, F1 Micro: 0.9352, F1 Macro: 0.9294\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0936, Accuracy: 0.9433, F1 Micro: 0.9433, F1 Macro: 0.9365\n",
      "Epoch 6/10, Train Loss: 0.097, Accuracy: 0.9312, F1 Micro: 0.9312, F1 Macro: 0.9248\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0694, Accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9415\n",
      "Epoch 8/10, Train Loss: 0.0621, Accuracy: 0.9433, F1 Micro: 0.9433, F1 Macro: 0.9376\n",
      "Epoch 9/10, Train Loss: 0.0514, Accuracy: 0.9393, F1 Micro: 0.9393, F1 Macro: 0.9322\n",
      "Epoch 10/10, Train Loss: 0.0576, Accuracy: 0.9393, F1 Micro: 0.9393, F1 Macro: 0.9309\n",
      "\n",
      "Sentiment analysis accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9415\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.92        82\n",
      "    positive       0.97      0.95      0.96       165\n",
      "\n",
      "    accuracy                           0.95       247\n",
      "   macro avg       0.94      0.95      0.94       247\n",
      "weighted avg       0.95      0.95      0.95       247\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9193\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.92      0.97      0.95       152\n",
      "    positive       0.91      0.79      0.85        52\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.91      0.84      0.87       216\n",
      "weighted avg       0.92      0.92      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.91      0.87        23\n",
      "     neutral       0.96      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.90      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.89      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 136.77160835266113 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0013024846324697138\n",
      "Acquired samples: 8\n",
      "Sampling duration: 1.0386147499084473 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5219, Accuracy: 0.7976, F1 Micro: 0.8864, F1 Macro: 0.885\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4004, Accuracy: 0.9204, F1 Micro: 0.9511, F1 Macro: 0.9496\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2457, Accuracy: 0.9524, F1 Micro: 0.9704, F1 Macro: 0.9689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1689, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1222, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9773\n",
      "Epoch 6/10, Train Loss: 0.0919, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9771\n",
      "Epoch 7/10, Train Loss: 0.0746, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9742\n",
      "Epoch 8/10, Train Loss: 0.0598, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9764\n",
      "Epoch 9/10, Train Loss: 0.0498, Accuracy: 0.9613, F1 Micro: 0.9755, F1 Macro: 0.9734\n",
      "Epoch 10/10, Train Loss: 0.044, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9756\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.94      0.94      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4917, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.9004\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2277, Accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.9393\n",
      "Epoch 3/10, Train Loss: 0.1384, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9201\n",
      "Epoch 4/10, Train Loss: 0.1135, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9197\n",
      "Epoch 5/10, Train Loss: 0.112, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9168\n",
      "Epoch 6/10, Train Loss: 0.0698, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9318\n",
      "Epoch 7/10, Train Loss: 0.0737, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.895\n",
      "Epoch 8/10, Train Loss: 0.0593, Accuracy: 0.9432, F1 Micro: 0.9432, F1 Macro: 0.9363\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0704, Accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.9403\n",
      "Epoch 10/10, Train Loss: 0.0497, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.926\n",
      "\n",
      "Sentiment analysis accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.9403\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        84\n",
      "    positive       0.98      0.94      0.96       180\n",
      "\n",
      "    accuracy                           0.95       264\n",
      "   macro avg       0.93      0.95      0.94       264\n",
      "weighted avg       0.95      0.95      0.95       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.9207\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.86      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.92      0.88        12\n",
      "     neutral       0.94      0.95      0.94       152\n",
      "    positive       0.84      0.81      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.88      0.89      0.88       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.94      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 139.36983227729797 s\n",
      "Total runtime: 3091.495689868927 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[4], 4)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6734022,
     "sourceId": 10843162,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6262.186773,
   "end_time": "2025-03-26T11:23:04.866143",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-26T09:38:42.679370",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0272a5e13cae4899b670dffaa475dab8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "0e1fb028146540f1840e5f3c054491ab": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_fe6d215e55a7430b98533a67b48b8afc",
       "placeholder": "",
       "style": "IPY_MODEL_8595f5fa132f43a58aef0edb5659e077",
       "tabbable": null,
       "tooltip": null,
       "value": "2.00/2.00[00:00&lt;00:00,160B/s]"
      }
     },
     "16bd6aded67d47afb89ca00978515da6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "183baa3aaf9742e08a1a28cf3c75de3c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_63005188a17e4e80873e60656097778a",
       "max": 2,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_774e1c123d104d76b86ee60b938e8d63",
       "tabbable": null,
       "tooltip": null,
       "value": 2
      }
     },
     "18e33904ce14402d83efe90fbc91bcd9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3ee80a62c5e64a879d2e8eea48f6fea0",
       "max": 112,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0272a5e13cae4899b670dffaa475dab8",
       "tabbable": null,
       "tooltip": null,
       "value": 112
      }
     },
     "193a59acc8354659ba88d5583dcac19f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_bc1bf60ca9a04c00b2f33fdda384fbaf",
        "IPY_MODEL_4cf077bbac764e13beaa63f30a461f72",
        "IPY_MODEL_47cadc466e6c4e53b9af73af123e26e7"
       ],
       "layout": "IPY_MODEL_f1fc8263dcff4a969c4987b9f3c70f97",
       "tabbable": null,
       "tooltip": null
      }
     },
     "1b3a6e2feb184610bcd92e721fd57af6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_39a0b30943d645d88125223ba09d0939",
       "placeholder": "",
       "style": "IPY_MODEL_16bd6aded67d47afb89ca00978515da6",
       "tabbable": null,
       "tooltip": null,
       "value": "112/112[00:00&lt;00:00,11.2kB/s]"
      }
     },
     "252b664280be4046abb0568e8f93b775": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6450f15099d847fdba7ca9b3a8e64e88",
        "IPY_MODEL_18e33904ce14402d83efe90fbc91bcd9",
        "IPY_MODEL_1b3a6e2feb184610bcd92e721fd57af6"
       ],
       "layout": "IPY_MODEL_7c858011d6614b2db61768d23b4cd340",
       "tabbable": null,
       "tooltip": null
      }
     },
     "26d725e875364ac48c888532189ae7da": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_90881aa6827b43d7952be8bdf872726c",
        "IPY_MODEL_183baa3aaf9742e08a1a28cf3c75de3c",
        "IPY_MODEL_0e1fb028146540f1840e5f3c054491ab"
       ],
       "layout": "IPY_MODEL_eccc2dcde0314c059e14232d0dff5c6f",
       "tabbable": null,
       "tooltip": null
      }
     },
     "284d8e69b4504842adaf8a4133039303": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "357ac7736c8244d19f85f856be4f155f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "39a0b30943d645d88125223ba09d0939": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3a5700de28244c408cfa9f23f0776b90": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3ee80a62c5e64a879d2e8eea48f6fea0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "430a816effe64cf39c1ffa0ef6bd41e8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "47cadc466e6c4e53b9af73af123e26e7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b85cc7725ded44128a875f2cab3cabf6",
       "placeholder": "",
       "style": "IPY_MODEL_357ac7736c8244d19f85f856be4f155f",
       "tabbable": null,
       "tooltip": null,
       "value": "1.53k/1.53k[00:00&lt;00:00,162kB/s]"
      }
     },
     "4b587979d8ed4c76b09e296f6a7e532f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "4cf077bbac764e13beaa63f30a461f72": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_66e0c0fb946847eda2a1d04de8e1b001",
       "max": 1534,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4b587979d8ed4c76b09e296f6a7e532f",
       "tabbable": null,
       "tooltip": null,
       "value": 1534
      }
     },
     "51afefe169a04726a9743f33e7e877cb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5d7f27dd28ca44d1a4a011aef6521232": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "63005188a17e4e80873e60656097778a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6450f15099d847fdba7ca9b3a8e64e88": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7f3828a8d6ac41d2956cd07bf1b47139",
       "placeholder": "",
       "style": "IPY_MODEL_d9b1d5ad71a44423997152ed483b22f6",
       "tabbable": null,
       "tooltip": null,
       "value": "special_tokens_map.json:100%"
      }
     },
     "66e0c0fb946847eda2a1d04de8e1b001": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "672998ee00b848278efc385a062ff1f7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6f7477fd282f41f18350489ca14ae92c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7040a67c6a5c4d0b86fd5abeca634089": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_81e2dec8626f421bb421eb277edb117c",
        "IPY_MODEL_b8258c727fc54ac3a2141a7ac9b64e94",
        "IPY_MODEL_c69e6475b3b14f81bee3589195a9f574"
       ],
       "layout": "IPY_MODEL_a993b11051bb4df4ba38bb23db872296",
       "tabbable": null,
       "tooltip": null
      }
     },
     "774e1c123d104d76b86ee60b938e8d63": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7c858011d6614b2db61768d23b4cd340": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7f3828a8d6ac41d2956cd07bf1b47139": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "81e2dec8626f421bb421eb277edb117c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6f7477fd282f41f18350489ca14ae92c",
       "placeholder": "",
       "style": "IPY_MODEL_5d7f27dd28ca44d1a4a011aef6521232",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.txt:100%"
      }
     },
     "8595f5fa132f43a58aef0edb5659e077": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "86f7ae650e4d482085507ef23e077a8d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "90881aa6827b43d7952be8bdf872726c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_faf1ca589434430ea03ad1b5c452063e",
       "placeholder": "",
       "style": "IPY_MODEL_51afefe169a04726a9743f33e7e877cb",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json:100%"
      }
     },
     "9e2866b4f2ae4b16b3fee7a31c3f0bcd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a993b11051bb4df4ba38bb23db872296": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b8258c727fc54ac3a2141a7ac9b64e94": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9e2866b4f2ae4b16b3fee7a31c3f0bcd",
       "max": 229167,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3a5700de28244c408cfa9f23f0776b90",
       "tabbable": null,
       "tooltip": null,
       "value": 229167
      }
     },
     "b85cc7725ded44128a875f2cab3cabf6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bc1bf60ca9a04c00b2f33fdda384fbaf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_284d8e69b4504842adaf8a4133039303",
       "placeholder": "",
       "style": "IPY_MODEL_86f7ae650e4d482085507ef23e077a8d",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json:100%"
      }
     },
     "c69e6475b3b14f81bee3589195a9f574": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_430a816effe64cf39c1ffa0ef6bd41e8",
       "placeholder": "",
       "style": "IPY_MODEL_672998ee00b848278efc385a062ff1f7",
       "tabbable": null,
       "tooltip": null,
       "value": "229k/229k[00:00&lt;00:00,1.87MB/s]"
      }
     },
     "d9b1d5ad71a44423997152ed483b22f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "eccc2dcde0314c059e14232d0dff5c6f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f1fc8263dcff4a969c4987b9f3c70f97": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "faf1ca589434430ea03ad1b5c452063e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fe6d215e55a7430b98533a67b48b8afc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
