{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "893878fb",
   "metadata": {
    "papermill": {
     "duration": 0.012215,
     "end_time": "2025-03-06T10:55:58.548304",
     "exception": false,
     "start_time": "2025-03-06T10:55:58.536089",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9a6945e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T10:55:58.571141Z",
     "iopub.status.busy": "2025-03-06T10:55:58.570890Z",
     "iopub.status.idle": "2025-03-06T10:56:20.555074Z",
     "shell.execute_reply": "2025-03-06T10:56:20.554338Z"
    },
    "papermill": {
     "duration": 21.997146,
     "end_time": "2025-03-06T10:56:20.556629",
     "exception": false,
     "start_time": "2025-03-06T10:55:58.559483",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score, classification_report\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "from torch.multiprocessing import Manager\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel, BertPreTrainedModel, BertConfig, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9066456",
   "metadata": {
    "papermill": {
     "duration": 0.010762,
     "end_time": "2025-03-06T10:56:20.579040",
     "exception": false,
     "start_time": "2025-03-06T10:56:20.568278",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0618db6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T10:56:20.602033Z",
     "iopub.status.busy": "2025-03-06T10:56:20.601513Z",
     "iopub.status.idle": "2025-03-06T10:56:20.605146Z",
     "shell.execute_reply": "2025-03-06T10:56:20.604342Z"
    },
    "papermill": {
     "duration": 0.016524,
     "end_time": "2025-03-06T10:56:20.606417",
     "exception": false,
     "start_time": "2025-03-06T10:56:20.589893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3eaf217",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T10:56:20.628934Z",
     "iopub.status.busy": "2025-03-06T10:56:20.628665Z",
     "iopub.status.idle": "2025-03-06T10:56:20.632606Z",
     "shell.execute_reply": "2025-03-06T10:56:20.631826Z"
    },
    "papermill": {
     "duration": 0.016572,
     "end_time": "2025-03-06T10:56:20.633791",
     "exception": false,
     "start_time": "2025-03-06T10:56:20.617219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists('/kaggle/working/results') == False:\n",
    "    os.mkdir('/kaggle/working/results')\n",
    "\n",
    "if os.path.exists('/kaggle/working/acquired_data') == False:\n",
    "    os.mkdir('/kaggle/working/acquired_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2416b3bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T10:56:20.656743Z",
     "iopub.status.busy": "2025-03-06T10:56:20.656537Z",
     "iopub.status.idle": "2025-03-06T10:56:20.664414Z",
     "shell.execute_reply": "2025-03-06T10:56:20.663866Z"
    },
    "papermill": {
     "duration": 0.020405,
     "end_time": "2025-03-06T10:56:20.665500",
     "exception": false,
     "start_time": "2025-03-06T10:56:20.645095",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "    torch.backends.cudnn.benchmark=False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca91f837",
   "metadata": {
    "papermill": {
     "duration": 0.011061,
     "end_time": "2025-03-06T10:56:20.687560",
     "exception": false,
     "start_time": "2025-03-06T10:56:20.676499",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# GLOBAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e4422f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T10:56:20.710115Z",
     "iopub.status.busy": "2025-03-06T10:56:20.709888Z",
     "iopub.status.idle": "2025-03-06T10:56:20.771449Z",
     "shell.execute_reply": "2025-03-06T10:56:20.769954Z"
    },
    "papermill": {
     "duration": 0.074468,
     "end_time": "2025-03-06T10:56:20.772972",
     "exception": false,
     "start_time": "2025-03-06T10:56:20.698504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "\n",
    "# Shared resources\n",
    "aspect_accuracies = manager.list()\n",
    "aspect_f1_micros = manager.list()\n",
    "aspect_f1_macros = manager.list()\n",
    "sentiment_accuracies = manager.list()\n",
    "sentiment_f1_micros = manager.list()\n",
    "sentiment_f1_macros = manager.list()\n",
    "accuracies = manager.list()\n",
    "f1_micros = manager.list()\n",
    "f1_macros = manager.list()\n",
    "farthest_point = manager.Value(\"s\", \"test\")\n",
    "\n",
    "# Non shared resources\n",
    "filename = 'casa-coreset'\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "sequence_length = 48\n",
    "\n",
    "aspect_list = ['fuel', 'machine', 'others', 'part', 'price', 'service']\n",
    "aspect_mapping = {'fuel': 0, 'machine': 1, 'others': 2, 'part': 3, 'price': 4, 'service': 5 }\n",
    "label_mapping = {\"negative\": 0, \"neutral\": 1, 'positive': 2}\n",
    "ignored_keys = ['labels', 'ori_text', 'ori_label', 'ori_indices', 'aspect']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e7de51",
   "metadata": {
    "papermill": {
     "duration": 0.0115,
     "end_time": "2025-03-06T10:56:20.797930",
     "exception": false,
     "start_time": "2025-03-06T10:56:20.786430",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LOAD AND PREPROCESS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eac53ad6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T10:56:20.821068Z",
     "iopub.status.busy": "2025-03-06T10:56:20.820742Z",
     "iopub.status.idle": "2025-03-06T10:56:20.891654Z",
     "shell.execute_reply": "2025-03-06T10:56:20.890775Z"
    },
    "papermill": {
     "duration": 0.084068,
     "end_time": "2025-03-06T10:56:20.892947",
     "exception": false,
     "start_time": "2025-03-06T10:56:20.808879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>fuel</th>\n",
       "      <th>machine</th>\n",
       "      <th>others</th>\n",
       "      <th>part</th>\n",
       "      <th>price</th>\n",
       "      <th>service</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saya memakai Honda Jazz GK5 tahun 2014 ( perta...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Avanza kenapa jadi boros bensin begini dah ah....</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saran ku dan pengalaman ku , mending beli mobi...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dari segi harga juga pajero lebih mahal 30 jut...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kalo menurut gw enak pajero si</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence      fuel   machine  \\\n",
       "0  Saya memakai Honda Jazz GK5 tahun 2014 ( perta...   neutral   neutral   \n",
       "1  Avanza kenapa jadi boros bensin begini dah ah....  negative   neutral   \n",
       "2  saran ku dan pengalaman ku , mending beli mobi...  positive  positive   \n",
       "3  Dari segi harga juga pajero lebih mahal 30 jut...   neutral   neutral   \n",
       "4                     Kalo menurut gw enak pajero si   neutral   neutral   \n",
       "\n",
       "     others     part     price  service  \n",
       "0  positive  neutral   neutral  neutral  \n",
       "1   neutral  neutral   neutral  neutral  \n",
       "2   neutral  neutral   neutral  neutral  \n",
       "3   neutral  neutral  positive  neutral  \n",
       "4  positive  neutral   neutral  neutral  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('/kaggle/input/casa-dataset/train_preprocess.csv', encoding='latin-1')\n",
    "val_data = pd.read_csv('/kaggle/input/casa-dataset/valid_preprocess.csv', encoding='latin-1')\n",
    "test_data = pd.read_csv('/kaggle/input/casa-dataset/test_preprocess.csv', encoding='latin-1')\n",
    "\n",
    "data = pd.concat([train_data, val_data, test_data], ignore_index=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52b28371",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T10:56:20.917979Z",
     "iopub.status.busy": "2025-03-06T10:56:20.917706Z",
     "iopub.status.idle": "2025-03-06T10:56:20.925778Z",
     "shell.execute_reply": "2025-03-06T10:56:20.924868Z"
    },
    "papermill": {
     "duration": 0.022393,
     "end_time": "2025-03-06T10:56:20.927166",
     "exception": false,
     "start_time": "2025-03-06T10:56:20.904773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3db8dca2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T10:56:20.950072Z",
     "iopub.status.busy": "2025-03-06T10:56:20.949835Z",
     "iopub.status.idle": "2025-03-06T10:56:20.960643Z",
     "shell.execute_reply": "2025-03-06T10:56:20.959936Z"
    },
    "papermill": {
     "duration": 0.023756,
     "end_time": "2025-03-06T10:56:20.962016",
     "exception": false,
     "start_time": "2025-03-06T10:56:20.938260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(864,) (864, 6)\n",
      "(216,) (216, 6)\n"
     ]
    }
   ],
   "source": [
    "train_labels = train_data.columns[1:]\n",
    "val_labels = val_data.columns[1:]\n",
    "\n",
    "# Extract features and labels for training and validation\n",
    "X_train = train_data['sentence'].values\n",
    "y_train = train_data[train_labels].values\n",
    "X_val = val_data['sentence'].values\n",
    "y_val = val_data[val_labels].values\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70c7ef5",
   "metadata": {
    "papermill": {
     "duration": 0.010965,
     "end_time": "2025-03-06T10:56:20.984554",
     "exception": false,
     "start_time": "2025-03-06T10:56:20.973589",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BUILD DATASET & DATALOADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87a044ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T10:56:21.007721Z",
     "iopub.status.busy": "2025-03-06T10:56:21.007476Z",
     "iopub.status.idle": "2025-03-06T10:56:21.013748Z",
     "shell.execute_reply": "2025-03-06T10:56:21.012986Z"
    },
    "papermill": {
     "duration": 0.019501,
     "end_time": "2025-03-06T10:56:21.015011",
     "exception": false,
     "start_time": "2025-03-06T10:56:20.995510",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AspectDetectionDataset(Dataset):\n",
    "    def __init__(self, texts, labels, label_mapping, tokenizer, max_length=sequence_length, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.use_float = use_float\n",
    "        self.label_mapping = label_mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "        \n",
    "        original_labels = [self.label_mapping[label] for label in self.labels[idx]]\n",
    "        encoded_labels = [1 if label == 1 else 0 for label in original_labels]\n",
    "        \n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['ori_indices'] = idx\n",
    "        item['ori_text'] = self.texts[idx]\n",
    "        item['ori_label'] = torch.tensor(original_labels, dtype=torch.float)\n",
    "        item['labels'] = torch.tensor(encoded_labels, dtype=torch.float if self.use_float else torch.long)\n",
    "        \n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73b79771",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T10:56:21.037967Z",
     "iopub.status.busy": "2025-03-06T10:56:21.037686Z",
     "iopub.status.idle": "2025-03-06T10:56:21.045568Z",
     "shell.execute_reply": "2025-03-06T10:56:21.044650Z"
    },
    "papermill": {
     "duration": 0.020976,
     "end_time": "2025-03-06T10:56:21.047184",
     "exception": false,
     "start_time": "2025-03-06T10:56:21.026208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SentimentAnalysisDataset(Dataset):\n",
    "    def __init__(self, texts, labels, aspects, indices, label_mapping, tokenizer, max_length=96, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.aspects = aspects\n",
    "        self.indices = indices\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.use_float = use_float\n",
    "        self.label_mapping = label_mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = aspect_token + ' ' + self.aspects[idx] + ' ' + review_token + ' ' + self.texts[idx] \n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "\n",
    "        if isinstance(self.labels[idx], str):\n",
    "            self.labels[idx] = self.label_mapping[self.labels[idx]]\n",
    "        elif torch.is_tensor(self.labels[idx]):\n",
    "            self.labels[idx] = int(self.labels[idx].item())\n",
    "\n",
    "        encoded_label = 1 if self.labels[idx] == 2 else self.labels[idx]\n",
    "        one_hot_label = F.one_hot(torch.tensor(encoded_label, dtype=torch.long), num_classes=2).float()\n",
    "\n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['aspect'] = self.aspects[idx]\n",
    "        item['labels'] = one_hot_label\n",
    "        item['ori_indices'] = self.indices[idx]\n",
    "        item['ori_text'] = self.texts[idx]\n",
    "        item['ori_label'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b77a29fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T10:56:21.071957Z",
     "iopub.status.busy": "2025-03-06T10:56:21.071707Z",
     "iopub.status.idle": "2025-03-06T10:56:21.785007Z",
     "shell.execute_reply": "2025-03-06T10:56:21.783876Z"
    },
    "papermill": {
     "duration": 0.72669,
     "end_time": "2025-03-06T10:56:21.786841",
     "exception": false,
     "start_time": "2025-03-06T10:56:21.060151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "733052b19f93499da399267eeabf2ef5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79acff3110a8478bab268f8e97863bd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/229k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e100ffe977e94e1db2df025fe73e62ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a63458c1355a467fbabac40ee2e2ded3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p1')\n",
    "review_token = '[REVIEW]'\n",
    "aspect_token = '[ASPECT]'\n",
    "special_tokens_dict = {'additional_special_tokens': [review_token, aspect_token]}\n",
    "num_added_tokens = tokenizer.add_special_tokens(special_tokens_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d44c7363",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T10:56:21.811800Z",
     "iopub.status.busy": "2025-03-06T10:56:21.811554Z",
     "iopub.status.idle": "2025-03-06T10:56:21.815755Z",
     "shell.execute_reply": "2025-03-06T10:56:21.815146Z"
    },
    "papermill": {
     "duration": 0.017629,
     "end_time": "2025-03-06T10:56:21.817070",
     "exception": false,
     "start_time": "2025-03-06T10:56:21.799441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_aspect_dataset(X_train, y_train, X_val, y_val, sequence_length, num_workers=4):\n",
    "    train_dataset = AspectDetectionDataset(X_train, y_train, label_mapping, tokenizer, max_length=sequence_length)\n",
    "    val_dataset = AspectDetectionDataset(X_val, y_val, label_mapping, tokenizer, max_length=sequence_length)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=num_workers,\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=num_workers, \n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf861431",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T10:56:21.841394Z",
     "iopub.status.busy": "2025-03-06T10:56:21.841155Z",
     "iopub.status.idle": "2025-03-06T10:56:21.853726Z",
     "shell.execute_reply": "2025-03-06T10:56:21.852770Z"
    },
    "papermill": {
     "duration": 0.026137,
     "end_time": "2025-03-06T10:56:21.855273",
     "exception": false,
     "start_time": "2025-03-06T10:56:21.829136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_sentiment_dataset(device, train_dataset, val_dataset, aspect_detection_model, tokenizer, max_length=sequence_length):\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "\n",
    "    aspect_detection_model.to(device)\n",
    "    aspect_detection_model.eval()\n",
    "\n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "    train_aspects = []\n",
    "    train_indices = []\n",
    "\n",
    "    val_data = []\n",
    "    val_labels = []\n",
    "    val_aspects = []\n",
    "    val_indices = []\n",
    "\n",
    "    # Transform train set\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        for batch in train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = aspect_detection_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            for i in range(len(preds)):\n",
    "                for j in range(len(preds[i])):\n",
    "                    if int(preds[i][j]) != 1:\n",
    "                        train_aspects.append(aspect_list[j])\n",
    "                        train_data.append(batch['ori_text'][i])\n",
    "                        train_labels.append(batch['ori_label'][i][j])\n",
    "                        train_indices.append(batch['ori_indices'][i])\n",
    "            \n",
    "        # Transform validation set\n",
    "        for batch in val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = aspect_detection_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            for i in range(len(preds)):\n",
    "                for j in range(len(preds[i])):\n",
    "                    if int(preds[i][j]) != 1:\n",
    "                        val_aspects.append(aspect_list[j])\n",
    "                        val_data.append(batch['ori_text'][i])\n",
    "                        val_labels.append(batch['ori_label'][i][j])\n",
    "                        val_indices.append(batch['ori_indices'][i])\n",
    "\n",
    "    train_dataset = SentimentAnalysisDataset(train_data, train_labels, train_aspects, train_indices, label_mapping, tokenizer, max_length=max_length)\n",
    "    val_dataset = SentimentAnalysisDataset(val_data, val_labels, val_aspects, val_indices, label_mapping, tokenizer, max_length=max_length)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9ced08",
   "metadata": {
    "papermill": {
     "duration": 0.020054,
     "end_time": "2025-03-06T10:56:21.889601",
     "exception": false,
     "start_time": "2025-03-06T10:56:21.869547",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03bf50b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T10:56:21.923043Z",
     "iopub.status.busy": "2025-03-06T10:56:21.922738Z",
     "iopub.status.idle": "2025-03-06T10:56:21.926735Z",
     "shell.execute_reply": "2025-03-06T10:56:21.925865Z"
    },
    "papermill": {
     "duration": 0.022627,
     "end_time": "2025-03-06T10:56:21.928120",
     "exception": false,
     "start_time": "2025-03-06T10:56:21.905493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_data = len(X_train) + len(X_val)\n",
    "initial_train_size = int(0.05 * total_data)\n",
    "checkpoints = [\n",
    "    int(0.5 * total_data), \n",
    "    int(0.6 * total_data), \n",
    "    int(0.7 * total_data),\n",
    "    len(X_train)\n",
    "]\n",
    "min_increment = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7177aaa6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T10:56:21.951799Z",
     "iopub.status.busy": "2025-03-06T10:56:21.951578Z",
     "iopub.status.idle": "2025-03-06T10:56:21.956119Z",
     "shell.execute_reply": "2025-03-06T10:56:21.955390Z"
    },
    "papermill": {
     "duration": 0.017973,
     "end_time": "2025-03-06T10:56:21.957433",
     "exception": false,
     "start_time": "2025-03-06T10:56:21.939460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p, label, classes):\n",
    "    preds = torch.tensor(p.predictions) # Sigmoid and threshold for multi-label\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Hamming accuracy: proportion of correctly predicted labels over total labels\n",
    "    hamming_accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Standard multi-label precision, recall, and F1 metrics\n",
    "    precision, recall, f1_micro, _ = precision_recall_fscore_support(labels, preds, average='micro', zero_division=0)\n",
    "    _, _, f1_macro, _ = precision_recall_fscore_support(labels, preds, average='macro', zero_division=0)\n",
    "\n",
    "    report = classification_report(\n",
    "        labels, \n",
    "        preds, \n",
    "        labels=label,\n",
    "        target_names=classes,\n",
    "        zero_division=0\n",
    "    ) \n",
    "\n",
    "    return {\n",
    "        'accuracy': hamming_accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'report': report\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f439554a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T10:56:21.981162Z",
     "iopub.status.busy": "2025-03-06T10:56:21.980939Z",
     "iopub.status.idle": "2025-03-06T10:56:21.987188Z",
     "shell.execute_reply": "2025-03-06T10:56:21.986399Z"
    },
    "papermill": {
     "duration": 0.019486,
     "end_time": "2025-03-06T10:56:21.988383",
     "exception": false,
     "start_time": "2025-03-06T10:56:21.968897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics_overall(p, classes):\n",
    "    preds = torch.tensor(p.predictions)\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Ensure it's in the correct shape\n",
    "    if preds.shape != labels.shape:\n",
    "        raise ValueError(\"Shape mismatch: predictions and labels must have the same shape.\")\n",
    "\n",
    "    # Hamming accuracy: proportion of correctly predicted labels over total labels\n",
    "    hamming_accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Compute per-label (column-wise) precision, recall, F1\n",
    "    precision_list, recall_list, f1_micro_list, f1_macro_list = [], [], [], []\n",
    "    \n",
    "    for i in range(labels.shape[1]):  # Loop through each column (multi-output)\n",
    "        prec, rec, f1_micro, _ = precision_recall_fscore_support(\n",
    "            labels[:, i], preds[:, i], average='micro', zero_division=0\n",
    "        )\n",
    "        _, _, f1_macro, _ = precision_recall_fscore_support(\n",
    "            labels[:, i], preds[:, i], average='macro', zero_division=0\n",
    "        )\n",
    "\n",
    "        precision_list.append(prec)\n",
    "        recall_list.append(rec)\n",
    "        f1_micro_list.append(f1_micro)\n",
    "        f1_macro_list.append(f1_macro)\n",
    "\n",
    "    # Compute average metrics across all outputs\n",
    "    precision = sum(precision_list) / len(precision_list)\n",
    "    recall = sum(recall_list) / len(recall_list)\n",
    "    f1_micro = sum(f1_micro_list) / len(f1_micro_list)\n",
    "    f1_macro = sum(f1_macro_list) / len(f1_macro_list)\n",
    "\n",
    "    # Generate classification report per output\n",
    "    reports = [classification_report(labels[:, i], preds[:, i], target_names=classes, zero_division=0) for i in range(labels.shape[1])]\n",
    "\n",
    "    return {\n",
    "        'accuracy': hamming_accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'reports': reports  # Returns list of reports, one for each output label\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "081e0c23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T10:56:22.012395Z",
     "iopub.status.busy": "2025-03-06T10:56:22.012191Z",
     "iopub.status.idle": "2025-03-06T10:56:22.038881Z",
     "shell.execute_reply": "2025-03-06T10:56:22.038070Z"
    },
    "papermill": {
     "duration": 0.04032,
     "end_time": "2025-03-06T10:56:22.040257",
     "exception": false,
     "start_time": "2025-03-06T10:56:21.999937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(current_train_size, train_indices, aspect_metrics, sentiment_metrics, metrics, trials, seed):\n",
    "    accelerator = Accelerator(mixed_precision='fp16')  # Initialize the accelerator\n",
    "    device = accelerator.device\n",
    "\n",
    "    aspect_model = BertForSequenceClassification.from_pretrained(\n",
    "        'indobenchmark/indobert-base-p1',\n",
    "        num_labels=len(train_labels),\n",
    "        problem_type=\"multi_label_classification\"\n",
    "    )\n",
    "\n",
    "    # Freeze the first few layers of the encoder\n",
    "    for name, param in aspect_model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    # Define optimizer and loss function\n",
    "    aspect_optimizer = torch.optim.AdamW(aspect_model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Define DataLoaders\n",
    "    current_X_train = [X_train[i] for i in train_indices]\n",
    "    current_y_train = [y_train[i] for i in train_indices]\n",
    "    aspect_train_loader, aspect_val_loader, aspect_train_dataset, aspect_val_dataset = build_aspect_dataset(current_X_train, current_y_train, X_val, y_val, sequence_length)\n",
    "\n",
    "    # Prepare everything with Accelerator\n",
    "    aspect_model, aspect_optimizer, aspect_train_loader, aspect_val_loader = accelerator.prepare(\n",
    "        aspect_model, aspect_optimizer, aspect_train_loader, aspect_val_loader\n",
    "    )\n",
    "\n",
    "    aspect_result = None\n",
    "    start_time = time.time()\n",
    "\n",
    "    # ASPECT DETECTION\n",
    "    accelerator.print(\"ASPECT DETECTION\")\n",
    "    for epoch in range(epochs):\n",
    "        aspect_model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for batch in aspect_train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels']\n",
    "        \n",
    "            aspect_optimizer.zero_grad()\n",
    "            outputs = aspect_model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            aspect_optimizer.step()\n",
    "        \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "        aspect_model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in aspect_val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "                labels = batch['labels']\n",
    "                \n",
    "                outputs = aspect_model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                # Gather predictions and labels from all devices\n",
    "                all_preds.append(accelerator.gather(preds))\n",
    "                all_labels.append(accelerator.gather(labels))\n",
    "\n",
    "        all_preds = torch.cat(all_preds).cpu().numpy()\n",
    "        all_labels = torch.cat(all_labels).cpu().numpy()\n",
    "\n",
    "        result = compute_metrics(\n",
    "            type('EvalOutput', (object,), {'predictions': all_preds, 'label_ids': all_labels}),\n",
    "            None,\n",
    "            ['fuel', 'machine', 'others', 'part', 'price', 'service']\n",
    "        )\n",
    "\n",
    "        if aspect_result is None or result['f1_micro'] >= aspect_result['f1_micro']:\n",
    "            accelerator.print(\"Higher F1 achieved, saving model\")\n",
    "            \n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(aspect_model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                f'{filename}-aspect-{trials + 1}-model',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "            aspect_result = result\n",
    "\n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(aspect_train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "\n",
    "    accelerator.print(f\"\\nAspect detection accuracy: {round(aspect_result['accuracy'], 4)}, F1 Micro: {round(aspect_result['f1_micro'], 4)}, F1 Macro: {round(aspect_result['f1_macro'], 4)}\")\n",
    "    accelerator.print(aspect_result['report'])\n",
    "\n",
    "    best_aspect_model = BertForSequenceClassification.from_pretrained(f'{filename}-aspect-{trials + 1}-model')\n",
    "    best_aspect_model = accelerator.prepare(best_aspect_model)\n",
    "\n",
    "    # SENTIMENT ANALYSIS ON NON NEUTRAL ASPECTS\n",
    "    accelerator.print(\"--------------------------------------------------\")\n",
    "    accelerator.print(\"SENTIMENT ANALYSIS\")\n",
    "\n",
    "    sentiment_model = BertForSequenceClassification.from_pretrained(\n",
    "        'indobenchmark/indobert-base-p1',\n",
    "        num_labels=2,\n",
    "    )\n",
    "    sentiment_optimizer = torch.optim.AdamW(sentiment_model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "\n",
    "    for name, param in sentiment_model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    sentiment_train_loader, sentiment_val_loader, sentiment_train_dataset, sentiment_val_dataset = build_sentiment_dataset(\n",
    "        device, aspect_train_dataset, aspect_val_dataset, best_aspect_model, tokenizer, max_length=sequence_length\n",
    "    )\n",
    "    sentiment_model, sentiment_optimizer, sentiment_train_loader, sentiment_val_loader = accelerator.prepare(\n",
    "        sentiment_model, sentiment_optimizer, sentiment_train_loader, sentiment_val_loader\n",
    "    )\n",
    "    sentiment_result = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        sentiment_model.train()\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for batch in sentiment_train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels']\n",
    "        \n",
    "            sentiment_optimizer.zero_grad()\n",
    "            outputs = sentiment_model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            sentiment_optimizer.step()\n",
    "        \n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        sentiment_model.eval()\n",
    "        sentiment_val_outputs = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in sentiment_val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "                \n",
    "                outputs = sentiment_model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                for i in range(len(preds)):\n",
    "                    val_output = {\n",
    "                        'label': batch['labels'][i],\n",
    "                        'aspect': batch['aspect'][i],\n",
    "                        'ori_indices': batch['ori_indices'][i],\n",
    "                        'pred': np.argmax(preds[i].cpu().numpy()),\n",
    "                    }\n",
    "                    sentiment_val_outputs.append(val_output)\n",
    "\n",
    "        sentiment_val_outputs = accelerator.gather_for_metrics(sentiment_val_outputs)\n",
    "        unique_val_outputs = {(x['ori_indices'].item(), x['aspect']): x for x in sentiment_val_outputs}\n",
    "        sentiment_val_outputs = list(unique_val_outputs.values())\n",
    "\n",
    "        result = compute_metrics(\n",
    "            type('EvalOutput', (object,), {'predictions': [item['pred'] for item in sentiment_val_outputs], 'label_ids': [np.argmax(item['label'].cpu().numpy()) for item in sentiment_val_outputs]}),\n",
    "            [0, 1],\n",
    "            ['negative', 'positive']\n",
    "        )\n",
    "\n",
    "        if sentiment_result is None or result['f1_micro'] >= sentiment_result['f1_micro']:\n",
    "            accelerator.print(\"Higher F1 achieved, saving model\")\n",
    "            sentiment_result = result\n",
    "            \n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(sentiment_model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                 f'{filename}-sentiment-{trials + 1}-model',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "\n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(sentiment_train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "\n",
    "    accelerator.print(f\"\\nSentiment analysis accuracy: {round(sentiment_result['accuracy'], 4)}, F1 Micro: {round(sentiment_result['f1_micro'], 4)}, F1 Macro: {round(sentiment_result['f1_macro'], 4)}\")\n",
    "    accelerator.print(sentiment_result['report'])\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    best_sentiment_model = BertForSequenceClassification.from_pretrained( f'{filename}-sentiment-{trials + 1}-model')\n",
    "    best_sentiment_model = accelerator.prepare(best_sentiment_model)\n",
    "\n",
    "    # Compute overall metrics\n",
    "    aspect_labels = []\n",
    "    aspect_indices = []\n",
    "    aspect_preds = []\n",
    "\n",
    "    aspect_outputs = {}\n",
    "    sentiment_outputs = []\n",
    "    \n",
    "    best_aspect_model.eval()\n",
    "    best_sentiment_model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in aspect_val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            outputs = aspect_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            aspect_indices.append(accelerator.gather(batch['ori_indices']))\n",
    "            aspect_labels.append(accelerator.gather(batch['ori_label']))\n",
    "            aspect_preds.append(accelerator.gather(preds))\n",
    "\n",
    "        aspect_indices = torch.cat(aspect_indices).cpu().numpy()\n",
    "        aspect_labels = torch.cat(aspect_labels).cpu().numpy()\n",
    "        aspect_preds = torch.cat(aspect_preds).cpu().numpy()\n",
    "\n",
    "        accelerator.wait_for_everyone()\n",
    "        aspect_outputs = [\n",
    "            {'ori_indices': aspect_indices[i], \n",
    "             'ori_labels': aspect_labels[i], \n",
    "             'pred': aspect_preds[i]}\n",
    "            for i in range(len(aspect_preds))\n",
    "        ]\n",
    "        aspect_outputs = {x['ori_indices'].item(): x for x in aspect_outputs}\n",
    "    \n",
    "        for batch in sentiment_val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            outputs = sentiment_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "    \n",
    "            for i in range(len(preds)):\n",
    "                output = {\n",
    "                    'aspect': batch['aspect'][i],\n",
    "                    'ori_indices': batch['ori_indices'][i],\n",
    "                    'pred': np.argmax(preds[i].cpu().numpy()),\n",
    "                }\n",
    "                sentiment_outputs.append(output)\n",
    "\n",
    "        sentiment_outputs = accelerator.gather_for_metrics(sentiment_outputs)\n",
    "        sentiment_outputs = {(x['ori_indices'].item(), x['aspect']): x for x in sentiment_outputs}\n",
    "\n",
    "    # Replcae non neutral aspect to its predicted sentiment\n",
    "    accelerator.wait_for_everyone()\n",
    "    if accelerator.is_main_process:\n",
    "        i = -1\n",
    "        for (ori_index, aspect), value in sentiment_outputs.items():\n",
    "            aspect = aspect_mapping[aspect]\n",
    "            aspect_outputs[ori_index]['pred'][aspect] = 2 if value['pred'] == 1.0 else value['pred']\n",
    "\n",
    "        result = compute_metrics_overall(\n",
    "            type('EvalOutput', (object,), {'predictions': [output['pred'] for output in aspect_outputs.values()], 'label_ids': [output['ori_labels'] for output in aspect_outputs.values()]}),\n",
    "            ['negative', 'neutral', 'positive'],\n",
    "        )\n",
    "\n",
    "        accelerator.print(\"--------------------------------------------------\")\n",
    "        accelerator.print(f\"Iteration {current_train_size}: Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "        accelerator.print(\"--------------------------------------------------\")\n",
    "        for i in range(len(train_labels)):\n",
    "            accelerator.print(f\"Aspect {aspect_list[i]} report:\")\n",
    "            accelerator.print(result['reports'][i])\n",
    "       \n",
    "        \n",
    "        aspect_metrics[0].append(aspect_result['accuracy'])\n",
    "        aspect_metrics[1].append(aspect_result['f1_micro'])\n",
    "        aspect_metrics[2].append(aspect_result['f1_macro'])\n",
    "        sentiment_metrics[0].append(sentiment_result['accuracy'])\n",
    "        sentiment_metrics[1].append(sentiment_result['f1_micro'])\n",
    "        sentiment_metrics[2].append(sentiment_result['f1_macro'])\n",
    "        metrics[0].append(current_train_size)\n",
    "        metrics[1].append(result['accuracy'])\n",
    "        metrics[2].append(result['f1_micro'])\n",
    "        metrics[3].append(result['f1_macro'])\n",
    "        \n",
    "    accelerator.print(f\"Total train time: {duration} s\")\n",
    "    accelerator.end_training()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4671661d",
   "metadata": {
    "papermill": {
     "duration": 0.011281,
     "end_time": "2025-03-06T10:56:22.063360",
     "exception": false,
     "start_time": "2025-03-06T10:56:22.052079",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PLOT THE RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b34c693",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T10:56:22.087200Z",
     "iopub.status.busy": "2025-03-06T10:56:22.086973Z",
     "iopub.status.idle": "2025-03-06T10:56:22.092228Z",
     "shell.execute_reply": "2025-03-06T10:56:22.091436Z"
    },
    "papermill": {
     "duration": 0.018538,
     "end_time": "2025-03-06T10:56:22.093412",
     "exception": false,
     "start_time": "2025-03-06T10:56:22.074874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_result(data_used, accuracies, f1_micros, f1_macros):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(21, 5))\n",
    "    data_used = [round(data / total_data * 100, 1) for data in data_used]\n",
    "\n",
    "    # Plot for Accuracy\n",
    "    axs[0].plot(data_used, accuracies, label=\"Accuracy\", color=\"blue\")\n",
    "    axs[0].set_xlabel(\"Percentage of data used\")\n",
    "    axs[0].set_title(\"Accuracy\")\n",
    "    axs[0].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Micro\n",
    "    axs[1].plot(data_used, f1_micros, label=\"F1 Micro\", color=\"orange\")\n",
    "    axs[1].set_xlabel(\"Percentage of data used\")\n",
    "    axs[1].set_title(\"F1 Micro\")\n",
    "    axs[1].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Macro\n",
    "    axs[2].plot(data_used, f1_macros, label=\"F1 Macro\", color=\"green\")\n",
    "    axs[2].set_xlabel(\"Percentage of data used\")\n",
    "    axs[2].set_title(\"F1 Macro\")\n",
    "    axs[2].set_xticks(data_used)\n",
    "\n",
    "    # Adjust layout and show the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634e80a8",
   "metadata": {
    "papermill": {
     "duration": 0.011456,
     "end_time": "2025-03-06T10:56:22.116615",
     "exception": false,
     "start_time": "2025-03-06T10:56:22.105159",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# QUERY STRATEGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8348e20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T10:56:22.140907Z",
     "iopub.status.busy": "2025-03-06T10:56:22.140652Z",
     "iopub.status.idle": "2025-03-06T10:56:22.156058Z",
     "shell.execute_reply": "2025-03-06T10:56:22.155345Z"
    },
    "papermill": {
     "duration": 0.029072,
     "end_time": "2025-03-06T10:56:22.157301",
     "exception": false,
     "start_time": "2025-03-06T10:56:22.128229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def coreset_sampling(aspect_model, sentiment_model, farthest_point, X_pool, train_indices, remaining_indices, sampling_dur, new_samples, trials, n_samples=min_increment):\n",
    "    accelerator = Accelerator(mixed_precision=\"fp16\")\n",
    "    device = accelerator.device\n",
    "\n",
    "    aspect_model.to(device)\n",
    "    aspect_model.eval()\n",
    "    sentiment_model.to(device)\n",
    "    sentiment_model.eval()\n",
    "\n",
    "    farthest_data = farthest_point.value\n",
    "    if farthest_data is not None:\n",
    "        X_pool.append(farthest_data)\n",
    "        \n",
    "    current_train_size = len(train_indices)\n",
    "    aspect_dataset = AspectDetectionDataset(\n",
    "        X_pool,\n",
    "        [['neutral' for i in range(len(train_labels))] for x in range(len(X_pool))], \n",
    "        label_mapping, \n",
    "        tokenizer, \n",
    "        max_length=sequence_length\n",
    "    )\n",
    "    aspect_loader = DataLoader(\n",
    "        aspect_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    \n",
    "    aspect_outputs = {}\n",
    "    sentiment_outputs = {}\n",
    "\n",
    "    aspects = []\n",
    "    data = []\n",
    "    labels = []\n",
    "    indices = []\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Pass through aspect detction model\n",
    "    for batch in aspect_loader:\n",
    "        token_type_ids = batch['token_type_ids'].to(device, non_blocking=True)\n",
    "        input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "        attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = aspect_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids).logits\n",
    "            embeddings = aspect_model.base_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "\n",
    "        for i in range(len(outputs)):\n",
    "            aspect_outputs[batch['ori_indices'][i].item()] = embeddings.last_hidden_state[i].mean(dim=1).cpu().numpy()\n",
    "            \n",
    "            for j in range(len(outputs[i])):\n",
    "                if int(outputs[i][j].round()) != 1:\n",
    "                    aspects.append(aspect_list[j])\n",
    "                    data.append(batch['ori_text'][i])\n",
    "                    labels.append(batch['ori_label'][i][j])\n",
    "                    indices.append(batch['ori_indices'][i])\n",
    "\n",
    "    if len(data) > 0:\n",
    "        sentiment_dataset = SentimentAnalysisDataset(data, labels, aspects, indices, label_mapping, tokenizer, max_length=sequence_length)\n",
    "        sentiment_loader = torch.utils.data.DataLoader(\n",
    "            sentiment_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4,\n",
    "        )\n",
    "    \n",
    "        # Pass through sentiment analysis model\n",
    "        for batch in sentiment_loader:\n",
    "            token_type_ids = batch['token_type_ids'].to(device, non_blocking=True)\n",
    "            input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "            attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "    \n",
    "            with torch.no_grad():\n",
    "                outputs = sentiment_model.base_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "    \n",
    "            for i in range(len(outputs.last_hidden_state)):\n",
    "                ori_index = batch['ori_indices'][i].item()\n",
    "                if ori_index in sentiment_outputs.keys():\n",
    "                    sentiment_outputs[ori_index].append(outputs.last_hidden_state[i].mean(dim=1).cpu().numpy())\n",
    "                else:\n",
    "                    sentiment_outputs[ori_index] = [outputs.last_hidden_state[i].mean(dim=1).cpu().numpy()]\n",
    "\n",
    "    for key, val in sentiment_outputs.items():\n",
    "        sentiment_outputs[key] = np.mean(val, axis=0)\n",
    "\n",
    "    collected_indices = set()  # Initialize set to store selected indices\n",
    "    thresholds = []\n",
    "\n",
    "    if accelerator.is_main_process:\n",
    "        aspect_outputs = dict(sorted(aspect_outputs.items()))\n",
    "\n",
    "        if len(data) > 0:\n",
    "            for key, val in sentiment_outputs.items():\n",
    "                aspect_outputs[key] = np.mean([val, aspect_outputs[key]], axis=0)\n",
    "\n",
    "        embeddings = np.array(list(aspect_outputs.values()))\n",
    "        distance_matrix = pairwise_distances(embeddings)\n",
    "        selected_indices = distance_matrix.shape[0] - 1 if farthest_data is not None else 0\n",
    "\n",
    "        # Calculate the minimum distance from selected points to all other points\n",
    "        min_distances = distance_matrix[selected_indices]\n",
    "\n",
    "        sorted_dist = np.argsort(min_distances)\n",
    "        sorted_dist = sorted_dist[::-1]\n",
    "        farthest_point.value = aspect_dataset[sorted_dist[0]]['ori_text']\n",
    "\n",
    "        threshold = np.percentile(min_distances, 90)\n",
    "        candidates = np.where(min_distances >= threshold)[0]  # Select the point farthest from the current set\n",
    "        num_of_candidates = len(candidates)\n",
    "    \n",
    "        # Check nearest checkpoint\n",
    "        nearest_cp = 0\n",
    "        arrived_at_cp = False\n",
    "        for cp in checkpoints:\n",
    "            if cp > current_train_size:\n",
    "                nearest_cp = cp\n",
    "                break\n",
    "                \n",
    "        # Determine number of maximum samples to be acquired\n",
    "        if num_of_candidates <= n_samples and n_samples < nearest_cp - current_train_size:\n",
    "            selected_indices = sorted_dist[:n_samples]\n",
    "        elif num_of_candidates > n_samples and num_of_candidates < nearest_cp - current_train_size:\n",
    "             selected_indices = sorted_dist[:max(n_samples, min(math.ceil(0.1*len(sorted_dist)), num_of_candidates))]\n",
    "        else:\n",
    "            selected_indices = sorted_dist[:nearest_cp - current_train_size]\n",
    "            \n",
    "            temp = train_indices.copy()\n",
    "            temp.extend(remaining_indices)\n",
    "            \n",
    "            # Save acquired data up to checkpoint\n",
    "            acquired_data = pd.DataFrame({\n",
    "                'processed_text': [X_train[i] for i in temp],\n",
    "                'fuel': [y_train[i][0] for i in temp],\n",
    "                'machine': [y_train[i][1] for i in temp],\n",
    "                'others': [y_train[i][2] for i in temp],\n",
    "                'part': [y_train[i][3] for i in temp],\n",
    "                'price': [y_train[i][4] for i in temp],\n",
    "                'service': [y_train[i][5] for i in temp],\n",
    "            })\n",
    "            acquired_data.to_csv(f'acquired_data/{filename}-{trials+1}-data-{nearest_cp}.csv', index=False)\n",
    "\n",
    "        end_time = time.time() \n",
    "        duration = end_time - start_time\n",
    "\n",
    "        sampling_dur.append(duration)\n",
    "        for i in selected_indices:\n",
    "            new_samples.append(remaining_indices[i])\n",
    "        \n",
    "        print(\"Nearest checkpoint:\", nearest_cp)\n",
    "        print(\"Threshold:\", threshold)\n",
    "        print(\"Acquired samples:\", len(selected_indices))\n",
    "        print(f\"Sampling duration: {duration} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c52517a",
   "metadata": {
    "papermill": {
     "duration": 0.011278,
     "end_time": "2025-03-06T10:56:22.180580",
     "exception": false,
     "start_time": "2025-03-06T10:56:22.169302",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MAIN LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2ed2bce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T10:56:22.204472Z",
     "iopub.status.busy": "2025-03-06T10:56:22.204266Z",
     "iopub.status.idle": "2025-03-06T10:56:22.212745Z",
     "shell.execute_reply": "2025-03-06T10:56:22.212177Z"
    },
    "papermill": {
     "duration": 0.02176,
     "end_time": "2025-03-06T10:56:22.213865",
     "exception": false,
     "start_time": "2025-03-06T10:56:22.192105",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def active_learning(seed, i):\n",
    "    aspect_accuracies = manager.list()\n",
    "    aspect_f1_micros = manager.list()\n",
    "    aspect_f1_macros = manager.list()\n",
    "    sentiment_accuracies = manager.list()\n",
    "    sentiment_f1_micros = manager.list()\n",
    "    sentiment_f1_macros = manager.list()\n",
    "    accuracies = manager.list()\n",
    "    f1_micros = manager.list()\n",
    "    f1_macros = manager.list()\n",
    "    data_used = manager.list()\n",
    "    sampling_dur = manager.list()\n",
    "    new_samples = manager.list()\n",
    "\n",
    "    set_seed(seed)\n",
    "    \n",
    "    print(\"===============================================\")\n",
    "    print(\"TRIAL {}\".format(i+1))\n",
    "    print(\"Random seed:\", seed)\n",
    "    \n",
    "    train_indices = np.random.choice(range(len(X_train)), initial_train_size, replace=False).tolist()\n",
    "    remaining_indices = list(set(range(len(X_train))) - set(train_indices))\n",
    "    \n",
    "    current_train_size = initial_train_size\n",
    "    \n",
    "    start_time = time.time()\n",
    "    # for i in range(1):\n",
    "    while current_train_size < checkpoints[len(checkpoints) - 1]:\n",
    "        # Train the model\n",
    "        args = (\n",
    "            current_train_size, \n",
    "            train_indices, \n",
    "            (aspect_accuracies, aspect_f1_micros, aspect_f1_macros), \n",
    "            (sentiment_accuracies, sentiment_f1_micros, sentiment_f1_macros),\n",
    "            (data_used, accuracies, f1_micros, f1_macros), \n",
    "            i,\n",
    "            seed\n",
    "        )\n",
    "        notebook_launcher(train_model, args, num_processes=2)\n",
    "\n",
    "        aspect_model = BertForSequenceClassification.from_pretrained(f'{filename}-aspect-{i+1}-model')\n",
    "        sentiment_model = BertForSequenceClassification.from_pretrained(f'{filename}-sentiment-{i+1}-model')\n",
    "    \n",
    "        # Perform query strategy to select new samples\n",
    "        new_samples = manager.list()\n",
    "        sampling_args = (\n",
    "            aspect_model, \n",
    "            sentiment_model, \n",
    "            farthest_point,\n",
    "            [X_train[i] for i in remaining_indices], \n",
    "            train_indices, \n",
    "            remaining_indices, \n",
    "            sampling_dur, \n",
    "            new_samples, \n",
    "            i\n",
    "        )\n",
    "        notebook_launcher(coreset_sampling, sampling_args, num_processes=2)\n",
    "        new_samples = list(new_samples)\n",
    "        train_indices.extend(new_samples)\n",
    "        remaining_indices = list(set(remaining_indices) - set(new_samples))\n",
    "    \n",
    "        # Update current training size\n",
    "        current_train_size = len(train_indices)\n",
    "        print(\"New train size: {}\".format(current_train_size))\n",
    "    \n",
    "    # Train last epoch\n",
    "    args = (\n",
    "        current_train_size, \n",
    "        train_indices, \n",
    "        (aspect_accuracies, aspect_f1_micros, aspect_f1_macros), \n",
    "        (sentiment_accuracies, sentiment_f1_micros, sentiment_f1_macros),\n",
    "        (data_used, accuracies, f1_micros, f1_macros), \n",
    "        i,\n",
    "        seed\n",
    "    )\n",
    "    notebook_launcher(train_model, args, num_processes=2)\n",
    "    data_used, accuracies, f1_micros, f1_macros, sampling_dur = list(data_used), list(accuracies), list(f1_micros), list(f1_macros), list(sampling_dur)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    # print(f\"Total sampling time: {np.array(sampling_dur).sum().round(2)} seconds\")\n",
    "    print(f\"Total runtime: {duration} seconds\")\n",
    "    \n",
    "    plot_result(data_used, accuracies, f1_micros, f1_macros)\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        'Data Used': data_used,\n",
    "        'Aspect Accuracy': aspect_accuracies,\n",
    "        'Aspect F1 Micro': aspect_f1_micros,\n",
    "        'Aspect F1 Macro': aspect_f1_macros,\n",
    "        'Sentiment Accuracy': sentiment_accuracies,\n",
    "        'Sentiment F1 Micro': sentiment_f1_micros,\n",
    "        'Sentiment F1 Macro': sentiment_f1_macros,\n",
    "        'Accuracy': accuracies,\n",
    "        'F1 Micro': f1_micros,\n",
    "        'F1 Macro': f1_macros,\n",
    "    })\n",
    "    \n",
    "    sampling_dur.insert(0, 0)\n",
    "    results['Sampling Duration'] = sampling_dur\n",
    "    results.to_csv(f'results/{filename}-{i+1}-results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7a68ab1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T10:56:22.237578Z",
     "iopub.status.busy": "2025-03-06T10:56:22.237350Z",
     "iopub.status.idle": "2025-03-06T10:56:22.240520Z",
     "shell.execute_reply": "2025-03-06T10:56:22.239723Z"
    },
    "papermill": {
     "duration": 0.016463,
     "end_time": "2025-03-06T10:56:22.241711",
     "exception": false,
     "start_time": "2025-03-06T10:56:22.225248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seeds = [50, 81, 14, 3, 94]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a31f15e",
   "metadata": {
    "papermill": {
     "duration": 0.011241,
     "end_time": "2025-03-06T10:56:22.264439",
     "exception": false,
     "start_time": "2025-03-06T10:56:22.253198",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2fcc490c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T10:56:22.288112Z",
     "iopub.status.busy": "2025-03-06T10:56:22.287826Z",
     "iopub.status.idle": "2025-03-06T11:42:49.502961Z",
     "shell.execute_reply": "2025-03-06T11:42:49.502158Z"
    },
    "papermill": {
     "duration": 2787.228594,
     "end_time": "2025-03-06T11:42:49.504466",
     "exception": false,
     "start_time": "2025-03-06T10:56:22.275872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 1\n",
      "Random seed: 50\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6756, Accuracy: 0.7731, F1 Micro: 0.8711, F1 Macro: 0.8698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5958, Accuracy: 0.7887, F1 Micro: 0.8819, F1 Macro: 0.8804\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5785, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.513, Accuracy: 0.7939, F1 Micro: 0.8843, F1 Macro: 0.8828\n",
      "Epoch 5/10, Train Loss: 0.5006, Accuracy: 0.7924, F1 Micro: 0.8829, F1 Macro: 0.881\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4695, Accuracy: 0.7954, F1 Micro: 0.8846, F1 Macro: 0.8828\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4328, Accuracy: 0.7969, F1 Micro: 0.8857, F1 Macro: 0.8842\n",
      "Epoch 8/10, Train Loss: 0.4369, Accuracy: 0.7932, F1 Micro: 0.8832, F1 Macro: 0.8812\n",
      "Epoch 9/10, Train Loss: 0.415, Accuracy: 0.7917, F1 Micro: 0.8816, F1 Macro: 0.8789\n",
      "Epoch 10/10, Train Loss: 0.3884, Accuracy: 0.7894, F1 Micro: 0.88, F1 Macro: 0.8769\n",
      "\n",
      "Aspect detection accuracy: 0.7969, F1 Micro: 0.8857, F1 Macro: 0.8842\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.78      1.00      0.88       175\n",
      "      others       0.71      1.00      0.83       158\n",
      "        part       0.75      0.98      0.85       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.80      1.00      0.89      1061\n",
      "   macro avg       0.80      1.00      0.88      1061\n",
      "weighted avg       0.80      1.00      0.89      1061\n",
      " samples avg       0.80      1.00      0.88      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7162, Accuracy: 0.2857, F1 Micro: 0.2857, F1 Macro: 0.2222\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.6764, Accuracy: 0.5, F1 Micro: 0.5, F1 Macro: 0.4974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.6621, Accuracy: 0.7143, F1 Micro: 0.7143, F1 Macro: 0.65\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.6053, Accuracy: 0.7857, F1 Micro: 0.7857, F1 Macro: 0.7143\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.5803, Accuracy: 0.7857, F1 Micro: 0.7857, F1 Macro: 0.7143\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.5674, Accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.825\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4789, Accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.825\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4895, Accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.825\n",
      "Epoch 9/10, Train Loss: 0.4054, Accuracy: 0.7143, F1 Micro: 0.7143, F1 Macro: 0.6889\n",
      "Epoch 10/10, Train Loss: 0.3482, Accuracy: 0.5, F1 Micro: 0.5, F1 Macro: 0.4974\n",
      "\n",
      "Sentiment analysis accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.825\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75         4\n",
      "    positive       0.90      0.90      0.90        10\n",
      "\n",
      "    accuracy                           0.86        14\n",
      "   macro avg       0.82      0.82      0.82        14\n",
      "weighted avg       0.86      0.86      0.86        14\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.7793, F1 Micro: 0.7793, F1 Macro: 0.3103\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.77      1.00      0.87       167\n",
      "    positive       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.77       216\n",
      "   macro avg       0.26      0.33      0.29       216\n",
      "weighted avg       0.60      0.77      0.67       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.70      1.00      0.83       152\n",
      "    positive       0.00      0.00      0.00        52\n",
      "\n",
      "    accuracy                           0.70       216\n",
      "   macro avg       0.23      0.33      0.28       216\n",
      "weighted avg       0.50      0.70      0.58       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.16      0.26      0.20        23\n",
      "     neutral       0.75      0.86      0.80       152\n",
      "    positive       0.60      0.07      0.13        41\n",
      "\n",
      "    accuracy                           0.64       216\n",
      "   macro avg       0.50      0.40      0.38       216\n",
      "weighted avg       0.66      0.64      0.61       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 52.2697639465332 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.004588124807924032\n",
      "Acquired samples: 82\n",
      "Sampling duration: 9.30966305732727 seconds\n",
      "New train size: 136\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6434, Accuracy: 0.7894, F1 Micro: 0.8822, F1 Macro: 0.8808\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5617, Accuracy: 0.8013, F1 Micro: 0.8877, F1 Macro: 0.8861\n",
      "Epoch 3/10, Train Loss: 0.5271, Accuracy: 0.7939, F1 Micro: 0.8844, F1 Macro: 0.8829\n",
      "Epoch 4/10, Train Loss: 0.4906, Accuracy: 0.7954, F1 Micro: 0.8851, F1 Macro: 0.8835\n",
      "Epoch 5/10, Train Loss: 0.457, Accuracy: 0.7991, F1 Micro: 0.8859, F1 Macro: 0.884\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4262, Accuracy: 0.8028, F1 Micro: 0.8885, F1 Macro: 0.887\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4069, Accuracy: 0.8222, F1 Micro: 0.8968, F1 Macro: 0.8948\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3631, Accuracy: 0.8385, F1 Micro: 0.9053, F1 Macro: 0.9032\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3127, Accuracy: 0.8661, F1 Micro: 0.9204, F1 Macro: 0.9184\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2772, Accuracy: 0.8854, F1 Micro: 0.9296, F1 Macro: 0.9257\n",
      "\n",
      "Aspect detection accuracy: 0.8854, F1 Micro: 0.9296, F1 Macro: 0.9257\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.94      1.00      0.97       187\n",
      "     machine       0.88      0.95      0.91       175\n",
      "      others       0.88      0.82      0.85       158\n",
      "        part       0.84      0.97      0.90       158\n",
      "       price       0.91      0.99      0.95       192\n",
      "     service       0.95      0.99      0.97       191\n",
      "\n",
      "   micro avg       0.90      0.96      0.93      1061\n",
      "   macro avg       0.90      0.95      0.93      1061\n",
      "weighted avg       0.90      0.96      0.93      1061\n",
      " samples avg       0.91      0.95      0.92      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5818, Accuracy: 0.7381, F1 Micro: 0.7381, F1 Macro: 0.4247\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4505, Accuracy: 0.7381, F1 Micro: 0.7381, F1 Macro: 0.4247\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3807, Accuracy: 0.7571, F1 Micro: 0.7571, F1 Macro: 0.5109\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2778, Accuracy: 0.9, F1 Micro: 0.9, F1 Macro: 0.8683\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2564, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9157\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1753, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9175\n",
      "Epoch 7/10, Train Loss: 0.1665, Accuracy: 0.9143, F1 Micro: 0.9143, F1 Macro: 0.897\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1042, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9127\n",
      "Epoch 9/10, Train Loss: 0.1483, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9121\n",
      "Epoch 10/10, Train Loss: 0.0922, Accuracy: 0.9238, F1 Micro: 0.9238, F1 Macro: 0.9076\n",
      "\n",
      "Sentiment analysis accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9127\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87        55\n",
      "    positive       0.95      0.96      0.96       155\n",
      "\n",
      "    accuracy                           0.93       210\n",
      "   macro avg       0.92      0.91      0.91       210\n",
      "weighted avg       0.93      0.93      0.93       210\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 136: Accuracy: 0.8735, F1 Micro: 0.8735, F1 Macro: 0.7403\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.64      0.78        11\n",
      "     neutral       0.94      1.00      0.97       181\n",
      "    positive       1.00      0.67      0.80        24\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.98      0.77      0.85       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.44      0.58        16\n",
      "     neutral       0.88      0.95      0.91       167\n",
      "    positive       0.67      0.55      0.60        33\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.81      0.65      0.70       216\n",
      "weighted avg       0.85      0.85      0.84       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.44      0.67      0.53        12\n",
      "     neutral       0.88      0.81      0.85       152\n",
      "    positive       0.54      0.62      0.58        52\n",
      "\n",
      "    accuracy                           0.75       216\n",
      "   macro avg       0.62      0.70      0.65       216\n",
      "weighted avg       0.78      0.75      0.76       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.61      0.74        23\n",
      "     neutral       0.83      0.97      0.89       152\n",
      "    positive       0.79      0.46      0.58        41\n",
      "\n",
      "    accuracy                           0.83       216\n",
      "   macro avg       0.85      0.68      0.74       216\n",
      "weighted avg       0.83      0.83      0.82       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.38      0.56        13\n",
      "     neutral       0.91      0.99      0.95       186\n",
      "    positive       0.88      0.41      0.56        17\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.93      0.60      0.69       216\n",
      "weighted avg       0.91      0.91      0.90       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.86      0.86        14\n",
      "     neutral       0.95      0.99      0.97       185\n",
      "    positive       0.89      0.47      0.62        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.77      0.82       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Total train time: 67.46385335922241 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.00895455088466406\n",
      "Acquired samples: 73\n",
      "Sampling duration: 14.068538188934326 seconds\n",
      "New train size: 209\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6182, Accuracy: 0.7924, F1 Micro: 0.8837, F1 Macro: 0.8822\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.54, Accuracy: 0.7946, F1 Micro: 0.8849, F1 Macro: 0.8834\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4892, Accuracy: 0.7969, F1 Micro: 0.886, F1 Macro: 0.8846\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.463, Accuracy: 0.8103, F1 Micro: 0.8917, F1 Macro: 0.8905\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4277, Accuracy: 0.8341, F1 Micro: 0.9044, F1 Macro: 0.9035\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.368, Accuracy: 0.8839, F1 Micro: 0.9309, F1 Macro: 0.9299\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3155, Accuracy: 0.9115, F1 Micro: 0.9458, F1 Macro: 0.9439\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2558, Accuracy: 0.9256, F1 Micro: 0.9539, F1 Macro: 0.9518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2104, Accuracy: 0.9278, F1 Micro: 0.9553, F1 Macro: 0.953\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1803, Accuracy: 0.9382, F1 Micro: 0.9613, F1 Macro: 0.9586\n",
      "\n",
      "Aspect detection accuracy: 0.9382, F1 Micro: 0.9613, F1 Macro: 0.9586\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.97      0.96       175\n",
      "      others       0.90      0.92      0.91       158\n",
      "        part       0.93      0.92      0.93       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       0.97      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.95      0.97      0.96      1061\n",
      "   macro avg       0.95      0.97      0.96      1061\n",
      "weighted avg       0.95      0.97      0.96      1061\n",
      " samples avg       0.95      0.97      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.616, Accuracy: 0.6929, F1 Micro: 0.6929, F1 Macro: 0.4093\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5164, Accuracy: 0.748, F1 Micro: 0.748, F1 Macro: 0.6816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4152, Accuracy: 0.7598, F1 Micro: 0.7598, F1 Macro: 0.7489\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2975, Accuracy: 0.878, F1 Micro: 0.878, F1 Macro: 0.8591\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3045, Accuracy: 0.8819, F1 Micro: 0.8819, F1 Macro: 0.8681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2265, Accuracy: 0.8819, F1 Micro: 0.8819, F1 Macro: 0.8622\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2087, Accuracy: 0.8858, F1 Micro: 0.8858, F1 Macro: 0.8663\n",
      "Epoch 8/10, Train Loss: 0.0846, Accuracy: 0.8701, F1 Micro: 0.8701, F1 Macro: 0.8562\n",
      "Epoch 9/10, Train Loss: 0.1622, Accuracy: 0.874, F1 Micro: 0.874, F1 Macro: 0.853\n",
      "Epoch 10/10, Train Loss: 0.162, Accuracy: 0.8543, F1 Micro: 0.8543, F1 Macro: 0.8434\n",
      "\n",
      "Sentiment analysis accuracy: 0.8858, F1 Micro: 0.8858, F1 Macro: 0.8663\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.82      0.82        78\n",
      "    positive       0.92      0.91      0.92       176\n",
      "\n",
      "    accuracy                           0.89       254\n",
      "   macro avg       0.87      0.87      0.87       254\n",
      "weighted avg       0.89      0.89      0.89       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 209: Accuracy: 0.9174, F1 Micro: 0.9174, F1 Macro: 0.8386\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.94      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.81      0.79        16\n",
      "     neutral       0.95      0.96      0.96       167\n",
      "    positive       0.79      0.70      0.74        33\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.83      0.82      0.83       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.42      0.67      0.52        12\n",
      "     neutral       0.90      0.91      0.91       152\n",
      "    positive       0.71      0.58      0.64        52\n",
      "\n",
      "    accuracy                           0.82       216\n",
      "   macro avg       0.68      0.72      0.69       216\n",
      "weighted avg       0.83      0.82      0.82       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.53      0.83      0.64        23\n",
      "     neutral       0.93      0.92      0.92       152\n",
      "    positive       0.86      0.61      0.71        41\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.77      0.79      0.76       216\n",
      "weighted avg       0.87      0.85      0.85       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.97      1.00      0.99       186\n",
      "    positive       0.92      0.65      0.76        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.86      0.89       216\n",
      "weighted avg       0.97      0.97      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.97      1.00      0.98       185\n",
      "    positive       1.00      0.65      0.79        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.97      0.86      0.90       216\n",
      "weighted avg       0.97      0.97      0.96       216\n",
      "\n",
      "Total train time: 81.4779360294342 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.006665317807346582\n",
      "Acquired samples: 66\n",
      "Sampling duration: 16.95132541656494 seconds\n",
      "New train size: 275\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6038, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5153, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4942, Accuracy: 0.7969, F1 Micro: 0.8859, F1 Macro: 0.8844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4571, Accuracy: 0.8244, F1 Micro: 0.8984, F1 Macro: 0.8967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3741, Accuracy: 0.8921, F1 Micro: 0.9347, F1 Macro: 0.933\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2996, Accuracy: 0.9196, F1 Micro: 0.95, F1 Macro: 0.9471\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2424, Accuracy: 0.9256, F1 Micro: 0.9537, F1 Macro: 0.9509\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1985, Accuracy: 0.9278, F1 Micro: 0.9552, F1 Macro: 0.9525\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1614, Accuracy: 0.9375, F1 Micro: 0.9607, F1 Macro: 0.9577\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1346, Accuracy: 0.9472, F1 Micro: 0.9671, F1 Macro: 0.9653\n",
      "\n",
      "Aspect detection accuracy: 0.9472, F1 Micro: 0.9671, F1 Macro: 0.9653\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.93      0.99      0.96       175\n",
      "      others       0.90      0.94      0.92       158\n",
      "        part       0.96      0.96      0.96       158\n",
      "       price       0.97      1.00      0.98       192\n",
      "     service       0.97      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.95      0.98      0.97      1061\n",
      "   macro avg       0.95      0.98      0.97      1061\n",
      "weighted avg       0.95      0.98      0.97      1061\n",
      " samples avg       0.95      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.572, Accuracy: 0.6777, F1 Micro: 0.6777, F1 Macro: 0.4039\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4231, Accuracy: 0.8554, F1 Micro: 0.8554, F1 Macro: 0.8316\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.25, Accuracy: 0.8926, F1 Micro: 0.8926, F1 Macro: 0.8839\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1845, Accuracy: 0.8967, F1 Micro: 0.8967, F1 Macro: 0.8881\n",
      "Epoch 5/10, Train Loss: 0.2062, Accuracy: 0.8926, F1 Micro: 0.8926, F1 Macro: 0.8808\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1158, Accuracy: 0.9008, F1 Micro: 0.9008, F1 Macro: 0.8918\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1324, Accuracy: 0.9008, F1 Micro: 0.9008, F1 Macro: 0.8918\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1019, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8979\n",
      "Epoch 9/10, Train Loss: 0.0765, Accuracy: 0.9008, F1 Micro: 0.9008, F1 Macro: 0.8887\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1066, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8997\n",
      "\n",
      "Sentiment analysis accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.94      0.87        78\n",
      "    positive       0.97      0.90      0.93       164\n",
      "\n",
      "    accuracy                           0.91       242\n",
      "   macro avg       0.89      0.92      0.90       242\n",
      "weighted avg       0.92      0.91      0.91       242\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 275: Accuracy: 0.9352, F1 Micro: 0.9352, F1 Macro: 0.87\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.69      0.73        16\n",
      "     neutral       0.93      0.99      0.96       167\n",
      "    positive       0.92      0.67      0.77        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.88      0.78      0.82       216\n",
      "weighted avg       0.91      0.92      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.75      0.72        12\n",
      "     neutral       0.90      0.93      0.92       152\n",
      "    positive       0.78      0.67      0.72        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.79      0.79      0.79       216\n",
      "weighted avg       0.86      0.86      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.87      0.77        23\n",
      "     neutral       0.95      0.95      0.95       152\n",
      "    positive       0.91      0.78      0.84        41\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.85      0.87      0.86       216\n",
      "weighted avg       0.92      0.91      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.97      1.00      0.98       186\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.83      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.97      1.00      0.98       185\n",
      "    positive       1.00      0.71      0.83        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.99      0.88      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 87.4738392829895 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.006366878328844905\n",
      "Acquired samples: 59\n",
      "Sampling duration: 14.912194013595581 seconds\n",
      "New train size: 334\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5845, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Epoch 2/10, Train Loss: 0.5161, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4739, Accuracy: 0.8095, F1 Micro: 0.8921, F1 Macro: 0.8909\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4056, Accuracy: 0.8847, F1 Micro: 0.931, F1 Macro: 0.9296\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3137, Accuracy: 0.9271, F1 Micro: 0.9553, F1 Macro: 0.9538\n",
      "Epoch 6/10, Train Loss: 0.2466, Accuracy: 0.9211, F1 Micro: 0.9506, F1 Macro: 0.9463\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1982, Accuracy: 0.9487, F1 Micro: 0.9681, F1 Macro: 0.9665\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1457, Accuracy: 0.9554, F1 Micro: 0.9722, F1 Macro: 0.9709\n",
      "Epoch 9/10, Train Loss: 0.1256, Accuracy: 0.9546, F1 Micro: 0.9717, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1026, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.972\n",
      "\n",
      "Aspect detection accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.972\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.91      0.93      0.92       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.97      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.563, Accuracy: 0.6786, F1 Micro: 0.6786, F1 Macro: 0.4043\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4059, Accuracy: 0.8849, F1 Micro: 0.8849, F1 Macro: 0.8649\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2422, Accuracy: 0.8968, F1 Micro: 0.8968, F1 Macro: 0.8882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1934, Accuracy: 0.8968, F1 Micro: 0.8968, F1 Macro: 0.8846\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.164, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8947\n",
      "Epoch 6/10, Train Loss: 0.1463, Accuracy: 0.8929, F1 Micro: 0.8929, F1 Macro: 0.8842\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1209, Accuracy: 0.9127, F1 Micro: 0.9127, F1 Macro: 0.9012\n",
      "Epoch 8/10, Train Loss: 0.0887, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8929\n",
      "Epoch 9/10, Train Loss: 0.1195, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8947\n",
      "Epoch 10/10, Train Loss: 0.0825, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.9009\n",
      "\n",
      "Sentiment analysis accuracy: 0.9127, F1 Micro: 0.9127, F1 Macro: 0.9012\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.89      0.87        81\n",
      "    positive       0.95      0.92      0.93       171\n",
      "\n",
      "    accuracy                           0.91       252\n",
      "   macro avg       0.90      0.91      0.90       252\n",
      "weighted avg       0.91      0.91      0.91       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 334: Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.8791\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.93      0.82      0.87        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.56      0.75      0.64        12\n",
      "     neutral       0.91      0.93      0.92       152\n",
      "    positive       0.76      0.65      0.70        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.74      0.78      0.75       216\n",
      "weighted avg       0.85      0.85      0.85       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.96      0.83        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.73      0.83        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.89      0.88       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.88      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.86      0.86        14\n",
      "     neutral       0.97      1.00      0.98       185\n",
      "    positive       1.00      0.65      0.79        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.83      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Total train time: 82.61223006248474 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0031618166249245405\n",
      "Acquired samples: 54\n",
      "Sampling duration: 13.699331283569336 seconds\n",
      "New train size: 388\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5699, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5004, Accuracy: 0.7939, F1 Micro: 0.8845, F1 Macro: 0.8831\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4453, Accuracy: 0.8259, F1 Micro: 0.9004, F1 Macro: 0.8993\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3519, Accuracy: 0.9211, F1 Micro: 0.9513, F1 Macro: 0.9495\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.27, Accuracy: 0.9338, F1 Micro: 0.9588, F1 Macro: 0.9563\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2068, Accuracy: 0.9472, F1 Micro: 0.967, F1 Macro: 0.9654\n",
      "Epoch 7/10, Train Loss: 0.1557, Accuracy: 0.9464, F1 Micro: 0.9663, F1 Macro: 0.9634\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1251, Accuracy: 0.9561, F1 Micro: 0.9724, F1 Macro: 0.9707\n",
      "Epoch 9/10, Train Loss: 0.1036, Accuracy: 0.9524, F1 Micro: 0.9701, F1 Macro: 0.9678\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0871, Accuracy: 0.9568, F1 Micro: 0.9728, F1 Macro: 0.9711\n",
      "\n",
      "Aspect detection accuracy: 0.9568, F1 Micro: 0.9728, F1 Macro: 0.9711\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.94      0.89      0.92       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.97      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5983, Accuracy: 0.678, F1 Micro: 0.678, F1 Macro: 0.4041\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.377, Accuracy: 0.8712, F1 Micro: 0.8712, F1 Macro: 0.8621\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2137, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9193\n",
      "Epoch 4/10, Train Loss: 0.1491, Accuracy: 0.9015, F1 Micro: 0.9015, F1 Macro: 0.8931\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1439, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9241\n",
      "Epoch 6/10, Train Loss: 0.1307, Accuracy: 0.9205, F1 Micro: 0.9205, F1 Macro: 0.908\n",
      "Epoch 7/10, Train Loss: 0.1227, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.9087\n",
      "Epoch 8/10, Train Loss: 0.1217, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.9048\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1125, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9326\n",
      "Epoch 10/10, Train Loss: 0.0894, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9237\n",
      "\n",
      "Sentiment analysis accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9326\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.98      0.91        84\n",
      "    positive       0.99      0.92      0.95       180\n",
      "\n",
      "    accuracy                           0.94       264\n",
      "   macro avg       0.92      0.95      0.93       264\n",
      "weighted avg       0.95      0.94      0.94       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 388: Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.8921\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.88      0.82        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.92      0.70      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.85      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.83      0.74        12\n",
      "     neutral       0.94      0.89      0.92       152\n",
      "    positive       0.74      0.81      0.77        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.78      0.85      0.81       216\n",
      "weighted avg       0.88      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.95      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.87      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89        14\n",
      "     neutral       0.97      1.00      0.98       185\n",
      "    positive       1.00      0.71      0.83        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.96      0.85      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 89.37252831459045 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.003674876969307661\n",
      "Acquired samples: 48\n",
      "Sampling duration: 12.23208236694336 seconds\n",
      "New train size: 436\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5738, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5003, Accuracy: 0.7946, F1 Micro: 0.8849, F1 Macro: 0.8834\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4353, Accuracy: 0.8609, F1 Micro: 0.9182, F1 Macro: 0.9173\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3324, Accuracy: 0.9323, F1 Micro: 0.9582, F1 Macro: 0.9564\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2532, Accuracy: 0.9509, F1 Micro: 0.9693, F1 Macro: 0.9678\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1766, Accuracy: 0.9561, F1 Micro: 0.9726, F1 Macro: 0.9711\n",
      "Epoch 7/10, Train Loss: 0.1467, Accuracy: 0.9554, F1 Micro: 0.972, F1 Macro: 0.9701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1244, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.094, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9752\n",
      "Epoch 10/10, Train Loss: 0.0807, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9752\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.94      0.92      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5625, Accuracy: 0.7954, F1 Micro: 0.7954, F1 Macro: 0.7292\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3453, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9244\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2539, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9304\n",
      "Epoch 4/10, Train Loss: 0.15, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9253\n",
      "Epoch 5/10, Train Loss: 0.1523, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9207\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1289, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9304\n",
      "Epoch 7/10, Train Loss: 0.1586, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9266\n",
      "Epoch 8/10, Train Loss: 0.1368, Accuracy: 0.888, F1 Micro: 0.888, F1 Macro: 0.8792\n",
      "Epoch 9/10, Train Loss: 0.09, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9225\n",
      "Epoch 10/10, Train Loss: 0.0617, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9176\n",
      "\n",
      "Sentiment analysis accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9304\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.95      0.91        82\n",
      "    positive       0.98      0.93      0.95       177\n",
      "\n",
      "    accuracy                           0.94       259\n",
      "   macro avg       0.92      0.94      0.93       259\n",
      "weighted avg       0.94      0.94      0.94       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 436: Accuracy: 0.9483, F1 Micro: 0.9483, F1 Macro: 0.8915\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.88      0.80        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.92      0.70      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.85      0.85       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.56      0.75      0.64        12\n",
      "     neutral       0.94      0.91      0.93       152\n",
      "    positive       0.77      0.77      0.77        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.76      0.81      0.78       216\n",
      "weighted avg       0.88      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.96      0.86        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.92      0.91       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.79      0.85        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.89      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 92.48314595222473 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.003985429648309946\n",
      "Acquired samples: 43\n",
      "Sampling duration: 11.003655672073364 seconds\n",
      "New train size: 479\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5747, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4994, Accuracy: 0.7946, F1 Micro: 0.8849, F1 Macro: 0.8834\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4344, Accuracy: 0.881, F1 Micro: 0.9296, F1 Macro: 0.9282\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3215, Accuracy: 0.9375, F1 Micro: 0.9611, F1 Macro: 0.9588\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.235, Accuracy: 0.9546, F1 Micro: 0.9716, F1 Macro: 0.9699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1669, Accuracy: 0.9583, F1 Micro: 0.974, F1 Macro: 0.9723\n",
      "Epoch 7/10, Train Loss: 0.1264, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1089, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9745\n",
      "Epoch 9/10, Train Loss: 0.0925, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0778, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9746\n",
      "\n",
      "Aspect detection accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9746\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.94      0.92      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.57, Accuracy: 0.7893, F1 Micro: 0.7893, F1 Macro: 0.7138\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3453, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9269\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2002, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9273\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2222, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9247\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2008, Accuracy: 0.9425, F1 Micro: 0.9425, F1 Macro: 0.9348\n",
      "Epoch 6/10, Train Loss: 0.1458, Accuracy: 0.9195, F1 Micro: 0.9195, F1 Macro: 0.9044\n",
      "Epoch 7/10, Train Loss: 0.1182, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9281\n",
      "Epoch 8/10, Train Loss: 0.1107, Accuracy: 0.9387, F1 Micro: 0.9387, F1 Macro: 0.9306\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1059, Accuracy: 0.9425, F1 Micro: 0.9425, F1 Macro: 0.9352\n",
      "Epoch 10/10, Train Loss: 0.0793, Accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.9077\n",
      "\n",
      "Sentiment analysis accuracy: 0.9425, F1 Micro: 0.9425, F1 Macro: 0.9352\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.94      0.91        84\n",
      "    positive       0.97      0.94      0.96       177\n",
      "\n",
      "    accuracy                           0.94       261\n",
      "   macro avg       0.93      0.94      0.94       261\n",
      "weighted avg       0.94      0.94      0.94       261\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 479: Accuracy: 0.9475, F1 Micro: 0.9475, F1 Macro: 0.8904\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.91      0.88      0.89        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.81      0.79        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.84      0.86       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.83      0.71        12\n",
      "     neutral       0.94      0.92      0.93       152\n",
      "    positive       0.76      0.75      0.76        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.78      0.83      0.80       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.76      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.91      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.89      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 97.29606127738953 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.003367098863236606\n",
      "Acquired samples: 39\n",
      "Sampling duration: 10.402583122253418 seconds\n",
      "New train size: 518\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5499, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4911, Accuracy: 0.8192, F1 Micro: 0.897, F1 Macro: 0.8967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3914, Accuracy: 0.9167, F1 Micro: 0.9493, F1 Macro: 0.9478\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2805, Accuracy: 0.9524, F1 Micro: 0.9703, F1 Macro: 0.9689\n",
      "Epoch 5/10, Train Loss: 0.1958, Accuracy: 0.9516, F1 Micro: 0.9697, F1 Macro: 0.9683\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1558, Accuracy: 0.9561, F1 Micro: 0.9723, F1 Macro: 0.9699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.12, Accuracy: 0.9591, F1 Micro: 0.9741, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0942, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9761\n",
      "Epoch 9/10, Train Loss: 0.0815, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.975\n",
      "Epoch 10/10, Train Loss: 0.0701, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.973\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9761\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5325, Accuracy: 0.8294, F1 Micro: 0.8294, F1 Macro: 0.7782\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2601, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.9018\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2297, Accuracy: 0.9524, F1 Micro: 0.9524, F1 Macro: 0.9467\n",
      "Epoch 4/10, Train Loss: 0.1374, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.9099\n",
      "Epoch 5/10, Train Loss: 0.1379, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9343\n",
      "Epoch 6/10, Train Loss: 0.1062, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9343\n",
      "Epoch 7/10, Train Loss: 0.1042, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8878\n",
      "Epoch 8/10, Train Loss: 0.1086, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9332\n",
      "Epoch 9/10, Train Loss: 0.0947, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9264\n",
      "Epoch 10/10, Train Loss: 0.0629, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.8993\n",
      "\n",
      "Sentiment analysis accuracy: 0.9524, F1 Micro: 0.9524, F1 Macro: 0.9467\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93        83\n",
      "    positive       0.98      0.95      0.96       169\n",
      "\n",
      "    accuracy                           0.95       252\n",
      "   macro avg       0.94      0.95      0.95       252\n",
      "weighted avg       0.95      0.95      0.95       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 518: Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.8623\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.75      0.73        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.88      0.70      0.78        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.85      0.81      0.82       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.41      0.75      0.53        12\n",
      "     neutral       0.94      0.91      0.92       152\n",
      "    positive       0.85      0.77      0.81        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.73      0.81      0.75       216\n",
      "weighted avg       0.89      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.96      0.86        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.94      0.78      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.91      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.77      0.74        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.80      0.71      0.75        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.83      0.82      0.83       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.93      0.90        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 93.99321126937866 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.004608967062085868\n",
      "Acquired samples: 22\n",
      "Sampling duration: 9.312098979949951 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5603, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4787, Accuracy: 0.8088, F1 Micro: 0.8919, F1 Macro: 0.8908\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3917, Accuracy: 0.9152, F1 Micro: 0.9478, F1 Macro: 0.9459\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2852, Accuracy: 0.936, F1 Micro: 0.9599, F1 Macro: 0.958\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2012, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9713\n",
      "Epoch 6/10, Train Loss: 0.1488, Accuracy: 0.9546, F1 Micro: 0.9715, F1 Macro: 0.9695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.122, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9738\n",
      "Epoch 8/10, Train Loss: 0.0976, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9728\n",
      "Epoch 9/10, Train Loss: 0.0814, Accuracy: 0.9554, F1 Micro: 0.9718, F1 Macro: 0.9696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.071, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9765\n",
      "\n",
      "Aspect detection accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.93      0.95      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5011, Accuracy: 0.888, F1 Micro: 0.888, F1 Macro: 0.8702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2445, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.8993\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2037, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9189\n",
      "Epoch 4/10, Train Loss: 0.1625, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9153\n",
      "Epoch 5/10, Train Loss: 0.153, Accuracy: 0.9112, F1 Micro: 0.9112, F1 Macro: 0.9028\n",
      "Epoch 6/10, Train Loss: 0.1439, Accuracy: 0.8996, F1 Micro: 0.8996, F1 Macro: 0.8915\n",
      "Epoch 7/10, Train Loss: 0.137, Accuracy: 0.8996, F1 Micro: 0.8996, F1 Macro: 0.8915\n",
      "Epoch 8/10, Train Loss: 0.0903, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.8989\n",
      "Epoch 9/10, Train Loss: 0.0947, Accuracy: 0.8764, F1 Micro: 0.8764, F1 Macro: 0.8687\n",
      "Epoch 10/10, Train Loss: 0.0915, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.9068\n",
      "\n",
      "Sentiment analysis accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9189\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.96      0.89        83\n",
      "    positive       0.98      0.91      0.94       176\n",
      "\n",
      "    accuracy                           0.93       259\n",
      "   macro avg       0.91      0.94      0.92       259\n",
      "weighted avg       0.93      0.93      0.93       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.8902\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.88      0.70      0.78        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.83      0.85       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.75      0.69        12\n",
      "     neutral       0.93      0.95      0.94       152\n",
      "    positive       0.83      0.75      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.80      0.82      0.81       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 96.96726655960083 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.004187841434031725\n",
      "Acquired samples: 33\n",
      "Sampling duration: 8.856455564498901 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5479, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4701, Accuracy: 0.8311, F1 Micro: 0.9031, F1 Macro: 0.9023\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3713, Accuracy: 0.9308, F1 Micro: 0.9574, F1 Macro: 0.9557\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2557, Accuracy: 0.9539, F1 Micro: 0.9713, F1 Macro: 0.9699\n",
      "Epoch 5/10, Train Loss: 0.1855, Accuracy: 0.9494, F1 Micro: 0.968, F1 Macro: 0.965\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1453, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1156, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0931, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.076, Accuracy: 0.9613, F1 Micro: 0.9755, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0636, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9762\n",
      "\n",
      "Aspect detection accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.93      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5133, Accuracy: 0.8977, F1 Micro: 0.8977, F1 Macro: 0.8776\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2894, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9168\n",
      "Epoch 3/10, Train Loss: 0.2023, Accuracy: 0.9242, F1 Micro: 0.9242, F1 Macro: 0.9162\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1531, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9322\n",
      "Epoch 5/10, Train Loss: 0.1083, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.9004\n",
      "Epoch 6/10, Train Loss: 0.1103, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9241\n",
      "Epoch 7/10, Train Loss: 0.1214, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.9004\n",
      "Epoch 8/10, Train Loss: 0.0869, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9173\n",
      "Epoch 9/10, Train Loss: 0.0927, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9229\n",
      "Epoch 10/10, Train Loss: 0.0842, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9197\n",
      "\n",
      "Sentiment analysis accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9322\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.96      0.91        84\n",
      "    positive       0.98      0.93      0.95       180\n",
      "\n",
      "    accuracy                           0.94       264\n",
      "   macro avg       0.92      0.95      0.93       264\n",
      "weighted avg       0.94      0.94      0.94       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.8994\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.81      0.81      0.81        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.83      0.83      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.93      0.90        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 103.78465986251831 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.0038413401460275056\n",
      "Acquired samples: 30\n",
      "Sampling duration: 7.945376634597778 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5433, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4723, Accuracy: 0.817, F1 Micro: 0.8959, F1 Macro: 0.8949\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.36, Accuracy: 0.9412, F1 Micro: 0.9636, F1 Macro: 0.9619\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2425, Accuracy: 0.9554, F1 Micro: 0.9721, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1817, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9765\n",
      "Epoch 6/10, Train Loss: 0.1317, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9753\n",
      "Epoch 7/10, Train Loss: 0.1034, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0865, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9781\n",
      "Epoch 9/10, Train Loss: 0.0703, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9767\n",
      "Epoch 10/10, Train Loss: 0.0601, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9758\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.91      0.97      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.52, Accuracy: 0.874, F1 Micro: 0.874, F1 Macro: 0.8449\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2286, Accuracy: 0.8898, F1 Micro: 0.8898, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1692, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.9063\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1497, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9144\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1378, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9179\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1114, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9204\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.083, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9327\n",
      "Epoch 8/10, Train Loss: 0.0924, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9308\n",
      "Epoch 9/10, Train Loss: 0.0574, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9147\n",
      "Epoch 10/10, Train Loss: 0.0567, Accuracy: 0.9055, F1 Micro: 0.9055, F1 Macro: 0.8973\n",
      "\n",
      "Sentiment analysis accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9327\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.90      0.91        83\n",
      "    positive       0.95      0.96      0.96       171\n",
      "\n",
      "    accuracy                           0.94       254\n",
      "   macro avg       0.93      0.93      0.93       254\n",
      "weighted avg       0.94      0.94      0.94       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9437, F1 Micro: 0.9437, F1 Macro: 0.8747\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.83      0.73      0.77        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.86      0.84      0.85       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.32      0.83      0.47        12\n",
      "     neutral       0.94      0.90      0.92       152\n",
      "    positive       0.90      0.69      0.78        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.72      0.81      0.72       216\n",
      "weighted avg       0.90      0.85      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.93      0.87        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.92      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 107.6780698299408 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.00330640256870538\n",
      "Acquired samples: 27\n",
      "Sampling duration: 7.440347194671631 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5596, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4745, Accuracy: 0.8192, F1 Micro: 0.897, F1 Macro: 0.8956\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3462, Accuracy: 0.939, F1 Micro: 0.9624, F1 Macro: 0.9607\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2413, Accuracy: 0.9546, F1 Micro: 0.9718, F1 Macro: 0.9703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1749, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9754\n",
      "Epoch 6/10, Train Loss: 0.1273, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1007, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9777\n",
      "Epoch 8/10, Train Loss: 0.0854, Accuracy: 0.965, F1 Micro: 0.9778, F1 Macro: 0.9759\n",
      "Epoch 9/10, Train Loss: 0.0708, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9748\n",
      "Epoch 10/10, Train Loss: 0.0603, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9774\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9777\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5054, Accuracy: 0.8803, F1 Micro: 0.8803, F1 Macro: 0.854\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2502, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9193\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.181, Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9484\n",
      "Epoch 4/10, Train Loss: 0.1414, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9401\n",
      "Epoch 5/10, Train Loss: 0.1146, Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9439\n",
      "Epoch 6/10, Train Loss: 0.1057, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9391\n",
      "Epoch 7/10, Train Loss: 0.096, Accuracy: 0.9112, F1 Micro: 0.9112, F1 Macro: 0.9042\n",
      "Epoch 8/10, Train Loss: 0.0883, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.936\n",
      "Epoch 9/10, Train Loss: 0.0698, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9274\n",
      "Epoch 10/10, Train Loss: 0.045, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9398\n",
      "\n",
      "Sentiment analysis accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9484\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.93        84\n",
      "    positive       0.99      0.94      0.96       175\n",
      "\n",
      "    accuracy                           0.95       259\n",
      "   macro avg       0.94      0.96      0.95       259\n",
      "weighted avg       0.96      0.95      0.95       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9099\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.88      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.59      0.83      0.69        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.83      0.77      0.80        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.79      0.84      0.81       216\n",
      "weighted avg       0.89      0.88      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 103.36269044876099 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.0046526392921805385\n",
      "Acquired samples: 18\n",
      "Sampling duration: 6.616932153701782 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5367, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4643, Accuracy: 0.8542, F1 Micro: 0.9149, F1 Macro: 0.9145\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3323, Accuracy: 0.942, F1 Micro: 0.964, F1 Macro: 0.9625\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2287, Accuracy: 0.9598, F1 Micro: 0.975, F1 Macro: 0.9738\n",
      "Epoch 5/10, Train Loss: 0.1603, Accuracy: 0.9539, F1 Micro: 0.971, F1 Macro: 0.9686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1199, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0974, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0773, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9766\n",
      "Epoch 9/10, Train Loss: 0.0631, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0536, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9792\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9792\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.95      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5411, Accuracy: 0.8943, F1 Micro: 0.8943, F1 Macro: 0.8772\n",
      "Epoch 2/10, Train Loss: 0.2852, Accuracy: 0.8906, F1 Micro: 0.8906, F1 Macro: 0.8829\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1842, Accuracy: 0.8981, F1 Micro: 0.8981, F1 Macro: 0.89\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1607, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9327\n",
      "Epoch 5/10, Train Loss: 0.1384, Accuracy: 0.9321, F1 Micro: 0.9321, F1 Macro: 0.923\n",
      "Epoch 6/10, Train Loss: 0.1162, Accuracy: 0.9358, F1 Micro: 0.9358, F1 Macro: 0.9275\n",
      "Epoch 7/10, Train Loss: 0.0872, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.9175\n",
      "Epoch 8/10, Train Loss: 0.0752, Accuracy: 0.9358, F1 Micro: 0.9358, F1 Macro: 0.9271\n",
      "Epoch 9/10, Train Loss: 0.0703, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.9194\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.043, Accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.9356\n",
      "\n",
      "Sentiment analysis accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.9356\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.93      0.91        85\n",
      "    positive       0.97      0.95      0.96       180\n",
      "\n",
      "    accuracy                           0.94       265\n",
      "   macro avg       0.93      0.94      0.94       265\n",
      "weighted avg       0.94      0.94      0.94       265\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9192\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.69      0.76        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.81      0.79      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.82      0.84       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.75      0.86        12\n",
      "     neutral       0.94      0.95      0.94       152\n",
      "    positive       0.83      0.85      0.84        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.92      0.85      0.88       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.95      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 112.60372495651245 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.003136814711615443\n",
      "Acquired samples: 25\n",
      "Sampling duration: 6.228323221206665 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5358, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4465, Accuracy: 0.8527, F1 Micro: 0.9144, F1 Macro: 0.9144\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3254, Accuracy: 0.9397, F1 Micro: 0.9626, F1 Macro: 0.9608\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2088, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1509, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9748\n",
      "Epoch 6/10, Train Loss: 0.1157, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9743\n",
      "Epoch 7/10, Train Loss: 0.0925, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9734\n",
      "Epoch 8/10, Train Loss: 0.0777, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0607, Accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9783\n",
      "Epoch 10/10, Train Loss: 0.0535, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.978\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9783\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4997, Accuracy: 0.902, F1 Micro: 0.902, F1 Macro: 0.8929\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2537, Accuracy: 0.9059, F1 Micro: 0.9059, F1 Macro: 0.8892\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.204, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9154\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.146, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9272\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1462, Accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.9435\n",
      "Epoch 6/10, Train Loss: 0.1292, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9252\n",
      "Epoch 7/10, Train Loss: 0.1048, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9231\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0668, Accuracy: 0.9569, F1 Micro: 0.9569, F1 Macro: 0.9507\n",
      "Epoch 9/10, Train Loss: 0.0659, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9141\n",
      "Epoch 10/10, Train Loss: 0.0676, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9313\n",
      "\n",
      "Sentiment analysis accuracy: 0.9569, F1 Micro: 0.9569, F1 Macro: 0.9507\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.91      0.93        85\n",
      "    positive       0.95      0.98      0.97       170\n",
      "\n",
      "    accuracy                           0.96       255\n",
      "   macro avg       0.96      0.94      0.95       255\n",
      "weighted avg       0.96      0.96      0.96       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.8984\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.97      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.88      0.80        16\n",
      "     neutral       0.97      0.98      0.97       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.87      0.88      0.87       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.75      0.72        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.85      0.75      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.82      0.82      0.82       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      1.00      0.82        23\n",
      "     neutral       0.98      0.97      0.97       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.92      0.89       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 112.17779493331909 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.0031768945045769215\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.694297790527344 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5265, Accuracy: 0.7939, F1 Micro: 0.8845, F1 Macro: 0.8831\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.431, Accuracy: 0.8943, F1 Micro: 0.9364, F1 Macro: 0.9356\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2967, Accuracy: 0.9531, F1 Micro: 0.9708, F1 Macro: 0.9695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1986, Accuracy: 0.9598, F1 Micro: 0.975, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1408, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1167, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0884, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.977\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0749, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9771\n",
      "Epoch 9/10, Train Loss: 0.0604, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9771\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0557, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9778\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.95      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5311, Accuracy: 0.9, F1 Micro: 0.9, F1 Macro: 0.889\n",
      "Epoch 2/10, Train Loss: 0.2516, Accuracy: 0.8846, F1 Micro: 0.8846, F1 Macro: 0.8767\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1785, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9167\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1801, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.928\n",
      "Epoch 5/10, Train Loss: 0.1565, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9159\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1123, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.928\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.133, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.928\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.088, Accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.944\n",
      "Epoch 9/10, Train Loss: 0.072, Accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9402\n",
      "Epoch 10/10, Train Loss: 0.0688, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.932\n",
      "\n",
      "Sentiment analysis accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.944\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.96      0.93        84\n",
      "    positive       0.98      0.94      0.96       176\n",
      "\n",
      "    accuracy                           0.95       260\n",
      "   macro avg       0.94      0.95      0.94       260\n",
      "weighted avg       0.95      0.95      0.95       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9104\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.85      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.84      0.79      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.86      0.83      0.84       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.95      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 118.39890170097351 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.00341047877445817\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.083825349807739 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5405, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4294, Accuracy: 0.9234, F1 Micro: 0.9532, F1 Macro: 0.9522\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2881, Accuracy: 0.9509, F1 Micro: 0.9694, F1 Macro: 0.9676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.198, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1396, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1068, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "Epoch 7/10, Train Loss: 0.0863, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0696, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.977\n",
      "Epoch 9/10, Train Loss: 0.0597, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0505, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9778\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.95      0.92      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5255, Accuracy: 0.9044, F1 Micro: 0.9044, F1 Macro: 0.8958\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.219, Accuracy: 0.9265, F1 Micro: 0.9265, F1 Macro: 0.916\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1512, Accuracy: 0.9301, F1 Micro: 0.9301, F1 Macro: 0.9226\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1276, Accuracy: 0.9338, F1 Micro: 0.9338, F1 Macro: 0.9265\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.113, Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9449\n",
      "Epoch 6/10, Train Loss: 0.0871, Accuracy: 0.9485, F1 Micro: 0.9485, F1 Macro: 0.9419\n",
      "Epoch 7/10, Train Loss: 0.0671, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9343\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0567, Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9459\n",
      "Epoch 9/10, Train Loss: 0.0535, Accuracy: 0.9265, F1 Micro: 0.9265, F1 Macro: 0.9187\n",
      "Epoch 10/10, Train Loss: 0.076, Accuracy: 0.9265, F1 Micro: 0.9265, F1 Macro: 0.9187\n",
      "\n",
      "Sentiment analysis accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9459\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.93        87\n",
      "    positive       0.98      0.95      0.96       185\n",
      "\n",
      "    accuracy                           0.95       272\n",
      "   macro avg       0.94      0.95      0.95       272\n",
      "weighted avg       0.95      0.95      0.95       272\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9121\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.86      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.95      0.92      0.94       152\n",
      "    positive       0.76      0.81      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.81      0.85      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 119.00112819671631 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.0031994540244340897\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.403445482254028 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5308, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4261, Accuracy: 0.9263, F1 Micro: 0.9544, F1 Macro: 0.9524\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2807, Accuracy: 0.9531, F1 Micro: 0.9708, F1 Macro: 0.9694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1897, Accuracy: 0.9621, F1 Micro: 0.9764, F1 Macro: 0.9753\n",
      "Epoch 5/10, Train Loss: 0.1383, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1001, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9763\n",
      "Epoch 7/10, Train Loss: 0.0875, Accuracy: 0.9613, F1 Micro: 0.9755, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.069, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0572, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0509, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9779\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9779\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.93      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4749, Accuracy: 0.9071, F1 Micro: 0.9071, F1 Macro: 0.8985\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2211, Accuracy: 0.9071, F1 Micro: 0.9071, F1 Macro: 0.8876\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1807, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.932\n",
      "Epoch 4/10, Train Loss: 0.147, Accuracy: 0.9257, F1 Micro: 0.9257, F1 Macro: 0.9178\n",
      "Epoch 5/10, Train Loss: 0.1343, Accuracy: 0.9368, F1 Micro: 0.9368, F1 Macro: 0.9271\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0945, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9328\n",
      "Epoch 7/10, Train Loss: 0.0893, Accuracy: 0.9257, F1 Micro: 0.9257, F1 Macro: 0.9178\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0602, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9332\n",
      "Epoch 9/10, Train Loss: 0.0501, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9244\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0561, Accuracy: 0.948, F1 Micro: 0.948, F1 Macro: 0.9416\n",
      "\n",
      "Sentiment analysis accuracy: 0.948, F1 Micro: 0.948, F1 Macro: 0.9416\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.97      0.92        86\n",
      "    positive       0.98      0.94      0.96       183\n",
      "\n",
      "    accuracy                           0.95       269\n",
      "   macro avg       0.93      0.95      0.94       269\n",
      "weighted avg       0.95      0.95      0.95       269\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9259\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.78      0.81      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.87      0.86      0.86       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 121.59778547286987 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.0046424539759755135\n",
      "Acquired samples: 8\n",
      "Sampling duration: 3.7835707664489746 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5318, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.42, Accuracy: 0.9196, F1 Micro: 0.9511, F1 Macro: 0.9498\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2727, Accuracy: 0.9494, F1 Micro: 0.9686, F1 Macro: 0.967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1882, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1394, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.977\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1055, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9784\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0869, Accuracy: 0.9717, F1 Micro: 0.9822, F1 Macro: 0.9813\n",
      "Epoch 8/10, Train Loss: 0.0681, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9742\n",
      "Epoch 9/10, Train Loss: 0.0553, Accuracy: 0.9658, F1 Micro: 0.9783, F1 Macro: 0.9766\n",
      "Epoch 10/10, Train Loss: 0.0506, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9781\n",
      "\n",
      "Aspect detection accuracy: 0.9717, F1 Micro: 0.9822, F1 Macro: 0.9813\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.94      0.96      0.95       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5306, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9262\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2324, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9322\n",
      "Epoch 3/10, Train Loss: 0.1905, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9262\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1359, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9353\n",
      "Epoch 5/10, Train Loss: 0.133, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9229\n",
      "Epoch 6/10, Train Loss: 0.1112, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9157\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0854, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9401\n",
      "Epoch 8/10, Train Loss: 0.0859, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.936\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0605, Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9481\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0589, Accuracy: 0.9575, F1 Micro: 0.9575, F1 Macro: 0.9523\n",
      "\n",
      "Sentiment analysis accuracy: 0.9575, F1 Micro: 0.9575, F1 Macro: 0.9523\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.95      0.94        85\n",
      "    positive       0.98      0.96      0.97       174\n",
      "\n",
      "    accuracy                           0.96       259\n",
      "   macro avg       0.95      0.96      0.95       259\n",
      "weighted avg       0.96      0.96      0.96       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9172\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.97      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.86      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.83      0.74        12\n",
      "     neutral       0.94      0.93      0.93       152\n",
      "    positive       0.86      0.85      0.85        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.82      0.87      0.84       216\n",
      "weighted avg       0.91      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 119.5754599571228 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.002753984648734331\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.565967321395874 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5311, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4151, Accuracy: 0.9249, F1 Micro: 0.9542, F1 Macro: 0.953\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2706, Accuracy: 0.9524, F1 Micro: 0.9703, F1 Macro: 0.9685\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1741, Accuracy: 0.9554, F1 Micro: 0.9719, F1 Macro: 0.97\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1264, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9782\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1016, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9787\n",
      "Epoch 7/10, Train Loss: 0.0798, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9757\n",
      "Epoch 8/10, Train Loss: 0.0657, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9747\n",
      "Epoch 9/10, Train Loss: 0.0538, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9781\n",
      "Epoch 10/10, Train Loss: 0.0482, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9779\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9787\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.93      0.94      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5174, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9272\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2205, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9358\n",
      "Epoch 3/10, Train Loss: 0.1504, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9239\n",
      "Epoch 4/10, Train Loss: 0.1316, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9268\n",
      "Epoch 5/10, Train Loss: 0.1304, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9084\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1074, Accuracy: 0.9577, F1 Micro: 0.9577, F1 Macro: 0.9524\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0751, Accuracy: 0.9577, F1 Micro: 0.9577, F1 Macro: 0.9524\n",
      "Epoch 8/10, Train Loss: 0.064, Accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9399\n",
      "Epoch 9/10, Train Loss: 0.0658, Accuracy: 0.9538, F1 Micro: 0.9538, F1 Macro: 0.9476\n",
      "Epoch 10/10, Train Loss: 0.0452, Accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.9427\n",
      "\n",
      "Sentiment analysis accuracy: 0.9577, F1 Micro: 0.9577, F1 Macro: 0.9524\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        84\n",
      "    positive       0.98      0.95      0.97       176\n",
      "\n",
      "    accuracy                           0.96       260\n",
      "   macro avg       0.95      0.96      0.95       260\n",
      "weighted avg       0.96      0.96      0.96       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9043\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.96      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.75      0.73        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.85      0.83      0.84       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.75      0.72        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.81      0.81      0.81        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.81      0.83      0.82       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.97      0.88      0.92        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.95      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 118.5713005065918 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0030179068446159365\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.9283440113067627 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5316, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4155, Accuracy: 0.9211, F1 Micro: 0.9519, F1 Macro: 0.9509\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2665, Accuracy: 0.9509, F1 Micro: 0.9696, F1 Macro: 0.968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1776, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9755\n",
      "Epoch 5/10, Train Loss: 0.1233, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9747\n",
      "Epoch 6/10, Train Loss: 0.0951, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0802, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "Epoch 8/10, Train Loss: 0.0656, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0557, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9779\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0464, Accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9794\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9794\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.93      0.95      0.94       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.99      1.00      1.00       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4716, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9104\n",
      "Epoch 2/10, Train Loss: 0.2554, Accuracy: 0.8955, F1 Micro: 0.8955, F1 Macro: 0.8869\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2155, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9367\n",
      "Epoch 4/10, Train Loss: 0.1457, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9319\n",
      "Epoch 5/10, Train Loss: 0.1015, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9255\n",
      "Epoch 6/10, Train Loss: 0.1382, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9334\n",
      "Epoch 7/10, Train Loss: 0.0904, Accuracy: 0.9179, F1 Micro: 0.9179, F1 Macro: 0.9027\n",
      "Epoch 8/10, Train Loss: 0.0691, Accuracy: 0.9179, F1 Micro: 0.9179, F1 Macro: 0.9085\n",
      "Epoch 9/10, Train Loss: 0.0486, Accuracy: 0.9254, F1 Micro: 0.9254, F1 Macro: 0.9159\n",
      "Epoch 10/10, Train Loss: 0.0495, Accuracy: 0.9104, F1 Micro: 0.9104, F1 Macro: 0.9017\n",
      "\n",
      "Sentiment analysis accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9367\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.95      0.92        85\n",
      "    positive       0.98      0.94      0.96       183\n",
      "\n",
      "    accuracy                           0.94       268\n",
      "   macro avg       0.93      0.95      0.94       268\n",
      "weighted avg       0.95      0.94      0.94       268\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9021\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.88      0.82        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.87      0.87      0.87       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.75      0.69        12\n",
      "     neutral       0.93      0.95      0.94       152\n",
      "    positive       0.85      0.77      0.81        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.81      0.82      0.81       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      1.00      0.85        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.94      0.78      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.92      0.89       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      1.00      1.00       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.92      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 120.18345165252686 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0027790669817477466\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.3430373668670654 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.532, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4177, Accuracy: 0.9196, F1 Micro: 0.9512, F1 Macro: 0.9498\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2664, Accuracy: 0.9501, F1 Micro: 0.969, F1 Macro: 0.9675\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.178, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1275, Accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9784\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1025, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9789\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0815, Accuracy: 0.9717, F1 Micro: 0.9822, F1 Macro: 0.9813\n",
      "Epoch 8/10, Train Loss: 0.0631, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9772\n",
      "Epoch 9/10, Train Loss: 0.0543, Accuracy: 0.9702, F1 Micro: 0.9812, F1 Macro: 0.9799\n",
      "Epoch 10/10, Train Loss: 0.0471, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9791\n",
      "\n",
      "Aspect detection accuracy: 0.9717, F1 Micro: 0.9822, F1 Macro: 0.9813\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.93      0.97      0.95       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4841, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.9077\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2501, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9194\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1582, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9234\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1446, Accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9388\n",
      "Epoch 5/10, Train Loss: 0.1289, Accuracy: 0.9416, F1 Micro: 0.9416, F1 Macro: 0.935\n",
      "Epoch 6/10, Train Loss: 0.1171, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9251\n",
      "Epoch 7/10, Train Loss: 0.0892, Accuracy: 0.9183, F1 Micro: 0.9183, F1 Macro: 0.9113\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0785, Accuracy: 0.9494, F1 Micro: 0.9494, F1 Macro: 0.9434\n",
      "Epoch 9/10, Train Loss: 0.0747, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9246\n",
      "Epoch 10/10, Train Loss: 0.0841, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9186\n",
      "\n",
      "Sentiment analysis accuracy: 0.9494, F1 Micro: 0.9494, F1 Macro: 0.9434\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.94      0.92        85\n",
      "    positive       0.97      0.95      0.96       172\n",
      "\n",
      "    accuracy                           0.95       257\n",
      "   macro avg       0.94      0.95      0.94       257\n",
      "weighted avg       0.95      0.95      0.95       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9061\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.88      0.78        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.86      0.86      0.85       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.48      0.83      0.61        12\n",
      "     neutral       0.95      0.93      0.94       152\n",
      "    positive       0.89      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.77      0.85      0.79       216\n",
      "weighted avg       0.91      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.96      0.85        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.91      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 124.87427163124084 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0029140385100618004\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.731963872909546 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.53, Accuracy: 0.8006, F1 Micro: 0.8879, F1 Macro: 0.8865\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.396, Accuracy: 0.9375, F1 Micro: 0.9614, F1 Macro: 0.96\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2483, Accuracy: 0.9524, F1 Micro: 0.9704, F1 Macro: 0.9691\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.168, Accuracy: 0.9643, F1 Micro: 0.9777, F1 Macro: 0.9768\n",
      "Epoch 5/10, Train Loss: 0.1284, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.094, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.978\n",
      "Epoch 7/10, Train Loss: 0.0774, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9745\n",
      "Epoch 8/10, Train Loss: 0.064, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0525, Accuracy: 0.9732, F1 Micro: 0.9831, F1 Macro: 0.9822\n",
      "Epoch 10/10, Train Loss: 0.0457, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9783\n",
      "\n",
      "Aspect detection accuracy: 0.9732, F1 Micro: 0.9831, F1 Macro: 0.9822\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.93      0.97      0.95       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.98      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.98      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4724, Accuracy: 0.9278, F1 Micro: 0.9278, F1 Macro: 0.9186\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2238, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9288\n",
      "Epoch 3/10, Train Loss: 0.1677, Accuracy: 0.9278, F1 Micro: 0.9278, F1 Macro: 0.9208\n",
      "Epoch 4/10, Train Loss: 0.1451, Accuracy: 0.9011, F1 Micro: 0.9011, F1 Macro: 0.8938\n",
      "Epoch 5/10, Train Loss: 0.1292, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.8998\n",
      "Epoch 6/10, Train Loss: 0.096, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9168\n",
      "Epoch 7/10, Train Loss: 0.0757, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9164\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0596, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9313\n",
      "Epoch 9/10, Train Loss: 0.052, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9164\n",
      "Epoch 10/10, Train Loss: 0.0569, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.916\n",
      "\n",
      "Sentiment analysis accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9313\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.92      0.91        86\n",
      "    positive       0.96      0.95      0.95       177\n",
      "\n",
      "    accuracy                           0.94       263\n",
      "   macro avg       0.93      0.93      0.93       263\n",
      "weighted avg       0.94      0.94      0.94       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9052\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.81      0.79        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.87      0.86      0.86       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.48      0.83      0.61        12\n",
      "     neutral       0.94      0.93      0.93       152\n",
      "    positive       0.89      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.77      0.84      0.79       216\n",
      "weighted avg       0.90      0.88      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 123.70094108581543 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0017317894846200943\n",
      "Acquired samples: 8\n",
      "Sampling duration: 1.0780596733093262 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5303, Accuracy: 0.8058, F1 Micro: 0.8905, F1 Macro: 0.8893\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3796, Accuracy: 0.9234, F1 Micro: 0.9527, F1 Macro: 0.9507\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2411, Accuracy: 0.9576, F1 Micro: 0.9737, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1627, Accuracy: 0.9665, F1 Micro: 0.9791, F1 Macro: 0.9783\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1203, Accuracy: 0.9695, F1 Micro: 0.9809, F1 Macro: 0.98\n",
      "Epoch 6/10, Train Loss: 0.0981, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.979\n",
      "Epoch 7/10, Train Loss: 0.0738, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9775\n",
      "Epoch 8/10, Train Loss: 0.0626, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9759\n",
      "Epoch 9/10, Train Loss: 0.0529, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9772\n",
      "Epoch 10/10, Train Loss: 0.0454, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9784\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9809, F1 Macro: 0.98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.93      0.97      0.95       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4927, Accuracy: 0.8906, F1 Micro: 0.8906, F1 Macro: 0.8843\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.244, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9397\n",
      "Epoch 3/10, Train Loss: 0.1756, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9352\n",
      "Epoch 4/10, Train Loss: 0.1364, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9352\n",
      "Epoch 5/10, Train Loss: 0.123, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9274\n",
      "Epoch 6/10, Train Loss: 0.0921, Accuracy: 0.9258, F1 Micro: 0.9258, F1 Macro: 0.9196\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.083, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9397\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0456, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9397\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.057, Accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9439\n",
      "Epoch 10/10, Train Loss: 0.0848, Accuracy: 0.9219, F1 Micro: 0.9219, F1 Macro: 0.9152\n",
      "\n",
      "Sentiment analysis accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9439\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.93        86\n",
      "    positive       0.98      0.95      0.96       170\n",
      "\n",
      "    accuracy                           0.95       256\n",
      "   macro avg       0.94      0.95      0.94       256\n",
      "weighted avg       0.95      0.95      0.95       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.8857\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.88      0.72        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.92      0.67      0.77        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.83      0.84      0.82       216\n",
      "weighted avg       0.93      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.83      0.62        12\n",
      "     neutral       0.95      0.93      0.94       152\n",
      "    positive       0.87      0.79      0.83        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.77      0.85      0.80       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.92      0.83        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.87      0.89      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 124.4943118095398 s\n",
      "Total runtime: 2786.345229625702 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[0], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb463314",
   "metadata": {
    "papermill": {
     "duration": 0.146824,
     "end_time": "2025-03-06T11:42:49.800621",
     "exception": false,
     "start_time": "2025-03-06T11:42:49.653797",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a24330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 2\n",
      "Random seed: 81\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.647, Accuracy: 0.7054, F1 Micro: 0.8127, F1 Macro: 0.7262\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5731, Accuracy: 0.7374, F1 Micro: 0.8408, F1 Macro: 0.7949\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5493, Accuracy: 0.7917, F1 Micro: 0.8824, F1 Macro: 0.8802\n",
      "Epoch 4/10, Train Loss: 0.5049, Accuracy: 0.7894, F1 Micro: 0.8822, F1 Macro: 0.8807\n",
      "Epoch 5/10, Train Loss: 0.4781, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 6/10, Train Loss: 0.4364, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4061, Accuracy: 0.7902, F1 Micro: 0.8826, F1 Macro: 0.8811\n",
      "Epoch 8/10, Train Loss: 0.4421, Accuracy: 0.7902, F1 Micro: 0.8825, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.4208, Accuracy: 0.7939, F1 Micro: 0.8842, F1 Macro: 0.8826\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3864, Accuracy: 0.8036, F1 Micro: 0.8886, F1 Macro: 0.8869\n",
      "\n",
      "Aspect detection accuracy: 0.8036, F1 Micro: 0.8886, F1 Macro: 0.8869\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.79      1.00      0.88       175\n",
      "      others       0.78      0.95      0.86       158\n",
      "        part       0.71      1.00      0.83       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.80      0.99      0.89      1061\n",
      "   macro avg       0.80      0.99      0.89      1061\n",
      "weighted avg       0.81      0.99      0.89      1061\n",
      " samples avg       0.81      0.99      0.89      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6351, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5577, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5004, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4905, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4593, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4341, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4188, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2323, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2613, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2353, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "\n",
      "Sentiment analysis accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         3\n",
      "    positive       0.91      1.00      0.95        31\n",
      "\n",
      "    accuracy                           0.91        34\n",
      "   macro avg       0.46      0.50      0.48        34\n",
      "weighted avg       0.83      0.91      0.87        34\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.8009, F1 Micro: 0.8009, F1 Macro: 0.3313\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.78      1.00      0.88       167\n",
      "    positive       1.00      0.06      0.11        33\n",
      "\n",
      "    accuracy                           0.78       216\n",
      "   macro avg       0.59      0.35      0.33       216\n",
      "weighted avg       0.76      0.78      0.70       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.78      0.95      0.85       152\n",
      "    positive       0.65      0.38      0.48        52\n",
      "\n",
      "    accuracy                           0.76       216\n",
      "   macro avg       0.47      0.44      0.45       216\n",
      "weighted avg       0.70      0.76      0.72       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        23\n",
      "     neutral       0.71      1.00      0.83       152\n",
      "    positive       1.00      0.02      0.05        41\n",
      "\n",
      "    accuracy                           0.71       216\n",
      "   macro avg       0.57      0.34      0.29       216\n",
      "weighted avg       0.69      0.71      0.59       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 57.82589054107666 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.004997514188289642\n",
      "Acquired samples: 82\n",
      "Sampling duration: 12.602189540863037 seconds\n",
      "New train size: 136\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6211, Accuracy: 0.7924, F1 Micro: 0.8824, F1 Macro: 0.8801\n",
      "Epoch 2/10, Train Loss: 0.5161, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 3/10, Train Loss: 0.4789, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4471, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4156, Accuracy: 0.8021, F1 Micro: 0.8885, F1 Macro: 0.887\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4074, Accuracy: 0.8452, F1 Micro: 0.9096, F1 Macro: 0.9082\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3404, Accuracy: 0.8772, F1 Micro: 0.926, F1 Macro: 0.9243\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2852, Accuracy: 0.8899, F1 Micro: 0.933, F1 Macro: 0.9312\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.255, Accuracy: 0.8988, F1 Micro: 0.9377, F1 Macro: 0.9357\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2226, Accuracy: 0.9062, F1 Micro: 0.9425, F1 Macro: 0.9404\n",
      "\n",
      "Aspect detection accuracy: 0.9062, F1 Micro: 0.9425, F1 Macro: 0.9404\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.97      1.00      0.99       187\n",
      "     machine       0.93      0.97      0.95       175\n",
      "      others       0.86      0.93      0.89       158\n",
      "        part       0.86      0.94      0.90       158\n",
      "       price       0.94      0.98      0.96       192\n",
      "     service       0.91      1.00      0.95       191\n",
      "\n",
      "   micro avg       0.91      0.97      0.94      1061\n",
      "   macro avg       0.91      0.97      0.94      1061\n",
      "weighted avg       0.91      0.97      0.94      1061\n",
      " samples avg       0.92      0.97      0.94      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6911, Accuracy: 0.6961, F1 Micro: 0.6961, F1 Macro: 0.4104\n",
      "Epoch 2/10, Train Loss: 0.6505, Accuracy: 0.6912, F1 Micro: 0.6912, F1 Macro: 0.4629\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5618, Accuracy: 0.7745, F1 Micro: 0.7745, F1 Macro: 0.7032\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4435, Accuracy: 0.8578, F1 Micro: 0.8578, F1 Macro: 0.8342\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3129, Accuracy: 0.8922, F1 Micro: 0.8922, F1 Macro: 0.8819\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1977, Accuracy: 0.8971, F1 Micro: 0.8971, F1 Macro: 0.8829\n",
      "Epoch 7/10, Train Loss: 0.1712, Accuracy: 0.8873, F1 Micro: 0.8873, F1 Macro: 0.8736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1513, Accuracy: 0.8971, F1 Micro: 0.8971, F1 Macro: 0.88\n",
      "Epoch 9/10, Train Loss: 0.1387, Accuracy: 0.8873, F1 Micro: 0.8873, F1 Macro: 0.8736\n",
      "Epoch 10/10, Train Loss: 0.1093, Accuracy: 0.8824, F1 Micro: 0.8824, F1 Macro: 0.8676\n",
      "\n",
      "Sentiment analysis accuracy: 0.8971, F1 Micro: 0.8971, F1 Macro: 0.88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.85      0.83        62\n",
      "    positive       0.94      0.92      0.93       142\n",
      "\n",
      "    accuracy                           0.90       204\n",
      "   macro avg       0.88      0.89      0.88       204\n",
      "weighted avg       0.90      0.90      0.90       204\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 136: Accuracy: 0.8951, F1 Micro: 0.8951, F1 Macro: 0.7649\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       1.00      0.83      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.99      0.94      0.97       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.69      0.76        16\n",
      "     neutral       0.93      0.98      0.95       167\n",
      "    positive       0.79      0.67      0.72        33\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.85      0.78      0.81       216\n",
      "weighted avg       0.90      0.91      0.90       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.47      0.67      0.55        12\n",
      "     neutral       0.87      0.93      0.90       152\n",
      "    positive       0.77      0.52      0.62        52\n",
      "\n",
      "    accuracy                           0.82       216\n",
      "   macro avg       0.70      0.71      0.69       216\n",
      "weighted avg       0.82      0.82      0.81       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      0.57      0.63        23\n",
      "     neutral       0.85      0.95      0.90       152\n",
      "    positive       0.79      0.56      0.66        41\n",
      "\n",
      "    accuracy                           0.83       216\n",
      "   macro avg       0.79      0.69      0.73       216\n",
      "weighted avg       0.83      0.83      0.82       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.69      0.75        13\n",
      "     neutral       0.94      0.98      0.96       186\n",
      "    positive       0.73      0.47      0.57        17\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.83      0.72      0.76       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.29      0.44        14\n",
      "     neutral       0.90      1.00      0.95       185\n",
      "    positive       0.86      0.35      0.50        17\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.92      0.55      0.63       216\n",
      "weighted avg       0.91      0.90      0.88       216\n",
      "\n",
      "Total train time: 69.21379327774048 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.010945362225174905\n",
      "Acquired samples: 73\n",
      "Sampling duration: 15.179450273513794 seconds\n",
      "New train size: 209\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6059, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5335, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5122, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4655, Accuracy: 0.8341, F1 Micro: 0.9043, F1 Macro: 0.903\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.387, Accuracy: 0.8661, F1 Micro: 0.9203, F1 Macro: 0.9189\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3351, Accuracy: 0.8914, F1 Micro: 0.9335, F1 Macro: 0.9312\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2958, Accuracy: 0.9055, F1 Micro: 0.9414, F1 Macro: 0.9386\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2517, Accuracy: 0.9196, F1 Micro: 0.9499, F1 Macro: 0.9474\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2021, Accuracy: 0.9263, F1 Micro: 0.9544, F1 Macro: 0.9524\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.191, Accuracy: 0.9308, F1 Micro: 0.9568, F1 Macro: 0.9541\n",
      "\n",
      "Aspect detection accuracy: 0.9308, F1 Micro: 0.9568, F1 Macro: 0.9541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.93      0.98      0.96       175\n",
      "      others       0.91      0.87      0.89       158\n",
      "        part       0.92      0.97      0.94       158\n",
      "       price       0.95      0.99      0.97       192\n",
      "     service       0.96      0.99      0.98       191\n",
      "\n",
      "   micro avg       0.94      0.97      0.96      1061\n",
      "   macro avg       0.94      0.97      0.95      1061\n",
      "weighted avg       0.94      0.97      0.96      1061\n",
      " samples avg       0.94      0.97      0.95      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5381, Accuracy: 0.7102, F1 Micro: 0.7102, F1 Macro: 0.4153\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5293, Accuracy: 0.7102, F1 Micro: 0.7102, F1 Macro: 0.4153\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3784, Accuracy: 0.7265, F1 Micro: 0.7265, F1 Macro: 0.4726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3624, Accuracy: 0.8367, F1 Micro: 0.8367, F1 Macro: 0.7817\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1847, Accuracy: 0.898, F1 Micro: 0.898, F1 Macro: 0.8785\n",
      "Epoch 6/10, Train Loss: 0.143, Accuracy: 0.8939, F1 Micro: 0.8939, F1 Macro: 0.8721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1279, Accuracy: 0.9061, F1 Micro: 0.9061, F1 Macro: 0.8891\n",
      "Epoch 8/10, Train Loss: 0.0922, Accuracy: 0.902, F1 Micro: 0.902, F1 Macro: 0.8871\n",
      "Epoch 9/10, Train Loss: 0.1253, Accuracy: 0.8857, F1 Micro: 0.8857, F1 Macro: 0.8562\n",
      "Epoch 10/10, Train Loss: 0.0955, Accuracy: 0.898, F1 Micro: 0.898, F1 Macro: 0.8836\n",
      "\n",
      "Sentiment analysis accuracy: 0.9061, F1 Micro: 0.9061, F1 Macro: 0.8891\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.89      0.85        71\n",
      "    positive       0.95      0.91      0.93       174\n",
      "\n",
      "    accuracy                           0.91       245\n",
      "   macro avg       0.88      0.90      0.89       245\n",
      "weighted avg       0.91      0.91      0.91       245\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 209: Accuracy: 0.919, F1 Micro: 0.919, F1 Macro: 0.8364\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.94      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.93      0.98      0.95       167\n",
      "    positive       0.81      0.67      0.73        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.89      0.82      0.85       216\n",
      "weighted avg       0.91      0.92      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.45      0.75      0.56        12\n",
      "     neutral       0.91      0.87      0.89       152\n",
      "    positive       0.71      0.69      0.70        52\n",
      "\n",
      "    accuracy                           0.82       216\n",
      "   macro avg       0.69      0.77      0.72       216\n",
      "weighted avg       0.84      0.82      0.83       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.70      0.70        23\n",
      "     neutral       0.92      0.97      0.95       152\n",
      "    positive       0.91      0.71      0.79        41\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.84      0.79      0.81       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.95      0.99      0.97       186\n",
      "    positive       0.82      0.53      0.64        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.76      0.82       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.64      0.75        14\n",
      "     neutral       0.96      0.99      0.98       185\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.80      0.85       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Total train time: 83.23663187026978 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.007458060281351209\n",
      "Acquired samples: 66\n",
      "Sampling duration: 15.968002557754517 seconds\n",
      "New train size: 275\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.576, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4926, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4775, Accuracy: 0.808, F1 Micro: 0.8914, F1 Macro: 0.89\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4239, Accuracy: 0.8713, F1 Micro: 0.9239, F1 Macro: 0.9231\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3439, Accuracy: 0.904, F1 Micro: 0.9411, F1 Macro: 0.9395\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2904, Accuracy: 0.9115, F1 Micro: 0.9453, F1 Macro: 0.9437\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2401, Accuracy: 0.9278, F1 Micro: 0.955, F1 Macro: 0.9526\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1947, Accuracy: 0.939, F1 Micro: 0.9619, F1 Macro: 0.9597\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1563, Accuracy: 0.9397, F1 Micro: 0.9623, F1 Macro: 0.9602\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1292, Accuracy: 0.942, F1 Micro: 0.9637, F1 Macro: 0.9614\n",
      "\n",
      "Aspect detection accuracy: 0.942, F1 Micro: 0.9637, F1 Macro: 0.9614\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.94      0.99      0.96       175\n",
      "      others       0.92      0.87      0.90       158\n",
      "        part       0.93      0.99      0.96       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.95      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.95      0.98      0.96      1061\n",
      "   macro avg       0.95      0.97      0.96      1061\n",
      "weighted avg       0.95      0.98      0.96      1061\n",
      " samples avg       0.95      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6193, Accuracy: 0.6992, F1 Micro: 0.6992, F1 Macro: 0.4363\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4971, Accuracy: 0.7236, F1 Micro: 0.7236, F1 Macro: 0.7117\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3173, Accuracy: 0.8659, F1 Micro: 0.8659, F1 Macro: 0.8495\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2272, Accuracy: 0.8862, F1 Micro: 0.8862, F1 Macro: 0.8677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.179, Accuracy: 0.9024, F1 Micro: 0.9024, F1 Macro: 0.8896\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1464, Accuracy: 0.9146, F1 Micro: 0.9146, F1 Macro: 0.9018\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0944, Accuracy: 0.9146, F1 Micro: 0.9146, F1 Macro: 0.9043\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1578, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9128\n",
      "Epoch 9/10, Train Loss: 0.1241, Accuracy: 0.9146, F1 Micro: 0.9146, F1 Macro: 0.9024\n",
      "Epoch 10/10, Train Loss: 0.1202, Accuracy: 0.9024, F1 Micro: 0.9024, F1 Macro: 0.8915\n",
      "\n",
      "Sentiment analysis accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9128\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.96      0.88        75\n",
      "    positive       0.98      0.91      0.94       171\n",
      "\n",
      "    accuracy                           0.92       246\n",
      "   macro avg       0.90      0.93      0.91       246\n",
      "weighted avg       0.93      0.92      0.92       246\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 275: Accuracy: 0.9298, F1 Micro: 0.9298, F1 Macro: 0.8596\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.94      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.93      0.99      0.96       167\n",
      "    positive       0.88      0.64      0.74        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.89      0.81      0.84       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.45      0.83      0.59        12\n",
      "     neutral       0.92      0.88      0.90       152\n",
      "    positive       0.76      0.73      0.75        52\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.71      0.81      0.74       216\n",
      "weighted avg       0.86      0.84      0.84       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.78      0.77        23\n",
      "     neutral       0.93      0.99      0.96       152\n",
      "    positive       0.94      0.71      0.81        41\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.87      0.83      0.84       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.86      0.71      0.77        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.85      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.71      0.83        14\n",
      "     neutral       0.95      1.00      0.98       185\n",
      "    positive       1.00      0.71      0.83        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.98      0.81      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Total train time: 94.41355633735657 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.007842029258608819\n",
      "Acquired samples: 59\n",
      "Sampling duration: 14.742501497268677 seconds\n",
      "New train size: 334\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5855, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4906, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4526, Accuracy: 0.8408, F1 Micro: 0.9081, F1 Macro: 0.9071\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3716, Accuracy: 0.907, F1 Micro: 0.9432, F1 Macro: 0.9412\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2931, Accuracy: 0.9293, F1 Micro: 0.9562, F1 Macro: 0.9538\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2285, Accuracy: 0.942, F1 Micro: 0.964, F1 Macro: 0.9624\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1914, Accuracy: 0.9501, F1 Micro: 0.9689, F1 Macro: 0.9672\n",
      "Epoch 8/10, Train Loss: 0.1592, Accuracy: 0.9501, F1 Micro: 0.9686, F1 Macro: 0.9663\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1285, Accuracy: 0.9531, F1 Micro: 0.9706, F1 Macro: 0.969\n",
      "Epoch 10/10, Train Loss: 0.1067, Accuracy: 0.9516, F1 Micro: 0.9697, F1 Macro: 0.9676\n",
      "\n",
      "Aspect detection accuracy: 0.9531, F1 Micro: 0.9706, F1 Macro: 0.969\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.97      0.96       175\n",
      "      others       0.91      0.93      0.92       158\n",
      "        part       0.95      0.99      0.97       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5611, Accuracy: 0.6853, F1 Micro: 0.6853, F1 Macro: 0.4066\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4434, Accuracy: 0.8367, F1 Micro: 0.8367, F1 Macro: 0.8126\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2518, Accuracy: 0.8446, F1 Micro: 0.8446, F1 Macro: 0.8352\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1997, Accuracy: 0.9004, F1 Micro: 0.9004, F1 Macro: 0.8807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1622, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.8948\n",
      "Epoch 6/10, Train Loss: 0.1086, Accuracy: 0.9044, F1 Micro: 0.9044, F1 Macro: 0.8944\n",
      "Epoch 7/10, Train Loss: 0.0934, Accuracy: 0.9044, F1 Micro: 0.9044, F1 Macro: 0.895\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0764, Accuracy: 0.9243, F1 Micro: 0.9243, F1 Macro: 0.9131\n",
      "Epoch 9/10, Train Loss: 0.0798, Accuracy: 0.9044, F1 Micro: 0.9044, F1 Macro: 0.895\n",
      "Epoch 10/10, Train Loss: 0.0707, Accuracy: 0.9004, F1 Micro: 0.9004, F1 Macro: 0.8898\n",
      "\n",
      "Sentiment analysis accuracy: 0.9243, F1 Micro: 0.9243, F1 Macro: 0.9131\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.90      0.88        79\n",
      "    positive       0.95      0.94      0.94       172\n",
      "\n",
      "    accuracy                           0.92       251\n",
      "   macro avg       0.91      0.92      0.91       251\n",
      "weighted avg       0.93      0.92      0.92       251\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 334: Accuracy: 0.936, F1 Micro: 0.936, F1 Macro: 0.8655\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.95      0.97      0.96       167\n",
      "    positive       0.77      0.73      0.75        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.86      0.82      0.84       216\n",
      "weighted avg       0.91      0.92      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.39      0.75      0.51        12\n",
      "     neutral       0.93      0.91      0.92       152\n",
      "    positive       0.82      0.69      0.75        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.71      0.78      0.73       216\n",
      "weighted avg       0.87      0.85      0.85       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.91      0.82        23\n",
      "     neutral       0.94      0.99      0.96       152\n",
      "    positive       0.97      0.68      0.80        41\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.89      0.86      0.86       216\n",
      "weighted avg       0.93      0.92      0.92       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.92      0.83        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.92      0.65      0.76        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.88      0.85      0.86       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.99      0.91      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 91.84568428993225 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.007876313291490078\n",
      "Acquired samples: 54\n",
      "Sampling duration: 13.448960304260254 seconds\n",
      "New train size: 388\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5619, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.507, Accuracy: 0.8051, F1 Micro: 0.8901, F1 Macro: 0.8888\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4135, Accuracy: 0.8772, F1 Micro: 0.927, F1 Macro: 0.9263\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3256, Accuracy: 0.9234, F1 Micro: 0.9525, F1 Macro: 0.9503\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2556, Accuracy: 0.9487, F1 Micro: 0.968, F1 Macro: 0.9669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1996, Accuracy: 0.9531, F1 Micro: 0.9707, F1 Macro: 0.9691\n",
      "Epoch 7/10, Train Loss: 0.1476, Accuracy: 0.9442, F1 Micro: 0.9647, F1 Macro: 0.9612\n",
      "Epoch 8/10, Train Loss: 0.1308, Accuracy: 0.9472, F1 Micro: 0.9666, F1 Macro: 0.9636\n",
      "Epoch 9/10, Train Loss: 0.1013, Accuracy: 0.9531, F1 Micro: 0.9705, F1 Macro: 0.9683\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0851, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9715\n",
      "\n",
      "Aspect detection accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9715\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.94      0.90      0.92       158\n",
      "        part       0.96      0.99      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.97      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5898, Accuracy: 0.6897, F1 Micro: 0.6897, F1 Macro: 0.4082\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4797, Accuracy: 0.8467, F1 Micro: 0.8467, F1 Macro: 0.8082\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2814, Accuracy: 0.9004, F1 Micro: 0.9004, F1 Macro: 0.8892\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1581, Accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.9035\n",
      "Epoch 5/10, Train Loss: 0.1567, Accuracy: 0.9119, F1 Micro: 0.9119, F1 Macro: 0.9022\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1366, Accuracy: 0.9195, F1 Micro: 0.9195, F1 Macro: 0.9057\n",
      "Epoch 7/10, Train Loss: 0.1521, Accuracy: 0.8736, F1 Micro: 0.8736, F1 Macro: 0.8631\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1286, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9256\n",
      "Epoch 9/10, Train Loss: 0.0644, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9133\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0715, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9265\n",
      "\n",
      "Sentiment analysis accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9265\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        81\n",
      "    positive       0.98      0.92      0.95       180\n",
      "\n",
      "    accuracy                           0.93       261\n",
      "   macro avg       0.92      0.94      0.93       261\n",
      "weighted avg       0.94      0.93      0.94       261\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 388: Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.9045\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       1.00      0.96      0.98        24\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.99      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.84      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.59      0.83      0.69        12\n",
      "     neutral       0.94      0.90      0.92       152\n",
      "    positive       0.80      0.83      0.81        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.78      0.85      0.81       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.96      0.99      0.97       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.92      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.71      0.83        14\n",
      "     neutral       0.97      1.00      0.98       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.99      0.87      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 99.58996415138245 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0051100277341902265\n",
      "Acquired samples: 48\n",
      "Sampling duration: 12.343008995056152 seconds\n",
      "New train size: 436\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5713, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4907, Accuracy: 0.8155, F1 Micro: 0.8954, F1 Macro: 0.8943\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4013, Accuracy: 0.9003, F1 Micro: 0.94, F1 Macro: 0.9391\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2956, Accuracy: 0.9315, F1 Micro: 0.9574, F1 Macro: 0.9549\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2252, Accuracy: 0.9494, F1 Micro: 0.9684, F1 Macro: 0.9666\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.183, Accuracy: 0.9539, F1 Micro: 0.9712, F1 Macro: 0.97\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1399, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9719\n",
      "Epoch 8/10, Train Loss: 0.1137, Accuracy: 0.9516, F1 Micro: 0.9696, F1 Macro: 0.9677\n",
      "Epoch 9/10, Train Loss: 0.0977, Accuracy: 0.9546, F1 Micro: 0.9715, F1 Macro: 0.9697\n",
      "Epoch 10/10, Train Loss: 0.0783, Accuracy: 0.9516, F1 Micro: 0.9696, F1 Macro: 0.9674\n",
      "\n",
      "Aspect detection accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9719\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.91      0.94      0.92       158\n",
      "        part       0.96      0.97      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5921, Accuracy: 0.6773, F1 Micro: 0.6773, F1 Macro: 0.4038\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3533, Accuracy: 0.8924, F1 Micro: 0.8924, F1 Macro: 0.8844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1749, Accuracy: 0.9124, F1 Micro: 0.9124, F1 Macro: 0.9043\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1324, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.9074\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1294, Accuracy: 0.9402, F1 Micro: 0.9402, F1 Macro: 0.9323\n",
      "Epoch 6/10, Train Loss: 0.0986, Accuracy: 0.8924, F1 Micro: 0.8924, F1 Macro: 0.885\n",
      "Epoch 7/10, Train Loss: 0.0686, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.9079\n",
      "Epoch 8/10, Train Loss: 0.0773, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.9079\n",
      "Epoch 9/10, Train Loss: 0.0646, Accuracy: 0.9243, F1 Micro: 0.9243, F1 Macro: 0.9131\n",
      "Epoch 10/10, Train Loss: 0.1034, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.9002\n",
      "\n",
      "Sentiment analysis accuracy: 0.9402, F1 Micro: 0.9402, F1 Macro: 0.9323\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.93      0.91        81\n",
      "    positive       0.96      0.95      0.96       170\n",
      "\n",
      "    accuracy                           0.94       251\n",
      "   macro avg       0.93      0.94      0.93       251\n",
      "weighted avg       0.94      0.94      0.94       251\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 436: Accuracy: 0.9383, F1 Micro: 0.9383, F1 Macro: 0.8765\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.97      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.88      0.67      0.76        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.82      0.85       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.38      0.92      0.54        12\n",
      "     neutral       0.94      0.89      0.91       152\n",
      "    positive       0.84      0.69      0.76        52\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.72      0.83      0.74       216\n",
      "weighted avg       0.88      0.84      0.85       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.96      0.81        23\n",
      "     neutral       0.96      0.96      0.96       152\n",
      "    positive       0.94      0.76      0.84        41\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.87      0.89      0.87       216\n",
      "weighted avg       0.93      0.92      0.92       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.99      0.91      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 98.91280269622803 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.005882041994482279\n",
      "Acquired samples: 43\n",
      "Sampling duration: 10.89629578590393 seconds\n",
      "New train size: 479\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5639, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4648, Accuracy: 0.8185, F1 Micro: 0.8969, F1 Macro: 0.896\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3805, Accuracy: 0.9048, F1 Micro: 0.9418, F1 Macro: 0.9399\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2884, Accuracy: 0.9338, F1 Micro: 0.9587, F1 Macro: 0.9563\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2194, Accuracy: 0.9487, F1 Micro: 0.9679, F1 Macro: 0.9657\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1631, Accuracy: 0.9554, F1 Micro: 0.9721, F1 Macro: 0.9708\n",
      "Epoch 7/10, Train Loss: 0.13, Accuracy: 0.9554, F1 Micro: 0.972, F1 Macro: 0.9702\n",
      "Epoch 8/10, Train Loss: 0.1155, Accuracy: 0.9554, F1 Micro: 0.9719, F1 Macro: 0.97\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0908, Accuracy: 0.9561, F1 Micro: 0.9724, F1 Macro: 0.9708\n",
      "Epoch 10/10, Train Loss: 0.0735, Accuracy: 0.9554, F1 Micro: 0.9721, F1 Macro: 0.9705\n",
      "\n",
      "Aspect detection accuracy: 0.9561, F1 Micro: 0.9724, F1 Macro: 0.9708\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.92      0.92      0.92       158\n",
      "        part       0.96      0.97      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.97      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5559, Accuracy: 0.8353, F1 Micro: 0.8353, F1 Macro: 0.795\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2967, Accuracy: 0.8824, F1 Micro: 0.8824, F1 Macro: 0.8731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2146, Accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.9047\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1566, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9271\n",
      "Epoch 5/10, Train Loss: 0.1033, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9256\n",
      "Epoch 6/10, Train Loss: 0.1073, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9223\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1126, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9281\n",
      "Epoch 8/10, Train Loss: 0.0883, Accuracy: 0.9255, F1 Micro: 0.9255, F1 Macro: 0.9169\n",
      "Epoch 9/10, Train Loss: 0.0922, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9256\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0529, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9328\n",
      "\n",
      "Sentiment analysis accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9328\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.93      0.91        81\n",
      "    positive       0.96      0.95      0.96       174\n",
      "\n",
      "    accuracy                           0.94       255\n",
      "   macro avg       0.93      0.94      0.93       255\n",
      "weighted avg       0.94      0.94      0.94       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 479: Accuracy: 0.9491, F1 Micro: 0.9491, F1 Macro: 0.8999\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.83      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.80      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.83      0.85      0.84       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.96      0.86        23\n",
      "     neutral       0.96      0.97      0.97       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.91      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.89      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.64      0.78        14\n",
      "     neutral       0.97      1.00      0.99       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.97      0.86      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 105.27681231498718 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.004403699189424515\n",
      "Acquired samples: 39\n",
      "Sampling duration: 10.13177752494812 seconds\n",
      "New train size: 518\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5641, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4637, Accuracy: 0.8534, F1 Micro: 0.9146, F1 Macro: 0.9146\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3592, Accuracy: 0.9293, F1 Micro: 0.9565, F1 Macro: 0.9548\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2603, Accuracy: 0.9435, F1 Micro: 0.9648, F1 Macro: 0.963\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1959, Accuracy: 0.9449, F1 Micro: 0.9654, F1 Macro: 0.963\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1534, Accuracy: 0.9539, F1 Micro: 0.9709, F1 Macro: 0.9687\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1197, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9718\n",
      "Epoch 8/10, Train Loss: 0.0988, Accuracy: 0.9546, F1 Micro: 0.9714, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0784, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0706, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9745\n",
      "\n",
      "Aspect detection accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9745\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.92      0.93       158\n",
      "        part       0.96      0.98      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5883, Accuracy: 0.7273, F1 Micro: 0.7273, F1 Macro: 0.5866\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3091, Accuracy: 0.8788, F1 Micro: 0.8788, F1 Macro: 0.8696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1864, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.9043\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1706, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9197\n",
      "Epoch 5/10, Train Loss: 0.159, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.9043\n",
      "Epoch 6/10, Train Loss: 0.113, Accuracy: 0.9205, F1 Micro: 0.9205, F1 Macro: 0.9113\n",
      "Epoch 7/10, Train Loss: 0.1168, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.9082\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0796, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9183\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0788, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9265\n",
      "Epoch 10/10, Train Loss: 0.0973, Accuracy: 0.9242, F1 Micro: 0.9242, F1 Macro: 0.9116\n",
      "\n",
      "Sentiment analysis accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9265\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.92      0.90        84\n",
      "    positive       0.96      0.94      0.95       180\n",
      "\n",
      "    accuracy                           0.94       264\n",
      "   macro avg       0.92      0.93      0.93       264\n",
      "weighted avg       0.94      0.94      0.94       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 518: Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.8942\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.69      0.79        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.82      0.82      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.83      0.86       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.93      0.92      0.93       152\n",
      "    positive       0.79      0.81      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.83      0.85      0.84       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.91      0.89        23\n",
      "     neutral       0.96      0.98      0.97       152\n",
      "    positive       0.92      0.83      0.87        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.91      0.91       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.71      0.83        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.89      1.00      0.94        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.90      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 115.13102197647095 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.004297042824327946\n",
      "Acquired samples: 22\n",
      "Sampling duration: 9.228099822998047 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5508, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4673, Accuracy: 0.8445, F1 Micro: 0.9103, F1 Macro: 0.9095\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3564, Accuracy: 0.9271, F1 Micro: 0.9553, F1 Macro: 0.9537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2576, Accuracy: 0.9405, F1 Micro: 0.9629, F1 Macro: 0.9604\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2006, Accuracy: 0.9568, F1 Micro: 0.9731, F1 Macro: 0.9718\n",
      "Epoch 6/10, Train Loss: 0.1439, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9715\n",
      "Epoch 7/10, Train Loss: 0.1176, Accuracy: 0.9546, F1 Micro: 0.9715, F1 Macro: 0.9697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1047, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9745\n",
      "Epoch 9/10, Train Loss: 0.0843, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.972\n",
      "Epoch 10/10, Train Loss: 0.0722, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9737\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9745\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.89      0.99      0.93       158\n",
      "        part       0.97      0.96      0.96       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.97      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5741, Accuracy: 0.7945, F1 Micro: 0.7945, F1 Macro: 0.7335\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2802, Accuracy: 0.8458, F1 Micro: 0.8458, F1 Macro: 0.8385\n",
      "Epoch 3/10, Train Loss: 0.2108, Accuracy: 0.8419, F1 Micro: 0.8419, F1 Macro: 0.8346\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1658, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.933\n",
      "Epoch 5/10, Train Loss: 0.1188, Accuracy: 0.9289, F1 Micro: 0.9289, F1 Macro: 0.9193\n",
      "Epoch 6/10, Train Loss: 0.1053, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9249\n",
      "Epoch 7/10, Train Loss: 0.0972, Accuracy: 0.9209, F1 Micro: 0.9209, F1 Macro: 0.9092\n",
      "Epoch 8/10, Train Loss: 0.1016, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9245\n",
      "Epoch 9/10, Train Loss: 0.0638, Accuracy: 0.9368, F1 Micro: 0.9368, F1 Macro: 0.9291\n",
      "Epoch 10/10, Train Loss: 0.0532, Accuracy: 0.9249, F1 Micro: 0.9249, F1 Macro: 0.9146\n",
      "\n",
      "Sentiment analysis accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.933\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.94      0.91        81\n",
      "    positive       0.97      0.94      0.96       172\n",
      "\n",
      "    accuracy                           0.94       253\n",
      "   macro avg       0.93      0.94      0.93       253\n",
      "weighted avg       0.94      0.94      0.94       253\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.8852\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.82      0.82      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.85      0.87       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.36      1.00      0.53        12\n",
      "     neutral       0.94      0.90      0.92       152\n",
      "    positive       0.95      0.69      0.80        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.75      0.86      0.75       216\n",
      "weighted avg       0.91      0.86      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.96      0.83        23\n",
      "     neutral       0.97      0.95      0.96       152\n",
      "    positive       0.92      0.83      0.87        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.91      0.89       216\n",
      "weighted avg       0.94      0.93      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.71      0.83        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.89      1.00      0.94        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.90      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 104.11638569831848 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.0055134503170847894\n",
      "Acquired samples: 33\n",
      "Sampling duration: 8.568360090255737 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5384, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4572, Accuracy: 0.878, F1 Micro: 0.9278, F1 Macro: 0.9267\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3319, Accuracy: 0.9449, F1 Micro: 0.9661, F1 Macro: 0.9648\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2378, Accuracy: 0.9516, F1 Micro: 0.9698, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1915, Accuracy: 0.9546, F1 Micro: 0.9714, F1 Macro: 0.9695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1489, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9729\n",
      "Epoch 7/10, Train Loss: 0.1143, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9714\n",
      "Epoch 8/10, Train Loss: 0.0924, Accuracy: 0.9561, F1 Micro: 0.9722, F1 Macro: 0.9696\n",
      "Epoch 9/10, Train Loss: 0.0754, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0641, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9741\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9741\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.94      0.92      0.93       158\n",
      "        part       0.97      0.97      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5717, Accuracy: 0.7034, F1 Micro: 0.7034, F1 Macro: 0.4862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2908, Accuracy: 0.8631, F1 Micro: 0.8631, F1 Macro: 0.853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.174, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.8997\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1407, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9231\n",
      "Epoch 5/10, Train Loss: 0.1351, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9155\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1386, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9213\n",
      "Epoch 7/10, Train Loss: 0.1291, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9151\n",
      "Epoch 8/10, Train Loss: 0.0656, Accuracy: 0.9278, F1 Micro: 0.9278, F1 Macro: 0.9195\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0675, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9305\n",
      "Epoch 10/10, Train Loss: 0.0698, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9259\n",
      "\n",
      "Sentiment analysis accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9305\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.93      0.91        83\n",
      "    positive       0.97      0.94      0.96       180\n",
      "\n",
      "    accuracy                           0.94       263\n",
      "   macro avg       0.93      0.94      0.93       263\n",
      "weighted avg       0.94      0.94      0.94       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9071\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.83      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.95      0.92      0.93       152\n",
      "    positive       0.80      0.85      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.84      0.87      0.85       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.96      0.86        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.91      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.89      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.93      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 116.26407933235168 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.0026658918242901566\n",
      "Acquired samples: 30\n",
      "Sampling duration: 7.883903741836548 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5486, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4511, Accuracy: 0.8802, F1 Micro: 0.9292, F1 Macro: 0.9282\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3273, Accuracy: 0.9382, F1 Micro: 0.9615, F1 Macro: 0.9595\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2279, Accuracy: 0.9531, F1 Micro: 0.9708, F1 Macro: 0.9692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1771, Accuracy: 0.9583, F1 Micro: 0.9737, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1328, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1048, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9754\n",
      "Epoch 8/10, Train Loss: 0.0856, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0781, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9766\n",
      "Epoch 10/10, Train Loss: 0.0676, Accuracy: 0.9591, F1 Micro: 0.974, F1 Macro: 0.9714\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9766\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.92      0.95      0.93       158\n",
      "        part       0.98      0.97      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5525, Accuracy: 0.8566, F1 Micro: 0.8566, F1 Macro: 0.8344\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2993, Accuracy: 0.9208, F1 Micro: 0.9208, F1 Macro: 0.9114\n",
      "Epoch 3/10, Train Loss: 0.1815, Accuracy: 0.917, F1 Micro: 0.917, F1 Macro: 0.9089\n",
      "Epoch 4/10, Train Loss: 0.1731, Accuracy: 0.9132, F1 Micro: 0.9132, F1 Macro: 0.9054\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1205, Accuracy: 0.9245, F1 Micro: 0.9245, F1 Macro: 0.9159\n",
      "Epoch 6/10, Train Loss: 0.1587, Accuracy: 0.9057, F1 Micro: 0.9057, F1 Macro: 0.8972\n",
      "Epoch 7/10, Train Loss: 0.1217, Accuracy: 0.9208, F1 Micro: 0.9208, F1 Macro: 0.9124\n",
      "Epoch 8/10, Train Loss: 0.0866, Accuracy: 0.9094, F1 Micro: 0.9094, F1 Macro: 0.9011\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.104, Accuracy: 0.9245, F1 Micro: 0.9245, F1 Macro: 0.9168\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0684, Accuracy: 0.9245, F1 Micro: 0.9245, F1 Macro: 0.9168\n",
      "\n",
      "Sentiment analysis accuracy: 0.9245, F1 Micro: 0.9245, F1 Macro: 0.9168\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.96      0.89        85\n",
      "    positive       0.98      0.91      0.94       180\n",
      "\n",
      "    accuracy                           0.92       265\n",
      "   macro avg       0.91      0.94      0.92       265\n",
      "weighted avg       0.93      0.92      0.93       265\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9452, F1 Micro: 0.9452, F1 Macro: 0.8921\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.97      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.97      0.98      0.97       167\n",
      "    positive       0.84      0.82      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.89      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.31      0.92      0.47        12\n",
      "     neutral       0.96      0.86      0.91       152\n",
      "    positive       0.89      0.75      0.81        52\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.72      0.84      0.73       216\n",
      "weighted avg       0.90      0.84      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      1.00      0.85        23\n",
      "     neutral       0.98      0.97      0.97       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.92      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.95      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 119.22363018989563 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.0030809331219643354\n",
      "Acquired samples: 27\n",
      "Sampling duration: 7.139275789260864 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5473, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4421, Accuracy: 0.8854, F1 Micro: 0.9318, F1 Macro: 0.9311\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.312, Accuracy: 0.9435, F1 Micro: 0.965, F1 Macro: 0.9636\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2188, Accuracy: 0.9539, F1 Micro: 0.9714, F1 Macro: 0.9698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1678, Accuracy: 0.9568, F1 Micro: 0.9728, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1446, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1011, Accuracy: 0.9613, F1 Micro: 0.9755, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0866, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0723, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.978\n",
      "Epoch 10/10, Train Loss: 0.064, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9772\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.99      0.98       175\n",
      "      others       0.94      0.94      0.94       158\n",
      "        part       0.97      0.97      0.97       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5337, Accuracy: 0.8447, F1 Micro: 0.8447, F1 Macro: 0.8113\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.26, Accuracy: 0.9242, F1 Micro: 0.9242, F1 Macro: 0.9109\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.178, Accuracy: 0.9432, F1 Micro: 0.9432, F1 Macro: 0.9363\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1297, Accuracy: 0.9508, F1 Micro: 0.9508, F1 Macro: 0.9434\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1138, Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9486\n",
      "Epoch 6/10, Train Loss: 0.1155, Accuracy: 0.9508, F1 Micro: 0.9508, F1 Macro: 0.9444\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.087, Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9489\n",
      "Epoch 8/10, Train Loss: 0.0996, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9306\n",
      "Epoch 9/10, Train Loss: 0.0594, Accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.9396\n",
      "Epoch 10/10, Train Loss: 0.0942, Accuracy: 0.9432, F1 Micro: 0.9432, F1 Macro: 0.9355\n",
      "\n",
      "Sentiment analysis accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9489\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.96      0.93        85\n",
      "    positive       0.98      0.95      0.97       179\n",
      "\n",
      "    accuracy                           0.95       264\n",
      "   macro avg       0.94      0.96      0.95       264\n",
      "weighted avg       0.96      0.95      0.95       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9202\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.96      0.99      0.98       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.87      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.92      0.88        12\n",
      "     neutral       0.95      0.94      0.95       152\n",
      "    positive       0.83      0.85      0.84        52\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.88      0.90      0.89       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.96      0.86        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       0.92      0.80      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.91      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.89      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.95      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 127.51200413703918 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.0030520408879965545\n",
      "Acquired samples: 18\n",
      "Sampling duration: 6.631239891052246 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5456, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4263, Accuracy: 0.901, F1 Micro: 0.9403, F1 Macro: 0.9387\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2973, Accuracy: 0.9472, F1 Micro: 0.9673, F1 Macro: 0.9658\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1976, Accuracy: 0.9554, F1 Micro: 0.9722, F1 Macro: 0.9708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1564, Accuracy: 0.9635, F1 Micro: 0.9773, F1 Macro: 0.9763\n",
      "Epoch 6/10, Train Loss: 0.1234, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9756\n",
      "Epoch 7/10, Train Loss: 0.0951, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0759, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9766\n",
      "Epoch 9/10, Train Loss: 0.0639, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0526, Accuracy: 0.9658, F1 Micro: 0.9783, F1 Macro: 0.9767\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9783, F1 Macro: 0.9767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.95      0.91      0.93       158\n",
      "        part       0.97      0.98      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5172, Accuracy: 0.9007, F1 Micro: 0.9007, F1 Macro: 0.8876\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2712, Accuracy: 0.9485, F1 Micro: 0.9485, F1 Macro: 0.9419\n",
      "Epoch 3/10, Train Loss: 0.1827, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9368\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1478, Accuracy: 0.9485, F1 Micro: 0.9485, F1 Macro: 0.9422\n",
      "Epoch 5/10, Train Loss: 0.1363, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9382\n",
      "Epoch 6/10, Train Loss: 0.1266, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9372\n",
      "Epoch 7/10, Train Loss: 0.0922, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9382\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0776, Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9462\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0496, Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9446\n",
      "Epoch 10/10, Train Loss: 0.05, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9364\n",
      "\n",
      "Sentiment analysis accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9446\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.91      0.92        87\n",
      "    positive       0.96      0.97      0.97       185\n",
      "\n",
      "    accuracy                           0.95       272\n",
      "   macro avg       0.95      0.94      0.94       272\n",
      "weighted avg       0.95      0.95      0.95       272\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9177\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.69      0.79        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.79      0.82      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.83      0.85       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        12\n",
      "     neutral       0.95      0.91      0.93       152\n",
      "    positive       0.76      0.85      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.88      0.89      0.88       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.98      0.97       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.93      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 124.70232963562012 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.002694692136719823\n",
      "Acquired samples: 25\n",
      "Sampling duration: 6.088840484619141 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5416, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.41, Accuracy: 0.9152, F1 Micro: 0.9478, F1 Macro: 0.9458\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2813, Accuracy: 0.9464, F1 Micro: 0.9668, F1 Macro: 0.9652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2017, Accuracy: 0.9591, F1 Micro: 0.9746, F1 Macro: 0.9734\n",
      "Epoch 5/10, Train Loss: 0.1407, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1094, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9783\n",
      "Epoch 7/10, Train Loss: 0.088, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9762\n",
      "Epoch 8/10, Train Loss: 0.0715, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9747\n",
      "Epoch 9/10, Train Loss: 0.0604, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.978\n",
      "Epoch 10/10, Train Loss: 0.0531, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9766\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9783\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.97      0.99      0.98       175\n",
      "      others       0.95      0.92      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5024, Accuracy: 0.8943, F1 Micro: 0.8943, F1 Macro: 0.8828\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2544, Accuracy: 0.9132, F1 Micro: 0.9132, F1 Macro: 0.8959\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1789, Accuracy: 0.9623, F1 Micro: 0.9623, F1 Macro: 0.9577\n",
      "Epoch 4/10, Train Loss: 0.1426, Accuracy: 0.9547, F1 Micro: 0.9547, F1 Macro: 0.9477\n",
      "Epoch 5/10, Train Loss: 0.0911, Accuracy: 0.9547, F1 Micro: 0.9547, F1 Macro: 0.949\n",
      "Epoch 6/10, Train Loss: 0.1095, Accuracy: 0.9547, F1 Micro: 0.9547, F1 Macro: 0.9484\n",
      "Epoch 7/10, Train Loss: 0.1051, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9331\n",
      "Epoch 8/10, Train Loss: 0.0777, Accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.9371\n",
      "Epoch 9/10, Train Loss: 0.0457, Accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.9411\n",
      "Epoch 10/10, Train Loss: 0.0643, Accuracy: 0.9509, F1 Micro: 0.9509, F1 Macro: 0.9452\n",
      "\n",
      "Sentiment analysis accuracy: 0.9623, F1 Micro: 0.9623, F1 Macro: 0.9577\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94        86\n",
      "    positive       0.99      0.96      0.97       179\n",
      "\n",
      "    accuracy                           0.96       265\n",
      "   macro avg       0.95      0.97      0.96       265\n",
      "weighted avg       0.96      0.96      0.96       265\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9135\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       1.00      0.88      0.93        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.90      0.82      0.86        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.92      0.73        12\n",
      "     neutral       0.96      0.89      0.93       152\n",
      "    positive       0.79      0.85      0.81        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.78      0.89      0.82       216\n",
      "weighted avg       0.90      0.88      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.95      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 120.79910802841187 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.0053452692925930025\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.499467134475708 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5374, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4255, Accuracy: 0.9107, F1 Micro: 0.9448, F1 Macro: 0.9425\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2924, Accuracy: 0.9472, F1 Micro: 0.9672, F1 Macro: 0.966\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1875, Accuracy: 0.9598, F1 Micro: 0.9751, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1517, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1114, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9766\n",
      "Epoch 7/10, Train Loss: 0.094, Accuracy: 0.9591, F1 Micro: 0.9741, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0781, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9771\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0637, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9777\n",
      "Epoch 10/10, Train Loss: 0.0518, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9753\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9777\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.93      0.95      0.94       158\n",
      "        part       0.97      0.98      0.97       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5244, Accuracy: 0.8833, F1 Micro: 0.8833, F1 Macro: 0.8704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.255, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9293\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1643, Accuracy: 0.9494, F1 Micro: 0.9494, F1 Macro: 0.943\n",
      "Epoch 4/10, Train Loss: 0.1456, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9271\n",
      "Epoch 5/10, Train Loss: 0.1385, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9189\n",
      "Epoch 6/10, Train Loss: 0.1313, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9305\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0784, Accuracy: 0.9533, F1 Micro: 0.9533, F1 Macro: 0.9473\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0953, Accuracy: 0.965, F1 Micro: 0.965, F1 Macro: 0.9598\n",
      "Epoch 9/10, Train Loss: 0.0654, Accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9388\n",
      "Epoch 10/10, Train Loss: 0.0744, Accuracy: 0.9494, F1 Micro: 0.9494, F1 Macro: 0.9416\n",
      "\n",
      "Sentiment analysis accuracy: 0.965, F1 Micro: 0.965, F1 Macro: 0.9598\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.94      0.95        83\n",
      "    positive       0.97      0.98      0.97       174\n",
      "\n",
      "    accuracy                           0.96       257\n",
      "   macro avg       0.96      0.96      0.96       257\n",
      "weighted avg       0.96      0.96      0.96       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.8998\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.81      0.79        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.86      0.85      0.86       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.58      0.92      0.71        12\n",
      "     neutral       0.96      0.91      0.94       152\n",
      "    positive       0.85      0.85      0.85        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.79      0.89      0.83       216\n",
      "weighted avg       0.91      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.97      0.98      0.97       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.88      0.86      0.87       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.71      0.83        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.89      1.00      0.94        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.90      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 131.75618839263916 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.002763909893110395\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.98420786857605 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5319, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3995, Accuracy: 0.9137, F1 Micro: 0.947, F1 Macro: 0.945\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2699, Accuracy: 0.9509, F1 Micro: 0.9696, F1 Macro: 0.9682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1851, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1429, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1106, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.977\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0826, Accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9782\n",
      "Epoch 8/10, Train Loss: 0.0726, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9757\n",
      "Epoch 9/10, Train Loss: 0.0555, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9753\n",
      "Epoch 10/10, Train Loss: 0.0495, Accuracy: 0.9598, F1 Micro: 0.9744, F1 Macro: 0.9718\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9782\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.95      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.48, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.9005\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2457, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9402\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.19, Accuracy: 0.9569, F1 Micro: 0.9569, F1 Macro: 0.9524\n",
      "Epoch 4/10, Train Loss: 0.1039, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9238\n",
      "Epoch 5/10, Train Loss: 0.1262, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.932\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1016, Accuracy: 0.9647, F1 Micro: 0.9647, F1 Macro: 0.9611\n",
      "Epoch 7/10, Train Loss: 0.0755, Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9485\n",
      "Epoch 8/10, Train Loss: 0.0658, Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9485\n",
      "Epoch 9/10, Train Loss: 0.0578, Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9485\n",
      "Epoch 10/10, Train Loss: 0.0506, Accuracy: 0.9608, F1 Micro: 0.9608, F1 Macro: 0.9568\n",
      "\n",
      "Sentiment analysis accuracy: 0.9647, F1 Micro: 0.9647, F1 Macro: 0.9611\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95        86\n",
      "    positive       0.99      0.96      0.97       169\n",
      "\n",
      "    accuracy                           0.96       255\n",
      "   macro avg       0.96      0.97      0.96       255\n",
      "weighted avg       0.97      0.96      0.96       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9475, F1 Micro: 0.9475, F1 Macro: 0.9002\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.97      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.88      0.78        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.85      0.86      0.85       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.34      1.00      0.51        12\n",
      "     neutral       0.97      0.85      0.91       152\n",
      "    positive       0.83      0.77      0.80        52\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.72      0.87      0.74       216\n",
      "weighted avg       0.90      0.84      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.80      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.93      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 129.72349452972412 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.0024880596436560156\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.3527820110321045 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5258, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4093, Accuracy: 0.9077, F1 Micro: 0.9433, F1 Macro: 0.9414\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2718, Accuracy: 0.9509, F1 Micro: 0.9696, F1 Macro: 0.9684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1919, Accuracy: 0.9561, F1 Micro: 0.9726, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1351, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1081, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9768\n",
      "Epoch 7/10, Train Loss: 0.0817, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9749\n",
      "Epoch 8/10, Train Loss: 0.0678, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0579, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9784\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0496, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9792\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9792\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.92      0.97      0.94       158\n",
      "        part       0.97      0.98      0.97       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.513, Accuracy: 0.9027, F1 Micro: 0.9027, F1 Macro: 0.8923\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.228, Accuracy: 0.9183, F1 Micro: 0.9183, F1 Macro: 0.9121\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2048, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9301\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1379, Accuracy: 0.9416, F1 Micro: 0.9416, F1 Macro: 0.9364\n",
      "Epoch 5/10, Train Loss: 0.1046, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9312\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.087, Accuracy: 0.9533, F1 Micro: 0.9533, F1 Macro: 0.9482\n",
      "Epoch 7/10, Train Loss: 0.0802, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9275\n",
      "Epoch 8/10, Train Loss: 0.0687, Accuracy: 0.9494, F1 Micro: 0.9494, F1 Macro: 0.9427\n",
      "Epoch 9/10, Train Loss: 0.0747, Accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9385\n",
      "Epoch 10/10, Train Loss: 0.0713, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9135\n",
      "\n",
      "Sentiment analysis accuracy: 0.9533, F1 Micro: 0.9533, F1 Macro: 0.9482\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93        86\n",
      "    positive       0.98      0.95      0.96       171\n",
      "\n",
      "    accuracy                           0.95       257\n",
      "   macro avg       0.94      0.95      0.95       257\n",
      "weighted avg       0.95      0.95      0.95       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.896\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.64      0.78        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.81      0.92      0.86        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.93      0.85      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.82      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.87      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.75      0.86        12\n",
      "     neutral       0.92      0.97      0.94       152\n",
      "    positive       0.87      0.79      0.83        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.93      0.84      0.88       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        23\n",
      "     neutral       0.97      0.98      0.97       152\n",
      "    positive       0.90      0.85      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.92      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.62      0.76        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.75      0.88      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.83      0.86       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.89      1.00      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 137.08590269088745 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.0026340083684772255\n",
      "Acquired samples: 8\n",
      "Sampling duration: 3.6926543712615967 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5276, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4066, Accuracy: 0.9211, F1 Micro: 0.9515, F1 Macro: 0.9499\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2696, Accuracy: 0.9501, F1 Micro: 0.969, F1 Macro: 0.9674\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1934, Accuracy: 0.9561, F1 Micro: 0.9725, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1394, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1081, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.975\n",
      "Epoch 7/10, Train Loss: 0.0858, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0657, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0577, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0515, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.978\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.93      0.93      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.536, Accuracy: 0.883, F1 Micro: 0.883, F1 Macro: 0.8653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2398, Accuracy: 0.9358, F1 Micro: 0.9358, F1 Macro: 0.9294\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1855, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9337\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1387, Accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.9417\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1116, Accuracy: 0.9509, F1 Micro: 0.9509, F1 Macro: 0.9457\n",
      "Epoch 6/10, Train Loss: 0.0902, Accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.9414\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0748, Accuracy: 0.9509, F1 Micro: 0.9509, F1 Macro: 0.9455\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0687, Accuracy: 0.9623, F1 Micro: 0.9623, F1 Macro: 0.9577\n",
      "Epoch 9/10, Train Loss: 0.0767, Accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.936\n",
      "Epoch 10/10, Train Loss: 0.0512, Accuracy: 0.9547, F1 Micro: 0.9547, F1 Macro: 0.9495\n",
      "\n",
      "Sentiment analysis accuracy: 0.9623, F1 Micro: 0.9623, F1 Macro: 0.9577\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.97      0.94        87\n",
      "    positive       0.98      0.96      0.97       178\n",
      "\n",
      "    accuracy                           0.96       265\n",
      "   macro avg       0.95      0.96      0.96       265\n",
      "weighted avg       0.96      0.96      0.96       265\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9287\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.88      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.78      0.81      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.87      0.86      0.86       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.78      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.92      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 143.57996678352356 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.002473926404491067\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.5675430297851562 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5271, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.383, Accuracy: 0.9293, F1 Micro: 0.956, F1 Macro: 0.9537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2571, Accuracy: 0.9546, F1 Micro: 0.9718, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1715, Accuracy: 0.9606, F1 Micro: 0.9755, F1 Macro: 0.9746\n",
      "Epoch 5/10, Train Loss: 0.127, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9715\n",
      "Epoch 6/10, Train Loss: 0.0955, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0797, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9766\n",
      "Epoch 8/10, Train Loss: 0.0649, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9741\n",
      "Epoch 9/10, Train Loss: 0.0568, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0469, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9786\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9786\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.95      0.94       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4883, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8937\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2223, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9307\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1595, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9315\n",
      "Epoch 4/10, Train Loss: 0.1508, Accuracy: 0.9219, F1 Micro: 0.9219, F1 Macro: 0.9091\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1075, Accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9439\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1137, Accuracy: 0.957, F1 Micro: 0.957, F1 Macro: 0.9523\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1004, Accuracy: 0.957, F1 Micro: 0.957, F1 Macro: 0.9523\n",
      "Epoch 8/10, Train Loss: 0.084, Accuracy: 0.9531, F1 Micro: 0.9531, F1 Macro: 0.9481\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0688, Accuracy: 0.957, F1 Micro: 0.957, F1 Macro: 0.9523\n",
      "Epoch 10/10, Train Loss: 0.0669, Accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9436\n",
      "\n",
      "Sentiment analysis accuracy: 0.957, F1 Micro: 0.957, F1 Macro: 0.9523\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        85\n",
      "    positive       0.98      0.95      0.97       171\n",
      "\n",
      "    accuracy                           0.96       256\n",
      "   macro avg       0.95      0.96      0.95       256\n",
      "weighted avg       0.96      0.96      0.96       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9221\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.97      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.84      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.94      0.95      0.94       152\n",
      "    positive       0.82      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.86      0.86      0.86       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.96      0.99      0.97       152\n",
      "    positive       1.00      0.76      0.86        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.94      0.92      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.89      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 137.78912329673767 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0027113758493214845\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.9487743377685547 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5247, Accuracy: 0.8021, F1 Micro: 0.8886, F1 Macro: 0.8872\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3851, Accuracy: 0.9286, F1 Micro: 0.9556, F1 Macro: 0.9534\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2553, Accuracy: 0.9546, F1 Micro: 0.9719, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.18, Accuracy: 0.9621, F1 Micro: 0.9763, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1224, Accuracy: 0.965, F1 Micro: 0.9782, F1 Macro: 0.9773\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.105, Accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9783\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0836, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9794\n",
      "Epoch 8/10, Train Loss: 0.0601, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9791\n",
      "Epoch 9/10, Train Loss: 0.052, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9788\n",
      "Epoch 10/10, Train Loss: 0.0489, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9789\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9794\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.93      0.94      0.94       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5255, Accuracy: 0.9057, F1 Micro: 0.9057, F1 Macro: 0.8934\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2494, Accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.9414\n",
      "Epoch 3/10, Train Loss: 0.1837, Accuracy: 0.9358, F1 Micro: 0.9358, F1 Macro: 0.9283\n",
      "Epoch 4/10, Train Loss: 0.1434, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9323\n",
      "Epoch 5/10, Train Loss: 0.0857, Accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.9371\n",
      "Epoch 6/10, Train Loss: 0.0802, Accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.9374\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0492, Accuracy: 0.9585, F1 Micro: 0.9585, F1 Macro: 0.9531\n",
      "Epoch 8/10, Train Loss: 0.0548, Accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.9367\n",
      "Epoch 9/10, Train Loss: 0.056, Accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.9371\n",
      "Epoch 10/10, Train Loss: 0.0432, Accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.9371\n",
      "\n",
      "Sentiment analysis accuracy: 0.9585, F1 Micro: 0.9585, F1 Macro: 0.9531\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        87\n",
      "    positive       0.97      0.97      0.97       178\n",
      "\n",
      "    accuracy                           0.96       265\n",
      "   macro avg       0.95      0.95      0.95       265\n",
      "weighted avg       0.96      0.96      0.96       265\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9135\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.97      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.97      0.97      0.97       167\n",
      "    positive       0.85      0.85      0.85        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.88      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.92      0.79        12\n",
      "     neutral       0.94      0.93      0.93       152\n",
      "    positive       0.82      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.82      0.88      0.84       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.93      0.91       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 137.579283952713 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0020413632970303296\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.338308334350586 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5262, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3841, Accuracy: 0.9241, F1 Micro: 0.953, F1 Macro: 0.9507\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2527, Accuracy: 0.9546, F1 Micro: 0.9719, F1 Macro: 0.9707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1691, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1334, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1012, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9794\n",
      "Epoch 7/10, Train Loss: 0.079, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9779\n",
      "Epoch 8/10, Train Loss: 0.0662, Accuracy: 0.9688, F1 Micro: 0.9802, F1 Macro: 0.9786\n",
      "Epoch 9/10, Train Loss: 0.0517, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9783\n",
      "Epoch 10/10, Train Loss: 0.0484, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9783\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9794\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.91      0.97      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5294, Accuracy: 0.9116, F1 Micro: 0.9116, F1 Macro: 0.9043\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2353, Accuracy: 0.9357, F1 Micro: 0.9357, F1 Macro: 0.9297\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1723, Accuracy: 0.9357, F1 Micro: 0.9357, F1 Macro: 0.9293\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1462, Accuracy: 0.9357, F1 Micro: 0.9357, F1 Macro: 0.9281\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1059, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9378\n",
      "Epoch 6/10, Train Loss: 0.0952, Accuracy: 0.9357, F1 Micro: 0.9357, F1 Macro: 0.9293\n",
      "Epoch 7/10, Train Loss: 0.0796, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9339\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0761, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9371\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0569, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9382\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0471, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9382\n",
      "\n",
      "Sentiment analysis accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9382\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.95      0.92        84\n",
      "    positive       0.97      0.94      0.96       165\n",
      "\n",
      "    accuracy                           0.94       249\n",
      "   macro avg       0.93      0.95      0.94       249\n",
      "weighted avg       0.95      0.94      0.94       249\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.8962\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.91      0.87        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.87      0.86      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.42      0.83      0.56        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.93      0.73      0.82        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.76      0.83      0.77       216\n",
      "weighted avg       0.90      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      1.00      0.84        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       1.00      0.80      0.89        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.93      0.90       216\n",
      "weighted avg       0.96      0.94      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 142.7058653831482 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.002797035383991897\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.8228049278259277 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.517, Accuracy: 0.8065, F1 Micro: 0.8908, F1 Macro: 0.8897\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3706, Accuracy: 0.9382, F1 Micro: 0.9614, F1 Macro: 0.9601\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2338, Accuracy: 0.9539, F1 Micro: 0.9713, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1592, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.118, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0904, Accuracy: 0.9717, F1 Micro: 0.9822, F1 Macro: 0.9811\n",
      "Epoch 7/10, Train Loss: 0.0759, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.976\n",
      "Epoch 8/10, Train Loss: 0.0571, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9762\n",
      "Epoch 9/10, Train Loss: 0.0526, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9764\n",
      "Epoch 10/10, Train Loss: 0.0452, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9789\n",
      "\n",
      "Aspect detection accuracy: 0.9717, F1 Micro: 0.9822, F1 Macro: 0.9811\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.97      0.99      0.98       175\n",
      "      others       0.94      0.94      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.98      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.98      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4898, Accuracy: 0.8859, F1 Micro: 0.8859, F1 Macro: 0.8785\n",
      "Epoch 2/10, Train Loss: 0.2792, Accuracy: 0.8821, F1 Micro: 0.8821, F1 Macro: 0.8757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1615, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9365\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.147, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9368\n",
      "Epoch 5/10, Train Loss: 0.1055, Accuracy: 0.9202, F1 Micro: 0.9202, F1 Macro: 0.9137\n",
      "Epoch 6/10, Train Loss: 0.1049, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9295\n",
      "Epoch 7/10, Train Loss: 0.0809, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9172\n",
      "Epoch 8/10, Train Loss: 0.0742, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9227\n",
      "Epoch 9/10, Train Loss: 0.0676, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9331\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0587, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9372\n",
      "\n",
      "Sentiment analysis accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9372\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.97      0.92        87\n",
      "    positive       0.98      0.93      0.96       176\n",
      "\n",
      "    accuracy                           0.94       263\n",
      "   macro avg       0.93      0.95      0.94       263\n",
      "weighted avg       0.95      0.94      0.94       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9146\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       1.00      0.88      0.93        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.96      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.88      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.95      0.94      0.94       152\n",
      "    positive       0.81      0.81      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.84      0.86      0.85       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       1.00      0.80      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.93      0.91       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 139.9704191684723 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0020067074801772833\n",
      "Acquired samples: 8\n",
      "Sampling duration: 1.0620942115783691 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5195, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3608, Accuracy: 0.9308, F1 Micro: 0.9571, F1 Macro: 0.9551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.236, Accuracy: 0.9568, F1 Micro: 0.9731, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1664, Accuracy: 0.9621, F1 Micro: 0.9763, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1242, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9775\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0886, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9784\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0713, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9791\n",
      "Epoch 8/10, Train Loss: 0.0598, Accuracy: 0.9688, F1 Micro: 0.9802, F1 Macro: 0.9787\n",
      "Epoch 9/10, Train Loss: 0.0478, Accuracy: 0.9658, F1 Micro: 0.9783, F1 Macro: 0.9766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0428, Accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9793\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.94      0.92      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5023, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9114\n",
      "Epoch 2/10, Train Loss: 0.2169, Accuracy: 0.9104, F1 Micro: 0.9104, F1 Macro: 0.9031\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1555, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.936\n",
      "Epoch 4/10, Train Loss: 0.1355, Accuracy: 0.9254, F1 Micro: 0.9254, F1 Macro: 0.9177\n",
      "Epoch 5/10, Train Loss: 0.095, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.9256\n",
      "Epoch 6/10, Train Loss: 0.1201, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9259\n",
      "Epoch 7/10, Train Loss: 0.0896, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9184\n",
      "Epoch 8/10, Train Loss: 0.089, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9255\n",
      "Epoch 9/10, Train Loss: 0.0753, Accuracy: 0.9254, F1 Micro: 0.9254, F1 Macro: 0.9149\n",
      "Epoch 10/10, Train Loss: 0.0627, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9216\n",
      "\n",
      "Sentiment analysis accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.936\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.91      0.91        87\n",
      "    positive       0.96      0.96      0.96       181\n",
      "\n",
      "    accuracy                           0.94       268\n",
      "   macro avg       0.94      0.93      0.94       268\n",
      "weighted avg       0.94      0.94      0.94       268\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9116\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.86      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.95      0.92      0.93       152\n",
      "    positive       0.78      0.83      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.83      0.86      0.85       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 141.73192858695984 s\n",
      "Total runtime: 3095.051122188568 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79d7d1b",
   "metadata": {
    "papermill": {
     "duration": 0.145086,
     "end_time": "2025-03-06T11:42:50.434760",
     "exception": false,
     "start_time": "2025-03-06T11:42:50.289674",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a851bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 3\n",
      "Random seed: 14\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6791, Accuracy: 0.7746, F1 Micro: 0.8722, F1 Macro: 0.8703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5752, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.512, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4609, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4635, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4127, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3898, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4151, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.396, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3746, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "\n",
      "Aspect detection accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.78      1.00      0.88       175\n",
      "      others       0.71      1.00      0.83       158\n",
      "        part       0.71      1.00      0.83       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.79      1.00      0.88      1061\n",
      "   macro avg       0.79      1.00      0.88      1061\n",
      "weighted avg       0.80      1.00      0.89      1061\n",
      " samples avg       0.79      1.00      0.88      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.8159, Accuracy: 0.3333, F1 Micro: 0.3333, F1 Macro: 0.25\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.6264, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5442, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5154, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4038, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3617, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3192, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2942, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3391, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2952, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "\n",
      "Sentiment analysis accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         1\n",
      "    positive       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.67         3\n",
      "   macro avg       0.33      0.50      0.40         3\n",
      "weighted avg       0.44      0.67      0.53         3\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.7909, F1 Micro: 0.7909, F1 Macro: 0.298\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.77      1.00      0.87       167\n",
      "    positive       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.77       216\n",
      "   macro avg       0.26      0.33      0.29       216\n",
      "weighted avg       0.60      0.77      0.67       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.71      1.00      0.83       152\n",
      "    positive       0.67      0.04      0.07        52\n",
      "\n",
      "    accuracy                           0.71       216\n",
      "   macro avg       0.46      0.35      0.30       216\n",
      "weighted avg       0.66      0.71      0.60       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        23\n",
      "     neutral       0.70      1.00      0.83       152\n",
      "    positive       0.00      0.00      0.00        41\n",
      "\n",
      "    accuracy                           0.70       216\n",
      "   macro avg       0.23      0.33      0.28       216\n",
      "weighted avg       0.50      0.70      0.58       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 63.92467141151428 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.004887192044407129\n",
      "Acquired samples: 82\n",
      "Sampling duration: 12.734896659851074 seconds\n",
      "New train size: 136\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.624, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4937, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.491, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4548, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4271, Accuracy: 0.7961, F1 Micro: 0.8855, F1 Macro: 0.8841\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3768, Accuracy: 0.8028, F1 Micro: 0.8883, F1 Macro: 0.8868\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3466, Accuracy: 0.8445, F1 Micro: 0.9092, F1 Macro: 0.9077\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2986, Accuracy: 0.8683, F1 Micro: 0.9219, F1 Macro: 0.9202\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2597, Accuracy: 0.8847, F1 Micro: 0.9305, F1 Macro: 0.9286\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2144, Accuracy: 0.904, F1 Micro: 0.9418, F1 Macro: 0.9401\n",
      "\n",
      "Aspect detection accuracy: 0.904, F1 Micro: 0.9418, F1 Macro: 0.9401\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.92      0.94      0.93       175\n",
      "      others       0.84      0.97      0.90       158\n",
      "        part       0.81      0.99      0.89       158\n",
      "       price       0.95      0.99      0.97       192\n",
      "     service       0.92      1.00      0.96       191\n",
      "\n",
      "   micro avg       0.90      0.98      0.94      1061\n",
      "   macro avg       0.90      0.98      0.94      1061\n",
      "weighted avg       0.91      0.98      0.94      1061\n",
      " samples avg       0.91      0.98      0.94      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.665, Accuracy: 0.676, F1 Micro: 0.676, F1 Macro: 0.4033\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.6114, Accuracy: 0.6927, F1 Micro: 0.6927, F1 Macro: 0.4566\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.561, Accuracy: 0.7207, F1 Micro: 0.7207, F1 Macro: 0.5654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5134, Accuracy: 0.8212, F1 Micro: 0.8212, F1 Macro: 0.7625\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4102, Accuracy: 0.8883, F1 Micro: 0.8883, F1 Macro: 0.8688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3159, Accuracy: 0.8939, F1 Micro: 0.8939, F1 Macro: 0.8734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2019, Accuracy: 0.905, F1 Micro: 0.905, F1 Macro: 0.889\n",
      "Epoch 8/10, Train Loss: 0.1706, Accuracy: 0.8994, F1 Micro: 0.8994, F1 Macro: 0.8831\n",
      "Epoch 9/10, Train Loss: 0.1707, Accuracy: 0.8994, F1 Micro: 0.8994, F1 Macro: 0.8807\n",
      "Epoch 10/10, Train Loss: 0.1205, Accuracy: 0.8827, F1 Micro: 0.8827, F1 Macro: 0.8719\n",
      "\n",
      "Sentiment analysis accuracy: 0.905, F1 Micro: 0.905, F1 Macro: 0.889\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.81      0.85        58\n",
      "    positive       0.91      0.95      0.93       121\n",
      "\n",
      "    accuracy                           0.91       179\n",
      "   macro avg       0.90      0.88      0.89       179\n",
      "weighted avg       0.90      0.91      0.90       179\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 136: Accuracy: 0.8912, F1 Micro: 0.8912, F1 Macro: 0.7512\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      1.00      0.85        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.75      0.86        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.92      0.90       216\n",
      "weighted avg       0.98      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.69      0.73        16\n",
      "     neutral       0.91      0.95      0.93       167\n",
      "    positive       0.75      0.64      0.69        33\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.82      0.76      0.78       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.57      0.67      0.62        12\n",
      "     neutral       0.84      0.97      0.90       152\n",
      "    positive       0.84      0.40      0.55        52\n",
      "\n",
      "    accuracy                           0.82       216\n",
      "   macro avg       0.75      0.68      0.69       216\n",
      "weighted avg       0.82      0.82      0.80       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.35      0.48        23\n",
      "     neutral       0.80      0.99      0.88       152\n",
      "    positive       0.95      0.44      0.60        41\n",
      "\n",
      "    accuracy                           0.81       216\n",
      "   macro avg       0.85      0.59      0.66       216\n",
      "weighted avg       0.83      0.81      0.79       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.95      0.99      0.97       186\n",
      "    positive       0.70      0.41      0.52        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.86      0.75      0.79       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.29      0.44        14\n",
      "     neutral       0.92      1.00      0.96       185\n",
      "    positive       0.90      0.53      0.67        17\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.94      0.61      0.69       216\n",
      "weighted avg       0.92      0.92      0.90       216\n",
      "\n",
      "Total train time: 73.01700472831726 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.012399231269955638\n",
      "Acquired samples: 73\n",
      "Sampling duration: 14.187742233276367 seconds\n",
      "New train size: 209\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6065, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5179, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5036, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4734, Accuracy: 0.8036, F1 Micro: 0.8892, F1 Macro: 0.8876\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4309, Accuracy: 0.8177, F1 Micro: 0.8949, F1 Macro: 0.893\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3432, Accuracy: 0.8542, F1 Micro: 0.9127, F1 Macro: 0.9096\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3135, Accuracy: 0.8936, F1 Micro: 0.935, F1 Macro: 0.9325\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2625, Accuracy: 0.9092, F1 Micro: 0.9444, F1 Macro: 0.9421\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2118, Accuracy: 0.9263, F1 Micro: 0.9544, F1 Macro: 0.952\n",
      "Epoch 10/10, Train Loss: 0.1804, Accuracy: 0.9144, F1 Micro: 0.9469, F1 Macro: 0.9433\n",
      "\n",
      "Aspect detection accuracy: 0.9263, F1 Micro: 0.9544, F1 Macro: 0.952\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.93      0.96      0.94       175\n",
      "      others       0.89      0.90      0.90       158\n",
      "        part       0.87      0.99      0.93       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.95      0.99      0.97       191\n",
      "\n",
      "   micro avg       0.93      0.98      0.95      1061\n",
      "   macro avg       0.93      0.97      0.95      1061\n",
      "weighted avg       0.94      0.98      0.95      1061\n",
      " samples avg       0.94      0.98      0.95      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5792, Accuracy: 0.6947, F1 Micro: 0.6947, F1 Macro: 0.4099\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4216, Accuracy: 0.6947, F1 Micro: 0.6947, F1 Macro: 0.4099\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3337, Accuracy: 0.8451, F1 Micro: 0.8451, F1 Macro: 0.7982\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2261, Accuracy: 0.8982, F1 Micro: 0.8982, F1 Macro: 0.8741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1694, Accuracy: 0.9071, F1 Micro: 0.9071, F1 Macro: 0.8918\n",
      "Epoch 6/10, Train Loss: 0.128, Accuracy: 0.8938, F1 Micro: 0.8938, F1 Macro: 0.8738\n",
      "Epoch 7/10, Train Loss: 0.1296, Accuracy: 0.885, F1 Micro: 0.885, F1 Macro: 0.8569\n",
      "Epoch 8/10, Train Loss: 0.0858, Accuracy: 0.8982, F1 Micro: 0.8982, F1 Macro: 0.8764\n",
      "Epoch 9/10, Train Loss: 0.0916, Accuracy: 0.8938, F1 Micro: 0.8938, F1 Macro: 0.8727\n",
      "Epoch 10/10, Train Loss: 0.0597, Accuracy: 0.885, F1 Micro: 0.885, F1 Macro: 0.8609\n",
      "\n",
      "Sentiment analysis accuracy: 0.9071, F1 Micro: 0.9071, F1 Macro: 0.8918\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.87      0.85        69\n",
      "    positive       0.94      0.92      0.93       157\n",
      "\n",
      "    accuracy                           0.91       226\n",
      "   macro avg       0.89      0.90      0.89       226\n",
      "weighted avg       0.91      0.91      0.91       226\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 209: Accuracy: 0.9012, F1 Micro: 0.9012, F1 Macro: 0.7872\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.56      0.67        16\n",
      "     neutral       0.93      0.96      0.94       167\n",
      "    positive       0.71      0.67      0.69        33\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.82      0.73      0.77       216\n",
      "weighted avg       0.88      0.89      0.88       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.31      0.67      0.42        12\n",
      "     neutral       0.89      0.83      0.86       152\n",
      "    positive       0.71      0.67      0.69        52\n",
      "\n",
      "    accuracy                           0.78       216\n",
      "   macro avg       0.64      0.72      0.66       216\n",
      "weighted avg       0.82      0.78      0.80       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.48      0.63        23\n",
      "     neutral       0.86      0.99      0.92       152\n",
      "    positive       0.86      0.61      0.71        41\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.88      0.69      0.76       216\n",
      "weighted avg       0.87      0.87      0.85       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.54      0.70        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.68      0.76      0.72        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.89      0.77      0.80       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.64      0.75        14\n",
      "     neutral       0.95      0.99      0.97       185\n",
      "    positive       0.75      0.53      0.62        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.87      0.72      0.78       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Total train time: 79.8388409614563 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.010192002169787884\n",
      "Acquired samples: 66\n",
      "Sampling duration: 14.907765626907349 seconds\n",
      "New train size: 275\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5964, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4979, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4847, Accuracy: 0.7984, F1 Micro: 0.8867, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4199, Accuracy: 0.8289, F1 Micro: 0.9001, F1 Macro: 0.8979\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.356, Accuracy: 0.8757, F1 Micro: 0.9251, F1 Macro: 0.9223\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2886, Accuracy: 0.9129, F1 Micro: 0.946, F1 Macro: 0.9431\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2408, Accuracy: 0.9278, F1 Micro: 0.9552, F1 Macro: 0.9526\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1896, Accuracy: 0.9368, F1 Micro: 0.9606, F1 Macro: 0.9582\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1536, Accuracy: 0.9412, F1 Micro: 0.9633, F1 Macro: 0.9612\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1284, Accuracy: 0.9427, F1 Micro: 0.9642, F1 Macro: 0.9623\n",
      "\n",
      "Aspect detection accuracy: 0.9427, F1 Micro: 0.9642, F1 Macro: 0.9623\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.96      0.95       175\n",
      "      others       0.88      0.92      0.90       158\n",
      "        part       0.93      0.98      0.96       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.96      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.95      0.98      0.96      1061\n",
      "   macro avg       0.95      0.98      0.96      1061\n",
      "weighted avg       0.95      0.98      0.96      1061\n",
      " samples avg       0.95      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5565, Accuracy: 0.7449, F1 Micro: 0.7449, F1 Macro: 0.6776\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4151, Accuracy: 0.8519, F1 Micro: 0.8519, F1 Macro: 0.8333\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2812, Accuracy: 0.9012, F1 Micro: 0.9012, F1 Macro: 0.8914\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2309, Accuracy: 0.9177, F1 Micro: 0.9177, F1 Macro: 0.908\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1845, Accuracy: 0.9177, F1 Micro: 0.9177, F1 Macro: 0.9043\n",
      "Epoch 6/10, Train Loss: 0.1197, Accuracy: 0.9136, F1 Micro: 0.9136, F1 Macro: 0.9042\n",
      "Epoch 7/10, Train Loss: 0.141, Accuracy: 0.9136, F1 Micro: 0.9136, F1 Macro: 0.9025\n",
      "Epoch 8/10, Train Loss: 0.1598, Accuracy: 0.9053, F1 Micro: 0.9053, F1 Macro: 0.8938\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1302, Accuracy: 0.9177, F1 Micro: 0.9177, F1 Macro: 0.9074\n",
      "Epoch 10/10, Train Loss: 0.1159, Accuracy: 0.893, F1 Micro: 0.893, F1 Macro: 0.8853\n",
      "\n",
      "Sentiment analysis accuracy: 0.9177, F1 Micro: 0.9177, F1 Macro: 0.9074\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.90      0.88        79\n",
      "    positive       0.95      0.93      0.94       164\n",
      "\n",
      "    accuracy                           0.92       243\n",
      "   macro avg       0.90      0.91      0.91       243\n",
      "weighted avg       0.92      0.92      0.92       243\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 275: Accuracy: 0.9275, F1 Micro: 0.9275, F1 Macro: 0.8514\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.88      0.93        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.88      0.80        16\n",
      "     neutral       0.95      0.96      0.96       167\n",
      "    positive       0.85      0.70      0.77        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.85      0.85      0.84       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.67      0.57        12\n",
      "     neutral       0.88      0.92      0.90       152\n",
      "    positive       0.76      0.60      0.67        52\n",
      "\n",
      "    accuracy                           0.83       216\n",
      "   macro avg       0.71      0.73      0.71       216\n",
      "weighted avg       0.83      0.83      0.83       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.87      0.80        23\n",
      "     neutral       0.93      0.98      0.96       152\n",
      "    positive       0.93      0.66      0.77        41\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.87      0.84      0.84       216\n",
      "weighted avg       0.91      0.91      0.90       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.89      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.86      0.86        14\n",
      "     neutral       0.96      1.00      0.98       185\n",
      "    positive       1.00      0.53      0.69        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.94      0.80      0.84       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Total train time: 89.52580571174622 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.007692150212824345\n",
      "Acquired samples: 59\n",
      "Sampling duration: 13.729244232177734 seconds\n",
      "New train size: 334\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5747, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4925, Accuracy: 0.7917, F1 Micro: 0.8833, F1 Macro: 0.8818\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4558, Accuracy: 0.8147, F1 Micro: 0.8935, F1 Macro: 0.8913\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3822, Accuracy: 0.875, F1 Micro: 0.9244, F1 Macro: 0.9218\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3108, Accuracy: 0.9048, F1 Micro: 0.9413, F1 Macro: 0.9381\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2403, Accuracy: 0.936, F1 Micro: 0.9601, F1 Macro: 0.9579\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1859, Accuracy: 0.939, F1 Micro: 0.9619, F1 Macro: 0.9597\n",
      "Epoch 8/10, Train Loss: 0.152, Accuracy: 0.939, F1 Micro: 0.9615, F1 Macro: 0.9581\n",
      "Epoch 9/10, Train Loss: 0.1232, Accuracy: 0.9301, F1 Micro: 0.9558, F1 Macro: 0.9512\n",
      "Epoch 10/10, Train Loss: 0.0984, Accuracy: 0.9345, F1 Micro: 0.959, F1 Macro: 0.9555\n",
      "\n",
      "Aspect detection accuracy: 0.939, F1 Micro: 0.9619, F1 Macro: 0.9597\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.94      0.96      0.95       175\n",
      "      others       0.89      0.91      0.90       158\n",
      "        part       0.92      0.97      0.95       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.95      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.95      0.98      0.96      1061\n",
      "   macro avg       0.95      0.97      0.96      1061\n",
      "weighted avg       0.95      0.98      0.96      1061\n",
      " samples avg       0.95      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5779, Accuracy: 0.6749, F1 Micro: 0.6749, F1 Macro: 0.4029\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3653, Accuracy: 0.8807, F1 Micro: 0.8807, F1 Macro: 0.8626\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2394, Accuracy: 0.9012, F1 Micro: 0.9012, F1 Macro: 0.8936\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.137, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9229\n",
      "Epoch 5/10, Train Loss: 0.154, Accuracy: 0.9177, F1 Micro: 0.9177, F1 Macro: 0.9056\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1153, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9215\n",
      "Epoch 7/10, Train Loss: 0.1328, Accuracy: 0.9095, F1 Micro: 0.9095, F1 Macro: 0.8931\n",
      "Epoch 8/10, Train Loss: 0.1184, Accuracy: 0.9259, F1 Micro: 0.9259, F1 Macro: 0.9161\n",
      "Epoch 9/10, Train Loss: 0.0626, Accuracy: 0.8971, F1 Micro: 0.8971, F1 Macro: 0.8761\n",
      "Epoch 10/10, Train Loss: 0.0794, Accuracy: 0.9177, F1 Micro: 0.9177, F1 Macro: 0.9049\n",
      "\n",
      "Sentiment analysis accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9215\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.92      0.90        79\n",
      "    positive       0.96      0.93      0.95       164\n",
      "\n",
      "    accuracy                           0.93       243\n",
      "   macro avg       0.92      0.93      0.92       243\n",
      "weighted avg       0.93      0.93      0.93       243\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 334: Accuracy: 0.9174, F1 Micro: 0.9174, F1 Macro: 0.8317\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.94      0.96      0.95       167\n",
      "    positive       0.77      0.70      0.73        33\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.86      0.82      0.84       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.32      0.92      0.48        12\n",
      "     neutral       0.95      0.82      0.88       152\n",
      "    positive       0.74      0.71      0.73        52\n",
      "\n",
      "    accuracy                           0.80       216\n",
      "   macro avg       0.67      0.82      0.69       216\n",
      "weighted avg       0.86      0.80      0.82       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.70      0.73        23\n",
      "     neutral       0.93      0.97      0.95       152\n",
      "    positive       0.77      0.66      0.71        41\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.82      0.78      0.80       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.89      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.64      0.64        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       0.79      0.65      0.71        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.80      0.76      0.78       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Total train time: 88.49112677574158 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.008384198881685734\n",
      "Acquired samples: 54\n",
      "Sampling duration: 12.355499267578125 seconds\n",
      "New train size: 388\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5535, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.488, Accuracy: 0.7999, F1 Micro: 0.8875, F1 Macro: 0.886\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4226, Accuracy: 0.8259, F1 Micro: 0.8979, F1 Macro: 0.8946\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3509, Accuracy: 0.9033, F1 Micro: 0.9403, F1 Macro: 0.9373\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2549, Accuracy: 0.9375, F1 Micro: 0.9612, F1 Macro: 0.9596\n",
      "Epoch 6/10, Train Loss: 0.1947, Accuracy: 0.936, F1 Micro: 0.9598, F1 Macro: 0.957\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.152, Accuracy: 0.942, F1 Micro: 0.9632, F1 Macro: 0.9598\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1121, Accuracy: 0.9509, F1 Micro: 0.9692, F1 Macro: 0.9672\n",
      "Epoch 9/10, Train Loss: 0.0989, Accuracy: 0.9509, F1 Micro: 0.969, F1 Macro: 0.9664\n",
      "Epoch 10/10, Train Loss: 0.0814, Accuracy: 0.9487, F1 Micro: 0.9675, F1 Macro: 0.9647\n",
      "\n",
      "Aspect detection accuracy: 0.9509, F1 Micro: 0.9692, F1 Macro: 0.9672\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.97      0.96       175\n",
      "      others       0.92      0.91      0.92       158\n",
      "        part       0.92      0.99      0.95       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5692, Accuracy: 0.8386, F1 Micro: 0.8386, F1 Macro: 0.8182\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3537, Accuracy: 0.9016, F1 Micro: 0.9016, F1 Macro: 0.8922\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1878, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.9044\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2055, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9126\n",
      "Epoch 5/10, Train Loss: 0.103, Accuracy: 0.8898, F1 Micro: 0.8898, F1 Macro: 0.8813\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1209, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9176\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1222, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9136\n",
      "Epoch 8/10, Train Loss: 0.0743, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9105\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1025, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9213\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0596, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9293\n",
      "\n",
      "Sentiment analysis accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9293\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.94      0.91        82\n",
      "    positive       0.97      0.94      0.95       172\n",
      "\n",
      "    accuracy                           0.94       254\n",
      "   macro avg       0.92      0.94      0.93       254\n",
      "weighted avg       0.94      0.94      0.94       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 388: Accuracy: 0.9321, F1 Micro: 0.9321, F1 Macro: 0.8701\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.88      0.82        16\n",
      "     neutral       0.95      0.96      0.96       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.85      0.86      0.86       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.34      0.83      0.49        12\n",
      "     neutral       0.95      0.84      0.89       152\n",
      "    positive       0.77      0.77      0.77        52\n",
      "\n",
      "    accuracy                           0.82       216\n",
      "   macro avg       0.69      0.81      0.72       216\n",
      "weighted avg       0.87      0.82      0.84       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.68      0.91      0.78        23\n",
      "     neutral       0.95      0.99      0.97       152\n",
      "    positive       0.96      0.63      0.76        41\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.86      0.84      0.84       216\n",
      "weighted avg       0.92      0.91      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.98       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.89      0.94      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 99.32910513877869 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.006748074386268854\n",
      "Acquired samples: 48\n",
      "Sampling duration: 11.651993751525879 seconds\n",
      "New train size: 436\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5465, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.483, Accuracy: 0.8021, F1 Micro: 0.8886, F1 Macro: 0.8872\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4272, Accuracy: 0.8542, F1 Micro: 0.9134, F1 Macro: 0.911\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3314, Accuracy: 0.9137, F1 Micro: 0.9462, F1 Macro: 0.9428\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2484, Accuracy: 0.9397, F1 Micro: 0.9623, F1 Macro: 0.9604\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1914, Accuracy: 0.9479, F1 Micro: 0.9675, F1 Macro: 0.9658\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1524, Accuracy: 0.9561, F1 Micro: 0.9724, F1 Macro: 0.9709\n",
      "Epoch 8/10, Train Loss: 0.1132, Accuracy: 0.9479, F1 Micro: 0.967, F1 Macro: 0.9636\n",
      "Epoch 9/10, Train Loss: 0.0972, Accuracy: 0.9546, F1 Micro: 0.9713, F1 Macro: 0.969\n",
      "Epoch 10/10, Train Loss: 0.0767, Accuracy: 0.9539, F1 Micro: 0.9709, F1 Macro: 0.9684\n",
      "\n",
      "Aspect detection accuracy: 0.9561, F1 Micro: 0.9724, F1 Macro: 0.9709\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.97      0.97       175\n",
      "      others       0.90      0.95      0.93       158\n",
      "        part       0.97      0.96      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5657, Accuracy: 0.821, F1 Micro: 0.821, F1 Macro: 0.78\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3212, Accuracy: 0.8833, F1 Micro: 0.8833, F1 Macro: 0.8736\n",
      "Epoch 3/10, Train Loss: 0.2192, Accuracy: 0.8599, F1 Micro: 0.8599, F1 Macro: 0.8497\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1276, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9204\n",
      "Epoch 5/10, Train Loss: 0.1569, Accuracy: 0.8872, F1 Micro: 0.8872, F1 Macro: 0.877\n",
      "Epoch 6/10, Train Loss: 0.1207, Accuracy: 0.9105, F1 Micro: 0.9105, F1 Macro: 0.8953\n",
      "Epoch 7/10, Train Loss: 0.1211, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.9039\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.08, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9172\n",
      "Epoch 9/10, Train Loss: 0.0778, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9141\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0701, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9204\n",
      "\n",
      "Sentiment analysis accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9204\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.94      0.89        80\n",
      "    positive       0.97      0.93      0.95       177\n",
      "\n",
      "    accuracy                           0.93       257\n",
      "   macro avg       0.91      0.93      0.92       257\n",
      "weighted avg       0.93      0.93      0.93       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 436: Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.8804\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.96      0.97      0.96       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.87      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.33      0.92      0.49        12\n",
      "     neutral       0.96      0.86      0.91       152\n",
      "    positive       0.85      0.75      0.80        52\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.71      0.84      0.73       216\n",
      "weighted avg       0.90      0.84      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.91      0.82        23\n",
      "     neutral       0.97      0.96      0.96       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.91      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.89      0.94      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 100.0983464717865 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.005115563608705997\n",
      "Acquired samples: 43\n",
      "Sampling duration: 10.432772397994995 seconds\n",
      "New train size: 479\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.562, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.485, Accuracy: 0.8058, F1 Micro: 0.8905, F1 Macro: 0.889\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4114, Accuracy: 0.8571, F1 Micro: 0.9125, F1 Macro: 0.9066\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3068, Accuracy: 0.9249, F1 Micro: 0.9531, F1 Macro: 0.9506\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2165, Accuracy: 0.942, F1 Micro: 0.964, F1 Macro: 0.9621\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1784, Accuracy: 0.9449, F1 Micro: 0.9656, F1 Macro: 0.9635\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1307, Accuracy: 0.9531, F1 Micro: 0.9704, F1 Macro: 0.9681\n",
      "Epoch 8/10, Train Loss: 0.1078, Accuracy: 0.9524, F1 Micro: 0.9701, F1 Macro: 0.968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0906, Accuracy: 0.9554, F1 Micro: 0.972, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0701, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9721\n",
      "\n",
      "Aspect detection accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9721\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.90      0.95      0.92       158\n",
      "        part       0.97      0.97      0.97       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5626, Accuracy: 0.8071, F1 Micro: 0.8071, F1 Macro: 0.7551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2761, Accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.9069\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1936, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9195\n",
      "Epoch 4/10, Train Loss: 0.1685, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9135\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1222, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9237\n",
      "Epoch 6/10, Train Loss: 0.1278, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9126\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1139, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9275\n",
      "Epoch 8/10, Train Loss: 0.079, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9213\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0757, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9377\n",
      "Epoch 10/10, Train Loss: 0.0536, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9322\n",
      "\n",
      "Sentiment analysis accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9377\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.95      0.92        81\n",
      "    positive       0.98      0.94      0.96       173\n",
      "\n",
      "    accuracy                           0.94       254\n",
      "   macro avg       0.93      0.95      0.94       254\n",
      "weighted avg       0.95      0.94      0.95       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 479: Accuracy: 0.9491, F1 Micro: 0.9491, F1 Macro: 0.8964\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.98      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.88      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.87      0.86      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.67      0.76        12\n",
      "     neutral       0.90      0.95      0.92       152\n",
      "    positive       0.83      0.75      0.79        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.87      0.79      0.82       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.93      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.87      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.93      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 108.12268090248108 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.004992398200556636\n",
      "Acquired samples: 39\n",
      "Sampling duration: 9.761188268661499 seconds\n",
      "New train size: 518\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5456, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4733, Accuracy: 0.8147, F1 Micro: 0.8937, F1 Macro: 0.8918\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3808, Accuracy: 0.8958, F1 Micro: 0.936, F1 Macro: 0.9327\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2702, Accuracy: 0.9338, F1 Micro: 0.9586, F1 Macro: 0.9564\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1966, Accuracy: 0.9442, F1 Micro: 0.9651, F1 Macro: 0.9628\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1484, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9742\n",
      "Epoch 7/10, Train Loss: 0.1169, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9713\n",
      "Epoch 8/10, Train Loss: 0.0954, Accuracy: 0.9554, F1 Micro: 0.9719, F1 Macro: 0.9695\n",
      "Epoch 9/10, Train Loss: 0.0805, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.972\n",
      "Epoch 10/10, Train Loss: 0.0654, Accuracy: 0.9561, F1 Micro: 0.9724, F1 Macro: 0.9705\n",
      "\n",
      "Aspect detection accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9742\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.91      0.96      0.94       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.97      1061\n",
      "weighted avg       0.96      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5433, Accuracy: 0.8664, F1 Micro: 0.8664, F1 Macro: 0.8414\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2871, Accuracy: 0.8988, F1 Micro: 0.8988, F1 Macro: 0.8899\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1722, Accuracy: 0.9312, F1 Micro: 0.9312, F1 Macro: 0.9195\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1291, Accuracy: 0.9393, F1 Micro: 0.9393, F1 Macro: 0.9322\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0781, Accuracy: 0.9433, F1 Micro: 0.9433, F1 Macro: 0.9349\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1112, Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.9452\n",
      "Epoch 7/10, Train Loss: 0.0693, Accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9408\n",
      "Epoch 8/10, Train Loss: 0.0806, Accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9405\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0505, Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.9445\n",
      "Epoch 10/10, Train Loss: 0.0428, Accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9405\n",
      "\n",
      "Sentiment analysis accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.9445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.94      0.92        79\n",
      "    positive       0.97      0.96      0.96       168\n",
      "\n",
      "    accuracy                           0.95       247\n",
      "   macro avg       0.94      0.95      0.94       247\n",
      "weighted avg       0.95      0.95      0.95       247\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 518: Accuracy: 0.946, F1 Micro: 0.946, F1 Macro: 0.8924\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.85      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.44      0.92      0.59        12\n",
      "     neutral       0.94      0.90      0.92       152\n",
      "    positive       0.89      0.79      0.84        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.76      0.87      0.78       216\n",
      "weighted avg       0.90      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.87      0.80        23\n",
      "     neutral       0.96      0.98      0.97       152\n",
      "    positive       0.94      0.78      0.85        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.88      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.98       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 108.45046305656433 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.004527782835066319\n",
      "Acquired samples: 22\n",
      "Sampling duration: 8.699082136154175 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5481, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4598, Accuracy: 0.8147, F1 Micro: 0.8926, F1 Macro: 0.8899\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3711, Accuracy: 0.8988, F1 Micro: 0.9373, F1 Macro: 0.9342\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2713, Accuracy: 0.9382, F1 Micro: 0.9613, F1 Macro: 0.9597\n",
      "Epoch 5/10, Train Loss: 0.2031, Accuracy: 0.936, F1 Micro: 0.9595, F1 Macro: 0.954\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1486, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1143, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.973\n",
      "Epoch 8/10, Train Loss: 0.0987, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0771, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9745\n",
      "Epoch 10/10, Train Loss: 0.0674, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9729\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9745\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.97      0.97       175\n",
      "      others       0.90      0.95      0.92       158\n",
      "        part       0.96      1.00      0.98       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.97      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5571, Accuracy: 0.88, F1 Micro: 0.88, F1 Macro: 0.8663\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2589, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9383\n",
      "Epoch 3/10, Train Loss: 0.1976, Accuracy: 0.916, F1 Micro: 0.916, F1 Macro: 0.9095\n",
      "Epoch 4/10, Train Loss: 0.1282, Accuracy: 0.916, F1 Micro: 0.916, F1 Macro: 0.9095\n",
      "Epoch 5/10, Train Loss: 0.1247, Accuracy: 0.932, F1 Micro: 0.932, F1 Macro: 0.926\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1021, Accuracy: 0.952, F1 Micro: 0.952, F1 Macro: 0.9471\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0954, Accuracy: 0.952, F1 Micro: 0.952, F1 Macro: 0.9465\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0864, Accuracy: 0.952, F1 Micro: 0.952, F1 Macro: 0.9465\n",
      "Epoch 9/10, Train Loss: 0.0636, Accuracy: 0.948, F1 Micro: 0.948, F1 Macro: 0.9405\n",
      "Epoch 10/10, Train Loss: 0.066, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9361\n",
      "\n",
      "Sentiment analysis accuracy: 0.952, F1 Micro: 0.952, F1 Macro: 0.9465\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93        83\n",
      "    positive       0.98      0.95      0.96       167\n",
      "\n",
      "    accuracy                           0.95       250\n",
      "   macro avg       0.94      0.95      0.95       250\n",
      "weighted avg       0.95      0.95      0.95       250\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9475, F1 Micro: 0.9475, F1 Macro: 0.8879\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.92      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.88      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.97      0.97      0.97       167\n",
      "    positive       0.85      0.85      0.85        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.90      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.44      0.92      0.59        12\n",
      "     neutral       0.95      0.91      0.93       152\n",
      "    positive       0.84      0.73      0.78        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.74      0.85      0.77       216\n",
      "weighted avg       0.89      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87        23\n",
      "     neutral       0.96      0.99      0.98       152\n",
      "    positive       0.92      0.80      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.89      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.87      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.93      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 108.91693663597107 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.0029448454733937983\n",
      "Acquired samples: 33\n",
      "Sampling duration: 8.296834230422974 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5366, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4634, Accuracy: 0.8207, F1 Micro: 0.8964, F1 Macro: 0.8946\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.373, Accuracy: 0.904, F1 Micro: 0.94, F1 Macro: 0.936\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2663, Accuracy: 0.9427, F1 Micro: 0.9641, F1 Macro: 0.9624\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1995, Accuracy: 0.9546, F1 Micro: 0.9717, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1488, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9732\n",
      "Epoch 7/10, Train Loss: 0.1169, Accuracy: 0.9554, F1 Micro: 0.9721, F1 Macro: 0.9703\n",
      "Epoch 8/10, Train Loss: 0.0985, Accuracy: 0.9576, F1 Micro: 0.9732, F1 Macro: 0.9712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0773, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "Epoch 10/10, Train Loss: 0.0677, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9723\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.93      0.94      0.94       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5369, Accuracy: 0.8828, F1 Micro: 0.8828, F1 Macro: 0.8715\n",
      "Epoch 2/10, Train Loss: 0.2648, Accuracy: 0.8789, F1 Micro: 0.8789, F1 Macro: 0.8721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2026, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8956\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.132, Accuracy: 0.9141, F1 Micro: 0.9141, F1 Macro: 0.9071\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1532, Accuracy: 0.9141, F1 Micro: 0.9141, F1 Macro: 0.9067\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1363, Accuracy: 0.9258, F1 Micro: 0.9258, F1 Macro: 0.9175\n",
      "Epoch 7/10, Train Loss: 0.1071, Accuracy: 0.918, F1 Micro: 0.918, F1 Macro: 0.9093\n",
      "Epoch 8/10, Train Loss: 0.0813, Accuracy: 0.9102, F1 Micro: 0.9102, F1 Macro: 0.9031\n",
      "Epoch 9/10, Train Loss: 0.0845, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8952\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0833, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9249\n",
      "\n",
      "Sentiment analysis accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9249\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.89      0.90        85\n",
      "    positive       0.95      0.95      0.95       171\n",
      "\n",
      "    accuracy                           0.93       256\n",
      "   macro avg       0.93      0.92      0.92       256\n",
      "weighted avg       0.93      0.93      0.93       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.946, F1 Micro: 0.946, F1 Macro: 0.886\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.73      0.80        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.84      0.88      0.86        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.87      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.85      0.70      0.77        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.83      0.86       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.83      0.62        12\n",
      "     neutral       0.95      0.91      0.93       152\n",
      "    positive       0.82      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.76      0.84      0.79       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.91      0.86        23\n",
      "     neutral       0.96      0.97      0.96       152\n",
      "    positive       0.92      0.83      0.87        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.90      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 116.07101130485535 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.00426389086060226\n",
      "Acquired samples: 30\n",
      "Sampling duration: 7.718360900878906 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5454, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4536, Accuracy: 0.8251, F1 Micro: 0.8988, F1 Macro: 0.8968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3422, Accuracy: 0.9278, F1 Micro: 0.9556, F1 Macro: 0.9536\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2394, Accuracy: 0.9501, F1 Micro: 0.9688, F1 Macro: 0.9671\n",
      "Epoch 5/10, Train Loss: 0.1726, Accuracy: 0.9494, F1 Micro: 0.9683, F1 Macro: 0.9662\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1356, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1102, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.975\n",
      "Epoch 8/10, Train Loss: 0.0911, Accuracy: 0.9554, F1 Micro: 0.9719, F1 Macro: 0.9699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0737, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0602, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.96      0.99      0.97       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4984, Accuracy: 0.8906, F1 Micro: 0.8906, F1 Macro: 0.8818\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2587, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.93\n",
      "Epoch 3/10, Train Loss: 0.1661, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8947\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1225, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9387\n",
      "Epoch 5/10, Train Loss: 0.1428, Accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.8991\n",
      "Epoch 6/10, Train Loss: 0.105, Accuracy: 0.9258, F1 Micro: 0.9258, F1 Macro: 0.9139\n",
      "Epoch 7/10, Train Loss: 0.0861, Accuracy: 0.9297, F1 Micro: 0.9297, F1 Macro: 0.9212\n",
      "Epoch 8/10, Train Loss: 0.0724, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9287\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0683, Accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9433\n",
      "Epoch 10/10, Train Loss: 0.0463, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9249\n",
      "\n",
      "Sentiment analysis accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9433\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.96      0.92        83\n",
      "    positive       0.98      0.94      0.96       173\n",
      "\n",
      "    accuracy                           0.95       256\n",
      "   macro avg       0.94      0.95      0.94       256\n",
      "weighted avg       0.95      0.95      0.95       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9058\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.82      0.86        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.88      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.90      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.87      0.86      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.85      0.79      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.87      0.83      0.85       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.96      0.99      0.97       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.91      0.91       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 117.17585778236389 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.003615477913990617\n",
      "Acquired samples: 27\n",
      "Sampling duration: 6.875966787338257 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5448, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.448, Accuracy: 0.8244, F1 Micro: 0.8982, F1 Macro: 0.8964\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3288, Accuracy: 0.9226, F1 Micro: 0.9518, F1 Macro: 0.9487\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2343, Accuracy: 0.9494, F1 Micro: 0.9686, F1 Macro: 0.9671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1746, Accuracy: 0.9568, F1 Micro: 0.9731, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1321, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0998, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9756\n",
      "Epoch 8/10, Train Loss: 0.0728, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0617, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0568, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.976\n",
      "\n",
      "Aspect detection accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.93      0.92      0.93       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5247, Accuracy: 0.9035, F1 Micro: 0.9035, F1 Macro: 0.8933\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2576, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9353\n",
      "Epoch 3/10, Train Loss: 0.1943, Accuracy: 0.9035, F1 Micro: 0.9035, F1 Macro: 0.8968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1302, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9401\n",
      "Epoch 5/10, Train Loss: 0.1157, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9241\n",
      "Epoch 6/10, Train Loss: 0.1446, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9366\n",
      "Epoch 7/10, Train Loss: 0.084, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9312\n",
      "Epoch 8/10, Train Loss: 0.0948, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.936\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0657, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9398\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0503, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9398\n",
      "\n",
      "Sentiment analysis accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9398\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        86\n",
      "    positive       0.97      0.95      0.96       173\n",
      "\n",
      "    accuracy                           0.95       259\n",
      "   macro avg       0.94      0.94      0.94       259\n",
      "weighted avg       0.95      0.95      0.95       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9122\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.99      0.97       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.88      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.93      0.92      0.93       152\n",
      "    positive       0.77      0.79      0.78        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.83      0.85      0.84       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.96      0.99      0.97       152\n",
      "    positive       0.97      0.76      0.85        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.94      0.92      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.88      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 124.01315450668335 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.003935916163027286\n",
      "Acquired samples: 18\n",
      "Sampling duration: 6.262045383453369 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5379, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.441, Accuracy: 0.846, F1 Micro: 0.9089, F1 Macro: 0.9068\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3227, Accuracy: 0.9301, F1 Micro: 0.9566, F1 Macro: 0.9542\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2167, Accuracy: 0.9561, F1 Micro: 0.9728, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.156, Accuracy: 0.9583, F1 Micro: 0.974, F1 Macro: 0.9726\n",
      "Epoch 6/10, Train Loss: 0.1127, Accuracy: 0.9539, F1 Micro: 0.9709, F1 Macro: 0.9688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0952, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9754\n",
      "Epoch 8/10, Train Loss: 0.0748, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.975\n",
      "Epoch 9/10, Train Loss: 0.0638, Accuracy: 0.9613, F1 Micro: 0.9755, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.051, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9765\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.94      0.92      0.93       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5314, Accuracy: 0.8958, F1 Micro: 0.8958, F1 Macro: 0.8875\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2838, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9304\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.173, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9326\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.13, Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9445\n",
      "Epoch 5/10, Train Loss: 0.1087, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9391\n",
      "Epoch 6/10, Train Loss: 0.0933, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9315\n",
      "Epoch 7/10, Train Loss: 0.0936, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9353\n",
      "Epoch 8/10, Train Loss: 0.0644, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9262\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0812, Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9445\n",
      "Epoch 10/10, Train Loss: 0.0582, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9333\n",
      "\n",
      "Sentiment analysis accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.97      0.93        86\n",
      "    positive       0.98      0.94      0.96       173\n",
      "\n",
      "    accuracy                           0.95       259\n",
      "   macro avg       0.94      0.95      0.94       259\n",
      "weighted avg       0.95      0.95      0.95       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9095\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.87      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.75      0.86        12\n",
      "     neutral       0.94      0.93      0.93       152\n",
      "    positive       0.77      0.85      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.90      0.84      0.87       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.87      0.89        23\n",
      "     neutral       0.96      0.99      0.98       152\n",
      "    positive       0.89      0.80      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.89      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 126.12984037399292 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.002108126599341631\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.942375183105469 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.533, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4261, Accuracy: 0.8631, F1 Micro: 0.9184, F1 Macro: 0.9158\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2923, Accuracy: 0.9353, F1 Micro: 0.9597, F1 Macro: 0.9577\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2008, Accuracy: 0.9568, F1 Micro: 0.9731, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1477, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9721\n",
      "Epoch 6/10, Train Loss: 0.1158, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0906, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0689, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0576, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.977\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0534, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9772\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9772\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.96      0.98      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5146, Accuracy: 0.8803, F1 Micro: 0.8803, F1 Macro: 0.8677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2509, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9274\n",
      "Epoch 3/10, Train Loss: 0.2055, Accuracy: 0.8996, F1 Micro: 0.8996, F1 Macro: 0.8808\n",
      "Epoch 4/10, Train Loss: 0.1359, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9201\n",
      "Epoch 5/10, Train Loss: 0.1326, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9205\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1291, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9308\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0555, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9398\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0721, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9398\n",
      "Epoch 9/10, Train Loss: 0.0643, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9345\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0682, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9404\n",
      "\n",
      "Sentiment analysis accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9404\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.97      0.92        86\n",
      "    positive       0.98      0.94      0.96       173\n",
      "\n",
      "    accuracy                           0.95       259\n",
      "   macro avg       0.93      0.95      0.94       259\n",
      "weighted avg       0.95      0.95      0.95       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.9237\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.90      0.82      0.86        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.83      0.77      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.89      0.85      0.87       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.96      0.98      0.97       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.92      0.91       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 133.6621286869049 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.0023875507060438397\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.390785455703735 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5263, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4495, Accuracy: 0.8668, F1 Micro: 0.9203, F1 Macro: 0.9178\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3115, Accuracy: 0.9427, F1 Micro: 0.9646, F1 Macro: 0.9631\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2164, Accuracy: 0.9554, F1 Micro: 0.9721, F1 Macro: 0.9708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1536, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1188, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0908, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0737, Accuracy: 0.9665, F1 Micro: 0.9791, F1 Macro: 0.9781\n",
      "Epoch 9/10, Train Loss: 0.0662, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9746\n",
      "Epoch 10/10, Train Loss: 0.0536, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9765\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9791, F1 Macro: 0.9781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.98       175\n",
      "      others       0.90      0.99      0.94       158\n",
      "        part       0.96      0.99      0.97       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5093, Accuracy: 0.9024, F1 Micro: 0.9024, F1 Macro: 0.8963\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.231, Accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.9417\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1719, Accuracy: 0.9553, F1 Micro: 0.9553, F1 Macro: 0.9504\n",
      "Epoch 4/10, Train Loss: 0.1373, Accuracy: 0.9512, F1 Micro: 0.9512, F1 Macro: 0.9458\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1041, Accuracy: 0.9593, F1 Micro: 0.9593, F1 Macro: 0.9551\n",
      "Epoch 6/10, Train Loss: 0.1018, Accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.9421\n",
      "Epoch 7/10, Train Loss: 0.074, Accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.9421\n",
      "Epoch 8/10, Train Loss: 0.0779, Accuracy: 0.939, F1 Micro: 0.939, F1 Macro: 0.9331\n",
      "Epoch 9/10, Train Loss: 0.0616, Accuracy: 0.9512, F1 Micro: 0.9512, F1 Macro: 0.9461\n",
      "Epoch 10/10, Train Loss: 0.0671, Accuracy: 0.9553, F1 Micro: 0.9553, F1 Macro: 0.9507\n",
      "\n",
      "Sentiment analysis accuracy: 0.9593, F1 Micro: 0.9593, F1 Macro: 0.9551\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94        82\n",
      "    positive       0.99      0.95      0.97       164\n",
      "\n",
      "    accuracy                           0.96       246\n",
      "   macro avg       0.95      0.96      0.96       246\n",
      "weighted avg       0.96      0.96      0.96       246\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9041\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.97      0.98      0.98       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.53      0.67      0.59        12\n",
      "     neutral       0.91      0.96      0.93       152\n",
      "    positive       0.95      0.73      0.83        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.80      0.79      0.78       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      1.00      0.85        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.92      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.87      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 127.10772109031677 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.0022491718642413615\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.735049247741699 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5245, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4184, Accuracy: 0.8884, F1 Micro: 0.9328, F1 Macro: 0.9304\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2795, Accuracy: 0.9524, F1 Micro: 0.9705, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1938, Accuracy: 0.9576, F1 Micro: 0.9736, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1414, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9765\n",
      "Epoch 6/10, Train Loss: 0.1046, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9743\n",
      "Epoch 7/10, Train Loss: 0.0821, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9748\n",
      "Epoch 8/10, Train Loss: 0.0712, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9717\n",
      "Epoch 9/10, Train Loss: 0.057, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0483, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9791\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9791\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.93      0.96      0.94       158\n",
      "        part       0.96      0.99      0.97       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4804, Accuracy: 0.898, F1 Micro: 0.898, F1 Macro: 0.891\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2723, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9238\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1851, Accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.9435\n",
      "Epoch 4/10, Train Loss: 0.1647, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9358\n",
      "Epoch 5/10, Train Loss: 0.0977, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.934\n",
      "Epoch 6/10, Train Loss: 0.0703, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9344\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0778, Accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.9438\n",
      "Epoch 8/10, Train Loss: 0.0635, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9332\n",
      "Epoch 9/10, Train Loss: 0.0711, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9306\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0603, Accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.944\n",
      "\n",
      "Sentiment analysis accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.944\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.97      0.93        86\n",
      "    positive       0.98      0.94      0.96       169\n",
      "\n",
      "    accuracy                           0.95       255\n",
      "   macro avg       0.94      0.95      0.94       255\n",
      "weighted avg       0.95      0.95      0.95       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9216\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.99      0.97       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.88      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.93      0.96      0.94       152\n",
      "    positive       0.85      0.79      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.87      0.83      0.85       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.96      0.99      0.97       152\n",
      "    positive       0.97      0.76      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.91      0.91       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 131.3628692626953 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.002762408694252372\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.1994078159332275 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5381, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4217, Accuracy: 0.8936, F1 Micro: 0.9361, F1 Macro: 0.9344\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.284, Accuracy: 0.9368, F1 Micro: 0.9609, F1 Macro: 0.9588\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1821, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1422, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1081, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.978\n",
      "Epoch 7/10, Train Loss: 0.0808, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0713, Accuracy: 0.9695, F1 Micro: 0.9809, F1 Macro: 0.9798\n",
      "Epoch 9/10, Train Loss: 0.0587, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.977\n",
      "Epoch 10/10, Train Loss: 0.0498, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9775\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9809, F1 Macro: 0.9798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.91      0.98      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5122, Accuracy: 0.881, F1 Micro: 0.881, F1 Macro: 0.8757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2179, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9274\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1592, Accuracy: 0.9603, F1 Micro: 0.9603, F1 Macro: 0.9563\n",
      "Epoch 4/10, Train Loss: 0.1561, Accuracy: 0.8929, F1 Micro: 0.8929, F1 Macro: 0.8875\n",
      "Epoch 5/10, Train Loss: 0.1152, Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9382\n",
      "Epoch 6/10, Train Loss: 0.1053, Accuracy: 0.9524, F1 Micro: 0.9524, F1 Macro: 0.9479\n",
      "Epoch 7/10, Train Loss: 0.085, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9271\n",
      "Epoch 8/10, Train Loss: 0.0797, Accuracy: 0.9524, F1 Micro: 0.9524, F1 Macro: 0.9473\n",
      "Epoch 9/10, Train Loss: 0.0708, Accuracy: 0.9524, F1 Micro: 0.9524, F1 Macro: 0.9467\n",
      "Epoch 10/10, Train Loss: 0.0536, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.923\n",
      "\n",
      "Sentiment analysis accuracy: 0.9603, F1 Micro: 0.9603, F1 Macro: 0.9563\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.97      0.94        86\n",
      "    positive       0.98      0.96      0.97       166\n",
      "\n",
      "    accuracy                           0.96       252\n",
      "   macro avg       0.95      0.96      0.96       252\n",
      "weighted avg       0.96      0.96      0.96       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.8926\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.89      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.38      0.83      0.53        12\n",
      "     neutral       0.95      0.93      0.94       152\n",
      "    positive       0.93      0.73      0.82        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.75      0.83      0.76       216\n",
      "weighted avg       0.91      0.88      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.73      0.83        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.91      0.89       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.92      0.83        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 130.4179403781891 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.002411093469709158\n",
      "Acquired samples: 8\n",
      "Sampling duration: 3.7277944087982178 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5355, Accuracy: 0.7946, F1 Micro: 0.8849, F1 Macro: 0.8834\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4164, Accuracy: 0.8862, F1 Micro: 0.9307, F1 Macro: 0.928\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2757, Accuracy: 0.9568, F1 Micro: 0.9732, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1913, Accuracy: 0.9613, F1 Micro: 0.9759, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1333, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9795\n",
      "Epoch 6/10, Train Loss: 0.1008, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9758\n",
      "Epoch 7/10, Train Loss: 0.0849, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9732\n",
      "Epoch 8/10, Train Loss: 0.0658, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9792\n",
      "Epoch 9/10, Train Loss: 0.0602, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0517, Accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9794\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9794\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.98       175\n",
      "      others       0.93      0.94      0.94       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5089, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9208\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2491, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9259\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1713, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9263\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1513, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9374\n",
      "Epoch 5/10, Train Loss: 0.1302, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.9298\n",
      "Epoch 6/10, Train Loss: 0.0965, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9334\n",
      "Epoch 7/10, Train Loss: 0.1044, Accuracy: 0.9254, F1 Micro: 0.9254, F1 Macro: 0.9172\n",
      "Epoch 8/10, Train Loss: 0.0899, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9255\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0608, Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9498\n",
      "Epoch 10/10, Train Loss: 0.0418, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9259\n",
      "\n",
      "Sentiment analysis accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9498\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.93        87\n",
      "    positive       0.98      0.95      0.97       181\n",
      "\n",
      "    accuracy                           0.96       268\n",
      "   macro avg       0.94      0.96      0.95       268\n",
      "weighted avg       0.96      0.96      0.96       268\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.9172\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.83      0.89        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.97      0.98      0.98       167\n",
      "    positive       0.88      0.85      0.86        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.93      0.94      0.94       152\n",
      "    positive       0.80      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.86      0.85      0.86       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      1.00      0.85        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.94      0.78      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.92      0.89       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 135.76560497283936 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0021861907560378315\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.4511523246765137 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5248, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.408, Accuracy: 0.9129, F1 Micro: 0.9467, F1 Macro: 0.9444\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2681, Accuracy: 0.9524, F1 Micro: 0.9705, F1 Macro: 0.9688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1771, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.126, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0918, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9786\n",
      "Epoch 7/10, Train Loss: 0.0815, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9775\n",
      "Epoch 8/10, Train Loss: 0.0651, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0548, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9796\n",
      "Epoch 10/10, Train Loss: 0.0442, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9778\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9796\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4753, Accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.9106\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2368, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9265\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1646, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9306\n",
      "Epoch 4/10, Train Loss: 0.151, Accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.9167\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1063, Accuracy: 0.9535, F1 Micro: 0.9535, F1 Macro: 0.9477\n",
      "Epoch 6/10, Train Loss: 0.0876, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9358\n",
      "Epoch 7/10, Train Loss: 0.0683, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9314\n",
      "Epoch 8/10, Train Loss: 0.0712, Accuracy: 0.9457, F1 Micro: 0.9457, F1 Macro: 0.9396\n",
      "Epoch 9/10, Train Loss: 0.0723, Accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.9148\n",
      "Epoch 10/10, Train Loss: 0.0476, Accuracy: 0.907, F1 Micro: 0.907, F1 Macro: 0.8976\n",
      "\n",
      "Sentiment analysis accuracy: 0.9535, F1 Micro: 0.9535, F1 Macro: 0.9477\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        86\n",
      "    positive       0.97      0.97      0.97       172\n",
      "\n",
      "    accuracy                           0.95       258\n",
      "   macro avg       0.95      0.95      0.95       258\n",
      "weighted avg       0.95      0.95      0.95       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9483, F1 Micro: 0.9483, F1 Macro: 0.8796\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.82      0.86        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.92      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.81      0.70        16\n",
      "     neutral       0.98      0.98      0.98       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.82      0.84      0.82       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.57      0.67      0.62        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.80      0.77      0.78        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.77      0.79      0.78       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.76      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.91      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 136.699693441391 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.002631179336458445\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.994431495666504 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.526, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4046, Accuracy: 0.8988, F1 Micro: 0.9385, F1 Macro: 0.9364\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.261, Accuracy: 0.9568, F1 Micro: 0.9732, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1745, Accuracy: 0.9583, F1 Micro: 0.9741, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1242, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1074, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9771\n",
      "Epoch 7/10, Train Loss: 0.0828, Accuracy: 0.9591, F1 Micro: 0.9741, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0648, Accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9796\n",
      "Epoch 9/10, Train Loss: 0.0547, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9763\n",
      "Epoch 10/10, Train Loss: 0.0463, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9771\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9796\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.97      0.97       175\n",
      "      others       0.94      0.95      0.95       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4839, Accuracy: 0.9101, F1 Micro: 0.9101, F1 Macro: 0.902\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2031, Accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.9078\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1558, Accuracy: 0.9288, F1 Micro: 0.9288, F1 Macro: 0.9222\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1288, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9246\n",
      "Epoch 5/10, Train Loss: 0.1281, Accuracy: 0.9288, F1 Micro: 0.9288, F1 Macro: 0.921\n",
      "Epoch 6/10, Train Loss: 0.0716, Accuracy: 0.9251, F1 Micro: 0.9251, F1 Macro: 0.9137\n",
      "Epoch 7/10, Train Loss: 0.0922, Accuracy: 0.9288, F1 Micro: 0.9288, F1 Macro: 0.921\n",
      "Epoch 8/10, Train Loss: 0.0452, Accuracy: 0.9288, F1 Micro: 0.9288, F1 Macro: 0.9206\n",
      "Epoch 9/10, Train Loss: 0.0631, Accuracy: 0.9288, F1 Micro: 0.9288, F1 Macro: 0.9218\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0517, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9258\n",
      "\n",
      "Sentiment analysis accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9258\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.97      0.90        87\n",
      "    positive       0.98      0.92      0.95       180\n",
      "\n",
      "    accuracy                           0.93       267\n",
      "   macro avg       0.92      0.94      0.93       267\n",
      "weighted avg       0.94      0.93      0.93       267\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9067\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.97      0.97      0.97       167\n",
      "    positive       0.84      0.82      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.89      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.53      0.83      0.65        12\n",
      "     neutral       0.95      0.91      0.93       152\n",
      "    positive       0.84      0.81      0.82        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.77      0.85      0.80       216\n",
      "weighted avg       0.90      0.88      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.97      0.98      0.97       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.92      0.91       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 140.78065609931946 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0017409669933840636\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.2978715896606445 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5297, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4046, Accuracy: 0.9234, F1 Micro: 0.9528, F1 Macro: 0.9509\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2558, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9735\n",
      "Epoch 4/10, Train Loss: 0.17, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1255, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9769\n",
      "Epoch 6/10, Train Loss: 0.1032, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9757\n",
      "Epoch 7/10, Train Loss: 0.0749, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0635, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9788\n",
      "Epoch 9/10, Train Loss: 0.0524, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9764\n",
      "Epoch 10/10, Train Loss: 0.0472, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9745\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9788\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.93      0.96      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4799, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9323\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2032, Accuracy: 0.9416, F1 Micro: 0.9416, F1 Macro: 0.9357\n",
      "Epoch 3/10, Train Loss: 0.1621, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9251\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1251, Accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9395\n",
      "Epoch 5/10, Train Loss: 0.1046, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9201\n",
      "Epoch 6/10, Train Loss: 0.0825, Accuracy: 0.9222, F1 Micro: 0.9222, F1 Macro: 0.9161\n",
      "Epoch 7/10, Train Loss: 0.0676, Accuracy: 0.9183, F1 Micro: 0.9183, F1 Macro: 0.9117\n",
      "Epoch 8/10, Train Loss: 0.095, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9268\n",
      "Epoch 9/10, Train Loss: 0.0854, Accuracy: 0.9183, F1 Micro: 0.9183, F1 Macro: 0.9117\n",
      "Epoch 10/10, Train Loss: 0.0609, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9275\n",
      "\n",
      "Sentiment analysis accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9395\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        86\n",
      "    positive       0.97      0.95      0.96       171\n",
      "\n",
      "    accuracy                           0.95       257\n",
      "   macro avg       0.94      0.94      0.94       257\n",
      "weighted avg       0.95      0.95      0.95       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.8996\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.86      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.38      0.83      0.53        12\n",
      "     neutral       0.94      0.89      0.92       152\n",
      "    positive       0.87      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.73      0.83      0.75       216\n",
      "weighted avg       0.90      0.86      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.94      0.78      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.92      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 135.74356055259705 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0024054209934547544\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.7597410678863525 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5171, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.39, Accuracy: 0.9308, F1 Micro: 0.9575, F1 Macro: 0.9561\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2463, Accuracy: 0.9546, F1 Micro: 0.9717, F1 Macro: 0.97\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1635, Accuracy: 0.9621, F1 Micro: 0.9764, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1248, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9776\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0902, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9776\n",
      "Epoch 7/10, Train Loss: 0.0772, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0619, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9787\n",
      "Epoch 9/10, Train Loss: 0.0489, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9767\n",
      "Epoch 10/10, Train Loss: 0.0414, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9781\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9787\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4854, Accuracy: 0.9186, F1 Micro: 0.9186, F1 Macro: 0.9102\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2521, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9314\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1872, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9306\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.124, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9321\n",
      "Epoch 5/10, Train Loss: 0.0935, Accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.9192\n",
      "Epoch 6/10, Train Loss: 0.0834, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9277\n",
      "Epoch 7/10, Train Loss: 0.0632, Accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.9196\n",
      "Epoch 8/10, Train Loss: 0.0632, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.9232\n",
      "Epoch 9/10, Train Loss: 0.0712, Accuracy: 0.9109, F1 Micro: 0.9109, F1 Macro: 0.8994\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0522, Accuracy: 0.9457, F1 Micro: 0.9457, F1 Macro: 0.9393\n",
      "\n",
      "Sentiment analysis accuracy: 0.9457, F1 Micro: 0.9457, F1 Macro: 0.9393\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        85\n",
      "    positive       0.97      0.95      0.96       173\n",
      "\n",
      "    accuracy                           0.95       258\n",
      "   macro avg       0.93      0.94      0.94       258\n",
      "weighted avg       0.95      0.95      0.95       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9175\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.96      0.97      0.97       167\n",
      "    positive       0.84      0.82      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.87      0.87      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.83      0.75      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.84      0.84      0.84       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.91       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 146.3534767627716 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0017806049203500153\n",
      "Acquired samples: 8\n",
      "Sampling duration: 1.1037867069244385 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5253, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.403, Accuracy: 0.9211, F1 Micro: 0.9517, F1 Macro: 0.9503\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2553, Accuracy: 0.9546, F1 Micro: 0.9718, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1604, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1282, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "Epoch 6/10, Train Loss: 0.0908, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0772, Accuracy: 0.9702, F1 Micro: 0.9814, F1 Macro: 0.9803\n",
      "Epoch 8/10, Train Loss: 0.0602, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0534, Accuracy: 0.971, F1 Micro: 0.9818, F1 Macro: 0.9808\n",
      "Epoch 10/10, Train Loss: 0.0442, Accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9801\n",
      "\n",
      "Aspect detection accuracy: 0.971, F1 Micro: 0.9818, F1 Macro: 0.9808\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.93      0.96      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5131, Accuracy: 0.8962, F1 Micro: 0.8962, F1 Macro: 0.8888\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.243, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9324\n",
      "Epoch 3/10, Train Loss: 0.1529, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9203\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1252, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9361\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1247, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9364\n",
      "Epoch 6/10, Train Loss: 0.098, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.9084\n",
      "Epoch 7/10, Train Loss: 0.0844, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9203\n",
      "Epoch 8/10, Train Loss: 0.0881, Accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.9131\n",
      "Epoch 9/10, Train Loss: 0.0811, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9268\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0528, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.935\n",
      "\n",
      "Sentiment analysis accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.935\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.92      0.91        86\n",
      "    positive       0.96      0.95      0.96       174\n",
      "\n",
      "    accuracy                           0.94       260\n",
      "   macro avg       0.93      0.94      0.94       260\n",
      "weighted avg       0.94      0.94      0.94       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.9101\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.92      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.88      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.99      0.98       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.88      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.92      0.73        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.89      0.79      0.84        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.81      0.88      0.83       216\n",
      "weighted avg       0.91      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.95      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 146.1655433177948 s\n",
      "Total runtime: 3087.2629249095917 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[2], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33791aa6",
   "metadata": {
    "papermill": {
     "duration": 0.148329,
     "end_time": "2025-03-06T11:42:51.026081",
     "exception": false,
     "start_time": "2025-03-06T11:42:50.877752",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcedf24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 4\n",
      "Random seed: 3\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6456, Accuracy: 0.7865, F1 Micro: 0.8804, F1 Macro: 0.8788\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5639, Accuracy: 0.7894, F1 Micro: 0.8822, F1 Macro: 0.8807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5346, Accuracy: 0.7894, F1 Micro: 0.8822, F1 Macro: 0.8807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5259, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4788, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Epoch 6/10, Train Loss: 0.477, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 7/10, Train Loss: 0.4707, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4588, Accuracy: 0.7909, F1 Micro: 0.883, F1 Macro: 0.8814\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.4215, Accuracy: 0.7932, F1 Micro: 0.8839, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3936, Accuracy: 0.7976, F1 Micro: 0.8857, F1 Macro: 0.884\n",
      "\n",
      "Aspect detection accuracy: 0.7976, F1 Micro: 0.8857, F1 Macro: 0.884\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.78      1.00      0.88       175\n",
      "      others       0.76      0.96      0.84       158\n",
      "        part       0.71      1.00      0.83       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.80      0.99      0.89      1061\n",
      "   macro avg       0.80      0.99      0.88      1061\n",
      "weighted avg       0.80      0.99      0.89      1061\n",
      " samples avg       0.80      0.99      0.88      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7056, Accuracy: 0.44, F1 Micro: 0.44, F1 Macro: 0.4318\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5997, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5241, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5185, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.494, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4806, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4617, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.422, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3873, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2944, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "\n",
      "Sentiment analysis accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         4\n",
      "    positive       0.84      1.00      0.91        21\n",
      "\n",
      "    accuracy                           0.84        25\n",
      "   macro avg       0.42      0.50      0.46        25\n",
      "weighted avg       0.71      0.84      0.77        25\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.7948, F1 Micro: 0.7948, F1 Macro: 0.3169\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.78      1.00      0.87       167\n",
      "    positive       1.00      0.03      0.06        33\n",
      "\n",
      "    accuracy                           0.78       216\n",
      "   macro avg       0.59      0.34      0.31       216\n",
      "weighted avg       0.75      0.78      0.68       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.76      0.95      0.84       152\n",
      "    positive       0.54      0.25      0.34        52\n",
      "\n",
      "    accuracy                           0.73       216\n",
      "   macro avg       0.43      0.40      0.40       216\n",
      "weighted avg       0.66      0.73      0.68       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        23\n",
      "     neutral       0.70      1.00      0.83       152\n",
      "    positive       0.00      0.00      0.00        41\n",
      "\n",
      "    accuracy                           0.70       216\n",
      "   macro avg       0.23      0.33      0.28       216\n",
      "weighted avg       0.50      0.70      0.58       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 60.059224367141724 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.004655062220990658\n",
      "Acquired samples: 82\n",
      "Sampling duration: 10.890834331512451 seconds\n",
      "New train size: 136\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6159, Accuracy: 0.7894, F1 Micro: 0.8822, F1 Macro: 0.8807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5424, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Epoch 3/10, Train Loss: 0.5317, Accuracy: 0.7902, F1 Micro: 0.8825, F1 Macro: 0.881\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.498, Accuracy: 0.7954, F1 Micro: 0.884, F1 Macro: 0.8822\n",
      "Epoch 5/10, Train Loss: 0.4577, Accuracy: 0.7976, F1 Micro: 0.884, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4142, Accuracy: 0.8073, F1 Micro: 0.8887, F1 Macro: 0.8864\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3732, Accuracy: 0.8326, F1 Micro: 0.9016, F1 Macro: 0.8993\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3382, Accuracy: 0.8527, F1 Micro: 0.9124, F1 Macro: 0.9105\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2945, Accuracy: 0.8735, F1 Micro: 0.9238, F1 Macro: 0.9221\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.253, Accuracy: 0.8847, F1 Micro: 0.9295, F1 Macro: 0.9268\n",
      "\n",
      "Aspect detection accuracy: 0.8847, F1 Micro: 0.9295, F1 Macro: 0.9268\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.89      0.94      0.91       175\n",
      "      others       0.88      0.89      0.88       158\n",
      "        part       0.78      0.94      0.85       158\n",
      "       price       0.96      0.99      0.98       192\n",
      "     service       0.90      1.00      0.95       191\n",
      "\n",
      "   micro avg       0.90      0.96      0.93      1061\n",
      "   macro avg       0.90      0.96      0.93      1061\n",
      "weighted avg       0.90      0.96      0.93      1061\n",
      " samples avg       0.90      0.96      0.93      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5607, Accuracy: 0.7437, F1 Micro: 0.7437, F1 Macro: 0.4265\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4392, Accuracy: 0.7487, F1 Micro: 0.7487, F1 Macro: 0.4644\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3903, Accuracy: 0.7688, F1 Micro: 0.7688, F1 Macro: 0.6968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3015, Accuracy: 0.804, F1 Micro: 0.804, F1 Macro: 0.7536\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2422, Accuracy: 0.8442, F1 Micro: 0.8442, F1 Macro: 0.8124\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1361, Accuracy: 0.8643, F1 Micro: 0.8643, F1 Macro: 0.8294\n",
      "Epoch 7/10, Train Loss: 0.0926, Accuracy: 0.8593, F1 Micro: 0.8593, F1 Macro: 0.8178\n",
      "Epoch 8/10, Train Loss: 0.145, Accuracy: 0.8593, F1 Micro: 0.8593, F1 Macro: 0.8178\n",
      "Epoch 9/10, Train Loss: 0.1495, Accuracy: 0.8593, F1 Micro: 0.8593, F1 Macro: 0.8345\n",
      "Epoch 10/10, Train Loss: 0.0923, Accuracy: 0.8442, F1 Micro: 0.8442, F1 Macro: 0.7857\n",
      "\n",
      "Sentiment analysis accuracy: 0.8643, F1 Micro: 0.8643, F1 Macro: 0.8294\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.80      0.75        51\n",
      "    positive       0.93      0.89      0.91       148\n",
      "\n",
      "    accuracy                           0.86       199\n",
      "   macro avg       0.82      0.84      0.83       199\n",
      "weighted avg       0.87      0.86      0.87       199\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 136: Accuracy: 0.8627, F1 Micro: 0.8627, F1 Macro: 0.6669\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.64      0.78        11\n",
      "     neutral       0.98      0.99      0.99       181\n",
      "    positive       0.81      0.88      0.84        24\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.84      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.31      0.48        16\n",
      "     neutral       0.88      0.94      0.91       167\n",
      "    positive       0.58      0.58      0.58        33\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.82      0.61      0.65       216\n",
      "weighted avg       0.84      0.84      0.83       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.40      0.67      0.50        12\n",
      "     neutral       0.88      0.88      0.88       152\n",
      "    positive       0.70      0.60      0.65        52\n",
      "\n",
      "    accuracy                           0.80       216\n",
      "   macro avg       0.66      0.71      0.68       216\n",
      "weighted avg       0.81      0.80      0.80       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.09      0.16        23\n",
      "     neutral       0.77      0.94      0.85       152\n",
      "    positive       0.55      0.39      0.46        41\n",
      "\n",
      "    accuracy                           0.75       216\n",
      "   macro avg       0.77      0.47      0.49       216\n",
      "weighted avg       0.76      0.75      0.70       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.54      0.70        13\n",
      "     neutral       0.96      0.99      0.98       186\n",
      "    positive       0.71      0.71      0.71        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.75      0.79       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.21      0.35        14\n",
      "     neutral       0.89      1.00      0.94       185\n",
      "    positive       0.50      0.18      0.26        17\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.80      0.46      0.52       216\n",
      "weighted avg       0.87      0.88      0.85       216\n",
      "\n",
      "Total train time: 71.78334164619446 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.013031547330319882\n",
      "Acquired samples: 73\n",
      "Sampling duration: 15.332336664199829 seconds\n",
      "New train size: 209\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5921, Accuracy: 0.7894, F1 Micro: 0.8822, F1 Macro: 0.8807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5076, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4983, Accuracy: 0.7917, F1 Micro: 0.8829, F1 Macro: 0.8814\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4466, Accuracy: 0.8006, F1 Micro: 0.8849, F1 Macro: 0.8822\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4092, Accuracy: 0.8214, F1 Micro: 0.896, F1 Macro: 0.8937\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3639, Accuracy: 0.8557, F1 Micro: 0.9136, F1 Macro: 0.9115\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3199, Accuracy: 0.8884, F1 Micro: 0.9319, F1 Macro: 0.9291\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2586, Accuracy: 0.9018, F1 Micro: 0.9398, F1 Macro: 0.9369\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2044, Accuracy: 0.9196, F1 Micro: 0.9496, F1 Macro: 0.946\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1727, Accuracy: 0.9234, F1 Micro: 0.9523, F1 Macro: 0.9492\n",
      "\n",
      "Aspect detection accuracy: 0.9234, F1 Micro: 0.9523, F1 Macro: 0.9492\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.92      0.96      0.94       175\n",
      "      others       0.88      0.87      0.88       158\n",
      "        part       0.87      0.97      0.92       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       0.95      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.94      0.97      0.95      1061\n",
      "   macro avg       0.93      0.97      0.95      1061\n",
      "weighted avg       0.94      0.97      0.95      1061\n",
      " samples avg       0.94      0.97      0.95      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6172, Accuracy: 0.7362, F1 Micro: 0.7362, F1 Macro: 0.6965\n",
      "Epoch 2/10, Train Loss: 0.4313, Accuracy: 0.7319, F1 Micro: 0.7319, F1 Macro: 0.7239\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3038, Accuracy: 0.8043, F1 Micro: 0.8043, F1 Macro: 0.792\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1839, Accuracy: 0.8681, F1 Micro: 0.8681, F1 Macro: 0.8442\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1964, Accuracy: 0.8894, F1 Micro: 0.8894, F1 Macro: 0.8768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1927, Accuracy: 0.9064, F1 Micro: 0.9064, F1 Macro: 0.8915\n",
      "Epoch 7/10, Train Loss: 0.1408, Accuracy: 0.8894, F1 Micro: 0.8894, F1 Macro: 0.8768\n",
      "Epoch 8/10, Train Loss: 0.1018, Accuracy: 0.8851, F1 Micro: 0.8851, F1 Macro: 0.8683\n",
      "Epoch 9/10, Train Loss: 0.0799, Accuracy: 0.8894, F1 Micro: 0.8894, F1 Macro: 0.8753\n",
      "Epoch 10/10, Train Loss: 0.0503, Accuracy: 0.8809, F1 Micro: 0.8809, F1 Macro: 0.8681\n",
      "\n",
      "Sentiment analysis accuracy: 0.9064, F1 Micro: 0.9064, F1 Macro: 0.8915\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.88      0.85        72\n",
      "    positive       0.94      0.92      0.93       163\n",
      "\n",
      "    accuracy                           0.91       235\n",
      "   macro avg       0.89      0.90      0.89       235\n",
      "weighted avg       0.91      0.91      0.91       235\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 209: Accuracy: 0.9066, F1 Micro: 0.9066, F1 Macro: 0.8142\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.83      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.94      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.69      0.79        16\n",
      "     neutral       0.92      0.96      0.94       167\n",
      "    positive       0.73      0.67      0.70        33\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.86      0.77      0.81       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.36      0.75      0.49        12\n",
      "     neutral       0.89      0.88      0.88       152\n",
      "    positive       0.66      0.52      0.58        52\n",
      "\n",
      "    accuracy                           0.78       216\n",
      "   macro avg       0.64      0.71      0.65       216\n",
      "weighted avg       0.80      0.78      0.79       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.61      0.72        23\n",
      "     neutral       0.87      0.97      0.92       152\n",
      "    positive       0.84      0.63      0.72        41\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.86      0.74      0.79       216\n",
      "weighted avg       0.86      0.87      0.86       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.69      0.82        13\n",
      "     neutral       0.97      1.00      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.84      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.93      0.90        14\n",
      "     neutral       0.95      1.00      0.98       185\n",
      "    positive       1.00      0.41      0.58        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.94      0.78      0.82       216\n",
      "weighted avg       0.95      0.95      0.94       216\n",
      "\n",
      "Total train time: 81.65375137329102 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.011315702926367521\n",
      "Acquired samples: 66\n",
      "Sampling duration: 15.150923013687134 seconds\n",
      "New train size: 275\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5837, Accuracy: 0.785, F1 Micro: 0.8786, F1 Macro: 0.8761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5116, Accuracy: 0.7902, F1 Micro: 0.8823, F1 Macro: 0.8806\n",
      "Epoch 3/10, Train Loss: 0.4664, Accuracy: 0.7946, F1 Micro: 0.8823, F1 Macro: 0.8793\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4455, Accuracy: 0.8185, F1 Micro: 0.8938, F1 Macro: 0.8911\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3742, Accuracy: 0.8519, F1 Micro: 0.9109, F1 Macro: 0.9078\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3204, Accuracy: 0.9137, F1 Micro: 0.9466, F1 Macro: 0.9443\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.255, Accuracy: 0.9226, F1 Micro: 0.9518, F1 Macro: 0.9487\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1946, Accuracy: 0.9263, F1 Micro: 0.9536, F1 Macro: 0.9494\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1628, Accuracy: 0.942, F1 Micro: 0.9638, F1 Macro: 0.9612\n",
      "Epoch 10/10, Train Loss: 0.1298, Accuracy: 0.9375, F1 Micro: 0.9609, F1 Macro: 0.9576\n",
      "\n",
      "Aspect detection accuracy: 0.942, F1 Micro: 0.9638, F1 Macro: 0.9612\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      1.00      0.97       175\n",
      "      others       0.92      0.87      0.89       158\n",
      "        part       0.92      0.99      0.95       158\n",
      "       price       0.96      0.99      0.98       192\n",
      "     service       0.96      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.95      0.98      0.96      1061\n",
      "   macro avg       0.95      0.97      0.96      1061\n",
      "weighted avg       0.95      0.98      0.96      1061\n",
      " samples avg       0.95      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.561, Accuracy: 0.7102, F1 Micro: 0.7102, F1 Macro: 0.5364\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3298, Accuracy: 0.8694, F1 Micro: 0.8694, F1 Macro: 0.8534\n",
      "Epoch 3/10, Train Loss: 0.219, Accuracy: 0.8327, F1 Micro: 0.8327, F1 Macro: 0.822\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1564, Accuracy: 0.9061, F1 Micro: 0.9061, F1 Macro: 0.8864\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1466, Accuracy: 0.9184, F1 Micro: 0.9184, F1 Macro: 0.9083\n",
      "Epoch 6/10, Train Loss: 0.1181, Accuracy: 0.902, F1 Micro: 0.902, F1 Macro: 0.8855\n",
      "Epoch 7/10, Train Loss: 0.0714, Accuracy: 0.9061, F1 Micro: 0.9061, F1 Macro: 0.8907\n",
      "Epoch 8/10, Train Loss: 0.067, Accuracy: 0.902, F1 Micro: 0.902, F1 Macro: 0.8864\n",
      "Epoch 9/10, Train Loss: 0.0488, Accuracy: 0.8816, F1 Micro: 0.8816, F1 Macro: 0.8641\n",
      "Epoch 10/10, Train Loss: 0.0474, Accuracy: 0.8939, F1 Micro: 0.8939, F1 Macro: 0.8794\n",
      "\n",
      "Sentiment analysis accuracy: 0.9184, F1 Micro: 0.9184, F1 Macro: 0.9083\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.95      0.88        76\n",
      "    positive       0.97      0.91      0.94       169\n",
      "\n",
      "    accuracy                           0.92       245\n",
      "   macro avg       0.90      0.93      0.91       245\n",
      "weighted avg       0.93      0.92      0.92       245\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 275: Accuracy: 0.9198, F1 Micro: 0.9198, F1 Macro: 0.8386\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.94      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.69      0.79        16\n",
      "     neutral       0.94      1.00      0.97       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.80      0.85       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.34      0.92      0.50        12\n",
      "     neutral       0.94      0.82      0.87       152\n",
      "    positive       0.65      0.65      0.65        52\n",
      "\n",
      "    accuracy                           0.78       216\n",
      "   macro avg       0.65      0.80      0.68       216\n",
      "weighted avg       0.84      0.78      0.80       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.70      0.78        23\n",
      "     neutral       0.92      0.99      0.95       152\n",
      "    positive       0.83      0.71      0.76        41\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.88      0.80      0.83       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.69      0.82        13\n",
      "     neutral       0.96      0.99      0.98       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.82      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.86      0.86        14\n",
      "     neutral       0.96      1.00      0.98       185\n",
      "    positive       0.90      0.53      0.67        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.80      0.84       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Total train time: 84.17163681983948 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.01025028033182025\n",
      "Acquired samples: 59\n",
      "Sampling duration: 13.640748023986816 seconds\n",
      "New train size: 334\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5781, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.493, Accuracy: 0.7954, F1 Micro: 0.8846, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.434, Accuracy: 0.8073, F1 Micro: 0.8886, F1 Macro: 0.8858\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3954, Accuracy: 0.8564, F1 Micro: 0.9142, F1 Macro: 0.912\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3036, Accuracy: 0.904, F1 Micro: 0.9408, F1 Macro: 0.9372\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2475, Accuracy: 0.9301, F1 Micro: 0.9568, F1 Macro: 0.9542\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1837, Accuracy: 0.9345, F1 Micro: 0.959, F1 Macro: 0.9558\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1512, Accuracy: 0.9427, F1 Micro: 0.9642, F1 Macro: 0.9613\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1194, Accuracy: 0.9449, F1 Micro: 0.9651, F1 Macro: 0.9623\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0966, Accuracy: 0.9509, F1 Micro: 0.9689, F1 Macro: 0.9657\n",
      "\n",
      "Aspect detection accuracy: 0.9509, F1 Micro: 0.9689, F1 Macro: 0.9657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.94      0.83      0.88       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      1061\n",
      "   macro avg       0.97      0.97      0.97      1061\n",
      "weighted avg       0.97      0.97      0.97      1061\n",
      " samples avg       0.97      0.97      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.595, Accuracy: 0.7399, F1 Micro: 0.7399, F1 Macro: 0.7238\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3549, Accuracy: 0.8462, F1 Micro: 0.8462, F1 Macro: 0.8296\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2413, Accuracy: 0.8755, F1 Micro: 0.8755, F1 Macro: 0.8548\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1737, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8851\n",
      "Epoch 5/10, Train Loss: 0.1103, Accuracy: 0.8938, F1 Micro: 0.8938, F1 Macro: 0.8765\n",
      "Epoch 6/10, Train Loss: 0.0714, Accuracy: 0.8901, F1 Micro: 0.8901, F1 Macro: 0.875\n",
      "Epoch 7/10, Train Loss: 0.0603, Accuracy: 0.8901, F1 Micro: 0.8901, F1 Macro: 0.8674\n",
      "Epoch 8/10, Train Loss: 0.0682, Accuracy: 0.9011, F1 Micro: 0.9011, F1 Macro: 0.889\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.06, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8867\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0555, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.8936\n",
      "\n",
      "Sentiment analysis accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.8936\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.87      0.85        84\n",
      "    positive       0.94      0.93      0.93       189\n",
      "\n",
      "    accuracy                           0.91       273\n",
      "   macro avg       0.89      0.90      0.89       273\n",
      "weighted avg       0.91      0.91      0.91       273\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 334: Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.8728\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.69      0.79        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.81      0.76      0.78        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.81      0.84       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.53      0.75      0.62        12\n",
      "     neutral       0.94      0.82      0.88       152\n",
      "    positive       0.61      0.77      0.68        52\n",
      "\n",
      "    accuracy                           0.81       216\n",
      "   macro avg       0.69      0.78      0.73       216\n",
      "weighted avg       0.84      0.81      0.81       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.83      0.84        23\n",
      "     neutral       0.96      0.99      0.97       152\n",
      "    positive       0.89      0.78      0.83        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.69      0.82        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.93      0.84      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.93        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.76      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 98.88210654258728 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.011827283538877964\n",
      "Acquired samples: 54\n",
      "Sampling duration: 12.659327745437622 seconds\n",
      "New train size: 388\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5632, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4871, Accuracy: 0.8028, F1 Micro: 0.8882, F1 Macro: 0.8865\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4399, Accuracy: 0.8244, F1 Micro: 0.8983, F1 Macro: 0.8964\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3518, Accuracy: 0.901, F1 Micro: 0.94, F1 Macro: 0.9379\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2731, Accuracy: 0.9286, F1 Micro: 0.9554, F1 Macro: 0.9524\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2104, Accuracy: 0.9375, F1 Micro: 0.9605, F1 Macro: 0.9569\n",
      "Epoch 7/10, Train Loss: 0.1538, Accuracy: 0.9353, F1 Micro: 0.9589, F1 Macro: 0.9544\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1276, Accuracy: 0.9442, F1 Micro: 0.9647, F1 Macro: 0.9622\n",
      "Epoch 9/10, Train Loss: 0.1048, Accuracy: 0.9427, F1 Micro: 0.9638, F1 Macro: 0.9611\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0862, Accuracy: 0.9457, F1 Micro: 0.9657, F1 Macro: 0.9629\n",
      "\n",
      "Aspect detection accuracy: 0.9457, F1 Micro: 0.9657, F1 Macro: 0.9629\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.95      0.95       175\n",
      "      others       0.91      0.86      0.89       158\n",
      "        part       0.94      0.99      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.97      0.97      1061\n",
      "   macro avg       0.96      0.97      0.96      1061\n",
      "weighted avg       0.96      0.97      0.97      1061\n",
      " samples avg       0.96      0.97      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5623, Accuracy: 0.8111, F1 Micro: 0.8111, F1 Macro: 0.7616\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2725, Accuracy: 0.8704, F1 Micro: 0.8704, F1 Macro: 0.8502\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1711, Accuracy: 0.9074, F1 Micro: 0.9074, F1 Macro: 0.8943\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.117, Accuracy: 0.9148, F1 Micro: 0.9148, F1 Macro: 0.901\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1339, Accuracy: 0.9222, F1 Micro: 0.9222, F1 Macro: 0.909\n",
      "Epoch 6/10, Train Loss: 0.0792, Accuracy: 0.9111, F1 Micro: 0.9111, F1 Macro: 0.8989\n",
      "Epoch 7/10, Train Loss: 0.043, Accuracy: 0.9074, F1 Micro: 0.9074, F1 Macro: 0.8949\n",
      "Epoch 8/10, Train Loss: 0.0522, Accuracy: 0.9148, F1 Micro: 0.9148, F1 Macro: 0.9016\n",
      "Epoch 9/10, Train Loss: 0.0348, Accuracy: 0.9, F1 Micro: 0.9, F1 Macro: 0.8814\n",
      "Epoch 10/10, Train Loss: 0.0505, Accuracy: 0.9185, F1 Micro: 0.9185, F1 Macro: 0.9073\n",
      "\n",
      "Sentiment analysis accuracy: 0.9222, F1 Micro: 0.9222, F1 Macro: 0.909\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.90      0.87        81\n",
      "    positive       0.96      0.93      0.94       189\n",
      "\n",
      "    accuracy                           0.92       270\n",
      "   macro avg       0.90      0.92      0.91       270\n",
      "weighted avg       0.92      0.92      0.92       270\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 388: Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.8728\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.95      0.95       167\n",
      "    positive       0.76      0.79      0.78        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.86      0.85      0.86       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.53      0.75      0.62        12\n",
      "     neutral       0.92      0.86      0.88       152\n",
      "    positive       0.65      0.71      0.68        52\n",
      "\n",
      "    accuracy                           0.81       216\n",
      "   macro avg       0.70      0.77      0.73       216\n",
      "weighted avg       0.83      0.81      0.82       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.83      0.84        23\n",
      "     neutral       0.94      0.99      0.96       152\n",
      "    positive       0.91      0.73      0.81        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.85      0.87       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.91      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.93      0.90        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.71      0.83        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.88      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 98.21323251724243 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.008176492899656298\n",
      "Acquired samples: 48\n",
      "Sampling duration: 11.815514087677002 seconds\n",
      "New train size: 436\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5573, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4994, Accuracy: 0.7961, F1 Micro: 0.8834, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.435, Accuracy: 0.84, F1 Micro: 0.9039, F1 Macro: 0.9004\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3512, Accuracy: 0.9129, F1 Micro: 0.9466, F1 Macro: 0.944\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2644, Accuracy: 0.9308, F1 Micro: 0.957, F1 Macro: 0.9536\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1926, Accuracy: 0.9338, F1 Micro: 0.9585, F1 Macro: 0.9545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1535, Accuracy: 0.9464, F1 Micro: 0.9662, F1 Macro: 0.9626\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1223, Accuracy: 0.9464, F1 Micro: 0.9663, F1 Macro: 0.9631\n",
      "Epoch 9/10, Train Loss: 0.0986, Accuracy: 0.9442, F1 Micro: 0.9648, F1 Macro: 0.9614\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0848, Accuracy: 0.9487, F1 Micro: 0.9677, F1 Macro: 0.9652\n",
      "\n",
      "Aspect detection accuracy: 0.9487, F1 Micro: 0.9677, F1 Macro: 0.9652\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.91      0.87      0.89       158\n",
      "        part       0.95      0.99      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.97      0.97      1061\n",
      "   macro avg       0.96      0.97      0.97      1061\n",
      "weighted avg       0.96      0.97      0.97      1061\n",
      " samples avg       0.96      0.97      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5775, Accuracy: 0.8473, F1 Micro: 0.8473, F1 Macro: 0.8248\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3012, Accuracy: 0.8855, F1 Micro: 0.8855, F1 Macro: 0.8702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1801, Accuracy: 0.9008, F1 Micro: 0.9008, F1 Macro: 0.8804\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1352, Accuracy: 0.9122, F1 Micro: 0.9122, F1 Macro: 0.8996\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.096, Accuracy: 0.9122, F1 Micro: 0.9122, F1 Macro: 0.8962\n",
      "Epoch 6/10, Train Loss: 0.0864, Accuracy: 0.9046, F1 Micro: 0.9046, F1 Macro: 0.8879\n",
      "Epoch 7/10, Train Loss: 0.0732, Accuracy: 0.9046, F1 Micro: 0.9046, F1 Macro: 0.8908\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0566, Accuracy: 0.9122, F1 Micro: 0.9122, F1 Macro: 0.9024\n",
      "Epoch 9/10, Train Loss: 0.0533, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.899\n",
      "Epoch 10/10, Train Loss: 0.0444, Accuracy: 0.9046, F1 Micro: 0.9046, F1 Macro: 0.8901\n",
      "\n",
      "Sentiment analysis accuracy: 0.9122, F1 Micro: 0.9122, F1 Macro: 0.9024\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.96      0.87        81\n",
      "    positive       0.98      0.89      0.93       181\n",
      "\n",
      "    accuracy                           0.91       262\n",
      "   macro avg       0.89      0.93      0.90       262\n",
      "weighted avg       0.92      0.91      0.91       262\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 436: Accuracy: 0.9306, F1 Micro: 0.9306, F1 Macro: 0.8631\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.69      0.79        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.81      0.76      0.78        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.81      0.84       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.59      0.83      0.69        12\n",
      "     neutral       0.92      0.87      0.89       152\n",
      "    positive       0.64      0.67      0.65        52\n",
      "\n",
      "    accuracy                           0.82       216\n",
      "   macro avg       0.71      0.79      0.75       216\n",
      "weighted avg       0.83      0.82      0.82       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.78      0.80        23\n",
      "     neutral       0.94      0.99      0.96       152\n",
      "    positive       0.89      0.76      0.82        41\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.88      0.84      0.86       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.88      0.86      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.87      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 105.08730173110962 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.006675472669303417\n",
      "Acquired samples: 43\n",
      "Sampling duration: 10.59751558303833 seconds\n",
      "New train size: 479\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5401, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4895, Accuracy: 0.8028, F1 Micro: 0.8865, F1 Macro: 0.8839\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4172, Accuracy: 0.8631, F1 Micro: 0.9182, F1 Macro: 0.9163\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3267, Accuracy: 0.9249, F1 Micro: 0.9531, F1 Macro: 0.9494\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2469, Accuracy: 0.9435, F1 Micro: 0.9647, F1 Macro: 0.9621\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1699, Accuracy: 0.9576, F1 Micro: 0.9736, F1 Macro: 0.9724\n",
      "Epoch 7/10, Train Loss: 0.1419, Accuracy: 0.9561, F1 Micro: 0.9726, F1 Macro: 0.9712\n",
      "Epoch 8/10, Train Loss: 0.1117, Accuracy: 0.9546, F1 Micro: 0.9715, F1 Macro: 0.9695\n",
      "Epoch 9/10, Train Loss: 0.0889, Accuracy: 0.9487, F1 Micro: 0.9676, F1 Macro: 0.9651\n",
      "Epoch 10/10, Train Loss: 0.0784, Accuracy: 0.9539, F1 Micro: 0.9709, F1 Macro: 0.9686\n",
      "\n",
      "Aspect detection accuracy: 0.9576, F1 Micro: 0.9736, F1 Macro: 0.9724\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.89      0.96      0.93       158\n",
      "        part       0.95      0.99      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.97      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.97      1061\n",
      "   macro avg       0.96      0.99      0.97      1061\n",
      "weighted avg       0.96      0.99      0.97      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5522, Accuracy: 0.8193, F1 Micro: 0.8193, F1 Macro: 0.7851\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2872, Accuracy: 0.8992, F1 Micro: 0.8992, F1 Macro: 0.8902\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1741, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9268\n",
      "Epoch 4/10, Train Loss: 0.1378, Accuracy: 0.9244, F1 Micro: 0.9244, F1 Macro: 0.9163\n",
      "Epoch 5/10, Train Loss: 0.1078, Accuracy: 0.9244, F1 Micro: 0.9244, F1 Macro: 0.9142\n",
      "Epoch 6/10, Train Loss: 0.0896, Accuracy: 0.9244, F1 Micro: 0.9244, F1 Macro: 0.9168\n",
      "Epoch 7/10, Train Loss: 0.0847, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9207\n",
      "Epoch 8/10, Train Loss: 0.0843, Accuracy: 0.9244, F1 Micro: 0.9244, F1 Macro: 0.9185\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0676, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.93\n",
      "Epoch 10/10, Train Loss: 0.0585, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9268\n",
      "\n",
      "Sentiment analysis accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.93      0.91        80\n",
      "    positive       0.96      0.94      0.95       158\n",
      "\n",
      "    accuracy                           0.94       238\n",
      "   macro avg       0.93      0.93      0.93       238\n",
      "weighted avg       0.94      0.94      0.94       238\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 479: Accuracy: 0.936, F1 Micro: 0.936, F1 Macro: 0.868\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.81      0.79        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.85      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.30      0.92      0.45        12\n",
      "     neutral       0.94      0.86      0.90       152\n",
      "    positive       0.87      0.65      0.75        52\n",
      "\n",
      "    accuracy                           0.81       216\n",
      "   macro avg       0.70      0.81      0.70       216\n",
      "weighted avg       0.88      0.81      0.84       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.96      0.86        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.94      0.76      0.84        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.90      0.89       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.93      0.87        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.65      0.79        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.93      0.86      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 97.425297498703 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.006224920507520437\n",
      "Acquired samples: 39\n",
      "Sampling duration: 9.288095951080322 seconds\n",
      "New train size: 518\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5447, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4698, Accuracy: 0.8036, F1 Micro: 0.8885, F1 Macro: 0.8867\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.386, Accuracy: 0.904, F1 Micro: 0.9417, F1 Macro: 0.9396\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2862, Accuracy: 0.936, F1 Micro: 0.9601, F1 Macro: 0.9581\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2094, Accuracy: 0.9509, F1 Micro: 0.9695, F1 Macro: 0.9685\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1478, Accuracy: 0.9516, F1 Micro: 0.9696, F1 Macro: 0.9673\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1175, Accuracy: 0.9531, F1 Micro: 0.9706, F1 Macro: 0.9687\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0952, Accuracy: 0.9546, F1 Micro: 0.9714, F1 Macro: 0.9698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0776, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0651, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9746\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9746\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.91      0.96      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5353, Accuracy: 0.8627, F1 Micro: 0.8627, F1 Macro: 0.8494\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2405, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9132\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1519, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9219\n",
      "Epoch 4/10, Train Loss: 0.1396, Accuracy: 0.9255, F1 Micro: 0.9255, F1 Macro: 0.9159\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0936, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9206\n",
      "Epoch 6/10, Train Loss: 0.0671, Accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.9101\n",
      "Epoch 7/10, Train Loss: 0.0519, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9137\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0646, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9201\n",
      "Epoch 9/10, Train Loss: 0.0542, Accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.9071\n",
      "Epoch 10/10, Train Loss: 0.0473, Accuracy: 0.9137, F1 Micro: 0.9137, F1 Macro: 0.9018\n",
      "\n",
      "Sentiment analysis accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9201\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.90      0.89        83\n",
      "    positive       0.95      0.94      0.95       172\n",
      "\n",
      "    accuracy                           0.93       255\n",
      "   macro avg       0.92      0.92      0.92       255\n",
      "weighted avg       0.93      0.93      0.93       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 518: Accuracy: 0.9452, F1 Micro: 0.9452, F1 Macro: 0.8774\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.92      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.88      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.69      0.79        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.78      0.76      0.77        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.88      0.81      0.84       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.91      0.95      0.93       152\n",
      "    positive       0.83      0.73      0.78        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.85      0.81      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.92      0.80      0.86        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.85      0.81        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.88      0.87      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.79      0.85        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.89      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 115.36601185798645 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.006512556411325932\n",
      "Acquired samples: 22\n",
      "Sampling duration: 8.939941644668579 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5518, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.476, Accuracy: 0.8006, F1 Micro: 0.887, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4061, Accuracy: 0.8906, F1 Micro: 0.934, F1 Macro: 0.932\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2896, Accuracy: 0.9412, F1 Micro: 0.9637, F1 Macro: 0.9624\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2152, Accuracy: 0.9539, F1 Micro: 0.9711, F1 Macro: 0.9698\n",
      "Epoch 6/10, Train Loss: 0.1549, Accuracy: 0.9524, F1 Micro: 0.97, F1 Macro: 0.9673\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1346, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9716\n",
      "Epoch 8/10, Train Loss: 0.101, Accuracy: 0.9531, F1 Micro: 0.9704, F1 Macro: 0.9679\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0865, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9738\n",
      "Epoch 10/10, Train Loss: 0.0684, Accuracy: 0.9561, F1 Micro: 0.9723, F1 Macro: 0.9706\n",
      "\n",
      "Aspect detection accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9738\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.91      0.93      0.92       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5124, Accuracy: 0.8682, F1 Micro: 0.8682, F1 Macro: 0.847\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2768, Accuracy: 0.9186, F1 Micro: 0.9186, F1 Macro: 0.9087\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1478, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9261\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1155, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9265\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0704, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9252\n",
      "Epoch 6/10, Train Loss: 0.0852, Accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.913\n",
      "Epoch 7/10, Train Loss: 0.0465, Accuracy: 0.9031, F1 Micro: 0.9031, F1 Macro: 0.8956\n",
      "Epoch 8/10, Train Loss: 0.0775, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.922\n",
      "Epoch 9/10, Train Loss: 0.0597, Accuracy: 0.9147, F1 Micro: 0.9147, F1 Macro: 0.8997\n",
      "Epoch 10/10, Train Loss: 0.0362, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.9215\n",
      "\n",
      "Sentiment analysis accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9252\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.90      0.90        84\n",
      "    positive       0.95      0.95      0.95       174\n",
      "\n",
      "    accuracy                           0.93       258\n",
      "   macro avg       0.92      0.93      0.93       258\n",
      "weighted avg       0.93      0.93      0.93       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9437, F1 Micro: 0.9437, F1 Macro: 0.8856\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.85      0.83      0.84       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.56      0.75      0.64        12\n",
      "     neutral       0.92      0.90      0.91       152\n",
      "    positive       0.76      0.75      0.76        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.75      0.80      0.77       216\n",
      "weighted avg       0.86      0.86      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.91      0.87        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.89      0.80      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.90      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.92      0.83        13\n",
      "     neutral       0.99      0.98      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.87      0.91      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.76      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 111.41366052627563 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.005328501109033824\n",
      "Acquired samples: 33\n",
      "Sampling duration: 8.427735567092896 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5483, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4692, Accuracy: 0.8125, F1 Micro: 0.8918, F1 Macro: 0.8896\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3719, Accuracy: 0.9196, F1 Micro: 0.9506, F1 Macro: 0.9485\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2639, Accuracy: 0.9524, F1 Micro: 0.9705, F1 Macro: 0.9696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.19, Accuracy: 0.9554, F1 Micro: 0.9722, F1 Macro: 0.9707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1549, Accuracy: 0.9561, F1 Micro: 0.9724, F1 Macro: 0.9712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1154, Accuracy: 0.9583, F1 Micro: 0.974, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0929, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.072, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.975\n",
      "Epoch 10/10, Train Loss: 0.0641, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9745\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.94      0.91      0.92       158\n",
      "        part       0.98      1.00      0.99       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5265, Accuracy: 0.8502, F1 Micro: 0.8502, F1 Macro: 0.8407\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2577, Accuracy: 0.9064, F1 Micro: 0.9064, F1 Macro: 0.8981\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.18, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.914\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1614, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9258\n",
      "Epoch 5/10, Train Loss: 0.095, Accuracy: 0.9288, F1 Micro: 0.9288, F1 Macro: 0.921\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0792, Accuracy: 0.9401, F1 Micro: 0.9401, F1 Macro: 0.933\n",
      "Epoch 7/10, Train Loss: 0.0639, Accuracy: 0.9288, F1 Micro: 0.9288, F1 Macro: 0.9218\n",
      "Epoch 8/10, Train Loss: 0.0762, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9223\n",
      "Epoch 9/10, Train Loss: 0.0419, Accuracy: 0.9251, F1 Micro: 0.9251, F1 Macro: 0.9171\n",
      "Epoch 10/10, Train Loss: 0.0396, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.929\n",
      "\n",
      "Sentiment analysis accuracy: 0.9401, F1 Micro: 0.9401, F1 Macro: 0.933\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.95      0.91        86\n",
      "    positive       0.98      0.93      0.95       181\n",
      "\n",
      "    accuracy                           0.94       267\n",
      "   macro avg       0.92      0.94      0.93       267\n",
      "weighted avg       0.94      0.94      0.94       267\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9028\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.83      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.92      0.85        12\n",
      "     neutral       0.94      0.90      0.92       152\n",
      "    positive       0.74      0.81      0.77        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.82      0.88      0.85       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       1.00      0.80      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.93      0.91       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.93      0.90        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 117.99124240875244 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.003983107674866915\n",
      "Acquired samples: 30\n",
      "Sampling duration: 7.649335145950317 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5332, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.455, Accuracy: 0.8251, F1 Micro: 0.8984, F1 Macro: 0.8964\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3515, Accuracy: 0.9293, F1 Micro: 0.9565, F1 Macro: 0.9548\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2478, Accuracy: 0.9494, F1 Micro: 0.9684, F1 Macro: 0.9665\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1766, Accuracy: 0.9606, F1 Micro: 0.9755, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1398, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9746\n",
      "Epoch 7/10, Train Loss: 0.11, Accuracy: 0.9561, F1 Micro: 0.9723, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0773, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9757\n",
      "Epoch 9/10, Train Loss: 0.0703, Accuracy: 0.9561, F1 Micro: 0.9723, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0592, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9757\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9757\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.97      0.97       175\n",
      "      others       0.92      0.93      0.92       158\n",
      "        part       0.98      1.00      0.99       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.478, Accuracy: 0.8523, F1 Micro: 0.8523, F1 Macro: 0.845\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2125, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.9062\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1556, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9241\n",
      "Epoch 4/10, Train Loss: 0.1208, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.921\n",
      "Epoch 5/10, Train Loss: 0.0809, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.9057\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0767, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9237\n",
      "Epoch 7/10, Train Loss: 0.0647, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.8993\n",
      "Epoch 8/10, Train Loss: 0.0864, Accuracy: 0.9205, F1 Micro: 0.9205, F1 Macro: 0.9126\n",
      "Epoch 9/10, Train Loss: 0.0529, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.9091\n",
      "Epoch 10/10, Train Loss: 0.0606, Accuracy: 0.9242, F1 Micro: 0.9242, F1 Macro: 0.9127\n",
      "\n",
      "Sentiment analysis accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9237\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.93      0.90        86\n",
      "    positive       0.97      0.93      0.95       178\n",
      "\n",
      "    accuracy                           0.93       264\n",
      "   macro avg       0.92      0.93      0.92       264\n",
      "weighted avg       0.93      0.93      0.93       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.8922\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.92      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.88      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.96      0.97      0.96       167\n",
      "    positive       0.79      0.79      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.84      0.85       216\n",
      "weighted avg       0.92      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.92      0.93      0.92       152\n",
      "    positive       0.78      0.77      0.78        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.85      0.84      0.84       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.96      0.94        23\n",
      "     neutral       0.97      1.00      0.99       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.94      0.94       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.79      0.85        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 116.56886458396912 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.0045978534035384655\n",
      "Acquired samples: 27\n",
      "Sampling duration: 6.871474027633667 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5284, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4629, Accuracy: 0.8289, F1 Micro: 0.9003, F1 Macro: 0.8983\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3522, Accuracy: 0.9234, F1 Micro: 0.9525, F1 Macro: 0.9497\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2303, Accuracy: 0.9546, F1 Micro: 0.9719, F1 Macro: 0.9706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1743, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9732\n",
      "Epoch 6/10, Train Loss: 0.132, Accuracy: 0.9583, F1 Micro: 0.9737, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0941, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0872, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9768\n",
      "Epoch 9/10, Train Loss: 0.0648, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.973\n",
      "Epoch 10/10, Train Loss: 0.0603, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9758\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5186, Accuracy: 0.8636, F1 Micro: 0.8636, F1 Macro: 0.8506\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2444, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.9057\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1814, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.9057\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1535, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9206\n",
      "Epoch 5/10, Train Loss: 0.1442, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.9018\n",
      "Epoch 6/10, Train Loss: 0.0917, Accuracy: 0.8977, F1 Micro: 0.8977, F1 Macro: 0.8911\n",
      "Epoch 7/10, Train Loss: 0.1062, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.9091\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0575, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9326\n",
      "Epoch 9/10, Train Loss: 0.0552, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9229\n",
      "Epoch 10/10, Train Loss: 0.0567, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.9078\n",
      "\n",
      "Sentiment analysis accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9326\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.95      0.91        86\n",
      "    positive       0.98      0.93      0.95       178\n",
      "\n",
      "    accuracy                           0.94       264\n",
      "   macro avg       0.92      0.94      0.93       264\n",
      "weighted avg       0.94      0.94      0.94       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.9483, F1 Micro: 0.9483, F1 Macro: 0.8913\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.91      0.88      0.89        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.81      0.79      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.84      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.75      0.67        12\n",
      "     neutral       0.93      0.92      0.93       152\n",
      "    positive       0.78      0.77      0.78        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.77      0.81      0.79       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      1.00      0.84        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       1.00      0.76      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.91      0.89       216\n",
      "weighted avg       0.96      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.91      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.96      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 120.19693875312805 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.002777983387932181\n",
      "Acquired samples: 18\n",
      "Sampling duration: 6.237768173217773 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.516, Accuracy: 0.7946, F1 Micro: 0.8847, F1 Macro: 0.8832\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4548, Accuracy: 0.8467, F1 Micro: 0.9092, F1 Macro: 0.9075\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3342, Accuracy: 0.9375, F1 Micro: 0.9616, F1 Macro: 0.9603\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2305, Accuracy: 0.9568, F1 Micro: 0.9732, F1 Macro: 0.9724\n",
      "Epoch 5/10, Train Loss: 0.1616, Accuracy: 0.9472, F1 Micro: 0.9666, F1 Macro: 0.963\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1244, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9744\n",
      "Epoch 7/10, Train Loss: 0.0936, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9732\n",
      "Epoch 8/10, Train Loss: 0.0746, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9741\n",
      "Epoch 9/10, Train Loss: 0.061, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0551, Accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9787\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9787\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.91      0.97      0.94       158\n",
      "        part       0.98      1.00      0.99       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5144, Accuracy: 0.8884, F1 Micro: 0.8884, F1 Macro: 0.8775\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2387, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9314\n",
      "Epoch 3/10, Train Loss: 0.1367, Accuracy: 0.9203, F1 Micro: 0.9203, F1 Macro: 0.915\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1173, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9314\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1014, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9314\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0801, Accuracy: 0.9402, F1 Micro: 0.9402, F1 Macro: 0.9352\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0695, Accuracy: 0.9482, F1 Micro: 0.9482, F1 Macro: 0.9433\n",
      "Epoch 8/10, Train Loss: 0.0655, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9269\n",
      "Epoch 9/10, Train Loss: 0.0452, Accuracy: 0.9402, F1 Micro: 0.9402, F1 Macro: 0.9346\n",
      "Epoch 10/10, Train Loss: 0.0708, Accuracy: 0.9402, F1 Micro: 0.9402, F1 Macro: 0.9352\n",
      "\n",
      "Sentiment analysis accuracy: 0.9482, F1 Micro: 0.9482, F1 Macro: 0.9433\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.93        86\n",
      "    positive       0.97      0.95      0.96       165\n",
      "\n",
      "    accuracy                           0.95       251\n",
      "   macro avg       0.94      0.95      0.94       251\n",
      "weighted avg       0.95      0.95      0.95       251\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9113\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.91      0.97      0.94       152\n",
      "    positive       0.88      0.71      0.79        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.85      0.84      0.84       216\n",
      "weighted avg       0.90      0.90      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.98      1.00      0.99       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.92      0.92       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.94      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 121.95499587059021 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.00421104459092021\n",
      "Acquired samples: 25\n",
      "Sampling duration: 6.039031267166138 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5334, Accuracy: 0.7924, F1 Micro: 0.8836, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.44, Accuracy: 0.8408, F1 Micro: 0.9065, F1 Macro: 0.9051\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3127, Accuracy: 0.9368, F1 Micro: 0.9609, F1 Macro: 0.9596\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2143, Accuracy: 0.9516, F1 Micro: 0.9698, F1 Macro: 0.9679\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1558, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1142, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9758\n",
      "Epoch 7/10, Train Loss: 0.09, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9753\n",
      "Epoch 8/10, Train Loss: 0.0782, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0627, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9765\n",
      "Epoch 10/10, Train Loss: 0.0522, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9757\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.91      0.93      0.92       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5593, Accuracy: 0.8973, F1 Micro: 0.8973, F1 Macro: 0.883\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.284, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9309\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1329, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9365\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0963, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9368\n",
      "Epoch 5/10, Train Loss: 0.1416, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9328\n",
      "Epoch 6/10, Train Loss: 0.1059, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9321\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0748, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9354\n",
      "Epoch 8/10, Train Loss: 0.0613, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9248\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0685, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9368\n",
      "Epoch 10/10, Train Loss: 0.0476, Accuracy: 0.9278, F1 Micro: 0.9278, F1 Macro: 0.9208\n",
      "\n",
      "Sentiment analysis accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9368\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.98      0.92        85\n",
      "    positive       0.99      0.93      0.96       178\n",
      "\n",
      "    accuracy                           0.94       263\n",
      "   macro avg       0.93      0.95      0.94       263\n",
      "weighted avg       0.95      0.94      0.94       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.8999\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.87      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      1.00      0.67        12\n",
      "     neutral       0.94      0.89      0.92       152\n",
      "    positive       0.79      0.73      0.76        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.75      0.88      0.78       216\n",
      "weighted avg       0.88      0.86      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.94      0.78      0.85        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.90      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.92      0.80        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.88      0.89      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 127.77621579170227 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.0034193152096122503\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.263793230056763 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5349, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4412, Accuracy: 0.8363, F1 Micro: 0.9047, F1 Macro: 0.9031\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3207, Accuracy: 0.9323, F1 Micro: 0.958, F1 Macro: 0.9562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2296, Accuracy: 0.9561, F1 Micro: 0.9726, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.163, Accuracy: 0.9643, F1 Micro: 0.9777, F1 Macro: 0.9768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1129, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9771\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0919, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9778\n",
      "Epoch 8/10, Train Loss: 0.0749, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0619, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.979\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0512, Accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.98\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.92      0.95      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      1.00      1.00       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5061, Accuracy: 0.8851, F1 Micro: 0.8851, F1 Macro: 0.8775\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2633, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9277\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1857, Accuracy: 0.9387, F1 Micro: 0.9387, F1 Macro: 0.9329\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1287, Accuracy: 0.9425, F1 Micro: 0.9425, F1 Macro: 0.9369\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1177, Accuracy: 0.9579, F1 Micro: 0.9579, F1 Macro: 0.953\n",
      "Epoch 6/10, Train Loss: 0.0747, Accuracy: 0.954, F1 Micro: 0.954, F1 Macro: 0.9483\n",
      "Epoch 7/10, Train Loss: 0.0714, Accuracy: 0.9272, F1 Micro: 0.9272, F1 Macro: 0.9205\n",
      "Epoch 8/10, Train Loss: 0.0766, Accuracy: 0.931, F1 Micro: 0.931, F1 Macro: 0.9248\n",
      "Epoch 9/10, Train Loss: 0.0697, Accuracy: 0.9387, F1 Micro: 0.9387, F1 Macro: 0.9314\n",
      "Epoch 10/10, Train Loss: 0.0745, Accuracy: 0.9195, F1 Micro: 0.9195, F1 Macro: 0.9075\n",
      "\n",
      "Sentiment analysis accuracy: 0.9579, F1 Micro: 0.9579, F1 Macro: 0.953\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94        86\n",
      "    positive       0.98      0.95      0.97       175\n",
      "\n",
      "    accuracy                           0.96       261\n",
      "   macro avg       0.95      0.96      0.95       261\n",
      "weighted avg       0.96      0.96      0.96       261\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.8994\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.92      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.88      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.82      0.82      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.85      0.87       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.83      0.75      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.84      0.84      0.84       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.91      0.89        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.92      0.92       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.99      1.00      1.00       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.85      1.00      0.92        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.93      0.93       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 130.3039424419403 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.003432838432490826\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.7995405197143555 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5223, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4424, Accuracy: 0.843, F1 Micro: 0.9081, F1 Macro: 0.9066\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2983, Accuracy: 0.9464, F1 Micro: 0.9669, F1 Macro: 0.9659\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2031, Accuracy: 0.9613, F1 Micro: 0.9759, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1373, Accuracy: 0.9621, F1 Micro: 0.9763, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1126, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9772\n",
      "Epoch 7/10, Train Loss: 0.0914, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9765\n",
      "Epoch 8/10, Train Loss: 0.0726, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0588, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9792\n",
      "Epoch 10/10, Train Loss: 0.05, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9776\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9792\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.98       175\n",
      "      others       0.92      0.96      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5696, Accuracy: 0.8649, F1 Micro: 0.8649, F1 Macro: 0.8423\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.272, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9241\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1783, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9356\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1389, Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9484\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1424, Accuracy: 0.9575, F1 Micro: 0.9575, F1 Macro: 0.952\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1002, Accuracy: 0.9575, F1 Micro: 0.9575, F1 Macro: 0.9528\n",
      "Epoch 7/10, Train Loss: 0.0932, Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9442\n",
      "Epoch 8/10, Train Loss: 0.0641, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9186\n",
      "Epoch 9/10, Train Loss: 0.0562, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9322\n",
      "Epoch 10/10, Train Loss: 0.0409, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9258\n",
      "\n",
      "Sentiment analysis accuracy: 0.9575, F1 Micro: 0.9575, F1 Macro: 0.9528\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94        85\n",
      "    positive       0.99      0.95      0.97       174\n",
      "\n",
      "    accuracy                           0.96       259\n",
      "   macro avg       0.95      0.96      0.95       259\n",
      "weighted avg       0.96      0.96      0.96       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.56      0.60        16\n",
      "     neutral       0.98      0.96      0.97       167\n",
      "    positive       0.76      0.85      0.80        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.79      0.79      0.79       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.92      0.81        12\n",
      "     neutral       0.93      0.94      0.93       152\n",
      "    positive       0.85      0.77      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.84      0.88      0.85       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.91       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.92      0.89      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 133.14216327667236 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.003691493649967015\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.185899972915649 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5206, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4259, Accuracy: 0.8914, F1 Micro: 0.9346, F1 Macro: 0.9333\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2842, Accuracy: 0.9524, F1 Micro: 0.9703, F1 Macro: 0.969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1887, Accuracy: 0.965, F1 Micro: 0.9782, F1 Macro: 0.9771\n",
      "Epoch 5/10, Train Loss: 0.1366, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9759\n",
      "Epoch 6/10, Train Loss: 0.107, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0878, Accuracy: 0.9702, F1 Micro: 0.9812, F1 Macro: 0.9799\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0645, Accuracy: 0.971, F1 Micro: 0.9817, F1 Macro: 0.9805\n",
      "Epoch 9/10, Train Loss: 0.0567, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9768\n",
      "Epoch 10/10, Train Loss: 0.0469, Accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9792\n",
      "\n",
      "Aspect detection accuracy: 0.971, F1 Micro: 0.9817, F1 Macro: 0.9805\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.94      0.94       158\n",
      "        part       0.98      1.00      0.99       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.98      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.492, Accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.9035\n",
      "Epoch 2/10, Train Loss: 0.2349, Accuracy: 0.9119, F1 Micro: 0.9119, F1 Macro: 0.905\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1843, Accuracy: 0.9425, F1 Micro: 0.9425, F1 Macro: 0.9369\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1204, Accuracy: 0.9655, F1 Micro: 0.9655, F1 Macro: 0.9611\n",
      "Epoch 5/10, Train Loss: 0.1122, Accuracy: 0.9387, F1 Micro: 0.9387, F1 Macro: 0.9329\n",
      "Epoch 6/10, Train Loss: 0.0936, Accuracy: 0.954, F1 Micro: 0.954, F1 Macro: 0.9489\n",
      "Epoch 7/10, Train Loss: 0.0818, Accuracy: 0.9617, F1 Micro: 0.9617, F1 Macro: 0.9574\n",
      "Epoch 8/10, Train Loss: 0.0723, Accuracy: 0.9617, F1 Micro: 0.9617, F1 Macro: 0.9569\n",
      "Epoch 9/10, Train Loss: 0.0678, Accuracy: 0.9425, F1 Micro: 0.9425, F1 Macro: 0.9369\n",
      "Epoch 10/10, Train Loss: 0.046, Accuracy: 0.9579, F1 Micro: 0.9579, F1 Macro: 0.9524\n",
      "\n",
      "Sentiment analysis accuracy: 0.9655, F1 Micro: 0.9655, F1 Macro: 0.9611\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.94      0.95        87\n",
      "    positive       0.97      0.98      0.97       174\n",
      "\n",
      "    accuracy                           0.97       261\n",
      "   macro avg       0.96      0.96      0.96       261\n",
      "weighted avg       0.97      0.97      0.97       261\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9219\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.86      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.92      0.73        12\n",
      "     neutral       0.95      0.91      0.93       152\n",
      "    positive       0.83      0.83      0.83        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.79      0.88      0.83       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.92      0.91       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      1.00       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.94      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 128.46547079086304 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.003083391068503261\n",
      "Acquired samples: 8\n",
      "Sampling duration: 3.671287775039673 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5218, Accuracy: 0.7939, F1 Micro: 0.8845, F1 Macro: 0.8831\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4292, Accuracy: 0.8966, F1 Micro: 0.9378, F1 Macro: 0.9361\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2839, Accuracy: 0.9472, F1 Micro: 0.9672, F1 Macro: 0.9657\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.197, Accuracy: 0.9568, F1 Micro: 0.9731, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1404, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1031, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9773\n",
      "Epoch 7/10, Train Loss: 0.0808, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9774\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0625, Accuracy: 0.9702, F1 Micro: 0.9812, F1 Macro: 0.9795\n",
      "Epoch 9/10, Train Loss: 0.0551, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.978\n",
      "Epoch 10/10, Train Loss: 0.0478, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9779\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9812, F1 Macro: 0.9795\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.94      0.92      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      1.00      1.00       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4986, Accuracy: 0.9004, F1 Micro: 0.9004, F1 Macro: 0.8914\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.24, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.9075\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1385, Accuracy: 0.952, F1 Micro: 0.952, F1 Macro: 0.9458\n",
      "Epoch 4/10, Train Loss: 0.1202, Accuracy: 0.9299, F1 Micro: 0.9299, F1 Macro: 0.9224\n",
      "Epoch 5/10, Train Loss: 0.1133, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9302\n",
      "Epoch 6/10, Train Loss: 0.0952, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9299\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0549, Accuracy: 0.952, F1 Micro: 0.952, F1 Macro: 0.9458\n",
      "Epoch 8/10, Train Loss: 0.0559, Accuracy: 0.9446, F1 Micro: 0.9446, F1 Macro: 0.9367\n",
      "Epoch 9/10, Train Loss: 0.0406, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.9061\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0579, Accuracy: 0.9557, F1 Micro: 0.9557, F1 Macro: 0.9501\n",
      "\n",
      "Sentiment analysis accuracy: 0.9557, F1 Micro: 0.9557, F1 Macro: 0.9501\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.93        87\n",
      "    positive       0.98      0.95      0.97       184\n",
      "\n",
      "    accuracy                           0.96       271\n",
      "   macro avg       0.94      0.96      0.95       271\n",
      "weighted avg       0.96      0.96      0.96       271\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9614, F1 Micro: 0.9614, F1 Macro: 0.935\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       1.00      0.96      0.98        24\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.99      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.97      0.98      0.97       167\n",
      "    positive       0.88      0.85      0.86        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.90      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.92      0.88        12\n",
      "     neutral       0.95      0.91      0.93       152\n",
      "    positive       0.75      0.81      0.78        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.85      0.88      0.86       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.91       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      1.00       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.94      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 134.44658398628235 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.001924624084495008\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.6465964317321777 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5235, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4217, Accuracy: 0.9048, F1 Micro: 0.9419, F1 Macro: 0.9398\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2726, Accuracy: 0.9539, F1 Micro: 0.9714, F1 Macro: 0.9701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1854, Accuracy: 0.9554, F1 Micro: 0.972, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1304, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0998, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9775\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0804, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9797\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0618, Accuracy: 0.9695, F1 Micro: 0.9809, F1 Macro: 0.9798\n",
      "Epoch 9/10, Train Loss: 0.056, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9777\n",
      "Epoch 10/10, Train Loss: 0.0482, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.978\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9809, F1 Macro: 0.9798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5186, Accuracy: 0.9141, F1 Micro: 0.9141, F1 Macro: 0.9062\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2371, Accuracy: 0.918, F1 Micro: 0.918, F1 Macro: 0.9115\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1669, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9277\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.091, Accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9442\n",
      "Epoch 5/10, Train Loss: 0.097, Accuracy: 0.9258, F1 Micro: 0.9258, F1 Macro: 0.9171\n",
      "Epoch 6/10, Train Loss: 0.0841, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.94\n",
      "Epoch 7/10, Train Loss: 0.0871, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9277\n",
      "Epoch 8/10, Train Loss: 0.0667, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9345\n",
      "Epoch 9/10, Train Loss: 0.0645, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9315\n",
      "Epoch 10/10, Train Loss: 0.0516, Accuracy: 0.9141, F1 Micro: 0.9141, F1 Macro: 0.9079\n",
      "\n",
      "Sentiment analysis accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9442\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.97      0.93        86\n",
      "    positive       0.98      0.94      0.96       170\n",
      "\n",
      "    accuracy                           0.95       256\n",
      "   macro avg       0.94      0.95      0.94       256\n",
      "weighted avg       0.95      0.95      0.95       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.8883\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.88      0.93        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.94      0.86        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.89      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.56      0.75      0.64        12\n",
      "     neutral       0.92      0.94      0.93       152\n",
      "    positive       0.84      0.71      0.77        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.77      0.80      0.78       216\n",
      "weighted avg       0.88      0.88      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      1.00      0.85        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.76      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.91      0.89       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.92      0.83        13\n",
      "     neutral       0.99      1.00      1.00       186\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.88      0.87       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 136.7601044178009 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0032124977093189954\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.8371996879577637 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5183, Accuracy: 0.7946, F1 Micro: 0.8849, F1 Macro: 0.8834\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4143, Accuracy: 0.9055, F1 Micro: 0.942, F1 Macro: 0.9393\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2676, Accuracy: 0.9539, F1 Micro: 0.9712, F1 Macro: 0.9697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.17, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1201, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.096, Accuracy: 0.9695, F1 Micro: 0.9809, F1 Macro: 0.9799\n",
      "Epoch 7/10, Train Loss: 0.0728, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9777\n",
      "Epoch 8/10, Train Loss: 0.0642, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9793\n",
      "Epoch 9/10, Train Loss: 0.0533, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9795\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0441, Accuracy: 0.9702, F1 Micro: 0.9812, F1 Macro: 0.98\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9812, F1 Macro: 0.98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.98       175\n",
      "      others       0.94      0.94      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5117, Accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.8989\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2271, Accuracy: 0.9188, F1 Micro: 0.9188, F1 Macro: 0.9117\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1678, Accuracy: 0.941, F1 Micro: 0.941, F1 Macro: 0.9338\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1494, Accuracy: 0.952, F1 Micro: 0.952, F1 Macro: 0.9464\n",
      "Epoch 5/10, Train Loss: 0.1163, Accuracy: 0.941, F1 Micro: 0.941, F1 Macro: 0.9331\n",
      "Epoch 6/10, Train Loss: 0.0912, Accuracy: 0.9262, F1 Micro: 0.9262, F1 Macro: 0.9186\n",
      "Epoch 7/10, Train Loss: 0.06, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9306\n",
      "Epoch 8/10, Train Loss: 0.0495, Accuracy: 0.9483, F1 Micro: 0.9483, F1 Macro: 0.9424\n",
      "Epoch 9/10, Train Loss: 0.0495, Accuracy: 0.9188, F1 Micro: 0.9188, F1 Macro: 0.9113\n",
      "Epoch 10/10, Train Loss: 0.0519, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9299\n",
      "\n",
      "Sentiment analysis accuracy: 0.952, F1 Micro: 0.952, F1 Macro: 0.9464\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.97      0.93        88\n",
      "    positive       0.98      0.95      0.96       183\n",
      "\n",
      "    accuracy                           0.95       271\n",
      "   macro avg       0.94      0.96      0.95       271\n",
      "weighted avg       0.95      0.95      0.95       271\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.922\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.97      0.98      0.98       167\n",
      "    positive       0.85      0.85      0.85        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.88      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.92      0.88        12\n",
      "     neutral       0.94      0.93      0.94       152\n",
      "    positive       0.79      0.79      0.79        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.86      0.88      0.87       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 138.29142498970032 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.006424322538077831\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.306091785430908 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5279, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4371, Accuracy: 0.8757, F1 Micro: 0.9263, F1 Macro: 0.9246\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2711, Accuracy: 0.9516, F1 Micro: 0.9699, F1 Macro: 0.9685\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1816, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1297, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0949, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "Epoch 7/10, Train Loss: 0.0799, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0649, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.977\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0529, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9773\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0429, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9787\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9787\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.98       175\n",
      "      others       0.92      0.95      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5249, Accuracy: 0.8855, F1 Micro: 0.8855, F1 Macro: 0.8772\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2452, Accuracy: 0.9046, F1 Micro: 0.9046, F1 Macro: 0.8975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1674, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9279\n",
      "Epoch 4/10, Train Loss: 0.1305, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.8949\n",
      "Epoch 5/10, Train Loss: 0.1044, Accuracy: 0.9275, F1 Micro: 0.9275, F1 Macro: 0.9194\n",
      "Epoch 6/10, Train Loss: 0.1005, Accuracy: 0.9275, F1 Micro: 0.9275, F1 Macro: 0.921\n",
      "Epoch 7/10, Train Loss: 0.0903, Accuracy: 0.9275, F1 Micro: 0.9275, F1 Macro: 0.918\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0722, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9286\n",
      "Epoch 9/10, Train Loss: 0.0488, Accuracy: 0.9122, F1 Micro: 0.9122, F1 Macro: 0.9048\n",
      "Epoch 10/10, Train Loss: 0.0542, Accuracy: 0.916, F1 Micro: 0.916, F1 Macro: 0.9088\n",
      "\n",
      "Sentiment analysis accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9286\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.95      0.91        87\n",
      "    positive       0.98      0.93      0.95       175\n",
      "\n",
      "    accuracy                           0.94       262\n",
      "   macro avg       0.92      0.94      0.93       262\n",
      "weighted avg       0.94      0.94      0.94       262\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.8991\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.91      0.87        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.91      0.83      0.87        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.97      0.98      0.98       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.83      0.74        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.82      0.71      0.76        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.80      0.83      0.81       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.80      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.92      0.83        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.86      0.71      0.77        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.87      0.87      0.86       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 144.39063000679016 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.002075945073738694\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.6676182746887207 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5216, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4072, Accuracy: 0.9033, F1 Micro: 0.9417, F1 Macro: 0.9397\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2545, Accuracy: 0.9554, F1 Micro: 0.9723, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1694, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1267, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0954, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9786\n",
      "Epoch 7/10, Train Loss: 0.0775, Accuracy: 0.9673, F1 Micro: 0.9792, F1 Macro: 0.9777\n",
      "Epoch 8/10, Train Loss: 0.0588, Accuracy: 0.968, F1 Micro: 0.9797, F1 Macro: 0.9782\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0507, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9794\n",
      "Epoch 10/10, Train Loss: 0.041, Accuracy: 0.968, F1 Micro: 0.9797, F1 Macro: 0.9783\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9794\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.94      0.94      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4823, Accuracy: 0.9242, F1 Micro: 0.9242, F1 Macro: 0.9157\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2194, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9318\n",
      "Epoch 3/10, Train Loss: 0.1797, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9253\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1092, Accuracy: 0.9432, F1 Micro: 0.9432, F1 Macro: 0.9355\n",
      "Epoch 5/10, Train Loss: 0.1075, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9249\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0821, Accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.94\n",
      "Epoch 7/10, Train Loss: 0.0901, Accuracy: 0.9242, F1 Micro: 0.9242, F1 Macro: 0.9166\n",
      "Epoch 8/10, Train Loss: 0.0787, Accuracy: 0.9432, F1 Micro: 0.9432, F1 Macro: 0.9351\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0732, Accuracy: 0.9508, F1 Micro: 0.9508, F1 Macro: 0.9448\n",
      "Epoch 10/10, Train Loss: 0.0567, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9314\n",
      "\n",
      "Sentiment analysis accuracy: 0.9508, F1 Micro: 0.9508, F1 Macro: 0.9448\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.93        86\n",
      "    positive       0.98      0.95      0.96       178\n",
      "\n",
      "    accuracy                           0.95       264\n",
      "   macro avg       0.94      0.95      0.94       264\n",
      "weighted avg       0.95      0.95      0.95       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9036\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.82      0.86        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.92      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.81      0.79        16\n",
      "     neutral       0.97      0.98      0.98       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.87      0.86      0.86       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.92      0.76        12\n",
      "     neutral       0.95      0.91      0.93       152\n",
      "    positive       0.79      0.81      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.80      0.88      0.83       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      1.00      0.84        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.92      0.89       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.95      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 145.0963306427002 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0017867399845272304\n",
      "Acquired samples: 8\n",
      "Sampling duration: 1.1169745922088623 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5171, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4025, Accuracy: 0.9137, F1 Micro: 0.9471, F1 Macro: 0.9452\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2479, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1691, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1172, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0895, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9771\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0764, Accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9802\n",
      "Epoch 8/10, Train Loss: 0.06, Accuracy: 0.9658, F1 Micro: 0.9783, F1 Macro: 0.9765\n",
      "Epoch 9/10, Train Loss: 0.05, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9772\n",
      "Epoch 10/10, Train Loss: 0.0401, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9795\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9802\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.92      0.97      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4593, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.9053\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2437, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9319\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1523, Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9439\n",
      "Epoch 4/10, Train Loss: 0.107, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9278\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0931, Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9486\n",
      "Epoch 6/10, Train Loss: 0.0715, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9308\n",
      "Epoch 7/10, Train Loss: 0.0823, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9201\n",
      "Epoch 8/10, Train Loss: 0.0675, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9401\n",
      "Epoch 9/10, Train Loss: 0.056, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9221\n",
      "Epoch 10/10, Train Loss: 0.0503, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.936\n",
      "\n",
      "Sentiment analysis accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9486\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.93        85\n",
      "    positive       0.99      0.94      0.96       174\n",
      "\n",
      "    accuracy                           0.95       259\n",
      "   macro avg       0.94      0.96      0.95       259\n",
      "weighted avg       0.96      0.95      0.95       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.9128\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.96      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.82      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.87      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      1.00      0.77        12\n",
      "     neutral       0.94      0.94      0.94       152\n",
      "    positive       0.89      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.82      0.90      0.85       216\n",
      "weighted avg       0.91      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      1.00      1.00       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.91      0.90      0.90       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 143.84686589241028 s\n",
      "Total runtime: 3083.785140514374 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[3], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdcb24e",
   "metadata": {
    "papermill": {
     "duration": 0.186289,
     "end_time": "2025-03-06T11:42:51.655960",
     "exception": false,
     "start_time": "2025-03-06T11:42:51.469671",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f508b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 5\n",
      "Random seed: 94\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6298, Accuracy: 0.7522, F1 Micro: 0.854, F1 Macro: 0.8362\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5654, Accuracy: 0.7887, F1 Micro: 0.8819, F1 Macro: 0.8803\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5262, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4783, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4582, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4326, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4132, Accuracy: 0.7924, F1 Micro: 0.8837, F1 Macro: 0.8822\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4395, Accuracy: 0.7939, F1 Micro: 0.8842, F1 Macro: 0.8826\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.4306, Accuracy: 0.7999, F1 Micro: 0.887, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3956, Accuracy: 0.8036, F1 Micro: 0.8888, F1 Macro: 0.8871\n",
      "\n",
      "Aspect detection accuracy: 0.8036, F1 Micro: 0.8888, F1 Macro: 0.8871\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.78      1.00      0.88       175\n",
      "      others       0.75      0.99      0.85       158\n",
      "        part       0.74      0.97      0.84       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.80      0.99      0.89      1061\n",
      "   macro avg       0.80      0.99      0.89      1061\n",
      "weighted avg       0.81      0.99      0.89      1061\n",
      " samples avg       0.81      0.99      0.89      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7142, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5719, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.6151, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5677, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.5123, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.5138, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4932, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3579, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3098, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2431, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "\n",
      "Sentiment analysis accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         6\n",
      "    positive       0.81      1.00      0.89        25\n",
      "\n",
      "    accuracy                           0.81        31\n",
      "   macro avg       0.40      0.50      0.45        31\n",
      "weighted avg       0.65      0.81      0.72        31\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.7994, F1 Micro: 0.7994, F1 Macro: 0.3298\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.77      1.00      0.87       167\n",
      "    positive       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.77       216\n",
      "   macro avg       0.26      0.33      0.29       216\n",
      "weighted avg       0.60      0.77      0.67       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.75      0.99      0.85       152\n",
      "    positive       0.67      0.19      0.30        52\n",
      "\n",
      "    accuracy                           0.74       216\n",
      "   macro avg       0.47      0.39      0.38       216\n",
      "weighted avg       0.69      0.74      0.67       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        23\n",
      "     neutral       0.74      0.97      0.84       152\n",
      "    positive       0.56      0.22      0.32        41\n",
      "\n",
      "    accuracy                           0.73       216\n",
      "   macro avg       0.43      0.40      0.39       216\n",
      "weighted avg       0.63      0.73      0.65       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 67.54837846755981 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.004518020898103714\n",
      "Acquired samples: 82\n",
      "Sampling duration: 14.151984691619873 seconds\n",
      "New train size: 136\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6205, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5585, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5256, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4961, Accuracy: 0.8028, F1 Micro: 0.8881, F1 Macro: 0.8863\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.483, Accuracy: 0.8058, F1 Micro: 0.8897, F1 Macro: 0.888\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4131, Accuracy: 0.814, F1 Micro: 0.8935, F1 Macro: 0.8916\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3886, Accuracy: 0.8266, F1 Micro: 0.8994, F1 Macro: 0.8975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3387, Accuracy: 0.8438, F1 Micro: 0.9077, F1 Macro: 0.9055\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2886, Accuracy: 0.8579, F1 Micro: 0.9159, F1 Macro: 0.9144\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2587, Accuracy: 0.872, F1 Micro: 0.9227, F1 Macro: 0.9205\n",
      "\n",
      "Aspect detection accuracy: 0.872, F1 Micro: 0.9227, F1 Macro: 0.9205\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.92      0.99      0.95       187\n",
      "     machine       0.82      0.99      0.89       175\n",
      "      others       0.88      0.84      0.86       158\n",
      "        part       0.87      0.97      0.92       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.96      0.99      0.97       191\n",
      "\n",
      "   micro avg       0.88      0.97      0.92      1061\n",
      "   macro avg       0.88      0.96      0.92      1061\n",
      "weighted avg       0.88      0.97      0.92      1061\n",
      " samples avg       0.89      0.97      0.92      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.551, Accuracy: 0.7701, F1 Micro: 0.7701, F1 Macro: 0.4351\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4534, Accuracy: 0.7701, F1 Micro: 0.7701, F1 Macro: 0.4351\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4111, Accuracy: 0.7701, F1 Micro: 0.7701, F1 Macro: 0.4351\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3035, Accuracy: 0.7816, F1 Micro: 0.7816, F1 Macro: 0.4855\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2234, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8655\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1284, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0868, Accuracy: 0.931, F1 Micro: 0.931, F1 Macro: 0.9058\n",
      "Epoch 8/10, Train Loss: 0.0842, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.8818\n",
      "Epoch 9/10, Train Loss: 0.0854, Accuracy: 0.9195, F1 Micro: 0.9195, F1 Macro: 0.8902\n",
      "Epoch 10/10, Train Loss: 0.0161, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.8818\n",
      "\n",
      "Sentiment analysis accuracy: 0.931, F1 Micro: 0.931, F1 Macro: 0.9058\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.90      0.86        40\n",
      "    positive       0.97      0.94      0.95       134\n",
      "\n",
      "    accuracy                           0.93       174\n",
      "   macro avg       0.89      0.92      0.91       174\n",
      "weighted avg       0.93      0.93      0.93       174\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 136: Accuracy: 0.8634, F1 Micro: 0.8634, F1 Macro: 0.6356\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.36      0.53        11\n",
      "     neutral       0.92      0.99      0.95       181\n",
      "    positive       0.88      0.62      0.73        24\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.93      0.66      0.74       216\n",
      "weighted avg       0.92      0.92      0.91       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.12      0.22        16\n",
      "     neutral       0.81      0.99      0.89       167\n",
      "    positive       0.80      0.24      0.37        33\n",
      "\n",
      "    accuracy                           0.81       216\n",
      "   macro avg       0.87      0.45      0.49       216\n",
      "weighted avg       0.82      0.81      0.76       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.47      0.67      0.55        12\n",
      "     neutral       0.88      0.84      0.86       152\n",
      "    positive       0.62      0.65      0.64        52\n",
      "\n",
      "    accuracy                           0.78       216\n",
      "   macro avg       0.66      0.72      0.68       216\n",
      "weighted avg       0.80      0.78      0.79       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.52      0.65        23\n",
      "     neutral       0.87      0.98      0.92       152\n",
      "    positive       0.87      0.63      0.73        41\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.86      0.71      0.77       216\n",
      "weighted avg       0.87      0.87      0.86       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.86      0.83        14\n",
      "     neutral       0.96      0.99      0.97       185\n",
      "    positive       0.90      0.53      0.67        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.79      0.82       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Total train time: 79.06074595451355 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.008940141089260579\n",
      "Acquired samples: 73\n",
      "Sampling duration: 14.917396068572998 seconds\n",
      "New train size: 209\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.595, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5147, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4887, Accuracy: 0.8006, F1 Micro: 0.8879, F1 Macro: 0.8864\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4587, Accuracy: 0.8058, F1 Micro: 0.89, F1 Macro: 0.8884\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4261, Accuracy: 0.8207, F1 Micro: 0.8968, F1 Macro: 0.8951\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3735, Accuracy: 0.8438, F1 Micro: 0.9082, F1 Macro: 0.9067\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2986, Accuracy: 0.8862, F1 Micro: 0.9316, F1 Macro: 0.93\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2613, Accuracy: 0.907, F1 Micro: 0.9428, F1 Macro: 0.9401\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1996, Accuracy: 0.9174, F1 Micro: 0.9488, F1 Macro: 0.9449\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1656, Accuracy: 0.9308, F1 Micro: 0.9572, F1 Macro: 0.9551\n",
      "\n",
      "Aspect detection accuracy: 0.9308, F1 Micro: 0.9572, F1 Macro: 0.9551\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.97      1.00      0.99       187\n",
      "     machine       0.93      0.97      0.95       175\n",
      "      others       0.89      0.92      0.91       158\n",
      "        part       0.89      0.98      0.93       158\n",
      "       price       0.95      1.00      0.97       192\n",
      "     service       0.97      0.99      0.98       191\n",
      "\n",
      "   micro avg       0.94      0.98      0.96      1061\n",
      "   macro avg       0.93      0.98      0.96      1061\n",
      "weighted avg       0.94      0.98      0.96      1061\n",
      " samples avg       0.94      0.98      0.95      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6172, Accuracy: 0.7022, F1 Micro: 0.7022, F1 Macro: 0.4125\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4545, Accuracy: 0.8267, F1 Micro: 0.8267, F1 Macro: 0.8043\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3328, Accuracy: 0.8889, F1 Micro: 0.8889, F1 Macro: 0.877\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.203, Accuracy: 0.9156, F1 Micro: 0.9156, F1 Macro: 0.9026\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1267, Accuracy: 0.9244, F1 Micro: 0.9244, F1 Macro: 0.9108\n",
      "Epoch 6/10, Train Loss: 0.1258, Accuracy: 0.92, F1 Micro: 0.92, F1 Macro: 0.9088\n",
      "Epoch 7/10, Train Loss: 0.1122, Accuracy: 0.9156, F1 Micro: 0.9156, F1 Macro: 0.9003\n",
      "Epoch 8/10, Train Loss: 0.1046, Accuracy: 0.92, F1 Micro: 0.92, F1 Macro: 0.9067\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1107, Accuracy: 0.9244, F1 Micro: 0.9244, F1 Macro: 0.9122\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1046, Accuracy: 0.9244, F1 Micro: 0.9244, F1 Macro: 0.9108\n",
      "\n",
      "Sentiment analysis accuracy: 0.9244, F1 Micro: 0.9244, F1 Macro: 0.9108\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.90      0.88        67\n",
      "    positive       0.95      0.94      0.95       158\n",
      "\n",
      "    accuracy                           0.92       225\n",
      "   macro avg       0.91      0.92      0.91       225\n",
      "weighted avg       0.93      0.92      0.92       225\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 209: Accuracy: 0.9198, F1 Micro: 0.9198, F1 Macro: 0.8269\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       1.00      0.88      0.93        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.99      0.93      0.96       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.93      0.96      0.94       167\n",
      "    positive       0.78      0.64      0.70        33\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.86      0.80      0.83       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.56      0.42      0.48        12\n",
      "     neutral       0.89      0.92      0.91       152\n",
      "    positive       0.74      0.71      0.73        52\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.73      0.68      0.70       216\n",
      "weighted avg       0.84      0.84      0.84       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.65      0.75        23\n",
      "     neutral       0.89      0.99      0.93       152\n",
      "    positive       0.90      0.66      0.76        41\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.89      0.77      0.82       216\n",
      "weighted avg       0.89      0.89      0.88       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.46      0.60        13\n",
      "     neutral       0.95      1.00      0.97       186\n",
      "    positive       0.85      0.65      0.73        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.70      0.77       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.79      0.85        14\n",
      "     neutral       0.97      0.99      0.98       185\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.85      0.89       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Total train time: 90.78709840774536 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.006170511245727539\n",
      "Acquired samples: 66\n",
      "Sampling duration: 17.833820819854736 seconds\n",
      "New train size: 275\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5744, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 2/10, Train Loss: 0.5009, Accuracy: 0.7894, F1 Micro: 0.8804, F1 Macro: 0.8777\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4685, Accuracy: 0.8028, F1 Micro: 0.8878, F1 Macro: 0.8856\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4321, Accuracy: 0.814, F1 Micro: 0.8921, F1 Macro: 0.8893\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3679, Accuracy: 0.8542, F1 Micro: 0.9132, F1 Macro: 0.9108\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2984, Accuracy: 0.8981, F1 Micro: 0.9365, F1 Macro: 0.9314\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2436, Accuracy: 0.9174, F1 Micro: 0.9488, F1 Macro: 0.9454\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1861, Accuracy: 0.9315, F1 Micro: 0.9575, F1 Macro: 0.9548\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1476, Accuracy: 0.9323, F1 Micro: 0.9575, F1 Macro: 0.9536\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1285, Accuracy: 0.9338, F1 Micro: 0.9582, F1 Macro: 0.9541\n",
      "\n",
      "Aspect detection accuracy: 0.9338, F1 Micro: 0.9582, F1 Macro: 0.9541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.97      0.96       175\n",
      "      others       0.91      0.80      0.86       158\n",
      "        part       0.92      0.98      0.95       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       0.97      0.99      0.98       191\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      1061\n",
      "   macro avg       0.95      0.96      0.95      1061\n",
      "weighted avg       0.95      0.96      0.96      1061\n",
      " samples avg       0.96      0.96      0.95      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6142, Accuracy: 0.7068, F1 Micro: 0.7068, F1 Macro: 0.4141\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4114, Accuracy: 0.8797, F1 Micro: 0.8797, F1 Macro: 0.8549\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.226, Accuracy: 0.906, F1 Micro: 0.906, F1 Macro: 0.8879\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.16, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.8969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1025, Accuracy: 0.9211, F1 Micro: 0.9211, F1 Macro: 0.9013\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1443, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9165\n",
      "Epoch 7/10, Train Loss: 0.103, Accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.903\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0799, Accuracy: 0.9361, F1 Micro: 0.9361, F1 Macro: 0.9232\n",
      "Epoch 9/10, Train Loss: 0.1134, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9154\n",
      "Epoch 10/10, Train Loss: 0.0627, Accuracy: 0.9248, F1 Micro: 0.9248, F1 Macro: 0.9064\n",
      "\n",
      "Sentiment analysis accuracy: 0.9361, F1 Micro: 0.9361, F1 Macro: 0.9232\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.90      0.89        78\n",
      "    positive       0.96      0.95      0.95       188\n",
      "\n",
      "    accuracy                           0.94       266\n",
      "   macro avg       0.92      0.92      0.92       266\n",
      "weighted avg       0.94      0.94      0.94       266\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 275: Accuracy: 0.9221, F1 Micro: 0.9221, F1 Macro: 0.8484\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.88      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.69      0.81        16\n",
      "     neutral       0.95      0.96      0.96       167\n",
      "    positive       0.74      0.79      0.76        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.90      0.81      0.85       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.67      0.70        12\n",
      "     neutral       0.92      0.81      0.86       152\n",
      "    positive       0.61      0.83      0.70        52\n",
      "\n",
      "    accuracy                           0.81       216\n",
      "   macro avg       0.75      0.77      0.75       216\n",
      "weighted avg       0.83      0.81      0.81       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.83      0.86        23\n",
      "     neutral       0.92      0.98      0.95       152\n",
      "    positive       0.88      0.71      0.78        41\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.90      0.84      0.87       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.54      0.70        13\n",
      "     neutral       0.97      1.00      0.99       186\n",
      "    positive       0.72      0.76      0.74        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.90      0.77      0.81       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.79      0.85        14\n",
      "     neutral       0.97      0.99      0.98       185\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.87      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 97.67386984825134 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.008447544369846582\n",
      "Acquired samples: 59\n",
      "Sampling duration: 15.41175127029419 seconds\n",
      "New train size: 334\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5899, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5165, Accuracy: 0.7946, F1 Micro: 0.8834, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4603, Accuracy: 0.8095, F1 Micro: 0.89, F1 Macro: 0.8872\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.41, Accuracy: 0.8586, F1 Micro: 0.917, F1 Macro: 0.9161\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.318, Accuracy: 0.9115, F1 Micro: 0.9447, F1 Macro: 0.9407\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2452, Accuracy: 0.9219, F1 Micro: 0.9507, F1 Macro: 0.9464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1849, Accuracy: 0.9353, F1 Micro: 0.9591, F1 Macro: 0.9551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1447, Accuracy: 0.9435, F1 Micro: 0.9645, F1 Macro: 0.9617\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1172, Accuracy: 0.9472, F1 Micro: 0.9667, F1 Macro: 0.964\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.097, Accuracy: 0.9509, F1 Micro: 0.9691, F1 Macro: 0.9666\n",
      "\n",
      "Aspect detection accuracy: 0.9509, F1 Micro: 0.9691, F1 Macro: 0.9666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.91      0.89      0.90       158\n",
      "        part       0.93      0.98      0.96       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.97      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6263, Accuracy: 0.6873, F1 Micro: 0.6873, F1 Macro: 0.4073\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4418, Accuracy: 0.8726, F1 Micro: 0.8726, F1 Macro: 0.8568\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2793, Accuracy: 0.9189, F1 Micro: 0.9189, F1 Macro: 0.9094\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1958, Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9422\n",
      "Epoch 5/10, Train Loss: 0.1369, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9225\n",
      "Epoch 6/10, Train Loss: 0.1126, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9217\n",
      "Epoch 7/10, Train Loss: 0.1089, Accuracy: 0.9189, F1 Micro: 0.9189, F1 Macro: 0.9072\n",
      "Epoch 8/10, Train Loss: 0.1162, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9221\n",
      "Epoch 9/10, Train Loss: 0.109, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.918\n",
      "Epoch 10/10, Train Loss: 0.0617, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9221\n",
      "\n",
      "Sentiment analysis accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9422\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        81\n",
      "    positive       0.97      0.96      0.96       178\n",
      "\n",
      "    accuracy                           0.95       259\n",
      "   macro avg       0.94      0.95      0.94       259\n",
      "weighted avg       0.95      0.95      0.95       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 334: Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.8895\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.86      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.75      0.72        12\n",
      "     neutral       0.91      0.88      0.90       152\n",
      "    positive       0.70      0.75      0.72        52\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.77      0.79      0.78       216\n",
      "weighted avg       0.85      0.84      0.84       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.83      0.81        23\n",
      "     neutral       0.93      0.98      0.96       152\n",
      "    positive       0.91      0.71      0.79        41\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.88      0.84      0.85       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.90      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.93        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.76      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 100.35206627845764 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.006231543608009815\n",
      "Acquired samples: 54\n",
      "Sampling duration: 14.185634851455688 seconds\n",
      "New train size: 388\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5583, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5122, Accuracy: 0.7999, F1 Micro: 0.8863, F1 Macro: 0.8843\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4483, Accuracy: 0.8229, F1 Micro: 0.8963, F1 Macro: 0.8931\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3585, Accuracy: 0.8884, F1 Micro: 0.9325, F1 Macro: 0.9302\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2664, Accuracy: 0.9256, F1 Micro: 0.9539, F1 Macro: 0.9504\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2052, Accuracy: 0.9531, F1 Micro: 0.9709, F1 Macro: 0.9696\n",
      "Epoch 7/10, Train Loss: 0.1569, Accuracy: 0.9524, F1 Micro: 0.9701, F1 Macro: 0.9681\n",
      "Epoch 8/10, Train Loss: 0.1272, Accuracy: 0.9501, F1 Micro: 0.9686, F1 Macro: 0.9662\n",
      "Epoch 9/10, Train Loss: 0.0992, Accuracy: 0.9531, F1 Micro: 0.9705, F1 Macro: 0.9685\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0806, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9711\n",
      "\n",
      "Aspect detection accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9711\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.90      0.92      0.91       158\n",
      "        part       0.97      0.98      0.97       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      0.99      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5854, Accuracy: 0.6834, F1 Micro: 0.6834, F1 Macro: 0.406\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4026, Accuracy: 0.8996, F1 Micro: 0.8996, F1 Macro: 0.8904\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.191, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9185\n",
      "Epoch 4/10, Train Loss: 0.1608, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.8993\n",
      "Epoch 5/10, Train Loss: 0.1391, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.9025\n",
      "Epoch 6/10, Train Loss: 0.1166, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.9053\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0745, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9262\n",
      "Epoch 8/10, Train Loss: 0.0848, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9139\n",
      "Epoch 9/10, Train Loss: 0.0761, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9185\n",
      "Epoch 10/10, Train Loss: 0.0642, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9185\n",
      "\n",
      "Sentiment analysis accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9262\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.95      0.90        82\n",
      "    positive       0.98      0.93      0.95       177\n",
      "\n",
      "    accuracy                           0.93       259\n",
      "   macro avg       0.92      0.94      0.93       259\n",
      "weighted avg       0.94      0.93      0.94       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 388: Accuracy: 0.9452, F1 Micro: 0.9452, F1 Macro: 0.8946\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.81      0.79        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.85      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.90      0.91      0.91       152\n",
      "    positive       0.74      0.71      0.73        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.80      0.79      0.79       216\n",
      "weighted avg       0.85      0.86      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.96      0.86        23\n",
      "     neutral       0.97      0.98      0.97       152\n",
      "    positive       0.94      0.78      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.91      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.87      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.93        14\n",
      "     neutral       0.99      0.99      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 100.2035813331604 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.003477677144110203\n",
      "Acquired samples: 48\n",
      "Sampling duration: 13.044627666473389 seconds\n",
      "New train size: 436\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5568, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5212, Accuracy: 0.8043, F1 Micro: 0.8885, F1 Macro: 0.8865\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4344, Accuracy: 0.8668, F1 Micro: 0.9215, F1 Macro: 0.9206\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3155, Accuracy: 0.9263, F1 Micro: 0.9546, F1 Macro: 0.9529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2295, Accuracy: 0.9405, F1 Micro: 0.9625, F1 Macro: 0.9593\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1677, Accuracy: 0.9509, F1 Micro: 0.9692, F1 Macro: 0.9671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1368, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9711\n",
      "Epoch 8/10, Train Loss: 0.1081, Accuracy: 0.9554, F1 Micro: 0.972, F1 Macro: 0.9701\n",
      "Epoch 9/10, Train Loss: 0.089, Accuracy: 0.9509, F1 Micro: 0.9689, F1 Macro: 0.9655\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0801, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9742\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9742\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.93      0.93      0.93       158\n",
      "        part       0.97      0.98      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5756, Accuracy: 0.6962, F1 Micro: 0.6962, F1 Macro: 0.4828\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3281, Accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.9115\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2042, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9155\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1275, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9235\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1404, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9245\n",
      "Epoch 6/10, Train Loss: 0.127, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9109\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1193, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9305\n",
      "Epoch 8/10, Train Loss: 0.0946, Accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.9115\n",
      "Epoch 9/10, Train Loss: 0.0751, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9209\n",
      "Epoch 10/10, Train Loss: 0.0493, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9223\n",
      "\n",
      "Sentiment analysis accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9305\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.93      0.91        84\n",
      "    positive       0.97      0.94      0.95       176\n",
      "\n",
      "    accuracy                           0.94       260\n",
      "   macro avg       0.93      0.94      0.93       260\n",
      "weighted avg       0.94      0.94      0.94       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 436: Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.9054\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.85      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.79      0.81      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.85      0.83      0.84       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.91      0.86        23\n",
      "     neutral       0.97      0.98      0.97       152\n",
      "    positive       0.89      0.78      0.83        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 109.94014716148376 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.004586305283010006\n",
      "Acquired samples: 43\n",
      "Sampling duration: 12.08018159866333 seconds\n",
      "New train size: 479\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5464, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4781, Accuracy: 0.808, F1 Micro: 0.8912, F1 Macro: 0.8896\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4095, Accuracy: 0.881, F1 Micro: 0.9288, F1 Macro: 0.9281\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3016, Accuracy: 0.9263, F1 Micro: 0.9542, F1 Macro: 0.952\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2229, Accuracy: 0.9435, F1 Micro: 0.9647, F1 Macro: 0.9621\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1692, Accuracy: 0.9524, F1 Micro: 0.9702, F1 Macro: 0.9683\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1203, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1037, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9736\n",
      "Epoch 9/10, Train Loss: 0.0938, Accuracy: 0.9472, F1 Micro: 0.9665, F1 Macro: 0.9627\n",
      "Epoch 10/10, Train Loss: 0.0776, Accuracy: 0.9576, F1 Micro: 0.9732, F1 Macro: 0.9711\n",
      "\n",
      "Aspect detection accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9736\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.94      0.98      0.96       175\n",
      "      others       0.92      0.92      0.92       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5622, Accuracy: 0.6769, F1 Micro: 0.6769, F1 Macro: 0.4037\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3184, Accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.8991\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.158, Accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.9119\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1508, Accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.9119\n",
      "Epoch 5/10, Train Loss: 0.1534, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.8992\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1427, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9218\n",
      "Epoch 7/10, Train Loss: 0.115, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9191\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0917, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9272\n",
      "Epoch 9/10, Train Loss: 0.0895, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.9084\n",
      "Epoch 10/10, Train Loss: 0.0735, Accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.908\n",
      "\n",
      "Sentiment analysis accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9272\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.95      0.90        84\n",
      "    positive       0.98      0.93      0.95       176\n",
      "\n",
      "    accuracy                           0.93       260\n",
      "   macro avg       0.92      0.94      0.93       260\n",
      "weighted avg       0.94      0.93      0.94       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 479: Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.8803\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.62      0.69        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.77      0.73      0.75        33\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.83      0.78      0.80       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.40      0.83      0.54        12\n",
      "     neutral       0.94      0.88      0.91       152\n",
      "    positive       0.80      0.77      0.78        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.71      0.83      0.74       216\n",
      "weighted avg       0.88      0.85      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.87      0.85        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.87      0.83      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 113.78300666809082 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.004337621154263616\n",
      "Acquired samples: 39\n",
      "Sampling duration: 10.79978060722351 seconds\n",
      "New train size: 518\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5408, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4878, Accuracy: 0.8251, F1 Micro: 0.8997, F1 Macro: 0.8984\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3716, Accuracy: 0.9077, F1 Micro: 0.944, F1 Macro: 0.9433\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2628, Accuracy: 0.9397, F1 Micro: 0.9623, F1 Macro: 0.9593\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1843, Accuracy: 0.9494, F1 Micro: 0.9684, F1 Macro: 0.9663\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1384, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9713\n",
      "Epoch 7/10, Train Loss: 0.1162, Accuracy: 0.9546, F1 Micro: 0.9713, F1 Macro: 0.9692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0888, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0757, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0685, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9754\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9754\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.97      0.96       175\n",
      "      others       0.90      0.96      0.93       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5355, Accuracy: 0.8599, F1 Micro: 0.8599, F1 Macro: 0.8292\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2718, Accuracy: 0.9066, F1 Micro: 0.9066, F1 Macro: 0.8974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1921, Accuracy: 0.9105, F1 Micro: 0.9105, F1 Macro: 0.9019\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1508, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9177\n",
      "Epoch 5/10, Train Loss: 0.1047, Accuracy: 0.9066, F1 Micro: 0.9066, F1 Macro: 0.8979\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1143, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9264\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.099, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9297\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0901, Accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9385\n",
      "Epoch 9/10, Train Loss: 0.062, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9241\n",
      "Epoch 10/10, Train Loss: 0.0851, Accuracy: 0.9222, F1 Micro: 0.9222, F1 Macro: 0.9131\n",
      "\n",
      "Sentiment analysis accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9385\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.95      0.92        82\n",
      "    positive       0.98      0.94      0.96       175\n",
      "\n",
      "    accuracy                           0.95       257\n",
      "   macro avg       0.93      0.95      0.94       257\n",
      "weighted avg       0.95      0.95      0.95       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 518: Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.8984\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.95      0.97      0.96       167\n",
      "    positive       0.81      0.79      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.84      0.85       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.67      0.73        12\n",
      "     neutral       0.90      0.96      0.93       152\n",
      "    positive       0.86      0.73      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.85      0.79      0.82       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.91      0.82        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.89      0.76      0.82        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.88      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.85      0.81        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 122.84213209152222 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.005141957476735116\n",
      "Acquired samples: 22\n",
      "Sampling duration: 9.963488101959229 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5503, Accuracy: 0.7961, F1 Micro: 0.8849, F1 Macro: 0.883\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4798, Accuracy: 0.8125, F1 Micro: 0.8933, F1 Macro: 0.8918\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3821, Accuracy: 0.9107, F1 Micro: 0.9457, F1 Macro: 0.9448\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2674, Accuracy: 0.9412, F1 Micro: 0.9632, F1 Macro: 0.9603\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1886, Accuracy: 0.9554, F1 Micro: 0.9722, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1485, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9713\n",
      "Epoch 7/10, Train Loss: 0.1193, Accuracy: 0.9531, F1 Micro: 0.9704, F1 Macro: 0.9679\n",
      "Epoch 8/10, Train Loss: 0.0846, Accuracy: 0.9561, F1 Micro: 0.9722, F1 Macro: 0.9696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0731, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9751\n",
      "Epoch 10/10, Train Loss: 0.0653, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9737\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9751\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.94      0.93       158\n",
      "        part       0.98      0.97      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5882, Accuracy: 0.8008, F1 Micro: 0.8008, F1 Macro: 0.725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2773, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.8998\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1734, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9152\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1552, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9261\n",
      "Epoch 5/10, Train Loss: 0.1373, Accuracy: 0.9195, F1 Micro: 0.9195, F1 Macro: 0.9121\n",
      "Epoch 6/10, Train Loss: 0.1119, Accuracy: 0.9272, F1 Micro: 0.9272, F1 Macro: 0.9174\n",
      "Epoch 7/10, Train Loss: 0.1015, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9105\n",
      "Epoch 8/10, Train Loss: 0.1039, Accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.9035\n",
      "Epoch 9/10, Train Loss: 0.0625, Accuracy: 0.931, F1 Micro: 0.931, F1 Macro: 0.922\n",
      "Epoch 10/10, Train Loss: 0.053, Accuracy: 0.9195, F1 Micro: 0.9195, F1 Macro: 0.9112\n",
      "\n",
      "Sentiment analysis accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9261\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.92      0.90        84\n",
      "    positive       0.96      0.94      0.95       177\n",
      "\n",
      "    accuracy                           0.93       261\n",
      "   macro avg       0.92      0.93      0.93       261\n",
      "weighted avg       0.94      0.93      0.94       261\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.8863\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.91      0.82      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.45      0.75      0.56        12\n",
      "     neutral       0.94      0.91      0.92       152\n",
      "    positive       0.78      0.73      0.75        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.72      0.80      0.75       216\n",
      "weighted avg       0.87      0.86      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      1.00      0.84        23\n",
      "     neutral       0.98      0.95      0.97       152\n",
      "    positive       0.89      0.78      0.83        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.86      0.91      0.88       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.92      0.80        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.92      0.65      0.76        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.87      0.85      0.85       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 114.15639114379883 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.004025315213948488\n",
      "Acquired samples: 33\n",
      "Sampling duration: 9.353861570358276 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5388, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4722, Accuracy: 0.8318, F1 Micro: 0.9031, F1 Macro: 0.902\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3693, Accuracy: 0.91, F1 Micro: 0.9451, F1 Macro: 0.9437\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2451, Accuracy: 0.942, F1 Micro: 0.9639, F1 Macro: 0.9615\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1735, Accuracy: 0.9524, F1 Micro: 0.9701, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1382, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9748\n",
      "Epoch 7/10, Train Loss: 0.1102, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0894, Accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9775\n",
      "Epoch 9/10, Train Loss: 0.0693, Accuracy: 0.9591, F1 Micro: 0.9741, F1 Macro: 0.9716\n",
      "Epoch 10/10, Train Loss: 0.0659, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9768\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9775\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.91      0.97      0.94       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5317, Accuracy: 0.8725, F1 Micro: 0.8725, F1 Macro: 0.86\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2708, Accuracy: 0.9124, F1 Micro: 0.9124, F1 Macro: 0.9056\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2113, Accuracy: 0.9402, F1 Micro: 0.9402, F1 Macro: 0.9339\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1631, Accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.937\n",
      "Epoch 5/10, Train Loss: 0.126, Accuracy: 0.9402, F1 Micro: 0.9402, F1 Macro: 0.9342\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0963, Accuracy: 0.9482, F1 Micro: 0.9482, F1 Macro: 0.942\n",
      "Epoch 7/10, Train Loss: 0.103, Accuracy: 0.9402, F1 Micro: 0.9402, F1 Macro: 0.9327\n",
      "Epoch 8/10, Train Loss: 0.0848, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9262\n",
      "Epoch 9/10, Train Loss: 0.0577, Accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9377\n",
      "Epoch 10/10, Train Loss: 0.0532, Accuracy: 0.9124, F1 Micro: 0.9124, F1 Macro: 0.8977\n",
      "\n",
      "Sentiment analysis accuracy: 0.9482, F1 Micro: 0.9482, F1 Macro: 0.942\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.94      0.92        83\n",
      "    positive       0.97      0.95      0.96       168\n",
      "\n",
      "    accuracy                           0.95       251\n",
      "   macro avg       0.94      0.95      0.94       251\n",
      "weighted avg       0.95      0.95      0.95       251\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9483, F1 Micro: 0.9483, F1 Macro: 0.8789\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.88      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.56      0.69        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.77      0.73      0.75        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.87      0.76      0.80       216\n",
      "weighted avg       0.91      0.92      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.67      0.64        12\n",
      "     neutral       0.91      0.94      0.93       152\n",
      "    positive       0.87      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.80      0.79      0.79       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.88      0.85      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.90      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.88      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 120.25971055030823 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.0034467535791918645\n",
      "Acquired samples: 30\n",
      "Sampling duration: 8.474472045898438 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5435, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4614, Accuracy: 0.8393, F1 Micro: 0.9072, F1 Macro: 0.9061\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3401, Accuracy: 0.9293, F1 Micro: 0.9565, F1 Macro: 0.9548\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2411, Accuracy: 0.9561, F1 Micro: 0.9727, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1689, Accuracy: 0.9583, F1 Micro: 0.9741, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1293, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0934, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9763\n",
      "Epoch 8/10, Train Loss: 0.0863, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.975\n",
      "Epoch 9/10, Train Loss: 0.0681, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9759\n",
      "Epoch 10/10, Train Loss: 0.0561, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.975\n",
      "\n",
      "Aspect detection accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9763\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.91      0.95      0.93       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4993, Accuracy: 0.8824, F1 Micro: 0.8824, F1 Macro: 0.8684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2775, Accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.9047\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2009, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9386\n",
      "Epoch 4/10, Train Loss: 0.1295, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.915\n",
      "Epoch 5/10, Train Loss: 0.1506, Accuracy: 0.902, F1 Micro: 0.902, F1 Macro: 0.8954\n",
      "Epoch 6/10, Train Loss: 0.1277, Accuracy: 0.9059, F1 Micro: 0.9059, F1 Macro: 0.8993\n",
      "Epoch 7/10, Train Loss: 0.1241, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9265\n",
      "Epoch 8/10, Train Loss: 0.0689, Accuracy: 0.9137, F1 Micro: 0.9137, F1 Macro: 0.906\n",
      "Epoch 9/10, Train Loss: 0.0657, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9348\n",
      "Epoch 10/10, Train Loss: 0.0508, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9219\n",
      "\n",
      "Sentiment analysis accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9386\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        84\n",
      "    positive       0.97      0.95      0.96       171\n",
      "\n",
      "    accuracy                           0.95       255\n",
      "   macro avg       0.93      0.94      0.94       255\n",
      "weighted avg       0.95      0.95      0.95       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.8829\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.92      0.70      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.83      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.32      0.75      0.45        12\n",
      "     neutral       0.96      0.88      0.92       152\n",
      "    positive       0.80      0.75      0.77        52\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.69      0.79      0.71       216\n",
      "weighted avg       0.89      0.84      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.94      0.78      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.92      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.85      0.81        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 118.60626649856567 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.0028634088113903998\n",
      "Acquired samples: 27\n",
      "Sampling duration: 7.738609313964844 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5448, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4601, Accuracy: 0.8289, F1 Micro: 0.9007, F1 Macro: 0.8992\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3469, Accuracy: 0.9405, F1 Micro: 0.9632, F1 Macro: 0.9617\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2305, Accuracy: 0.9524, F1 Micro: 0.9704, F1 Macro: 0.9691\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1607, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1263, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0963, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9768\n",
      "Epoch 8/10, Train Loss: 0.0803, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.975\n",
      "Epoch 9/10, Train Loss: 0.0655, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0568, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9783\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9783\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.93      0.95      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5171, Accuracy: 0.8803, F1 Micro: 0.8803, F1 Macro: 0.8703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2611, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9353\n",
      "Epoch 3/10, Train Loss: 0.1914, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9315\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.129, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.936\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1345, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.936\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1151, Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9439\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0836, Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9481\n",
      "Epoch 8/10, Train Loss: 0.0793, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9387\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0739, Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9475\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0847, Accuracy: 0.9575, F1 Micro: 0.9575, F1 Macro: 0.9525\n",
      "\n",
      "Sentiment analysis accuracy: 0.9575, F1 Micro: 0.9575, F1 Macro: 0.9525\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94        84\n",
      "    positive       0.99      0.95      0.97       175\n",
      "\n",
      "    accuracy                           0.96       259\n",
      "   macro avg       0.94      0.96      0.95       259\n",
      "weighted avg       0.96      0.96      0.96       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9276\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.84      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.93      0.95      0.94       152\n",
      "    positive       0.84      0.79      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.84      0.83      0.83       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.95      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 135.3894271850586 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.003475978272035718\n",
      "Acquired samples: 18\n",
      "Sampling duration: 7.2854204177856445 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5367, Accuracy: 0.8006, F1 Micro: 0.887, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4586, Accuracy: 0.84, F1 Micro: 0.9071, F1 Macro: 0.9062\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.329, Accuracy: 0.9397, F1 Micro: 0.9629, F1 Macro: 0.9613\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2203, Accuracy: 0.9598, F1 Micro: 0.975, F1 Macro: 0.9738\n",
      "Epoch 5/10, Train Loss: 0.1537, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1274, Accuracy: 0.968, F1 Micro: 0.98, F1 Macro: 0.979\n",
      "Epoch 7/10, Train Loss: 0.0989, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9774\n",
      "Epoch 8/10, Train Loss: 0.0753, Accuracy: 0.9613, F1 Micro: 0.9755, F1 Macro: 0.9737\n",
      "Epoch 9/10, Train Loss: 0.0639, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9757\n",
      "Epoch 10/10, Train Loss: 0.052, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9771\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.98, F1 Macro: 0.979\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.97      0.94       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.551, Accuracy: 0.873, F1 Micro: 0.873, F1 Macro: 0.8661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2113, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9335\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1521, Accuracy: 0.9508, F1 Micro: 0.9508, F1 Macro: 0.9464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1655, Accuracy: 0.9549, F1 Micro: 0.9549, F1 Macro: 0.9493\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.116, Accuracy: 0.959, F1 Micro: 0.959, F1 Macro: 0.9549\n",
      "Epoch 6/10, Train Loss: 0.0973, Accuracy: 0.9549, F1 Micro: 0.9549, F1 Macro: 0.9507\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0705, Accuracy: 0.9631, F1 Micro: 0.9631, F1 Macro: 0.9588\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0678, Accuracy: 0.9672, F1 Micro: 0.9672, F1 Macro: 0.9637\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0568, Accuracy: 0.9672, F1 Micro: 0.9672, F1 Macro: 0.9635\n",
      "Epoch 10/10, Train Loss: 0.0649, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9305\n",
      "\n",
      "Sentiment analysis accuracy: 0.9672, F1 Micro: 0.9672, F1 Macro: 0.9635\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.95      0.95        83\n",
      "    positive       0.98      0.98      0.98       161\n",
      "\n",
      "    accuracy                           0.97       244\n",
      "   macro avg       0.96      0.96      0.96       244\n",
      "weighted avg       0.97      0.97      0.97       244\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9491, F1 Micro: 0.9491, F1 Macro: 0.8818\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.75      0.77        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.82      0.85       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.45      0.83      0.59        12\n",
      "     neutral       0.96      0.93      0.94       152\n",
      "    positive       0.89      0.81      0.85        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.77      0.86      0.79       216\n",
      "weighted avg       0.92      0.89      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.87      0.78        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.92      0.80      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.87      0.88      0.87       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.69      0.72        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.85      0.82      0.83       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 128.30227828025818 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.0027802006341516973\n",
      "Acquired samples: 25\n",
      "Sampling duration: 6.5587639808654785 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5359, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4373, Accuracy: 0.8683, F1 Micro: 0.9221, F1 Macro: 0.921\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.298, Accuracy: 0.9457, F1 Micro: 0.9659, F1 Macro: 0.9633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1995, Accuracy: 0.9568, F1 Micro: 0.9731, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1347, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1046, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9768\n",
      "Epoch 7/10, Train Loss: 0.0817, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9743\n",
      "Epoch 8/10, Train Loss: 0.068, Accuracy: 0.9628, F1 Micro: 0.9768, F1 Macro: 0.9758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0583, Accuracy: 0.9695, F1 Micro: 0.9809, F1 Macro: 0.9799\n",
      "Epoch 10/10, Train Loss: 0.0507, Accuracy: 0.9613, F1 Micro: 0.9755, F1 Macro: 0.9735\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9809, F1 Macro: 0.9799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.93      0.96      0.95       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5399, Accuracy: 0.8945, F1 Micro: 0.8945, F1 Macro: 0.8846\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2708, Accuracy: 0.8984, F1 Micro: 0.8984, F1 Macro: 0.8774\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1909, Accuracy: 0.9609, F1 Micro: 0.9609, F1 Macro: 0.9562\n",
      "Epoch 4/10, Train Loss: 0.1523, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9391\n",
      "Epoch 5/10, Train Loss: 0.1193, Accuracy: 0.9531, F1 Micro: 0.9531, F1 Macro: 0.9475\n",
      "Epoch 6/10, Train Loss: 0.1096, Accuracy: 0.9531, F1 Micro: 0.9531, F1 Macro: 0.9478\n",
      "Epoch 7/10, Train Loss: 0.0912, Accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9436\n",
      "Epoch 8/10, Train Loss: 0.0564, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.938\n",
      "Epoch 9/10, Train Loss: 0.0758, Accuracy: 0.9297, F1 Micro: 0.9297, F1 Macro: 0.9233\n",
      "Epoch 10/10, Train Loss: 0.0472, Accuracy: 0.9297, F1 Micro: 0.9297, F1 Macro: 0.9233\n",
      "\n",
      "Sentiment analysis accuracy: 0.9609, F1 Micro: 0.9609, F1 Macro: 0.9562\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.96      0.94        84\n",
      "    positive       0.98      0.96      0.97       172\n",
      "\n",
      "    accuracy                           0.96       256\n",
      "   macro avg       0.95      0.96      0.96       256\n",
      "weighted avg       0.96      0.96      0.96       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.946, F1 Micro: 0.946, F1 Macro: 0.884\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.81      0.79        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.92      0.70      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.83      0.85       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.33      0.83      0.48        12\n",
      "     neutral       0.96      0.88      0.92       152\n",
      "    positive       0.87      0.79      0.83        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.72      0.83      0.74       216\n",
      "weighted avg       0.91      0.86      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.91       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.85      0.79        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.88      0.87      0.87       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 130.3768081665039 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.0027804297162219885\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.935048341751099 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5322, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4511, Accuracy: 0.8594, F1 Micro: 0.9177, F1 Macro: 0.9176\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.306, Accuracy: 0.9397, F1 Micro: 0.9628, F1 Macro: 0.9611\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2065, Accuracy: 0.9531, F1 Micro: 0.9707, F1 Macro: 0.9691\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1463, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1162, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9779\n",
      "Epoch 7/10, Train Loss: 0.0925, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9771\n",
      "Epoch 8/10, Train Loss: 0.0762, Accuracy: 0.9613, F1 Micro: 0.9754, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0585, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9789\n",
      "Epoch 10/10, Train Loss: 0.0519, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9776\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.97      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.533, Accuracy: 0.8867, F1 Micro: 0.8867, F1 Macro: 0.8686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2676, Accuracy: 0.9297, F1 Micro: 0.9297, F1 Macro: 0.9216\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1848, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9352\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1294, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9349\n",
      "Epoch 5/10, Train Loss: 0.1095, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9311\n",
      "Epoch 6/10, Train Loss: 0.1043, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9307\n",
      "Epoch 7/10, Train Loss: 0.0769, Accuracy: 0.9102, F1 Micro: 0.9102, F1 Macro: 0.9027\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0601, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9345\n",
      "Epoch 9/10, Train Loss: 0.0686, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9258\n",
      "Epoch 10/10, Train Loss: 0.0641, Accuracy: 0.9297, F1 Micro: 0.9297, F1 Macro: 0.9207\n",
      "\n",
      "Sentiment analysis accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9345\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.95      0.91        83\n",
      "    positive       0.98      0.94      0.96       173\n",
      "\n",
      "    accuracy                           0.94       256\n",
      "   macro avg       0.93      0.94      0.93       256\n",
      "weighted avg       0.94      0.94      0.94       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9022\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.62      0.69        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.85      0.79      0.82       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.53      0.83      0.65        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.89      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.78      0.85      0.80       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.92      0.83      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.90      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 135.86931371688843 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.0022877593524754047\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.444101572036743 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5491, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4431, Accuracy: 0.8772, F1 Micro: 0.9266, F1 Macro: 0.9261\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2909, Accuracy: 0.9457, F1 Micro: 0.9663, F1 Macro: 0.9646\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.192, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1362, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9757\n",
      "Epoch 6/10, Train Loss: 0.112, Accuracy: 0.9591, F1 Micro: 0.974, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0847, Accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9786\n",
      "Epoch 8/10, Train Loss: 0.0681, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9784\n",
      "Epoch 9/10, Train Loss: 0.0597, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0497, Accuracy: 0.9695, F1 Micro: 0.9809, F1 Macro: 0.9799\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9809, F1 Macro: 0.9799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.97      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4726, Accuracy: 0.8867, F1 Micro: 0.8867, F1 Macro: 0.8794\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2504, Accuracy: 0.9219, F1 Micro: 0.9219, F1 Macro: 0.9148\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1697, Accuracy: 0.9258, F1 Micro: 0.9258, F1 Macro: 0.9188\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1765, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9245\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1294, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9287\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1123, Accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9429\n",
      "Epoch 7/10, Train Loss: 0.0928, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9352\n",
      "Epoch 8/10, Train Loss: 0.0696, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.927\n",
      "Epoch 9/10, Train Loss: 0.068, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9391\n",
      "Epoch 10/10, Train Loss: 0.0484, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.938\n",
      "\n",
      "Sentiment analysis accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9429\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.92        83\n",
      "    positive       0.98      0.95      0.96       173\n",
      "\n",
      "    accuracy                           0.95       256\n",
      "   macro avg       0.94      0.95      0.94       256\n",
      "weighted avg       0.95      0.95      0.95       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9162\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.69      0.79        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.79      0.79      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.82      0.85       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.92      0.97      0.95       152\n",
      "    positive       0.91      0.77      0.83        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.88      0.83      0.85       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.95      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.89      1.00      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 139.82403469085693 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.002551960968412459\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.760246753692627 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5291, Accuracy: 0.7954, F1 Micro: 0.8853, F1 Macro: 0.8838\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.426, Accuracy: 0.8906, F1 Micro: 0.9349, F1 Macro: 0.9342\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2829, Accuracy: 0.9509, F1 Micro: 0.9694, F1 Macro: 0.968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1792, Accuracy: 0.9561, F1 Micro: 0.9726, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1259, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1029, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.081, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.978\n",
      "Epoch 8/10, Train Loss: 0.0639, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9766\n",
      "Epoch 9/10, Train Loss: 0.0568, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "Epoch 10/10, Train Loss: 0.0456, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9766\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.93      0.97      0.95       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5626, Accuracy: 0.8906, F1 Micro: 0.8906, F1 Macro: 0.8781\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2999, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9274\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2034, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.93\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1571, Accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9439\n",
      "Epoch 5/10, Train Loss: 0.1432, Accuracy: 0.918, F1 Micro: 0.918, F1 Macro: 0.9111\n",
      "Epoch 6/10, Train Loss: 0.1322, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9356\n",
      "Epoch 7/10, Train Loss: 0.092, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9394\n",
      "Epoch 8/10, Train Loss: 0.0706, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9356\n",
      "Epoch 9/10, Train Loss: 0.0683, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9315\n",
      "Epoch 10/10, Train Loss: 0.0676, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9345\n",
      "\n",
      "Sentiment analysis accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9439\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.96      0.93        85\n",
      "    positive       0.98      0.94      0.96       171\n",
      "\n",
      "    accuracy                           0.95       256\n",
      "   macro avg       0.94      0.95      0.94       256\n",
      "weighted avg       0.95      0.95      0.95       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.8971\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.79      0.70      0.74        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.87      0.83      0.85       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.53      0.75      0.62        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.88      0.81      0.84        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.78      0.83      0.80       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.94      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.85      0.79        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.86      0.87      0.86       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 137.5772807598114 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.0027540032751858234\n",
      "Acquired samples: 8\n",
      "Sampling duration: 4.6934123039245605 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5188, Accuracy: 0.8006, F1 Micro: 0.8879, F1 Macro: 0.8864\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4271, Accuracy: 0.8958, F1 Micro: 0.9373, F1 Macro: 0.9362\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2916, Accuracy: 0.9457, F1 Micro: 0.9662, F1 Macro: 0.9646\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1871, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1385, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1071, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.082, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0675, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9785\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0567, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.979\n",
      "Epoch 10/10, Train Loss: 0.046, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9758\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.979\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      0.98      0.96       175\n",
      "      others       0.94      0.96      0.95       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5323, Accuracy: 0.9, F1 Micro: 0.9, F1 Macro: 0.8912\n",
      "Epoch 2/10, Train Loss: 0.3023, Accuracy: 0.8923, F1 Micro: 0.8923, F1 Macro: 0.8854\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1983, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9218\n",
      "Epoch 4/10, Train Loss: 0.1504, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.9079\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1481, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9305\n",
      "Epoch 6/10, Train Loss: 0.1064, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9276\n",
      "Epoch 7/10, Train Loss: 0.1152, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.928\n",
      "Epoch 8/10, Train Loss: 0.0746, Accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.9068\n",
      "Epoch 9/10, Train Loss: 0.0765, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.907\n",
      "Epoch 10/10, Train Loss: 0.0528, Accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.8991\n",
      "\n",
      "Sentiment analysis accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9305\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.92      0.91        85\n",
      "    positive       0.96      0.95      0.95       175\n",
      "\n",
      "    accuracy                           0.94       260\n",
      "   macro avg       0.93      0.93      0.93       260\n",
      "weighted avg       0.94      0.94      0.94       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.946, F1 Micro: 0.946, F1 Macro: 0.8793\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.91      0.88      0.89        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.88      0.82        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.85      0.67      0.75        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.86      0.84      0.84       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.42      0.83      0.56        12\n",
      "     neutral       0.95      0.90      0.93       152\n",
      "    positive       0.85      0.79      0.82        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.74      0.84      0.77       216\n",
      "weighted avg       0.90      0.87      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.92      0.91       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.85      0.76        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.87      0.85      0.85       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 142.0146656036377 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.002132221544161439\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.8118627071380615 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5233, Accuracy: 0.7984, F1 Micro: 0.8868, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4283, Accuracy: 0.8876, F1 Micro: 0.9329, F1 Macro: 0.9324\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2773, Accuracy: 0.9524, F1 Micro: 0.9705, F1 Macro: 0.9692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1781, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1287, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9754\n",
      "Epoch 6/10, Train Loss: 0.1008, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0741, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0686, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9785\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.056, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9797\n",
      "Epoch 10/10, Train Loss: 0.048, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9797\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.96      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5038, Accuracy: 0.9046, F1 Micro: 0.9046, F1 Macro: 0.895\n",
      "Epoch 2/10, Train Loss: 0.2833, Accuracy: 0.8969, F1 Micro: 0.8969, F1 Macro: 0.8906\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1828, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.9327\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1617, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.933\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1164, Accuracy: 0.9427, F1 Micro: 0.9427, F1 Macro: 0.9367\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1153, Accuracy: 0.9466, F1 Micro: 0.9466, F1 Macro: 0.9401\n",
      "Epoch 7/10, Train Loss: 0.0767, Accuracy: 0.9427, F1 Micro: 0.9427, F1 Macro: 0.9364\n",
      "Epoch 8/10, Train Loss: 0.0778, Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.9226\n",
      "Epoch 9/10, Train Loss: 0.0746, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.9323\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0575, Accuracy: 0.9466, F1 Micro: 0.9466, F1 Macro: 0.9404\n",
      "\n",
      "Sentiment analysis accuracy: 0.9466, F1 Micro: 0.9466, F1 Macro: 0.9404\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.95      0.92        86\n",
      "    positive       0.98      0.94      0.96       176\n",
      "\n",
      "    accuracy                           0.95       262\n",
      "   macro avg       0.93      0.95      0.94       262\n",
      "weighted avg       0.95      0.95      0.95       262\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.9168\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.86      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.58      0.92      0.71        12\n",
      "     neutral       0.94      0.93      0.93       152\n",
      "    positive       0.87      0.79      0.83        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.80      0.88      0.82       216\n",
      "weighted avg       0.90      0.89      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.95      0.88      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.95      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 146.81454300880432 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0019699406111612916\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.195425271987915 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5327, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.417, Accuracy: 0.9077, F1 Micro: 0.9441, F1 Macro: 0.943\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.263, Accuracy: 0.9509, F1 Micro: 0.9697, F1 Macro: 0.9685\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1713, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1272, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9765\n",
      "Epoch 6/10, Train Loss: 0.0962, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9726\n",
      "Epoch 7/10, Train Loss: 0.0798, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0587, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9779\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0554, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9778\n",
      "Epoch 10/10, Train Loss: 0.0462, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9772\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.93      0.96      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4722, Accuracy: 0.8992, F1 Micro: 0.8992, F1 Macro: 0.8917\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2341, Accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.9169\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2009, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9269\n",
      "Epoch 4/10, Train Loss: 0.1577, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.921\n",
      "Epoch 5/10, Train Loss: 0.1333, Accuracy: 0.9147, F1 Micro: 0.9147, F1 Macro: 0.901\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1062, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9269\n",
      "Epoch 7/10, Train Loss: 0.097, Accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.9196\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0707, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9314\n",
      "Epoch 9/10, Train Loss: 0.0603, Accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.9151\n",
      "Epoch 10/10, Train Loss: 0.0403, Accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.9187\n",
      "\n",
      "Sentiment analysis accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9314\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.95      0.91        85\n",
      "    positive       0.98      0.93      0.95       173\n",
      "\n",
      "    accuracy                           0.94       258\n",
      "   macro avg       0.92      0.94      0.93       258\n",
      "weighted avg       0.94      0.94      0.94       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.8972\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.81      0.79        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.84      0.85       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.59      0.83      0.69        12\n",
      "     neutral       0.94      0.94      0.94       152\n",
      "    positive       0.83      0.75      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.79      0.84      0.81       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.91       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.85      0.81        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 148.07639598846436 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0019307264126837255\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.467085599899292 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5293, Accuracy: 0.7939, F1 Micro: 0.8809, F1 Macro: 0.8763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4053, Accuracy: 0.9196, F1 Micro: 0.9513, F1 Macro: 0.9503\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2562, Accuracy: 0.9524, F1 Micro: 0.9705, F1 Macro: 0.9695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1706, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1249, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0971, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.978\n",
      "Epoch 7/10, Train Loss: 0.0723, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9751\n",
      "Epoch 8/10, Train Loss: 0.0642, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.977\n",
      "Epoch 9/10, Train Loss: 0.0536, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9742\n",
      "Epoch 10/10, Train Loss: 0.0457, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9768\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      0.99      0.96       175\n",
      "      others       0.93      0.97      0.95       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5123, Accuracy: 0.8984, F1 Micro: 0.8984, F1 Macro: 0.8897\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2636, Accuracy: 0.918, F1 Micro: 0.918, F1 Macro: 0.9111\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1873, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9349\n",
      "Epoch 4/10, Train Loss: 0.1372, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.924\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0873, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9352\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0986, Accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9436\n",
      "Epoch 7/10, Train Loss: 0.0669, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9311\n",
      "Epoch 8/10, Train Loss: 0.0652, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9352\n",
      "Epoch 9/10, Train Loss: 0.08, Accuracy: 0.9258, F1 Micro: 0.9258, F1 Macro: 0.9188\n",
      "Epoch 10/10, Train Loss: 0.0449, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.927\n",
      "\n",
      "Sentiment analysis accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9436\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.96      0.93        84\n",
      "    positive       0.98      0.94      0.96       172\n",
      "\n",
      "    accuracy                           0.95       256\n",
      "   macro avg       0.94      0.95      0.94       256\n",
      "weighted avg       0.95      0.95      0.95       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.8976\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.88      0.82        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.92      0.70      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.85      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.45      0.83      0.59        12\n",
      "     neutral       0.95      0.91      0.93       152\n",
      "    positive       0.87      0.79      0.83        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.76      0.85      0.78       216\n",
      "weighted avg       0.90      0.88      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.92      0.83        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.87      0.89      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 144.73847079277039 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0017135688452981413\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.8606557846069336 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5252, Accuracy: 0.7969, F1 Micro: 0.886, F1 Macro: 0.8846\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4134, Accuracy: 0.9211, F1 Micro: 0.9523, F1 Macro: 0.9513\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2573, Accuracy: 0.9546, F1 Micro: 0.972, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1643, Accuracy: 0.9621, F1 Micro: 0.9763, F1 Macro: 0.9752\n",
      "Epoch 5/10, Train Loss: 0.1213, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1005, Accuracy: 0.9688, F1 Micro: 0.9805, F1 Macro: 0.9794\n",
      "Epoch 7/10, Train Loss: 0.0703, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9789\n",
      "Epoch 8/10, Train Loss: 0.0628, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "Epoch 9/10, Train Loss: 0.0541, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9764\n",
      "Epoch 10/10, Train Loss: 0.0439, Accuracy: 0.9613, F1 Micro: 0.9754, F1 Macro: 0.9733\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9805, F1 Macro: 0.9794\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.97      0.94       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4608, Accuracy: 0.9393, F1 Micro: 0.9393, F1 Macro: 0.9336\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2322, Accuracy: 0.9433, F1 Micro: 0.9433, F1 Macro: 0.9376\n",
      "Epoch 3/10, Train Loss: 0.1437, Accuracy: 0.9312, F1 Micro: 0.9312, F1 Macro: 0.9252\n",
      "Epoch 4/10, Train Loss: 0.0975, Accuracy: 0.9352, F1 Micro: 0.9352, F1 Macro: 0.9294\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0936, Accuracy: 0.9433, F1 Micro: 0.9433, F1 Macro: 0.9365\n",
      "Epoch 6/10, Train Loss: 0.097, Accuracy: 0.9312, F1 Micro: 0.9312, F1 Macro: 0.9248\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0694, Accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9415\n",
      "Epoch 8/10, Train Loss: 0.0621, Accuracy: 0.9433, F1 Micro: 0.9433, F1 Macro: 0.9376\n",
      "Epoch 9/10, Train Loss: 0.0514, Accuracy: 0.9393, F1 Micro: 0.9393, F1 Macro: 0.9322\n",
      "Epoch 10/10, Train Loss: 0.0576, Accuracy: 0.9393, F1 Micro: 0.9393, F1 Macro: 0.9309\n",
      "\n",
      "Sentiment analysis accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9415\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.92        82\n",
      "    positive       0.97      0.95      0.96       165\n",
      "\n",
      "    accuracy                           0.95       247\n",
      "   macro avg       0.94      0.95      0.94       247\n",
      "weighted avg       0.95      0.95      0.95       247\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.8836\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.73      0.76        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.88      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.87      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.69      0.71        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.85      0.81      0.83       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.38      1.00      0.55        12\n",
      "     neutral       0.96      0.87      0.91       152\n",
      "    positive       0.91      0.81      0.86        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.75      0.89      0.77       216\n",
      "weighted avg       0.91      0.86      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.96      0.85        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.90      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 145.34755396842957 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0013024846324697138\n",
      "Acquired samples: 8\n",
      "Sampling duration: 1.147576093673706 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5219, Accuracy: 0.7976, F1 Micro: 0.8864, F1 Macro: 0.885\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4004, Accuracy: 0.9204, F1 Micro: 0.9511, F1 Macro: 0.9496\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2457, Accuracy: 0.9524, F1 Micro: 0.9704, F1 Macro: 0.9689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1689, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1222, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9773\n",
      "Epoch 6/10, Train Loss: 0.0919, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9771\n",
      "Epoch 7/10, Train Loss: 0.0746, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9742\n",
      "Epoch 8/10, Train Loss: 0.0598, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9764\n",
      "Epoch 9/10, Train Loss: 0.0498, Accuracy: 0.9613, F1 Micro: 0.9755, F1 Macro: 0.9734\n",
      "Epoch 10/10, Train Loss: 0.044, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9756\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.94      0.94      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4917, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.9004\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2277, Accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.9393\n",
      "Epoch 3/10, Train Loss: 0.1384, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9201\n",
      "Epoch 4/10, Train Loss: 0.1135, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9197\n",
      "Epoch 5/10, Train Loss: 0.112, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9168\n",
      "Epoch 6/10, Train Loss: 0.0698, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9318\n",
      "Epoch 7/10, Train Loss: 0.0737, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.895\n",
      "Epoch 8/10, Train Loss: 0.0593, Accuracy: 0.9432, F1 Micro: 0.9432, F1 Macro: 0.9363\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0704, Accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.9403\n",
      "Epoch 10/10, Train Loss: 0.0497, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.926\n",
      "\n",
      "Sentiment analysis accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.9403\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        84\n",
      "    positive       0.98      0.94      0.96       180\n",
      "\n",
      "    accuracy                           0.95       264\n",
      "   macro avg       0.93      0.95      0.94       264\n",
      "weighted avg       0.95      0.95      0.95       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.8961\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.92      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.88      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.84      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      1.00      0.75        12\n",
      "     neutral       0.97      0.92      0.94       152\n",
      "    positive       0.84      0.83      0.83        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.80      0.92      0.84       216\n",
      "weighted avg       0.92      0.90      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.92      0.88      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.77      0.74        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.86      0.86      0.86       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 144.65505194664001 s\n",
      "Total runtime: 3259.303354740143 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[4], 4)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6175447,
     "sourceId": 10843157,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2819.364412,
   "end_time": "2025-03-06T11:42:55.307323",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-06T10:55:55.942911",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0535cf5575a744c685e91a45fe3a016a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e465e8e0f91b4cd8990dd623d72ace0e",
       "placeholder": "",
       "style": "IPY_MODEL_fff091de4fed459a86648df5bf54b95b",
       "tabbable": null,
       "tooltip": null,
       "value": "112/112[00:00&lt;00:00,11.5kB/s]"
      }
     },
     "1b9eff7fca4b450799c79838a3671582": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_62d7a258aa31487c99d42175f636eed8",
       "placeholder": "",
       "style": "IPY_MODEL_b0129730b4b3451e9a2b6ab3f75933bc",
       "tabbable": null,
       "tooltip": null,
       "value": "special_tokens_map.json:100%"
      }
     },
     "1cd296befde74a8b978902ba421f3da8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "230692eee19a4a56aa361ef00963d63b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_351fce6daaf24d098e8612d7483caf6f",
       "placeholder": "",
       "style": "IPY_MODEL_35b77ac8e99a41f4a06c814f8755dc81",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json:100%"
      }
     },
     "269b3dea88b24914b83635552082d83d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "351fce6daaf24d098e8612d7483caf6f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "35b77ac8e99a41f4a06c814f8755dc81": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "380a9a1452b64e7bbc3d760a4d4fa7ba": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3a60a28597104a2d84c9f172498fea17": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e8e9f260f3234491a42dc370c6aefd39",
       "placeholder": "",
       "style": "IPY_MODEL_5f5a975ed58243c08c1380497504bb29",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json:100%"
      }
     },
     "3e671a904b8b43f1a3d510bfde9985f1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3eaf839346bc4a8f95a76140b7d70d69": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "40d26a91d31c481faf511c1a1b70a6f6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "465af8df13604b3582a07c50212de93b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "54d2214b4f2a4b98882692d43fed7381": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "57fc1a8e618245cf904da22ee4b06259": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5f5a975ed58243c08c1380497504bb29": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "62d7a258aa31487c99d42175f636eed8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "663d6f5360de46b5a0a8038582b735aa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "719285dd50a6483bbea6b3a7b19e6508": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b8980b1f169349e1b6b112e35da4747a",
       "max": 1534,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_8d02ab76f4f14359b9801ea1f7b68dd1",
       "tabbable": null,
       "tooltip": null,
       "value": 1534
      }
     },
     "733052b19f93499da399267eeabf2ef5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3a60a28597104a2d84c9f172498fea17",
        "IPY_MODEL_fbb08c617fd1431cbd60bb81c0662914",
        "IPY_MODEL_c3d2fcd311584cd191e042cc255819ec"
       ],
       "layout": "IPY_MODEL_1cd296befde74a8b978902ba421f3da8",
       "tabbable": null,
       "tooltip": null
      }
     },
     "79acff3110a8478bab268f8e97863bd9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_cd5c3c0c6ee94fd3aee4763693b3c352",
        "IPY_MODEL_87b2f5dfce9b4dd1946bb44875ad1b8d",
        "IPY_MODEL_9503ed5e9b3a46f887afc6e45a95ebf4"
       ],
       "layout": "IPY_MODEL_f05d7bdc5d3a4cae98364d7c207f0a72",
       "tabbable": null,
       "tooltip": null
      }
     },
     "8230c8238271418a8673acabbb3adf34": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "87b2f5dfce9b4dd1946bb44875ad1b8d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_380a9a1452b64e7bbc3d760a4d4fa7ba",
       "max": 229167,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_57fc1a8e618245cf904da22ee4b06259",
       "tabbable": null,
       "tooltip": null,
       "value": 229167
      }
     },
     "8bc76cb5fe9347178d8c65ea5c9a2eb6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8d02ab76f4f14359b9801ea1f7b68dd1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "92c3ca111b73490cacb5295964ffb39a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "9503ed5e9b3a46f887afc6e45a95ebf4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8230c8238271418a8673acabbb3adf34",
       "placeholder": "",
       "style": "IPY_MODEL_54d2214b4f2a4b98882692d43fed7381",
       "tabbable": null,
       "tooltip": null,
       "value": "229k/229k[00:00&lt;00:00,6.56MB/s]"
      }
     },
     "997674d4bad54c7b835b02c9b46d6cf9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a57e34eba0ef482c91454ca7bdd38f3d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_40d26a91d31c481faf511c1a1b70a6f6",
       "max": 112,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_92c3ca111b73490cacb5295964ffb39a",
       "tabbable": null,
       "tooltip": null,
       "value": 112
      }
     },
     "a63458c1355a467fbabac40ee2e2ded3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_230692eee19a4a56aa361ef00963d63b",
        "IPY_MODEL_719285dd50a6483bbea6b3a7b19e6508",
        "IPY_MODEL_b5bccd0a62944ceebc865fcc4227b11c"
       ],
       "layout": "IPY_MODEL_d848bc0f694a42a29cfd1e5e957c4163",
       "tabbable": null,
       "tooltip": null
      }
     },
     "b0129730b4b3451e9a2b6ab3f75933bc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b5bccd0a62944ceebc865fcc4227b11c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_663d6f5360de46b5a0a8038582b735aa",
       "placeholder": "",
       "style": "IPY_MODEL_3e671a904b8b43f1a3d510bfde9985f1",
       "tabbable": null,
       "tooltip": null,
       "value": "1.53k/1.53k[00:00&lt;00:00,173kB/s]"
      }
     },
     "b8980b1f169349e1b6b112e35da4747a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c3d2fcd311584cd191e042cc255819ec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f75c8de8fb0b43a399791a2ba0896347",
       "placeholder": "",
       "style": "IPY_MODEL_3eaf839346bc4a8f95a76140b7d70d69",
       "tabbable": null,
       "tooltip": null,
       "value": "2.00/2.00[00:00&lt;00:00,174B/s]"
      }
     },
     "cd5c3c0c6ee94fd3aee4763693b3c352": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d94c2de6531d4eb7bc97c18d7d7aa089",
       "placeholder": "",
       "style": "IPY_MODEL_269b3dea88b24914b83635552082d83d",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.txt:100%"
      }
     },
     "d848bc0f694a42a29cfd1e5e957c4163": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d94c2de6531d4eb7bc97c18d7d7aa089": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e100ffe977e94e1db2df025fe73e62ae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1b9eff7fca4b450799c79838a3671582",
        "IPY_MODEL_a57e34eba0ef482c91454ca7bdd38f3d",
        "IPY_MODEL_0535cf5575a744c685e91a45fe3a016a"
       ],
       "layout": "IPY_MODEL_8bc76cb5fe9347178d8c65ea5c9a2eb6",
       "tabbable": null,
       "tooltip": null
      }
     },
     "e465e8e0f91b4cd8990dd623d72ace0e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e8e9f260f3234491a42dc370c6aefd39": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f05d7bdc5d3a4cae98364d7c207f0a72": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f75c8de8fb0b43a399791a2ba0896347": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fbb08c617fd1431cbd60bb81c0662914": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_997674d4bad54c7b835b02c9b46d6cf9",
       "max": 2,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_465af8df13604b3582a07c50212de93b",
       "tabbable": null,
       "tooltip": null,
       "value": 2
      }
     },
     "fff091de4fed459a86648df5bf54b95b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
