{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ff9f09b",
   "metadata": {
    "papermill": {
     "duration": 0.011962,
     "end_time": "2025-03-23T13:24:20.146280",
     "exception": false,
     "start_time": "2025-03-23T13:24:20.134318",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af357026",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T13:24:20.169810Z",
     "iopub.status.busy": "2025-03-23T13:24:20.169547Z",
     "iopub.status.idle": "2025-03-23T13:24:43.667307Z",
     "shell.execute_reply": "2025-03-23T13:24:43.666594Z"
    },
    "papermill": {
     "duration": 23.51103,
     "end_time": "2025-03-23T13:24:43.668766",
     "exception": false,
     "start_time": "2025-03-23T13:24:20.157736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score, classification_report\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "from torch.multiprocessing import Manager\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel, BertPreTrainedModel, BertConfig, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed7f9e2",
   "metadata": {
    "papermill": {
     "duration": 0.010857,
     "end_time": "2025-03-23T13:24:43.690985",
     "exception": false,
     "start_time": "2025-03-23T13:24:43.680128",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "741e1dc8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T13:24:43.714139Z",
     "iopub.status.busy": "2025-03-23T13:24:43.713637Z",
     "iopub.status.idle": "2025-03-23T13:24:43.716847Z",
     "shell.execute_reply": "2025-03-23T13:24:43.716287Z"
    },
    "papermill": {
     "duration": 0.015921,
     "end_time": "2025-03-23T13:24:43.718027",
     "exception": false,
     "start_time": "2025-03-23T13:24:43.702106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab0f2117",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T13:24:43.741155Z",
     "iopub.status.busy": "2025-03-23T13:24:43.740905Z",
     "iopub.status.idle": "2025-03-23T13:24:43.744402Z",
     "shell.execute_reply": "2025-03-23T13:24:43.743779Z"
    },
    "papermill": {
     "duration": 0.016175,
     "end_time": "2025-03-23T13:24:43.745579",
     "exception": false,
     "start_time": "2025-03-23T13:24:43.729404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists('/kaggle/working/results') == False:\n",
    "    os.mkdir('/kaggle/working/results')\n",
    "\n",
    "if os.path.exists('/kaggle/working/acquired_data') == False:\n",
    "    os.mkdir('/kaggle/working/acquired_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaf52b47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T13:24:43.768202Z",
     "iopub.status.busy": "2025-03-23T13:24:43.767985Z",
     "iopub.status.idle": "2025-03-23T13:24:43.776742Z",
     "shell.execute_reply": "2025-03-23T13:24:43.776194Z"
    },
    "papermill": {
     "duration": 0.021125,
     "end_time": "2025-03-23T13:24:43.777884",
     "exception": false,
     "start_time": "2025-03-23T13:24:43.756759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "    torch.backends.cudnn.benchmark=False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c960c30",
   "metadata": {
    "papermill": {
     "duration": 0.010642,
     "end_time": "2025-03-23T13:24:43.799497",
     "exception": false,
     "start_time": "2025-03-23T13:24:43.788855",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# GLOBAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0a3b3df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T13:24:43.825341Z",
     "iopub.status.busy": "2025-03-23T13:24:43.825142Z",
     "iopub.status.idle": "2025-03-23T13:24:43.883996Z",
     "shell.execute_reply": "2025-03-23T13:24:43.882502Z"
    },
    "papermill": {
     "duration": 0.071903,
     "end_time": "2025-03-23T13:24:43.885905",
     "exception": false,
     "start_time": "2025-03-23T13:24:43.814002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "\n",
    "# Shared resources\n",
    "aspect_accuracies = manager.list()\n",
    "aspect_f1_micros = manager.list()\n",
    "aspect_f1_macros = manager.list()\n",
    "sentiment_accuracies = manager.list()\n",
    "sentiment_f1_micros = manager.list()\n",
    "sentiment_f1_macros = manager.list()\n",
    "accuracies = manager.list()\n",
    "f1_micros = manager.list()\n",
    "f1_macros = manager.list()\n",
    "farthest_point = manager.Value(\"s\", \"test\")\n",
    "\n",
    "# Non shared resources\n",
    "filename = 'casa-coreset'\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "sequence_length = 48\n",
    "\n",
    "aspect_list = ['fuel', 'machine', 'others', 'part', 'price', 'service']\n",
    "aspect_mapping = {'fuel': 0, 'machine': 1, 'others': 2, 'part': 3, 'price': 4, 'service': 5 }\n",
    "label_mapping = {\"negative\": 0, \"neutral\": 1, 'positive': 2}\n",
    "ignored_keys = ['labels', 'ori_text', 'ori_label', 'ori_indices', 'aspect']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb5fe44",
   "metadata": {
    "papermill": {
     "duration": 0.010835,
     "end_time": "2025-03-23T13:24:43.907869",
     "exception": false,
     "start_time": "2025-03-23T13:24:43.897034",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LOAD AND PREPROCESS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "296034a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T13:24:43.931205Z",
     "iopub.status.busy": "2025-03-23T13:24:43.930896Z",
     "iopub.status.idle": "2025-03-23T13:24:44.001343Z",
     "shell.execute_reply": "2025-03-23T13:24:44.000556Z"
    },
    "papermill": {
     "duration": 0.083678,
     "end_time": "2025-03-23T13:24:44.002571",
     "exception": false,
     "start_time": "2025-03-23T13:24:43.918893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>fuel</th>\n",
       "      <th>machine</th>\n",
       "      <th>others</th>\n",
       "      <th>part</th>\n",
       "      <th>price</th>\n",
       "      <th>service</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saya memakai Honda Jazz GK5 tahun 2014 ( perta...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Avanza kenapa jadi boros bensin begini dah ah....</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saran ku dan pengalaman ku , mending beli mobi...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dari segi harga juga pajero lebih mahal 30 jut...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kalo menurut gw enak pajero si</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence      fuel   machine  \\\n",
       "0  Saya memakai Honda Jazz GK5 tahun 2014 ( perta...   neutral   neutral   \n",
       "1  Avanza kenapa jadi boros bensin begini dah ah....  negative   neutral   \n",
       "2  saran ku dan pengalaman ku , mending beli mobi...  positive  positive   \n",
       "3  Dari segi harga juga pajero lebih mahal 30 jut...   neutral   neutral   \n",
       "4                     Kalo menurut gw enak pajero si   neutral   neutral   \n",
       "\n",
       "     others     part     price  service  \n",
       "0  positive  neutral   neutral  neutral  \n",
       "1   neutral  neutral   neutral  neutral  \n",
       "2   neutral  neutral   neutral  neutral  \n",
       "3   neutral  neutral  positive  neutral  \n",
       "4  positive  neutral   neutral  neutral  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('/kaggle/input/casa-dataset/train_preprocess.csv', encoding='latin-1')\n",
    "val_data = pd.read_csv('/kaggle/input/casa-dataset/valid_preprocess.csv', encoding='latin-1')\n",
    "test_data = pd.read_csv('/kaggle/input/casa-dataset/test_preprocess.csv', encoding='latin-1')\n",
    "\n",
    "data = pd.concat([train_data, val_data, test_data], ignore_index=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa9bc20e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T13:24:44.026005Z",
     "iopub.status.busy": "2025-03-23T13:24:44.025799Z",
     "iopub.status.idle": "2025-03-23T13:24:44.032832Z",
     "shell.execute_reply": "2025-03-23T13:24:44.032218Z"
    },
    "papermill": {
     "duration": 0.020246,
     "end_time": "2025-03-23T13:24:44.034193",
     "exception": false,
     "start_time": "2025-03-23T13:24:44.013947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03b36c97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T13:24:44.056954Z",
     "iopub.status.busy": "2025-03-23T13:24:44.056749Z",
     "iopub.status.idle": "2025-03-23T13:24:44.067028Z",
     "shell.execute_reply": "2025-03-23T13:24:44.066215Z"
    },
    "papermill": {
     "duration": 0.023092,
     "end_time": "2025-03-23T13:24:44.068331",
     "exception": false,
     "start_time": "2025-03-23T13:24:44.045239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(864,) (864, 6)\n",
      "(216,) (216, 6)\n"
     ]
    }
   ],
   "source": [
    "train_labels = train_data.columns[1:]\n",
    "val_labels = val_data.columns[1:]\n",
    "\n",
    "# Extract features and labels for training and validation\n",
    "X_train = train_data['sentence'].values\n",
    "y_train = train_data[train_labels].values\n",
    "X_val = val_data['sentence'].values\n",
    "y_val = val_data[val_labels].values\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88f670d",
   "metadata": {
    "papermill": {
     "duration": 0.010822,
     "end_time": "2025-03-23T13:24:44.090340",
     "exception": false,
     "start_time": "2025-03-23T13:24:44.079518",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BUILD DATASET & DATALOADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "351d4c8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T13:24:44.113015Z",
     "iopub.status.busy": "2025-03-23T13:24:44.112791Z",
     "iopub.status.idle": "2025-03-23T13:24:44.118522Z",
     "shell.execute_reply": "2025-03-23T13:24:44.117852Z"
    },
    "papermill": {
     "duration": 0.018435,
     "end_time": "2025-03-23T13:24:44.119755",
     "exception": false,
     "start_time": "2025-03-23T13:24:44.101320",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AspectDetectionDataset(Dataset):\n",
    "    def __init__(self, texts, labels, label_mapping, tokenizer, max_length=sequence_length, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.use_float = use_float\n",
    "        self.label_mapping = label_mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "        \n",
    "        original_labels = [self.label_mapping[label] for label in self.labels[idx]]\n",
    "        encoded_labels = [1 if label == 1 else 0 for label in original_labels]\n",
    "        \n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['ori_indices'] = idx\n",
    "        item['ori_text'] = self.texts[idx]\n",
    "        item['ori_label'] = torch.tensor(original_labels, dtype=torch.float)\n",
    "        item['labels'] = torch.tensor(encoded_labels, dtype=torch.float if self.use_float else torch.long)\n",
    "        \n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d60aeb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T13:24:44.142623Z",
     "iopub.status.busy": "2025-03-23T13:24:44.142411Z",
     "iopub.status.idle": "2025-03-23T13:24:44.149014Z",
     "shell.execute_reply": "2025-03-23T13:24:44.148410Z"
    },
    "papermill": {
     "duration": 0.019494,
     "end_time": "2025-03-23T13:24:44.150269",
     "exception": false,
     "start_time": "2025-03-23T13:24:44.130775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SentimentAnalysisDataset(Dataset):\n",
    "    def __init__(self, texts, labels, aspects, indices, label_mapping, tokenizer, max_length=96, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.aspects = aspects\n",
    "        self.indices = indices\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.use_float = use_float\n",
    "        self.label_mapping = label_mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = aspect_token + ' ' + self.aspects[idx] + ' ' + review_token + ' ' + self.texts[idx] \n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "\n",
    "        if isinstance(self.labels[idx], str):\n",
    "            self.labels[idx] = self.label_mapping[self.labels[idx]]\n",
    "        elif torch.is_tensor(self.labels[idx]):\n",
    "            self.labels[idx] = int(self.labels[idx].item())\n",
    "\n",
    "        encoded_label = 1 if self.labels[idx] == 2 else self.labels[idx]\n",
    "        one_hot_label = F.one_hot(torch.tensor(encoded_label, dtype=torch.long), num_classes=2).float()\n",
    "\n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['aspect'] = self.aspects[idx]\n",
    "        item['labels'] = one_hot_label\n",
    "        item['ori_indices'] = self.indices[idx]\n",
    "        item['ori_text'] = self.texts[idx]\n",
    "        item['ori_label'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2717da2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T13:24:44.173839Z",
     "iopub.status.busy": "2025-03-23T13:24:44.173593Z",
     "iopub.status.idle": "2025-03-23T13:24:45.575773Z",
     "shell.execute_reply": "2025-03-23T13:24:45.575182Z"
    },
    "papermill": {
     "duration": 1.415494,
     "end_time": "2025-03-23T13:24:45.577024",
     "exception": false,
     "start_time": "2025-03-23T13:24:44.161530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9875b31f8c0e4483bdbdabd6973b2a53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c6c5aab94634158877f73915ae749ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/229k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a8183b1a81c4f96b95086fddd1ba9b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "695842332125432e8f5a3f5989b64f6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p1')\n",
    "review_token = '[REVIEW]'\n",
    "aspect_token = '[ASPECT]'\n",
    "special_tokens_dict = {'additional_special_tokens': [review_token, aspect_token]}\n",
    "num_added_tokens = tokenizer.add_special_tokens(special_tokens_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf7fbc54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T13:24:45.601809Z",
     "iopub.status.busy": "2025-03-23T13:24:45.601570Z",
     "iopub.status.idle": "2025-03-23T13:24:45.605954Z",
     "shell.execute_reply": "2025-03-23T13:24:45.605189Z"
    },
    "papermill": {
     "duration": 0.018147,
     "end_time": "2025-03-23T13:24:45.607276",
     "exception": false,
     "start_time": "2025-03-23T13:24:45.589129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_aspect_dataset(X_train, y_train, X_val, y_val, sequence_length, num_workers=4):\n",
    "    train_dataset = AspectDetectionDataset(X_train, y_train, label_mapping, tokenizer, max_length=sequence_length)\n",
    "    val_dataset = AspectDetectionDataset(X_val, y_val, label_mapping, tokenizer, max_length=sequence_length)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=num_workers,\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=num_workers, \n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8485a574",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T13:24:45.631400Z",
     "iopub.status.busy": "2025-03-23T13:24:45.631189Z",
     "iopub.status.idle": "2025-03-23T13:24:45.640485Z",
     "shell.execute_reply": "2025-03-23T13:24:45.639884Z"
    },
    "papermill": {
     "duration": 0.022749,
     "end_time": "2025-03-23T13:24:45.641664",
     "exception": false,
     "start_time": "2025-03-23T13:24:45.618915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_sentiment_dataset(device, train_dataset, val_dataset, aspect_detection_model, tokenizer, max_length=sequence_length):\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "\n",
    "    aspect_detection_model.to(device)\n",
    "    aspect_detection_model.eval()\n",
    "\n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "    train_aspects = []\n",
    "    train_indices = []\n",
    "\n",
    "    val_data = []\n",
    "    val_labels = []\n",
    "    val_aspects = []\n",
    "    val_indices = []\n",
    "\n",
    "    # Transform train set\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        for batch in train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = aspect_detection_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            for i in range(len(preds)):\n",
    "                for j in range(len(preds[i])):\n",
    "                    if int(preds[i][j]) != 1:\n",
    "                        train_aspects.append(aspect_list[j])\n",
    "                        train_data.append(batch['ori_text'][i])\n",
    "                        train_labels.append(batch['ori_label'][i][j])\n",
    "                        train_indices.append(batch['ori_indices'][i])\n",
    "            \n",
    "        # Transform validation set\n",
    "        for batch in val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = aspect_detection_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            for i in range(len(preds)):\n",
    "                for j in range(len(preds[i])):\n",
    "                    if int(preds[i][j]) != 1:\n",
    "                        val_aspects.append(aspect_list[j])\n",
    "                        val_data.append(batch['ori_text'][i])\n",
    "                        val_labels.append(batch['ori_label'][i][j])\n",
    "                        val_indices.append(batch['ori_indices'][i])\n",
    "\n",
    "    train_dataset = SentimentAnalysisDataset(train_data, train_labels, train_aspects, train_indices, label_mapping, tokenizer, max_length=max_length)\n",
    "    val_dataset = SentimentAnalysisDataset(val_data, val_labels, val_aspects, val_indices, label_mapping, tokenizer, max_length=max_length)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fae8078",
   "metadata": {
    "papermill": {
     "duration": 0.011335,
     "end_time": "2025-03-23T13:24:45.665753",
     "exception": false,
     "start_time": "2025-03-23T13:24:45.654418",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "688c2c66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T13:24:45.689303Z",
     "iopub.status.busy": "2025-03-23T13:24:45.689096Z",
     "iopub.status.idle": "2025-03-23T13:24:45.692322Z",
     "shell.execute_reply": "2025-03-23T13:24:45.691750Z"
    },
    "papermill": {
     "duration": 0.016527,
     "end_time": "2025-03-23T13:24:45.693570",
     "exception": false,
     "start_time": "2025-03-23T13:24:45.677043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_data = len(X_train) + len(X_val)\n",
    "initial_train_size = int(0.05 * total_data)\n",
    "checkpoints = [\n",
    "    int(0.5 * total_data), \n",
    "    int(0.6 * total_data), \n",
    "    int(0.7 * total_data),\n",
    "    len(X_train)\n",
    "]\n",
    "min_increment = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1a7fb64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T13:24:45.716981Z",
     "iopub.status.busy": "2025-03-23T13:24:45.716782Z",
     "iopub.status.idle": "2025-03-23T13:24:45.721237Z",
     "shell.execute_reply": "2025-03-23T13:24:45.720460Z"
    },
    "papermill": {
     "duration": 0.017577,
     "end_time": "2025-03-23T13:24:45.722539",
     "exception": false,
     "start_time": "2025-03-23T13:24:45.704962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p, label, classes):\n",
    "    preds = torch.tensor(p.predictions) # Sigmoid and threshold for multi-label\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Hamming accuracy: proportion of correctly predicted labels over total labels\n",
    "    hamming_accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Standard multi-label precision, recall, and F1 metrics\n",
    "    precision, recall, f1_micro, _ = precision_recall_fscore_support(labels, preds, average='micro', zero_division=0)\n",
    "    _, _, f1_macro, _ = precision_recall_fscore_support(labels, preds, average='macro', zero_division=0)\n",
    "\n",
    "    report = classification_report(\n",
    "        labels, \n",
    "        preds, \n",
    "        labels=label,\n",
    "        target_names=classes,\n",
    "        zero_division=0\n",
    "    ) \n",
    "\n",
    "    return {\n",
    "        'accuracy': hamming_accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'report': report\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a09d558",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T13:24:45.747630Z",
     "iopub.status.busy": "2025-03-23T13:24:45.747408Z",
     "iopub.status.idle": "2025-03-23T13:24:45.753616Z",
     "shell.execute_reply": "2025-03-23T13:24:45.752834Z"
    },
    "papermill": {
     "duration": 0.019348,
     "end_time": "2025-03-23T13:24:45.754877",
     "exception": false,
     "start_time": "2025-03-23T13:24:45.735529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics_overall(p, classes):\n",
    "    preds = torch.tensor(p.predictions)\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Ensure it's in the correct shape\n",
    "    if preds.shape != labels.shape:\n",
    "        raise ValueError(\"Shape mismatch: predictions and labels must have the same shape.\")\n",
    "\n",
    "    # Hamming accuracy: proportion of correctly predicted labels over total labels\n",
    "    hamming_accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Compute per-label (column-wise) precision, recall, F1\n",
    "    precision_list, recall_list, f1_micro_list, f1_macro_list = [], [], [], []\n",
    "    \n",
    "    for i in range(labels.shape[1]):  # Loop through each column (multi-output)\n",
    "        prec, rec, f1_micro, _ = precision_recall_fscore_support(\n",
    "            labels[:, i], preds[:, i], average='micro', zero_division=0\n",
    "        )\n",
    "        _, _, f1_macro, _ = precision_recall_fscore_support(\n",
    "            labels[:, i], preds[:, i], average='macro', zero_division=0\n",
    "        )\n",
    "\n",
    "        precision_list.append(prec)\n",
    "        recall_list.append(rec)\n",
    "        f1_micro_list.append(f1_micro)\n",
    "        f1_macro_list.append(f1_macro)\n",
    "\n",
    "    # Compute average metrics across all outputs\n",
    "    precision = sum(precision_list) / len(precision_list)\n",
    "    recall = sum(recall_list) / len(recall_list)\n",
    "    f1_micro = sum(f1_micro_list) / len(f1_micro_list)\n",
    "    f1_macro = sum(f1_macro_list) / len(f1_macro_list)\n",
    "\n",
    "    # Generate classification report per output\n",
    "    reports = [classification_report(labels[:, i], preds[:, i], target_names=classes, zero_division=0) for i in range(labels.shape[1])]\n",
    "\n",
    "    return {\n",
    "        'accuracy': hamming_accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'reports': reports  # Returns list of reports, one for each output label\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "924c3625",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T13:24:45.778612Z",
     "iopub.status.busy": "2025-03-23T13:24:45.778413Z",
     "iopub.status.idle": "2025-03-23T13:24:45.803490Z",
     "shell.execute_reply": "2025-03-23T13:24:45.802863Z"
    },
    "papermill": {
     "duration": 0.038294,
     "end_time": "2025-03-23T13:24:45.804707",
     "exception": false,
     "start_time": "2025-03-23T13:24:45.766413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(current_train_size, train_indices, aspect_metrics, sentiment_metrics, metrics, trials, seed):\n",
    "    accelerator = Accelerator(mixed_precision='fp16')  # Initialize the accelerator\n",
    "    device = accelerator.device\n",
    "\n",
    "    aspect_model = BertForSequenceClassification.from_pretrained(\n",
    "        'indobenchmark/indobert-base-p1',\n",
    "        num_labels=len(train_labels),\n",
    "        problem_type=\"multi_label_classification\"\n",
    "    )\n",
    "\n",
    "    # Freeze the first few layers of the encoder\n",
    "    for name, param in aspect_model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    # Define optimizer and loss function\n",
    "    aspect_optimizer = torch.optim.AdamW(aspect_model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Define DataLoaders\n",
    "    current_X_train = [X_train[i] for i in train_indices]\n",
    "    current_y_train = [y_train[i] for i in train_indices]\n",
    "    aspect_train_loader, aspect_val_loader, aspect_train_dataset, aspect_val_dataset = build_aspect_dataset(current_X_train, current_y_train, X_val, y_val, sequence_length)\n",
    "\n",
    "    # Prepare everything with Accelerator\n",
    "    aspect_model, aspect_optimizer, aspect_train_loader, aspect_val_loader = accelerator.prepare(\n",
    "        aspect_model, aspect_optimizer, aspect_train_loader, aspect_val_loader\n",
    "    )\n",
    "\n",
    "    aspect_result = None\n",
    "    start_time = time.time()\n",
    "\n",
    "    # ASPECT DETECTION\n",
    "    accelerator.print(\"ASPECT DETECTION\")\n",
    "    for epoch in range(epochs):\n",
    "        aspect_model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for batch in aspect_train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels']\n",
    "        \n",
    "            aspect_optimizer.zero_grad()\n",
    "            outputs = aspect_model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            aspect_optimizer.step()\n",
    "        \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "        aspect_model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in aspect_val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "                labels = batch['labels']\n",
    "                \n",
    "                outputs = aspect_model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                # Gather predictions and labels from all devices\n",
    "                all_preds.append(accelerator.gather(preds))\n",
    "                all_labels.append(accelerator.gather(labels))\n",
    "\n",
    "        all_preds = torch.cat(all_preds).cpu().numpy()\n",
    "        all_labels = torch.cat(all_labels).cpu().numpy()\n",
    "\n",
    "        result = compute_metrics(\n",
    "            type('EvalOutput', (object,), {'predictions': all_preds, 'label_ids': all_labels}),\n",
    "            None,\n",
    "            ['fuel', 'machine', 'others', 'part', 'price', 'service']\n",
    "        )\n",
    "\n",
    "        if aspect_result is None or result['f1_micro'] >= aspect_result['f1_micro']:\n",
    "            accelerator.print(\"Higher F1 achieved, saving model\")\n",
    "            \n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(aspect_model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                f'{filename}-aspect-{trials + 1}-model',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "            aspect_result = result\n",
    "\n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(aspect_train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "\n",
    "    accelerator.print(f\"\\nAspect detection accuracy: {round(aspect_result['accuracy'], 4)}, F1 Micro: {round(aspect_result['f1_micro'], 4)}, F1 Macro: {round(aspect_result['f1_macro'], 4)}\")\n",
    "    accelerator.print(aspect_result['report'])\n",
    "\n",
    "    best_aspect_model = BertForSequenceClassification.from_pretrained(f'{filename}-aspect-{trials + 1}-model')\n",
    "    best_aspect_model = accelerator.prepare(best_aspect_model)\n",
    "\n",
    "    # SENTIMENT ANALYSIS ON NON NEUTRAL ASPECTS\n",
    "    accelerator.print(\"--------------------------------------------------\")\n",
    "    accelerator.print(\"SENTIMENT ANALYSIS\")\n",
    "\n",
    "    sentiment_model = BertForSequenceClassification.from_pretrained(\n",
    "        'indobenchmark/indobert-base-p1',\n",
    "        num_labels=2,\n",
    "    )\n",
    "    sentiment_optimizer = torch.optim.AdamW(sentiment_model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "\n",
    "    for name, param in sentiment_model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    sentiment_train_loader, sentiment_val_loader, sentiment_train_dataset, sentiment_val_dataset = build_sentiment_dataset(\n",
    "        device, aspect_train_dataset, aspect_val_dataset, best_aspect_model, tokenizer, max_length=sequence_length\n",
    "    )\n",
    "    sentiment_model, sentiment_optimizer, sentiment_train_loader, sentiment_val_loader = accelerator.prepare(\n",
    "        sentiment_model, sentiment_optimizer, sentiment_train_loader, sentiment_val_loader\n",
    "    )\n",
    "    sentiment_result = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        sentiment_model.train()\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for batch in sentiment_train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels']\n",
    "        \n",
    "            sentiment_optimizer.zero_grad()\n",
    "            outputs = sentiment_model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            sentiment_optimizer.step()\n",
    "        \n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        sentiment_model.eval()\n",
    "        sentiment_val_outputs = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in sentiment_val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "                \n",
    "                outputs = sentiment_model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                for i in range(len(preds)):\n",
    "                    val_output = {\n",
    "                        'label': batch['labels'][i],\n",
    "                        'aspect': batch['aspect'][i],\n",
    "                        'ori_indices': batch['ori_indices'][i],\n",
    "                        'pred': np.argmax(preds[i].cpu().numpy()),\n",
    "                    }\n",
    "                    sentiment_val_outputs.append(val_output)\n",
    "\n",
    "        sentiment_val_outputs = accelerator.gather_for_metrics(sentiment_val_outputs)\n",
    "        unique_val_outputs = {(x['ori_indices'].item(), x['aspect']): x for x in sentiment_val_outputs}\n",
    "        sentiment_val_outputs = list(unique_val_outputs.values())\n",
    "\n",
    "        result = compute_metrics(\n",
    "            type('EvalOutput', (object,), {'predictions': [item['pred'] for item in sentiment_val_outputs], 'label_ids': [np.argmax(item['label'].cpu().numpy()) for item in sentiment_val_outputs]}),\n",
    "            [0, 1],\n",
    "            ['negative', 'positive']\n",
    "        )\n",
    "\n",
    "        if sentiment_result is None or result['f1_micro'] >= sentiment_result['f1_micro']:\n",
    "            accelerator.print(\"Higher F1 achieved, saving model\")\n",
    "            sentiment_result = result\n",
    "            \n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(sentiment_model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                 f'{filename}-sentiment-{trials + 1}-model',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "\n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(sentiment_train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "\n",
    "    accelerator.print(f\"\\nSentiment analysis accuracy: {round(sentiment_result['accuracy'], 4)}, F1 Micro: {round(sentiment_result['f1_micro'], 4)}, F1 Macro: {round(sentiment_result['f1_macro'], 4)}\")\n",
    "    accelerator.print(sentiment_result['report'])\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    best_sentiment_model = BertForSequenceClassification.from_pretrained( f'{filename}-sentiment-{trials + 1}-model')\n",
    "    best_sentiment_model = accelerator.prepare(best_sentiment_model)\n",
    "\n",
    "    # Compute overall metrics\n",
    "    aspect_labels = []\n",
    "    aspect_indices = []\n",
    "    aspect_preds = []\n",
    "\n",
    "    aspect_outputs = {}\n",
    "    sentiment_outputs = []\n",
    "    \n",
    "    best_aspect_model.eval()\n",
    "    best_sentiment_model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in aspect_val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            outputs = aspect_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            aspect_indices.append(accelerator.gather(batch['ori_indices']))\n",
    "            aspect_labels.append(accelerator.gather(batch['ori_label']))\n",
    "            aspect_preds.append(accelerator.gather(preds))\n",
    "\n",
    "        aspect_indices = torch.cat(aspect_indices).cpu().numpy()\n",
    "        aspect_labels = torch.cat(aspect_labels).cpu().numpy()\n",
    "        aspect_preds = torch.cat(aspect_preds).cpu().numpy()\n",
    "\n",
    "        accelerator.wait_for_everyone()\n",
    "        aspect_outputs = [\n",
    "            {'ori_indices': aspect_indices[i], \n",
    "             'ori_labels': aspect_labels[i], \n",
    "             'pred': aspect_preds[i]}\n",
    "            for i in range(len(aspect_preds))\n",
    "        ]\n",
    "        aspect_outputs = {x['ori_indices'].item(): x for x in aspect_outputs}\n",
    "    \n",
    "        for batch in sentiment_val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            outputs = sentiment_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "    \n",
    "            for i in range(len(preds)):\n",
    "                output = {\n",
    "                    'aspect': batch['aspect'][i],\n",
    "                    'ori_indices': batch['ori_indices'][i],\n",
    "                    'pred': np.argmax(preds[i].cpu().numpy()),\n",
    "                }\n",
    "                sentiment_outputs.append(output)\n",
    "\n",
    "        sentiment_outputs = accelerator.gather_for_metrics(sentiment_outputs)\n",
    "        sentiment_outputs = {(x['ori_indices'].item(), x['aspect']): x for x in sentiment_outputs}\n",
    "\n",
    "    # Replcae non neutral aspect to its predicted sentiment\n",
    "    accelerator.wait_for_everyone()\n",
    "    if accelerator.is_main_process:\n",
    "        i = -1\n",
    "        for (ori_index, aspect), value in sentiment_outputs.items():\n",
    "            aspect = aspect_mapping[aspect]\n",
    "            aspect_outputs[ori_index]['pred'][aspect] = 2 if value['pred'] == 1.0 else value['pred']\n",
    "\n",
    "        result = compute_metrics_overall(\n",
    "            type('EvalOutput', (object,), {'predictions': [output['pred'] for output in aspect_outputs.values()], 'label_ids': [output['ori_labels'] for output in aspect_outputs.values()]}),\n",
    "            ['negative', 'neutral', 'positive'],\n",
    "        )\n",
    "\n",
    "        accelerator.print(\"--------------------------------------------------\")\n",
    "        accelerator.print(f\"Iteration {current_train_size}: Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "        accelerator.print(\"--------------------------------------------------\")\n",
    "        for i in range(len(train_labels)):\n",
    "            accelerator.print(f\"Aspect {aspect_list[i]} report:\")\n",
    "            accelerator.print(result['reports'][i])\n",
    "       \n",
    "        \n",
    "        aspect_metrics[0].append(aspect_result['accuracy'])\n",
    "        aspect_metrics[1].append(aspect_result['f1_micro'])\n",
    "        aspect_metrics[2].append(aspect_result['f1_macro'])\n",
    "        sentiment_metrics[0].append(sentiment_result['accuracy'])\n",
    "        sentiment_metrics[1].append(sentiment_result['f1_micro'])\n",
    "        sentiment_metrics[2].append(sentiment_result['f1_macro'])\n",
    "        metrics[0].append(current_train_size)\n",
    "        metrics[1].append(result['accuracy'])\n",
    "        metrics[2].append(result['f1_micro'])\n",
    "        metrics[3].append(result['f1_macro'])\n",
    "        \n",
    "    accelerator.print(f\"Total train time: {duration} s\")\n",
    "    accelerator.end_training()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3aff83",
   "metadata": {
    "papermill": {
     "duration": 0.011325,
     "end_time": "2025-03-23T13:24:45.827450",
     "exception": false,
     "start_time": "2025-03-23T13:24:45.816125",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PLOT THE RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "419c8dda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T13:24:45.851584Z",
     "iopub.status.busy": "2025-03-23T13:24:45.851382Z",
     "iopub.status.idle": "2025-03-23T13:24:45.856150Z",
     "shell.execute_reply": "2025-03-23T13:24:45.855558Z"
    },
    "papermill": {
     "duration": 0.018472,
     "end_time": "2025-03-23T13:24:45.857362",
     "exception": false,
     "start_time": "2025-03-23T13:24:45.838890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_result(data_used, accuracies, f1_micros, f1_macros):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(21, 5))\n",
    "    data_used = [round(data / total_data * 100, 1) for data in data_used]\n",
    "\n",
    "    # Plot for Accuracy\n",
    "    axs[0].plot(data_used, accuracies, label=\"Accuracy\", color=\"blue\")\n",
    "    axs[0].set_xlabel(\"Percentage of data used\")\n",
    "    axs[0].set_title(\"Accuracy\")\n",
    "    axs[0].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Micro\n",
    "    axs[1].plot(data_used, f1_micros, label=\"F1 Micro\", color=\"orange\")\n",
    "    axs[1].set_xlabel(\"Percentage of data used\")\n",
    "    axs[1].set_title(\"F1 Micro\")\n",
    "    axs[1].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Macro\n",
    "    axs[2].plot(data_used, f1_macros, label=\"F1 Macro\", color=\"green\")\n",
    "    axs[2].set_xlabel(\"Percentage of data used\")\n",
    "    axs[2].set_title(\"F1 Macro\")\n",
    "    axs[2].set_xticks(data_used)\n",
    "\n",
    "    # Adjust layout and show the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792b99fd",
   "metadata": {
    "papermill": {
     "duration": 0.011668,
     "end_time": "2025-03-23T13:24:45.880382",
     "exception": false,
     "start_time": "2025-03-23T13:24:45.868714",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# QUERY STRATEGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09366849",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T13:24:45.903962Z",
     "iopub.status.busy": "2025-03-23T13:24:45.903764Z",
     "iopub.status.idle": "2025-03-23T13:24:45.918963Z",
     "shell.execute_reply": "2025-03-23T13:24:45.918353Z"
    },
    "papermill": {
     "duration": 0.028265,
     "end_time": "2025-03-23T13:24:45.920017",
     "exception": false,
     "start_time": "2025-03-23T13:24:45.891752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def coreset_sampling(aspect_model, sentiment_model, farthest_point, X_pool, train_indices, remaining_indices, sampling_dur, new_samples, trials, n_samples=min_increment):\n",
    "    accelerator = Accelerator(mixed_precision=\"fp16\")\n",
    "    device = accelerator.device\n",
    "\n",
    "    aspect_model.to(device)\n",
    "    aspect_model.eval()\n",
    "    sentiment_model.to(device)\n",
    "    sentiment_model.eval()\n",
    "\n",
    "    farthest_data = farthest_point.value\n",
    "    if farthest_data is not None:\n",
    "        X_pool.append(farthest_data)\n",
    "        \n",
    "    current_train_size = len(train_indices)\n",
    "    aspect_dataset = AspectDetectionDataset(\n",
    "        X_pool,\n",
    "        [['neutral' for i in range(len(train_labels))] for x in range(len(X_pool))], \n",
    "        label_mapping, \n",
    "        tokenizer, \n",
    "        max_length=sequence_length\n",
    "    )\n",
    "    aspect_loader = DataLoader(\n",
    "        aspect_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    \n",
    "    aspect_outputs = {}\n",
    "    sentiment_outputs = {}\n",
    "\n",
    "    aspects = []\n",
    "    data = []\n",
    "    labels = []\n",
    "    indices = []\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Pass through aspect detction model\n",
    "    for batch in aspect_loader:\n",
    "        token_type_ids = batch['token_type_ids'].to(device, non_blocking=True)\n",
    "        input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "        attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = aspect_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids).logits\n",
    "            embeddings = aspect_model.base_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "\n",
    "        for i in range(len(outputs)):\n",
    "            aspect_outputs[batch['ori_indices'][i].item()] = embeddings.last_hidden_state[i].mean(dim=1).cpu().numpy()\n",
    "            \n",
    "            for j in range(len(outputs[i])):\n",
    "                if int(outputs[i][j].round()) != 1:\n",
    "                    aspects.append(aspect_list[j])\n",
    "                    data.append(batch['ori_text'][i])\n",
    "                    labels.append(batch['ori_label'][i][j])\n",
    "                    indices.append(batch['ori_indices'][i])\n",
    "\n",
    "    if len(data) > 0:\n",
    "        sentiment_dataset = SentimentAnalysisDataset(data, labels, aspects, indices, label_mapping, tokenizer, max_length=sequence_length)\n",
    "        sentiment_loader = torch.utils.data.DataLoader(\n",
    "            sentiment_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4,\n",
    "        )\n",
    "    \n",
    "        # Pass through sentiment analysis model\n",
    "        for batch in sentiment_loader:\n",
    "            token_type_ids = batch['token_type_ids'].to(device, non_blocking=True)\n",
    "            input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "            attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "    \n",
    "            with torch.no_grad():\n",
    "                outputs = sentiment_model.base_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "    \n",
    "            for i in range(len(outputs.last_hidden_state)):\n",
    "                ori_index = batch['ori_indices'][i].item()\n",
    "                if ori_index in sentiment_outputs.keys():\n",
    "                    sentiment_outputs[ori_index].append(outputs.last_hidden_state[i].mean(dim=1).cpu().numpy())\n",
    "                else:\n",
    "                    sentiment_outputs[ori_index] = [outputs.last_hidden_state[i].mean(dim=1).cpu().numpy()]\n",
    "\n",
    "    for key, val in sentiment_outputs.items():\n",
    "        sentiment_outputs[key] = np.mean(val, axis=0)\n",
    "\n",
    "    collected_indices = set()  # Initialize set to store selected indices\n",
    "    thresholds = []\n",
    "\n",
    "    if accelerator.is_main_process:\n",
    "        aspect_outputs = dict(sorted(aspect_outputs.items()))\n",
    "\n",
    "        if len(data) > 0:\n",
    "            for key, val in sentiment_outputs.items():\n",
    "                aspect_outputs[key] = np.mean([val, aspect_outputs[key]], axis=0)\n",
    "\n",
    "        embeddings = np.array(list(aspect_outputs.values()))\n",
    "        distance_matrix = pairwise_distances(embeddings)\n",
    "        selected_indices = distance_matrix.shape[0] - 1 if farthest_data is not None else 0\n",
    "\n",
    "        # Calculate the minimum distance from selected points to all other points\n",
    "        min_distances = distance_matrix[selected_indices]\n",
    "\n",
    "        sorted_dist = np.argsort(min_distances)\n",
    "        sorted_dist = sorted_dist[::-1]\n",
    "        farthest_point.value = aspect_dataset[sorted_dist[0]]['ori_text']\n",
    "\n",
    "        threshold = np.percentile(min_distances, 90)\n",
    "        candidates = np.where(min_distances >= threshold)[0]  # Select the point farthest from the current set\n",
    "        num_of_candidates = len(candidates)\n",
    "    \n",
    "        # Check nearest checkpoint\n",
    "        nearest_cp = 0\n",
    "        arrived_at_cp = False\n",
    "        for cp in checkpoints:\n",
    "            if cp > current_train_size:\n",
    "                nearest_cp = cp\n",
    "                break\n",
    "                \n",
    "        # Determine number of maximum samples to be acquired\n",
    "        if num_of_candidates <= n_samples and n_samples < nearest_cp - current_train_size:\n",
    "            selected_indices = sorted_dist[:n_samples]\n",
    "        elif num_of_candidates > n_samples and num_of_candidates < nearest_cp - current_train_size:\n",
    "             selected_indices = sorted_dist[:max(n_samples, min(math.ceil(0.1*len(sorted_dist)), num_of_candidates))]\n",
    "        else:\n",
    "            selected_indices = sorted_dist[:nearest_cp - current_train_size]\n",
    "            \n",
    "            temp = train_indices.copy()\n",
    "            temp.extend([remaining_indices[i] for i in selected_indices])\n",
    "            \n",
    "            # Save acquired data up to checkpoint\n",
    "            acquired_data = pd.DataFrame({\n",
    "                'processed_text': [X_train[i] for i in temp],\n",
    "                'fuel': [y_train[i][0] for i in temp],\n",
    "                'machine': [y_train[i][1] for i in temp],\n",
    "                'others': [y_train[i][2] for i in temp],\n",
    "                'part': [y_train[i][3] for i in temp],\n",
    "                'price': [y_train[i][4] for i in temp],\n",
    "                'service': [y_train[i][5] for i in temp],\n",
    "            })\n",
    "            acquired_data.to_csv(f'acquired_data/{filename}-{trials+1}-data-{nearest_cp}.csv', index=False)\n",
    "\n",
    "        end_time = time.time() \n",
    "        duration = end_time - start_time\n",
    "\n",
    "        sampling_dur.append(duration)\n",
    "        for i in selected_indices:\n",
    "            new_samples.append(remaining_indices[i])\n",
    "        \n",
    "        print(\"Nearest checkpoint:\", nearest_cp)\n",
    "        print(\"Threshold:\", threshold)\n",
    "        print(\"Acquired samples:\", len(selected_indices))\n",
    "        print(f\"Sampling duration: {duration} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a9632a",
   "metadata": {
    "papermill": {
     "duration": 0.0113,
     "end_time": "2025-03-23T13:24:45.942726",
     "exception": false,
     "start_time": "2025-03-23T13:24:45.931426",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MAIN LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65f91f4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T13:24:45.966284Z",
     "iopub.status.busy": "2025-03-23T13:24:45.966045Z",
     "iopub.status.idle": "2025-03-23T13:24:45.974680Z",
     "shell.execute_reply": "2025-03-23T13:24:45.974025Z"
    },
    "papermill": {
     "duration": 0.02175,
     "end_time": "2025-03-23T13:24:45.975851",
     "exception": false,
     "start_time": "2025-03-23T13:24:45.954101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def active_learning(seed, i):\n",
    "    aspect_accuracies = manager.list()\n",
    "    aspect_f1_micros = manager.list()\n",
    "    aspect_f1_macros = manager.list()\n",
    "    sentiment_accuracies = manager.list()\n",
    "    sentiment_f1_micros = manager.list()\n",
    "    sentiment_f1_macros = manager.list()\n",
    "    accuracies = manager.list()\n",
    "    f1_micros = manager.list()\n",
    "    f1_macros = manager.list()\n",
    "    data_used = manager.list()\n",
    "    sampling_dur = manager.list()\n",
    "    new_samples = manager.list()\n",
    "\n",
    "    set_seed(seed)\n",
    "    \n",
    "    print(\"===============================================\")\n",
    "    print(\"TRIAL {}\".format(i+1))\n",
    "    print(\"Random seed:\", seed)\n",
    "    \n",
    "    train_indices = np.random.choice(range(len(X_train)), initial_train_size, replace=False).tolist()\n",
    "    remaining_indices = list(set(range(len(X_train))) - set(train_indices))\n",
    "    \n",
    "    current_train_size = initial_train_size\n",
    "    \n",
    "    start_time = time.time()\n",
    "    while current_train_size < checkpoints[len(checkpoints) - 1]:\n",
    "        # Train the model\n",
    "        args = (\n",
    "            current_train_size, \n",
    "            train_indices, \n",
    "            (aspect_accuracies, aspect_f1_micros, aspect_f1_macros), \n",
    "            (sentiment_accuracies, sentiment_f1_micros, sentiment_f1_macros),\n",
    "            (data_used, accuracies, f1_micros, f1_macros), \n",
    "            i,\n",
    "            seed\n",
    "        )\n",
    "        notebook_launcher(train_model, args, num_processes=2)\n",
    "\n",
    "        aspect_model = BertForSequenceClassification.from_pretrained(f'{filename}-aspect-{i+1}-model')\n",
    "        sentiment_model = BertForSequenceClassification.from_pretrained(f'{filename}-sentiment-{i+1}-model')\n",
    "    \n",
    "        # Perform query strategy to select new samples\n",
    "        new_samples = manager.list()\n",
    "        sampling_args = (\n",
    "            aspect_model, \n",
    "            sentiment_model, \n",
    "            farthest_point,\n",
    "            [X_train[i] for i in remaining_indices], \n",
    "            train_indices, \n",
    "            remaining_indices, \n",
    "            sampling_dur, \n",
    "            new_samples, \n",
    "            i\n",
    "        )\n",
    "        notebook_launcher(coreset_sampling, sampling_args, num_processes=2)\n",
    "        new_samples = list(new_samples)\n",
    "        train_indices.extend(new_samples)\n",
    "        remaining_indices = list(set(remaining_indices) - set(new_samples))\n",
    "    \n",
    "        # Update current training size\n",
    "        current_train_size = len(train_indices)\n",
    "        print(\"New train size: {}\".format(current_train_size))\n",
    "    \n",
    "    # Train last epoch\n",
    "    args = (\n",
    "        current_train_size, \n",
    "        train_indices, \n",
    "        (aspect_accuracies, aspect_f1_micros, aspect_f1_macros), \n",
    "        (sentiment_accuracies, sentiment_f1_micros, sentiment_f1_macros),\n",
    "        (data_used, accuracies, f1_micros, f1_macros), \n",
    "        i,\n",
    "        seed\n",
    "    )\n",
    "    notebook_launcher(train_model, args, num_processes=2)\n",
    "    data_used, accuracies, f1_micros, f1_macros, sampling_dur = list(data_used), list(accuracies), list(f1_micros), list(f1_macros), list(sampling_dur)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    # print(f\"Total sampling time: {np.array(sampling_dur).sum().round(2)} seconds\")\n",
    "    print(f\"Total runtime: {duration} seconds\")\n",
    "    \n",
    "    plot_result(data_used, accuracies, f1_micros, f1_macros)\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        'Data Used': data_used,\n",
    "        'Aspect Accuracy': aspect_accuracies,\n",
    "        'Aspect F1 Micro': aspect_f1_micros,\n",
    "        'Aspect F1 Macro': aspect_f1_macros,\n",
    "        'Sentiment Accuracy': sentiment_accuracies,\n",
    "        'Sentiment F1 Micro': sentiment_f1_micros,\n",
    "        'Sentiment F1 Macro': sentiment_f1_macros,\n",
    "        'Accuracy': accuracies,\n",
    "        'F1 Micro': f1_micros,\n",
    "        'F1 Macro': f1_macros,\n",
    "    })\n",
    "    \n",
    "    sampling_dur.insert(0, 0)\n",
    "    results['Sampling Duration'] = sampling_dur\n",
    "    results.to_csv(f'results/{filename}-{i+1}-results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b20b9b95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T13:24:45.999417Z",
     "iopub.status.busy": "2025-03-23T13:24:45.999180Z",
     "iopub.status.idle": "2025-03-23T13:24:46.002274Z",
     "shell.execute_reply": "2025-03-23T13:24:46.001492Z"
    },
    "papermill": {
     "duration": 0.016189,
     "end_time": "2025-03-23T13:24:46.003462",
     "exception": false,
     "start_time": "2025-03-23T13:24:45.987273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seeds = [50, 81, 14, 3, 94]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d55b94b",
   "metadata": {
    "papermill": {
     "duration": 0.011269,
     "end_time": "2025-03-23T13:24:46.026146",
     "exception": false,
     "start_time": "2025-03-23T13:24:46.014877",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c8653f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T13:24:46.049710Z",
     "iopub.status.busy": "2025-03-23T13:24:46.049513Z",
     "iopub.status.idle": "2025-03-23T14:15:24.156089Z",
     "shell.execute_reply": "2025-03-23T14:15:24.155294Z"
    },
    "papermill": {
     "duration": 3038.119978,
     "end_time": "2025-03-23T14:15:24.157581",
     "exception": false,
     "start_time": "2025-03-23T13:24:46.037603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 1\n",
      "Random seed: 50\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6756, Accuracy: 0.7731, F1 Micro: 0.8711, F1 Macro: 0.8698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5958, Accuracy: 0.7887, F1 Micro: 0.8819, F1 Macro: 0.8804\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5785, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.513, Accuracy: 0.7939, F1 Micro: 0.8843, F1 Macro: 0.8828\n",
      "Epoch 5/10, Train Loss: 0.5006, Accuracy: 0.7924, F1 Micro: 0.8829, F1 Macro: 0.881\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4695, Accuracy: 0.7954, F1 Micro: 0.8846, F1 Macro: 0.8828\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4328, Accuracy: 0.7969, F1 Micro: 0.8857, F1 Macro: 0.8842\n",
      "Epoch 8/10, Train Loss: 0.4369, Accuracy: 0.7932, F1 Micro: 0.8832, F1 Macro: 0.8812\n",
      "Epoch 9/10, Train Loss: 0.415, Accuracy: 0.7917, F1 Micro: 0.8816, F1 Macro: 0.8789\n",
      "Epoch 10/10, Train Loss: 0.3884, Accuracy: 0.7894, F1 Micro: 0.88, F1 Macro: 0.8769\n",
      "\n",
      "Aspect detection accuracy: 0.7969, F1 Micro: 0.8857, F1 Macro: 0.8842\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.78      1.00      0.88       175\n",
      "      others       0.71      1.00      0.83       158\n",
      "        part       0.75      0.98      0.85       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.80      1.00      0.89      1061\n",
      "   macro avg       0.80      1.00      0.88      1061\n",
      "weighted avg       0.80      1.00      0.89      1061\n",
      " samples avg       0.80      1.00      0.88      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7162, Accuracy: 0.2857, F1 Micro: 0.2857, F1 Macro: 0.2222\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.6764, Accuracy: 0.5, F1 Micro: 0.5, F1 Macro: 0.4974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.6621, Accuracy: 0.7143, F1 Micro: 0.7143, F1 Macro: 0.65\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.6053, Accuracy: 0.7857, F1 Micro: 0.7857, F1 Macro: 0.7143\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.5803, Accuracy: 0.7857, F1 Micro: 0.7857, F1 Macro: 0.7143\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.5674, Accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.825\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4789, Accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.825\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4895, Accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.825\n",
      "Epoch 9/10, Train Loss: 0.4054, Accuracy: 0.7143, F1 Micro: 0.7143, F1 Macro: 0.6889\n",
      "Epoch 10/10, Train Loss: 0.3482, Accuracy: 0.5, F1 Micro: 0.5, F1 Macro: 0.4974\n",
      "\n",
      "Sentiment analysis accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.825\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75         4\n",
      "    positive       0.90      0.90      0.90        10\n",
      "\n",
      "    accuracy                           0.86        14\n",
      "   macro avg       0.82      0.82      0.82        14\n",
      "weighted avg       0.86      0.86      0.86        14\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.7793, F1 Micro: 0.7793, F1 Macro: 0.3103\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.77      1.00      0.87       167\n",
      "    positive       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.77       216\n",
      "   macro avg       0.26      0.33      0.29       216\n",
      "weighted avg       0.60      0.77      0.67       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.70      1.00      0.83       152\n",
      "    positive       0.00      0.00      0.00        52\n",
      "\n",
      "    accuracy                           0.70       216\n",
      "   macro avg       0.23      0.33      0.28       216\n",
      "weighted avg       0.50      0.70      0.58       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.16      0.26      0.20        23\n",
      "     neutral       0.75      0.86      0.80       152\n",
      "    positive       0.60      0.07      0.13        41\n",
      "\n",
      "    accuracy                           0.64       216\n",
      "   macro avg       0.50      0.40      0.38       216\n",
      "weighted avg       0.66      0.64      0.61       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 51.579975843429565 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.004588124807924032\n",
      "Acquired samples: 82\n",
      "Sampling duration: 9.386718988418579 seconds\n",
      "New train size: 136\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6434, Accuracy: 0.7894, F1 Micro: 0.8822, F1 Macro: 0.8808\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5617, Accuracy: 0.8013, F1 Micro: 0.8877, F1 Macro: 0.8861\n",
      "Epoch 3/10, Train Loss: 0.5271, Accuracy: 0.7939, F1 Micro: 0.8844, F1 Macro: 0.8829\n",
      "Epoch 4/10, Train Loss: 0.4906, Accuracy: 0.7954, F1 Micro: 0.8851, F1 Macro: 0.8835\n",
      "Epoch 5/10, Train Loss: 0.457, Accuracy: 0.7991, F1 Micro: 0.8859, F1 Macro: 0.884\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4262, Accuracy: 0.8028, F1 Micro: 0.8885, F1 Macro: 0.887\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4069, Accuracy: 0.8222, F1 Micro: 0.8968, F1 Macro: 0.8948\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3631, Accuracy: 0.8385, F1 Micro: 0.9053, F1 Macro: 0.9032\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3127, Accuracy: 0.8661, F1 Micro: 0.9204, F1 Macro: 0.9184\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2772, Accuracy: 0.8854, F1 Micro: 0.9296, F1 Macro: 0.9257\n",
      "\n",
      "Aspect detection accuracy: 0.8854, F1 Micro: 0.9296, F1 Macro: 0.9257\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.94      1.00      0.97       187\n",
      "     machine       0.88      0.95      0.91       175\n",
      "      others       0.88      0.82      0.85       158\n",
      "        part       0.84      0.97      0.90       158\n",
      "       price       0.91      0.99      0.95       192\n",
      "     service       0.95      0.99      0.97       191\n",
      "\n",
      "   micro avg       0.90      0.96      0.93      1061\n",
      "   macro avg       0.90      0.95      0.93      1061\n",
      "weighted avg       0.90      0.96      0.93      1061\n",
      " samples avg       0.91      0.95      0.92      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5818, Accuracy: 0.7381, F1 Micro: 0.7381, F1 Macro: 0.4247\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4505, Accuracy: 0.7381, F1 Micro: 0.7381, F1 Macro: 0.4247\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3807, Accuracy: 0.7571, F1 Micro: 0.7571, F1 Macro: 0.5109\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2778, Accuracy: 0.9, F1 Micro: 0.9, F1 Macro: 0.8683\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2564, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9157\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1753, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9175\n",
      "Epoch 7/10, Train Loss: 0.1665, Accuracy: 0.9143, F1 Micro: 0.9143, F1 Macro: 0.897\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1042, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9127\n",
      "Epoch 9/10, Train Loss: 0.1483, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9121\n",
      "Epoch 10/10, Train Loss: 0.0922, Accuracy: 0.9238, F1 Micro: 0.9238, F1 Macro: 0.9076\n",
      "\n",
      "Sentiment analysis accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9127\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87        55\n",
      "    positive       0.95      0.96      0.96       155\n",
      "\n",
      "    accuracy                           0.93       210\n",
      "   macro avg       0.92      0.91      0.91       210\n",
      "weighted avg       0.93      0.93      0.93       210\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 136: Accuracy: 0.8735, F1 Micro: 0.8735, F1 Macro: 0.7403\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.64      0.78        11\n",
      "     neutral       0.94      1.00      0.97       181\n",
      "    positive       1.00      0.67      0.80        24\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.98      0.77      0.85       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.44      0.58        16\n",
      "     neutral       0.88      0.95      0.91       167\n",
      "    positive       0.67      0.55      0.60        33\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.81      0.65      0.70       216\n",
      "weighted avg       0.85      0.85      0.84       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.44      0.67      0.53        12\n",
      "     neutral       0.88      0.81      0.85       152\n",
      "    positive       0.54      0.62      0.58        52\n",
      "\n",
      "    accuracy                           0.75       216\n",
      "   macro avg       0.62      0.70      0.65       216\n",
      "weighted avg       0.78      0.75      0.76       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.61      0.74        23\n",
      "     neutral       0.83      0.97      0.89       152\n",
      "    positive       0.79      0.46      0.58        41\n",
      "\n",
      "    accuracy                           0.83       216\n",
      "   macro avg       0.85      0.68      0.74       216\n",
      "weighted avg       0.83      0.83      0.82       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.38      0.56        13\n",
      "     neutral       0.91      0.99      0.95       186\n",
      "    positive       0.88      0.41      0.56        17\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.93      0.60      0.69       216\n",
      "weighted avg       0.91      0.91      0.90       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.86      0.86        14\n",
      "     neutral       0.95      0.99      0.97       185\n",
      "    positive       0.89      0.47      0.62        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.77      0.82       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Total train time: 71.21482300758362 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.00895455088466406\n",
      "Acquired samples: 73\n",
      "Sampling duration: 13.5071439743042 seconds\n",
      "New train size: 209\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6182, Accuracy: 0.7924, F1 Micro: 0.8837, F1 Macro: 0.8822\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.54, Accuracy: 0.7946, F1 Micro: 0.8849, F1 Macro: 0.8834\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4892, Accuracy: 0.7969, F1 Micro: 0.886, F1 Macro: 0.8846\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.463, Accuracy: 0.8103, F1 Micro: 0.8917, F1 Macro: 0.8905\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4277, Accuracy: 0.8341, F1 Micro: 0.9044, F1 Macro: 0.9035\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.368, Accuracy: 0.8839, F1 Micro: 0.9309, F1 Macro: 0.9299\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3155, Accuracy: 0.9115, F1 Micro: 0.9458, F1 Macro: 0.9439\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2558, Accuracy: 0.9256, F1 Micro: 0.9539, F1 Macro: 0.9518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2104, Accuracy: 0.9278, F1 Micro: 0.9553, F1 Macro: 0.953\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1803, Accuracy: 0.9382, F1 Micro: 0.9613, F1 Macro: 0.9586\n",
      "\n",
      "Aspect detection accuracy: 0.9382, F1 Micro: 0.9613, F1 Macro: 0.9586\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.97      0.96       175\n",
      "      others       0.90      0.92      0.91       158\n",
      "        part       0.93      0.92      0.93       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       0.97      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.95      0.97      0.96      1061\n",
      "   macro avg       0.95      0.97      0.96      1061\n",
      "weighted avg       0.95      0.97      0.96      1061\n",
      " samples avg       0.95      0.97      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.616, Accuracy: 0.6929, F1 Micro: 0.6929, F1 Macro: 0.4093\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5164, Accuracy: 0.748, F1 Micro: 0.748, F1 Macro: 0.6816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4152, Accuracy: 0.7598, F1 Micro: 0.7598, F1 Macro: 0.7489\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2975, Accuracy: 0.878, F1 Micro: 0.878, F1 Macro: 0.8591\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3045, Accuracy: 0.8819, F1 Micro: 0.8819, F1 Macro: 0.8681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2265, Accuracy: 0.8819, F1 Micro: 0.8819, F1 Macro: 0.8622\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2087, Accuracy: 0.8858, F1 Micro: 0.8858, F1 Macro: 0.8663\n",
      "Epoch 8/10, Train Loss: 0.0846, Accuracy: 0.8701, F1 Micro: 0.8701, F1 Macro: 0.8562\n",
      "Epoch 9/10, Train Loss: 0.1622, Accuracy: 0.874, F1 Micro: 0.874, F1 Macro: 0.853\n",
      "Epoch 10/10, Train Loss: 0.162, Accuracy: 0.8543, F1 Micro: 0.8543, F1 Macro: 0.8434\n",
      "\n",
      "Sentiment analysis accuracy: 0.8858, F1 Micro: 0.8858, F1 Macro: 0.8663\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.82      0.82        78\n",
      "    positive       0.92      0.91      0.92       176\n",
      "\n",
      "    accuracy                           0.89       254\n",
      "   macro avg       0.87      0.87      0.87       254\n",
      "weighted avg       0.89      0.89      0.89       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 209: Accuracy: 0.9174, F1 Micro: 0.9174, F1 Macro: 0.8386\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.94      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.81      0.79        16\n",
      "     neutral       0.95      0.96      0.96       167\n",
      "    positive       0.79      0.70      0.74        33\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.83      0.82      0.83       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.42      0.67      0.52        12\n",
      "     neutral       0.90      0.91      0.91       152\n",
      "    positive       0.71      0.58      0.64        52\n",
      "\n",
      "    accuracy                           0.82       216\n",
      "   macro avg       0.68      0.72      0.69       216\n",
      "weighted avg       0.83      0.82      0.82       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.53      0.83      0.64        23\n",
      "     neutral       0.93      0.92      0.92       152\n",
      "    positive       0.86      0.61      0.71        41\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.77      0.79      0.76       216\n",
      "weighted avg       0.87      0.85      0.85       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.97      1.00      0.99       186\n",
      "    positive       0.92      0.65      0.76        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.86      0.89       216\n",
      "weighted avg       0.97      0.97      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.97      1.00      0.98       185\n",
      "    positive       1.00      0.65      0.79        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.97      0.86      0.90       216\n",
      "weighted avg       0.97      0.97      0.96       216\n",
      "\n",
      "Total train time: 89.74286985397339 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.006665317807346582\n",
      "Acquired samples: 66\n",
      "Sampling duration: 13.888811588287354 seconds\n",
      "New train size: 275\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6038, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5153, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4942, Accuracy: 0.7969, F1 Micro: 0.8859, F1 Macro: 0.8844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4571, Accuracy: 0.8244, F1 Micro: 0.8984, F1 Macro: 0.8967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3741, Accuracy: 0.8921, F1 Micro: 0.9347, F1 Macro: 0.933\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2996, Accuracy: 0.9196, F1 Micro: 0.95, F1 Macro: 0.9471\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2424, Accuracy: 0.9256, F1 Micro: 0.9537, F1 Macro: 0.9509\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1985, Accuracy: 0.9278, F1 Micro: 0.9552, F1 Macro: 0.9525\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1614, Accuracy: 0.9375, F1 Micro: 0.9607, F1 Macro: 0.9577\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1346, Accuracy: 0.9472, F1 Micro: 0.9671, F1 Macro: 0.9653\n",
      "\n",
      "Aspect detection accuracy: 0.9472, F1 Micro: 0.9671, F1 Macro: 0.9653\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.93      0.99      0.96       175\n",
      "      others       0.90      0.94      0.92       158\n",
      "        part       0.96      0.96      0.96       158\n",
      "       price       0.97      1.00      0.98       192\n",
      "     service       0.97      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.95      0.98      0.97      1061\n",
      "   macro avg       0.95      0.98      0.97      1061\n",
      "weighted avg       0.95      0.98      0.97      1061\n",
      " samples avg       0.95      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.572, Accuracy: 0.6777, F1 Micro: 0.6777, F1 Macro: 0.4039\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4231, Accuracy: 0.8554, F1 Micro: 0.8554, F1 Macro: 0.8316\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.25, Accuracy: 0.8926, F1 Micro: 0.8926, F1 Macro: 0.8839\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1845, Accuracy: 0.8967, F1 Micro: 0.8967, F1 Macro: 0.8881\n",
      "Epoch 5/10, Train Loss: 0.2062, Accuracy: 0.8926, F1 Micro: 0.8926, F1 Macro: 0.8808\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1158, Accuracy: 0.9008, F1 Micro: 0.9008, F1 Macro: 0.8918\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1324, Accuracy: 0.9008, F1 Micro: 0.9008, F1 Macro: 0.8918\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1019, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8979\n",
      "Epoch 9/10, Train Loss: 0.0765, Accuracy: 0.9008, F1 Micro: 0.9008, F1 Macro: 0.8887\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1066, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8997\n",
      "\n",
      "Sentiment analysis accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.94      0.87        78\n",
      "    positive       0.97      0.90      0.93       164\n",
      "\n",
      "    accuracy                           0.91       242\n",
      "   macro avg       0.89      0.92      0.90       242\n",
      "weighted avg       0.92      0.91      0.91       242\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 275: Accuracy: 0.9352, F1 Micro: 0.9352, F1 Macro: 0.87\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.69      0.73        16\n",
      "     neutral       0.93      0.99      0.96       167\n",
      "    positive       0.92      0.67      0.77        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.88      0.78      0.82       216\n",
      "weighted avg       0.91      0.92      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.75      0.72        12\n",
      "     neutral       0.90      0.93      0.92       152\n",
      "    positive       0.78      0.67      0.72        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.79      0.79      0.79       216\n",
      "weighted avg       0.86      0.86      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.87      0.77        23\n",
      "     neutral       0.95      0.95      0.95       152\n",
      "    positive       0.91      0.78      0.84        41\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.85      0.87      0.86       216\n",
      "weighted avg       0.92      0.91      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.97      1.00      0.98       186\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.83      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.97      1.00      0.98       185\n",
      "    positive       1.00      0.71      0.83        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.99      0.88      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 91.142746925354 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.006366878328844905\n",
      "Acquired samples: 59\n",
      "Sampling duration: 13.000041961669922 seconds\n",
      "New train size: 334\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5845, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Epoch 2/10, Train Loss: 0.5161, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4739, Accuracy: 0.8095, F1 Micro: 0.8921, F1 Macro: 0.8909\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4056, Accuracy: 0.8847, F1 Micro: 0.931, F1 Macro: 0.9296\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3137, Accuracy: 0.9271, F1 Micro: 0.9553, F1 Macro: 0.9538\n",
      "Epoch 6/10, Train Loss: 0.2466, Accuracy: 0.9211, F1 Micro: 0.9506, F1 Macro: 0.9463\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1982, Accuracy: 0.9487, F1 Micro: 0.9681, F1 Macro: 0.9665\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1457, Accuracy: 0.9554, F1 Micro: 0.9722, F1 Macro: 0.9709\n",
      "Epoch 9/10, Train Loss: 0.1256, Accuracy: 0.9546, F1 Micro: 0.9717, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1026, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.972\n",
      "\n",
      "Aspect detection accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.972\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.91      0.93      0.92       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.97      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.563, Accuracy: 0.6786, F1 Micro: 0.6786, F1 Macro: 0.4043\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4059, Accuracy: 0.8849, F1 Micro: 0.8849, F1 Macro: 0.8649\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2422, Accuracy: 0.8968, F1 Micro: 0.8968, F1 Macro: 0.8882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1934, Accuracy: 0.8968, F1 Micro: 0.8968, F1 Macro: 0.8846\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.164, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8947\n",
      "Epoch 6/10, Train Loss: 0.1463, Accuracy: 0.8929, F1 Micro: 0.8929, F1 Macro: 0.8842\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1209, Accuracy: 0.9127, F1 Micro: 0.9127, F1 Macro: 0.9012\n",
      "Epoch 8/10, Train Loss: 0.0887, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8929\n",
      "Epoch 9/10, Train Loss: 0.1195, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8947\n",
      "Epoch 10/10, Train Loss: 0.0825, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.9009\n",
      "\n",
      "Sentiment analysis accuracy: 0.9127, F1 Micro: 0.9127, F1 Macro: 0.9012\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.89      0.87        81\n",
      "    positive       0.95      0.92      0.93       171\n",
      "\n",
      "    accuracy                           0.91       252\n",
      "   macro avg       0.90      0.91      0.90       252\n",
      "weighted avg       0.91      0.91      0.91       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 334: Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.8791\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.93      0.82      0.87        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.56      0.75      0.64        12\n",
      "     neutral       0.91      0.93      0.92       152\n",
      "    positive       0.76      0.65      0.70        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.74      0.78      0.75       216\n",
      "weighted avg       0.85      0.85      0.85       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.96      0.83        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.73      0.83        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.89      0.88       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.88      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.86      0.86        14\n",
      "     neutral       0.97      1.00      0.98       185\n",
      "    positive       1.00      0.65      0.79        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.83      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Total train time: 89.23475503921509 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0031618166249245405\n",
      "Acquired samples: 54\n",
      "Sampling duration: 11.875292539596558 seconds\n",
      "New train size: 388\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5699, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5004, Accuracy: 0.7939, F1 Micro: 0.8845, F1 Macro: 0.8831\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4453, Accuracy: 0.8259, F1 Micro: 0.9004, F1 Macro: 0.8993\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3519, Accuracy: 0.9211, F1 Micro: 0.9513, F1 Macro: 0.9495\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.27, Accuracy: 0.9338, F1 Micro: 0.9588, F1 Macro: 0.9563\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2068, Accuracy: 0.9472, F1 Micro: 0.967, F1 Macro: 0.9654\n",
      "Epoch 7/10, Train Loss: 0.1557, Accuracy: 0.9464, F1 Micro: 0.9663, F1 Macro: 0.9634\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1251, Accuracy: 0.9561, F1 Micro: 0.9724, F1 Macro: 0.9707\n",
      "Epoch 9/10, Train Loss: 0.1036, Accuracy: 0.9524, F1 Micro: 0.9701, F1 Macro: 0.9678\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0871, Accuracy: 0.9568, F1 Micro: 0.9728, F1 Macro: 0.9711\n",
      "\n",
      "Aspect detection accuracy: 0.9568, F1 Micro: 0.9728, F1 Macro: 0.9711\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.94      0.89      0.92       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.97      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5983, Accuracy: 0.678, F1 Micro: 0.678, F1 Macro: 0.4041\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.377, Accuracy: 0.8712, F1 Micro: 0.8712, F1 Macro: 0.8621\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2137, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9193\n",
      "Epoch 4/10, Train Loss: 0.1491, Accuracy: 0.9015, F1 Micro: 0.9015, F1 Macro: 0.8931\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1439, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9241\n",
      "Epoch 6/10, Train Loss: 0.1307, Accuracy: 0.9205, F1 Micro: 0.9205, F1 Macro: 0.908\n",
      "Epoch 7/10, Train Loss: 0.1227, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.9087\n",
      "Epoch 8/10, Train Loss: 0.1217, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.9048\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1125, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9326\n",
      "Epoch 10/10, Train Loss: 0.0894, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9237\n",
      "\n",
      "Sentiment analysis accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9326\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.98      0.91        84\n",
      "    positive       0.99      0.92      0.95       180\n",
      "\n",
      "    accuracy                           0.94       264\n",
      "   macro avg       0.92      0.95      0.93       264\n",
      "weighted avg       0.95      0.94      0.94       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 388: Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.8921\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.88      0.82        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.92      0.70      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.85      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.83      0.74        12\n",
      "     neutral       0.94      0.89      0.92       152\n",
      "    positive       0.74      0.81      0.77        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.78      0.85      0.81       216\n",
      "weighted avg       0.88      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.95      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.87      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89        14\n",
      "     neutral       0.97      1.00      0.98       185\n",
      "    positive       1.00      0.71      0.83        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.96      0.85      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 101.96312475204468 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.003674876969307661\n",
      "Acquired samples: 48\n",
      "Sampling duration: 10.969206809997559 seconds\n",
      "New train size: 436\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5738, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5003, Accuracy: 0.7946, F1 Micro: 0.8849, F1 Macro: 0.8834\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4353, Accuracy: 0.8609, F1 Micro: 0.9182, F1 Macro: 0.9173\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3324, Accuracy: 0.9323, F1 Micro: 0.9582, F1 Macro: 0.9564\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2532, Accuracy: 0.9509, F1 Micro: 0.9693, F1 Macro: 0.9678\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1766, Accuracy: 0.9561, F1 Micro: 0.9726, F1 Macro: 0.9711\n",
      "Epoch 7/10, Train Loss: 0.1467, Accuracy: 0.9554, F1 Micro: 0.972, F1 Macro: 0.9701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1244, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.094, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9752\n",
      "Epoch 10/10, Train Loss: 0.0807, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9752\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.94      0.92      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5625, Accuracy: 0.7954, F1 Micro: 0.7954, F1 Macro: 0.7292\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3453, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9244\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2539, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9304\n",
      "Epoch 4/10, Train Loss: 0.15, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9253\n",
      "Epoch 5/10, Train Loss: 0.1523, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9207\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1289, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9304\n",
      "Epoch 7/10, Train Loss: 0.1586, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9266\n",
      "Epoch 8/10, Train Loss: 0.1368, Accuracy: 0.888, F1 Micro: 0.888, F1 Macro: 0.8792\n",
      "Epoch 9/10, Train Loss: 0.09, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9225\n",
      "Epoch 10/10, Train Loss: 0.0617, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9176\n",
      "\n",
      "Sentiment analysis accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9304\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.95      0.91        82\n",
      "    positive       0.98      0.93      0.95       177\n",
      "\n",
      "    accuracy                           0.94       259\n",
      "   macro avg       0.92      0.94      0.93       259\n",
      "weighted avg       0.94      0.94      0.94       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 436: Accuracy: 0.9483, F1 Micro: 0.9483, F1 Macro: 0.8915\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.88      0.80        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.92      0.70      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.85      0.85       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.56      0.75      0.64        12\n",
      "     neutral       0.94      0.91      0.93       152\n",
      "    positive       0.77      0.77      0.77        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.76      0.81      0.78       216\n",
      "weighted avg       0.88      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.96      0.86        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.92      0.91       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.79      0.85        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.89      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 99.03061723709106 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.003985429648309946\n",
      "Acquired samples: 43\n",
      "Sampling duration: 9.890741348266602 seconds\n",
      "New train size: 479\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5747, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4994, Accuracy: 0.7946, F1 Micro: 0.8849, F1 Macro: 0.8834\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4344, Accuracy: 0.881, F1 Micro: 0.9296, F1 Macro: 0.9282\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3215, Accuracy: 0.9375, F1 Micro: 0.9611, F1 Macro: 0.9588\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.235, Accuracy: 0.9546, F1 Micro: 0.9716, F1 Macro: 0.9699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1669, Accuracy: 0.9583, F1 Micro: 0.974, F1 Macro: 0.9723\n",
      "Epoch 7/10, Train Loss: 0.1264, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1089, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9745\n",
      "Epoch 9/10, Train Loss: 0.0925, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0778, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9746\n",
      "\n",
      "Aspect detection accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9746\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.94      0.92      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.57, Accuracy: 0.7893, F1 Micro: 0.7893, F1 Macro: 0.7138\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3453, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9269\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2002, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9273\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2222, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9247\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2008, Accuracy: 0.9425, F1 Micro: 0.9425, F1 Macro: 0.9348\n",
      "Epoch 6/10, Train Loss: 0.1458, Accuracy: 0.9195, F1 Micro: 0.9195, F1 Macro: 0.9044\n",
      "Epoch 7/10, Train Loss: 0.1182, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9281\n",
      "Epoch 8/10, Train Loss: 0.1107, Accuracy: 0.9387, F1 Micro: 0.9387, F1 Macro: 0.9306\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1059, Accuracy: 0.9425, F1 Micro: 0.9425, F1 Macro: 0.9352\n",
      "Epoch 10/10, Train Loss: 0.0793, Accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.9077\n",
      "\n",
      "Sentiment analysis accuracy: 0.9425, F1 Micro: 0.9425, F1 Macro: 0.9352\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.94      0.91        84\n",
      "    positive       0.97      0.94      0.96       177\n",
      "\n",
      "    accuracy                           0.94       261\n",
      "   macro avg       0.93      0.94      0.94       261\n",
      "weighted avg       0.94      0.94      0.94       261\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 479: Accuracy: 0.9475, F1 Micro: 0.9475, F1 Macro: 0.8904\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.91      0.88      0.89        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.81      0.79        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.84      0.86       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.83      0.71        12\n",
      "     neutral       0.94      0.92      0.93       152\n",
      "    positive       0.76      0.75      0.76        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.78      0.83      0.80       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.76      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.91      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.89      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 106.17754030227661 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.003367098863236606\n",
      "Acquired samples: 39\n",
      "Sampling duration: 8.989133834838867 seconds\n",
      "New train size: 518\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5499, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4911, Accuracy: 0.8192, F1 Micro: 0.897, F1 Macro: 0.8967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3914, Accuracy: 0.9167, F1 Micro: 0.9493, F1 Macro: 0.9478\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2805, Accuracy: 0.9524, F1 Micro: 0.9703, F1 Macro: 0.9689\n",
      "Epoch 5/10, Train Loss: 0.1958, Accuracy: 0.9516, F1 Micro: 0.9697, F1 Macro: 0.9683\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1558, Accuracy: 0.9561, F1 Micro: 0.9723, F1 Macro: 0.9699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.12, Accuracy: 0.9591, F1 Micro: 0.9741, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0942, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9761\n",
      "Epoch 9/10, Train Loss: 0.0815, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.975\n",
      "Epoch 10/10, Train Loss: 0.0701, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.973\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9761\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5325, Accuracy: 0.8294, F1 Micro: 0.8294, F1 Macro: 0.7782\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2601, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.9018\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2297, Accuracy: 0.9524, F1 Micro: 0.9524, F1 Macro: 0.9467\n",
      "Epoch 4/10, Train Loss: 0.1374, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.9099\n",
      "Epoch 5/10, Train Loss: 0.1379, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9343\n",
      "Epoch 6/10, Train Loss: 0.1062, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9343\n",
      "Epoch 7/10, Train Loss: 0.1042, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8878\n",
      "Epoch 8/10, Train Loss: 0.1086, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9332\n",
      "Epoch 9/10, Train Loss: 0.0947, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9264\n",
      "Epoch 10/10, Train Loss: 0.0629, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.8993\n",
      "\n",
      "Sentiment analysis accuracy: 0.9524, F1 Micro: 0.9524, F1 Macro: 0.9467\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93        83\n",
      "    positive       0.98      0.95      0.96       169\n",
      "\n",
      "    accuracy                           0.95       252\n",
      "   macro avg       0.94      0.95      0.95       252\n",
      "weighted avg       0.95      0.95      0.95       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 518: Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.8623\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.75      0.73        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.88      0.70      0.78        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.85      0.81      0.82       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.41      0.75      0.53        12\n",
      "     neutral       0.94      0.91      0.92       152\n",
      "    positive       0.85      0.77      0.81        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.73      0.81      0.75       216\n",
      "weighted avg       0.89      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.96      0.86        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.94      0.78      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.91      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.77      0.74        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.80      0.71      0.75        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.83      0.82      0.83       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.93      0.90        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 103.60825753211975 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.004608967062085868\n",
      "Acquired samples: 22\n",
      "Sampling duration: 8.15517520904541 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5603, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4787, Accuracy: 0.8088, F1 Micro: 0.8919, F1 Macro: 0.8908\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3917, Accuracy: 0.9152, F1 Micro: 0.9478, F1 Macro: 0.9459\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2852, Accuracy: 0.936, F1 Micro: 0.9599, F1 Macro: 0.958\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2012, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9713\n",
      "Epoch 6/10, Train Loss: 0.1488, Accuracy: 0.9546, F1 Micro: 0.9715, F1 Macro: 0.9695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.122, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9738\n",
      "Epoch 8/10, Train Loss: 0.0976, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9728\n",
      "Epoch 9/10, Train Loss: 0.0814, Accuracy: 0.9554, F1 Micro: 0.9718, F1 Macro: 0.9696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.071, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9765\n",
      "\n",
      "Aspect detection accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.93      0.95      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5011, Accuracy: 0.888, F1 Micro: 0.888, F1 Macro: 0.8702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2445, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.8993\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2037, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9189\n",
      "Epoch 4/10, Train Loss: 0.1625, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9153\n",
      "Epoch 5/10, Train Loss: 0.153, Accuracy: 0.9112, F1 Micro: 0.9112, F1 Macro: 0.9028\n",
      "Epoch 6/10, Train Loss: 0.1439, Accuracy: 0.8996, F1 Micro: 0.8996, F1 Macro: 0.8915\n",
      "Epoch 7/10, Train Loss: 0.137, Accuracy: 0.8996, F1 Micro: 0.8996, F1 Macro: 0.8915\n",
      "Epoch 8/10, Train Loss: 0.0903, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.8989\n",
      "Epoch 9/10, Train Loss: 0.0947, Accuracy: 0.8764, F1 Micro: 0.8764, F1 Macro: 0.8687\n",
      "Epoch 10/10, Train Loss: 0.0915, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.9068\n",
      "\n",
      "Sentiment analysis accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9189\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.96      0.89        83\n",
      "    positive       0.98      0.91      0.94       176\n",
      "\n",
      "    accuracy                           0.93       259\n",
      "   macro avg       0.91      0.94      0.92       259\n",
      "weighted avg       0.93      0.93      0.93       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.8902\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.88      0.70      0.78        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.83      0.85       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.75      0.69        12\n",
      "     neutral       0.93      0.95      0.94       152\n",
      "    positive       0.83      0.75      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.80      0.82      0.81       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 105.98873376846313 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.004187841434031725\n",
      "Acquired samples: 33\n",
      "Sampling duration: 7.722210645675659 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5479, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4701, Accuracy: 0.8311, F1 Micro: 0.9031, F1 Macro: 0.9023\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3713, Accuracy: 0.9308, F1 Micro: 0.9574, F1 Macro: 0.9557\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2557, Accuracy: 0.9539, F1 Micro: 0.9713, F1 Macro: 0.9699\n",
      "Epoch 5/10, Train Loss: 0.1855, Accuracy: 0.9494, F1 Micro: 0.968, F1 Macro: 0.965\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1453, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1156, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0931, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.076, Accuracy: 0.9613, F1 Micro: 0.9755, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0636, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9762\n",
      "\n",
      "Aspect detection accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.93      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5133, Accuracy: 0.8977, F1 Micro: 0.8977, F1 Macro: 0.8776\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2894, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9168\n",
      "Epoch 3/10, Train Loss: 0.2023, Accuracy: 0.9242, F1 Micro: 0.9242, F1 Macro: 0.9162\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1531, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9322\n",
      "Epoch 5/10, Train Loss: 0.1083, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.9004\n",
      "Epoch 6/10, Train Loss: 0.1103, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9241\n",
      "Epoch 7/10, Train Loss: 0.1214, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.9004\n",
      "Epoch 8/10, Train Loss: 0.0869, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9173\n",
      "Epoch 9/10, Train Loss: 0.0927, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9229\n",
      "Epoch 10/10, Train Loss: 0.0842, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9197\n",
      "\n",
      "Sentiment analysis accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9322\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.96      0.91        84\n",
      "    positive       0.98      0.93      0.95       180\n",
      "\n",
      "    accuracy                           0.94       264\n",
      "   macro avg       0.92      0.95      0.93       264\n",
      "weighted avg       0.94      0.94      0.94       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.8994\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.81      0.81      0.81        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.83      0.83      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.93      0.90        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 115.25513577461243 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.0038413401460275056\n",
      "Acquired samples: 30\n",
      "Sampling duration: 7.105361461639404 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5433, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4723, Accuracy: 0.817, F1 Micro: 0.8959, F1 Macro: 0.8949\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.36, Accuracy: 0.9412, F1 Micro: 0.9636, F1 Macro: 0.9619\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2425, Accuracy: 0.9554, F1 Micro: 0.9721, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1817, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9765\n",
      "Epoch 6/10, Train Loss: 0.1317, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9753\n",
      "Epoch 7/10, Train Loss: 0.1034, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0865, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9781\n",
      "Epoch 9/10, Train Loss: 0.0703, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9767\n",
      "Epoch 10/10, Train Loss: 0.0601, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9758\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.91      0.97      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.52, Accuracy: 0.874, F1 Micro: 0.874, F1 Macro: 0.8449\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2286, Accuracy: 0.8898, F1 Micro: 0.8898, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1692, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.9063\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1497, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9144\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1378, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9179\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1114, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9204\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.083, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9327\n",
      "Epoch 8/10, Train Loss: 0.0924, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9308\n",
      "Epoch 9/10, Train Loss: 0.0574, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9147\n",
      "Epoch 10/10, Train Loss: 0.0567, Accuracy: 0.9055, F1 Micro: 0.9055, F1 Macro: 0.8973\n",
      "\n",
      "Sentiment analysis accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9327\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.90      0.91        83\n",
      "    positive       0.95      0.96      0.96       171\n",
      "\n",
      "    accuracy                           0.94       254\n",
      "   macro avg       0.93      0.93      0.93       254\n",
      "weighted avg       0.94      0.94      0.94       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9437, F1 Micro: 0.9437, F1 Macro: 0.8747\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.83      0.73      0.77        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.86      0.84      0.85       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.32      0.83      0.47        12\n",
      "     neutral       0.94      0.90      0.92       152\n",
      "    positive       0.90      0.69      0.78        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.72      0.81      0.72       216\n",
      "weighted avg       0.90      0.85      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.93      0.87        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.92      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 117.94436168670654 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.00330640256870538\n",
      "Acquired samples: 27\n",
      "Sampling duration: 6.624370336532593 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5596, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4745, Accuracy: 0.8192, F1 Micro: 0.897, F1 Macro: 0.8956\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3462, Accuracy: 0.939, F1 Micro: 0.9624, F1 Macro: 0.9607\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2413, Accuracy: 0.9546, F1 Micro: 0.9718, F1 Macro: 0.9703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1749, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9754\n",
      "Epoch 6/10, Train Loss: 0.1273, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1007, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9777\n",
      "Epoch 8/10, Train Loss: 0.0854, Accuracy: 0.965, F1 Micro: 0.9778, F1 Macro: 0.9759\n",
      "Epoch 9/10, Train Loss: 0.0708, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9748\n",
      "Epoch 10/10, Train Loss: 0.0603, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9774\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9777\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5054, Accuracy: 0.8803, F1 Micro: 0.8803, F1 Macro: 0.854\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2502, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9193\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.181, Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9484\n",
      "Epoch 4/10, Train Loss: 0.1414, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9401\n",
      "Epoch 5/10, Train Loss: 0.1146, Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9439\n",
      "Epoch 6/10, Train Loss: 0.1057, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9391\n",
      "Epoch 7/10, Train Loss: 0.096, Accuracy: 0.9112, F1 Micro: 0.9112, F1 Macro: 0.9042\n",
      "Epoch 8/10, Train Loss: 0.0883, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.936\n",
      "Epoch 9/10, Train Loss: 0.0698, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9274\n",
      "Epoch 10/10, Train Loss: 0.045, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9398\n",
      "\n",
      "Sentiment analysis accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9484\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.93        84\n",
      "    positive       0.99      0.94      0.96       175\n",
      "\n",
      "    accuracy                           0.95       259\n",
      "   macro avg       0.94      0.96      0.95       259\n",
      "weighted avg       0.96      0.95      0.95       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9099\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.88      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.59      0.83      0.69        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.83      0.77      0.80        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.79      0.84      0.81       216\n",
      "weighted avg       0.89      0.88      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 115.62466764450073 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.0046526392921805385\n",
      "Acquired samples: 18\n",
      "Sampling duration: 5.79591178894043 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5367, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4643, Accuracy: 0.8542, F1 Micro: 0.9149, F1 Macro: 0.9145\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3323, Accuracy: 0.942, F1 Micro: 0.964, F1 Macro: 0.9625\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2287, Accuracy: 0.9598, F1 Micro: 0.975, F1 Macro: 0.9738\n",
      "Epoch 5/10, Train Loss: 0.1603, Accuracy: 0.9539, F1 Micro: 0.971, F1 Macro: 0.9686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1199, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0974, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0773, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9766\n",
      "Epoch 9/10, Train Loss: 0.0631, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0536, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9792\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9792\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.95      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5411, Accuracy: 0.8943, F1 Micro: 0.8943, F1 Macro: 0.8772\n",
      "Epoch 2/10, Train Loss: 0.2852, Accuracy: 0.8906, F1 Micro: 0.8906, F1 Macro: 0.8829\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1842, Accuracy: 0.8981, F1 Micro: 0.8981, F1 Macro: 0.89\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1607, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9327\n",
      "Epoch 5/10, Train Loss: 0.1384, Accuracy: 0.9321, F1 Micro: 0.9321, F1 Macro: 0.923\n",
      "Epoch 6/10, Train Loss: 0.1162, Accuracy: 0.9358, F1 Micro: 0.9358, F1 Macro: 0.9275\n",
      "Epoch 7/10, Train Loss: 0.0872, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.9175\n",
      "Epoch 8/10, Train Loss: 0.0752, Accuracy: 0.9358, F1 Micro: 0.9358, F1 Macro: 0.9271\n",
      "Epoch 9/10, Train Loss: 0.0703, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.9194\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.043, Accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.9356\n",
      "\n",
      "Sentiment analysis accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.9356\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.93      0.91        85\n",
      "    positive       0.97      0.95      0.96       180\n",
      "\n",
      "    accuracy                           0.94       265\n",
      "   macro avg       0.93      0.94      0.94       265\n",
      "weighted avg       0.94      0.94      0.94       265\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9192\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.69      0.76        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.81      0.79      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.82      0.84       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.75      0.86        12\n",
      "     neutral       0.94      0.95      0.94       152\n",
      "    positive       0.83      0.85      0.84        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.92      0.85      0.88       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.95      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 125.26267075538635 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.003136814711615443\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.468088388442993 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5358, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4465, Accuracy: 0.8527, F1 Micro: 0.9144, F1 Macro: 0.9144\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3254, Accuracy: 0.9397, F1 Micro: 0.9626, F1 Macro: 0.9608\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2088, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1509, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9748\n",
      "Epoch 6/10, Train Loss: 0.1157, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9743\n",
      "Epoch 7/10, Train Loss: 0.0925, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9734\n",
      "Epoch 8/10, Train Loss: 0.0777, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0607, Accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9783\n",
      "Epoch 10/10, Train Loss: 0.0535, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.978\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9783\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4997, Accuracy: 0.902, F1 Micro: 0.902, F1 Macro: 0.8929\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2537, Accuracy: 0.9059, F1 Micro: 0.9059, F1 Macro: 0.8892\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.204, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9154\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.146, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9272\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1462, Accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.9435\n",
      "Epoch 6/10, Train Loss: 0.1292, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9252\n",
      "Epoch 7/10, Train Loss: 0.1048, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9231\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0668, Accuracy: 0.9569, F1 Micro: 0.9569, F1 Macro: 0.9507\n",
      "Epoch 9/10, Train Loss: 0.0659, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9141\n",
      "Epoch 10/10, Train Loss: 0.0676, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9313\n",
      "\n",
      "Sentiment analysis accuracy: 0.9569, F1 Micro: 0.9569, F1 Macro: 0.9507\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.91      0.93        85\n",
      "    positive       0.95      0.98      0.97       170\n",
      "\n",
      "    accuracy                           0.96       255\n",
      "   macro avg       0.96      0.94      0.95       255\n",
      "weighted avg       0.96      0.96      0.96       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.8984\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.97      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.88      0.80        16\n",
      "     neutral       0.97      0.98      0.97       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.87      0.88      0.87       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.75      0.72        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.85      0.75      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.82      0.82      0.82       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      1.00      0.82        23\n",
      "     neutral       0.98      0.97      0.97       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.92      0.89       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 125.03429746627808 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.0031768945045769215\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.990286350250244 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5265, Accuracy: 0.7939, F1 Micro: 0.8845, F1 Macro: 0.8831\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.431, Accuracy: 0.8943, F1 Micro: 0.9364, F1 Macro: 0.9356\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2967, Accuracy: 0.9531, F1 Micro: 0.9708, F1 Macro: 0.9695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1986, Accuracy: 0.9598, F1 Micro: 0.975, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1408, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1167, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0884, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.977\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0749, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9771\n",
      "Epoch 9/10, Train Loss: 0.0604, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9771\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0557, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9778\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.95      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5311, Accuracy: 0.9, F1 Micro: 0.9, F1 Macro: 0.889\n",
      "Epoch 2/10, Train Loss: 0.2516, Accuracy: 0.8846, F1 Micro: 0.8846, F1 Macro: 0.8767\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1785, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9167\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1801, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.928\n",
      "Epoch 5/10, Train Loss: 0.1565, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9159\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1123, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.928\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.133, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.928\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.088, Accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.944\n",
      "Epoch 9/10, Train Loss: 0.072, Accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9402\n",
      "Epoch 10/10, Train Loss: 0.0688, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.932\n",
      "\n",
      "Sentiment analysis accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.944\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.96      0.93        84\n",
      "    positive       0.98      0.94      0.96       176\n",
      "\n",
      "    accuracy                           0.95       260\n",
      "   macro avg       0.94      0.95      0.94       260\n",
      "weighted avg       0.95      0.95      0.95       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9104\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.85      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.84      0.79      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.86      0.83      0.84       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.95      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 135.39484548568726 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.00341047877445817\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.5224809646606445 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5405, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4294, Accuracy: 0.9234, F1 Micro: 0.9532, F1 Macro: 0.9522\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2881, Accuracy: 0.9509, F1 Micro: 0.9694, F1 Macro: 0.9676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.198, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1396, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1068, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "Epoch 7/10, Train Loss: 0.0863, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0696, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.977\n",
      "Epoch 9/10, Train Loss: 0.0597, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0505, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9778\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.95      0.92      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5255, Accuracy: 0.9044, F1 Micro: 0.9044, F1 Macro: 0.8958\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.219, Accuracy: 0.9265, F1 Micro: 0.9265, F1 Macro: 0.916\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1512, Accuracy: 0.9301, F1 Micro: 0.9301, F1 Macro: 0.9226\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1276, Accuracy: 0.9338, F1 Micro: 0.9338, F1 Macro: 0.9265\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.113, Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9449\n",
      "Epoch 6/10, Train Loss: 0.0871, Accuracy: 0.9485, F1 Micro: 0.9485, F1 Macro: 0.9419\n",
      "Epoch 7/10, Train Loss: 0.0671, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9343\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0567, Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9459\n",
      "Epoch 9/10, Train Loss: 0.0535, Accuracy: 0.9265, F1 Micro: 0.9265, F1 Macro: 0.9187\n",
      "Epoch 10/10, Train Loss: 0.076, Accuracy: 0.9265, F1 Micro: 0.9265, F1 Macro: 0.9187\n",
      "\n",
      "Sentiment analysis accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9459\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.93        87\n",
      "    positive       0.98      0.95      0.96       185\n",
      "\n",
      "    accuracy                           0.95       272\n",
      "   macro avg       0.94      0.95      0.95       272\n",
      "weighted avg       0.95      0.95      0.95       272\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9121\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.86      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.95      0.92      0.94       152\n",
      "    positive       0.76      0.81      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.81      0.85      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 133.38860249519348 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.0031994540244340897\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.9123001098632812 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5308, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4261, Accuracy: 0.9263, F1 Micro: 0.9544, F1 Macro: 0.9524\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2807, Accuracy: 0.9531, F1 Micro: 0.9708, F1 Macro: 0.9694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1897, Accuracy: 0.9621, F1 Micro: 0.9764, F1 Macro: 0.9753\n",
      "Epoch 5/10, Train Loss: 0.1383, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1001, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9763\n",
      "Epoch 7/10, Train Loss: 0.0875, Accuracy: 0.9613, F1 Micro: 0.9755, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.069, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0572, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0509, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9779\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9779\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.93      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4749, Accuracy: 0.9071, F1 Micro: 0.9071, F1 Macro: 0.8985\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2211, Accuracy: 0.9071, F1 Micro: 0.9071, F1 Macro: 0.8876\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1807, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.932\n",
      "Epoch 4/10, Train Loss: 0.147, Accuracy: 0.9257, F1 Micro: 0.9257, F1 Macro: 0.9178\n",
      "Epoch 5/10, Train Loss: 0.1343, Accuracy: 0.9368, F1 Micro: 0.9368, F1 Macro: 0.9271\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0945, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9328\n",
      "Epoch 7/10, Train Loss: 0.0893, Accuracy: 0.9257, F1 Micro: 0.9257, F1 Macro: 0.9178\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0602, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9332\n",
      "Epoch 9/10, Train Loss: 0.0501, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9244\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0561, Accuracy: 0.948, F1 Micro: 0.948, F1 Macro: 0.9416\n",
      "\n",
      "Sentiment analysis accuracy: 0.948, F1 Micro: 0.948, F1 Macro: 0.9416\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.97      0.92        86\n",
      "    positive       0.98      0.94      0.96       183\n",
      "\n",
      "    accuracy                           0.95       269\n",
      "   macro avg       0.93      0.95      0.94       269\n",
      "weighted avg       0.95      0.95      0.95       269\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9259\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.78      0.81      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.87      0.86      0.86       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 135.46603322029114 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.0046424539759755135\n",
      "Acquired samples: 8\n",
      "Sampling duration: 3.410907030105591 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5318, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.42, Accuracy: 0.9196, F1 Micro: 0.9511, F1 Macro: 0.9498\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2727, Accuracy: 0.9494, F1 Micro: 0.9686, F1 Macro: 0.967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1882, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1394, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.977\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1055, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9784\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0869, Accuracy: 0.9717, F1 Micro: 0.9822, F1 Macro: 0.9813\n",
      "Epoch 8/10, Train Loss: 0.0681, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9742\n",
      "Epoch 9/10, Train Loss: 0.0553, Accuracy: 0.9658, F1 Micro: 0.9783, F1 Macro: 0.9766\n",
      "Epoch 10/10, Train Loss: 0.0506, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9781\n",
      "\n",
      "Aspect detection accuracy: 0.9717, F1 Micro: 0.9822, F1 Macro: 0.9813\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.94      0.96      0.95       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5306, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9262\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2324, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9322\n",
      "Epoch 3/10, Train Loss: 0.1905, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9262\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1359, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9353\n",
      "Epoch 5/10, Train Loss: 0.133, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9229\n",
      "Epoch 6/10, Train Loss: 0.1112, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9157\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0854, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9401\n",
      "Epoch 8/10, Train Loss: 0.0859, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.936\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0605, Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9481\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0589, Accuracy: 0.9575, F1 Micro: 0.9575, F1 Macro: 0.9523\n",
      "\n",
      "Sentiment analysis accuracy: 0.9575, F1 Micro: 0.9575, F1 Macro: 0.9523\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.95      0.94        85\n",
      "    positive       0.98      0.96      0.97       174\n",
      "\n",
      "    accuracy                           0.96       259\n",
      "   macro avg       0.95      0.96      0.95       259\n",
      "weighted avg       0.96      0.96      0.96       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9172\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.97      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.86      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.83      0.74        12\n",
      "     neutral       0.94      0.93      0.93       152\n",
      "    positive       0.86      0.85      0.85        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.82      0.87      0.84       216\n",
      "weighted avg       0.91      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 134.0585343837738 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.002753984648734331\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.2307705879211426 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5311, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4151, Accuracy: 0.9249, F1 Micro: 0.9542, F1 Macro: 0.953\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2706, Accuracy: 0.9524, F1 Micro: 0.9703, F1 Macro: 0.9685\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1741, Accuracy: 0.9554, F1 Micro: 0.9719, F1 Macro: 0.97\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1264, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9782\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1016, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9787\n",
      "Epoch 7/10, Train Loss: 0.0798, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9757\n",
      "Epoch 8/10, Train Loss: 0.0657, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9747\n",
      "Epoch 9/10, Train Loss: 0.0538, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9781\n",
      "Epoch 10/10, Train Loss: 0.0482, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9779\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9787\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.93      0.94      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5174, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9272\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2205, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9358\n",
      "Epoch 3/10, Train Loss: 0.1504, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9239\n",
      "Epoch 4/10, Train Loss: 0.1316, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9268\n",
      "Epoch 5/10, Train Loss: 0.1304, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9084\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1074, Accuracy: 0.9577, F1 Micro: 0.9577, F1 Macro: 0.9524\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0751, Accuracy: 0.9577, F1 Micro: 0.9577, F1 Macro: 0.9524\n",
      "Epoch 8/10, Train Loss: 0.064, Accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9399\n",
      "Epoch 9/10, Train Loss: 0.0658, Accuracy: 0.9538, F1 Micro: 0.9538, F1 Macro: 0.9476\n",
      "Epoch 10/10, Train Loss: 0.0452, Accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.9427\n",
      "\n",
      "Sentiment analysis accuracy: 0.9577, F1 Micro: 0.9577, F1 Macro: 0.9524\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        84\n",
      "    positive       0.98      0.95      0.97       176\n",
      "\n",
      "    accuracy                           0.96       260\n",
      "   macro avg       0.95      0.96      0.95       260\n",
      "weighted avg       0.96      0.96      0.96       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9043\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.96      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.75      0.73        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.85      0.83      0.84       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.75      0.72        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.81      0.81      0.81        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.81      0.83      0.82       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.97      0.88      0.92        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.95      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 131.9149043560028 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0030179068446159365\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.7545480728149414 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5316, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4155, Accuracy: 0.9211, F1 Micro: 0.9519, F1 Macro: 0.9509\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2665, Accuracy: 0.9509, F1 Micro: 0.9696, F1 Macro: 0.968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1776, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9755\n",
      "Epoch 5/10, Train Loss: 0.1233, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9747\n",
      "Epoch 6/10, Train Loss: 0.0951, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0802, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "Epoch 8/10, Train Loss: 0.0656, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0557, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9779\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0464, Accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9794\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9794\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.93      0.95      0.94       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.99      1.00      1.00       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4716, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9104\n",
      "Epoch 2/10, Train Loss: 0.2554, Accuracy: 0.8955, F1 Micro: 0.8955, F1 Macro: 0.8869\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2155, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9367\n",
      "Epoch 4/10, Train Loss: 0.1457, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9319\n",
      "Epoch 5/10, Train Loss: 0.1015, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9255\n",
      "Epoch 6/10, Train Loss: 0.1382, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9334\n",
      "Epoch 7/10, Train Loss: 0.0904, Accuracy: 0.9179, F1 Micro: 0.9179, F1 Macro: 0.9027\n",
      "Epoch 8/10, Train Loss: 0.0691, Accuracy: 0.9179, F1 Micro: 0.9179, F1 Macro: 0.9085\n",
      "Epoch 9/10, Train Loss: 0.0486, Accuracy: 0.9254, F1 Micro: 0.9254, F1 Macro: 0.9159\n",
      "Epoch 10/10, Train Loss: 0.0495, Accuracy: 0.9104, F1 Micro: 0.9104, F1 Macro: 0.9017\n",
      "\n",
      "Sentiment analysis accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9367\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.95      0.92        85\n",
      "    positive       0.98      0.94      0.96       183\n",
      "\n",
      "    accuracy                           0.94       268\n",
      "   macro avg       0.93      0.95      0.94       268\n",
      "weighted avg       0.95      0.94      0.94       268\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9021\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.88      0.82        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.87      0.87      0.87       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.75      0.69        12\n",
      "     neutral       0.93      0.95      0.94       152\n",
      "    positive       0.85      0.77      0.81        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.81      0.82      0.81       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      1.00      0.85        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.94      0.78      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.92      0.89       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      1.00      1.00       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.92      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 134.57923650741577 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0027790669817477466\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.1421377658843994 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.532, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4177, Accuracy: 0.9196, F1 Micro: 0.9512, F1 Macro: 0.9498\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2664, Accuracy: 0.9501, F1 Micro: 0.969, F1 Macro: 0.9675\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.178, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1275, Accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9784\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1025, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9789\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0815, Accuracy: 0.9717, F1 Micro: 0.9822, F1 Macro: 0.9813\n",
      "Epoch 8/10, Train Loss: 0.0631, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9772\n",
      "Epoch 9/10, Train Loss: 0.0543, Accuracy: 0.9702, F1 Micro: 0.9812, F1 Macro: 0.9799\n",
      "Epoch 10/10, Train Loss: 0.0471, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9791\n",
      "\n",
      "Aspect detection accuracy: 0.9717, F1 Micro: 0.9822, F1 Macro: 0.9813\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.93      0.97      0.95       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4841, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.9077\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2501, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9194\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1582, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9234\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1446, Accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9388\n",
      "Epoch 5/10, Train Loss: 0.1289, Accuracy: 0.9416, F1 Micro: 0.9416, F1 Macro: 0.935\n",
      "Epoch 6/10, Train Loss: 0.1171, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9251\n",
      "Epoch 7/10, Train Loss: 0.0892, Accuracy: 0.9183, F1 Micro: 0.9183, F1 Macro: 0.9113\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0785, Accuracy: 0.9494, F1 Micro: 0.9494, F1 Macro: 0.9434\n",
      "Epoch 9/10, Train Loss: 0.0747, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9246\n",
      "Epoch 10/10, Train Loss: 0.0841, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9186\n",
      "\n",
      "Sentiment analysis accuracy: 0.9494, F1 Micro: 0.9494, F1 Macro: 0.9434\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.94      0.92        85\n",
      "    positive       0.97      0.95      0.96       172\n",
      "\n",
      "    accuracy                           0.95       257\n",
      "   macro avg       0.94      0.95      0.94       257\n",
      "weighted avg       0.95      0.95      0.95       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9061\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.88      0.78        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.86      0.86      0.85       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.48      0.83      0.61        12\n",
      "     neutral       0.95      0.93      0.94       152\n",
      "    positive       0.89      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.77      0.85      0.79       216\n",
      "weighted avg       0.91      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.96      0.85        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.91      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 138.76926231384277 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0029140385100618004\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.5989561080932617 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.53, Accuracy: 0.8006, F1 Micro: 0.8879, F1 Macro: 0.8865\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.396, Accuracy: 0.9375, F1 Micro: 0.9614, F1 Macro: 0.96\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2483, Accuracy: 0.9524, F1 Micro: 0.9704, F1 Macro: 0.9691\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.168, Accuracy: 0.9643, F1 Micro: 0.9777, F1 Macro: 0.9768\n",
      "Epoch 5/10, Train Loss: 0.1284, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.094, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.978\n",
      "Epoch 7/10, Train Loss: 0.0774, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9745\n",
      "Epoch 8/10, Train Loss: 0.064, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0525, Accuracy: 0.9732, F1 Micro: 0.9831, F1 Macro: 0.9822\n",
      "Epoch 10/10, Train Loss: 0.0457, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9783\n",
      "\n",
      "Aspect detection accuracy: 0.9732, F1 Micro: 0.9831, F1 Macro: 0.9822\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.93      0.97      0.95       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.98      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.98      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4724, Accuracy: 0.9278, F1 Micro: 0.9278, F1 Macro: 0.9186\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2238, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9288\n",
      "Epoch 3/10, Train Loss: 0.1677, Accuracy: 0.9278, F1 Micro: 0.9278, F1 Macro: 0.9208\n",
      "Epoch 4/10, Train Loss: 0.1451, Accuracy: 0.9011, F1 Micro: 0.9011, F1 Macro: 0.8938\n",
      "Epoch 5/10, Train Loss: 0.1292, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.8998\n",
      "Epoch 6/10, Train Loss: 0.096, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9168\n",
      "Epoch 7/10, Train Loss: 0.0757, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9164\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0596, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9313\n",
      "Epoch 9/10, Train Loss: 0.052, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9164\n",
      "Epoch 10/10, Train Loss: 0.0569, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.916\n",
      "\n",
      "Sentiment analysis accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9313\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.92      0.91        86\n",
      "    positive       0.96      0.95      0.95       177\n",
      "\n",
      "    accuracy                           0.94       263\n",
      "   macro avg       0.93      0.93      0.93       263\n",
      "weighted avg       0.94      0.94      0.94       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9052\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.81      0.79        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.87      0.86      0.86       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.48      0.83      0.61        12\n",
      "     neutral       0.94      0.93      0.93       152\n",
      "    positive       0.89      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.77      0.84      0.79       216\n",
      "weighted avg       0.90      0.88      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 138.6645703315735 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0017317894846200943\n",
      "Acquired samples: 8\n",
      "Sampling duration: 1.0435333251953125 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5303, Accuracy: 0.8058, F1 Micro: 0.8905, F1 Macro: 0.8893\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3796, Accuracy: 0.9234, F1 Micro: 0.9527, F1 Macro: 0.9507\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2411, Accuracy: 0.9576, F1 Micro: 0.9737, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1627, Accuracy: 0.9665, F1 Micro: 0.9791, F1 Macro: 0.9783\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1203, Accuracy: 0.9695, F1 Micro: 0.9809, F1 Macro: 0.98\n",
      "Epoch 6/10, Train Loss: 0.0981, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.979\n",
      "Epoch 7/10, Train Loss: 0.0738, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9775\n",
      "Epoch 8/10, Train Loss: 0.0626, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9759\n",
      "Epoch 9/10, Train Loss: 0.0529, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9772\n",
      "Epoch 10/10, Train Loss: 0.0454, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9784\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9809, F1 Macro: 0.98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.93      0.97      0.95       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4927, Accuracy: 0.8906, F1 Micro: 0.8906, F1 Macro: 0.8843\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.244, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9397\n",
      "Epoch 3/10, Train Loss: 0.1756, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9352\n",
      "Epoch 4/10, Train Loss: 0.1364, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9352\n",
      "Epoch 5/10, Train Loss: 0.123, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9274\n",
      "Epoch 6/10, Train Loss: 0.0921, Accuracy: 0.9258, F1 Micro: 0.9258, F1 Macro: 0.9196\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.083, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9397\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0456, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9397\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.057, Accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9439\n",
      "Epoch 10/10, Train Loss: 0.0848, Accuracy: 0.9219, F1 Micro: 0.9219, F1 Macro: 0.9152\n",
      "\n",
      "Sentiment analysis accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9439\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.93        86\n",
      "    positive       0.98      0.95      0.96       170\n",
      "\n",
      "    accuracy                           0.95       256\n",
      "   macro avg       0.94      0.95      0.94       256\n",
      "weighted avg       0.95      0.95      0.95       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.8857\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.88      0.72        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.92      0.67      0.77        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.83      0.84      0.82       216\n",
      "weighted avg       0.93      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.83      0.62        12\n",
      "     neutral       0.95      0.93      0.94       152\n",
      "    positive       0.87      0.79      0.83        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.77      0.85      0.80       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.92      0.83        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.87      0.89      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 140.76341223716736 s\n",
      "Total runtime: 3037.1960813999176 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[0], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba4c69e",
   "metadata": {
    "papermill": {
     "duration": 0.143091,
     "end_time": "2025-03-23T14:15:24.448492",
     "exception": false,
     "start_time": "2025-03-23T14:15:24.305401",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12dab4e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T14:15:24.736401Z",
     "iopub.status.busy": "2025-03-23T14:15:24.736103Z",
     "iopub.status.idle": "2025-03-23T15:06:22.778262Z",
     "shell.execute_reply": "2025-03-23T15:06:22.777277Z"
    },
    "papermill": {
     "duration": 3058.187116,
     "end_time": "2025-03-23T15:06:22.779848",
     "exception": false,
     "start_time": "2025-03-23T14:15:24.592732",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 2\n",
      "Random seed: 81\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.647, Accuracy: 0.7054, F1 Micro: 0.8127, F1 Macro: 0.7262\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5731, Accuracy: 0.7374, F1 Micro: 0.8408, F1 Macro: 0.7949\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5493, Accuracy: 0.7917, F1 Micro: 0.8824, F1 Macro: 0.8802\n",
      "Epoch 4/10, Train Loss: 0.5049, Accuracy: 0.7894, F1 Micro: 0.8822, F1 Macro: 0.8807\n",
      "Epoch 5/10, Train Loss: 0.4781, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 6/10, Train Loss: 0.4364, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4061, Accuracy: 0.7902, F1 Micro: 0.8826, F1 Macro: 0.8811\n",
      "Epoch 8/10, Train Loss: 0.4421, Accuracy: 0.7902, F1 Micro: 0.8825, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.4208, Accuracy: 0.7939, F1 Micro: 0.8842, F1 Macro: 0.8826\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3864, Accuracy: 0.8036, F1 Micro: 0.8886, F1 Macro: 0.8869\n",
      "\n",
      "Aspect detection accuracy: 0.8036, F1 Micro: 0.8886, F1 Macro: 0.8869\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.79      1.00      0.88       175\n",
      "      others       0.78      0.95      0.86       158\n",
      "        part       0.71      1.00      0.83       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.80      0.99      0.89      1061\n",
      "   macro avg       0.80      0.99      0.89      1061\n",
      "weighted avg       0.81      0.99      0.89      1061\n",
      " samples avg       0.81      0.99      0.89      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6351, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5577, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5004, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4905, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4593, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4341, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4188, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2323, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2613, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2353, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "\n",
      "Sentiment analysis accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         3\n",
      "    positive       0.91      1.00      0.95        31\n",
      "\n",
      "    accuracy                           0.91        34\n",
      "   macro avg       0.46      0.50      0.48        34\n",
      "weighted avg       0.83      0.91      0.87        34\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.8009, F1 Micro: 0.8009, F1 Macro: 0.3313\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.78      1.00      0.88       167\n",
      "    positive       1.00      0.06      0.11        33\n",
      "\n",
      "    accuracy                           0.78       216\n",
      "   macro avg       0.59      0.35      0.33       216\n",
      "weighted avg       0.76      0.78      0.70       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.78      0.95      0.85       152\n",
      "    positive       0.65      0.38      0.48        52\n",
      "\n",
      "    accuracy                           0.76       216\n",
      "   macro avg       0.47      0.44      0.45       216\n",
      "weighted avg       0.70      0.76      0.72       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        23\n",
      "     neutral       0.71      1.00      0.83       152\n",
      "    positive       1.00      0.02      0.05        41\n",
      "\n",
      "    accuracy                           0.71       216\n",
      "   macro avg       0.57      0.34      0.29       216\n",
      "weighted avg       0.69      0.71      0.59       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 56.78677415847778 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.004604773595929146\n",
      "Acquired samples: 82\n",
      "Sampling duration: 13.55602216720581 seconds\n",
      "New train size: 136\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.617, Accuracy: 0.7939, F1 Micro: 0.8834, F1 Macro: 0.8812\n",
      "Epoch 2/10, Train Loss: 0.5421, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4897, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4548, Accuracy: 0.8013, F1 Micro: 0.8875, F1 Macro: 0.8858\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4595, Accuracy: 0.814, F1 Micro: 0.8933, F1 Macro: 0.8916\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4321, Accuracy: 0.8385, F1 Micro: 0.9057, F1 Macro: 0.9043\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3553, Accuracy: 0.8638, F1 Micro: 0.9177, F1 Macro: 0.9152\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3278, Accuracy: 0.8795, F1 Micro: 0.9268, F1 Macro: 0.9246\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2775, Accuracy: 0.9025, F1 Micro: 0.9398, F1 Macro: 0.9374\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2455, Accuracy: 0.9092, F1 Micro: 0.9438, F1 Macro: 0.9414\n",
      "\n",
      "Aspect detection accuracy: 0.9092, F1 Micro: 0.9438, F1 Macro: 0.9414\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.97      1.00      0.99       187\n",
      "     machine       0.94      0.95      0.94       175\n",
      "      others       0.87      0.91      0.89       158\n",
      "        part       0.87      0.94      0.90       158\n",
      "       price       0.94      0.99      0.96       192\n",
      "     service       0.93      0.99      0.96       191\n",
      "\n",
      "   micro avg       0.92      0.97      0.94      1061\n",
      "   macro avg       0.92      0.96      0.94      1061\n",
      "weighted avg       0.92      0.97      0.94      1061\n",
      " samples avg       0.93      0.97      0.94      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5424, Accuracy: 0.7232, F1 Micro: 0.7232, F1 Macro: 0.4197\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.45, Accuracy: 0.7232, F1 Micro: 0.7232, F1 Macro: 0.4197\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4465, Accuracy: 0.7232, F1 Micro: 0.7232, F1 Macro: 0.4197\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3448, Accuracy: 0.808, F1 Micro: 0.808, F1 Macro: 0.736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2488, Accuracy: 0.875, F1 Micro: 0.875, F1 Macro: 0.8496\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1347, Accuracy: 0.8884, F1 Micro: 0.8884, F1 Macro: 0.8686\n",
      "Epoch 7/10, Train Loss: 0.1182, Accuracy: 0.8839, F1 Micro: 0.8839, F1 Macro: 0.8578\n",
      "Epoch 8/10, Train Loss: 0.1289, Accuracy: 0.875, F1 Micro: 0.875, F1 Macro: 0.8496\n",
      "Epoch 9/10, Train Loss: 0.0495, Accuracy: 0.8661, F1 Micro: 0.8661, F1 Macro: 0.8327\n",
      "Epoch 10/10, Train Loss: 0.0643, Accuracy: 0.8705, F1 Micro: 0.8705, F1 Macro: 0.8375\n",
      "\n",
      "Sentiment analysis accuracy: 0.8884, F1 Micro: 0.8884, F1 Macro: 0.8686\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.90      0.82        62\n",
      "    positive       0.96      0.88      0.92       162\n",
      "\n",
      "    accuracy                           0.89       224\n",
      "   macro avg       0.85      0.89      0.87       224\n",
      "weighted avg       0.90      0.89      0.89       224\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 136: Accuracy: 0.892, F1 Micro: 0.892, F1 Macro: 0.7504\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       0.91      0.88      0.89        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.96      0.87      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.62      0.74        16\n",
      "     neutral       0.93      0.95      0.94       167\n",
      "    positive       0.69      0.76      0.72        33\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.85      0.78      0.80       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.42      0.67      0.52        12\n",
      "     neutral       0.87      0.91      0.89       152\n",
      "    positive       0.76      0.56      0.64        52\n",
      "\n",
      "    accuracy                           0.81       216\n",
      "   macro avg       0.69      0.71      0.68       216\n",
      "weighted avg       0.82      0.81      0.81       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.48      0.63        23\n",
      "     neutral       0.87      0.94      0.90       152\n",
      "    positive       0.69      0.66      0.68        41\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.83      0.69      0.74       216\n",
      "weighted avg       0.84      0.84      0.83       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.23      0.38        13\n",
      "     neutral       0.94      0.99      0.96       186\n",
      "    positive       0.59      0.59      0.59        17\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.84      0.60      0.64       216\n",
      "weighted avg       0.91      0.91      0.90       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.50      0.64        14\n",
      "     neutral       0.93      0.99      0.96       185\n",
      "    positive       0.80      0.47      0.59        17\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.87      0.66      0.73       216\n",
      "weighted avg       0.92      0.92      0.91       216\n",
      "\n",
      "Total train time: 72.0643241405487 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.009672479890286923\n",
      "Acquired samples: 73\n",
      "Sampling duration: 14.574955224990845 seconds\n",
      "New train size: 209\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5978, Accuracy: 0.7924, F1 Micro: 0.8837, F1 Macro: 0.8822\n",
      "Epoch 2/10, Train Loss: 0.506, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4632, Accuracy: 0.7954, F1 Micro: 0.8852, F1 Macro: 0.8837\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4416, Accuracy: 0.8244, F1 Micro: 0.8985, F1 Macro: 0.897\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3754, Accuracy: 0.843, F1 Micro: 0.9074, F1 Macro: 0.9061\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3292, Accuracy: 0.8847, F1 Micro: 0.9291, F1 Macro: 0.9267\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2853, Accuracy: 0.8936, F1 Micro: 0.9343, F1 Macro: 0.9315\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2328, Accuracy: 0.9174, F1 Micro: 0.9485, F1 Macro: 0.9456\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1883, Accuracy: 0.9196, F1 Micro: 0.9498, F1 Macro: 0.9464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1692, Accuracy: 0.9315, F1 Micro: 0.9573, F1 Macro: 0.9552\n",
      "\n",
      "Aspect detection accuracy: 0.9315, F1 Micro: 0.9573, F1 Macro: 0.9552\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.95      0.95       175\n",
      "      others       0.89      0.94      0.91       158\n",
      "        part       0.91      0.94      0.93       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.95      1.00      0.97       191\n",
      "\n",
      "   micro avg       0.94      0.97      0.96      1061\n",
      "   macro avg       0.94      0.97      0.96      1061\n",
      "weighted avg       0.94      0.97      0.96      1061\n",
      " samples avg       0.94      0.97      0.95      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6558, Accuracy: 0.6983, F1 Micro: 0.6983, F1 Macro: 0.4112\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5011, Accuracy: 0.781, F1 Micro: 0.781, F1 Macro: 0.743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3911, Accuracy: 0.8843, F1 Micro: 0.8843, F1 Macro: 0.8676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2807, Accuracy: 0.9174, F1 Micro: 0.9174, F1 Macro: 0.9054\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1587, Accuracy: 0.9215, F1 Micro: 0.9215, F1 Macro: 0.9086\n",
      "Epoch 6/10, Train Loss: 0.1511, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8904\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1395, Accuracy: 0.9215, F1 Micro: 0.9215, F1 Macro: 0.9098\n",
      "Epoch 8/10, Train Loss: 0.1167, Accuracy: 0.9132, F1 Micro: 0.9132, F1 Macro: 0.8966\n",
      "Epoch 9/10, Train Loss: 0.1224, Accuracy: 0.9174, F1 Micro: 0.9174, F1 Macro: 0.9054\n",
      "Epoch 10/10, Train Loss: 0.0705, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8937\n",
      "\n",
      "Sentiment analysis accuracy: 0.9215, F1 Micro: 0.9215, F1 Macro: 0.9098\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.93      0.88        73\n",
      "    positive       0.97      0.92      0.94       169\n",
      "\n",
      "    accuracy                           0.92       242\n",
      "   macro avg       0.90      0.92      0.91       242\n",
      "weighted avg       0.93      0.92      0.92       242\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 209: Accuracy: 0.9205, F1 Micro: 0.9205, F1 Macro: 0.836\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.94      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.95      0.95       167\n",
      "    positive       0.71      0.76      0.74        33\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.84      0.84      0.84       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.75      0.67        12\n",
      "     neutral       0.89      0.94      0.92       152\n",
      "    positive       0.85      0.67      0.75        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.78      0.79      0.78       216\n",
      "weighted avg       0.87      0.87      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.70      0.73        23\n",
      "     neutral       0.91      0.94      0.92       152\n",
      "    positive       0.81      0.73      0.77        41\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.83      0.79      0.81       216\n",
      "weighted avg       0.87      0.88      0.87       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.54      0.70        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.68      0.76      0.72        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.76      0.80       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.64      0.78        14\n",
      "     neutral       0.94      1.00      0.97       185\n",
      "    positive       0.91      0.59      0.71        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.95      0.74      0.82       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Total train time: 83.5118899345398 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.008265296928584576\n",
      "Acquired samples: 66\n",
      "Sampling duration: 13.743176937103271 seconds\n",
      "New train size: 275\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5831, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5164, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4649, Accuracy: 0.8185, F1 Micro: 0.8959, F1 Macro: 0.8943\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3976, Accuracy: 0.881, F1 Micro: 0.9288, F1 Macro: 0.9279\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3395, Accuracy: 0.9077, F1 Micro: 0.9429, F1 Macro: 0.9406\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2686, Accuracy: 0.9226, F1 Micro: 0.9519, F1 Macro: 0.949\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2239, Accuracy: 0.9308, F1 Micro: 0.9567, F1 Macro: 0.9541\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1813, Accuracy: 0.9449, F1 Micro: 0.9656, F1 Macro: 0.9636\n",
      "Epoch 9/10, Train Loss: 0.1532, Accuracy: 0.9442, F1 Micro: 0.965, F1 Macro: 0.9628\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1228, Accuracy: 0.9457, F1 Micro: 0.9659, F1 Macro: 0.9637\n",
      "\n",
      "Aspect detection accuracy: 0.9457, F1 Micro: 0.9659, F1 Macro: 0.9637\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.93      0.97      0.95       175\n",
      "      others       0.91      0.89      0.90       158\n",
      "        part       0.94      0.99      0.97       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.95      0.97      0.96      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.97      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5078, Accuracy: 0.6917, F1 Micro: 0.6917, F1 Macro: 0.4089\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3734, Accuracy: 0.8142, F1 Micro: 0.8142, F1 Macro: 0.7798\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.252, Accuracy: 0.8933, F1 Micro: 0.8933, F1 Macro: 0.8808\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1582, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8978\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1439, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1137, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8952\n",
      "Epoch 7/10, Train Loss: 0.1161, Accuracy: 0.8893, F1 Micro: 0.8893, F1 Macro: 0.8767\n",
      "Epoch 8/10, Train Loss: 0.0986, Accuracy: 0.8972, F1 Micro: 0.8972, F1 Macro: 0.882\n",
      "Epoch 9/10, Train Loss: 0.1117, Accuracy: 0.8854, F1 Micro: 0.8854, F1 Macro: 0.874\n",
      "Epoch 10/10, Train Loss: 0.0807, Accuracy: 0.8814, F1 Micro: 0.8814, F1 Macro: 0.87\n",
      "\n",
      "Sentiment analysis accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8952\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.88      0.86        78\n",
      "    positive       0.95      0.92      0.93       175\n",
      "\n",
      "    accuracy                           0.91       253\n",
      "   macro avg       0.89      0.90      0.90       253\n",
      "weighted avg       0.91      0.91      0.91       253\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 275: Accuracy: 0.9298, F1 Micro: 0.9298, F1 Macro: 0.8615\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.81      0.79        16\n",
      "     neutral       0.93      0.97      0.95       167\n",
      "    positive       0.84      0.64      0.72        33\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.85      0.81      0.82       216\n",
      "weighted avg       0.90      0.91      0.90       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.40      0.83      0.54        12\n",
      "     neutral       0.91      0.89      0.90       152\n",
      "    positive       0.74      0.62      0.67        52\n",
      "\n",
      "    accuracy                           0.82       216\n",
      "   macro avg       0.69      0.78      0.70       216\n",
      "weighted avg       0.84      0.82      0.83       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.83      0.79        23\n",
      "     neutral       0.94      0.99      0.96       152\n",
      "    positive       0.97      0.71      0.82        41\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.89      0.84      0.86       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.69      0.78        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.90      0.82      0.85       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.99      0.91      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 88.67413377761841 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.010147236287593842\n",
      "Acquired samples: 59\n",
      "Sampling duration: 12.962971925735474 seconds\n",
      "New train size: 334\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5872, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4988, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4383, Accuracy: 0.8475, F1 Micro: 0.9111, F1 Macro: 0.9101\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3595, Accuracy: 0.904, F1 Micro: 0.9414, F1 Macro: 0.9395\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2924, Accuracy: 0.9301, F1 Micro: 0.9564, F1 Macro: 0.9543\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2269, Accuracy: 0.939, F1 Micro: 0.9618, F1 Macro: 0.9599\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1805, Accuracy: 0.9494, F1 Micro: 0.9683, F1 Macro: 0.9665\n",
      "Epoch 8/10, Train Loss: 0.1478, Accuracy: 0.9308, F1 Micro: 0.9562, F1 Macro: 0.9511\n",
      "Epoch 9/10, Train Loss: 0.1192, Accuracy: 0.9464, F1 Micro: 0.9665, F1 Macro: 0.9645\n",
      "Epoch 10/10, Train Loss: 0.1005, Accuracy: 0.9494, F1 Micro: 0.9682, F1 Macro: 0.9662\n",
      "\n",
      "Aspect detection accuracy: 0.9494, F1 Micro: 0.9683, F1 Macro: 0.9665\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      0.98      0.96       175\n",
      "      others       0.93      0.90      0.91       158\n",
      "        part       0.95      0.99      0.97       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.97      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5896, Accuracy: 0.7817, F1 Micro: 0.7817, F1 Macro: 0.7191\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3368, Accuracy: 0.869, F1 Micro: 0.869, F1 Macro: 0.8584\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.225, Accuracy: 0.9127, F1 Micro: 0.9127, F1 Macro: 0.8964\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1386, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9306\n",
      "Epoch 5/10, Train Loss: 0.1426, Accuracy: 0.9206, F1 Micro: 0.9206, F1 Macro: 0.9107\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1363, Accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9403\n",
      "Epoch 7/10, Train Loss: 0.1018, Accuracy: 0.9206, F1 Micro: 0.9206, F1 Macro: 0.9117\n",
      "Epoch 8/10, Train Loss: 0.0897, Accuracy: 0.9365, F1 Micro: 0.9365, F1 Macro: 0.9281\n",
      "Epoch 9/10, Train Loss: 0.0897, Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9359\n",
      "Epoch 10/10, Train Loss: 0.078, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9324\n",
      "\n",
      "Sentiment analysis accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9403\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        78\n",
      "    positive       0.97      0.95      0.96       174\n",
      "\n",
      "    accuracy                           0.95       252\n",
      "   macro avg       0.94      0.94      0.94       252\n",
      "weighted avg       0.95      0.95      0.95       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 334: Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.8763\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.75      0.77        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.87      0.82      0.84       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.83      0.62        12\n",
      "     neutral       0.94      0.88      0.90       152\n",
      "    positive       0.80      0.83      0.81        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.74      0.85      0.78       216\n",
      "weighted avg       0.88      0.86      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.91      0.87        23\n",
      "     neutral       0.94      0.99      0.96       152\n",
      "    positive       0.97      0.76      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.89      0.90       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.86      0.71      0.77        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.89      0.82      0.85       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.86      0.86        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.76      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.87      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 87.9478485584259 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.008623111993074417\n",
      "Acquired samples: 54\n",
      "Sampling duration: 11.434721231460571 seconds\n",
      "New train size: 388\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5718, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4971, Accuracy: 0.8006, F1 Micro: 0.8877, F1 Macro: 0.8861\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4165, Accuracy: 0.8787, F1 Micro: 0.9282, F1 Macro: 0.9269\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3208, Accuracy: 0.9204, F1 Micro: 0.9504, F1 Macro: 0.9475\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.251, Accuracy: 0.9412, F1 Micro: 0.9632, F1 Macro: 0.9613\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1989, Accuracy: 0.9457, F1 Micro: 0.966, F1 Macro: 0.9639\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1545, Accuracy: 0.9524, F1 Micro: 0.9703, F1 Macro: 0.9688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1308, Accuracy: 0.9531, F1 Micro: 0.9707, F1 Macro: 0.9691\n",
      "Epoch 9/10, Train Loss: 0.1052, Accuracy: 0.9479, F1 Micro: 0.9674, F1 Macro: 0.9659\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0908, Accuracy: 0.9539, F1 Micro: 0.9711, F1 Macro: 0.9697\n",
      "\n",
      "Aspect detection accuracy: 0.9539, F1 Micro: 0.9711, F1 Macro: 0.9697\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.94      0.99      0.96       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.97      0.95      0.96       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.96      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5634, Accuracy: 0.6905, F1 Micro: 0.6905, F1 Macro: 0.4725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3566, Accuracy: 0.8889, F1 Micro: 0.8889, F1 Macro: 0.8726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1797, Accuracy: 0.9127, F1 Micro: 0.9127, F1 Macro: 0.8971\n",
      "Epoch 4/10, Train Loss: 0.1312, Accuracy: 0.8968, F1 Micro: 0.8968, F1 Macro: 0.8859\n",
      "Epoch 5/10, Train Loss: 0.1318, Accuracy: 0.8929, F1 Micro: 0.8929, F1 Macro: 0.8824\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1474, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9176\n",
      "Epoch 7/10, Train Loss: 0.1249, Accuracy: 0.9246, F1 Micro: 0.9246, F1 Macro: 0.9144\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0818, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9219\n",
      "Epoch 9/10, Train Loss: 0.0519, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.8982\n",
      "Epoch 10/10, Train Loss: 0.0868, Accuracy: 0.8849, F1 Micro: 0.8849, F1 Macro: 0.8744\n",
      "\n",
      "Sentiment analysis accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9219\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.91      0.89        78\n",
      "    positive       0.96      0.94      0.95       174\n",
      "\n",
      "    accuracy                           0.93       252\n",
      "   macro avg       0.92      0.93      0.92       252\n",
      "weighted avg       0.93      0.93      0.93       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 388: Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.8708\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       1.00      0.96      0.98        24\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.99      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.75      0.77        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.92      0.70      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.81      0.84       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.56      0.83      0.67        12\n",
      "     neutral       0.93      0.95      0.94       152\n",
      "    positive       0.86      0.71      0.78        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.78      0.83      0.79       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.96      0.77        23\n",
      "     neutral       0.97      0.95      0.96       152\n",
      "    positive       0.91      0.76      0.83        41\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.84      0.89      0.85       216\n",
      "weighted avg       0.93      0.91      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.77      0.77        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.92      0.65      0.76        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.88      0.80      0.84       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.71      0.83        14\n",
      "     neutral       0.96      1.00      0.98       185\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.99      0.85      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 100.65299797058105 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.00518269594758749\n",
      "Acquired samples: 48\n",
      "Sampling duration: 10.948925256729126 seconds\n",
      "New train size: 436\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5719, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4766, Accuracy: 0.8103, F1 Micro: 0.8926, F1 Macro: 0.8914\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3967, Accuracy: 0.904, F1 Micro: 0.941, F1 Macro: 0.939\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3077, Accuracy: 0.9293, F1 Micro: 0.956, F1 Macro: 0.9538\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2308, Accuracy: 0.9457, F1 Micro: 0.9659, F1 Macro: 0.9637\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.18, Accuracy: 0.9524, F1 Micro: 0.9702, F1 Macro: 0.9686\n",
      "Epoch 7/10, Train Loss: 0.1434, Accuracy: 0.9501, F1 Micro: 0.9686, F1 Macro: 0.9662\n",
      "Epoch 8/10, Train Loss: 0.1237, Accuracy: 0.9472, F1 Micro: 0.9665, F1 Macro: 0.963\n",
      "Epoch 9/10, Train Loss: 0.0951, Accuracy: 0.9524, F1 Micro: 0.97, F1 Macro: 0.9675\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0789, Accuracy: 0.9554, F1 Micro: 0.9719, F1 Macro: 0.9696\n",
      "\n",
      "Aspect detection accuracy: 0.9554, F1 Micro: 0.9719, F1 Macro: 0.9696\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.94      0.88      0.91       158\n",
      "        part       0.95      0.99      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5779, Accuracy: 0.7824, F1 Micro: 0.7824, F1 Macro: 0.7682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3135, Accuracy: 0.8893, F1 Micro: 0.8893, F1 Macro: 0.8794\n",
      "Epoch 3/10, Train Loss: 0.1734, Accuracy: 0.8664, F1 Micro: 0.8664, F1 Macro: 0.8588\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1943, Accuracy: 0.9198, F1 Micro: 0.9198, F1 Macro: 0.9094\n",
      "Epoch 5/10, Train Loss: 0.1667, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.8995\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1332, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9267\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1127, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9267\n",
      "Epoch 8/10, Train Loss: 0.1087, Accuracy: 0.9198, F1 Micro: 0.9198, F1 Macro: 0.9065\n",
      "Epoch 9/10, Train Loss: 0.0905, Accuracy: 0.9237, F1 Micro: 0.9237, F1 Macro: 0.9144\n",
      "Epoch 10/10, Train Loss: 0.0817, Accuracy: 0.9275, F1 Micro: 0.9275, F1 Macro: 0.9194\n",
      "\n",
      "Sentiment analysis accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9267\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.93      0.90        84\n",
      "    positive       0.97      0.94      0.95       178\n",
      "\n",
      "    accuracy                           0.94       262\n",
      "   macro avg       0.92      0.93      0.93       262\n",
      "weighted avg       0.94      0.94      0.94       262\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 436: Accuracy: 0.9452, F1 Micro: 0.9452, F1 Macro: 0.897\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.83      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.92      0.76        12\n",
      "     neutral       0.94      0.88      0.91       152\n",
      "    positive       0.75      0.83      0.79        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.78      0.88      0.82       216\n",
      "weighted avg       0.88      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.96      0.86        23\n",
      "     neutral       0.94      0.99      0.97       152\n",
      "    positive       0.96      0.66      0.78        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.87      0.87       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.86      0.71      0.77        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.93      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 101.04397296905518 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0054802150465548035\n",
      "Acquired samples: 43\n",
      "Sampling duration: 10.008361101150513 seconds\n",
      "New train size: 479\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5568, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4942, Accuracy: 0.8207, F1 Micro: 0.898, F1 Macro: 0.8969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3792, Accuracy: 0.9129, F1 Micro: 0.9461, F1 Macro: 0.9434\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.294, Accuracy: 0.9278, F1 Micro: 0.9551, F1 Macro: 0.9523\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2275, Accuracy: 0.9501, F1 Micro: 0.969, F1 Macro: 0.9676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1805, Accuracy: 0.9539, F1 Micro: 0.9711, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1371, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9723\n",
      "Epoch 8/10, Train Loss: 0.1036, Accuracy: 0.9568, F1 Micro: 0.9727, F1 Macro: 0.9708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0946, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0775, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9753\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9753\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.96      0.99      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5457, Accuracy: 0.7677, F1 Micro: 0.7677, F1 Macro: 0.687\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2984, Accuracy: 0.9094, F1 Micro: 0.9094, F1 Macro: 0.9003\n",
      "Epoch 3/10, Train Loss: 0.2194, Accuracy: 0.9055, F1 Micro: 0.9055, F1 Macro: 0.8962\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1639, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9377\n",
      "Epoch 5/10, Train Loss: 0.1652, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.9063\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1328, Accuracy: 0.9528, F1 Micro: 0.9528, F1 Macro: 0.946\n",
      "Epoch 7/10, Train Loss: 0.1018, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9124\n",
      "Epoch 8/10, Train Loss: 0.1208, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9144\n",
      "Epoch 9/10, Train Loss: 0.0972, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9339\n",
      "Epoch 10/10, Train Loss: 0.0731, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9346\n",
      "\n",
      "Sentiment analysis accuracy: 0.9528, F1 Micro: 0.9528, F1 Macro: 0.946\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.92      0.93        83\n",
      "    positive       0.96      0.97      0.97       171\n",
      "\n",
      "    accuracy                           0.95       254\n",
      "   macro avg       0.95      0.94      0.95       254\n",
      "weighted avg       0.95      0.95      0.95       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 479: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9082\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.84      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.93      0.94      0.94       152\n",
      "    positive       0.84      0.81      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.85      0.86      0.85       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.96      0.99      0.97       152\n",
      "    positive       0.97      0.73      0.83        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.91      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.89      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.79      0.85        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 105.81712770462036 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.006545739714056253\n",
      "Acquired samples: 39\n",
      "Sampling duration: 9.042928695678711 seconds\n",
      "New train size: 518\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5638, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.454, Accuracy: 0.8452, F1 Micro: 0.9105, F1 Macro: 0.9101\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3541, Accuracy: 0.9189, F1 Micro: 0.9497, F1 Macro: 0.9475\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2569, Accuracy: 0.9375, F1 Micro: 0.9608, F1 Macro: 0.9584\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1942, Accuracy: 0.9472, F1 Micro: 0.9671, F1 Macro: 0.9655\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1539, Accuracy: 0.9546, F1 Micro: 0.9715, F1 Macro: 0.9699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1239, Accuracy: 0.9568, F1 Micro: 0.9727, F1 Macro: 0.971\n",
      "Epoch 8/10, Train Loss: 0.0949, Accuracy: 0.9561, F1 Micro: 0.9723, F1 Macro: 0.9703\n",
      "Epoch 9/10, Train Loss: 0.0829, Accuracy: 0.9561, F1 Micro: 0.9723, F1 Macro: 0.9704\n",
      "Epoch 10/10, Train Loss: 0.0674, Accuracy: 0.9531, F1 Micro: 0.9704, F1 Macro: 0.9682\n",
      "\n",
      "Aspect detection accuracy: 0.9568, F1 Micro: 0.9727, F1 Macro: 0.971\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.90      0.93      0.92       158\n",
      "        part       0.98      0.95      0.96       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      1061\n",
      "   macro avg       0.97      0.97      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.97      0.97      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5624, Accuracy: 0.8284, F1 Micro: 0.8284, F1 Macro: 0.7888\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2941, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9184\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1726, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.9275\n",
      "Epoch 4/10, Train Loss: 0.154, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9234\n",
      "Epoch 5/10, Train Loss: 0.1154, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9162\n",
      "Epoch 6/10, Train Loss: 0.1124, Accuracy: 0.9254, F1 Micro: 0.9254, F1 Macro: 0.9149\n",
      "Epoch 7/10, Train Loss: 0.1011, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9087\n",
      "Epoch 8/10, Train Loss: 0.0914, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9074\n",
      "Epoch 9/10, Train Loss: 0.0978, Accuracy: 0.9179, F1 Micro: 0.9179, F1 Macro: 0.902\n",
      "Epoch 10/10, Train Loss: 0.0883, Accuracy: 0.9179, F1 Micro: 0.9179, F1 Macro: 0.908\n",
      "\n",
      "Sentiment analysis accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.9275\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.95      0.90        82\n",
      "    positive       0.98      0.93      0.95       186\n",
      "\n",
      "    accuracy                           0.94       268\n",
      "   macro avg       0.92      0.94      0.93       268\n",
      "weighted avg       0.94      0.94      0.94       268\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 518: Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.8831\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.97      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.88      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.48      1.00      0.65        12\n",
      "     neutral       0.94      0.88      0.91       152\n",
      "    positive       0.81      0.75      0.78        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.74      0.88      0.78       216\n",
      "weighted avg       0.88      0.86      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.96      0.80        23\n",
      "     neutral       0.98      0.95      0.96       152\n",
      "    positive       0.89      0.80      0.85        41\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.85      0.90      0.87       216\n",
      "weighted avg       0.93      0.92      0.92       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.80      0.71      0.75        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.86      0.87      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.79      0.85        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 106.960928440094 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0036260992288589477\n",
      "Acquired samples: 22\n",
      "Sampling duration: 8.156286478042603 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5462, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4605, Accuracy: 0.8557, F1 Micro: 0.9159, F1 Macro: 0.9155\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3511, Accuracy: 0.9211, F1 Micro: 0.9513, F1 Macro: 0.949\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.262, Accuracy: 0.9323, F1 Micro: 0.9578, F1 Macro: 0.9554\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.195, Accuracy: 0.9524, F1 Micro: 0.9702, F1 Macro: 0.9687\n",
      "Epoch 6/10, Train Loss: 0.1543, Accuracy: 0.9516, F1 Micro: 0.9696, F1 Macro: 0.9677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1274, Accuracy: 0.9546, F1 Micro: 0.9716, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0977, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9714\n",
      "Epoch 9/10, Train Loss: 0.0836, Accuracy: 0.9531, F1 Micro: 0.9705, F1 Macro: 0.9683\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.069, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9725\n",
      "\n",
      "Aspect detection accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9725\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.94      0.92      0.93       158\n",
      "        part       0.96      0.97      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5557, Accuracy: 0.711, F1 Micro: 0.711, F1 Macro: 0.5378\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3117, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9151\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.175, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9276\n",
      "Epoch 4/10, Train Loss: 0.1469, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.9002\n",
      "Epoch 5/10, Train Loss: 0.1628, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.9076\n",
      "Epoch 6/10, Train Loss: 0.1694, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9236\n",
      "Epoch 7/10, Train Loss: 0.1159, Accuracy: 0.9278, F1 Micro: 0.9278, F1 Macro: 0.9186\n",
      "Epoch 8/10, Train Loss: 0.1042, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9231\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.078, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9317\n",
      "Epoch 10/10, Train Loss: 0.0795, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9236\n",
      "\n",
      "Sentiment analysis accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9317\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.95      0.91        84\n",
      "    positive       0.98      0.93      0.95       179\n",
      "\n",
      "    accuracy                           0.94       263\n",
      "   macro avg       0.92      0.94      0.93       263\n",
      "weighted avg       0.94      0.94      0.94       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.9049\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.86      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.92      0.81        12\n",
      "     neutral       0.94      0.92      0.93       152\n",
      "    positive       0.81      0.81      0.81        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.83      0.88      0.85       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.96      0.86        23\n",
      "     neutral       0.96      0.97      0.96       152\n",
      "    positive       0.91      0.78      0.84        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.90      0.89       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.85      0.65      0.73        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.89      0.85      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.93      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 110.24159932136536 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.0033403500448912385\n",
      "Acquired samples: 33\n",
      "Sampling duration: 7.751637697219849 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5467, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.459, Accuracy: 0.8638, F1 Micro: 0.9203, F1 Macro: 0.9199\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3434, Accuracy: 0.9249, F1 Micro: 0.9531, F1 Macro: 0.9505\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2357, Accuracy: 0.9487, F1 Micro: 0.9681, F1 Macro: 0.9664\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1881, Accuracy: 0.9554, F1 Micro: 0.972, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1335, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9728\n",
      "Epoch 7/10, Train Loss: 0.1104, Accuracy: 0.9539, F1 Micro: 0.9708, F1 Macro: 0.9683\n",
      "Epoch 8/10, Train Loss: 0.0886, Accuracy: 0.9576, F1 Micro: 0.9732, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0736, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0634, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9745\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9745\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.93      0.95      0.94       158\n",
      "        part       0.97      0.97      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5471, Accuracy: 0.8353, F1 Micro: 0.8353, F1 Macro: 0.8113\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.314, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.921\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.17, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9206\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1599, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9324\n",
      "Epoch 5/10, Train Loss: 0.1197, Accuracy: 0.9059, F1 Micro: 0.9059, F1 Macro: 0.898\n",
      "Epoch 6/10, Train Loss: 0.111, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9306\n",
      "Epoch 7/10, Train Loss: 0.1169, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9286\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0878, Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9464\n",
      "Epoch 9/10, Train Loss: 0.092, Accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.9425\n",
      "Epoch 10/10, Train Loss: 0.0753, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9175\n",
      "\n",
      "Sentiment analysis accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9464\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.94      0.93        82\n",
      "    positive       0.97      0.96      0.97       173\n",
      "\n",
      "    accuracy                           0.95       255\n",
      "   macro avg       0.94      0.95      0.95       255\n",
      "weighted avg       0.95      0.95      0.95       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.8957\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.96      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.91      0.82      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.83      0.91        12\n",
      "     neutral       0.93      0.95      0.94       152\n",
      "    positive       0.84      0.83      0.83        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.83      0.81        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       0.87      0.83      0.85        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.88      0.88       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.76      0.76      0.76        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.91      0.84      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.71      0.83        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.98      0.90      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 118.20853567123413 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.002320724120363593\n",
      "Acquired samples: 30\n",
      "Sampling duration: 7.131402254104614 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5589, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4472, Accuracy: 0.869, F1 Micro: 0.923, F1 Macro: 0.9225\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3276, Accuracy: 0.9293, F1 Micro: 0.956, F1 Macro: 0.9535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2302, Accuracy: 0.9457, F1 Micro: 0.966, F1 Macro: 0.9637\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1769, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1304, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1062, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0861, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0699, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9752\n",
      "Epoch 10/10, Train Loss: 0.0623, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.973\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9752\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.91      0.95      0.93       158\n",
      "        part       0.98      0.96      0.97       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5767, Accuracy: 0.8405, F1 Micro: 0.8405, F1 Macro: 0.8031\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3212, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9152\n",
      "Epoch 3/10, Train Loss: 0.2081, Accuracy: 0.9105, F1 Micro: 0.9105, F1 Macro: 0.9024\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1508, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9135\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1188, Accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9385\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1172, Accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9388\n",
      "Epoch 7/10, Train Loss: 0.0836, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9264\n",
      "Epoch 8/10, Train Loss: 0.095, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9305\n",
      "Epoch 9/10, Train Loss: 0.0652, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9181\n",
      "Epoch 10/10, Train Loss: 0.0734, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9181\n",
      "\n",
      "Sentiment analysis accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9388\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        82\n",
      "    positive       0.98      0.94      0.96       175\n",
      "\n",
      "    accuracy                           0.95       257\n",
      "   macro avg       0.93      0.95      0.94       257\n",
      "weighted avg       0.95      0.95      0.95       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.946, F1 Micro: 0.946, F1 Macro: 0.8885\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       1.00      0.88      0.93        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.96      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.38      0.92      0.54        12\n",
      "     neutral       0.96      0.88      0.92       152\n",
      "    positive       0.83      0.75      0.79        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.72      0.85      0.75       216\n",
      "weighted avg       0.89      0.85      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      1.00      0.84        23\n",
      "     neutral       0.98      0.96      0.97       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.92      0.89       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.95      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 121.86641192436218 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.0033016569213941693\n",
      "Acquired samples: 27\n",
      "Sampling duration: 6.528013706207275 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5486, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4376, Accuracy: 0.8676, F1 Micro: 0.9218, F1 Macro: 0.9209\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3132, Accuracy: 0.9286, F1 Micro: 0.9554, F1 Macro: 0.9522\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2209, Accuracy: 0.9509, F1 Micro: 0.9695, F1 Macro: 0.9678\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1667, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9718\n",
      "Epoch 6/10, Train Loss: 0.1298, Accuracy: 0.9576, F1 Micro: 0.9732, F1 Macro: 0.9708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1028, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9751\n",
      "Epoch 8/10, Train Loss: 0.0849, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0731, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9753\n",
      "Epoch 10/10, Train Loss: 0.0618, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9742\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9753\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.92      0.92      0.92       158\n",
      "        part       0.96      0.99      0.97       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5596, Accuracy: 0.8859, F1 Micro: 0.8859, F1 Macro: 0.8719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2485, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9354\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1856, Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9412\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1665, Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9399\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.142, Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9402\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1036, Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9412\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0863, Accuracy: 0.9544, F1 Micro: 0.9544, F1 Macro: 0.9485\n",
      "Epoch 8/10, Train Loss: 0.0775, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9259\n",
      "Epoch 9/10, Train Loss: 0.0721, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9372\n",
      "Epoch 10/10, Train Loss: 0.0717, Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9409\n",
      "\n",
      "Sentiment analysis accuracy: 0.9544, F1 Micro: 0.9544, F1 Macro: 0.9485\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        87\n",
      "    positive       0.97      0.97      0.97       176\n",
      "\n",
      "    accuracy                           0.95       263\n",
      "   macro avg       0.95      0.95      0.95       263\n",
      "weighted avg       0.95      0.95      0.95       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9134\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.91      0.88      0.89        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.89      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.92      0.79        12\n",
      "     neutral       0.93      0.91      0.92       152\n",
      "    positive       0.77      0.77      0.77        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.80      0.86      0.82       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      1.00      0.84        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       0.97      0.76      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.91      0.89       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 124.1573417186737 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.0030665238853543994\n",
      "Acquired samples: 18\n",
      "Sampling duration: 5.946034908294678 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5542, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4314, Accuracy: 0.9159, F1 Micro: 0.9486, F1 Macro: 0.9467\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2948, Accuracy: 0.9353, F1 Micro: 0.9596, F1 Macro: 0.9569\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2119, Accuracy: 0.9568, F1 Micro: 0.9732, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1571, Accuracy: 0.9643, F1 Micro: 0.9777, F1 Macro: 0.9766\n",
      "Epoch 6/10, Train Loss: 0.1152, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9763\n",
      "Epoch 7/10, Train Loss: 0.0955, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9736\n",
      "Epoch 8/10, Train Loss: 0.0788, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9746\n",
      "Epoch 9/10, Train Loss: 0.0646, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0543, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9796\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9796\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.99      0.98       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.97      0.98      0.97       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5503, Accuracy: 0.8953, F1 Micro: 0.8953, F1 Macro: 0.8845\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.239, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.931\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1513, Accuracy: 0.9457, F1 Micro: 0.9457, F1 Macro: 0.9393\n",
      "Epoch 4/10, Train Loss: 0.143, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9257\n",
      "Epoch 5/10, Train Loss: 0.1078, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9302\n",
      "Epoch 6/10, Train Loss: 0.1026, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.9236\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0845, Accuracy: 0.9535, F1 Micro: 0.9535, F1 Macro: 0.9483\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0865, Accuracy: 0.9535, F1 Micro: 0.9535, F1 Macro: 0.948\n",
      "Epoch 9/10, Train Loss: 0.0629, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.928\n",
      "Epoch 10/10, Train Loss: 0.0467, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9348\n",
      "\n",
      "Sentiment analysis accuracy: 0.9535, F1 Micro: 0.9535, F1 Macro: 0.948\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.94      0.93        86\n",
      "    positive       0.97      0.96      0.96       172\n",
      "\n",
      "    accuracy                           0.95       258\n",
      "   macro avg       0.95      0.95      0.95       258\n",
      "weighted avg       0.95      0.95      0.95       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9197\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.99      0.98       167\n",
      "    positive       0.90      0.82      0.86        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.89      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.92      0.96      0.94       152\n",
      "    positive       0.85      0.75      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.86      0.82      0.84       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.97      0.98      0.97       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.92      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.89      1.00      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 121.94584846496582 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.0023111365269869568\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.591579914093018 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5343, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4149, Accuracy: 0.9159, F1 Micro: 0.9486, F1 Macro: 0.9469\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2868, Accuracy: 0.9494, F1 Micro: 0.9687, F1 Macro: 0.9672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1983, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1406, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1139, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.977\n",
      "Epoch 7/10, Train Loss: 0.0876, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9741\n",
      "Epoch 8/10, Train Loss: 0.0711, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9756\n",
      "Epoch 9/10, Train Loss: 0.0565, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.052, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.91      0.95      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5383, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.901\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.258, Accuracy: 0.9255, F1 Micro: 0.9255, F1 Macro: 0.9194\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1889, Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9477\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1433, Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9474\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1167, Accuracy: 0.9608, F1 Micro: 0.9608, F1 Macro: 0.9561\n",
      "Epoch 6/10, Train Loss: 0.0973, Accuracy: 0.9569, F1 Micro: 0.9569, F1 Macro: 0.9519\n",
      "Epoch 7/10, Train Loss: 0.0971, Accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.9421\n",
      "Epoch 8/10, Train Loss: 0.102, Accuracy: 0.9569, F1 Micro: 0.9569, F1 Macro: 0.9513\n",
      "Epoch 9/10, Train Loss: 0.0585, Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9471\n",
      "Epoch 10/10, Train Loss: 0.0694, Accuracy: 0.9569, F1 Micro: 0.9569, F1 Macro: 0.9522\n",
      "\n",
      "Sentiment analysis accuracy: 0.9608, F1 Micro: 0.9608, F1 Macro: 0.9561\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.95      0.94        85\n",
      "    positive       0.98      0.96      0.97       170\n",
      "\n",
      "    accuracy                           0.96       255\n",
      "   macro avg       0.95      0.96      0.96       255\n",
      "weighted avg       0.96      0.96      0.96       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.9228\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.89      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.92      0.95      0.93       152\n",
      "    positive       0.81      0.75      0.78        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.85      0.82      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.80      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.97      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.97      0.87      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 128.19866633415222 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.003250432340428233\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.060646295547485 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5326, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4065, Accuracy: 0.91, F1 Micro: 0.9447, F1 Macro: 0.9429\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2836, Accuracy: 0.9494, F1 Micro: 0.9687, F1 Macro: 0.9675\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1989, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9737\n",
      "Epoch 5/10, Train Loss: 0.1445, Accuracy: 0.9531, F1 Micro: 0.9704, F1 Macro: 0.9672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1151, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0876, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9784\n",
      "Epoch 8/10, Train Loss: 0.0731, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9746\n",
      "Epoch 9/10, Train Loss: 0.0648, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9777\n",
      "Epoch 10/10, Train Loss: 0.0556, Accuracy: 0.968, F1 Micro: 0.9797, F1 Macro: 0.9781\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9784\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.95      0.92      0.94       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5005, Accuracy: 0.9026, F1 Micro: 0.9026, F1 Macro: 0.8933\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2231, Accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.9097\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1606, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.925\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1305, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9258\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.128, Accuracy: 0.9401, F1 Micro: 0.9401, F1 Macro: 0.933\n",
      "Epoch 6/10, Train Loss: 0.0968, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9113\n",
      "Epoch 7/10, Train Loss: 0.0927, Accuracy: 0.9288, F1 Micro: 0.9288, F1 Macro: 0.9206\n",
      "Epoch 8/10, Train Loss: 0.0542, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.925\n",
      "Epoch 9/10, Train Loss: 0.0557, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9246\n",
      "Epoch 10/10, Train Loss: 0.0623, Accuracy: 0.9251, F1 Micro: 0.9251, F1 Macro: 0.9166\n",
      "\n",
      "Sentiment analysis accuracy: 0.9401, F1 Micro: 0.9401, F1 Macro: 0.933\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.94      0.91        87\n",
      "    positive       0.97      0.94      0.95       180\n",
      "\n",
      "    accuracy                           0.94       267\n",
      "   macro avg       0.93      0.94      0.93       267\n",
      "weighted avg       0.94      0.94      0.94       267\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9011\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.81      0.72        16\n",
      "     neutral       0.97      0.98      0.97       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.83      0.84      0.83       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.52      0.92      0.67        12\n",
      "     neutral       0.95      0.89      0.92       152\n",
      "    positive       0.81      0.81      0.81        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.76      0.87      0.80       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.94      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 127.74162936210632 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.0025154244620352985\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.099086046218872 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5318, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4141, Accuracy: 0.9189, F1 Micro: 0.9503, F1 Macro: 0.9486\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2685, Accuracy: 0.9487, F1 Micro: 0.9681, F1 Macro: 0.9669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1848, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1448, Accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9776\n",
      "Epoch 6/10, Train Loss: 0.1161, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0864, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9779\n",
      "Epoch 8/10, Train Loss: 0.073, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9755\n",
      "Epoch 9/10, Train Loss: 0.06, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9738\n",
      "Epoch 10/10, Train Loss: 0.0519, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9773\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9779\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4987, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.9027\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2688, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9385\n",
      "Epoch 3/10, Train Loss: 0.1803, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9246\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1592, Accuracy: 0.9488, F1 Micro: 0.9488, F1 Macro: 0.9424\n",
      "Epoch 5/10, Train Loss: 0.1283, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9297\n",
      "Epoch 6/10, Train Loss: 0.1307, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9232\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0961, Accuracy: 0.9488, F1 Micro: 0.9488, F1 Macro: 0.9427\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0887, Accuracy: 0.9567, F1 Micro: 0.9567, F1 Macro: 0.9515\n",
      "Epoch 9/10, Train Loss: 0.087, Accuracy: 0.9488, F1 Micro: 0.9488, F1 Macro: 0.942\n",
      "Epoch 10/10, Train Loss: 0.0718, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9251\n",
      "\n",
      "Sentiment analysis accuracy: 0.9567, F1 Micro: 0.9567, F1 Macro: 0.9515\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.95      0.94        84\n",
      "    positive       0.98      0.96      0.97       170\n",
      "\n",
      "    accuracy                           0.96       254\n",
      "   macro avg       0.95      0.96      0.95       254\n",
      "weighted avg       0.96      0.96      0.96       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.8977\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      0.81      0.76        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.85      0.84      0.84       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.83      0.62        12\n",
      "     neutral       0.94      0.92      0.93       152\n",
      "    positive       0.85      0.77      0.81        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.76      0.84      0.79       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 127.00296998023987 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.0020570639055222275\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.9722256660461426 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5332, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4077, Accuracy: 0.9182, F1 Micro: 0.949, F1 Macro: 0.9458\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2632, Accuracy: 0.9561, F1 Micro: 0.9727, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1905, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1343, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9769\n",
      "Epoch 6/10, Train Loss: 0.1058, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9745\n",
      "Epoch 7/10, Train Loss: 0.0869, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0698, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9776\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0578, Accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9802\n",
      "Epoch 10/10, Train Loss: 0.0486, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9795\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9802\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.96      0.95       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.537, Accuracy: 0.9035, F1 Micro: 0.9035, F1 Macro: 0.8938\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2428, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9238\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1431, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9404\n",
      "Epoch 4/10, Train Loss: 0.1234, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9244\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0866, Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9486\n",
      "Epoch 6/10, Train Loss: 0.0908, Accuracy: 0.9189, F1 Micro: 0.9189, F1 Macro: 0.9121\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0909, Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9484\n",
      "Epoch 8/10, Train Loss: 0.0948, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9319\n",
      "Epoch 9/10, Train Loss: 0.072, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9304\n",
      "Epoch 10/10, Train Loss: 0.0599, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.9063\n",
      "\n",
      "Sentiment analysis accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9484\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93        86\n",
      "    positive       0.98      0.95      0.96       173\n",
      "\n",
      "    accuracy                           0.95       259\n",
      "   macro avg       0.94      0.95      0.95       259\n",
      "weighted avg       0.95      0.95      0.95       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.8904\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.81      0.79      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.84      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.59      0.83      0.69        12\n",
      "     neutral       0.94      0.94      0.94       152\n",
      "    positive       0.85      0.77      0.81        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.79      0.85      0.81       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       1.00      0.80      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.93      0.91       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.88      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.93      0.90        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.93      0.94      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 133.92183017730713 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.002039209147915244\n",
      "Acquired samples: 8\n",
      "Sampling duration: 3.496469736099243 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5272, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4003, Accuracy: 0.9196, F1 Micro: 0.9499, F1 Macro: 0.9469\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2695, Accuracy: 0.9531, F1 Micro: 0.9709, F1 Macro: 0.9695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1813, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1377, Accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9775\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1053, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.979\n",
      "Epoch 7/10, Train Loss: 0.0846, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.976\n",
      "Epoch 8/10, Train Loss: 0.0668, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9783\n",
      "Epoch 9/10, Train Loss: 0.0529, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0481, Accuracy: 0.971, F1 Micro: 0.9817, F1 Macro: 0.9805\n",
      "\n",
      "Aspect detection accuracy: 0.971, F1 Micro: 0.9817, F1 Macro: 0.9805\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.95      0.94      0.95       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5093, Accuracy: 0.8914, F1 Micro: 0.8914, F1 Macro: 0.8813\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2419, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.93\n",
      "Epoch 3/10, Train Loss: 0.1849, Accuracy: 0.9101, F1 Micro: 0.9101, F1 Macro: 0.8958\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1431, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9293\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1002, Accuracy: 0.9401, F1 Micro: 0.9401, F1 Macro: 0.9337\n",
      "Epoch 6/10, Train Loss: 0.0955, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9254\n",
      "Epoch 7/10, Train Loss: 0.076, Accuracy: 0.9251, F1 Micro: 0.9251, F1 Macro: 0.9183\n",
      "Epoch 8/10, Train Loss: 0.0795, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9293\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.053, Accuracy: 0.9401, F1 Micro: 0.9401, F1 Macro: 0.9314\n",
      "Epoch 10/10, Train Loss: 0.0585, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9258\n",
      "\n",
      "Sentiment analysis accuracy: 0.9401, F1 Micro: 0.9401, F1 Macro: 0.9314\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.89      0.91        88\n",
      "    positive       0.95      0.97      0.96       179\n",
      "\n",
      "    accuracy                           0.94       267\n",
      "   macro avg       0.94      0.93      0.93       267\n",
      "weighted avg       0.94      0.94      0.94       267\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9179\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.88      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.92      0.81        12\n",
      "     neutral       0.95      0.95      0.95       152\n",
      "    positive       0.82      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.84      0.88      0.86       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.80      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 133.6558449268341 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0029356244951486594\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.231671094894409 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5199, Accuracy: 0.8028, F1 Micro: 0.889, F1 Macro: 0.8877\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3812, Accuracy: 0.9219, F1 Micro: 0.9513, F1 Macro: 0.9487\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2594, Accuracy: 0.9516, F1 Micro: 0.97, F1 Macro: 0.9686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1722, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9746\n",
      "Epoch 5/10, Train Loss: 0.1319, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1007, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9792\n",
      "Epoch 7/10, Train Loss: 0.0797, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0609, Accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9802\n",
      "Epoch 9/10, Train Loss: 0.0544, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9785\n",
      "Epoch 10/10, Train Loss: 0.0455, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9788\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9802\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.97      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5105, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.902\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1916, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9252\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1685, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9358\n",
      "Epoch 4/10, Train Loss: 0.133, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9294\n",
      "Epoch 5/10, Train Loss: 0.1359, Accuracy: 0.9255, F1 Micro: 0.9255, F1 Macro: 0.919\n",
      "Epoch 6/10, Train Loss: 0.0775, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9276\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0883, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9389\n",
      "Epoch 8/10, Train Loss: 0.0519, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9231\n",
      "Epoch 9/10, Train Loss: 0.058, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9298\n",
      "Epoch 10/10, Train Loss: 0.0433, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9351\n",
      "\n",
      "Sentiment analysis accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9389\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        85\n",
      "    positive       0.97      0.95      0.96       170\n",
      "\n",
      "    accuracy                           0.95       255\n",
      "   macro avg       0.93      0.94      0.94       255\n",
      "weighted avg       0.95      0.95      0.95       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.9091\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.97      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.82      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.56      0.83      0.67        12\n",
      "     neutral       0.93      0.94      0.93       152\n",
      "    positive       0.89      0.75      0.81        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.79      0.84      0.80       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.83      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 133.22462916374207 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.00275310087017715\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.7832510471343994 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5199, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3847, Accuracy: 0.9256, F1 Micro: 0.9537, F1 Macro: 0.951\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2499, Accuracy: 0.9561, F1 Micro: 0.9727, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.171, Accuracy: 0.9628, F1 Micro: 0.9768, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1245, Accuracy: 0.968, F1 Micro: 0.98, F1 Macro: 0.979\n",
      "Epoch 6/10, Train Loss: 0.0977, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9738\n",
      "Epoch 7/10, Train Loss: 0.0753, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9785\n",
      "Epoch 8/10, Train Loss: 0.0641, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.978\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.054, Accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9793\n",
      "Epoch 10/10, Train Loss: 0.0435, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9784\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.97      0.97       175\n",
      "      others       0.94      0.93      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4893, Accuracy: 0.8897, F1 Micro: 0.8897, F1 Macro: 0.8787\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1852, Accuracy: 0.9338, F1 Micro: 0.9338, F1 Macro: 0.9268\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1769, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9307\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1414, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9376\n",
      "Epoch 5/10, Train Loss: 0.1137, Accuracy: 0.9301, F1 Micro: 0.9301, F1 Macro: 0.923\n",
      "Epoch 6/10, Train Loss: 0.083, Accuracy: 0.9301, F1 Micro: 0.9301, F1 Macro: 0.9185\n",
      "Epoch 7/10, Train Loss: 0.081, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9149\n",
      "Epoch 8/10, Train Loss: 0.083, Accuracy: 0.9338, F1 Micro: 0.9338, F1 Macro: 0.9253\n",
      "Epoch 9/10, Train Loss: 0.0376, Accuracy: 0.9265, F1 Micro: 0.9265, F1 Macro: 0.9127\n",
      "Epoch 10/10, Train Loss: 0.0403, Accuracy: 0.9191, F1 Micro: 0.9191, F1 Macro: 0.9081\n",
      "\n",
      "Sentiment analysis accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9376\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.93      0.92        88\n",
      "    positive       0.97      0.95      0.96       184\n",
      "\n",
      "    accuracy                           0.94       272\n",
      "   macro avg       0.93      0.94      0.94       272\n",
      "weighted avg       0.95      0.94      0.95       272\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.8971\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.69      0.79        16\n",
      "     neutral       0.97      0.97      0.97       167\n",
      "    positive       0.76      0.85      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.84      0.85       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.75      0.67        12\n",
      "     neutral       0.95      0.91      0.93       152\n",
      "    positive       0.75      0.79      0.77        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.77      0.82      0.79       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.92      0.91       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 137.76143670082092 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0021311200223863127\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.0926883220672607 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5231, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3825, Accuracy: 0.9204, F1 Micro: 0.9507, F1 Macro: 0.9485\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.246, Accuracy: 0.9546, F1 Micro: 0.9719, F1 Macro: 0.9707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1688, Accuracy: 0.9628, F1 Micro: 0.9768, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1303, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.976\n",
      "Epoch 6/10, Train Loss: 0.0995, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0835, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9768\n",
      "Epoch 8/10, Train Loss: 0.066, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0518, Accuracy: 0.971, F1 Micro: 0.9818, F1 Macro: 0.9806\n",
      "Epoch 10/10, Train Loss: 0.0461, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9776\n",
      "\n",
      "Aspect detection accuracy: 0.971, F1 Micro: 0.9818, F1 Macro: 0.9806\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.93      0.97      0.95       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4967, Accuracy: 0.9038, F1 Micro: 0.9038, F1 Macro: 0.897\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2628, Accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.9055\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1908, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9371\n",
      "Epoch 4/10, Train Loss: 0.1549, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.925\n",
      "Epoch 5/10, Train Loss: 0.1032, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9213\n",
      "Epoch 6/10, Train Loss: 0.0814, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.932\n",
      "Epoch 7/10, Train Loss: 0.0961, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9247\n",
      "Epoch 8/10, Train Loss: 0.0723, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.9025\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0671, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9343\n",
      "Epoch 10/10, Train Loss: 0.055, Accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.9119\n",
      "\n",
      "Sentiment analysis accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9343\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.89      0.91        87\n",
      "    positive       0.94      0.97      0.96       173\n",
      "\n",
      "    accuracy                           0.94       260\n",
      "   macro avg       0.94      0.93      0.93       260\n",
      "weighted avg       0.94      0.94      0.94       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.8975\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.97      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.87      0.86      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.83      0.62        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.89      0.75      0.81        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.77      0.84      0.79       216\n",
      "weighted avg       0.90      0.88      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 141.0247049331665 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0022163694258779286\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.5903511047363281 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5183, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3607, Accuracy: 0.933, F1 Micro: 0.9586, F1 Macro: 0.9567\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.236, Accuracy: 0.9561, F1 Micro: 0.9727, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1737, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9774\n",
      "Epoch 5/10, Train Loss: 0.114, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0966, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9768\n",
      "Epoch 7/10, Train Loss: 0.0716, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9754\n",
      "Epoch 8/10, Train Loss: 0.0588, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.975\n",
      "Epoch 9/10, Train Loss: 0.0533, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.977\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.046, Accuracy: 0.971, F1 Micro: 0.9818, F1 Macro: 0.9807\n",
      "\n",
      "Aspect detection accuracy: 0.971, F1 Micro: 0.9818, F1 Macro: 0.9807\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.97      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4889, Accuracy: 0.8984, F1 Micro: 0.8984, F1 Macro: 0.8897\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.218, Accuracy: 0.9102, F1 Micro: 0.9102, F1 Macro: 0.904\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.165, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9311\n",
      "Epoch 4/10, Train Loss: 0.1577, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9262\n",
      "Epoch 5/10, Train Loss: 0.1189, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9258\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1012, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9387\n",
      "Epoch 7/10, Train Loss: 0.0987, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9318\n",
      "Epoch 8/10, Train Loss: 0.0862, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9352\n",
      "Epoch 9/10, Train Loss: 0.054, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.927\n",
      "Epoch 10/10, Train Loss: 0.043, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9315\n",
      "\n",
      "Sentiment analysis accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9387\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        86\n",
      "    positive       0.96      0.96      0.96       170\n",
      "\n",
      "    accuracy                           0.95       256\n",
      "   macro avg       0.94      0.94      0.94       256\n",
      "weighted avg       0.95      0.95      0.95       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9177\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.96      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.86      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.92      0.97      0.94       152\n",
      "    positive       0.87      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.90      0.83      0.86       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.78      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.92      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 140.7114975452423 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0017865214496850968\n",
      "Acquired samples: 8\n",
      "Sampling duration: 1.064957857131958 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5173, Accuracy: 0.7954, F1 Micro: 0.8853, F1 Macro: 0.8838\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.364, Accuracy: 0.9144, F1 Micro: 0.9462, F1 Macro: 0.9429\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2451, Accuracy: 0.9554, F1 Micro: 0.9722, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1691, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.123, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9766\n",
      "Epoch 6/10, Train Loss: 0.0946, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0709, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "Epoch 8/10, Train Loss: 0.0592, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.975\n",
      "Epoch 9/10, Train Loss: 0.0514, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0445, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9772\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9772\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.97      0.97       175\n",
      "      others       0.94      0.92      0.93       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.97      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5259, Accuracy: 0.8832, F1 Micro: 0.8832, F1 Macro: 0.8691\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2302, Accuracy: 0.9526, F1 Micro: 0.9526, F1 Macro: 0.9458\n",
      "Epoch 3/10, Train Loss: 0.1799, Accuracy: 0.9343, F1 Micro: 0.9343, F1 Macro: 0.926\n",
      "Epoch 4/10, Train Loss: 0.1515, Accuracy: 0.9307, F1 Micro: 0.9307, F1 Macro: 0.9212\n",
      "Epoch 5/10, Train Loss: 0.1308, Accuracy: 0.9161, F1 Micro: 0.9161, F1 Macro: 0.9076\n",
      "Epoch 6/10, Train Loss: 0.1084, Accuracy: 0.9307, F1 Micro: 0.9307, F1 Macro: 0.9202\n",
      "Epoch 7/10, Train Loss: 0.1023, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9286\n",
      "Epoch 8/10, Train Loss: 0.0603, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9291\n",
      "Epoch 9/10, Train Loss: 0.0805, Accuracy: 0.9343, F1 Micro: 0.9343, F1 Macro: 0.9217\n",
      "Epoch 10/10, Train Loss: 0.0759, Accuracy: 0.9343, F1 Micro: 0.9343, F1 Macro: 0.9268\n",
      "\n",
      "Sentiment analysis accuracy: 0.9526, F1 Micro: 0.9526, F1 Macro: 0.9458\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.94      0.93        87\n",
      "    positive       0.97      0.96      0.96       187\n",
      "\n",
      "    accuracy                           0.95       274\n",
      "   macro avg       0.94      0.95      0.95       274\n",
      "weighted avg       0.95      0.95      0.95       274\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9177\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.96      0.97      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.88      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.95      0.91      0.93       152\n",
      "    positive       0.75      0.81      0.78        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.82      0.85      0.84       216\n",
      "weighted avg       0.89      0.88      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.91       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 140.0233805179596 s\n",
      "Total runtime: 3057.267333507538 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5873cef9",
   "metadata": {
    "papermill": {
     "duration": 0.327393,
     "end_time": "2025-03-23T15:06:23.389891",
     "exception": false,
     "start_time": "2025-03-23T15:06:23.062498",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7dc227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 3\n",
      "Random seed: 14\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6791, Accuracy: 0.7746, F1 Micro: 0.8722, F1 Macro: 0.8703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5752, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.512, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4609, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4635, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4127, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3898, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4151, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.396, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3746, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "\n",
      "Aspect detection accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.78      1.00      0.88       175\n",
      "      others       0.71      1.00      0.83       158\n",
      "        part       0.71      1.00      0.83       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.79      1.00      0.88      1061\n",
      "   macro avg       0.79      1.00      0.88      1061\n",
      "weighted avg       0.80      1.00      0.89      1061\n",
      " samples avg       0.79      1.00      0.88      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.8159, Accuracy: 0.3333, F1 Micro: 0.3333, F1 Macro: 0.25\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.6264, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5442, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5154, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4038, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3617, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3192, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2942, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3391, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2952, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "\n",
      "Sentiment analysis accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         1\n",
      "    positive       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.67         3\n",
      "   macro avg       0.33      0.50      0.40         3\n",
      "weighted avg       0.44      0.67      0.53         3\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.7909, F1 Micro: 0.7909, F1 Macro: 0.298\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.77      1.00      0.87       167\n",
      "    positive       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.77       216\n",
      "   macro avg       0.26      0.33      0.29       216\n",
      "weighted avg       0.60      0.77      0.67       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.71      1.00      0.83       152\n",
      "    positive       0.67      0.04      0.07        52\n",
      "\n",
      "    accuracy                           0.71       216\n",
      "   macro avg       0.46      0.35      0.30       216\n",
      "weighted avg       0.66      0.71      0.60       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        23\n",
      "     neutral       0.70      1.00      0.83       152\n",
      "    positive       0.00      0.00      0.00        41\n",
      "\n",
      "    accuracy                           0.70       216\n",
      "   macro avg       0.23      0.33      0.28       216\n",
      "weighted avg       0.50      0.70      0.58       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 64.09964036941528 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.004887192044407129\n",
      "Acquired samples: 82\n",
      "Sampling duration: 13.657120943069458 seconds\n",
      "New train size: 136\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.624, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4937, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.491, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4548, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4271, Accuracy: 0.7961, F1 Micro: 0.8855, F1 Macro: 0.8841\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3768, Accuracy: 0.8028, F1 Micro: 0.8883, F1 Macro: 0.8868\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3466, Accuracy: 0.8445, F1 Micro: 0.9092, F1 Macro: 0.9077\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2986, Accuracy: 0.8683, F1 Micro: 0.9219, F1 Macro: 0.9202\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2597, Accuracy: 0.8847, F1 Micro: 0.9305, F1 Macro: 0.9286\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2144, Accuracy: 0.904, F1 Micro: 0.9418, F1 Macro: 0.9401\n",
      "\n",
      "Aspect detection accuracy: 0.904, F1 Micro: 0.9418, F1 Macro: 0.9401\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.92      0.94      0.93       175\n",
      "      others       0.84      0.97      0.90       158\n",
      "        part       0.81      0.99      0.89       158\n",
      "       price       0.95      0.99      0.97       192\n",
      "     service       0.92      1.00      0.96       191\n",
      "\n",
      "   micro avg       0.90      0.98      0.94      1061\n",
      "   macro avg       0.90      0.98      0.94      1061\n",
      "weighted avg       0.91      0.98      0.94      1061\n",
      " samples avg       0.91      0.98      0.94      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.665, Accuracy: 0.676, F1 Micro: 0.676, F1 Macro: 0.4033\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.6114, Accuracy: 0.6927, F1 Micro: 0.6927, F1 Macro: 0.4566\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.561, Accuracy: 0.7207, F1 Micro: 0.7207, F1 Macro: 0.5654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5134, Accuracy: 0.8212, F1 Micro: 0.8212, F1 Macro: 0.7625\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4102, Accuracy: 0.8883, F1 Micro: 0.8883, F1 Macro: 0.8688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3159, Accuracy: 0.8939, F1 Micro: 0.8939, F1 Macro: 0.8734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2019, Accuracy: 0.905, F1 Micro: 0.905, F1 Macro: 0.889\n",
      "Epoch 8/10, Train Loss: 0.1706, Accuracy: 0.8994, F1 Micro: 0.8994, F1 Macro: 0.8831\n",
      "Epoch 9/10, Train Loss: 0.1707, Accuracy: 0.8994, F1 Micro: 0.8994, F1 Macro: 0.8807\n",
      "Epoch 10/10, Train Loss: 0.1205, Accuracy: 0.8827, F1 Micro: 0.8827, F1 Macro: 0.8719\n",
      "\n",
      "Sentiment analysis accuracy: 0.905, F1 Micro: 0.905, F1 Macro: 0.889\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.81      0.85        58\n",
      "    positive       0.91      0.95      0.93       121\n",
      "\n",
      "    accuracy                           0.91       179\n",
      "   macro avg       0.90      0.88      0.89       179\n",
      "weighted avg       0.90      0.91      0.90       179\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 136: Accuracy: 0.8912, F1 Micro: 0.8912, F1 Macro: 0.7512\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      1.00      0.85        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.75      0.86        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.92      0.90       216\n",
      "weighted avg       0.98      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.69      0.73        16\n",
      "     neutral       0.91      0.95      0.93       167\n",
      "    positive       0.75      0.64      0.69        33\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.82      0.76      0.78       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.57      0.67      0.62        12\n",
      "     neutral       0.84      0.97      0.90       152\n",
      "    positive       0.84      0.40      0.55        52\n",
      "\n",
      "    accuracy                           0.82       216\n",
      "   macro avg       0.75      0.68      0.69       216\n",
      "weighted avg       0.82      0.82      0.80       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.35      0.48        23\n",
      "     neutral       0.80      0.99      0.88       152\n",
      "    positive       0.95      0.44      0.60        41\n",
      "\n",
      "    accuracy                           0.81       216\n",
      "   macro avg       0.85      0.59      0.66       216\n",
      "weighted avg       0.83      0.81      0.79       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.95      0.99      0.97       186\n",
      "    positive       0.70      0.41      0.52        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.86      0.75      0.79       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.29      0.44        14\n",
      "     neutral       0.92      1.00      0.96       185\n",
      "    positive       0.90      0.53      0.67        17\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.94      0.61      0.69       216\n",
      "weighted avg       0.92      0.92      0.90       216\n",
      "\n",
      "Total train time: 74.26984357833862 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.012399231269955638\n",
      "Acquired samples: 73\n",
      "Sampling duration: 17.411657571792603 seconds\n",
      "New train size: 209\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6065, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5179, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5036, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4734, Accuracy: 0.8036, F1 Micro: 0.8892, F1 Macro: 0.8876\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4309, Accuracy: 0.8177, F1 Micro: 0.8949, F1 Macro: 0.893\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3432, Accuracy: 0.8542, F1 Micro: 0.9127, F1 Macro: 0.9096\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3135, Accuracy: 0.8936, F1 Micro: 0.935, F1 Macro: 0.9325\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2625, Accuracy: 0.9092, F1 Micro: 0.9444, F1 Macro: 0.9421\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2118, Accuracy: 0.9263, F1 Micro: 0.9544, F1 Macro: 0.952\n",
      "Epoch 10/10, Train Loss: 0.1804, Accuracy: 0.9144, F1 Micro: 0.9469, F1 Macro: 0.9433\n",
      "\n",
      "Aspect detection accuracy: 0.9263, F1 Micro: 0.9544, F1 Macro: 0.952\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.93      0.96      0.94       175\n",
      "      others       0.89      0.90      0.90       158\n",
      "        part       0.87      0.99      0.93       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.95      0.99      0.97       191\n",
      "\n",
      "   micro avg       0.93      0.98      0.95      1061\n",
      "   macro avg       0.93      0.97      0.95      1061\n",
      "weighted avg       0.94      0.98      0.95      1061\n",
      " samples avg       0.94      0.98      0.95      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5792, Accuracy: 0.6947, F1 Micro: 0.6947, F1 Macro: 0.4099\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4216, Accuracy: 0.6947, F1 Micro: 0.6947, F1 Macro: 0.4099\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3337, Accuracy: 0.8451, F1 Micro: 0.8451, F1 Macro: 0.7982\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2261, Accuracy: 0.8982, F1 Micro: 0.8982, F1 Macro: 0.8741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1694, Accuracy: 0.9071, F1 Micro: 0.9071, F1 Macro: 0.8918\n",
      "Epoch 6/10, Train Loss: 0.128, Accuracy: 0.8938, F1 Micro: 0.8938, F1 Macro: 0.8738\n",
      "Epoch 7/10, Train Loss: 0.1296, Accuracy: 0.885, F1 Micro: 0.885, F1 Macro: 0.8569\n",
      "Epoch 8/10, Train Loss: 0.0858, Accuracy: 0.8982, F1 Micro: 0.8982, F1 Macro: 0.8764\n",
      "Epoch 9/10, Train Loss: 0.0916, Accuracy: 0.8938, F1 Micro: 0.8938, F1 Macro: 0.8727\n",
      "Epoch 10/10, Train Loss: 0.0597, Accuracy: 0.885, F1 Micro: 0.885, F1 Macro: 0.8609\n",
      "\n",
      "Sentiment analysis accuracy: 0.9071, F1 Micro: 0.9071, F1 Macro: 0.8918\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.87      0.85        69\n",
      "    positive       0.94      0.92      0.93       157\n",
      "\n",
      "    accuracy                           0.91       226\n",
      "   macro avg       0.89      0.90      0.89       226\n",
      "weighted avg       0.91      0.91      0.91       226\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 209: Accuracy: 0.9012, F1 Micro: 0.9012, F1 Macro: 0.7872\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.56      0.67        16\n",
      "     neutral       0.93      0.96      0.94       167\n",
      "    positive       0.71      0.67      0.69        33\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.82      0.73      0.77       216\n",
      "weighted avg       0.88      0.89      0.88       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.31      0.67      0.42        12\n",
      "     neutral       0.89      0.83      0.86       152\n",
      "    positive       0.71      0.67      0.69        52\n",
      "\n",
      "    accuracy                           0.78       216\n",
      "   macro avg       0.64      0.72      0.66       216\n",
      "weighted avg       0.82      0.78      0.80       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.48      0.63        23\n",
      "     neutral       0.86      0.99      0.92       152\n",
      "    positive       0.86      0.61      0.71        41\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.88      0.69      0.76       216\n",
      "weighted avg       0.87      0.87      0.85       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.54      0.70        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.68      0.76      0.72        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.89      0.77      0.80       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.64      0.75        14\n",
      "     neutral       0.95      0.99      0.97       185\n",
      "    positive       0.75      0.53      0.62        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.87      0.72      0.78       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Total train time: 82.42769813537598 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.010192002169787884\n",
      "Acquired samples: 66\n",
      "Sampling duration: 16.735788345336914 seconds\n",
      "New train size: 275\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5964, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4979, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4847, Accuracy: 0.7984, F1 Micro: 0.8867, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4199, Accuracy: 0.8289, F1 Micro: 0.9001, F1 Macro: 0.8979\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.356, Accuracy: 0.8757, F1 Micro: 0.9251, F1 Macro: 0.9223\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2886, Accuracy: 0.9129, F1 Micro: 0.946, F1 Macro: 0.9431\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2408, Accuracy: 0.9278, F1 Micro: 0.9552, F1 Macro: 0.9526\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1896, Accuracy: 0.9368, F1 Micro: 0.9606, F1 Macro: 0.9582\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1536, Accuracy: 0.9412, F1 Micro: 0.9633, F1 Macro: 0.9612\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1284, Accuracy: 0.9427, F1 Micro: 0.9642, F1 Macro: 0.9623\n",
      "\n",
      "Aspect detection accuracy: 0.9427, F1 Micro: 0.9642, F1 Macro: 0.9623\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.96      0.95       175\n",
      "      others       0.88      0.92      0.90       158\n",
      "        part       0.93      0.98      0.96       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.96      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.95      0.98      0.96      1061\n",
      "   macro avg       0.95      0.98      0.96      1061\n",
      "weighted avg       0.95      0.98      0.96      1061\n",
      " samples avg       0.95      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5565, Accuracy: 0.7449, F1 Micro: 0.7449, F1 Macro: 0.6776\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4151, Accuracy: 0.8519, F1 Micro: 0.8519, F1 Macro: 0.8333\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2812, Accuracy: 0.9012, F1 Micro: 0.9012, F1 Macro: 0.8914\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2309, Accuracy: 0.9177, F1 Micro: 0.9177, F1 Macro: 0.908\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1845, Accuracy: 0.9177, F1 Micro: 0.9177, F1 Macro: 0.9043\n",
      "Epoch 6/10, Train Loss: 0.1197, Accuracy: 0.9136, F1 Micro: 0.9136, F1 Macro: 0.9042\n",
      "Epoch 7/10, Train Loss: 0.141, Accuracy: 0.9136, F1 Micro: 0.9136, F1 Macro: 0.9025\n",
      "Epoch 8/10, Train Loss: 0.1598, Accuracy: 0.9053, F1 Micro: 0.9053, F1 Macro: 0.8938\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1302, Accuracy: 0.9177, F1 Micro: 0.9177, F1 Macro: 0.9074\n",
      "Epoch 10/10, Train Loss: 0.1159, Accuracy: 0.893, F1 Micro: 0.893, F1 Macro: 0.8853\n",
      "\n",
      "Sentiment analysis accuracy: 0.9177, F1 Micro: 0.9177, F1 Macro: 0.9074\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.90      0.88        79\n",
      "    positive       0.95      0.93      0.94       164\n",
      "\n",
      "    accuracy                           0.92       243\n",
      "   macro avg       0.90      0.91      0.91       243\n",
      "weighted avg       0.92      0.92      0.92       243\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 275: Accuracy: 0.9275, F1 Micro: 0.9275, F1 Macro: 0.8514\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.88      0.93        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.88      0.80        16\n",
      "     neutral       0.95      0.96      0.96       167\n",
      "    positive       0.85      0.70      0.77        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.85      0.85      0.84       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.67      0.57        12\n",
      "     neutral       0.88      0.92      0.90       152\n",
      "    positive       0.76      0.60      0.67        52\n",
      "\n",
      "    accuracy                           0.83       216\n",
      "   macro avg       0.71      0.73      0.71       216\n",
      "weighted avg       0.83      0.83      0.83       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.87      0.80        23\n",
      "     neutral       0.93      0.98      0.96       152\n",
      "    positive       0.93      0.66      0.77        41\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.87      0.84      0.84       216\n",
      "weighted avg       0.91      0.91      0.90       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.89      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.86      0.86        14\n",
      "     neutral       0.96      1.00      0.98       185\n",
      "    positive       1.00      0.53      0.69        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.94      0.80      0.84       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Total train time: 89.62625694274902 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.007692150212824345\n",
      "Acquired samples: 59\n",
      "Sampling duration: 15.22248649597168 seconds\n",
      "New train size: 334\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5747, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4925, Accuracy: 0.7917, F1 Micro: 0.8833, F1 Macro: 0.8818\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4558, Accuracy: 0.8147, F1 Micro: 0.8935, F1 Macro: 0.8913\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3822, Accuracy: 0.875, F1 Micro: 0.9244, F1 Macro: 0.9218\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3108, Accuracy: 0.9048, F1 Micro: 0.9413, F1 Macro: 0.9381\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2403, Accuracy: 0.936, F1 Micro: 0.9601, F1 Macro: 0.9579\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1859, Accuracy: 0.939, F1 Micro: 0.9619, F1 Macro: 0.9597\n",
      "Epoch 8/10, Train Loss: 0.152, Accuracy: 0.939, F1 Micro: 0.9615, F1 Macro: 0.9581\n",
      "Epoch 9/10, Train Loss: 0.1232, Accuracy: 0.9301, F1 Micro: 0.9558, F1 Macro: 0.9512\n",
      "Epoch 10/10, Train Loss: 0.0984, Accuracy: 0.9345, F1 Micro: 0.959, F1 Macro: 0.9555\n",
      "\n",
      "Aspect detection accuracy: 0.939, F1 Micro: 0.9619, F1 Macro: 0.9597\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.94      0.96      0.95       175\n",
      "      others       0.89      0.91      0.90       158\n",
      "        part       0.92      0.97      0.95       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.95      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.95      0.98      0.96      1061\n",
      "   macro avg       0.95      0.97      0.96      1061\n",
      "weighted avg       0.95      0.98      0.96      1061\n",
      " samples avg       0.95      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5779, Accuracy: 0.6749, F1 Micro: 0.6749, F1 Macro: 0.4029\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3653, Accuracy: 0.8807, F1 Micro: 0.8807, F1 Macro: 0.8626\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2394, Accuracy: 0.9012, F1 Micro: 0.9012, F1 Macro: 0.8936\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.137, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9229\n",
      "Epoch 5/10, Train Loss: 0.154, Accuracy: 0.9177, F1 Micro: 0.9177, F1 Macro: 0.9056\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1153, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9215\n",
      "Epoch 7/10, Train Loss: 0.1328, Accuracy: 0.9095, F1 Micro: 0.9095, F1 Macro: 0.8931\n",
      "Epoch 8/10, Train Loss: 0.1184, Accuracy: 0.9259, F1 Micro: 0.9259, F1 Macro: 0.9161\n",
      "Epoch 9/10, Train Loss: 0.0626, Accuracy: 0.8971, F1 Micro: 0.8971, F1 Macro: 0.8761\n",
      "Epoch 10/10, Train Loss: 0.0794, Accuracy: 0.9177, F1 Micro: 0.9177, F1 Macro: 0.9049\n",
      "\n",
      "Sentiment analysis accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9215\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.92      0.90        79\n",
      "    positive       0.96      0.93      0.95       164\n",
      "\n",
      "    accuracy                           0.93       243\n",
      "   macro avg       0.92      0.93      0.92       243\n",
      "weighted avg       0.93      0.93      0.93       243\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 334: Accuracy: 0.9174, F1 Micro: 0.9174, F1 Macro: 0.8317\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.94      0.96      0.95       167\n",
      "    positive       0.77      0.70      0.73        33\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.86      0.82      0.84       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.32      0.92      0.48        12\n",
      "     neutral       0.95      0.82      0.88       152\n",
      "    positive       0.74      0.71      0.73        52\n",
      "\n",
      "    accuracy                           0.80       216\n",
      "   macro avg       0.67      0.82      0.69       216\n",
      "weighted avg       0.86      0.80      0.82       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.70      0.73        23\n",
      "     neutral       0.93      0.97      0.95       152\n",
      "    positive       0.77      0.66      0.71        41\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.82      0.78      0.80       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.89      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.64      0.64        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       0.79      0.65      0.71        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.80      0.76      0.78       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Total train time: 90.37879252433777 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.008384198881685734\n",
      "Acquired samples: 54\n",
      "Sampling duration: 13.639129400253296 seconds\n",
      "New train size: 388\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5535, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.488, Accuracy: 0.7999, F1 Micro: 0.8875, F1 Macro: 0.886\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4226, Accuracy: 0.8259, F1 Micro: 0.8979, F1 Macro: 0.8946\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3509, Accuracy: 0.9033, F1 Micro: 0.9403, F1 Macro: 0.9373\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2549, Accuracy: 0.9375, F1 Micro: 0.9612, F1 Macro: 0.9596\n",
      "Epoch 6/10, Train Loss: 0.1947, Accuracy: 0.936, F1 Micro: 0.9598, F1 Macro: 0.957\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.152, Accuracy: 0.942, F1 Micro: 0.9632, F1 Macro: 0.9598\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1121, Accuracy: 0.9509, F1 Micro: 0.9692, F1 Macro: 0.9672\n",
      "Epoch 9/10, Train Loss: 0.0989, Accuracy: 0.9509, F1 Micro: 0.969, F1 Macro: 0.9664\n",
      "Epoch 10/10, Train Loss: 0.0814, Accuracy: 0.9487, F1 Micro: 0.9675, F1 Macro: 0.9647\n",
      "\n",
      "Aspect detection accuracy: 0.9509, F1 Micro: 0.9692, F1 Macro: 0.9672\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.97      0.96       175\n",
      "      others       0.92      0.91      0.92       158\n",
      "        part       0.92      0.99      0.95       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5692, Accuracy: 0.8386, F1 Micro: 0.8386, F1 Macro: 0.8182\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3537, Accuracy: 0.9016, F1 Micro: 0.9016, F1 Macro: 0.8922\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1878, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.9044\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2055, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9126\n",
      "Epoch 5/10, Train Loss: 0.103, Accuracy: 0.8898, F1 Micro: 0.8898, F1 Macro: 0.8813\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1209, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9176\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1222, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9136\n",
      "Epoch 8/10, Train Loss: 0.0743, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9105\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1025, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9213\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0596, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9293\n",
      "\n",
      "Sentiment analysis accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9293\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.94      0.91        82\n",
      "    positive       0.97      0.94      0.95       172\n",
      "\n",
      "    accuracy                           0.94       254\n",
      "   macro avg       0.92      0.94      0.93       254\n",
      "weighted avg       0.94      0.94      0.94       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 388: Accuracy: 0.9321, F1 Micro: 0.9321, F1 Macro: 0.8701\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.88      0.82        16\n",
      "     neutral       0.95      0.96      0.96       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.85      0.86      0.86       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.34      0.83      0.49        12\n",
      "     neutral       0.95      0.84      0.89       152\n",
      "    positive       0.77      0.77      0.77        52\n",
      "\n",
      "    accuracy                           0.82       216\n",
      "   macro avg       0.69      0.81      0.72       216\n",
      "weighted avg       0.87      0.82      0.84       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.68      0.91      0.78        23\n",
      "     neutral       0.95      0.99      0.97       152\n",
      "    positive       0.96      0.63      0.76        41\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.86      0.84      0.84       216\n",
      "weighted avg       0.92      0.91      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.98       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.89      0.94      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 104.52301692962646 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.006748074386268854\n",
      "Acquired samples: 48\n",
      "Sampling duration: 12.991333961486816 seconds\n",
      "New train size: 436\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5465, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.483, Accuracy: 0.8021, F1 Micro: 0.8886, F1 Macro: 0.8872\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4272, Accuracy: 0.8542, F1 Micro: 0.9134, F1 Macro: 0.911\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3314, Accuracy: 0.9137, F1 Micro: 0.9462, F1 Macro: 0.9428\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2484, Accuracy: 0.9397, F1 Micro: 0.9623, F1 Macro: 0.9604\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1914, Accuracy: 0.9479, F1 Micro: 0.9675, F1 Macro: 0.9658\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1524, Accuracy: 0.9561, F1 Micro: 0.9724, F1 Macro: 0.9709\n",
      "Epoch 8/10, Train Loss: 0.1132, Accuracy: 0.9479, F1 Micro: 0.967, F1 Macro: 0.9636\n",
      "Epoch 9/10, Train Loss: 0.0972, Accuracy: 0.9546, F1 Micro: 0.9713, F1 Macro: 0.969\n",
      "Epoch 10/10, Train Loss: 0.0767, Accuracy: 0.9539, F1 Micro: 0.9709, F1 Macro: 0.9684\n",
      "\n",
      "Aspect detection accuracy: 0.9561, F1 Micro: 0.9724, F1 Macro: 0.9709\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.97      0.97       175\n",
      "      others       0.90      0.95      0.93       158\n",
      "        part       0.97      0.96      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5657, Accuracy: 0.821, F1 Micro: 0.821, F1 Macro: 0.78\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3212, Accuracy: 0.8833, F1 Micro: 0.8833, F1 Macro: 0.8736\n",
      "Epoch 3/10, Train Loss: 0.2192, Accuracy: 0.8599, F1 Micro: 0.8599, F1 Macro: 0.8497\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1276, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9204\n",
      "Epoch 5/10, Train Loss: 0.1569, Accuracy: 0.8872, F1 Micro: 0.8872, F1 Macro: 0.877\n",
      "Epoch 6/10, Train Loss: 0.1207, Accuracy: 0.9105, F1 Micro: 0.9105, F1 Macro: 0.8953\n",
      "Epoch 7/10, Train Loss: 0.1211, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.9039\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.08, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9172\n",
      "Epoch 9/10, Train Loss: 0.0778, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9141\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0701, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9204\n",
      "\n",
      "Sentiment analysis accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9204\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.94      0.89        80\n",
      "    positive       0.97      0.93      0.95       177\n",
      "\n",
      "    accuracy                           0.93       257\n",
      "   macro avg       0.91      0.93      0.92       257\n",
      "weighted avg       0.93      0.93      0.93       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 436: Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.8804\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.96      0.97      0.96       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.87      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.33      0.92      0.49        12\n",
      "     neutral       0.96      0.86      0.91       152\n",
      "    positive       0.85      0.75      0.80        52\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.71      0.84      0.73       216\n",
      "weighted avg       0.90      0.84      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.91      0.82        23\n",
      "     neutral       0.97      0.96      0.96       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.91      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.89      0.94      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 102.71657609939575 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.005115563608705997\n",
      "Acquired samples: 43\n",
      "Sampling duration: 11.546639204025269 seconds\n",
      "New train size: 479\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.562, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.485, Accuracy: 0.8058, F1 Micro: 0.8905, F1 Macro: 0.889\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4114, Accuracy: 0.8571, F1 Micro: 0.9125, F1 Macro: 0.9066\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3068, Accuracy: 0.9249, F1 Micro: 0.9531, F1 Macro: 0.9506\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2165, Accuracy: 0.942, F1 Micro: 0.964, F1 Macro: 0.9621\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1784, Accuracy: 0.9449, F1 Micro: 0.9656, F1 Macro: 0.9635\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1307, Accuracy: 0.9531, F1 Micro: 0.9704, F1 Macro: 0.9681\n",
      "Epoch 8/10, Train Loss: 0.1078, Accuracy: 0.9524, F1 Micro: 0.9701, F1 Macro: 0.968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0906, Accuracy: 0.9554, F1 Micro: 0.972, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0701, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9721\n",
      "\n",
      "Aspect detection accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9721\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.90      0.95      0.92       158\n",
      "        part       0.97      0.97      0.97       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5626, Accuracy: 0.8071, F1 Micro: 0.8071, F1 Macro: 0.7551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2761, Accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.9069\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1936, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9195\n",
      "Epoch 4/10, Train Loss: 0.1685, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9135\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1222, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9237\n",
      "Epoch 6/10, Train Loss: 0.1278, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9126\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1139, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9275\n",
      "Epoch 8/10, Train Loss: 0.079, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9213\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0757, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9377\n",
      "Epoch 10/10, Train Loss: 0.0536, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9322\n",
      "\n",
      "Sentiment analysis accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9377\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.95      0.92        81\n",
      "    positive       0.98      0.94      0.96       173\n",
      "\n",
      "    accuracy                           0.94       254\n",
      "   macro avg       0.93      0.95      0.94       254\n",
      "weighted avg       0.95      0.94      0.95       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 479: Accuracy: 0.9491, F1 Micro: 0.9491, F1 Macro: 0.8964\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.98      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.88      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.87      0.86      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.67      0.76        12\n",
      "     neutral       0.90      0.95      0.92       152\n",
      "    positive       0.83      0.75      0.79        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.87      0.79      0.82       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.93      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.87      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.93      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 109.68605828285217 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.004992398200556636\n",
      "Acquired samples: 39\n",
      "Sampling duration: 10.792297124862671 seconds\n",
      "New train size: 518\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5456, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4733, Accuracy: 0.8147, F1 Micro: 0.8937, F1 Macro: 0.8918\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3808, Accuracy: 0.8958, F1 Micro: 0.936, F1 Macro: 0.9327\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2702, Accuracy: 0.9338, F1 Micro: 0.9586, F1 Macro: 0.9564\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1966, Accuracy: 0.9442, F1 Micro: 0.9651, F1 Macro: 0.9628\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1484, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9742\n",
      "Epoch 7/10, Train Loss: 0.1169, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9713\n",
      "Epoch 8/10, Train Loss: 0.0954, Accuracy: 0.9554, F1 Micro: 0.9719, F1 Macro: 0.9695\n",
      "Epoch 9/10, Train Loss: 0.0805, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.972\n",
      "Epoch 10/10, Train Loss: 0.0654, Accuracy: 0.9561, F1 Micro: 0.9724, F1 Macro: 0.9705\n",
      "\n",
      "Aspect detection accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9742\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.91      0.96      0.94       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.97      1061\n",
      "weighted avg       0.96      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5433, Accuracy: 0.8664, F1 Micro: 0.8664, F1 Macro: 0.8414\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2871, Accuracy: 0.8988, F1 Micro: 0.8988, F1 Macro: 0.8899\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1722, Accuracy: 0.9312, F1 Micro: 0.9312, F1 Macro: 0.9195\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1291, Accuracy: 0.9393, F1 Micro: 0.9393, F1 Macro: 0.9322\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0781, Accuracy: 0.9433, F1 Micro: 0.9433, F1 Macro: 0.9349\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1112, Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.9452\n",
      "Epoch 7/10, Train Loss: 0.0693, Accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9408\n",
      "Epoch 8/10, Train Loss: 0.0806, Accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9405\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0505, Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.9445\n",
      "Epoch 10/10, Train Loss: 0.0428, Accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9405\n",
      "\n",
      "Sentiment analysis accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.9445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.94      0.92        79\n",
      "    positive       0.97      0.96      0.96       168\n",
      "\n",
      "    accuracy                           0.95       247\n",
      "   macro avg       0.94      0.95      0.94       247\n",
      "weighted avg       0.95      0.95      0.95       247\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 518: Accuracy: 0.946, F1 Micro: 0.946, F1 Macro: 0.8924\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.85      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.44      0.92      0.59        12\n",
      "     neutral       0.94      0.90      0.92       152\n",
      "    positive       0.89      0.79      0.84        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.76      0.87      0.78       216\n",
      "weighted avg       0.90      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.87      0.80        23\n",
      "     neutral       0.96      0.98      0.97       152\n",
      "    positive       0.94      0.78      0.85        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.88      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.98       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 110.66945338249207 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.004527782835066319\n",
      "Acquired samples: 22\n",
      "Sampling duration: 9.658899545669556 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5481, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4598, Accuracy: 0.8147, F1 Micro: 0.8926, F1 Macro: 0.8899\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3711, Accuracy: 0.8988, F1 Micro: 0.9373, F1 Macro: 0.9342\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2713, Accuracy: 0.9382, F1 Micro: 0.9613, F1 Macro: 0.9597\n",
      "Epoch 5/10, Train Loss: 0.2031, Accuracy: 0.936, F1 Micro: 0.9595, F1 Macro: 0.954\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1486, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1143, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.973\n",
      "Epoch 8/10, Train Loss: 0.0987, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0771, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9745\n",
      "Epoch 10/10, Train Loss: 0.0674, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9729\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9745\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.97      0.97       175\n",
      "      others       0.90      0.95      0.92       158\n",
      "        part       0.96      1.00      0.98       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.97      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5571, Accuracy: 0.88, F1 Micro: 0.88, F1 Macro: 0.8663\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2589, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9383\n",
      "Epoch 3/10, Train Loss: 0.1976, Accuracy: 0.916, F1 Micro: 0.916, F1 Macro: 0.9095\n",
      "Epoch 4/10, Train Loss: 0.1282, Accuracy: 0.916, F1 Micro: 0.916, F1 Macro: 0.9095\n",
      "Epoch 5/10, Train Loss: 0.1247, Accuracy: 0.932, F1 Micro: 0.932, F1 Macro: 0.926\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1021, Accuracy: 0.952, F1 Micro: 0.952, F1 Macro: 0.9471\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0954, Accuracy: 0.952, F1 Micro: 0.952, F1 Macro: 0.9465\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0864, Accuracy: 0.952, F1 Micro: 0.952, F1 Macro: 0.9465\n",
      "Epoch 9/10, Train Loss: 0.0636, Accuracy: 0.948, F1 Micro: 0.948, F1 Macro: 0.9405\n",
      "Epoch 10/10, Train Loss: 0.066, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9361\n",
      "\n",
      "Sentiment analysis accuracy: 0.952, F1 Micro: 0.952, F1 Macro: 0.9465\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93        83\n",
      "    positive       0.98      0.95      0.96       167\n",
      "\n",
      "    accuracy                           0.95       250\n",
      "   macro avg       0.94      0.95      0.95       250\n",
      "weighted avg       0.95      0.95      0.95       250\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9475, F1 Micro: 0.9475, F1 Macro: 0.8879\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.92      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.88      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.97      0.97      0.97       167\n",
      "    positive       0.85      0.85      0.85        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.90      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.44      0.92      0.59        12\n",
      "     neutral       0.95      0.91      0.93       152\n",
      "    positive       0.84      0.73      0.78        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.74      0.85      0.77       216\n",
      "weighted avg       0.89      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87        23\n",
      "     neutral       0.96      0.99      0.98       152\n",
      "    positive       0.92      0.80      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.89      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.87      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.93      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 110.72140216827393 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.0029448454733937983\n",
      "Acquired samples: 33\n",
      "Sampling duration: 9.282894611358643 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5366, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4634, Accuracy: 0.8207, F1 Micro: 0.8964, F1 Macro: 0.8946\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.373, Accuracy: 0.904, F1 Micro: 0.94, F1 Macro: 0.936\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2663, Accuracy: 0.9427, F1 Micro: 0.9641, F1 Macro: 0.9624\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1995, Accuracy: 0.9546, F1 Micro: 0.9717, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1488, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9732\n",
      "Epoch 7/10, Train Loss: 0.1169, Accuracy: 0.9554, F1 Micro: 0.9721, F1 Macro: 0.9703\n",
      "Epoch 8/10, Train Loss: 0.0985, Accuracy: 0.9576, F1 Micro: 0.9732, F1 Macro: 0.9712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0773, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "Epoch 10/10, Train Loss: 0.0677, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9723\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.93      0.94      0.94       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5369, Accuracy: 0.8828, F1 Micro: 0.8828, F1 Macro: 0.8715\n",
      "Epoch 2/10, Train Loss: 0.2648, Accuracy: 0.8789, F1 Micro: 0.8789, F1 Macro: 0.8721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2026, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8956\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.132, Accuracy: 0.9141, F1 Micro: 0.9141, F1 Macro: 0.9071\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1532, Accuracy: 0.9141, F1 Micro: 0.9141, F1 Macro: 0.9067\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1363, Accuracy: 0.9258, F1 Micro: 0.9258, F1 Macro: 0.9175\n",
      "Epoch 7/10, Train Loss: 0.1071, Accuracy: 0.918, F1 Micro: 0.918, F1 Macro: 0.9093\n",
      "Epoch 8/10, Train Loss: 0.0813, Accuracy: 0.9102, F1 Micro: 0.9102, F1 Macro: 0.9031\n",
      "Epoch 9/10, Train Loss: 0.0845, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8952\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0833, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9249\n",
      "\n",
      "Sentiment analysis accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9249\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.89      0.90        85\n",
      "    positive       0.95      0.95      0.95       171\n",
      "\n",
      "    accuracy                           0.93       256\n",
      "   macro avg       0.93      0.92      0.92       256\n",
      "weighted avg       0.93      0.93      0.93       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.946, F1 Micro: 0.946, F1 Macro: 0.886\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.73      0.80        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.84      0.88      0.86        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.87      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.85      0.70      0.77        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.83      0.86       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.83      0.62        12\n",
      "     neutral       0.95      0.91      0.93       152\n",
      "    positive       0.82      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.76      0.84      0.79       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.91      0.86        23\n",
      "     neutral       0.96      0.97      0.96       152\n",
      "    positive       0.92      0.83      0.87        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.90      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 116.55976104736328 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.00426389086060226\n",
      "Acquired samples: 30\n",
      "Sampling duration: 8.37942361831665 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5454, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4536, Accuracy: 0.8251, F1 Micro: 0.8988, F1 Macro: 0.8968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3422, Accuracy: 0.9278, F1 Micro: 0.9556, F1 Macro: 0.9536\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2394, Accuracy: 0.9501, F1 Micro: 0.9688, F1 Macro: 0.9671\n",
      "Epoch 5/10, Train Loss: 0.1726, Accuracy: 0.9494, F1 Micro: 0.9683, F1 Macro: 0.9662\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1356, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1102, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.975\n",
      "Epoch 8/10, Train Loss: 0.0911, Accuracy: 0.9554, F1 Micro: 0.9719, F1 Macro: 0.9699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0737, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0602, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.96      0.99      0.97       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4984, Accuracy: 0.8906, F1 Micro: 0.8906, F1 Macro: 0.8818\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2587, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.93\n",
      "Epoch 3/10, Train Loss: 0.1661, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8947\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1225, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9387\n",
      "Epoch 5/10, Train Loss: 0.1428, Accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.8991\n",
      "Epoch 6/10, Train Loss: 0.105, Accuracy: 0.9258, F1 Micro: 0.9258, F1 Macro: 0.9139\n",
      "Epoch 7/10, Train Loss: 0.0861, Accuracy: 0.9297, F1 Micro: 0.9297, F1 Macro: 0.9212\n",
      "Epoch 8/10, Train Loss: 0.0724, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9287\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0683, Accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9433\n",
      "Epoch 10/10, Train Loss: 0.0463, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9249\n",
      "\n",
      "Sentiment analysis accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9433\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.96      0.92        83\n",
      "    positive       0.98      0.94      0.96       173\n",
      "\n",
      "    accuracy                           0.95       256\n",
      "   macro avg       0.94      0.95      0.94       256\n",
      "weighted avg       0.95      0.95      0.95       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9058\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.82      0.86        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.88      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.90      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.87      0.86      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.85      0.79      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.87      0.83      0.85       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.96      0.99      0.97       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.91      0.91       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 117.25057721138 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.003615477913990617\n",
      "Acquired samples: 27\n",
      "Sampling duration: 7.5480797290802 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5448, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.448, Accuracy: 0.8244, F1 Micro: 0.8982, F1 Macro: 0.8964\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3288, Accuracy: 0.9226, F1 Micro: 0.9518, F1 Macro: 0.9487\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2343, Accuracy: 0.9494, F1 Micro: 0.9686, F1 Macro: 0.9671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1746, Accuracy: 0.9568, F1 Micro: 0.9731, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1321, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0998, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9756\n",
      "Epoch 8/10, Train Loss: 0.0728, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0617, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0568, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.976\n",
      "\n",
      "Aspect detection accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.93      0.92      0.93       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5247, Accuracy: 0.9035, F1 Micro: 0.9035, F1 Macro: 0.8933\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2576, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9353\n",
      "Epoch 3/10, Train Loss: 0.1943, Accuracy: 0.9035, F1 Micro: 0.9035, F1 Macro: 0.8968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1302, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9401\n",
      "Epoch 5/10, Train Loss: 0.1157, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9241\n",
      "Epoch 6/10, Train Loss: 0.1446, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9366\n",
      "Epoch 7/10, Train Loss: 0.084, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9312\n",
      "Epoch 8/10, Train Loss: 0.0948, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.936\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0657, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9398\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0503, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9398\n",
      "\n",
      "Sentiment analysis accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9398\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        86\n",
      "    positive       0.97      0.95      0.96       173\n",
      "\n",
      "    accuracy                           0.95       259\n",
      "   macro avg       0.94      0.94      0.94       259\n",
      "weighted avg       0.95      0.95      0.95       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9122\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.99      0.97       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.88      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.93      0.92      0.93       152\n",
      "    positive       0.77      0.79      0.78        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.83      0.85      0.84       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.96      0.99      0.97       152\n",
      "    positive       0.97      0.76      0.85        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.94      0.92      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.88      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 124.24188232421875 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.003935916163027286\n",
      "Acquired samples: 18\n",
      "Sampling duration: 6.947122097015381 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5379, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.441, Accuracy: 0.846, F1 Micro: 0.9089, F1 Macro: 0.9068\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3227, Accuracy: 0.9301, F1 Micro: 0.9566, F1 Macro: 0.9542\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2167, Accuracy: 0.9561, F1 Micro: 0.9728, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.156, Accuracy: 0.9583, F1 Micro: 0.974, F1 Macro: 0.9726\n",
      "Epoch 6/10, Train Loss: 0.1127, Accuracy: 0.9539, F1 Micro: 0.9709, F1 Macro: 0.9688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0952, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9754\n",
      "Epoch 8/10, Train Loss: 0.0748, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.975\n",
      "Epoch 9/10, Train Loss: 0.0638, Accuracy: 0.9613, F1 Micro: 0.9755, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.051, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9765\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.94      0.92      0.93       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5314, Accuracy: 0.8958, F1 Micro: 0.8958, F1 Macro: 0.8875\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2838, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9304\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.173, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9326\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.13, Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9445\n",
      "Epoch 5/10, Train Loss: 0.1087, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9391\n",
      "Epoch 6/10, Train Loss: 0.0933, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9315\n",
      "Epoch 7/10, Train Loss: 0.0936, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9353\n",
      "Epoch 8/10, Train Loss: 0.0644, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9262\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0812, Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9445\n",
      "Epoch 10/10, Train Loss: 0.0582, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9333\n",
      "\n",
      "Sentiment analysis accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.97      0.93        86\n",
      "    positive       0.98      0.94      0.96       173\n",
      "\n",
      "    accuracy                           0.95       259\n",
      "   macro avg       0.94      0.95      0.94       259\n",
      "weighted avg       0.95      0.95      0.95       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9095\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.87      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.75      0.86        12\n",
      "     neutral       0.94      0.93      0.93       152\n",
      "    positive       0.77      0.85      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.90      0.84      0.87       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.87      0.89        23\n",
      "     neutral       0.96      0.99      0.98       152\n",
      "    positive       0.89      0.80      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.89      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 126.41263914108276 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.002108126599341631\n",
      "Acquired samples: 25\n",
      "Sampling duration: 6.4610021114349365 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.533, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4261, Accuracy: 0.8631, F1 Micro: 0.9184, F1 Macro: 0.9158\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2923, Accuracy: 0.9353, F1 Micro: 0.9597, F1 Macro: 0.9577\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2008, Accuracy: 0.9568, F1 Micro: 0.9731, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1477, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9721\n",
      "Epoch 6/10, Train Loss: 0.1158, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0906, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0689, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0576, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.977\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0534, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9772\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9772\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.96      0.98      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5146, Accuracy: 0.8803, F1 Micro: 0.8803, F1 Macro: 0.8677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2509, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9274\n",
      "Epoch 3/10, Train Loss: 0.2055, Accuracy: 0.8996, F1 Micro: 0.8996, F1 Macro: 0.8808\n",
      "Epoch 4/10, Train Loss: 0.1359, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9201\n",
      "Epoch 5/10, Train Loss: 0.1326, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9205\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1291, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9308\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0555, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9398\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0721, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9398\n",
      "Epoch 9/10, Train Loss: 0.0643, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9345\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0682, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9404\n",
      "\n",
      "Sentiment analysis accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9404\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.97      0.92        86\n",
      "    positive       0.98      0.94      0.96       173\n",
      "\n",
      "    accuracy                           0.95       259\n",
      "   macro avg       0.93      0.95      0.94       259\n",
      "weighted avg       0.95      0.95      0.95       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.9237\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.90      0.82      0.86        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.83      0.77      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.89      0.85      0.87       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.96      0.98      0.97       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.92      0.91       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 132.44250178337097 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.0023875507060438397\n",
      "Acquired samples: 25\n",
      "Sampling duration: 6.034027814865112 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5263, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4495, Accuracy: 0.8668, F1 Micro: 0.9203, F1 Macro: 0.9178\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3115, Accuracy: 0.9427, F1 Micro: 0.9646, F1 Macro: 0.9631\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2164, Accuracy: 0.9554, F1 Micro: 0.9721, F1 Macro: 0.9708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1536, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1188, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0908, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0737, Accuracy: 0.9665, F1 Micro: 0.9791, F1 Macro: 0.9781\n",
      "Epoch 9/10, Train Loss: 0.0662, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9746\n",
      "Epoch 10/10, Train Loss: 0.0536, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9765\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9791, F1 Macro: 0.9781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.98       175\n",
      "      others       0.90      0.99      0.94       158\n",
      "        part       0.96      0.99      0.97       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5093, Accuracy: 0.9024, F1 Micro: 0.9024, F1 Macro: 0.8963\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.231, Accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.9417\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1719, Accuracy: 0.9553, F1 Micro: 0.9553, F1 Macro: 0.9504\n",
      "Epoch 4/10, Train Loss: 0.1373, Accuracy: 0.9512, F1 Micro: 0.9512, F1 Macro: 0.9458\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1041, Accuracy: 0.9593, F1 Micro: 0.9593, F1 Macro: 0.9551\n",
      "Epoch 6/10, Train Loss: 0.1018, Accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.9421\n",
      "Epoch 7/10, Train Loss: 0.074, Accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.9421\n",
      "Epoch 8/10, Train Loss: 0.0779, Accuracy: 0.939, F1 Micro: 0.939, F1 Macro: 0.9331\n",
      "Epoch 9/10, Train Loss: 0.0616, Accuracy: 0.9512, F1 Micro: 0.9512, F1 Macro: 0.9461\n",
      "Epoch 10/10, Train Loss: 0.0671, Accuracy: 0.9553, F1 Micro: 0.9553, F1 Macro: 0.9507\n",
      "\n",
      "Sentiment analysis accuracy: 0.9593, F1 Micro: 0.9593, F1 Macro: 0.9551\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94        82\n",
      "    positive       0.99      0.95      0.97       164\n",
      "\n",
      "    accuracy                           0.96       246\n",
      "   macro avg       0.95      0.96      0.96       246\n",
      "weighted avg       0.96      0.96      0.96       246\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9041\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.97      0.98      0.98       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.53      0.67      0.59        12\n",
      "     neutral       0.91      0.96      0.93       152\n",
      "    positive       0.95      0.73      0.83        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.80      0.79      0.78       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      1.00      0.85        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.92      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.87      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 127.50185322761536 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.0022491718642413615\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.247146844863892 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5245, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4184, Accuracy: 0.8884, F1 Micro: 0.9328, F1 Macro: 0.9304\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2795, Accuracy: 0.9524, F1 Micro: 0.9705, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1938, Accuracy: 0.9576, F1 Micro: 0.9736, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1414, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9765\n",
      "Epoch 6/10, Train Loss: 0.1046, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9743\n",
      "Epoch 7/10, Train Loss: 0.0821, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9748\n",
      "Epoch 8/10, Train Loss: 0.0712, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9717\n",
      "Epoch 9/10, Train Loss: 0.057, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0483, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9791\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9791\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.93      0.96      0.94       158\n",
      "        part       0.96      0.99      0.97       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4804, Accuracy: 0.898, F1 Micro: 0.898, F1 Macro: 0.891\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2723, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9238\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1851, Accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.9435\n",
      "Epoch 4/10, Train Loss: 0.1647, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9358\n",
      "Epoch 5/10, Train Loss: 0.0977, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.934\n",
      "Epoch 6/10, Train Loss: 0.0703, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9344\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0778, Accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.9438\n",
      "Epoch 8/10, Train Loss: 0.0635, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9332\n",
      "Epoch 9/10, Train Loss: 0.0711, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9306\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0603, Accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.944\n",
      "\n",
      "Sentiment analysis accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.944\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.97      0.93        86\n",
      "    positive       0.98      0.94      0.96       169\n",
      "\n",
      "    accuracy                           0.95       255\n",
      "   macro avg       0.94      0.95      0.94       255\n",
      "weighted avg       0.95      0.95      0.95       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9216\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.99      0.97       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.88      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.93      0.96      0.94       152\n",
      "    positive       0.85      0.79      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.87      0.83      0.85       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.96      0.99      0.97       152\n",
      "    positive       0.97      0.76      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.91      0.91       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 129.6241431236267 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.002762408694252372\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.5711870193481445 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5381, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4217, Accuracy: 0.8936, F1 Micro: 0.9361, F1 Macro: 0.9344\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.284, Accuracy: 0.9368, F1 Micro: 0.9609, F1 Macro: 0.9588\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1821, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1422, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1081, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.978\n",
      "Epoch 7/10, Train Loss: 0.0808, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0713, Accuracy: 0.9695, F1 Micro: 0.9809, F1 Macro: 0.9798\n",
      "Epoch 9/10, Train Loss: 0.0587, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.977\n",
      "Epoch 10/10, Train Loss: 0.0498, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9775\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9809, F1 Macro: 0.9798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.91      0.98      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5122, Accuracy: 0.881, F1 Micro: 0.881, F1 Macro: 0.8757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2179, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9274\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1592, Accuracy: 0.9603, F1 Micro: 0.9603, F1 Macro: 0.9563\n",
      "Epoch 4/10, Train Loss: 0.1561, Accuracy: 0.8929, F1 Micro: 0.8929, F1 Macro: 0.8875\n",
      "Epoch 5/10, Train Loss: 0.1152, Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9382\n",
      "Epoch 6/10, Train Loss: 0.1053, Accuracy: 0.9524, F1 Micro: 0.9524, F1 Macro: 0.9479\n",
      "Epoch 7/10, Train Loss: 0.085, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9271\n",
      "Epoch 8/10, Train Loss: 0.0797, Accuracy: 0.9524, F1 Micro: 0.9524, F1 Macro: 0.9473\n",
      "Epoch 9/10, Train Loss: 0.0708, Accuracy: 0.9524, F1 Micro: 0.9524, F1 Macro: 0.9467\n",
      "Epoch 10/10, Train Loss: 0.0536, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.923\n",
      "\n",
      "Sentiment analysis accuracy: 0.9603, F1 Micro: 0.9603, F1 Macro: 0.9563\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.97      0.94        86\n",
      "    positive       0.98      0.96      0.97       166\n",
      "\n",
      "    accuracy                           0.96       252\n",
      "   macro avg       0.95      0.96      0.96       252\n",
      "weighted avg       0.96      0.96      0.96       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.8926\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.89      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.38      0.83      0.53        12\n",
      "     neutral       0.95      0.93      0.94       152\n",
      "    positive       0.93      0.73      0.82        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.75      0.83      0.76       216\n",
      "weighted avg       0.91      0.88      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.73      0.83        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.91      0.89       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.92      0.83        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 130.3197009563446 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.002411093469709158\n",
      "Acquired samples: 8\n",
      "Sampling duration: 4.004137277603149 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5355, Accuracy: 0.7946, F1 Micro: 0.8849, F1 Macro: 0.8834\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4164, Accuracy: 0.8862, F1 Micro: 0.9307, F1 Macro: 0.928\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2757, Accuracy: 0.9568, F1 Micro: 0.9732, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1913, Accuracy: 0.9613, F1 Micro: 0.9759, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1333, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9795\n",
      "Epoch 6/10, Train Loss: 0.1008, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9758\n",
      "Epoch 7/10, Train Loss: 0.0849, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9732\n",
      "Epoch 8/10, Train Loss: 0.0658, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9792\n",
      "Epoch 9/10, Train Loss: 0.0602, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0517, Accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9794\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9794\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.98       175\n",
      "      others       0.93      0.94      0.94       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5089, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9208\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2491, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9259\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1713, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9263\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1513, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9374\n",
      "Epoch 5/10, Train Loss: 0.1302, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.9298\n",
      "Epoch 6/10, Train Loss: 0.0965, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9334\n",
      "Epoch 7/10, Train Loss: 0.1044, Accuracy: 0.9254, F1 Micro: 0.9254, F1 Macro: 0.9172\n",
      "Epoch 8/10, Train Loss: 0.0899, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9255\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0608, Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9498\n",
      "Epoch 10/10, Train Loss: 0.0418, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9259\n",
      "\n",
      "Sentiment analysis accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9498\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.93        87\n",
      "    positive       0.98      0.95      0.97       181\n",
      "\n",
      "    accuracy                           0.96       268\n",
      "   macro avg       0.94      0.96      0.95       268\n",
      "weighted avg       0.96      0.96      0.96       268\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.9172\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.83      0.89        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.97      0.98      0.98       167\n",
      "    positive       0.88      0.85      0.86        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.93      0.94      0.94       152\n",
      "    positive       0.80      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.86      0.85      0.86       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      1.00      0.85        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.94      0.78      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.92      0.89       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 135.06111884117126 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0021861907560378315\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.83998703956604 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5248, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.408, Accuracy: 0.9129, F1 Micro: 0.9467, F1 Macro: 0.9444\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2681, Accuracy: 0.9524, F1 Micro: 0.9705, F1 Macro: 0.9688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1771, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.126, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0918, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9786\n",
      "Epoch 7/10, Train Loss: 0.0815, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9775\n",
      "Epoch 8/10, Train Loss: 0.0651, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0548, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9796\n",
      "Epoch 10/10, Train Loss: 0.0442, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9778\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9796\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4753, Accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.9106\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2368, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9265\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1646, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9306\n",
      "Epoch 4/10, Train Loss: 0.151, Accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.9167\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1063, Accuracy: 0.9535, F1 Micro: 0.9535, F1 Macro: 0.9477\n",
      "Epoch 6/10, Train Loss: 0.0876, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9358\n",
      "Epoch 7/10, Train Loss: 0.0683, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9314\n",
      "Epoch 8/10, Train Loss: 0.0712, Accuracy: 0.9457, F1 Micro: 0.9457, F1 Macro: 0.9396\n",
      "Epoch 9/10, Train Loss: 0.0723, Accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.9148\n",
      "Epoch 10/10, Train Loss: 0.0476, Accuracy: 0.907, F1 Micro: 0.907, F1 Macro: 0.8976\n",
      "\n",
      "Sentiment analysis accuracy: 0.9535, F1 Micro: 0.9535, F1 Macro: 0.9477\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        86\n",
      "    positive       0.97      0.97      0.97       172\n",
      "\n",
      "    accuracy                           0.95       258\n",
      "   macro avg       0.95      0.95      0.95       258\n",
      "weighted avg       0.95      0.95      0.95       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9483, F1 Micro: 0.9483, F1 Macro: 0.8796\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.82      0.86        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.92      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.81      0.70        16\n",
      "     neutral       0.98      0.98      0.98       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.82      0.84      0.82       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.57      0.67      0.62        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.80      0.77      0.78        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.77      0.79      0.78       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.76      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.91      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 136.9604091644287 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.002631179336458445\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.045605421066284 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.526, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4046, Accuracy: 0.8988, F1 Micro: 0.9385, F1 Macro: 0.9364\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.261, Accuracy: 0.9568, F1 Micro: 0.9732, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1745, Accuracy: 0.9583, F1 Micro: 0.9741, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1242, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1074, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9771\n",
      "Epoch 7/10, Train Loss: 0.0828, Accuracy: 0.9591, F1 Micro: 0.9741, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0648, Accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9796\n",
      "Epoch 9/10, Train Loss: 0.0547, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9763\n",
      "Epoch 10/10, Train Loss: 0.0463, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9771\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9796\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.97      0.97       175\n",
      "      others       0.94      0.95      0.95       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4839, Accuracy: 0.9101, F1 Micro: 0.9101, F1 Macro: 0.902\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2031, Accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.9078\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1558, Accuracy: 0.9288, F1 Micro: 0.9288, F1 Macro: 0.9222\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1288, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9246\n",
      "Epoch 5/10, Train Loss: 0.1281, Accuracy: 0.9288, F1 Micro: 0.9288, F1 Macro: 0.921\n",
      "Epoch 6/10, Train Loss: 0.0716, Accuracy: 0.9251, F1 Micro: 0.9251, F1 Macro: 0.9137\n",
      "Epoch 7/10, Train Loss: 0.0922, Accuracy: 0.9288, F1 Micro: 0.9288, F1 Macro: 0.921\n",
      "Epoch 8/10, Train Loss: 0.0452, Accuracy: 0.9288, F1 Micro: 0.9288, F1 Macro: 0.9206\n",
      "Epoch 9/10, Train Loss: 0.0631, Accuracy: 0.9288, F1 Micro: 0.9288, F1 Macro: 0.9218\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0517, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9258\n",
      "\n",
      "Sentiment analysis accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9258\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.97      0.90        87\n",
      "    positive       0.98      0.92      0.95       180\n",
      "\n",
      "    accuracy                           0.93       267\n",
      "   macro avg       0.92      0.94      0.93       267\n",
      "weighted avg       0.94      0.93      0.93       267\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9067\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.97      0.97      0.97       167\n",
      "    positive       0.84      0.82      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.89      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.53      0.83      0.65        12\n",
      "     neutral       0.95      0.91      0.93       152\n",
      "    positive       0.84      0.81      0.82        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.77      0.85      0.80       216\n",
      "weighted avg       0.90      0.88      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.97      0.98      0.97       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.92      0.91       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 140.41746282577515 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0017409669933840636\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.3974335193634033 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5297, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4046, Accuracy: 0.9234, F1 Micro: 0.9528, F1 Macro: 0.9509\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2558, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9735\n",
      "Epoch 4/10, Train Loss: 0.17, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1255, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9769\n",
      "Epoch 6/10, Train Loss: 0.1032, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9757\n",
      "Epoch 7/10, Train Loss: 0.0749, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0635, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9788\n",
      "Epoch 9/10, Train Loss: 0.0524, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9764\n",
      "Epoch 10/10, Train Loss: 0.0472, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9745\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9788\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.93      0.96      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4799, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9323\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2032, Accuracy: 0.9416, F1 Micro: 0.9416, F1 Macro: 0.9357\n",
      "Epoch 3/10, Train Loss: 0.1621, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9251\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1251, Accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9395\n",
      "Epoch 5/10, Train Loss: 0.1046, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9201\n",
      "Epoch 6/10, Train Loss: 0.0825, Accuracy: 0.9222, F1 Micro: 0.9222, F1 Macro: 0.9161\n",
      "Epoch 7/10, Train Loss: 0.0676, Accuracy: 0.9183, F1 Micro: 0.9183, F1 Macro: 0.9117\n",
      "Epoch 8/10, Train Loss: 0.095, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9268\n",
      "Epoch 9/10, Train Loss: 0.0854, Accuracy: 0.9183, F1 Micro: 0.9183, F1 Macro: 0.9117\n",
      "Epoch 10/10, Train Loss: 0.0609, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9275\n",
      "\n",
      "Sentiment analysis accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9395\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        86\n",
      "    positive       0.97      0.95      0.96       171\n",
      "\n",
      "    accuracy                           0.95       257\n",
      "   macro avg       0.94      0.94      0.94       257\n",
      "weighted avg       0.95      0.95      0.95       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.8996\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.86      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.38      0.83      0.53        12\n",
      "     neutral       0.94      0.89      0.92       152\n",
      "    positive       0.87      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.73      0.83      0.75       216\n",
      "weighted avg       0.90      0.86      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.94      0.78      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.92      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 135.04379558563232 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0024054209934547544\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.8147857189178467 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5171, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.39, Accuracy: 0.9308, F1 Micro: 0.9575, F1 Macro: 0.9561\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2463, Accuracy: 0.9546, F1 Micro: 0.9717, F1 Macro: 0.97\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1635, Accuracy: 0.9621, F1 Micro: 0.9764, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1248, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9776\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0902, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9776\n",
      "Epoch 7/10, Train Loss: 0.0772, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0619, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9787\n",
      "Epoch 9/10, Train Loss: 0.0489, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9767\n",
      "Epoch 10/10, Train Loss: 0.0414, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9781\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9787\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4854, Accuracy: 0.9186, F1 Micro: 0.9186, F1 Macro: 0.9102\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2521, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9314\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1872, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9306\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.124, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9321\n",
      "Epoch 5/10, Train Loss: 0.0935, Accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.9192\n",
      "Epoch 6/10, Train Loss: 0.0834, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9277\n",
      "Epoch 7/10, Train Loss: 0.0632, Accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.9196\n",
      "Epoch 8/10, Train Loss: 0.0632, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.9232\n",
      "Epoch 9/10, Train Loss: 0.0712, Accuracy: 0.9109, F1 Micro: 0.9109, F1 Macro: 0.8994\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0522, Accuracy: 0.9457, F1 Micro: 0.9457, F1 Macro: 0.9393\n",
      "\n",
      "Sentiment analysis accuracy: 0.9457, F1 Micro: 0.9457, F1 Macro: 0.9393\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        85\n",
      "    positive       0.97      0.95      0.96       173\n",
      "\n",
      "    accuracy                           0.95       258\n",
      "   macro avg       0.93      0.94      0.94       258\n",
      "weighted avg       0.95      0.95      0.95       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9175\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.96      0.97      0.97       167\n",
      "    positive       0.84      0.82      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.87      0.87      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.83      0.75      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.84      0.84      0.84       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.91       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 145.90650033950806 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0017806049203500153\n",
      "Acquired samples: 8\n",
      "Sampling duration: 1.0901432037353516 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5253, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.403, Accuracy: 0.9211, F1 Micro: 0.9517, F1 Macro: 0.9503\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2553, Accuracy: 0.9546, F1 Micro: 0.9718, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1604, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1282, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "Epoch 6/10, Train Loss: 0.0908, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0772, Accuracy: 0.9702, F1 Micro: 0.9814, F1 Macro: 0.9803\n",
      "Epoch 8/10, Train Loss: 0.0602, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0534, Accuracy: 0.971, F1 Micro: 0.9818, F1 Macro: 0.9808\n",
      "Epoch 10/10, Train Loss: 0.0442, Accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9801\n",
      "\n",
      "Aspect detection accuracy: 0.971, F1 Micro: 0.9818, F1 Macro: 0.9808\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.93      0.96      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5131, Accuracy: 0.8962, F1 Micro: 0.8962, F1 Macro: 0.8888\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.243, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9324\n",
      "Epoch 3/10, Train Loss: 0.1529, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9203\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1252, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9361\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1247, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9364\n",
      "Epoch 6/10, Train Loss: 0.098, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.9084\n",
      "Epoch 7/10, Train Loss: 0.0844, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9203\n",
      "Epoch 8/10, Train Loss: 0.0881, Accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.9131\n",
      "Epoch 9/10, Train Loss: 0.0811, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9268\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0528, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.935\n",
      "\n",
      "Sentiment analysis accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.935\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.92      0.91        86\n",
      "    positive       0.96      0.95      0.96       174\n",
      "\n",
      "    accuracy                           0.94       260\n",
      "   macro avg       0.93      0.94      0.94       260\n",
      "weighted avg       0.94      0.94      0.94       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.9101\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.92      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.88      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.99      0.98       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.88      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.92      0.73        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.89      0.79      0.84        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.81      0.88      0.83       216\n",
      "weighted avg       0.91      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.95      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 144.73267364501953 s\n",
      "Total runtime: 3116.49932718277 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[2], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f4faf5",
   "metadata": {
    "papermill": {
     "duration": 0.332669,
     "end_time": "2025-03-23T15:06:24.562201",
     "exception": false,
     "start_time": "2025-03-23T15:06:24.229532",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69b48bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 4\n",
      "Random seed: 3\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6456, Accuracy: 0.7865, F1 Micro: 0.8804, F1 Macro: 0.8788\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5639, Accuracy: 0.7894, F1 Micro: 0.8822, F1 Macro: 0.8807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5346, Accuracy: 0.7894, F1 Micro: 0.8822, F1 Macro: 0.8807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5259, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4788, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Epoch 6/10, Train Loss: 0.477, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 7/10, Train Loss: 0.4707, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4588, Accuracy: 0.7909, F1 Micro: 0.883, F1 Macro: 0.8814\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.4215, Accuracy: 0.7932, F1 Micro: 0.8839, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3936, Accuracy: 0.7976, F1 Micro: 0.8857, F1 Macro: 0.884\n",
      "\n",
      "Aspect detection accuracy: 0.7976, F1 Micro: 0.8857, F1 Macro: 0.884\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.78      1.00      0.88       175\n",
      "      others       0.76      0.96      0.84       158\n",
      "        part       0.71      1.00      0.83       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.80      0.99      0.89      1061\n",
      "   macro avg       0.80      0.99      0.88      1061\n",
      "weighted avg       0.80      0.99      0.89      1061\n",
      " samples avg       0.80      0.99      0.88      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7056, Accuracy: 0.44, F1 Micro: 0.44, F1 Macro: 0.4318\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5997, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5241, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5185, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.494, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4806, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4617, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.422, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3873, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2944, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "\n",
      "Sentiment analysis accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         4\n",
      "    positive       0.84      1.00      0.91        21\n",
      "\n",
      "    accuracy                           0.84        25\n",
      "   macro avg       0.42      0.50      0.46        25\n",
      "weighted avg       0.71      0.84      0.77        25\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.7948, F1 Micro: 0.7948, F1 Macro: 0.3169\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.78      1.00      0.87       167\n",
      "    positive       1.00      0.03      0.06        33\n",
      "\n",
      "    accuracy                           0.78       216\n",
      "   macro avg       0.59      0.34      0.31       216\n",
      "weighted avg       0.75      0.78      0.68       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.76      0.95      0.84       152\n",
      "    positive       0.54      0.25      0.34        52\n",
      "\n",
      "    accuracy                           0.73       216\n",
      "   macro avg       0.43      0.40      0.40       216\n",
      "weighted avg       0.66      0.73      0.68       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        23\n",
      "     neutral       0.70      1.00      0.83       152\n",
      "    positive       0.00      0.00      0.00        41\n",
      "\n",
      "    accuracy                           0.70       216\n",
      "   macro avg       0.23      0.33      0.28       216\n",
      "weighted avg       0.50      0.70      0.58       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 59.257739305496216 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.004583974834531546\n",
      "Acquired samples: 82\n",
      "Sampling duration: 13.658363819122314 seconds\n",
      "New train size: 136\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6153, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5348, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5414, Accuracy: 0.7917, F1 Micro: 0.8831, F1 Macro: 0.8815\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4788, Accuracy: 0.7932, F1 Micro: 0.8837, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4659, Accuracy: 0.7984, F1 Micro: 0.8838, F1 Macro: 0.8818\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4186, Accuracy: 0.7991, F1 Micro: 0.8849, F1 Macro: 0.883\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3801, Accuracy: 0.8162, F1 Micro: 0.8939, F1 Macro: 0.892\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3471, Accuracy: 0.8423, F1 Micro: 0.9072, F1 Macro: 0.9052\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3055, Accuracy: 0.8661, F1 Micro: 0.9194, F1 Macro: 0.9175\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2636, Accuracy: 0.8884, F1 Micro: 0.9321, F1 Macro: 0.93\n",
      "\n",
      "Aspect detection accuracy: 0.8884, F1 Micro: 0.9321, F1 Macro: 0.93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.96      0.98      0.97       187\n",
      "     machine       0.90      0.92      0.91       175\n",
      "      others       0.84      0.97      0.90       158\n",
      "        part       0.84      0.94      0.89       158\n",
      "       price       0.92      1.00      0.96       192\n",
      "     service       0.90      1.00      0.95       191\n",
      "\n",
      "   micro avg       0.90      0.97      0.93      1061\n",
      "   macro avg       0.90      0.97      0.93      1061\n",
      "weighted avg       0.90      0.97      0.93      1061\n",
      " samples avg       0.90      0.97      0.93      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4978, Accuracy: 0.7316, F1 Micro: 0.7316, F1 Macro: 0.4225\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3169, Accuracy: 0.7316, F1 Micro: 0.7316, F1 Macro: 0.4225\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.365, Accuracy: 0.7316, F1 Micro: 0.7316, F1 Macro: 0.4225\n",
      "Epoch 4/10, Train Loss: 0.316, Accuracy: 0.7211, F1 Micro: 0.7211, F1 Macro: 0.4366\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2623, Accuracy: 0.8211, F1 Micro: 0.8211, F1 Macro: 0.7356\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1749, Accuracy: 0.8842, F1 Micro: 0.8842, F1 Macro: 0.8561\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0848, Accuracy: 0.8947, F1 Micro: 0.8947, F1 Macro: 0.8643\n",
      "Epoch 8/10, Train Loss: 0.0578, Accuracy: 0.8737, F1 Micro: 0.8737, F1 Macro: 0.8448\n",
      "Epoch 9/10, Train Loss: 0.0887, Accuracy: 0.8789, F1 Micro: 0.8789, F1 Macro: 0.8504\n",
      "Epoch 10/10, Train Loss: 0.0397, Accuracy: 0.8263, F1 Micro: 0.8263, F1 Macro: 0.7363\n",
      "\n",
      "Sentiment analysis accuracy: 0.8947, F1 Micro: 0.8947, F1 Macro: 0.8643\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.78      0.80        51\n",
      "    positive       0.92      0.94      0.93       139\n",
      "\n",
      "    accuracy                           0.89       190\n",
      "   macro avg       0.87      0.86      0.86       190\n",
      "weighted avg       0.89      0.89      0.89       190\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 136: Accuracy: 0.8642, F1 Micro: 0.8642, F1 Macro: 0.6326\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.45      0.62        11\n",
      "     neutral       0.97      0.98      0.98       181\n",
      "    positive       0.74      0.83      0.78        24\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.76      0.79       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.12      0.21        16\n",
      "     neutral       0.90      0.92      0.91       167\n",
      "    positive       0.51      0.67      0.58        33\n",
      "\n",
      "    accuracy                           0.82       216\n",
      "   macro avg       0.69      0.57      0.57       216\n",
      "weighted avg       0.82      0.82      0.81       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.43      0.25      0.32        12\n",
      "     neutral       0.84      0.97      0.90       152\n",
      "    positive       0.86      0.58      0.69        52\n",
      "\n",
      "    accuracy                           0.83       216\n",
      "   macro avg       0.71      0.60      0.64       216\n",
      "weighted avg       0.82      0.83      0.82       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.22      0.36        23\n",
      "     neutral       0.84      0.94      0.89       152\n",
      "    positive       0.55      0.54      0.54        41\n",
      "\n",
      "    accuracy                           0.79       216\n",
      "   macro avg       0.80      0.56      0.60       216\n",
      "weighted avg       0.80      0.79      0.76       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.23      0.38        13\n",
      "     neutral       0.93      1.00      0.96       186\n",
      "    positive       0.75      0.53      0.62        17\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.89      0.59      0.65       216\n",
      "weighted avg       0.92      0.92      0.90       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.36      0.53        14\n",
      "     neutral       0.90      1.00      0.95       185\n",
      "    positive       0.40      0.12      0.18        17\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.77      0.49      0.55       216\n",
      "weighted avg       0.87      0.89      0.86       216\n",
      "\n",
      "Total train time: 75.28480887413025 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.013268014416098595\n",
      "Acquired samples: 73\n",
      "Sampling duration: 17.947221517562866 seconds\n",
      "New train size: 209\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6074, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5185, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5029, Accuracy: 0.7932, F1 Micro: 0.8841, F1 Macro: 0.8825\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4546, Accuracy: 0.8021, F1 Micro: 0.8869, F1 Macro: 0.8849\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4157, Accuracy: 0.817, F1 Micro: 0.8943, F1 Macro: 0.8924\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3683, Accuracy: 0.8504, F1 Micro: 0.9116, F1 Macro: 0.9096\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3175, Accuracy: 0.8876, F1 Micro: 0.9317, F1 Macro: 0.9293\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2691, Accuracy: 0.9048, F1 Micro: 0.9416, F1 Macro: 0.9392\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2204, Accuracy: 0.9159, F1 Micro: 0.9478, F1 Macro: 0.9444\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1784, Accuracy: 0.9256, F1 Micro: 0.9542, F1 Macro: 0.9518\n",
      "\n",
      "Aspect detection accuracy: 0.9256, F1 Micro: 0.9542, F1 Macro: 0.9518\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.89      0.98      0.93       175\n",
      "      others       0.89      0.91      0.90       158\n",
      "        part       0.87      0.98      0.92       158\n",
      "       price       0.96      1.00      0.98       192\n",
      "     service       0.97      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.93      0.98      0.95      1061\n",
      "   macro avg       0.93      0.98      0.95      1061\n",
      "weighted avg       0.93      0.98      0.95      1061\n",
      " samples avg       0.93      0.98      0.95      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5923, Accuracy: 0.7023, F1 Micro: 0.7023, F1 Macro: 0.5266\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4121, Accuracy: 0.7674, F1 Micro: 0.7674, F1 Macro: 0.7485\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2347, Accuracy: 0.8558, F1 Micro: 0.8558, F1 Macro: 0.8408\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1629, Accuracy: 0.8651, F1 Micro: 0.8651, F1 Macro: 0.8537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1278, Accuracy: 0.8791, F1 Micro: 0.8791, F1 Macro: 0.8602\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0837, Accuracy: 0.8837, F1 Micro: 0.8837, F1 Macro: 0.8716\n",
      "Epoch 7/10, Train Loss: 0.0739, Accuracy: 0.8791, F1 Micro: 0.8791, F1 Macro: 0.8669\n",
      "Epoch 8/10, Train Loss: 0.0654, Accuracy: 0.8791, F1 Micro: 0.8791, F1 Macro: 0.8652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0576, Accuracy: 0.8837, F1 Micro: 0.8837, F1 Macro: 0.8708\n",
      "Epoch 10/10, Train Loss: 0.0426, Accuracy: 0.8605, F1 Micro: 0.8605, F1 Macro: 0.8491\n",
      "\n",
      "Sentiment analysis accuracy: 0.8837, F1 Micro: 0.8837, F1 Macro: 0.8708\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.91      0.83        67\n",
      "    positive       0.96      0.87      0.91       148\n",
      "\n",
      "    accuracy                           0.88       215\n",
      "   macro avg       0.86      0.89      0.87       215\n",
      "weighted avg       0.90      0.88      0.89       215\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 209: Accuracy: 0.9051, F1 Micro: 0.9051, F1 Macro: 0.8005\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       1.00      0.88      0.93        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.93      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.50      0.64        16\n",
      "     neutral       0.89      0.98      0.93       167\n",
      "    positive       0.82      0.55      0.65        33\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.86      0.68      0.74       216\n",
      "weighted avg       0.88      0.88      0.87       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.31      0.75      0.44        12\n",
      "     neutral       0.90      0.91      0.90       152\n",
      "    positive       0.70      0.44      0.54        52\n",
      "\n",
      "    accuracy                           0.79       216\n",
      "   macro avg       0.63      0.70      0.63       216\n",
      "weighted avg       0.82      0.79      0.79       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.61      0.72        23\n",
      "     neutral       0.86      0.98      0.92       152\n",
      "    positive       0.89      0.59      0.71        41\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.88      0.72      0.78       216\n",
      "weighted avg       0.87      0.87      0.86       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.62      0.76        13\n",
      "     neutral       0.96      1.00      0.98       186\n",
      "    positive       0.86      0.71      0.77        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.94      0.77      0.84       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.93        14\n",
      "     neutral       0.97      1.00      0.98       185\n",
      "    positive       1.00      0.53      0.69        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.95      0.84      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Total train time: 84.7815203666687 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.011933714151382446\n",
      "Acquired samples: 66\n",
      "Sampling duration: 17.17060375213623 seconds\n",
      "New train size: 275\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5913, Accuracy: 0.7879, F1 Micro: 0.8812, F1 Macro: 0.8795\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5126, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4885, Accuracy: 0.8006, F1 Micro: 0.8858, F1 Macro: 0.8833\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.438, Accuracy: 0.808, F1 Micro: 0.8903, F1 Macro: 0.8884\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3894, Accuracy: 0.8504, F1 Micro: 0.9107, F1 Macro: 0.9084\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3263, Accuracy: 0.8936, F1 Micro: 0.9337, F1 Macro: 0.9299\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2697, Accuracy: 0.9144, F1 Micro: 0.9473, F1 Macro: 0.9448\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2127, Accuracy: 0.9338, F1 Micro: 0.9587, F1 Macro: 0.9564\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1691, Accuracy: 0.9427, F1 Micro: 0.9641, F1 Macro: 0.962\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1388, Accuracy: 0.9509, F1 Micro: 0.9694, F1 Macro: 0.968\n",
      "\n",
      "Aspect detection accuracy: 0.9509, F1 Micro: 0.9694, F1 Macro: 0.968\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.90      0.94      0.92       158\n",
      "        part       0.95      0.99      0.97       158\n",
      "       price       0.96      1.00      0.98       192\n",
      "     service       0.96      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.95      0.99      0.97      1061\n",
      "   macro avg       0.95      0.98      0.97      1061\n",
      "weighted avg       0.95      0.99      0.97      1061\n",
      " samples avg       0.95      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5611, Accuracy: 0.6778, F1 Micro: 0.6778, F1 Macro: 0.404\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4104, Accuracy: 0.8243, F1 Micro: 0.8243, F1 Macro: 0.7913\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1865, Accuracy: 0.887, F1 Micro: 0.887, F1 Macro: 0.8743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1344, Accuracy: 0.9079, F1 Micro: 0.9079, F1 Macro: 0.8967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1217, Accuracy: 0.9079, F1 Micro: 0.9079, F1 Macro: 0.8915\n",
      "Epoch 6/10, Train Loss: 0.0852, Accuracy: 0.887, F1 Micro: 0.887, F1 Macro: 0.8777\n",
      "Epoch 7/10, Train Loss: 0.055, Accuracy: 0.8828, F1 Micro: 0.8828, F1 Macro: 0.8649\n",
      "Epoch 8/10, Train Loss: 0.0602, Accuracy: 0.8912, F1 Micro: 0.8912, F1 Macro: 0.8771\n",
      "Epoch 9/10, Train Loss: 0.0415, Accuracy: 0.887, F1 Micro: 0.887, F1 Macro: 0.8728\n",
      "Epoch 10/10, Train Loss: 0.052, Accuracy: 0.8912, F1 Micro: 0.8912, F1 Macro: 0.8807\n",
      "\n",
      "Sentiment analysis accuracy: 0.9079, F1 Micro: 0.9079, F1 Macro: 0.8915\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.81      0.85        77\n",
      "    positive       0.91      0.96      0.93       162\n",
      "\n",
      "    accuracy                           0.91       239\n",
      "   macro avg       0.91      0.88      0.89       239\n",
      "weighted avg       0.91      0.91      0.91       239\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 275: Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.8527\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.98      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.82      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.39      0.75      0.51        12\n",
      "     neutral       0.90      0.94      0.92       152\n",
      "    positive       0.76      0.50      0.60        52\n",
      "\n",
      "    accuracy                           0.82       216\n",
      "   macro avg       0.69      0.73      0.68       216\n",
      "weighted avg       0.84      0.82      0.82       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.78      0.82        23\n",
      "     neutral       0.94      0.99      0.96       152\n",
      "    positive       0.86      0.76      0.81        41\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.89      0.84      0.86       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.69      0.78        13\n",
      "     neutral       0.96      1.00      0.98       186\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.80      0.85       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.96      1.00      0.98       185\n",
      "    positive       1.00      0.59      0.74        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.96      0.84      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Total train time: 87.95621109008789 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.010881591401994229\n",
      "Acquired samples: 59\n",
      "Sampling duration: 15.768696069717407 seconds\n",
      "New train size: 334\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5733, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4944, Accuracy: 0.7976, F1 Micro: 0.8853, F1 Macro: 0.8834\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4463, Accuracy: 0.8147, F1 Micro: 0.8924, F1 Macro: 0.8901\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3781, Accuracy: 0.8497, F1 Micro: 0.9097, F1 Macro: 0.9071\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3113, Accuracy: 0.9062, F1 Micro: 0.9417, F1 Macro: 0.9383\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2498, Accuracy: 0.9308, F1 Micro: 0.9568, F1 Macro: 0.9533\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.194, Accuracy: 0.9427, F1 Micro: 0.964, F1 Macro: 0.9617\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.154, Accuracy: 0.9479, F1 Micro: 0.9676, F1 Macro: 0.9656\n",
      "Epoch 9/10, Train Loss: 0.13, Accuracy: 0.9472, F1 Micro: 0.9667, F1 Macro: 0.964\n",
      "Epoch 10/10, Train Loss: 0.1071, Accuracy: 0.9479, F1 Micro: 0.967, F1 Macro: 0.9637\n",
      "\n",
      "Aspect detection accuracy: 0.9479, F1 Micro: 0.9676, F1 Macro: 0.9656\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.94      0.99      0.96       175\n",
      "      others       0.91      0.91      0.91       158\n",
      "        part       0.93      0.99      0.96       158\n",
      "       price       0.96      1.00      0.98       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.95      0.98      0.97      1061\n",
      "   macro avg       0.95      0.98      0.97      1061\n",
      "weighted avg       0.95      0.98      0.97      1061\n",
      " samples avg       0.95      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5925, Accuracy: 0.6527, F1 Micro: 0.6527, F1 Macro: 0.513\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3382, Accuracy: 0.8117, F1 Micro: 0.8117, F1 Macro: 0.8031\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.208, Accuracy: 0.8912, F1 Micro: 0.8912, F1 Macro: 0.88\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1746, Accuracy: 0.8954, F1 Micro: 0.8954, F1 Macro: 0.8732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1323, Accuracy: 0.8996, F1 Micro: 0.8996, F1 Macro: 0.8834\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1105, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9262\n",
      "Epoch 7/10, Train Loss: 0.1082, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.9042\n",
      "Epoch 8/10, Train Loss: 0.0559, Accuracy: 0.9289, F1 Micro: 0.9289, F1 Macro: 0.9213\n",
      "Epoch 9/10, Train Loss: 0.0419, Accuracy: 0.9289, F1 Micro: 0.9289, F1 Macro: 0.9199\n",
      "Epoch 10/10, Train Loss: 0.0521, Accuracy: 0.9289, F1 Micro: 0.9289, F1 Macro: 0.9199\n",
      "\n",
      "Sentiment analysis accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9262\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.95      0.90        79\n",
      "    positive       0.97      0.93      0.95       160\n",
      "\n",
      "    accuracy                           0.93       239\n",
      "   macro avg       0.92      0.94      0.93       239\n",
      "weighted avg       0.94      0.93      0.93       239\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 334: Accuracy: 0.9267, F1 Micro: 0.9267, F1 Macro: 0.8486\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.97      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.75      0.69        16\n",
      "     neutral       0.95      0.97      0.96       167\n",
      "    positive       0.85      0.70      0.77        33\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.81      0.81      0.80       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.32      0.92      0.48        12\n",
      "     neutral       0.94      0.83      0.88       152\n",
      "    positive       0.75      0.69      0.72        52\n",
      "\n",
      "    accuracy                           0.80       216\n",
      "   macro avg       0.67      0.81      0.69       216\n",
      "weighted avg       0.86      0.80      0.82       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.70      0.76        23\n",
      "     neutral       0.94      0.99      0.97       152\n",
      "    positive       0.84      0.76      0.79        41\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.87      0.82      0.84       216\n",
      "weighted avg       0.91      0.92      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.85      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.93        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.71      0.83        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.90      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 93.23710560798645 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.009536482393741608\n",
      "Acquired samples: 54\n",
      "Sampling duration: 14.256247758865356 seconds\n",
      "New train size: 388\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5726, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4894, Accuracy: 0.7984, F1 Micro: 0.886, F1 Macro: 0.8842\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4479, Accuracy: 0.8214, F1 Micro: 0.8956, F1 Macro: 0.8927\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3578, Accuracy: 0.8802, F1 Micro: 0.9283, F1 Macro: 0.9257\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2776, Accuracy: 0.9338, F1 Micro: 0.959, F1 Macro: 0.9574\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2264, Accuracy: 0.9435, F1 Micro: 0.9645, F1 Macro: 0.9625\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1661, Accuracy: 0.9442, F1 Micro: 0.9648, F1 Macro: 0.9614\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1398, Accuracy: 0.9487, F1 Micro: 0.9677, F1 Macro: 0.9649\n",
      "Epoch 9/10, Train Loss: 0.1171, Accuracy: 0.9449, F1 Micro: 0.9652, F1 Macro: 0.9617\n",
      "Epoch 10/10, Train Loss: 0.0824, Accuracy: 0.9464, F1 Micro: 0.9663, F1 Macro: 0.9635\n",
      "\n",
      "Aspect detection accuracy: 0.9487, F1 Micro: 0.9677, F1 Macro: 0.9649\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.94      0.85      0.89       158\n",
      "        part       0.93      0.99      0.96       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.97      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.97      0.97      1061\n",
      "   macro avg       0.96      0.97      0.96      1061\n",
      "weighted avg       0.96      0.97      0.97      1061\n",
      " samples avg       0.96      0.97      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5233, Accuracy: 0.8206, F1 Micro: 0.8206, F1 Macro: 0.7814\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.228, Accuracy: 0.8511, F1 Micro: 0.8511, F1 Macro: 0.8386\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.152, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.8928\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0961, Accuracy: 0.9122, F1 Micro: 0.9122, F1 Macro: 0.8969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0785, Accuracy: 0.9237, F1 Micro: 0.9237, F1 Macro: 0.91\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0454, Accuracy: 0.9237, F1 Micro: 0.9237, F1 Macro: 0.9094\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0618, Accuracy: 0.9275, F1 Micro: 0.9275, F1 Macro: 0.9148\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0573, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9248\n",
      "Epoch 9/10, Train Loss: 0.0272, Accuracy: 0.9237, F1 Micro: 0.9237, F1 Macro: 0.9124\n",
      "Epoch 10/10, Train Loss: 0.0293, Accuracy: 0.9275, F1 Micro: 0.9275, F1 Macro: 0.916\n",
      "\n",
      "Sentiment analysis accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9248\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.91      0.90        81\n",
      "    positive       0.96      0.94      0.95       181\n",
      "\n",
      "    accuracy                           0.94       262\n",
      "   macro avg       0.92      0.93      0.92       262\n",
      "weighted avg       0.94      0.94      0.94       262\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 388: Accuracy: 0.9329, F1 Micro: 0.9329, F1 Macro: 0.8718\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.69      0.76        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.81      0.76      0.78        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.81      0.84       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.92      0.65        12\n",
      "     neutral       0.95      0.83      0.88       152\n",
      "    positive       0.67      0.79      0.73        52\n",
      "\n",
      "    accuracy                           0.82       216\n",
      "   macro avg       0.71      0.84      0.75       216\n",
      "weighted avg       0.86      0.82      0.83       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.78      0.84        23\n",
      "     neutral       0.94      0.99      0.96       152\n",
      "    positive       0.89      0.76      0.82        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.91      0.84      0.87       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.77      0.77        13\n",
      "     neutral       0.98      0.99      0.98       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.87      0.84      0.86       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.97      1.00      0.99       185\n",
      "    positive       1.00      0.76      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.99      0.90      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 105.08037567138672 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.01041125413030386\n",
      "Acquired samples: 48\n",
      "Sampling duration: 13.153515577316284 seconds\n",
      "New train size: 436\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.558, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4933, Accuracy: 0.7946, F1 Micro: 0.8828, F1 Macro: 0.8801\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4259, Accuracy: 0.8408, F1 Micro: 0.9068, F1 Macro: 0.905\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.343, Accuracy: 0.9129, F1 Micro: 0.9471, F1 Macro: 0.9454\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2488, Accuracy: 0.9397, F1 Micro: 0.9626, F1 Macro: 0.9603\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1928, Accuracy: 0.9449, F1 Micro: 0.9655, F1 Macro: 0.9629\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1487, Accuracy: 0.9494, F1 Micro: 0.9683, F1 Macro: 0.966\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1154, Accuracy: 0.9516, F1 Micro: 0.9696, F1 Macro: 0.967\n",
      "Epoch 9/10, Train Loss: 0.0981, Accuracy: 0.9494, F1 Micro: 0.9682, F1 Macro: 0.9658\n",
      "Epoch 10/10, Train Loss: 0.0801, Accuracy: 0.9509, F1 Micro: 0.969, F1 Macro: 0.9665\n",
      "\n",
      "Aspect detection accuracy: 0.9516, F1 Micro: 0.9696, F1 Macro: 0.967\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.93      0.87      0.90       158\n",
      "        part       0.94      0.99      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.97      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.97      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5468, Accuracy: 0.8053, F1 Micro: 0.8053, F1 Macro: 0.7836\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2362, Accuracy: 0.874, F1 Micro: 0.874, F1 Macro: 0.8614\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1285, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.8961\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1074, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.8961\n",
      "Epoch 5/10, Train Loss: 0.0635, Accuracy: 0.9008, F1 Micro: 0.9008, F1 Macro: 0.8838\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0706, Accuracy: 0.916, F1 Micro: 0.916, F1 Macro: 0.901\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0424, Accuracy: 0.9198, F1 Micro: 0.9198, F1 Macro: 0.9045\n",
      "Epoch 8/10, Train Loss: 0.0455, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.8967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0383, Accuracy: 0.9198, F1 Micro: 0.9198, F1 Macro: 0.9077\n",
      "Epoch 10/10, Train Loss: 0.0383, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.8955\n",
      "\n",
      "Sentiment analysis accuracy: 0.9198, F1 Micro: 0.9198, F1 Macro: 0.9077\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.90      0.87        81\n",
      "    positive       0.95      0.93      0.94       181\n",
      "\n",
      "    accuracy                           0.92       262\n",
      "   macro avg       0.90      0.91      0.91       262\n",
      "weighted avg       0.92      0.92      0.92       262\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 436: Accuracy: 0.936, F1 Micro: 0.936, F1 Macro: 0.878\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.62      0.69        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.86      0.79      0.82       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.92      0.65        12\n",
      "     neutral       0.93      0.85      0.89       152\n",
      "    positive       0.70      0.75      0.72        52\n",
      "\n",
      "    accuracy                           0.83       216\n",
      "   macro avg       0.71      0.84      0.75       216\n",
      "weighted avg       0.85      0.83      0.84       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        23\n",
      "     neutral       0.94      0.99      0.97       152\n",
      "    positive       0.88      0.71      0.78        41\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.88      0.84      0.86       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 106.80971837043762 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.009925566799938678\n",
      "Acquired samples: 43\n",
      "Sampling duration: 11.898101568222046 seconds\n",
      "New train size: 479\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5559, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4768, Accuracy: 0.8021, F1 Micro: 0.8865, F1 Macro: 0.8841\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.403, Accuracy: 0.8571, F1 Micro: 0.9159, F1 Macro: 0.9144\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3193, Accuracy: 0.9338, F1 Micro: 0.9593, F1 Macro: 0.958\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.243, Accuracy: 0.9449, F1 Micro: 0.9656, F1 Macro: 0.9634\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1739, Accuracy: 0.9509, F1 Micro: 0.9693, F1 Macro: 0.9672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1379, Accuracy: 0.9554, F1 Micro: 0.972, F1 Macro: 0.9706\n",
      "Epoch 8/10, Train Loss: 0.1152, Accuracy: 0.9524, F1 Micro: 0.9699, F1 Macro: 0.9675\n",
      "Epoch 9/10, Train Loss: 0.0948, Accuracy: 0.9509, F1 Micro: 0.9691, F1 Macro: 0.9669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0792, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9721\n",
      "\n",
      "Aspect detection accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9721\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.92      0.93      0.93       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.98      0.99      0.98       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5202, Accuracy: 0.8465, F1 Micro: 0.8465, F1 Macro: 0.8238\n",
      "Epoch 2/10, Train Loss: 0.2467, Accuracy: 0.8189, F1 Micro: 0.8189, F1 Macro: 0.8128\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1432, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.9049\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1172, Accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.9063\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0805, Accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.909\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0613, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9246\n",
      "Epoch 7/10, Train Loss: 0.0544, Accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.9069\n",
      "Epoch 8/10, Train Loss: 0.0459, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9167\n",
      "Epoch 9/10, Train Loss: 0.0495, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9176\n",
      "Epoch 10/10, Train Loss: 0.0375, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9131\n",
      "\n",
      "Sentiment analysis accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9246\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.93      0.90        82\n",
      "    positive       0.96      0.94      0.95       172\n",
      "\n",
      "    accuracy                           0.93       254\n",
      "   macro avg       0.92      0.93      0.92       254\n",
      "weighted avg       0.93      0.93      0.93       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 479: Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.8866\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.69      0.79        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.81      0.85       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.53      0.83      0.65        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.80      0.69      0.74        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.75      0.82      0.77       216\n",
      "weighted avg       0.87      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.96      0.99      0.98       152\n",
      "    positive       0.94      0.78      0.85        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.98       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.76      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.90      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 106.19857740402222 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.007467305054888129\n",
      "Acquired samples: 39\n",
      "Sampling duration: 11.02921986579895 seconds\n",
      "New train size: 518\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5287, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4697, Accuracy: 0.8043, F1 Micro: 0.8874, F1 Macro: 0.8847\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3849, Accuracy: 0.8966, F1 Micro: 0.9371, F1 Macro: 0.9345\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2838, Accuracy: 0.9397, F1 Micro: 0.9628, F1 Macro: 0.9617\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2082, Accuracy: 0.9568, F1 Micro: 0.9732, F1 Macro: 0.9723\n",
      "Epoch 6/10, Train Loss: 0.1504, Accuracy: 0.9568, F1 Micro: 0.9731, F1 Macro: 0.972\n",
      "Epoch 7/10, Train Loss: 0.1218, Accuracy: 0.9435, F1 Micro: 0.9643, F1 Macro: 0.9611\n",
      "Epoch 8/10, Train Loss: 0.0988, Accuracy: 0.9554, F1 Micro: 0.972, F1 Macro: 0.9704\n",
      "Epoch 9/10, Train Loss: 0.0758, Accuracy: 0.9561, F1 Micro: 0.9724, F1 Macro: 0.9708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0656, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9718\n",
      "\n",
      "Aspect detection accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9718\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.92      0.92      0.92       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5622, Accuracy: 0.8423, F1 Micro: 0.8423, F1 Macro: 0.8056\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2569, Accuracy: 0.8731, F1 Micro: 0.8731, F1 Macro: 0.8635\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1791, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9182\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1098, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9127\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0944, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9231\n",
      "Epoch 6/10, Train Loss: 0.1003, Accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.911\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0685, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9268\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0341, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9272\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0517, Accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9381\n",
      "Epoch 10/10, Train Loss: 0.0483, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9338\n",
      "\n",
      "Sentiment analysis accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9381\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.93      0.92        82\n",
      "    positive       0.97      0.96      0.96       178\n",
      "\n",
      "    accuracy                           0.95       260\n",
      "   macro avg       0.94      0.94      0.94       260\n",
      "weighted avg       0.95      0.95      0.95       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 518: Accuracy: 0.9475, F1 Micro: 0.9475, F1 Macro: 0.8948\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.69      0.76        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.81      0.76      0.78        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.87      0.81      0.83       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.67      0.67        12\n",
      "     neutral       0.92      0.91      0.92       152\n",
      "    positive       0.75      0.77      0.76        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.78      0.78      0.78       216\n",
      "weighted avg       0.87      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.95      0.95      0.95       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.84      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.96      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 115.57725811004639 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0034715426620095967\n",
      "Acquired samples: 22\n",
      "Sampling duration: 10.025025844573975 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5356, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4787, Accuracy: 0.8103, F1 Micro: 0.8906, F1 Macro: 0.8881\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3853, Accuracy: 0.9092, F1 Micro: 0.9445, F1 Macro: 0.9418\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2802, Accuracy: 0.9472, F1 Micro: 0.9674, F1 Macro: 0.9664\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.207, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9732\n",
      "Epoch 6/10, Train Loss: 0.1541, Accuracy: 0.9457, F1 Micro: 0.9657, F1 Macro: 0.9629\n",
      "Epoch 7/10, Train Loss: 0.119, Accuracy: 0.9539, F1 Micro: 0.9711, F1 Macro: 0.9698\n",
      "Epoch 8/10, Train Loss: 0.0948, Accuracy: 0.9561, F1 Micro: 0.9724, F1 Macro: 0.9706\n",
      "Epoch 9/10, Train Loss: 0.0809, Accuracy: 0.9568, F1 Micro: 0.9728, F1 Macro: 0.9713\n",
      "Epoch 10/10, Train Loss: 0.0691, Accuracy: 0.9546, F1 Micro: 0.9714, F1 Macro: 0.9696\n",
      "\n",
      "Aspect detection accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9732\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.91      0.96      0.93       158\n",
      "        part       0.95      0.99      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.97      1061\n",
      "   macro avg       0.96      0.99      0.97      1061\n",
      "weighted avg       0.96      0.99      0.97      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5201, Accuracy: 0.8361, F1 Micro: 0.8361, F1 Macro: 0.8262\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2293, Accuracy: 0.9262, F1 Micro: 0.9262, F1 Macro: 0.9158\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1412, Accuracy: 0.9467, F1 Micro: 0.9467, F1 Macro: 0.9394\n",
      "Epoch 4/10, Train Loss: 0.1132, Accuracy: 0.9221, F1 Micro: 0.9221, F1 Macro: 0.9149\n",
      "Epoch 5/10, Train Loss: 0.0979, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9274\n",
      "Epoch 6/10, Train Loss: 0.067, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9274\n",
      "Epoch 7/10, Train Loss: 0.07, Accuracy: 0.9221, F1 Micro: 0.9221, F1 Macro: 0.913\n",
      "Epoch 8/10, Train Loss: 0.066, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.93\n",
      "Epoch 9/10, Train Loss: 0.051, Accuracy: 0.9221, F1 Micro: 0.9221, F1 Macro: 0.9149\n",
      "Epoch 10/10, Train Loss: 0.034, Accuracy: 0.9303, F1 Micro: 0.9303, F1 Macro: 0.9217\n",
      "\n",
      "Sentiment analysis accuracy: 0.9467, F1 Micro: 0.9467, F1 Macro: 0.9394\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.92      0.92        79\n",
      "    positive       0.96      0.96      0.96       165\n",
      "\n",
      "    accuracy                           0.95       244\n",
      "   macro avg       0.94      0.94      0.94       244\n",
      "weighted avg       0.95      0.95      0.95       244\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.8683\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.91      0.87        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.86      0.83      0.84       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.37      0.92      0.52        12\n",
      "     neutral       0.95      0.88      0.91       152\n",
      "    positive       0.84      0.73      0.78        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.72      0.84      0.74       216\n",
      "weighted avg       0.89      0.85      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.94      0.78      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.91      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.85      0.81        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.80      0.71      0.75        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.86      0.85      0.85       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 103.34661173820496 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.00647987388074398\n",
      "Acquired samples: 33\n",
      "Sampling duration: 8.955235004425049 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5457, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4756, Accuracy: 0.8177, F1 Micro: 0.8946, F1 Macro: 0.8924\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3848, Accuracy: 0.9152, F1 Micro: 0.9486, F1 Macro: 0.947\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2755, Accuracy: 0.9479, F1 Micro: 0.9674, F1 Macro: 0.9656\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1864, Accuracy: 0.9501, F1 Micro: 0.9689, F1 Macro: 0.9669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1441, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1129, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9736\n",
      "Epoch 8/10, Train Loss: 0.0997, Accuracy: 0.9524, F1 Micro: 0.9699, F1 Macro: 0.9676\n",
      "Epoch 9/10, Train Loss: 0.0748, Accuracy: 0.9457, F1 Micro: 0.9657, F1 Macro: 0.9625\n",
      "Epoch 10/10, Train Loss: 0.0642, Accuracy: 0.9583, F1 Micro: 0.9737, F1 Macro: 0.9721\n",
      "\n",
      "Aspect detection accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9736\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.97      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5129, Accuracy: 0.8696, F1 Micro: 0.8696, F1 Macro: 0.8588\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1933, Accuracy: 0.917, F1 Micro: 0.917, F1 Macro: 0.9097\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1805, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9348\n",
      "Epoch 4/10, Train Loss: 0.1027, Accuracy: 0.9209, F1 Micro: 0.9209, F1 Macro: 0.9142\n",
      "Epoch 5/10, Train Loss: 0.0826, Accuracy: 0.9249, F1 Micro: 0.9249, F1 Macro: 0.9183\n",
      "Epoch 6/10, Train Loss: 0.0765, Accuracy: 0.9249, F1 Micro: 0.9249, F1 Macro: 0.9183\n",
      "Epoch 7/10, Train Loss: 0.0766, Accuracy: 0.9249, F1 Micro: 0.9249, F1 Macro: 0.917\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0644, Accuracy: 0.9486, F1 Micro: 0.9486, F1 Macro: 0.9432\n",
      "Epoch 9/10, Train Loss: 0.0385, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9257\n",
      "Epoch 10/10, Train Loss: 0.0402, Accuracy: 0.9447, F1 Micro: 0.9447, F1 Macro: 0.939\n",
      "\n",
      "Sentiment analysis accuracy: 0.9486, F1 Micro: 0.9486, F1 Macro: 0.9432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.98      0.93        83\n",
      "    positive       0.99      0.94      0.96       170\n",
      "\n",
      "    accuracy                           0.95       253\n",
      "   macro avg       0.93      0.96      0.94       253\n",
      "weighted avg       0.95      0.95      0.95       253\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.946, F1 Micro: 0.946, F1 Macro: 0.8889\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.97      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.85      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.55      0.92      0.69        12\n",
      "     neutral       0.94      0.91      0.92       152\n",
      "    positive       0.82      0.77      0.79        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.77      0.86      0.80       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      1.00      0.85        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.97      0.76      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.91      0.89       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.85      0.81        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.88      0.87      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.76      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 114.54111051559448 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.004701798129826784\n",
      "Acquired samples: 30\n",
      "Sampling duration: 8.49161696434021 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5372, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4703, Accuracy: 0.8177, F1 Micro: 0.8952, F1 Macro: 0.8933\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3737, Accuracy: 0.9122, F1 Micro: 0.9451, F1 Macro: 0.9415\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2666, Accuracy: 0.9375, F1 Micro: 0.9609, F1 Macro: 0.9578\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1981, Accuracy: 0.9554, F1 Micro: 0.9722, F1 Macro: 0.9713\n",
      "Epoch 6/10, Train Loss: 0.1544, Accuracy: 0.9554, F1 Micro: 0.9719, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1165, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9753\n",
      "Epoch 8/10, Train Loss: 0.0898, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9742\n",
      "Epoch 9/10, Train Loss: 0.0735, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9722\n",
      "Epoch 10/10, Train Loss: 0.0666, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9721\n",
      "\n",
      "Aspect detection accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9753\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.98       192\n",
      "     service       0.97      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5234, Accuracy: 0.874, F1 Micro: 0.874, F1 Macro: 0.852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2522, Accuracy: 0.9016, F1 Micro: 0.9016, F1 Macro: 0.8942\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1693, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.9058\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1266, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9226\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0984, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9226\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0686, Accuracy: 0.9528, F1 Micro: 0.9528, F1 Macro: 0.947\n",
      "Epoch 7/10, Train Loss: 0.0627, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.935\n",
      "Epoch 8/10, Train Loss: 0.043, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.9063\n",
      "Epoch 9/10, Train Loss: 0.048, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9343\n",
      "Epoch 10/10, Train Loss: 0.05, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9218\n",
      "\n",
      "Sentiment analysis accuracy: 0.9528, F1 Micro: 0.9528, F1 Macro: 0.947\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93        83\n",
      "    positive       0.98      0.95      0.96       171\n",
      "\n",
      "    accuracy                           0.95       254\n",
      "   macro avg       0.94      0.95      0.95       254\n",
      "weighted avg       0.95      0.95      0.95       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9452, F1 Micro: 0.9452, F1 Macro: 0.8801\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.97      0.98      0.97       167\n",
      "    positive       0.88      0.88      0.88        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.44      0.92      0.59        12\n",
      "     neutral       0.93      0.91      0.92       152\n",
      "    positive       0.86      0.71      0.78        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.74      0.85      0.76       216\n",
      "weighted avg       0.89      0.86      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.91      0.76      0.83        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.90      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.85      0.81        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.88      0.87      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      1.00      0.88        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.71      0.83        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.92      0.90      0.90       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 119.88452434539795 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.004004768049344421\n",
      "Acquired samples: 27\n",
      "Sampling duration: 7.720875263214111 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.539, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4558, Accuracy: 0.8214, F1 Micro: 0.8973, F1 Macro: 0.8954\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3627, Accuracy: 0.9323, F1 Micro: 0.9584, F1 Macro: 0.9569\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2493, Accuracy: 0.9524, F1 Micro: 0.9703, F1 Macro: 0.9689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1793, Accuracy: 0.9531, F1 Micro: 0.9706, F1 Macro: 0.969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1327, Accuracy: 0.9583, F1 Micro: 0.974, F1 Macro: 0.9729\n",
      "Epoch 7/10, Train Loss: 0.105, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9711\n",
      "Epoch 8/10, Train Loss: 0.0867, Accuracy: 0.9561, F1 Micro: 0.9722, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0694, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9738\n",
      "Epoch 10/10, Train Loss: 0.0585, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9724\n",
      "\n",
      "Aspect detection accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9738\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.91      0.94      0.93       158\n",
      "        part       0.96      1.00      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.97      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.97      1061\n",
      "   macro avg       0.96      0.99      0.97      1061\n",
      "weighted avg       0.96      0.99      0.97      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5104, Accuracy: 0.8735, F1 Micro: 0.8735, F1 Macro: 0.8592\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2429, Accuracy: 0.9306, F1 Micro: 0.9306, F1 Macro: 0.9252\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1536, Accuracy: 0.9469, F1 Micro: 0.9469, F1 Macro: 0.9422\n",
      "Epoch 4/10, Train Loss: 0.1325, Accuracy: 0.9429, F1 Micro: 0.9429, F1 Macro: 0.9373\n",
      "Epoch 5/10, Train Loss: 0.09, Accuracy: 0.9429, F1 Micro: 0.9429, F1 Macro: 0.9354\n",
      "Epoch 6/10, Train Loss: 0.078, Accuracy: 0.9347, F1 Micro: 0.9347, F1 Macro: 0.9287\n",
      "Epoch 7/10, Train Loss: 0.0514, Accuracy: 0.9429, F1 Micro: 0.9429, F1 Macro: 0.9379\n",
      "Epoch 8/10, Train Loss: 0.0599, Accuracy: 0.9429, F1 Micro: 0.9429, F1 Macro: 0.9379\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0531, Accuracy: 0.951, F1 Micro: 0.951, F1 Macro: 0.9465\n",
      "Epoch 10/10, Train Loss: 0.0437, Accuracy: 0.9429, F1 Micro: 0.9429, F1 Macro: 0.9337\n",
      "\n",
      "Sentiment analysis accuracy: 0.951, F1 Micro: 0.951, F1 Macro: 0.9465\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.93        83\n",
      "    positive       0.99      0.94      0.96       162\n",
      "\n",
      "    accuracy                           0.95       245\n",
      "   macro avg       0.94      0.96      0.95       245\n",
      "weighted avg       0.95      0.95      0.95       245\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.8596\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.73      0.80        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.92      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.88      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.56      0.62        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.81      0.79      0.80        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.82      0.78      0.80       216\n",
      "weighted avg       0.91      0.92      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      1.00      0.75        12\n",
      "     neutral       0.93      0.89      0.91       152\n",
      "    positive       0.82      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.78      0.89      0.82       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.96      0.94        23\n",
      "     neutral       0.97      1.00      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.69      0.75        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.86      0.84      0.85       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.86      0.80        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.85      0.86       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 123.02971291542053 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.004896873701363802\n",
      "Acquired samples: 18\n",
      "Sampling duration: 7.176796197891235 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5244, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4421, Accuracy: 0.8281, F1 Micro: 0.9, F1 Macro: 0.8981\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3414, Accuracy: 0.9345, F1 Micro: 0.9596, F1 Macro: 0.9579\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2347, Accuracy: 0.9561, F1 Micro: 0.9728, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1645, Accuracy: 0.9606, F1 Micro: 0.9754, F1 Macro: 0.9742\n",
      "Epoch 6/10, Train Loss: 0.1207, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0971, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9759\n",
      "Epoch 8/10, Train Loss: 0.082, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9749\n",
      "Epoch 9/10, Train Loss: 0.0641, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9747\n",
      "Epoch 10/10, Train Loss: 0.0589, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9759\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.91      0.95      0.93       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5201, Accuracy: 0.8765, F1 Micro: 0.8765, F1 Macro: 0.864\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2518, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9292\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1624, Accuracy: 0.9402, F1 Micro: 0.9402, F1 Macro: 0.9346\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1133, Accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9388\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0936, Accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9374\n",
      "Epoch 6/10, Train Loss: 0.0659, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9304\n",
      "Epoch 7/10, Train Loss: 0.0802, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.9016\n",
      "Epoch 8/10, Train Loss: 0.0568, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9254\n",
      "Epoch 9/10, Train Loss: 0.0318, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9242\n",
      "Epoch 10/10, Train Loss: 0.0502, Accuracy: 0.9243, F1 Micro: 0.9243, F1 Macro: 0.9148\n",
      "\n",
      "Sentiment analysis accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9374\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        84\n",
      "    positive       0.96      0.96      0.96       167\n",
      "\n",
      "    accuracy                           0.94       251\n",
      "   macro avg       0.94      0.94      0.94       251\n",
      "weighted avg       0.94      0.94      0.94       251\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.883\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.82      0.86        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.62      0.74        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.78      0.76      0.77        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.88      0.79      0.82       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.75      0.67        12\n",
      "     neutral       0.92      0.93      0.92       152\n",
      "    positive       0.81      0.75      0.78        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.78      0.81      0.79       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.96      0.86        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.91      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.85      0.81        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.88      0.87      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.96      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 123.25406885147095 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.00303198229521513\n",
      "Acquired samples: 25\n",
      "Sampling duration: 6.547126293182373 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5381, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4436, Accuracy: 0.8549, F1 Micro: 0.9131, F1 Macro: 0.9111\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3191, Accuracy: 0.9382, F1 Micro: 0.9616, F1 Macro: 0.9597\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2234, Accuracy: 0.9516, F1 Micro: 0.9699, F1 Macro: 0.9689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1609, Accuracy: 0.9598, F1 Micro: 0.975, F1 Macro: 0.9741\n",
      "Epoch 6/10, Train Loss: 0.1181, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0903, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.975\n",
      "Epoch 8/10, Train Loss: 0.0779, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0611, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0527, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9756\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9756\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.92      0.93      0.93       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5642, Accuracy: 0.891, F1 Micro: 0.891, F1 Macro: 0.8779\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2959, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9256\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1526, Accuracy: 0.9361, F1 Micro: 0.9361, F1 Macro: 0.9296\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1456, Accuracy: 0.9436, F1 Micro: 0.9436, F1 Macro: 0.9372\n",
      "Epoch 5/10, Train Loss: 0.0906, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9325\n",
      "Epoch 6/10, Train Loss: 0.0794, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9304\n",
      "Epoch 7/10, Train Loss: 0.0549, Accuracy: 0.9211, F1 Micro: 0.9211, F1 Macro: 0.913\n",
      "Epoch 8/10, Train Loss: 0.069, Accuracy: 0.9361, F1 Micro: 0.9361, F1 Macro: 0.9263\n",
      "Epoch 9/10, Train Loss: 0.0607, Accuracy: 0.8947, F1 Micro: 0.8947, F1 Macro: 0.8864\n",
      "Epoch 10/10, Train Loss: 0.0558, Accuracy: 0.9135, F1 Micro: 0.9135, F1 Macro: 0.9052\n",
      "\n",
      "Sentiment analysis accuracy: 0.9436, F1 Micro: 0.9436, F1 Macro: 0.9372\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.97      0.92        86\n",
      "    positive       0.98      0.93      0.96       180\n",
      "\n",
      "    accuracy                           0.94       266\n",
      "   macro avg       0.93      0.95      0.94       266\n",
      "weighted avg       0.95      0.94      0.94       266\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.9475, F1 Micro: 0.9475, F1 Macro: 0.8948\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.84      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.92      0.81        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.76      0.71      0.73        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.81      0.85      0.83       216\n",
      "weighted avg       0.88      0.88      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      1.00      0.85        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.94      0.76      0.84        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.91      0.89       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.85      0.81        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.88      0.87      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 131.37937021255493 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.0024244199274107816\n",
      "Acquired samples: 25\n",
      "Sampling duration: 6.4934539794921875 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5303, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4425, Accuracy: 0.8385, F1 Micro: 0.9054, F1 Macro: 0.9033\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3286, Accuracy: 0.9382, F1 Micro: 0.9619, F1 Macro: 0.9605\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2208, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1537, Accuracy: 0.9628, F1 Micro: 0.9768, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.116, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.097, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "Epoch 8/10, Train Loss: 0.0777, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9765\n",
      "Epoch 9/10, Train Loss: 0.0631, Accuracy: 0.9583, F1 Micro: 0.9737, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0558, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9781\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.97      0.97       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.98      1.00      0.99       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5005, Accuracy: 0.8943, F1 Micro: 0.8943, F1 Macro: 0.8802\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2069, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9341\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1323, Accuracy: 0.9585, F1 Micro: 0.9585, F1 Macro: 0.9536\n",
      "Epoch 4/10, Train Loss: 0.1358, Accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.9414\n",
      "Epoch 5/10, Train Loss: 0.0904, Accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.9414\n",
      "Epoch 6/10, Train Loss: 0.1019, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9337\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0761, Accuracy: 0.9585, F1 Micro: 0.9585, F1 Macro: 0.9539\n",
      "Epoch 8/10, Train Loss: 0.0584, Accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.9344\n",
      "Epoch 9/10, Train Loss: 0.051, Accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.9367\n",
      "Epoch 10/10, Train Loss: 0.0453, Accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.9414\n",
      "\n",
      "Sentiment analysis accuracy: 0.9585, F1 Micro: 0.9585, F1 Macro: 0.9539\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94        88\n",
      "    positive       0.98      0.95      0.97       177\n",
      "\n",
      "    accuracy                           0.96       265\n",
      "   macro avg       0.95      0.96      0.95       265\n",
      "weighted avg       0.96      0.96      0.96       265\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9209\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.96      0.97      0.96       167\n",
      "    positive       0.78      0.76      0.77        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.85      0.86       216\n",
      "weighted avg       0.92      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.78      0.77      0.78        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.88      0.87      0.87       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      1.00      0.99       152\n",
      "    positive       1.00      0.80      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 133.4244236946106 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.0031228512059897186\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.883546352386475 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5228, Accuracy: 0.7902, F1 Micro: 0.8824, F1 Macro: 0.8808\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4374, Accuracy: 0.8527, F1 Micro: 0.9125, F1 Macro: 0.9106\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3108, Accuracy: 0.942, F1 Micro: 0.9642, F1 Macro: 0.9627\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.214, Accuracy: 0.9509, F1 Micro: 0.9692, F1 Macro: 0.9673\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1487, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1143, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9755\n",
      "Epoch 7/10, Train Loss: 0.0873, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0734, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9768\n",
      "Epoch 9/10, Train Loss: 0.0639, Accuracy: 0.9606, F1 Micro: 0.975, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0531, Accuracy: 0.971, F1 Micro: 0.9818, F1 Macro: 0.9809\n",
      "\n",
      "Aspect detection accuracy: 0.971, F1 Micro: 0.9818, F1 Macro: 0.9809\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.98       175\n",
      "      others       0.92      0.97      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5278, Accuracy: 0.8858, F1 Micro: 0.8858, F1 Macro: 0.8743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2564, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9203\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1276, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9362\n",
      "Epoch 4/10, Train Loss: 0.135, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9321\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1104, Accuracy: 0.9488, F1 Micro: 0.9488, F1 Macro: 0.9442\n",
      "Epoch 6/10, Train Loss: 0.0819, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9293\n",
      "Epoch 7/10, Train Loss: 0.0809, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9404\n",
      "Epoch 8/10, Train Loss: 0.0793, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9243\n",
      "Epoch 9/10, Train Loss: 0.0509, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9321\n",
      "Epoch 10/10, Train Loss: 0.0505, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9359\n",
      "\n",
      "Sentiment analysis accuracy: 0.9488, F1 Micro: 0.9488, F1 Macro: 0.9442\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.93        88\n",
      "    positive       0.98      0.95      0.96       166\n",
      "\n",
      "    accuracy                           0.95       254\n",
      "   macro avg       0.94      0.95      0.94       254\n",
      "weighted avg       0.95      0.95      0.95       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9232\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.97      0.98      0.98       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        12\n",
      "     neutral       0.92      0.97      0.95       152\n",
      "    positive       0.88      0.73      0.80        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.91      0.87      0.89       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.78      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.92      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.96      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 135.47138810157776 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.0067005225922912364\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.623295783996582 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5189, Accuracy: 0.7909, F1 Micro: 0.8828, F1 Macro: 0.8811\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4309, Accuracy: 0.8743, F1 Micro: 0.9252, F1 Macro: 0.9241\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2874, Accuracy: 0.9494, F1 Micro: 0.9686, F1 Macro: 0.9677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1871, Accuracy: 0.9576, F1 Micro: 0.9736, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1368, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1069, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.978\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0827, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.978\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0654, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9784\n",
      "Epoch 9/10, Train Loss: 0.0545, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9775\n",
      "Epoch 10/10, Train Loss: 0.0498, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.978\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9784\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.95      0.92      0.93       158\n",
      "        part       0.97      1.00      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.506, Accuracy: 0.8973, F1 Micro: 0.8973, F1 Macro: 0.8904\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2559, Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.9452\n",
      "Epoch 3/10, Train Loss: 0.1581, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9365\n",
      "Epoch 4/10, Train Loss: 0.1415, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9309\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1114, Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.945\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0868, Accuracy: 0.9544, F1 Micro: 0.9544, F1 Macro: 0.9488\n",
      "Epoch 7/10, Train Loss: 0.0612, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9172\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0763, Accuracy: 0.9582, F1 Micro: 0.9582, F1 Macro: 0.9534\n",
      "Epoch 9/10, Train Loss: 0.0666, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9276\n",
      "Epoch 10/10, Train Loss: 0.0372, Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9406\n",
      "\n",
      "Sentiment analysis accuracy: 0.9582, F1 Micro: 0.9582, F1 Macro: 0.9534\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94        87\n",
      "    positive       0.98      0.95      0.97       176\n",
      "\n",
      "    accuracy                           0.96       263\n",
      "   macro avg       0.95      0.96      0.95       263\n",
      "weighted avg       0.96      0.96      0.96       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9161\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.85      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.92      0.81        12\n",
      "     neutral       0.95      0.91      0.93       152\n",
      "    positive       0.76      0.81      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.82      0.88      0.84       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.98      0.99      0.99       152\n",
      "    positive       1.00      0.78      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.92      0.91       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 137.76581048965454 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.003317292546853423\n",
      "Acquired samples: 8\n",
      "Sampling duration: 3.951899528503418 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5237, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4284, Accuracy: 0.8869, F1 Micro: 0.9319, F1 Macro: 0.9301\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2826, Accuracy: 0.9494, F1 Micro: 0.9688, F1 Macro: 0.9678\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1803, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1361, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1038, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9751\n",
      "Epoch 7/10, Train Loss: 0.0814, Accuracy: 0.9628, F1 Micro: 0.9764, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0639, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0518, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9773\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0463, Accuracy: 0.9673, F1 Micro: 0.9792, F1 Macro: 0.9772\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9792, F1 Macro: 0.9772\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.98      0.98      0.98       175\n",
      "      others       0.94      0.89      0.92       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      1.00      1.00       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.97      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.97      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5066, Accuracy: 0.9071, F1 Micro: 0.9071, F1 Macro: 0.8942\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2329, Accuracy: 0.9143, F1 Micro: 0.9143, F1 Macro: 0.9054\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1753, Accuracy: 0.9429, F1 Micro: 0.9429, F1 Macro: 0.9356\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1373, Accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.9423\n",
      "Epoch 5/10, Train Loss: 0.1243, Accuracy: 0.9321, F1 Micro: 0.9321, F1 Macro: 0.9241\n",
      "Epoch 6/10, Train Loss: 0.1055, Accuracy: 0.9393, F1 Micro: 0.9393, F1 Macro: 0.9302\n",
      "Epoch 7/10, Train Loss: 0.0588, Accuracy: 0.9357, F1 Micro: 0.9357, F1 Macro: 0.9275\n",
      "Epoch 8/10, Train Loss: 0.0712, Accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.9384\n",
      "Epoch 9/10, Train Loss: 0.0645, Accuracy: 0.9393, F1 Micro: 0.9393, F1 Macro: 0.9306\n",
      "Epoch 10/10, Train Loss: 0.0437, Accuracy: 0.9429, F1 Micro: 0.9429, F1 Macro: 0.9356\n",
      "\n",
      "Sentiment analysis accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.9423\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.93      0.92        88\n",
      "    positive       0.97      0.96      0.96       192\n",
      "\n",
      "    accuracy                           0.95       280\n",
      "   macro avg       0.94      0.95      0.94       280\n",
      "weighted avg       0.95      0.95      0.95       280\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.9271\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.98      0.98      0.98       167\n",
      "    positive       0.88      0.88      0.88        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.92      0.85        12\n",
      "     neutral       0.94      0.89      0.92       152\n",
      "    positive       0.71      0.79      0.75        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.81      0.87      0.84       216\n",
      "weighted avg       0.88      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      1.00      1.00       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.92      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 137.4283788204193 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.002847030479460955\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.7014684677124023 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5197, Accuracy: 0.7939, F1 Micro: 0.8841, F1 Macro: 0.8824\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4282, Accuracy: 0.8862, F1 Micro: 0.932, F1 Macro: 0.9307\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2778, Accuracy: 0.9501, F1 Micro: 0.9692, F1 Macro: 0.9679\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1821, Accuracy: 0.9606, F1 Micro: 0.9754, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.131, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0944, Accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9777\n",
      "Epoch 7/10, Train Loss: 0.078, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9776\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0652, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9787\n",
      "Epoch 9/10, Train Loss: 0.0516, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0447, Accuracy: 0.971, F1 Micro: 0.9817, F1 Macro: 0.9804\n",
      "\n",
      "Aspect detection accuracy: 0.971, F1 Micro: 0.9817, F1 Macro: 0.9804\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.98       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.519, Accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.903\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2568, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.9291\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1445, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.9305\n",
      "Epoch 4/10, Train Loss: 0.1287, Accuracy: 0.903, F1 Micro: 0.903, F1 Macro: 0.8959\n",
      "Epoch 5/10, Train Loss: 0.1173, Accuracy: 0.9254, F1 Micro: 0.9254, F1 Macro: 0.9188\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1133, Accuracy: 0.9478, F1 Micro: 0.9478, F1 Macro: 0.9408\n",
      "Epoch 7/10, Train Loss: 0.0981, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.9283\n",
      "Epoch 8/10, Train Loss: 0.0577, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.9283\n",
      "Epoch 9/10, Train Loss: 0.0503, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9327\n",
      "Epoch 10/10, Train Loss: 0.0372, Accuracy: 0.9254, F1 Micro: 0.9254, F1 Macro: 0.9181\n",
      "\n",
      "Sentiment analysis accuracy: 0.9478, F1 Micro: 0.9478, F1 Macro: 0.9408\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        88\n",
      "    positive       0.96      0.96      0.96       180\n",
      "\n",
      "    accuracy                           0.95       268\n",
      "   macro avg       0.94      0.94      0.94       268\n",
      "weighted avg       0.95      0.95      0.95       268\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.9197\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.97      0.98      0.98       167\n",
      "    positive       0.84      0.82      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.87      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.92      0.85        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.78      0.73      0.75        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.83      0.86      0.84       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      1.00      0.85        23\n",
      "     neutral       0.98      0.99      0.99       152\n",
      "    positive       1.00      0.76      0.86        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.92      0.90       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 138.80792760849 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0042436508461833\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.100417137145996 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5196, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4225, Accuracy: 0.91, F1 Micro: 0.9446, F1 Macro: 0.9418\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2631, Accuracy: 0.9531, F1 Micro: 0.9709, F1 Macro: 0.9696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.174, Accuracy: 0.9643, F1 Micro: 0.9777, F1 Macro: 0.9768\n",
      "Epoch 5/10, Train Loss: 0.1285, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9755\n",
      "Epoch 6/10, Train Loss: 0.0965, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9755\n",
      "Epoch 7/10, Train Loss: 0.072, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0613, Accuracy: 0.971, F1 Micro: 0.9817, F1 Macro: 0.9803\n",
      "Epoch 9/10, Train Loss: 0.0517, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9761\n",
      "Epoch 10/10, Train Loss: 0.0458, Accuracy: 0.971, F1 Micro: 0.9816, F1 Macro: 0.9803\n",
      "\n",
      "Aspect detection accuracy: 0.971, F1 Micro: 0.9817, F1 Macro: 0.9803\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.98      0.98      0.98       175\n",
      "      others       0.93      0.94      0.94       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5178, Accuracy: 0.9179, F1 Micro: 0.9179, F1 Macro: 0.9064\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.242, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9345\n",
      "Epoch 3/10, Train Loss: 0.1698, Accuracy: 0.9254, F1 Micro: 0.9254, F1 Macro: 0.9144\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1334, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9327\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1219, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9338\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.095, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9319\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0727, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9378\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0587, Accuracy: 0.9515, F1 Micro: 0.9515, F1 Macro: 0.9461\n",
      "Epoch 9/10, Train Loss: 0.0593, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9374\n",
      "Epoch 10/10, Train Loss: 0.0434, Accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.906\n",
      "\n",
      "Sentiment analysis accuracy: 0.9515, F1 Micro: 0.9515, F1 Macro: 0.9461\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.97      0.93        88\n",
      "    positive       0.98      0.94      0.96       180\n",
      "\n",
      "    accuracy                           0.95       268\n",
      "   macro avg       0.94      0.96      0.95       268\n",
      "weighted avg       0.95      0.95      0.95       268\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.89\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.91      0.87        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.91      0.88      0.89        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.91      0.93      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.98      0.98      0.98       167\n",
      "    positive       0.85      0.85      0.85        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.88      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.55      0.92      0.69        12\n",
      "     neutral       0.95      0.92      0.93       152\n",
      "    positive       0.79      0.73      0.76        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.76      0.86      0.79       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.94      0.78      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.92      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.92      0.80        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.87      0.87      0.86       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 141.82002305984497 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0019046194152906536\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.4558238983154297 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5261, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4344, Accuracy: 0.8929, F1 Micro: 0.935, F1 Macro: 0.9328\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2771, Accuracy: 0.9487, F1 Micro: 0.9681, F1 Macro: 0.9668\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1733, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1388, Accuracy: 0.9628, F1 Micro: 0.9764, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0991, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.979\n",
      "Epoch 7/10, Train Loss: 0.0769, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0657, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9791\n",
      "Epoch 9/10, Train Loss: 0.0506, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9757\n",
      "Epoch 10/10, Train Loss: 0.0463, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.979\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9791\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.95      0.93      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4878, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9119\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2508, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.922\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.158, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.9295\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1169, Accuracy: 0.9478, F1 Micro: 0.9478, F1 Macro: 0.9411\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1055, Accuracy: 0.9478, F1 Micro: 0.9478, F1 Macro: 0.9404\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0751, Accuracy: 0.9478, F1 Micro: 0.9478, F1 Macro: 0.9411\n",
      "Epoch 7/10, Train Loss: 0.0988, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9138\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0737, Accuracy: 0.9478, F1 Micro: 0.9478, F1 Macro: 0.9408\n",
      "Epoch 9/10, Train Loss: 0.0437, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9371\n",
      "Epoch 10/10, Train Loss: 0.051, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9364\n",
      "\n",
      "Sentiment analysis accuracy: 0.9478, F1 Micro: 0.9478, F1 Macro: 0.9408\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        86\n",
      "    positive       0.97      0.95      0.96       182\n",
      "\n",
      "    accuracy                           0.95       268\n",
      "   macro avg       0.94      0.95      0.94       268\n",
      "weighted avg       0.95      0.95      0.95       268\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9234\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.84      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        12\n",
      "     neutral       0.96      0.93      0.95       152\n",
      "    positive       0.81      0.88      0.84        52\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.92      0.91      0.92       216\n",
      "weighted avg       0.93      0.92      0.92       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 145.15667176246643 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0016653588623739778\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.8105895519256592 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5135, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3976, Accuracy: 0.9196, F1 Micro: 0.951, F1 Macro: 0.9492\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2429, Accuracy: 0.9568, F1 Micro: 0.9732, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1596, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9735\n",
      "Epoch 5/10, Train Loss: 0.1204, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0925, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.978\n",
      "Epoch 7/10, Train Loss: 0.0698, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9777\n",
      "Epoch 8/10, Train Loss: 0.0604, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0514, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9791\n",
      "Epoch 10/10, Train Loss: 0.042, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9786\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9791\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.94      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4336, Accuracy: 0.9251, F1 Micro: 0.9251, F1 Macro: 0.9179\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2219, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9258\n",
      "Epoch 3/10, Train Loss: 0.1495, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9066\n",
      "Epoch 4/10, Train Loss: 0.1326, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9102\n",
      "Epoch 5/10, Train Loss: 0.1104, Accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.9101\n",
      "Epoch 6/10, Train Loss: 0.101, Accuracy: 0.9288, F1 Micro: 0.9288, F1 Macro: 0.9202\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0778, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9233\n",
      "Epoch 8/10, Train Loss: 0.0704, Accuracy: 0.9288, F1 Micro: 0.9288, F1 Macro: 0.9218\n",
      "Epoch 9/10, Train Loss: 0.0664, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9127\n",
      "Epoch 10/10, Train Loss: 0.0485, Accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.9097\n",
      "\n",
      "Sentiment analysis accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9233\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.90      0.90        87\n",
      "    positive       0.95      0.95      0.95       180\n",
      "\n",
      "    accuracy                           0.93       267\n",
      "   macro avg       0.92      0.92      0.92       267\n",
      "weighted avg       0.93      0.93      0.93       267\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9034\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.97      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.88      0.82        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.87      0.87      0.87       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.83      0.74        12\n",
      "     neutral       0.94      0.94      0.94       152\n",
      "    positive       0.82      0.77      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.81      0.85      0.82       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      1.00      0.84        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.92      0.89       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 140.01124954223633 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0023709454108029604\n",
      "Acquired samples: 8\n",
      "Sampling duration: 1.0407726764678955 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5229, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4041, Accuracy: 0.9129, F1 Micro: 0.9468, F1 Macro: 0.9446\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2432, Accuracy: 0.9568, F1 Micro: 0.9732, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1663, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1198, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9787\n",
      "Epoch 6/10, Train Loss: 0.091, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9773\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0679, Accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9802\n",
      "Epoch 8/10, Train Loss: 0.0624, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9774\n",
      "Epoch 9/10, Train Loss: 0.0475, Accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9801\n",
      "Epoch 10/10, Train Loss: 0.0415, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.979\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9802\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.93      0.96      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4542, Accuracy: 0.9189, F1 Micro: 0.9189, F1 Macro: 0.9117\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2189, Accuracy: 0.9575, F1 Micro: 0.9575, F1 Macro: 0.952\n",
      "Epoch 3/10, Train Loss: 0.1673, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9356\n",
      "Epoch 4/10, Train Loss: 0.1243, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9315\n",
      "Epoch 5/10, Train Loss: 0.1172, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9239\n",
      "Epoch 6/10, Train Loss: 0.0815, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9197\n",
      "Epoch 7/10, Train Loss: 0.084, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9356\n",
      "Epoch 8/10, Train Loss: 0.0679, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9266\n",
      "Epoch 9/10, Train Loss: 0.0629, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9149\n",
      "Epoch 10/10, Train Loss: 0.0634, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9262\n",
      "\n",
      "Sentiment analysis accuracy: 0.9575, F1 Micro: 0.9575, F1 Macro: 0.952\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        85\n",
      "    positive       0.97      0.97      0.97       174\n",
      "\n",
      "    accuracy                           0.96       259\n",
      "   macro avg       0.95      0.95      0.95       259\n",
      "weighted avg       0.96      0.96      0.96       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.905\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.82      0.86        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.92      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.75      0.77        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.87      0.84      0.85       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.83      0.71        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.83      0.77      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.80      0.85      0.82       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 139.40108180046082 s\n",
      "Total runtime: 3134.2544507980347 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[3], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7341e45",
   "metadata": {
    "papermill": {
     "duration": 0.274824,
     "end_time": "2025-03-23T15:06:25.671548",
     "exception": false,
     "start_time": "2025-03-23T15:06:25.396724",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e569b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 5\n",
      "Random seed: 94\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6298, Accuracy: 0.7522, F1 Micro: 0.854, F1 Macro: 0.8362\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5654, Accuracy: 0.7887, F1 Micro: 0.8819, F1 Macro: 0.8803\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5262, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4783, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4582, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4326, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4132, Accuracy: 0.7924, F1 Micro: 0.8837, F1 Macro: 0.8822\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4395, Accuracy: 0.7939, F1 Micro: 0.8842, F1 Macro: 0.8826\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.4306, Accuracy: 0.7999, F1 Micro: 0.887, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3956, Accuracy: 0.8036, F1 Micro: 0.8888, F1 Macro: 0.8871\n",
      "\n",
      "Aspect detection accuracy: 0.8036, F1 Micro: 0.8888, F1 Macro: 0.8871\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.78      1.00      0.88       175\n",
      "      others       0.75      0.99      0.85       158\n",
      "        part       0.74      0.97      0.84       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.80      0.99      0.89      1061\n",
      "   macro avg       0.80      0.99      0.89      1061\n",
      "weighted avg       0.81      0.99      0.89      1061\n",
      " samples avg       0.81      0.99      0.89      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7142, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5719, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.6151, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5677, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.5123, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.5138, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4932, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3579, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3098, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2431, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "\n",
      "Sentiment analysis accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         6\n",
      "    positive       0.81      1.00      0.89        25\n",
      "\n",
      "    accuracy                           0.81        31\n",
      "   macro avg       0.40      0.50      0.45        31\n",
      "weighted avg       0.65      0.81      0.72        31\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.7994, F1 Micro: 0.7994, F1 Macro: 0.3298\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.77      1.00      0.87       167\n",
      "    positive       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.77       216\n",
      "   macro avg       0.26      0.33      0.29       216\n",
      "weighted avg       0.60      0.77      0.67       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.75      0.99      0.85       152\n",
      "    positive       0.67      0.19      0.30        52\n",
      "\n",
      "    accuracy                           0.74       216\n",
      "   macro avg       0.47      0.39      0.38       216\n",
      "weighted avg       0.69      0.74      0.67       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        23\n",
      "     neutral       0.74      0.97      0.84       152\n",
      "    positive       0.56      0.22      0.32        41\n",
      "\n",
      "    accuracy                           0.73       216\n",
      "   macro avg       0.43      0.40      0.39       216\n",
      "weighted avg       0.63      0.73      0.65       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 66.14356112480164 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.004518020898103714\n",
      "Acquired samples: 82\n",
      "Sampling duration: 13.811268091201782 seconds\n",
      "New train size: 136\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6205, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5585, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5256, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4961, Accuracy: 0.8028, F1 Micro: 0.8881, F1 Macro: 0.8863\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.483, Accuracy: 0.8058, F1 Micro: 0.8897, F1 Macro: 0.888\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4131, Accuracy: 0.814, F1 Micro: 0.8935, F1 Macro: 0.8916\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3886, Accuracy: 0.8266, F1 Micro: 0.8994, F1 Macro: 0.8975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3387, Accuracy: 0.8438, F1 Micro: 0.9077, F1 Macro: 0.9055\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2886, Accuracy: 0.8579, F1 Micro: 0.9159, F1 Macro: 0.9144\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2587, Accuracy: 0.872, F1 Micro: 0.9227, F1 Macro: 0.9205\n",
      "\n",
      "Aspect detection accuracy: 0.872, F1 Micro: 0.9227, F1 Macro: 0.9205\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.92      0.99      0.95       187\n",
      "     machine       0.82      0.99      0.89       175\n",
      "      others       0.88      0.84      0.86       158\n",
      "        part       0.87      0.97      0.92       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.96      0.99      0.97       191\n",
      "\n",
      "   micro avg       0.88      0.97      0.92      1061\n",
      "   macro avg       0.88      0.96      0.92      1061\n",
      "weighted avg       0.88      0.97      0.92      1061\n",
      " samples avg       0.89      0.97      0.92      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.551, Accuracy: 0.7701, F1 Micro: 0.7701, F1 Macro: 0.4351\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4534, Accuracy: 0.7701, F1 Micro: 0.7701, F1 Macro: 0.4351\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4111, Accuracy: 0.7701, F1 Micro: 0.7701, F1 Macro: 0.4351\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3035, Accuracy: 0.7816, F1 Micro: 0.7816, F1 Macro: 0.4855\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2234, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8655\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1284, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0868, Accuracy: 0.931, F1 Micro: 0.931, F1 Macro: 0.9058\n",
      "Epoch 8/10, Train Loss: 0.0842, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.8818\n",
      "Epoch 9/10, Train Loss: 0.0854, Accuracy: 0.9195, F1 Micro: 0.9195, F1 Macro: 0.8902\n",
      "Epoch 10/10, Train Loss: 0.0161, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.8818\n",
      "\n",
      "Sentiment analysis accuracy: 0.931, F1 Micro: 0.931, F1 Macro: 0.9058\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.90      0.86        40\n",
      "    positive       0.97      0.94      0.95       134\n",
      "\n",
      "    accuracy                           0.93       174\n",
      "   macro avg       0.89      0.92      0.91       174\n",
      "weighted avg       0.93      0.93      0.93       174\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 136: Accuracy: 0.8634, F1 Micro: 0.8634, F1 Macro: 0.6356\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.36      0.53        11\n",
      "     neutral       0.92      0.99      0.95       181\n",
      "    positive       0.88      0.62      0.73        24\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.93      0.66      0.74       216\n",
      "weighted avg       0.92      0.92      0.91       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.12      0.22        16\n",
      "     neutral       0.81      0.99      0.89       167\n",
      "    positive       0.80      0.24      0.37        33\n",
      "\n",
      "    accuracy                           0.81       216\n",
      "   macro avg       0.87      0.45      0.49       216\n",
      "weighted avg       0.82      0.81      0.76       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.47      0.67      0.55        12\n",
      "     neutral       0.88      0.84      0.86       152\n",
      "    positive       0.62      0.65      0.64        52\n",
      "\n",
      "    accuracy                           0.78       216\n",
      "   macro avg       0.66      0.72      0.68       216\n",
      "weighted avg       0.80      0.78      0.79       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.52      0.65        23\n",
      "     neutral       0.87      0.98      0.92       152\n",
      "    positive       0.87      0.63      0.73        41\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.86      0.71      0.77       216\n",
      "weighted avg       0.87      0.87      0.86       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.86      0.83        14\n",
      "     neutral       0.96      0.99      0.97       185\n",
      "    positive       0.90      0.53      0.67        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.79      0.82       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Total train time: 73.81687617301941 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.008940141089260579\n",
      "Acquired samples: 73\n",
      "Sampling duration: 14.529780864715576 seconds\n",
      "New train size: 209\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.595, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5147, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4887, Accuracy: 0.8006, F1 Micro: 0.8879, F1 Macro: 0.8864\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4587, Accuracy: 0.8058, F1 Micro: 0.89, F1 Macro: 0.8884\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4261, Accuracy: 0.8207, F1 Micro: 0.8968, F1 Macro: 0.8951\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3735, Accuracy: 0.8438, F1 Micro: 0.9082, F1 Macro: 0.9067\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2986, Accuracy: 0.8862, F1 Micro: 0.9316, F1 Macro: 0.93\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2613, Accuracy: 0.907, F1 Micro: 0.9428, F1 Macro: 0.9401\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1996, Accuracy: 0.9174, F1 Micro: 0.9488, F1 Macro: 0.9449\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1656, Accuracy: 0.9308, F1 Micro: 0.9572, F1 Macro: 0.9551\n",
      "\n",
      "Aspect detection accuracy: 0.9308, F1 Micro: 0.9572, F1 Macro: 0.9551\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.97      1.00      0.99       187\n",
      "     machine       0.93      0.97      0.95       175\n",
      "      others       0.89      0.92      0.91       158\n",
      "        part       0.89      0.98      0.93       158\n",
      "       price       0.95      1.00      0.97       192\n",
      "     service       0.97      0.99      0.98       191\n",
      "\n",
      "   micro avg       0.94      0.98      0.96      1061\n",
      "   macro avg       0.93      0.98      0.96      1061\n",
      "weighted avg       0.94      0.98      0.96      1061\n",
      " samples avg       0.94      0.98      0.95      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6172, Accuracy: 0.7022, F1 Micro: 0.7022, F1 Macro: 0.4125\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4545, Accuracy: 0.8267, F1 Micro: 0.8267, F1 Macro: 0.8043\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3328, Accuracy: 0.8889, F1 Micro: 0.8889, F1 Macro: 0.877\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.203, Accuracy: 0.9156, F1 Micro: 0.9156, F1 Macro: 0.9026\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1267, Accuracy: 0.9244, F1 Micro: 0.9244, F1 Macro: 0.9108\n",
      "Epoch 6/10, Train Loss: 0.1258, Accuracy: 0.92, F1 Micro: 0.92, F1 Macro: 0.9088\n",
      "Epoch 7/10, Train Loss: 0.1122, Accuracy: 0.9156, F1 Micro: 0.9156, F1 Macro: 0.9003\n",
      "Epoch 8/10, Train Loss: 0.1046, Accuracy: 0.92, F1 Micro: 0.92, F1 Macro: 0.9067\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1107, Accuracy: 0.9244, F1 Micro: 0.9244, F1 Macro: 0.9122\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1046, Accuracy: 0.9244, F1 Micro: 0.9244, F1 Macro: 0.9108\n",
      "\n",
      "Sentiment analysis accuracy: 0.9244, F1 Micro: 0.9244, F1 Macro: 0.9108\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.90      0.88        67\n",
      "    positive       0.95      0.94      0.95       158\n",
      "\n",
      "    accuracy                           0.92       225\n",
      "   macro avg       0.91      0.92      0.91       225\n",
      "weighted avg       0.93      0.92      0.92       225\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 209: Accuracy: 0.9198, F1 Micro: 0.9198, F1 Macro: 0.8269\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       1.00      0.88      0.93        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.99      0.93      0.96       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.93      0.96      0.94       167\n",
      "    positive       0.78      0.64      0.70        33\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.86      0.80      0.83       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.56      0.42      0.48        12\n",
      "     neutral       0.89      0.92      0.91       152\n",
      "    positive       0.74      0.71      0.73        52\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.73      0.68      0.70       216\n",
      "weighted avg       0.84      0.84      0.84       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.65      0.75        23\n",
      "     neutral       0.89      0.99      0.93       152\n",
      "    positive       0.90      0.66      0.76        41\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.89      0.77      0.82       216\n",
      "weighted avg       0.89      0.89      0.88       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.46      0.60        13\n",
      "     neutral       0.95      1.00      0.97       186\n",
      "    positive       0.85      0.65      0.73        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.70      0.77       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.79      0.85        14\n",
      "     neutral       0.97      0.99      0.98       185\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.85      0.89       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Total train time: 86.90713000297546 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.006170511245727539\n",
      "Acquired samples: 66\n",
      "Sampling duration: 17.323880195617676 seconds\n",
      "New train size: 275\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5744, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 2/10, Train Loss: 0.5009, Accuracy: 0.7894, F1 Micro: 0.8804, F1 Macro: 0.8777\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4685, Accuracy: 0.8028, F1 Micro: 0.8878, F1 Macro: 0.8856\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4321, Accuracy: 0.814, F1 Micro: 0.8921, F1 Macro: 0.8893\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3679, Accuracy: 0.8542, F1 Micro: 0.9132, F1 Macro: 0.9108\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2984, Accuracy: 0.8981, F1 Micro: 0.9365, F1 Macro: 0.9314\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2436, Accuracy: 0.9174, F1 Micro: 0.9488, F1 Macro: 0.9454\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1861, Accuracy: 0.9315, F1 Micro: 0.9575, F1 Macro: 0.9548\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1476, Accuracy: 0.9323, F1 Micro: 0.9575, F1 Macro: 0.9536\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1285, Accuracy: 0.9338, F1 Micro: 0.9582, F1 Macro: 0.9541\n",
      "\n",
      "Aspect detection accuracy: 0.9338, F1 Micro: 0.9582, F1 Macro: 0.9541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.97      0.96       175\n",
      "      others       0.91      0.80      0.86       158\n",
      "        part       0.92      0.98      0.95       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       0.97      0.99      0.98       191\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      1061\n",
      "   macro avg       0.95      0.96      0.95      1061\n",
      "weighted avg       0.95      0.96      0.96      1061\n",
      " samples avg       0.96      0.96      0.95      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6142, Accuracy: 0.7068, F1 Micro: 0.7068, F1 Macro: 0.4141\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4114, Accuracy: 0.8797, F1 Micro: 0.8797, F1 Macro: 0.8549\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.226, Accuracy: 0.906, F1 Micro: 0.906, F1 Macro: 0.8879\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.16, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.8969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1025, Accuracy: 0.9211, F1 Micro: 0.9211, F1 Macro: 0.9013\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1443, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9165\n",
      "Epoch 7/10, Train Loss: 0.103, Accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.903\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0799, Accuracy: 0.9361, F1 Micro: 0.9361, F1 Macro: 0.9232\n",
      "Epoch 9/10, Train Loss: 0.1134, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9154\n",
      "Epoch 10/10, Train Loss: 0.0627, Accuracy: 0.9248, F1 Micro: 0.9248, F1 Macro: 0.9064\n",
      "\n",
      "Sentiment analysis accuracy: 0.9361, F1 Micro: 0.9361, F1 Macro: 0.9232\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.90      0.89        78\n",
      "    positive       0.96      0.95      0.95       188\n",
      "\n",
      "    accuracy                           0.94       266\n",
      "   macro avg       0.92      0.92      0.92       266\n",
      "weighted avg       0.94      0.94      0.94       266\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 275: Accuracy: 0.9221, F1 Micro: 0.9221, F1 Macro: 0.8484\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.88      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.69      0.81        16\n",
      "     neutral       0.95      0.96      0.96       167\n",
      "    positive       0.74      0.79      0.76        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.90      0.81      0.85       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.67      0.70        12\n",
      "     neutral       0.92      0.81      0.86       152\n",
      "    positive       0.61      0.83      0.70        52\n",
      "\n",
      "    accuracy                           0.81       216\n",
      "   macro avg       0.75      0.77      0.75       216\n",
      "weighted avg       0.83      0.81      0.81       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.83      0.86        23\n",
      "     neutral       0.92      0.98      0.95       152\n",
      "    positive       0.88      0.71      0.78        41\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.90      0.84      0.87       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.54      0.70        13\n",
      "     neutral       0.97      1.00      0.99       186\n",
      "    positive       0.72      0.76      0.74        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.90      0.77      0.81       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.79      0.85        14\n",
      "     neutral       0.97      0.99      0.98       185\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.87      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 86.77389717102051 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.008447544369846582\n",
      "Acquired samples: 59\n",
      "Sampling duration: 15.253789901733398 seconds\n",
      "New train size: 334\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5899, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5165, Accuracy: 0.7946, F1 Micro: 0.8834, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4603, Accuracy: 0.8095, F1 Micro: 0.89, F1 Macro: 0.8872\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.41, Accuracy: 0.8586, F1 Micro: 0.917, F1 Macro: 0.9161\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.318, Accuracy: 0.9115, F1 Micro: 0.9447, F1 Macro: 0.9407\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2452, Accuracy: 0.9219, F1 Micro: 0.9507, F1 Macro: 0.9464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1849, Accuracy: 0.9353, F1 Micro: 0.9591, F1 Macro: 0.9551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1447, Accuracy: 0.9435, F1 Micro: 0.9645, F1 Macro: 0.9617\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1172, Accuracy: 0.9472, F1 Micro: 0.9667, F1 Macro: 0.964\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.097, Accuracy: 0.9509, F1 Micro: 0.9691, F1 Macro: 0.9666\n",
      "\n",
      "Aspect detection accuracy: 0.9509, F1 Micro: 0.9691, F1 Macro: 0.9666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.91      0.89      0.90       158\n",
      "        part       0.93      0.98      0.96       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.97      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6263, Accuracy: 0.6873, F1 Micro: 0.6873, F1 Macro: 0.4073\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4418, Accuracy: 0.8726, F1 Micro: 0.8726, F1 Macro: 0.8568\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2793, Accuracy: 0.9189, F1 Micro: 0.9189, F1 Macro: 0.9094\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1958, Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9422\n",
      "Epoch 5/10, Train Loss: 0.1369, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9225\n",
      "Epoch 6/10, Train Loss: 0.1126, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9217\n",
      "Epoch 7/10, Train Loss: 0.1089, Accuracy: 0.9189, F1 Micro: 0.9189, F1 Macro: 0.9072\n",
      "Epoch 8/10, Train Loss: 0.1162, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9221\n",
      "Epoch 9/10, Train Loss: 0.109, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.918\n",
      "Epoch 10/10, Train Loss: 0.0617, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9221\n",
      "\n",
      "Sentiment analysis accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9422\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        81\n",
      "    positive       0.97      0.96      0.96       178\n",
      "\n",
      "    accuracy                           0.95       259\n",
      "   macro avg       0.94      0.95      0.94       259\n",
      "weighted avg       0.95      0.95      0.95       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 334: Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.8895\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.86      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.75      0.72        12\n",
      "     neutral       0.91      0.88      0.90       152\n",
      "    positive       0.70      0.75      0.72        52\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.77      0.79      0.78       216\n",
      "weighted avg       0.85      0.84      0.84       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.83      0.81        23\n",
      "     neutral       0.93      0.98      0.96       152\n",
      "    positive       0.91      0.71      0.79        41\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.88      0.84      0.85       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.90      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.93        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.76      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 88.5439567565918 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.006231543608009815\n",
      "Acquired samples: 54\n",
      "Sampling duration: 14.064307928085327 seconds\n",
      "New train size: 388\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5583, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5122, Accuracy: 0.7999, F1 Micro: 0.8863, F1 Macro: 0.8843\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4483, Accuracy: 0.8229, F1 Micro: 0.8963, F1 Macro: 0.8931\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3585, Accuracy: 0.8884, F1 Micro: 0.9325, F1 Macro: 0.9302\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2664, Accuracy: 0.9256, F1 Micro: 0.9539, F1 Macro: 0.9504\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2052, Accuracy: 0.9531, F1 Micro: 0.9709, F1 Macro: 0.9696\n",
      "Epoch 7/10, Train Loss: 0.1569, Accuracy: 0.9524, F1 Micro: 0.9701, F1 Macro: 0.9681\n",
      "Epoch 8/10, Train Loss: 0.1272, Accuracy: 0.9501, F1 Micro: 0.9686, F1 Macro: 0.9662\n",
      "Epoch 9/10, Train Loss: 0.0992, Accuracy: 0.9531, F1 Micro: 0.9705, F1 Macro: 0.9685\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0806, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9711\n",
      "\n",
      "Aspect detection accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9711\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.90      0.92      0.91       158\n",
      "        part       0.97      0.98      0.97       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      0.99      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5854, Accuracy: 0.6834, F1 Micro: 0.6834, F1 Macro: 0.406\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4026, Accuracy: 0.8996, F1 Micro: 0.8996, F1 Macro: 0.8904\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.191, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9185\n",
      "Epoch 4/10, Train Loss: 0.1608, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.8993\n",
      "Epoch 5/10, Train Loss: 0.1391, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.9025\n",
      "Epoch 6/10, Train Loss: 0.1166, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.9053\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0745, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9262\n",
      "Epoch 8/10, Train Loss: 0.0848, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9139\n",
      "Epoch 9/10, Train Loss: 0.0761, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9185\n",
      "Epoch 10/10, Train Loss: 0.0642, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9185\n",
      "\n",
      "Sentiment analysis accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9262\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.95      0.90        82\n",
      "    positive       0.98      0.93      0.95       177\n",
      "\n",
      "    accuracy                           0.93       259\n",
      "   macro avg       0.92      0.94      0.93       259\n",
      "weighted avg       0.94      0.93      0.94       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 388: Accuracy: 0.9452, F1 Micro: 0.9452, F1 Macro: 0.8946\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.81      0.79        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.85      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.90      0.91      0.91       152\n",
      "    positive       0.74      0.71      0.73        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.80      0.79      0.79       216\n",
      "weighted avg       0.85      0.86      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.96      0.86        23\n",
      "     neutral       0.97      0.98      0.97       152\n",
      "    positive       0.94      0.78      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.91      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.87      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.93        14\n",
      "     neutral       0.99      0.99      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 88.30289506912231 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.003477677144110203\n",
      "Acquired samples: 48\n",
      "Sampling duration: 12.758470296859741 seconds\n",
      "New train size: 436\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5568, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5212, Accuracy: 0.8043, F1 Micro: 0.8885, F1 Macro: 0.8865\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4344, Accuracy: 0.8668, F1 Micro: 0.9215, F1 Macro: 0.9206\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3155, Accuracy: 0.9263, F1 Micro: 0.9546, F1 Macro: 0.9529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2295, Accuracy: 0.9405, F1 Micro: 0.9625, F1 Macro: 0.9593\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1677, Accuracy: 0.9509, F1 Micro: 0.9692, F1 Macro: 0.9671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1368, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9711\n",
      "Epoch 8/10, Train Loss: 0.1081, Accuracy: 0.9554, F1 Micro: 0.972, F1 Macro: 0.9701\n",
      "Epoch 9/10, Train Loss: 0.089, Accuracy: 0.9509, F1 Micro: 0.9689, F1 Macro: 0.9655\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0801, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9742\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9742\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.93      0.93      0.93       158\n",
      "        part       0.97      0.98      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5756, Accuracy: 0.6962, F1 Micro: 0.6962, F1 Macro: 0.4828\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3281, Accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.9115\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2042, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9155\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1275, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9235\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1404, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9245\n",
      "Epoch 6/10, Train Loss: 0.127, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9109\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1193, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9305\n",
      "Epoch 8/10, Train Loss: 0.0946, Accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.9115\n",
      "Epoch 9/10, Train Loss: 0.0751, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9209\n",
      "Epoch 10/10, Train Loss: 0.0493, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9223\n",
      "\n",
      "Sentiment analysis accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9305\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.93      0.91        84\n",
      "    positive       0.97      0.94      0.95       176\n",
      "\n",
      "    accuracy                           0.94       260\n",
      "   macro avg       0.93      0.94      0.93       260\n",
      "weighted avg       0.94      0.94      0.94       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 436: Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.9054\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.85      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.79      0.81      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.85      0.83      0.84       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.91      0.86        23\n",
      "     neutral       0.97      0.98      0.97       152\n",
      "    positive       0.89      0.78      0.83        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 96.69632983207703 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.004586305283010006\n",
      "Acquired samples: 43\n",
      "Sampling duration: 11.743616104125977 seconds\n",
      "New train size: 479\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5464, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4781, Accuracy: 0.808, F1 Micro: 0.8912, F1 Macro: 0.8896\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4095, Accuracy: 0.881, F1 Micro: 0.9288, F1 Macro: 0.9281\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3016, Accuracy: 0.9263, F1 Micro: 0.9542, F1 Macro: 0.952\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2229, Accuracy: 0.9435, F1 Micro: 0.9647, F1 Macro: 0.9621\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1692, Accuracy: 0.9524, F1 Micro: 0.9702, F1 Macro: 0.9683\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1203, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1037, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9736\n",
      "Epoch 9/10, Train Loss: 0.0938, Accuracy: 0.9472, F1 Micro: 0.9665, F1 Macro: 0.9627\n",
      "Epoch 10/10, Train Loss: 0.0776, Accuracy: 0.9576, F1 Micro: 0.9732, F1 Macro: 0.9711\n",
      "\n",
      "Aspect detection accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9736\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.94      0.98      0.96       175\n",
      "      others       0.92      0.92      0.92       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5622, Accuracy: 0.6769, F1 Micro: 0.6769, F1 Macro: 0.4037\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3184, Accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.8991\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.158, Accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.9119\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1508, Accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.9119\n",
      "Epoch 5/10, Train Loss: 0.1534, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.8992\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1427, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9218\n",
      "Epoch 7/10, Train Loss: 0.115, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9191\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0917, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9272\n",
      "Epoch 9/10, Train Loss: 0.0895, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.9084\n",
      "Epoch 10/10, Train Loss: 0.0735, Accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.908\n",
      "\n",
      "Sentiment analysis accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9272\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.95      0.90        84\n",
      "    positive       0.98      0.93      0.95       176\n",
      "\n",
      "    accuracy                           0.93       260\n",
      "   macro avg       0.92      0.94      0.93       260\n",
      "weighted avg       0.94      0.93      0.94       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 479: Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.8803\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.62      0.69        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.77      0.73      0.75        33\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.83      0.78      0.80       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.40      0.83      0.54        12\n",
      "     neutral       0.94      0.88      0.91       152\n",
      "    positive       0.80      0.77      0.78        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.71      0.83      0.74       216\n",
      "weighted avg       0.88      0.85      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.87      0.85        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.87      0.83      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 103.03268241882324 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.004337621154263616\n",
      "Acquired samples: 39\n",
      "Sampling duration: 10.739980459213257 seconds\n",
      "New train size: 518\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5408, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4878, Accuracy: 0.8251, F1 Micro: 0.8997, F1 Macro: 0.8984\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3716, Accuracy: 0.9077, F1 Micro: 0.944, F1 Macro: 0.9433\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2628, Accuracy: 0.9397, F1 Micro: 0.9623, F1 Macro: 0.9593\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1843, Accuracy: 0.9494, F1 Micro: 0.9684, F1 Macro: 0.9663\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1384, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9713\n",
      "Epoch 7/10, Train Loss: 0.1162, Accuracy: 0.9546, F1 Micro: 0.9713, F1 Macro: 0.9692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0888, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0757, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0685, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9754\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9754\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.97      0.96       175\n",
      "      others       0.90      0.96      0.93       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5355, Accuracy: 0.8599, F1 Micro: 0.8599, F1 Macro: 0.8292\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2718, Accuracy: 0.9066, F1 Micro: 0.9066, F1 Macro: 0.8974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1921, Accuracy: 0.9105, F1 Micro: 0.9105, F1 Macro: 0.9019\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1508, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9177\n",
      "Epoch 5/10, Train Loss: 0.1047, Accuracy: 0.9066, F1 Micro: 0.9066, F1 Macro: 0.8979\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1143, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9264\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.099, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9297\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0901, Accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9385\n",
      "Epoch 9/10, Train Loss: 0.062, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9241\n",
      "Epoch 10/10, Train Loss: 0.0851, Accuracy: 0.9222, F1 Micro: 0.9222, F1 Macro: 0.9131\n",
      "\n",
      "Sentiment analysis accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9385\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.95      0.92        82\n",
      "    positive       0.98      0.94      0.96       175\n",
      "\n",
      "    accuracy                           0.95       257\n",
      "   macro avg       0.93      0.95      0.94       257\n",
      "weighted avg       0.95      0.95      0.95       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 518: Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.8984\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.95      0.97      0.96       167\n",
      "    positive       0.81      0.79      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.84      0.85       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.67      0.73        12\n",
      "     neutral       0.90      0.96      0.93       152\n",
      "    positive       0.86      0.73      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.85      0.79      0.82       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.91      0.82        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.89      0.76      0.82        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.88      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.85      0.81        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 111.16495323181152 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.005141957476735116\n",
      "Acquired samples: 22\n",
      "Sampling duration: 9.832183361053467 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5503, Accuracy: 0.7961, F1 Micro: 0.8849, F1 Macro: 0.883\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4798, Accuracy: 0.8125, F1 Micro: 0.8933, F1 Macro: 0.8918\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3821, Accuracy: 0.9107, F1 Micro: 0.9457, F1 Macro: 0.9448\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2674, Accuracy: 0.9412, F1 Micro: 0.9632, F1 Macro: 0.9603\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1886, Accuracy: 0.9554, F1 Micro: 0.9722, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1485, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9713\n",
      "Epoch 7/10, Train Loss: 0.1193, Accuracy: 0.9531, F1 Micro: 0.9704, F1 Macro: 0.9679\n",
      "Epoch 8/10, Train Loss: 0.0846, Accuracy: 0.9561, F1 Micro: 0.9722, F1 Macro: 0.9696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0731, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9751\n",
      "Epoch 10/10, Train Loss: 0.0653, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9737\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9751\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.94      0.93       158\n",
      "        part       0.98      0.97      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5882, Accuracy: 0.8008, F1 Micro: 0.8008, F1 Macro: 0.725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2773, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.8998\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1734, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9152\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1552, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9261\n",
      "Epoch 5/10, Train Loss: 0.1373, Accuracy: 0.9195, F1 Micro: 0.9195, F1 Macro: 0.9121\n",
      "Epoch 6/10, Train Loss: 0.1119, Accuracy: 0.9272, F1 Micro: 0.9272, F1 Macro: 0.9174\n",
      "Epoch 7/10, Train Loss: 0.1015, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9105\n",
      "Epoch 8/10, Train Loss: 0.1039, Accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.9035\n",
      "Epoch 9/10, Train Loss: 0.0625, Accuracy: 0.931, F1 Micro: 0.931, F1 Macro: 0.922\n",
      "Epoch 10/10, Train Loss: 0.053, Accuracy: 0.9195, F1 Micro: 0.9195, F1 Macro: 0.9112\n",
      "\n",
      "Sentiment analysis accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9261\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.92      0.90        84\n",
      "    positive       0.96      0.94      0.95       177\n",
      "\n",
      "    accuracy                           0.93       261\n",
      "   macro avg       0.92      0.93      0.93       261\n",
      "weighted avg       0.94      0.93      0.94       261\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.8863\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.91      0.82      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.45      0.75      0.56        12\n",
      "     neutral       0.94      0.91      0.92       152\n",
      "    positive       0.78      0.73      0.75        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.72      0.80      0.75       216\n",
      "weighted avg       0.87      0.86      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      1.00      0.84        23\n",
      "     neutral       0.98      0.95      0.97       152\n",
      "    positive       0.89      0.78      0.83        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.86      0.91      0.88       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.92      0.80        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.92      0.65      0.76        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.87      0.85      0.85       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 102.19160628318787 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.004025315213948488\n",
      "Acquired samples: 33\n",
      "Sampling duration: 9.143414735794067 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5388, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4722, Accuracy: 0.8318, F1 Micro: 0.9031, F1 Macro: 0.902\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3693, Accuracy: 0.91, F1 Micro: 0.9451, F1 Macro: 0.9437\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2451, Accuracy: 0.942, F1 Micro: 0.9639, F1 Macro: 0.9615\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1735, Accuracy: 0.9524, F1 Micro: 0.9701, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1382, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9748\n",
      "Epoch 7/10, Train Loss: 0.1102, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0894, Accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9775\n",
      "Epoch 9/10, Train Loss: 0.0693, Accuracy: 0.9591, F1 Micro: 0.9741, F1 Macro: 0.9716\n",
      "Epoch 10/10, Train Loss: 0.0659, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9768\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9775\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.91      0.97      0.94       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5317, Accuracy: 0.8725, F1 Micro: 0.8725, F1 Macro: 0.86\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2708, Accuracy: 0.9124, F1 Micro: 0.9124, F1 Macro: 0.9056\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2113, Accuracy: 0.9402, F1 Micro: 0.9402, F1 Macro: 0.9339\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1631, Accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.937\n",
      "Epoch 5/10, Train Loss: 0.126, Accuracy: 0.9402, F1 Micro: 0.9402, F1 Macro: 0.9342\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0963, Accuracy: 0.9482, F1 Micro: 0.9482, F1 Macro: 0.942\n",
      "Epoch 7/10, Train Loss: 0.103, Accuracy: 0.9402, F1 Micro: 0.9402, F1 Macro: 0.9327\n",
      "Epoch 8/10, Train Loss: 0.0848, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9262\n",
      "Epoch 9/10, Train Loss: 0.0577, Accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9377\n",
      "Epoch 10/10, Train Loss: 0.0532, Accuracy: 0.9124, F1 Micro: 0.9124, F1 Macro: 0.8977\n",
      "\n",
      "Sentiment analysis accuracy: 0.9482, F1 Micro: 0.9482, F1 Macro: 0.942\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.94      0.92        83\n",
      "    positive       0.97      0.95      0.96       168\n",
      "\n",
      "    accuracy                           0.95       251\n",
      "   macro avg       0.94      0.95      0.94       251\n",
      "weighted avg       0.95      0.95      0.95       251\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9483, F1 Micro: 0.9483, F1 Macro: 0.8789\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.88      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.56      0.69        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.77      0.73      0.75        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.87      0.76      0.80       216\n",
      "weighted avg       0.91      0.92      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.67      0.64        12\n",
      "     neutral       0.91      0.94      0.93       152\n",
      "    positive       0.87      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.80      0.79      0.79       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.88      0.85      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.90      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.88      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 104.42398691177368 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.0034467535791918645\n",
      "Acquired samples: 30\n",
      "Sampling duration: 8.579174518585205 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5435, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4614, Accuracy: 0.8393, F1 Micro: 0.9072, F1 Macro: 0.9061\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3401, Accuracy: 0.9293, F1 Micro: 0.9565, F1 Macro: 0.9548\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2411, Accuracy: 0.9561, F1 Micro: 0.9727, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1689, Accuracy: 0.9583, F1 Micro: 0.9741, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1293, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0934, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9763\n",
      "Epoch 8/10, Train Loss: 0.0863, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.975\n",
      "Epoch 9/10, Train Loss: 0.0681, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9759\n",
      "Epoch 10/10, Train Loss: 0.0561, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.975\n",
      "\n",
      "Aspect detection accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9763\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.91      0.95      0.93       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4993, Accuracy: 0.8824, F1 Micro: 0.8824, F1 Macro: 0.8684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2775, Accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.9047\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2009, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9386\n",
      "Epoch 4/10, Train Loss: 0.1295, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.915\n",
      "Epoch 5/10, Train Loss: 0.1506, Accuracy: 0.902, F1 Micro: 0.902, F1 Macro: 0.8954\n",
      "Epoch 6/10, Train Loss: 0.1277, Accuracy: 0.9059, F1 Micro: 0.9059, F1 Macro: 0.8993\n",
      "Epoch 7/10, Train Loss: 0.1241, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9265\n",
      "Epoch 8/10, Train Loss: 0.0689, Accuracy: 0.9137, F1 Micro: 0.9137, F1 Macro: 0.906\n",
      "Epoch 9/10, Train Loss: 0.0657, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9348\n",
      "Epoch 10/10, Train Loss: 0.0508, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9219\n",
      "\n",
      "Sentiment analysis accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9386\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        84\n",
      "    positive       0.97      0.95      0.96       171\n",
      "\n",
      "    accuracy                           0.95       255\n",
      "   macro avg       0.93      0.94      0.94       255\n",
      "weighted avg       0.95      0.95      0.95       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.8829\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.92      0.70      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.83      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.32      0.75      0.45        12\n",
      "     neutral       0.96      0.88      0.92       152\n",
      "    positive       0.80      0.75      0.77        52\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.69      0.79      0.71       216\n",
      "weighted avg       0.89      0.84      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.94      0.78      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.92      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.85      0.81        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 103.79942297935486 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.0028634088113903998\n",
      "Acquired samples: 27\n",
      "Sampling duration: 7.481983661651611 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5448, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4601, Accuracy: 0.8289, F1 Micro: 0.9007, F1 Macro: 0.8992\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3469, Accuracy: 0.9405, F1 Micro: 0.9632, F1 Macro: 0.9617\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2305, Accuracy: 0.9524, F1 Micro: 0.9704, F1 Macro: 0.9691\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1607, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1263, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0963, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9768\n",
      "Epoch 8/10, Train Loss: 0.0803, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.975\n",
      "Epoch 9/10, Train Loss: 0.0655, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0568, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9783\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9783\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.93      0.95      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5171, Accuracy: 0.8803, F1 Micro: 0.8803, F1 Macro: 0.8703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2611, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9353\n",
      "Epoch 3/10, Train Loss: 0.1914, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9315\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.129, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.936\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1345, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.936\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1151, Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9439\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0836, Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9481\n",
      "Epoch 8/10, Train Loss: 0.0793, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9387\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0739, Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9475\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0847, Accuracy: 0.9575, F1 Micro: 0.9575, F1 Macro: 0.9525\n",
      "\n",
      "Sentiment analysis accuracy: 0.9575, F1 Micro: 0.9575, F1 Macro: 0.9525\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94        84\n",
      "    positive       0.99      0.95      0.97       175\n",
      "\n",
      "    accuracy                           0.96       259\n",
      "   macro avg       0.94      0.96      0.95       259\n",
      "weighted avg       0.96      0.96      0.96       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9276\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.84      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.93      0.95      0.94       152\n",
      "    positive       0.84      0.79      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.84      0.83      0.83       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.95      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 116.54447770118713 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.003475978272035718\n",
      "Acquired samples: 18\n",
      "Sampling duration: 6.9838707447052 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5367, Accuracy: 0.8006, F1 Micro: 0.887, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4586, Accuracy: 0.84, F1 Micro: 0.9071, F1 Macro: 0.9062\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.329, Accuracy: 0.9397, F1 Micro: 0.9629, F1 Macro: 0.9613\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2203, Accuracy: 0.9598, F1 Micro: 0.975, F1 Macro: 0.9738\n",
      "Epoch 5/10, Train Loss: 0.1537, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1274, Accuracy: 0.968, F1 Micro: 0.98, F1 Macro: 0.979\n",
      "Epoch 7/10, Train Loss: 0.0989, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9774\n",
      "Epoch 8/10, Train Loss: 0.0753, Accuracy: 0.9613, F1 Micro: 0.9755, F1 Macro: 0.9737\n",
      "Epoch 9/10, Train Loss: 0.0639, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9757\n",
      "Epoch 10/10, Train Loss: 0.052, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9771\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.98, F1 Macro: 0.979\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.97      0.94       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.551, Accuracy: 0.873, F1 Micro: 0.873, F1 Macro: 0.8661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2113, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9335\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1521, Accuracy: 0.9508, F1 Micro: 0.9508, F1 Macro: 0.9464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1655, Accuracy: 0.9549, F1 Micro: 0.9549, F1 Macro: 0.9493\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.116, Accuracy: 0.959, F1 Micro: 0.959, F1 Macro: 0.9549\n",
      "Epoch 6/10, Train Loss: 0.0973, Accuracy: 0.9549, F1 Micro: 0.9549, F1 Macro: 0.9507\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0705, Accuracy: 0.9631, F1 Micro: 0.9631, F1 Macro: 0.9588\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0678, Accuracy: 0.9672, F1 Micro: 0.9672, F1 Macro: 0.9637\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0568, Accuracy: 0.9672, F1 Micro: 0.9672, F1 Macro: 0.9635\n",
      "Epoch 10/10, Train Loss: 0.0649, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9305\n",
      "\n",
      "Sentiment analysis accuracy: 0.9672, F1 Micro: 0.9672, F1 Macro: 0.9635\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.95      0.95        83\n",
      "    positive       0.98      0.98      0.98       161\n",
      "\n",
      "    accuracy                           0.97       244\n",
      "   macro avg       0.96      0.96      0.96       244\n",
      "weighted avg       0.97      0.97      0.97       244\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9491, F1 Micro: 0.9491, F1 Macro: 0.8818\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.75      0.77        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.82      0.85       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.45      0.83      0.59        12\n",
      "     neutral       0.96      0.93      0.94       152\n",
      "    positive       0.89      0.81      0.85        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.77      0.86      0.79       216\n",
      "weighted avg       0.92      0.89      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.87      0.78        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.92      0.80      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.87      0.88      0.87       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.69      0.72        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.85      0.82      0.83       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 112.54888677597046 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.0027802006341516973\n",
      "Acquired samples: 25\n",
      "Sampling duration: 6.344452619552612 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5359, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4373, Accuracy: 0.8683, F1 Micro: 0.9221, F1 Macro: 0.921\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.298, Accuracy: 0.9457, F1 Micro: 0.9659, F1 Macro: 0.9633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1995, Accuracy: 0.9568, F1 Micro: 0.9731, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1347, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1046, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9768\n",
      "Epoch 7/10, Train Loss: 0.0817, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9743\n",
      "Epoch 8/10, Train Loss: 0.068, Accuracy: 0.9628, F1 Micro: 0.9768, F1 Macro: 0.9758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0583, Accuracy: 0.9695, F1 Micro: 0.9809, F1 Macro: 0.9799\n",
      "Epoch 10/10, Train Loss: 0.0507, Accuracy: 0.9613, F1 Micro: 0.9755, F1 Macro: 0.9735\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9809, F1 Macro: 0.9799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.93      0.96      0.95       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5399, Accuracy: 0.8945, F1 Micro: 0.8945, F1 Macro: 0.8846\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2708, Accuracy: 0.8984, F1 Micro: 0.8984, F1 Macro: 0.8774\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1909, Accuracy: 0.9609, F1 Micro: 0.9609, F1 Macro: 0.9562\n",
      "Epoch 4/10, Train Loss: 0.1523, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9391\n",
      "Epoch 5/10, Train Loss: 0.1193, Accuracy: 0.9531, F1 Micro: 0.9531, F1 Macro: 0.9475\n",
      "Epoch 6/10, Train Loss: 0.1096, Accuracy: 0.9531, F1 Micro: 0.9531, F1 Macro: 0.9478\n",
      "Epoch 7/10, Train Loss: 0.0912, Accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9436\n",
      "Epoch 8/10, Train Loss: 0.0564, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.938\n",
      "Epoch 9/10, Train Loss: 0.0758, Accuracy: 0.9297, F1 Micro: 0.9297, F1 Macro: 0.9233\n",
      "Epoch 10/10, Train Loss: 0.0472, Accuracy: 0.9297, F1 Micro: 0.9297, F1 Macro: 0.9233\n",
      "\n",
      "Sentiment analysis accuracy: 0.9609, F1 Micro: 0.9609, F1 Macro: 0.9562\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.96      0.94        84\n",
      "    positive       0.98      0.96      0.97       172\n",
      "\n",
      "    accuracy                           0.96       256\n",
      "   macro avg       0.95      0.96      0.96       256\n",
      "weighted avg       0.96      0.96      0.96       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.946, F1 Micro: 0.946, F1 Macro: 0.884\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.81      0.79        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.92      0.70      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.83      0.85       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.33      0.83      0.48        12\n",
      "     neutral       0.96      0.88      0.92       152\n",
      "    positive       0.87      0.79      0.83        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.72      0.83      0.74       216\n",
      "weighted avg       0.91      0.86      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.91       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.85      0.79        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.88      0.87      0.87       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 113.20504021644592 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.0027804297162219885\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.824858903884888 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5322, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4511, Accuracy: 0.8594, F1 Micro: 0.9177, F1 Macro: 0.9176\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.306, Accuracy: 0.9397, F1 Micro: 0.9628, F1 Macro: 0.9611\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2065, Accuracy: 0.9531, F1 Micro: 0.9707, F1 Macro: 0.9691\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1463, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1162, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9779\n",
      "Epoch 7/10, Train Loss: 0.0925, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9771\n",
      "Epoch 8/10, Train Loss: 0.0762, Accuracy: 0.9613, F1 Micro: 0.9754, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0585, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9789\n",
      "Epoch 10/10, Train Loss: 0.0519, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9776\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.97      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.533, Accuracy: 0.8867, F1 Micro: 0.8867, F1 Macro: 0.8686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2676, Accuracy: 0.9297, F1 Micro: 0.9297, F1 Macro: 0.9216\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1848, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9352\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1294, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9349\n",
      "Epoch 5/10, Train Loss: 0.1095, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9311\n",
      "Epoch 6/10, Train Loss: 0.1043, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9307\n",
      "Epoch 7/10, Train Loss: 0.0769, Accuracy: 0.9102, F1 Micro: 0.9102, F1 Macro: 0.9027\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0601, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9345\n",
      "Epoch 9/10, Train Loss: 0.0686, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9258\n",
      "Epoch 10/10, Train Loss: 0.0641, Accuracy: 0.9297, F1 Micro: 0.9297, F1 Macro: 0.9207\n",
      "\n",
      "Sentiment analysis accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9345\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.95      0.91        83\n",
      "    positive       0.98      0.94      0.96       173\n",
      "\n",
      "    accuracy                           0.94       256\n",
      "   macro avg       0.93      0.94      0.93       256\n",
      "weighted avg       0.94      0.94      0.94       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9022\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.62      0.69        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.85      0.79      0.82       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.53      0.83      0.65        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.89      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.78      0.85      0.80       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.92      0.83      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.90      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 121.22051191329956 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.0022877593524754047\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.236782550811768 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5491, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4431, Accuracy: 0.8772, F1 Micro: 0.9266, F1 Macro: 0.9261\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2909, Accuracy: 0.9457, F1 Micro: 0.9663, F1 Macro: 0.9646\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.192, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1362, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9757\n",
      "Epoch 6/10, Train Loss: 0.112, Accuracy: 0.9591, F1 Micro: 0.974, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0847, Accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9786\n",
      "Epoch 8/10, Train Loss: 0.0681, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9784\n",
      "Epoch 9/10, Train Loss: 0.0597, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0497, Accuracy: 0.9695, F1 Micro: 0.9809, F1 Macro: 0.9799\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9809, F1 Macro: 0.9799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.97      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4726, Accuracy: 0.8867, F1 Micro: 0.8867, F1 Macro: 0.8794\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2504, Accuracy: 0.9219, F1 Micro: 0.9219, F1 Macro: 0.9148\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1697, Accuracy: 0.9258, F1 Micro: 0.9258, F1 Macro: 0.9188\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1765, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9245\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1294, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9287\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1123, Accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9429\n",
      "Epoch 7/10, Train Loss: 0.0928, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9352\n",
      "Epoch 8/10, Train Loss: 0.0696, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.927\n",
      "Epoch 9/10, Train Loss: 0.068, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9391\n",
      "Epoch 10/10, Train Loss: 0.0484, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.938\n",
      "\n",
      "Sentiment analysis accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9429\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.92        83\n",
      "    positive       0.98      0.95      0.96       173\n",
      "\n",
      "    accuracy                           0.95       256\n",
      "   macro avg       0.94      0.95      0.94       256\n",
      "weighted avg       0.95      0.95      0.95       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9162\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.69      0.79        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.79      0.79      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.82      0.85       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.92      0.97      0.95       152\n",
      "    positive       0.91      0.77      0.83        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.88      0.83      0.85       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.95      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.89      1.00      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 122.31033706665039 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.002551960968412459\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.632457494735718 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5291, Accuracy: 0.7954, F1 Micro: 0.8853, F1 Macro: 0.8838\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.426, Accuracy: 0.8906, F1 Micro: 0.9349, F1 Macro: 0.9342\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2829, Accuracy: 0.9509, F1 Micro: 0.9694, F1 Macro: 0.968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1792, Accuracy: 0.9561, F1 Micro: 0.9726, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1259, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1029, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.081, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.978\n",
      "Epoch 8/10, Train Loss: 0.0639, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9766\n",
      "Epoch 9/10, Train Loss: 0.0568, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "Epoch 10/10, Train Loss: 0.0456, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9766\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.93      0.97      0.95       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5626, Accuracy: 0.8906, F1 Micro: 0.8906, F1 Macro: 0.8781\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2999, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9274\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2034, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.93\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1571, Accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9439\n",
      "Epoch 5/10, Train Loss: 0.1432, Accuracy: 0.918, F1 Micro: 0.918, F1 Macro: 0.9111\n",
      "Epoch 6/10, Train Loss: 0.1322, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9356\n",
      "Epoch 7/10, Train Loss: 0.092, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9394\n",
      "Epoch 8/10, Train Loss: 0.0706, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9356\n",
      "Epoch 9/10, Train Loss: 0.0683, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9315\n",
      "Epoch 10/10, Train Loss: 0.0676, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9345\n",
      "\n",
      "Sentiment analysis accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9439\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.96      0.93        85\n",
      "    positive       0.98      0.94      0.96       171\n",
      "\n",
      "    accuracy                           0.95       256\n",
      "   macro avg       0.94      0.95      0.94       256\n",
      "weighted avg       0.95      0.95      0.95       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.8971\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.79      0.70      0.74        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.87      0.83      0.85       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.53      0.75      0.62        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.88      0.81      0.84        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.78      0.83      0.80       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.94      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.85      0.79        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.86      0.87      0.86       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 119.74896693229675 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.0027540032751858234\n",
      "Acquired samples: 8\n",
      "Sampling duration: 3.9588024616241455 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5188, Accuracy: 0.8006, F1 Micro: 0.8879, F1 Macro: 0.8864\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4271, Accuracy: 0.8958, F1 Micro: 0.9373, F1 Macro: 0.9362\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2916, Accuracy: 0.9457, F1 Micro: 0.9662, F1 Macro: 0.9646\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1871, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1385, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1071, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.082, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0675, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9785\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0567, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.979\n",
      "Epoch 10/10, Train Loss: 0.046, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9758\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.979\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      0.98      0.96       175\n",
      "      others       0.94      0.96      0.95       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5323, Accuracy: 0.9, F1 Micro: 0.9, F1 Macro: 0.8912\n",
      "Epoch 2/10, Train Loss: 0.3023, Accuracy: 0.8923, F1 Micro: 0.8923, F1 Macro: 0.8854\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1983, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9218\n",
      "Epoch 4/10, Train Loss: 0.1504, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.9079\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1481, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9305\n",
      "Epoch 6/10, Train Loss: 0.1064, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9276\n",
      "Epoch 7/10, Train Loss: 0.1152, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.928\n",
      "Epoch 8/10, Train Loss: 0.0746, Accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.9068\n",
      "Epoch 9/10, Train Loss: 0.0765, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.907\n",
      "Epoch 10/10, Train Loss: 0.0528, Accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.8991\n",
      "\n",
      "Sentiment analysis accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9305\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.92      0.91        85\n",
      "    positive       0.96      0.95      0.95       175\n",
      "\n",
      "    accuracy                           0.94       260\n",
      "   macro avg       0.93      0.93      0.93       260\n",
      "weighted avg       0.94      0.94      0.94       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.946, F1 Micro: 0.946, F1 Macro: 0.8793\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.91      0.88      0.89        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.88      0.82        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.85      0.67      0.75        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.86      0.84      0.84       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.42      0.83      0.56        12\n",
      "     neutral       0.95      0.90      0.93       152\n",
      "    positive       0.85      0.79      0.82        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.74      0.84      0.77       216\n",
      "weighted avg       0.90      0.87      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.92      0.91       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.85      0.76        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.87      0.85      0.85       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 126.34484720230103 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.002132221544161439\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.7765424251556396 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5233, Accuracy: 0.7984, F1 Micro: 0.8868, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4283, Accuracy: 0.8876, F1 Micro: 0.9329, F1 Macro: 0.9324\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2773, Accuracy: 0.9524, F1 Micro: 0.9705, F1 Macro: 0.9692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1781, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1287, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9754\n",
      "Epoch 6/10, Train Loss: 0.1008, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0741, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0686, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9785\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.056, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9797\n",
      "Epoch 10/10, Train Loss: 0.048, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9797\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.96      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5038, Accuracy: 0.9046, F1 Micro: 0.9046, F1 Macro: 0.895\n",
      "Epoch 2/10, Train Loss: 0.2833, Accuracy: 0.8969, F1 Micro: 0.8969, F1 Macro: 0.8906\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1828, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.9327\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1617, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.933\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1164, Accuracy: 0.9427, F1 Micro: 0.9427, F1 Macro: 0.9367\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1153, Accuracy: 0.9466, F1 Micro: 0.9466, F1 Macro: 0.9401\n",
      "Epoch 7/10, Train Loss: 0.0767, Accuracy: 0.9427, F1 Micro: 0.9427, F1 Macro: 0.9364\n",
      "Epoch 8/10, Train Loss: 0.0778, Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.9226\n",
      "Epoch 9/10, Train Loss: 0.0746, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.9323\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0575, Accuracy: 0.9466, F1 Micro: 0.9466, F1 Macro: 0.9404\n",
      "\n",
      "Sentiment analysis accuracy: 0.9466, F1 Micro: 0.9466, F1 Macro: 0.9404\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.95      0.92        86\n",
      "    positive       0.98      0.94      0.96       176\n",
      "\n",
      "    accuracy                           0.95       262\n",
      "   macro avg       0.93      0.95      0.94       262\n",
      "weighted avg       0.95      0.95      0.95       262\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.9168\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.86      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.58      0.92      0.71        12\n",
      "     neutral       0.94      0.93      0.93       152\n",
      "    positive       0.87      0.79      0.83        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.80      0.88      0.82       216\n",
      "weighted avg       0.90      0.89      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.95      0.88      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.95      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 126.82125806808472 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0019699406111612916\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.0493805408477783 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5327, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.417, Accuracy: 0.9077, F1 Micro: 0.9441, F1 Macro: 0.943\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.263, Accuracy: 0.9509, F1 Micro: 0.9697, F1 Macro: 0.9685\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1713, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1272, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9765\n",
      "Epoch 6/10, Train Loss: 0.0962, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9726\n",
      "Epoch 7/10, Train Loss: 0.0798, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0587, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9779\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0554, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9778\n",
      "Epoch 10/10, Train Loss: 0.0462, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9772\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.93      0.96      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4722, Accuracy: 0.8992, F1 Micro: 0.8992, F1 Macro: 0.8917\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2341, Accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.9169\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2009, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9269\n",
      "Epoch 4/10, Train Loss: 0.1577, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.921\n",
      "Epoch 5/10, Train Loss: 0.1333, Accuracy: 0.9147, F1 Micro: 0.9147, F1 Macro: 0.901\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1062, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9269\n",
      "Epoch 7/10, Train Loss: 0.097, Accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.9196\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0707, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9314\n",
      "Epoch 9/10, Train Loss: 0.0603, Accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.9151\n",
      "Epoch 10/10, Train Loss: 0.0403, Accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.9187\n",
      "\n",
      "Sentiment analysis accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9314\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.95      0.91        85\n",
      "    positive       0.98      0.93      0.95       173\n",
      "\n",
      "    accuracy                           0.94       258\n",
      "   macro avg       0.92      0.94      0.93       258\n",
      "weighted avg       0.94      0.94      0.94       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.8972\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.81      0.79        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.84      0.85       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.59      0.83      0.69        12\n",
      "     neutral       0.94      0.94      0.94       152\n",
      "    positive       0.83      0.75      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.79      0.84      0.81       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.91       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.85      0.81        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 126.20789361000061 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0019307264126837255\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.4534213542938232 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5293, Accuracy: 0.7939, F1 Micro: 0.8809, F1 Macro: 0.8763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4053, Accuracy: 0.9196, F1 Micro: 0.9513, F1 Macro: 0.9503\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2562, Accuracy: 0.9524, F1 Micro: 0.9705, F1 Macro: 0.9695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1706, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1249, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0971, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.978\n",
      "Epoch 7/10, Train Loss: 0.0723, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9751\n",
      "Epoch 8/10, Train Loss: 0.0642, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.977\n",
      "Epoch 9/10, Train Loss: 0.0536, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9742\n",
      "Epoch 10/10, Train Loss: 0.0457, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9768\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      0.99      0.96       175\n",
      "      others       0.93      0.97      0.95       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5123, Accuracy: 0.8984, F1 Micro: 0.8984, F1 Macro: 0.8897\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2636, Accuracy: 0.918, F1 Micro: 0.918, F1 Macro: 0.9111\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1873, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9349\n",
      "Epoch 4/10, Train Loss: 0.1372, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.924\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0873, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9352\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0986, Accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9436\n",
      "Epoch 7/10, Train Loss: 0.0669, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9311\n",
      "Epoch 8/10, Train Loss: 0.0652, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9352\n",
      "Epoch 9/10, Train Loss: 0.08, Accuracy: 0.9258, F1 Micro: 0.9258, F1 Macro: 0.9188\n",
      "Epoch 10/10, Train Loss: 0.0449, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.927\n",
      "\n",
      "Sentiment analysis accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9436\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.96      0.93        84\n",
      "    positive       0.98      0.94      0.96       172\n",
      "\n",
      "    accuracy                           0.95       256\n",
      "   macro avg       0.94      0.95      0.94       256\n",
      "weighted avg       0.95      0.95      0.95       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.8976\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.88      0.82        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.92      0.70      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.85      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.45      0.83      0.59        12\n",
      "     neutral       0.95      0.91      0.93       152\n",
      "    positive       0.87      0.79      0.83        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.76      0.85      0.78       216\n",
      "weighted avg       0.90      0.88      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.92      0.83        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.87      0.89      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 124.3079571723938 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0017135688452981413\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.785640001296997 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5252, Accuracy: 0.7969, F1 Micro: 0.886, F1 Macro: 0.8846\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4134, Accuracy: 0.9211, F1 Micro: 0.9523, F1 Macro: 0.9513\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2573, Accuracy: 0.9546, F1 Micro: 0.972, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1643, Accuracy: 0.9621, F1 Micro: 0.9763, F1 Macro: 0.9752\n",
      "Epoch 5/10, Train Loss: 0.1213, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1005, Accuracy: 0.9688, F1 Micro: 0.9805, F1 Macro: 0.9794\n",
      "Epoch 7/10, Train Loss: 0.0703, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9789\n",
      "Epoch 8/10, Train Loss: 0.0628, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "Epoch 9/10, Train Loss: 0.0541, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9764\n",
      "Epoch 10/10, Train Loss: 0.0439, Accuracy: 0.9613, F1 Micro: 0.9754, F1 Macro: 0.9733\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9805, F1 Macro: 0.9794\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.97      0.94       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4608, Accuracy: 0.9393, F1 Micro: 0.9393, F1 Macro: 0.9336\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2322, Accuracy: 0.9433, F1 Micro: 0.9433, F1 Macro: 0.9376\n",
      "Epoch 3/10, Train Loss: 0.1437, Accuracy: 0.9312, F1 Micro: 0.9312, F1 Macro: 0.9252\n",
      "Epoch 4/10, Train Loss: 0.0975, Accuracy: 0.9352, F1 Micro: 0.9352, F1 Macro: 0.9294\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0936, Accuracy: 0.9433, F1 Micro: 0.9433, F1 Macro: 0.9365\n",
      "Epoch 6/10, Train Loss: 0.097, Accuracy: 0.9312, F1 Micro: 0.9312, F1 Macro: 0.9248\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0694, Accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9415\n",
      "Epoch 8/10, Train Loss: 0.0621, Accuracy: 0.9433, F1 Micro: 0.9433, F1 Macro: 0.9376\n",
      "Epoch 9/10, Train Loss: 0.0514, Accuracy: 0.9393, F1 Micro: 0.9393, F1 Macro: 0.9322\n",
      "Epoch 10/10, Train Loss: 0.0576, Accuracy: 0.9393, F1 Micro: 0.9393, F1 Macro: 0.9309\n",
      "\n",
      "Sentiment analysis accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9415\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.92        82\n",
      "    positive       0.97      0.95      0.96       165\n",
      "\n",
      "    accuracy                           0.95       247\n",
      "   macro avg       0.94      0.95      0.94       247\n",
      "weighted avg       0.95      0.95      0.95       247\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.8836\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.73      0.76        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.88      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.87      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.69      0.71        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.85      0.81      0.83       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.38      1.00      0.55        12\n",
      "     neutral       0.96      0.87      0.91       152\n",
      "    positive       0.91      0.81      0.86        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.75      0.89      0.77       216\n",
      "weighted avg       0.91      0.86      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.96      0.85        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.90      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 123.14709973335266 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0013024846324697138\n",
      "Acquired samples: 8\n",
      "Sampling duration: 1.093106746673584 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5219, Accuracy: 0.7976, F1 Micro: 0.8864, F1 Macro: 0.885\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4004, Accuracy: 0.9204, F1 Micro: 0.9511, F1 Macro: 0.9496\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2457, Accuracy: 0.9524, F1 Micro: 0.9704, F1 Macro: 0.9689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1689, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1222, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9773\n",
      "Epoch 6/10, Train Loss: 0.0919, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9771\n",
      "Epoch 7/10, Train Loss: 0.0746, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9742\n",
      "Epoch 8/10, Train Loss: 0.0598, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9764\n",
      "Epoch 9/10, Train Loss: 0.0498, Accuracy: 0.9613, F1 Micro: 0.9755, F1 Macro: 0.9734\n",
      "Epoch 10/10, Train Loss: 0.044, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9756\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.94      0.94      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4917, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.9004\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2277, Accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.9393\n",
      "Epoch 3/10, Train Loss: 0.1384, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9201\n",
      "Epoch 4/10, Train Loss: 0.1135, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9197\n",
      "Epoch 5/10, Train Loss: 0.112, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9168\n",
      "Epoch 6/10, Train Loss: 0.0698, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9318\n",
      "Epoch 7/10, Train Loss: 0.0737, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.895\n",
      "Epoch 8/10, Train Loss: 0.0593, Accuracy: 0.9432, F1 Micro: 0.9432, F1 Macro: 0.9363\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0704, Accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.9403\n",
      "Epoch 10/10, Train Loss: 0.0497, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.926\n",
      "\n",
      "Sentiment analysis accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.9403\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        84\n",
      "    positive       0.98      0.94      0.96       180\n",
      "\n",
      "    accuracy                           0.95       264\n",
      "   macro avg       0.93      0.95      0.94       264\n",
      "weighted avg       0.95      0.95      0.95       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.8961\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.92      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.88      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.84      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      1.00      0.75        12\n",
      "     neutral       0.97      0.92      0.94       152\n",
      "    positive       0.84      0.83      0.83        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.80      0.92      0.84       216\n",
      "weighted avg       0.92      0.90      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.92      0.88      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.77      0.74        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.86      0.86      0.86       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 122.18062233924866 s\n",
      "Total runtime: 2913.4949836730957 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[4], 4)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6159439,
     "sourceId": 10801903,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6132.479116,
   "end_time": "2025-03-23T15:06:29.948611",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-23T13:24:17.469495",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "06b0dda3371840e190dbf6d9341ad965": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0a8183b1a81c4f96b95086fddd1ba9b2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7012364fc1e844c89a4cb6143f7c712d",
        "IPY_MODEL_853edc29d2da4a48a1fdaa00d540b9df",
        "IPY_MODEL_7f49882cf96947fbb3c1d5abffc0ad8b"
       ],
       "layout": "IPY_MODEL_a9b04b6e5fd044bdbb9ffe8644b1c778",
       "tabbable": null,
       "tooltip": null
      }
     },
     "0e0c6ff26b1e4256946b738ef22e4f50": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1602e2173c484e5bbe92ec2d1f1dd4ed": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e8a9eaa86c574423b7fda0f159b88366",
       "placeholder": "​",
       "style": "IPY_MODEL_fc4b165586444e24b0a4410500f198c8",
       "tabbable": null,
       "tooltip": null,
       "value": " 2.00/2.00 [00:00&lt;00:00, 171B/s]"
      }
     },
     "19e3e897d51f49dc810f331ff7140abc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f71aa59d83494a3e83c8a1c3a340c010",
       "placeholder": "​",
       "style": "IPY_MODEL_692fe00851b9454cae3a4e94766d5e8b",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: 100%"
      }
     },
     "1cd4afafeb05449296dc29ce7341d247": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_eda0ef7650574d38b2602d9855ab44b8",
       "placeholder": "​",
       "style": "IPY_MODEL_5fb4301967504350bdae8cc693bcf7af",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json: 100%"
      }
     },
     "1cfb147e84a042c4b15058a167cd64e7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_bbcba25434be48a09593a99e5ec59d54",
       "max": 2,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_7e306376cf9540a3934c1fba0dc070bf",
       "tabbable": null,
       "tooltip": null,
       "value": 2
      }
     },
     "2013276456d749e8a857640be5f94b3d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "2c6c5aab94634158877f73915ae749ec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d8eb1af70d99419a9d8cd3d3a3e4fabf",
        "IPY_MODEL_b48f841b1bd4431f9e64f5398f7121bd",
        "IPY_MODEL_ea7658ff761f42ad8e5db963211a9538"
       ],
       "layout": "IPY_MODEL_c2c01c9ac5d34aca8edb5a26c6621002",
       "tabbable": null,
       "tooltip": null
      }
     },
     "37282aab8966487593f9fdab58057d8e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3bcfad69afd94e3181e8716edb1a7e31": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "47c03843515a4cb593a55caef8f6f864": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5fb4301967504350bdae8cc693bcf7af": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "645a03556c8c4b30b95605e1d89c2f9f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "6673bea38ad443beb28e6dce088e20ab": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "692fe00851b9454cae3a4e94766d5e8b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "695842332125432e8f5a3f5989b64f6d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_19e3e897d51f49dc810f331ff7140abc",
        "IPY_MODEL_fe105e33309345498ff42456bba9f22d",
        "IPY_MODEL_a05e5a0c61f248b2bed7853b5fbece8f"
       ],
       "layout": "IPY_MODEL_0e0c6ff26b1e4256946b738ef22e4f50",
       "tabbable": null,
       "tooltip": null
      }
     },
     "7012364fc1e844c89a4cb6143f7c712d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_06b0dda3371840e190dbf6d9341ad965",
       "placeholder": "​",
       "style": "IPY_MODEL_e1243d450d7c4a5a9a35ca292eeaa0e2",
       "tabbable": null,
       "tooltip": null,
       "value": "special_tokens_map.json: 100%"
      }
     },
     "7e306376cf9540a3934c1fba0dc070bf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7f49882cf96947fbb3c1d5abffc0ad8b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_37282aab8966487593f9fdab58057d8e",
       "placeholder": "​",
       "style": "IPY_MODEL_6673bea38ad443beb28e6dce088e20ab",
       "tabbable": null,
       "tooltip": null,
       "value": " 112/112 [00:00&lt;00:00, 11.7kB/s]"
      }
     },
     "853edc29d2da4a48a1fdaa00d540b9df": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_daf0249fd91e4f9c925adc4fdda049ed",
       "max": 112,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2013276456d749e8a857640be5f94b3d",
       "tabbable": null,
       "tooltip": null,
       "value": 112
      }
     },
     "8a700a6a47944a75a8558696e224f7e1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "981873ca49c1434394361c4a20c7c0d2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9875b31f8c0e4483bdbdabd6973b2a53": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1cd4afafeb05449296dc29ce7341d247",
        "IPY_MODEL_1cfb147e84a042c4b15058a167cd64e7",
        "IPY_MODEL_1602e2173c484e5bbe92ec2d1f1dd4ed"
       ],
       "layout": "IPY_MODEL_47c03843515a4cb593a55caef8f6f864",
       "tabbable": null,
       "tooltip": null
      }
     },
     "a05e5a0c61f248b2bed7853b5fbece8f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3bcfad69afd94e3181e8716edb1a7e31",
       "placeholder": "​",
       "style": "IPY_MODEL_981873ca49c1434394361c4a20c7c0d2",
       "tabbable": null,
       "tooltip": null,
       "value": " 1.53k/1.53k [00:00&lt;00:00, 167kB/s]"
      }
     },
     "a36b2f5e5e434bca932b4f03300b13c3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a56e8bb5e65e4da9bc1851939f97adcc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a60804ed31f1413aabb077d9343f3eb0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a9b04b6e5fd044bdbb9ffe8644b1c778": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b48f841b1bd4431f9e64f5398f7121bd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a36b2f5e5e434bca932b4f03300b13c3",
       "max": 229167,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_645a03556c8c4b30b95605e1d89c2f9f",
       "tabbable": null,
       "tooltip": null,
       "value": 229167
      }
     },
     "bbcba25434be48a09593a99e5ec59d54": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c2c01c9ac5d34aca8edb5a26c6621002": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cdfef465278540b3b5a5637f518d609b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d8eb1af70d99419a9d8cd3d3a3e4fabf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8a700a6a47944a75a8558696e224f7e1",
       "placeholder": "​",
       "style": "IPY_MODEL_a60804ed31f1413aabb077d9343f3eb0",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.txt: 100%"
      }
     },
     "daf0249fd91e4f9c925adc4fdda049ed": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e1243d450d7c4a5a9a35ca292eeaa0e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e8a9eaa86c574423b7fda0f159b88366": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ea7658ff761f42ad8e5db963211a9538": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_cdfef465278540b3b5a5637f518d609b",
       "placeholder": "​",
       "style": "IPY_MODEL_ffb9c139c4bc407c957f7989c3b4e0ae",
       "tabbable": null,
       "tooltip": null,
       "value": " 229k/229k [00:00&lt;00:00, 7.82MB/s]"
      }
     },
     "eda0ef7650574d38b2602d9855ab44b8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f67c8d7c0f11452eb2da15e9b984a8d2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "f71aa59d83494a3e83c8a1c3a340c010": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fc4b165586444e24b0a4410500f198c8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "fe105e33309345498ff42456bba9f22d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a56e8bb5e65e4da9bc1851939f97adcc",
       "max": 1534,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f67c8d7c0f11452eb2da15e9b984a8d2",
       "tabbable": null,
       "tooltip": null,
       "value": 1534
      }
     },
     "ffb9c139c4bc407c957f7989c3b4e0ae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
