{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d781bc43",
   "metadata": {
    "papermill": {
     "duration": 0.011812,
     "end_time": "2025-05-19T04:31:45.979329",
     "exception": false,
     "start_time": "2025-05-19T04:31:45.967517",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9eee759",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T04:31:46.003174Z",
     "iopub.status.busy": "2025-05-19T04:31:46.002956Z",
     "iopub.status.idle": "2025-05-19T04:32:08.210143Z",
     "shell.execute_reply": "2025-05-19T04:32:08.209239Z"
    },
    "papermill": {
     "duration": 22.220569,
     "end_time": "2025-05-19T04:32:08.211765",
     "exception": false,
     "start_time": "2025-05-19T04:31:45.991196",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score, classification_report\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "from torch.multiprocessing import Manager\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel, BertPreTrainedModel, BertConfig, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2587a48b",
   "metadata": {
    "papermill": {
     "duration": 0.012032,
     "end_time": "2025-05-19T04:32:08.235041",
     "exception": false,
     "start_time": "2025-05-19T04:32:08.223009",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0adf2e15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T04:32:08.257347Z",
     "iopub.status.busy": "2025-05-19T04:32:08.256868Z",
     "iopub.status.idle": "2025-05-19T04:32:08.260402Z",
     "shell.execute_reply": "2025-05-19T04:32:08.259630Z"
    },
    "papermill": {
     "duration": 0.016069,
     "end_time": "2025-05-19T04:32:08.261742",
     "exception": false,
     "start_time": "2025-05-19T04:32:08.245673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddfe095e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T04:32:08.284067Z",
     "iopub.status.busy": "2025-05-19T04:32:08.283840Z",
     "iopub.status.idle": "2025-05-19T04:32:08.287275Z",
     "shell.execute_reply": "2025-05-19T04:32:08.286722Z"
    },
    "papermill": {
     "duration": 0.015794,
     "end_time": "2025-05-19T04:32:08.288381",
     "exception": false,
     "start_time": "2025-05-19T04:32:08.272587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists('/kaggle/working/results') == False:\n",
    "    os.mkdir('/kaggle/working/results')\n",
    "\n",
    "if os.path.exists('/kaggle/working/acquired_data') == False:\n",
    "    os.mkdir('/kaggle/working/acquired_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "854b56c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T04:32:08.310755Z",
     "iopub.status.busy": "2025-05-19T04:32:08.310549Z",
     "iopub.status.idle": "2025-05-19T04:32:08.318379Z",
     "shell.execute_reply": "2025-05-19T04:32:08.317833Z"
    },
    "papermill": {
     "duration": 0.020503,
     "end_time": "2025-05-19T04:32:08.319582",
     "exception": false,
     "start_time": "2025-05-19T04:32:08.299079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "    torch.backends.cudnn.benchmark=False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df0f0d2",
   "metadata": {
    "papermill": {
     "duration": 0.010634,
     "end_time": "2025-05-19T04:32:08.341673",
     "exception": false,
     "start_time": "2025-05-19T04:32:08.331039",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# GLOBAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f13fd6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T04:32:08.364087Z",
     "iopub.status.busy": "2025-05-19T04:32:08.363848Z",
     "iopub.status.idle": "2025-05-19T04:32:08.419895Z",
     "shell.execute_reply": "2025-05-19T04:32:08.418661Z"
    },
    "papermill": {
     "duration": 0.069084,
     "end_time": "2025-05-19T04:32:08.421607",
     "exception": false,
     "start_time": "2025-05-19T04:32:08.352523",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "\n",
    "# Shared resources\n",
    "aspect_accuracies = manager.list()\n",
    "aspect_f1_micros = manager.list()\n",
    "aspect_f1_macros = manager.list()\n",
    "sentiment_accuracies = manager.list()\n",
    "sentiment_f1_micros = manager.list()\n",
    "sentiment_f1_macros = manager.list()\n",
    "accuracies = manager.list()\n",
    "f1_micros = manager.list()\n",
    "f1_macros = manager.list()\n",
    "\n",
    "# Non shared resources\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "sequence_length = 48\n",
    "\n",
    "aspect_list = ['fuel', 'machine', 'others', 'part', 'price', 'service']\n",
    "aspect_mapping = {'fuel': 0, 'machine': 1, 'others': 2, 'part': 3, 'price': 4, 'service': 5 }\n",
    "label_mapping = {\"negative\": 0, \"neutral\": 1, 'positive': 2}\n",
    "ignored_keys = ['labels', 'ori_text', 'ori_label', 'ori_indices', 'aspect']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba59488",
   "metadata": {
    "papermill": {
     "duration": 0.010637,
     "end_time": "2025-05-19T04:32:08.443275",
     "exception": false,
     "start_time": "2025-05-19T04:32:08.432638",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LOAD AND PREPROCESS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dd2bd41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T04:32:08.466190Z",
     "iopub.status.busy": "2025-05-19T04:32:08.465936Z",
     "iopub.status.idle": "2025-05-19T04:32:08.533451Z",
     "shell.execute_reply": "2025-05-19T04:32:08.532557Z"
    },
    "papermill": {
     "duration": 0.08033,
     "end_time": "2025-05-19T04:32:08.534652",
     "exception": false,
     "start_time": "2025-05-19T04:32:08.454322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>fuel</th>\n",
       "      <th>machine</th>\n",
       "      <th>others</th>\n",
       "      <th>part</th>\n",
       "      <th>price</th>\n",
       "      <th>service</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saya memakai Honda Jazz GK5 tahun 2014 ( perta...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Avanza kenapa jadi boros bensin begini dah ah....</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saran ku dan pengalaman ku , mending beli mobi...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dari segi harga juga pajero lebih mahal 30 jut...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kalo menurut gw enak pajero si</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence      fuel   machine  \\\n",
       "0  Saya memakai Honda Jazz GK5 tahun 2014 ( perta...   neutral   neutral   \n",
       "1  Avanza kenapa jadi boros bensin begini dah ah....  negative   neutral   \n",
       "2  saran ku dan pengalaman ku , mending beli mobi...  positive  positive   \n",
       "3  Dari segi harga juga pajero lebih mahal 30 jut...   neutral   neutral   \n",
       "4                     Kalo menurut gw enak pajero si   neutral   neutral   \n",
       "\n",
       "     others     part     price  service  \n",
       "0  positive  neutral   neutral  neutral  \n",
       "1   neutral  neutral   neutral  neutral  \n",
       "2   neutral  neutral   neutral  neutral  \n",
       "3   neutral  neutral  positive  neutral  \n",
       "4  positive  neutral   neutral  neutral  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('/kaggle/input/casa-dataset/train_preprocess.csv', encoding='latin-1')\n",
    "val_data = pd.read_csv('/kaggle/input/casa-dataset/valid_preprocess.csv', encoding='latin-1')\n",
    "test_data = pd.read_csv('/kaggle/input/casa-dataset/test_preprocess.csv', encoding='latin-1')\n",
    "\n",
    "data = pd.concat([train_data, val_data, test_data], ignore_index=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4bf2f71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T04:32:08.557530Z",
     "iopub.status.busy": "2025-05-19T04:32:08.557272Z",
     "iopub.status.idle": "2025-05-19T04:32:08.565989Z",
     "shell.execute_reply": "2025-05-19T04:32:08.565184Z"
    },
    "papermill": {
     "duration": 0.021458,
     "end_time": "2025-05-19T04:32:08.567234",
     "exception": false,
     "start_time": "2025-05-19T04:32:08.545776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>fuel</th>\n",
       "      <th>machine</th>\n",
       "      <th>others</th>\n",
       "      <th>part</th>\n",
       "      <th>price</th>\n",
       "      <th>service</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saya memakai Honda Jazz GK5 tahun 2014 ( perta...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Avanza kenapa jadi boros bensin begini dah ah....</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saran ku dan pengalaman ku , mending beli mobi...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dari segi harga juga pajero lebih mahal 30 jut...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kalo menurut gw enak pajero si</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence      fuel   machine  \\\n",
       "0  Saya memakai Honda Jazz GK5 tahun 2014 ( perta...   neutral   neutral   \n",
       "1  Avanza kenapa jadi boros bensin begini dah ah....  negative   neutral   \n",
       "2  saran ku dan pengalaman ku , mending beli mobi...  positive  positive   \n",
       "3  Dari segi harga juga pajero lebih mahal 30 jut...   neutral   neutral   \n",
       "4                     Kalo menurut gw enak pajero si   neutral   neutral   \n",
       "\n",
       "     others     part     price  service  \n",
       "0  positive  neutral   neutral  neutral  \n",
       "1   neutral  neutral   neutral  neutral  \n",
       "2   neutral  neutral   neutral  neutral  \n",
       "3   neutral  neutral  positive  neutral  \n",
       "4  positive  neutral   neutral  neutral  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4b429e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T04:32:08.590610Z",
     "iopub.status.busy": "2025-05-19T04:32:08.590355Z",
     "iopub.status.idle": "2025-05-19T04:32:08.597262Z",
     "shell.execute_reply": "2025-05-19T04:32:08.596436Z"
    },
    "papermill": {
     "duration": 0.019898,
     "end_time": "2025-05-19T04:32:08.598544",
     "exception": false,
     "start_time": "2025-05-19T04:32:08.578646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4894e6d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T04:32:08.621944Z",
     "iopub.status.busy": "2025-05-19T04:32:08.621718Z",
     "iopub.status.idle": "2025-05-19T04:32:08.632352Z",
     "shell.execute_reply": "2025-05-19T04:32:08.631572Z"
    },
    "papermill": {
     "duration": 0.023811,
     "end_time": "2025-05-19T04:32:08.633575",
     "exception": false,
     "start_time": "2025-05-19T04:32:08.609764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(864,) (864, 6)\n",
      "(216,) (216, 6)\n"
     ]
    }
   ],
   "source": [
    "train_labels = train_data.columns[1:]\n",
    "val_labels = val_data.columns[1:]\n",
    "\n",
    "# Extract features and labels for training and validation\n",
    "X_train = train_data['sentence'].values\n",
    "y_train = train_data[train_labels].values\n",
    "X_val = val_data['sentence'].values\n",
    "y_val = val_data[val_labels].values\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ed8915",
   "metadata": {
    "papermill": {
     "duration": 0.011037,
     "end_time": "2025-05-19T04:32:08.656031",
     "exception": false,
     "start_time": "2025-05-19T04:32:08.644994",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BUILD DATASET & DATALOADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be5a3944",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T04:32:08.679139Z",
     "iopub.status.busy": "2025-05-19T04:32:08.678913Z",
     "iopub.status.idle": "2025-05-19T04:32:08.684723Z",
     "shell.execute_reply": "2025-05-19T04:32:08.683902Z"
    },
    "papermill": {
     "duration": 0.018731,
     "end_time": "2025-05-19T04:32:08.685908",
     "exception": false,
     "start_time": "2025-05-19T04:32:08.667177",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AspectDetectionDataset(Dataset):\n",
    "    def __init__(self, texts, labels, label_mapping, tokenizer, max_length=sequence_length, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.use_float = use_float\n",
    "        self.label_mapping = label_mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "        \n",
    "        original_labels = [self.label_mapping[label] for label in self.labels[idx]]\n",
    "        encoded_labels = [1 if label == 1 else 0 for label in original_labels]\n",
    "        \n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['ori_indices'] = idx\n",
    "        item['ori_text'] = self.texts[idx]\n",
    "        item['ori_label'] = torch.tensor(original_labels, dtype=torch.float)\n",
    "        item['labels'] = torch.tensor(encoded_labels, dtype=torch.float if self.use_float else torch.long)\n",
    "        \n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5088e299",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T04:32:08.709437Z",
     "iopub.status.busy": "2025-05-19T04:32:08.709218Z",
     "iopub.status.idle": "2025-05-19T04:32:08.715773Z",
     "shell.execute_reply": "2025-05-19T04:32:08.715142Z"
    },
    "papermill": {
     "duration": 0.019467,
     "end_time": "2025-05-19T04:32:08.716929",
     "exception": false,
     "start_time": "2025-05-19T04:32:08.697462",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SentimentAnalysisDataset(Dataset):\n",
    "    def __init__(self, texts, labels, aspects, indices, label_mapping, tokenizer, max_length=96, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.aspects = aspects\n",
    "        self.indices = indices\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.use_float = use_float\n",
    "        self.label_mapping = label_mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = aspect_token + ' ' + self.aspects[idx] + ' ' + review_token + ' ' + self.texts[idx] \n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "\n",
    "        if isinstance(self.labels[idx], str):\n",
    "            self.labels[idx] = self.label_mapping[self.labels[idx]]\n",
    "        elif torch.is_tensor(self.labels[idx]):\n",
    "            self.labels[idx] = int(self.labels[idx].item())\n",
    "\n",
    "        encoded_label = 1 if self.labels[idx] == 2 else self.labels[idx]\n",
    "        one_hot_label = F.one_hot(torch.tensor(encoded_label, dtype=torch.long), num_classes=2).float()\n",
    "\n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['aspect'] = self.aspects[idx]\n",
    "        item['labels'] = one_hot_label\n",
    "        item['ori_indices'] = self.indices[idx]\n",
    "        item['ori_text'] = self.texts[idx]\n",
    "        item['ori_label'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e87057e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T04:32:08.740622Z",
     "iopub.status.busy": "2025-05-19T04:32:08.740413Z",
     "iopub.status.idle": "2025-05-19T04:32:10.036104Z",
     "shell.execute_reply": "2025-05-19T04:32:10.035025Z"
    },
    "papermill": {
     "duration": 1.309236,
     "end_time": "2025-05-19T04:32:10.037803",
     "exception": false,
     "start_time": "2025-05-19T04:32:08.728567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe2ca17af5024721a70aa798fdde8b8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce2891ca32d34dda8f0e2bb4f530731c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/229k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85938f820bfd44e3ac8e0777e94d1e87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1a96c1215ea48c0ac5ee11ab7e9a30b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p1')\n",
    "review_token = '[REVIEW]'\n",
    "aspect_token = '[ASPECT]'\n",
    "special_tokens_dict = {'additional_special_tokens': [review_token, aspect_token]}\n",
    "num_added_tokens = tokenizer.add_special_tokens(special_tokens_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9829a04a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T04:32:10.063698Z",
     "iopub.status.busy": "2025-05-19T04:32:10.063417Z",
     "iopub.status.idle": "2025-05-19T04:32:10.067930Z",
     "shell.execute_reply": "2025-05-19T04:32:10.067077Z"
    },
    "papermill": {
     "duration": 0.018404,
     "end_time": "2025-05-19T04:32:10.069047",
     "exception": false,
     "start_time": "2025-05-19T04:32:10.050643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_aspect_dataset(X_train, y_train, X_val, y_val, sequence_length, num_workers=4):\n",
    "    train_dataset = AspectDetectionDataset(X_train, y_train, label_mapping, tokenizer, max_length=sequence_length)\n",
    "    val_dataset = AspectDetectionDataset(X_val, y_val, label_mapping, tokenizer, max_length=sequence_length)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=num_workers,\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=num_workers, \n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "689d3e82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T04:32:10.094355Z",
     "iopub.status.busy": "2025-05-19T04:32:10.094087Z",
     "iopub.status.idle": "2025-05-19T04:32:10.104260Z",
     "shell.execute_reply": "2025-05-19T04:32:10.103444Z"
    },
    "papermill": {
     "duration": 0.024606,
     "end_time": "2025-05-19T04:32:10.105614",
     "exception": false,
     "start_time": "2025-05-19T04:32:10.081008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_sentiment_dataset(device, train_dataset, val_dataset, aspect_detection_model, tokenizer, max_length=sequence_length):\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "\n",
    "    aspect_detection_model.to(device)\n",
    "    aspect_detection_model.eval()\n",
    "\n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "    train_aspects = []\n",
    "    train_indices = []\n",
    "\n",
    "    val_data = []\n",
    "    val_labels = []\n",
    "    val_aspects = []\n",
    "    val_indices = []\n",
    "\n",
    "    # Transform train set\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        for batch in train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = aspect_detection_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            for i in range(len(preds)):\n",
    "                for j in range(len(preds[i])):\n",
    "                    if int(preds[i][j]) != 1:\n",
    "                        train_aspects.append(aspect_list[j])\n",
    "                        train_data.append(batch['ori_text'][i])\n",
    "                        train_labels.append(batch['ori_label'][i][j])\n",
    "                        train_indices.append(batch['ori_indices'][i])\n",
    "            \n",
    "        # Transform validation set\n",
    "        for batch in val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = aspect_detection_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            for i in range(len(preds)):\n",
    "                for j in range(len(preds[i])):\n",
    "                    if int(preds[i][j]) != 1:\n",
    "                        val_aspects.append(aspect_list[j])\n",
    "                        val_data.append(batch['ori_text'][i])\n",
    "                        val_labels.append(batch['ori_label'][i][j])\n",
    "                        val_indices.append(batch['ori_indices'][i])\n",
    "\n",
    "    train_dataset = SentimentAnalysisDataset(train_data, train_labels, train_aspects, train_indices, label_mapping, tokenizer, max_length=max_length)\n",
    "    val_dataset = SentimentAnalysisDataset(val_data, val_labels, val_aspects, val_indices, label_mapping, tokenizer, max_length=max_length)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f80cc8f",
   "metadata": {
    "papermill": {
     "duration": 0.01192,
     "end_time": "2025-05-19T04:32:10.129584",
     "exception": false,
     "start_time": "2025-05-19T04:32:10.117664",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d67d3f06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T04:32:10.154087Z",
     "iopub.status.busy": "2025-05-19T04:32:10.153869Z",
     "iopub.status.idle": "2025-05-19T04:32:10.157764Z",
     "shell.execute_reply": "2025-05-19T04:32:10.156732Z"
    },
    "papermill": {
     "duration": 0.017824,
     "end_time": "2025-05-19T04:32:10.159279",
     "exception": false,
     "start_time": "2025-05-19T04:32:10.141455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_data = len(X_train) + len(X_val)\n",
    "initial_train_size = int(0.05 * total_data)\n",
    "checkpoints = [\n",
    "    int(0.5 * total_data), \n",
    "    int(0.6 * total_data), \n",
    "    int(0.7 * total_data),\n",
    "    len(X_train)\n",
    "]\n",
    "min_increment = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aafcffd2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T04:32:10.183973Z",
     "iopub.status.busy": "2025-05-19T04:32:10.183756Z",
     "iopub.status.idle": "2025-05-19T04:32:10.188335Z",
     "shell.execute_reply": "2025-05-19T04:32:10.187732Z"
    },
    "papermill": {
     "duration": 0.018252,
     "end_time": "2025-05-19T04:32:10.189562",
     "exception": false,
     "start_time": "2025-05-19T04:32:10.171310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p, label, classes):\n",
    "    preds = torch.tensor(p.predictions) # Sigmoid and threshold for multi-label\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Hamming accuracy: proportion of correctly predicted labels over total labels\n",
    "    hamming_accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Standard multi-label precision, recall, and F1 metrics\n",
    "    precision, recall, f1_micro, _ = precision_recall_fscore_support(labels, preds, average='micro', zero_division=0)\n",
    "    _, _, f1_macro, _ = precision_recall_fscore_support(labels, preds, average='macro', zero_division=0)\n",
    "\n",
    "    report = classification_report(\n",
    "        labels, \n",
    "        preds, \n",
    "        labels=label,\n",
    "        target_names=classes,\n",
    "        zero_division=0\n",
    "    ) \n",
    "\n",
    "    return {\n",
    "        'accuracy': hamming_accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'report': report\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "899b96d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T04:32:10.214330Z",
     "iopub.status.busy": "2025-05-19T04:32:10.214106Z",
     "iopub.status.idle": "2025-05-19T04:32:10.220001Z",
     "shell.execute_reply": "2025-05-19T04:32:10.219442Z"
    },
    "papermill": {
     "duration": 0.019624,
     "end_time": "2025-05-19T04:32:10.221165",
     "exception": false,
     "start_time": "2025-05-19T04:32:10.201541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics_overall(p, classes):\n",
    "    preds = torch.tensor(p.predictions)\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Ensure it's in the correct shape\n",
    "    if preds.shape != labels.shape:\n",
    "        raise ValueError(\"Shape mismatch: predictions and labels must have the same shape.\")\n",
    "\n",
    "    # Hamming accuracy: proportion of correctly predicted labels over total labels\n",
    "    hamming_accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Compute per-label (column-wise) precision, recall, F1\n",
    "    precision_list, recall_list, f1_micro_list, f1_macro_list = [], [], [], []\n",
    "    \n",
    "    for i in range(labels.shape[1]):  # Loop through each column (multi-output)\n",
    "        prec, rec, f1_micro, _ = precision_recall_fscore_support(\n",
    "            labels[:, i], preds[:, i], average='micro', zero_division=0\n",
    "        )\n",
    "        _, _, f1_macro, _ = precision_recall_fscore_support(\n",
    "            labels[:, i], preds[:, i], average='macro', zero_division=0\n",
    "        )\n",
    "\n",
    "        precision_list.append(prec)\n",
    "        recall_list.append(rec)\n",
    "        f1_micro_list.append(f1_micro)\n",
    "        f1_macro_list.append(f1_macro)\n",
    "\n",
    "    # Compute average metrics across all outputs\n",
    "    precision = sum(precision_list) / len(precision_list)\n",
    "    recall = sum(recall_list) / len(recall_list)\n",
    "    f1_micro = sum(f1_micro_list) / len(f1_micro_list)\n",
    "    f1_macro = sum(f1_macro_list) / len(f1_macro_list)\n",
    "\n",
    "    # Generate classification report per output\n",
    "    reports = [classification_report(labels[:, i], preds[:, i], target_names=classes, zero_division=0) for i in range(labels.shape[1])]\n",
    "\n",
    "    return {\n",
    "        'accuracy': hamming_accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'reports': reports  # Returns list of reports, one for each output label\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3ca50c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T04:32:10.247495Z",
     "iopub.status.busy": "2025-05-19T04:32:10.247237Z",
     "iopub.status.idle": "2025-05-19T04:32:10.274074Z",
     "shell.execute_reply": "2025-05-19T04:32:10.273429Z"
    },
    "papermill": {
     "duration": 0.040708,
     "end_time": "2025-05-19T04:32:10.275150",
     "exception": false,
     "start_time": "2025-05-19T04:32:10.234442",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(current_train_size, train_indices, aspect_metrics, sentiment_metrics, metrics, trials, seed, filename):\n",
    "    accelerator = Accelerator(mixed_precision='fp16')  # Initialize the accelerator\n",
    "    device = accelerator.device\n",
    "\n",
    "    aspect_model = BertForSequenceClassification.from_pretrained(\n",
    "        'indobenchmark/indobert-base-p1',\n",
    "        num_labels=len(train_labels),\n",
    "        problem_type=\"multi_label_classification\"\n",
    "    )\n",
    "\n",
    "    # Freeze the first few layers of the encoder\n",
    "    for name, param in aspect_model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    # Define optimizer and loss function\n",
    "    aspect_optimizer = torch.optim.AdamW(aspect_model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Define DataLoaders\n",
    "    current_X_train = [X_train[i] for i in train_indices]\n",
    "    current_y_train = [y_train[i] for i in train_indices]\n",
    "    aspect_train_loader, aspect_val_loader, aspect_train_dataset, aspect_val_dataset = build_aspect_dataset(current_X_train, current_y_train, X_val, y_val, sequence_length)\n",
    "\n",
    "    # Prepare everything with Accelerator\n",
    "    aspect_model, aspect_optimizer, aspect_train_loader, aspect_val_loader = accelerator.prepare(\n",
    "        aspect_model, aspect_optimizer, aspect_train_loader, aspect_val_loader\n",
    "    )\n",
    "\n",
    "    nearest_cp = current_train_size\n",
    "    if nearest_cp not in checkpoints:\n",
    "        for cp in checkpoints:\n",
    "            if cp > current_train_size:\n",
    "                nearest_cp = cp\n",
    "                break\n",
    "    percentage = math.ceil(nearest_cp / total_data * 100)\n",
    "\n",
    "    aspect_result = None\n",
    "    start_time = time.time()\n",
    "\n",
    "    # ASPECT DETECTION\n",
    "    accelerator.print(\"ASPECT DETECTION\")\n",
    "    for epoch in range(epochs):\n",
    "        aspect_model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for batch in aspect_train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels']\n",
    "        \n",
    "            aspect_optimizer.zero_grad()\n",
    "            outputs = aspect_model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            aspect_optimizer.step()\n",
    "        \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "        aspect_model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in aspect_val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "                labels = batch['labels']\n",
    "                \n",
    "                outputs = aspect_model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                # Gather predictions and labels from all devices\n",
    "                all_preds.append(accelerator.gather(preds))\n",
    "                all_labels.append(accelerator.gather(labels))\n",
    "\n",
    "        all_preds = torch.cat(all_preds).cpu().numpy()\n",
    "        all_labels = torch.cat(all_labels).cpu().numpy()\n",
    "\n",
    "        result = compute_metrics(\n",
    "            type('EvalOutput', (object,), {'predictions': all_preds, 'label_ids': all_labels}),\n",
    "            None,\n",
    "            ['fuel', 'machine', 'others', 'part', 'price', 'service']\n",
    "        )\n",
    "\n",
    "        if aspect_result is None or result['f1_micro'] >= aspect_result['f1_micro']:\n",
    "            accelerator.print(\"Higher F1 achieved, saving model\")\n",
    "            \n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(aspect_model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                f'{filename}-aspect-{trials + 1}-model-{percentage}',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "            aspect_result = result\n",
    "\n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(aspect_train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "\n",
    "    accelerator.print(f\"\\nAspect detection accuracy: {round(aspect_result['accuracy'], 4)}, F1 Micro: {round(aspect_result['f1_micro'], 4)}, F1 Macro: {round(aspect_result['f1_macro'], 4)}\")\n",
    "    accelerator.print(aspect_result['report'])\n",
    "\n",
    "    best_aspect_model = BertForSequenceClassification.from_pretrained(f'{filename}-aspect-{trials + 1}-model-{percentage}')\n",
    "    best_aspect_model = accelerator.prepare(best_aspect_model)\n",
    "\n",
    "    # SENTIMENT ANALYSIS ON NON NEUTRAL ASPECTS\n",
    "    accelerator.print(\"--------------------------------------------------\")\n",
    "    accelerator.print(\"SENTIMENT ANALYSIS\")\n",
    "\n",
    "    sentiment_model = BertForSequenceClassification.from_pretrained(\n",
    "        'indobenchmark/indobert-base-p1',\n",
    "        num_labels=2,\n",
    "    )\n",
    "    sentiment_optimizer = torch.optim.AdamW(sentiment_model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "\n",
    "    for name, param in sentiment_model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    sentiment_train_loader, sentiment_val_loader, sentiment_train_dataset, sentiment_val_dataset = build_sentiment_dataset(\n",
    "        device, aspect_train_dataset, aspect_val_dataset, best_aspect_model, tokenizer, max_length=sequence_length\n",
    "    )\n",
    "    sentiment_model, sentiment_optimizer, sentiment_train_loader, sentiment_val_loader = accelerator.prepare(\n",
    "        sentiment_model, sentiment_optimizer, sentiment_train_loader, sentiment_val_loader\n",
    "    )\n",
    "    sentiment_result = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        sentiment_model.train()\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for batch in sentiment_train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels']\n",
    "        \n",
    "            sentiment_optimizer.zero_grad()\n",
    "            outputs = sentiment_model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            sentiment_optimizer.step()\n",
    "        \n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        sentiment_model.eval()\n",
    "        sentiment_val_outputs = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in sentiment_val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "                \n",
    "                outputs = sentiment_model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                for i in range(len(preds)):\n",
    "                    val_output = {\n",
    "                        'label': batch['labels'][i],\n",
    "                        'aspect': batch['aspect'][i],\n",
    "                        'ori_indices': batch['ori_indices'][i],\n",
    "                        'pred': np.argmax(preds[i].cpu().numpy()),\n",
    "                    }\n",
    "                    sentiment_val_outputs.append(val_output)\n",
    "\n",
    "        sentiment_val_outputs = accelerator.gather_for_metrics(sentiment_val_outputs)\n",
    "        unique_val_outputs = {(x['ori_indices'].item(), x['aspect']): x for x in sentiment_val_outputs}\n",
    "        sentiment_val_outputs = list(unique_val_outputs.values())\n",
    "\n",
    "        result = compute_metrics(\n",
    "            type('EvalOutput', (object,), {'predictions': [item['pred'] for item in sentiment_val_outputs], 'label_ids': [np.argmax(item['label'].cpu().numpy()) for item in sentiment_val_outputs]}),\n",
    "            [0, 1],\n",
    "            ['negative', 'positive']\n",
    "        )\n",
    "\n",
    "        if sentiment_result is None or result['f1_micro'] >= sentiment_result['f1_micro']:\n",
    "            accelerator.print(\"Higher F1 achieved, saving model\")\n",
    "            sentiment_result = result\n",
    "            \n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(sentiment_model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                 f'{filename}-sentiment-{trials + 1}-model-{percentage}',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "\n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(sentiment_train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "\n",
    "    accelerator.print(f\"\\nSentiment analysis accuracy: {round(sentiment_result['accuracy'], 4)}, F1 Micro: {round(sentiment_result['f1_micro'], 4)}, F1 Macro: {round(sentiment_result['f1_macro'], 4)}\")\n",
    "    accelerator.print(sentiment_result['report'])\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    best_sentiment_model = BertForSequenceClassification.from_pretrained( f'{filename}-sentiment-{trials + 1}-model-{percentage}')\n",
    "    best_sentiment_model = accelerator.prepare(best_sentiment_model)\n",
    "\n",
    "    # Compute overall metrics\n",
    "    aspect_labels = []\n",
    "    aspect_indices = []\n",
    "    aspect_preds = []\n",
    "\n",
    "    aspect_outputs = {}\n",
    "    sentiment_outputs = []\n",
    "    \n",
    "    best_aspect_model.eval()\n",
    "    best_sentiment_model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in aspect_val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            outputs = best_aspect_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            aspect_indices.append(accelerator.gather(batch['ori_indices']))\n",
    "            aspect_labels.append(accelerator.gather(batch['ori_label']))\n",
    "            aspect_preds.append(accelerator.gather(preds))\n",
    "\n",
    "        aspect_indices = torch.cat(aspect_indices).cpu().numpy()\n",
    "        aspect_labels = torch.cat(aspect_labels).cpu().numpy()\n",
    "        aspect_preds = torch.cat(aspect_preds).cpu().numpy()\n",
    "\n",
    "        accelerator.wait_for_everyone()\n",
    "        aspect_outputs = [\n",
    "            {'ori_indices': aspect_indices[i], \n",
    "             'ori_labels': aspect_labels[i], \n",
    "             'pred': aspect_preds[i]}\n",
    "            for i in range(len(aspect_preds))\n",
    "        ]\n",
    "        aspect_outputs = {x['ori_indices'].item(): x for x in aspect_outputs}\n",
    "    \n",
    "        for batch in sentiment_val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            outputs = best_sentiment_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "    \n",
    "            for i in range(len(preds)):\n",
    "                output = {\n",
    "                    'aspect': batch['aspect'][i],\n",
    "                    'ori_indices': batch['ori_indices'][i],\n",
    "                    'pred': np.argmax(preds[i].cpu().numpy()),\n",
    "                }\n",
    "                sentiment_outputs.append(output)\n",
    "\n",
    "        sentiment_outputs = accelerator.gather_for_metrics(sentiment_outputs)\n",
    "        sentiment_outputs = {(x['ori_indices'].item(), x['aspect']): x for x in sentiment_outputs}\n",
    "\n",
    "    # Replcae non neutral aspect to its predicted sentiment\n",
    "    accelerator.wait_for_everyone()\n",
    "    if accelerator.is_main_process:\n",
    "        i = -1\n",
    "        for (ori_index, aspect), value in sentiment_outputs.items():\n",
    "            aspect = aspect_mapping[aspect]\n",
    "            aspect_outputs[ori_index]['pred'][aspect] = 2 if value['pred'] == 1.0 else value['pred']\n",
    "\n",
    "        result = compute_metrics_overall(\n",
    "            type('EvalOutput', (object,), {'predictions': [output['pred'] for output in aspect_outputs.values()], 'label_ids': [output['ori_labels'] for output in aspect_outputs.values()]}),\n",
    "            ['negative', 'neutral', 'positive'],\n",
    "        )\n",
    "\n",
    "        accelerator.print(\"--------------------------------------------------\")\n",
    "        accelerator.print(f\"Iteration {current_train_size}: Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "        accelerator.print(\"--------------------------------------------------\")\n",
    "        for i in range(len(train_labels)):\n",
    "            accelerator.print(f\"Aspect {aspect_list[i]} report:\")\n",
    "            accelerator.print(result['reports'][i])\n",
    "       \n",
    "        \n",
    "        aspect_metrics[0].append(aspect_result['accuracy'])\n",
    "        aspect_metrics[1].append(aspect_result['f1_micro'])\n",
    "        aspect_metrics[2].append(aspect_result['f1_macro'])\n",
    "        sentiment_metrics[0].append(sentiment_result['accuracy'])\n",
    "        sentiment_metrics[1].append(sentiment_result['f1_micro'])\n",
    "        sentiment_metrics[2].append(sentiment_result['f1_macro'])\n",
    "        metrics[0].append(current_train_size)\n",
    "        metrics[1].append(result['accuracy'])\n",
    "        metrics[2].append(result['f1_micro'])\n",
    "        metrics[3].append(result['f1_macro'])\n",
    "        \n",
    "    accelerator.print(f\"Total train time: {duration} s\")\n",
    "    accelerator.end_training()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0055c4b",
   "metadata": {
    "papermill": {
     "duration": 0.012176,
     "end_time": "2025-05-19T04:32:10.299730",
     "exception": false,
     "start_time": "2025-05-19T04:32:10.287554",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PLOT THE RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ac89c81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T04:32:10.324750Z",
     "iopub.status.busy": "2025-05-19T04:32:10.324523Z",
     "iopub.status.idle": "2025-05-19T04:32:10.329490Z",
     "shell.execute_reply": "2025-05-19T04:32:10.328852Z"
    },
    "papermill": {
     "duration": 0.018748,
     "end_time": "2025-05-19T04:32:10.330641",
     "exception": false,
     "start_time": "2025-05-19T04:32:10.311893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_result(data_used, accuracies, f1_micros, f1_macros):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(21, 5))\n",
    "    data_used = [round(data / total_data * 100, 1) for data in data_used]\n",
    "\n",
    "    # Plot for Accuracy\n",
    "    axs[0].plot(data_used, accuracies, label=\"Accuracy\", color=\"blue\")\n",
    "    axs[0].set_xlabel(\"Percentage of data used\")\n",
    "    axs[0].set_title(\"Accuracy\")\n",
    "    axs[0].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Micro\n",
    "    axs[1].plot(data_used, f1_micros, label=\"F1 Micro\", color=\"orange\")\n",
    "    axs[1].set_xlabel(\"Percentage of data used\")\n",
    "    axs[1].set_title(\"F1 Micro\")\n",
    "    axs[1].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Macro\n",
    "    axs[2].plot(data_used, f1_macros, label=\"F1 Macro\", color=\"green\")\n",
    "    axs[2].set_xlabel(\"Percentage of data used\")\n",
    "    axs[2].set_title(\"F1 Macro\")\n",
    "    axs[2].set_xticks(data_used)\n",
    "\n",
    "    # Adjust layout and show the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e5a79b",
   "metadata": {
    "papermill": {
     "duration": 0.012191,
     "end_time": "2025-05-19T04:32:10.354870",
     "exception": false,
     "start_time": "2025-05-19T04:32:10.342679",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# QUERY STRATEGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eda76371",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T04:32:10.380226Z",
     "iopub.status.busy": "2025-05-19T04:32:10.380026Z",
     "iopub.status.idle": "2025-05-19T04:32:10.398592Z",
     "shell.execute_reply": "2025-05-19T04:32:10.397968Z"
    },
    "papermill": {
     "duration": 0.032688,
     "end_time": "2025-05-19T04:32:10.399713",
     "exception": false,
     "start_time": "2025-05-19T04:32:10.367025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def kmeans_clustering_sampling(aspect_model, sentiment_model, X_pool, train_indices, remaining_indices, sampling_dur, new_samples, trials, filename, n_clusters=min_increment):\n",
    "    accelerator = Accelerator(mixed_precision=\"fp16\")\n",
    "    device = accelerator.device\n",
    "\n",
    "    aspect_model.to(device)\n",
    "    aspect_model.eval()\n",
    "    sentiment_model.to(device)\n",
    "    sentiment_model.eval()\n",
    "\n",
    "    current_train_size = len(train_indices)\n",
    "    aspect_dataset = AspectDetectionDataset(\n",
    "        X_pool, \n",
    "        [['neutral' for i in range(len(train_labels))] for x in range(len(X_pool))], \n",
    "        label_mapping, \n",
    "        tokenizer, \n",
    "        max_length=sequence_length\n",
    "    )\n",
    "    aspect_loader = DataLoader(\n",
    "        aspect_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    \n",
    "    aspect_outputs = {}\n",
    "    sentiment_outputs = {}\n",
    "\n",
    "    aspects = []\n",
    "    data = []\n",
    "    labels = []\n",
    "    indices = []\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Pass through aspect detction model\n",
    "    for batch in aspect_loader:\n",
    "        token_type_ids = batch['token_type_ids'].to(device, non_blocking=True)\n",
    "        input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "        attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = aspect_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids).logits\n",
    "            embeddings = aspect_model.base_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "\n",
    "        for i in range(len(outputs)):\n",
    "            aspect_outputs[batch['ori_indices'][i].item()] = embeddings.last_hidden_state[i].mean(dim=1).cpu().numpy()\n",
    "            \n",
    "            for j in range(len(outputs[i])):\n",
    "                if int(outputs[i][j].round()) != 1:\n",
    "                    aspects.append(aspect_list[j])\n",
    "                    data.append(batch['ori_text'][i])\n",
    "                    labels.append(batch['ori_label'][i][j])\n",
    "                    indices.append(batch['ori_indices'][i])\n",
    "\n",
    "    if len(data) > 0:\n",
    "        sentiment_dataset = SentimentAnalysisDataset(data, labels, aspects, indices, label_mapping, tokenizer, max_length=sequence_length)\n",
    "        sentiment_loader = torch.utils.data.DataLoader(\n",
    "            sentiment_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4,\n",
    "        )\n",
    "    \n",
    "        # Pass through sentiment analysis model\n",
    "        for batch in sentiment_loader:\n",
    "            token_type_ids = batch['token_type_ids'].to(device, non_blocking=True)\n",
    "            input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "            attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "    \n",
    "            with torch.no_grad():\n",
    "                outputs = sentiment_model.base_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "    \n",
    "            for i in range(len(outputs.last_hidden_state)):\n",
    "                ori_index = batch['ori_indices'][i].item()\n",
    "                if ori_index in sentiment_outputs.keys():\n",
    "                    sentiment_outputs[ori_index].append(outputs.last_hidden_state[i].mean(dim=1).cpu().numpy())\n",
    "                else:\n",
    "                    sentiment_outputs[ori_index] = [outputs.last_hidden_state[i].mean(dim=1).cpu().numpy()]\n",
    "\n",
    "    for key, val in sentiment_outputs.items():\n",
    "        sentiment_outputs[key] = np.mean(val, axis=0)\n",
    "\n",
    "    collected_indices = set()  # Initialize set to store selected indices\n",
    "    thresholds = []\n",
    "\n",
    "    if accelerator.is_main_process:\n",
    "        aspect_outputs = dict(sorted(aspect_outputs.items()))\n",
    "\n",
    "        if len(data) > 0:\n",
    "            for key, val in sentiment_outputs.items():\n",
    "                aspect_outputs[key] = np.mean([val, aspect_outputs[key]], axis=0)\n",
    "\n",
    "        embeddings = np.array(list(aspect_outputs.values()))\n",
    "        target_samples = len(embeddings[:math.ceil(0.1 * len(embeddings))])\n",
    "    \n",
    "        # Check nearest checkpoint\n",
    "        nearest_cp = 0\n",
    "        arrived_at_cp = False\n",
    "        for cp in checkpoints:\n",
    "            if cp > current_train_size:\n",
    "                nearest_cp = cp\n",
    "                break\n",
    "                \n",
    "        # Determine number of maximum samples to be acquired\n",
    "        if target_samples <= n_clusters and n_clusters < nearest_cp - current_train_size:\n",
    "            target_samples = n_clusters\n",
    "        elif target_samples > n_clusters and target_samples < nearest_cp - current_train_size:\n",
    "            target_samples = target_samples\n",
    "        else:\n",
    "            arrived_at_cp = True\n",
    "            target_samples = nearest_cp - current_train_size\n",
    "\n",
    "        # No clustering needed when there's little data left\n",
    "        if current_train_size >= checkpoints[len(checkpoints)-1] - min_increment:\n",
    "            end_time = time.time()\n",
    "            duration = end_time - start_time\n",
    "            \n",
    "            temp = train_indices.copy()\n",
    "            temp.extend(remaining_indices)\n",
    "            \n",
    "            # Save acquired data up to checkpoint\n",
    "            acquired_data = pd.DataFrame({\n",
    "                'processed_text': [X_train[i] for i in temp],\n",
    "                'fuel': [y_train[i][0] for i in temp],\n",
    "                'machine': [y_train[i][1] for i in temp],\n",
    "                'others': [y_train[i][2] for i in temp],\n",
    "                'part': [y_train[i][3] for i in temp],\n",
    "                'price': [y_train[i][4] for i in temp],\n",
    "                'service': [y_train[i][5] for i in temp],\n",
    "            })\n",
    "            acquired_data.to_csv(f'acquired_data/{filename}-{trials+1}-data-{nearest_cp}.csv', index=False)\n",
    "\n",
    "            print(\"Nearest checkpoint:\", nearest_cp)\n",
    "            print(\"Acquired samples:\", len(remaining_indices))\n",
    "            print(f\"Sampling duration: {duration} seconds\")\n",
    "            \n",
    "            sampling_dur.append(duration)\n",
    "            for i in remaining_indices:\n",
    "                new_samples.append(i)\n",
    "        else:\n",
    "            # Cluster the data based on its embeddings\n",
    "            kmeans=KMeans(n_clusters=n_clusters, n_init=1)\n",
    "            kmeans.fit(embeddings)\n",
    "            \n",
    "            for cluster_id in range(n_clusters):\n",
    "                # Cluster center and indices of samples in the current cluster\n",
    "                cluster_center = kmeans.cluster_centers_[cluster_id]\n",
    "                cluster_indices = np.where(kmeans.labels_ == cluster_id)[0]\n",
    "            \n",
    "                if cluster_indices.size == 0:\n",
    "                    # Skip clusters with no members\n",
    "                    print(f\"Cluster {cluster_id} has no members, skipping.\")\n",
    "                    continue\n",
    "            \n",
    "                # Calculate distances of each point in the cluster from the cluster center\n",
    "                cluster_distances = np.linalg.norm(embeddings[cluster_indices] - cluster_center, axis=1)\n",
    "            \n",
    "                # Determine the local threshold (10th percentile of closest distances to cluster center)\n",
    "                local_threshold = np.percentile(cluster_distances, 90)\n",
    "                thresholds.append(local_threshold)\n",
    "            \n",
    "                below_threshold_indices = cluster_indices[cluster_distances >= local_threshold]\n",
    "                collected_indices.update(below_threshold_indices)\n",
    "\n",
    "            # To handle multiple points with same distance\n",
    "            if len(collected_indices) > target_samples:\n",
    "                collected_indices = np.array(list(collected_indices))\n",
    "                np.random.shuffle(collected_indices)\n",
    "                collected_indices = collected_indices[:target_samples]\n",
    "                \n",
    "            end_time = time.time() \n",
    "            duration = end_time - start_time \n",
    "    \n",
    "            if arrived_at_cp:\n",
    "                temp = train_indices.copy()\n",
    "                temp.extend(collected_indices)\n",
    "                \n",
    "                # Save acquired data up to checkpoint\n",
    "                acquired_data = pd.DataFrame({\n",
    "                    'processed_text': [X_train[i] for i in temp],\n",
    "                    'fuel': [y_train[i][0] for i in temp],\n",
    "                    'machine': [y_train[i][1] for i in temp],\n",
    "                    'others': [y_train[i][2] for i in temp],\n",
    "                    'part': [y_train[i][3] for i in temp],\n",
    "                    'price': [y_train[i][4] for i in temp],\n",
    "                    'service': [y_train[i][5] for i in temp],\n",
    "                })\n",
    "        \n",
    "                acquired_data.to_csv(f'acquired_data/{filename}-{trials+1}-data-{nearest_cp}.csv', index=False)\n",
    "            \n",
    "            print(\"Nearest checkpoint:\", nearest_cp)\n",
    "            print(\"Acquired samples:\", len(collected_indices))\n",
    "            print(f\"Sampling duration: {duration} seconds\")\n",
    "        \n",
    "            sampling_dur.append(duration)\n",
    "            for i in collected_indices:\n",
    "                new_samples.append(remaining_indices[i])\n",
    "\n",
    "        threshold_data = pd.DataFrame({\n",
    "            'Threshold': thresholds\n",
    "        })\n",
    "        threshold_data.to_csv(f\"results/{filename}-thresholds-{trials+1}-{current_train_size}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89399798",
   "metadata": {
    "papermill": {
     "duration": 0.011906,
     "end_time": "2025-05-19T04:32:10.423790",
     "exception": false,
     "start_time": "2025-05-19T04:32:10.411884",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MAIN LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c7ac321",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T04:32:10.448770Z",
     "iopub.status.busy": "2025-05-19T04:32:10.448569Z",
     "iopub.status.idle": "2025-05-19T04:32:10.458022Z",
     "shell.execute_reply": "2025-05-19T04:32:10.457422Z"
    },
    "papermill": {
     "duration": 0.023182,
     "end_time": "2025-05-19T04:32:10.459067",
     "exception": false,
     "start_time": "2025-05-19T04:32:10.435885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def active_learning(seed, i, init_size):\n",
    "    aspect_accuracies = manager.list()\n",
    "    aspect_f1_micros = manager.list()\n",
    "    aspect_f1_macros = manager.list()\n",
    "    sentiment_accuracies = manager.list()\n",
    "    sentiment_f1_micros = manager.list()\n",
    "    sentiment_f1_macros = manager.list()\n",
    "    accuracies = manager.list()\n",
    "    f1_micros = manager.list()\n",
    "    f1_macros = manager.list()\n",
    "    data_used = manager.list()\n",
    "    sampling_dur = manager.list()\n",
    "    new_samples = manager.list()\n",
    "    filename = f'casa-kmeans-init-{init_size}'\n",
    "\n",
    "    set_seed(seed)\n",
    "    \n",
    "    print(\"===============================================\")\n",
    "    print(\"Init Size {}\".format(init_size))\n",
    "    print(\"Random seed:\", seed)\n",
    "    \n",
    "    train_indices = np.random.choice(range(len(X_train)), initial_train_size, replace=False).tolist()\n",
    "    remaining_indices = list(set(range(len(X_train))) - set(train_indices))\n",
    "    \n",
    "    current_train_size = initial_train_size\n",
    "    \n",
    "    start_time = time.time()\n",
    "    while current_train_size < checkpoints[len(checkpoints) - 1]:\n",
    "        # Train the model\n",
    "        args = (\n",
    "            current_train_size, \n",
    "            train_indices, \n",
    "            (aspect_accuracies, aspect_f1_micros, aspect_f1_macros), \n",
    "            (sentiment_accuracies, sentiment_f1_micros, sentiment_f1_macros),\n",
    "            (data_used, accuracies, f1_micros, f1_macros), \n",
    "            i,\n",
    "            seed,\n",
    "            filename\n",
    "        )\n",
    "        notebook_launcher(train_model, args, num_processes=2)\n",
    "\n",
    "        nearest_cp = current_train_size\n",
    "        if nearest_cp not in checkpoints:\n",
    "            for cp in checkpoints:\n",
    "                if cp > current_train_size:\n",
    "                    nearest_cp = cp\n",
    "                    break\n",
    "        percentage = math.ceil(nearest_cp / total_data * 100)\n",
    "\n",
    "        aspect_model = BertForSequenceClassification.from_pretrained(f'{filename}-aspect-{i+1}-model-{percentage}')\n",
    "        sentiment_model = BertForSequenceClassification.from_pretrained(f'{filename}-sentiment-{i+1}-model-{percentage}')\n",
    "    \n",
    "        # Perform query strategy to select new samples\n",
    "        new_samples = manager.list()\n",
    "        sampling_args = (\n",
    "            aspect_model, \n",
    "            sentiment_model, \n",
    "            [X_train[i] for i in remaining_indices], \n",
    "            train_indices, \n",
    "            remaining_indices, \n",
    "            sampling_dur, \n",
    "            new_samples, \n",
    "            i,\n",
    "            filename\n",
    "        )\n",
    "        notebook_launcher(kmeans_clustering_sampling, sampling_args, num_processes=2)\n",
    "        new_samples = list(new_samples)\n",
    "        train_indices.extend(new_samples)\n",
    "        remaining_indices = list(set(remaining_indices) - set(new_samples))\n",
    "    \n",
    "        # Update current training size\n",
    "        current_train_size = len(train_indices)\n",
    "        print(\"New train size: {}\".format(current_train_size))\n",
    "    \n",
    "    # Train last epoch\n",
    "    args = (\n",
    "        current_train_size, \n",
    "        train_indices, \n",
    "        (aspect_accuracies, aspect_f1_micros, aspect_f1_macros), \n",
    "        (sentiment_accuracies, sentiment_f1_micros, sentiment_f1_macros),\n",
    "        (data_used, accuracies, f1_micros, f1_macros), \n",
    "        i,\n",
    "        seed,\n",
    "        filename\n",
    "    )\n",
    "    notebook_launcher(train_model, args, num_processes=2)\n",
    "    data_used, accuracies, f1_micros, f1_macros, sampling_dur = list(data_used), list(accuracies), list(f1_micros), list(f1_macros), list(sampling_dur)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    # print(f\"Total sampling time: {np.array(sampling_dur).sum().round(2)} seconds\")\n",
    "    print(f\"Total runtime: {duration} seconds\")\n",
    "    \n",
    "    plot_result(data_used, accuracies, f1_micros, f1_macros)\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        'Data Used': data_used,\n",
    "        'Aspect Accuracy': aspect_accuracies,\n",
    "        'Aspect F1 Micro': aspect_f1_micros,\n",
    "        'Aspect F1 Macro': aspect_f1_macros,\n",
    "        'Sentiment Accuracy': sentiment_accuracies,\n",
    "        'Sentiment F1 Micro': sentiment_f1_micros,\n",
    "        'Sentiment F1 Macro': sentiment_f1_macros,\n",
    "        'Accuracy': accuracies,\n",
    "        'F1 Micro': f1_micros,\n",
    "        'F1 Macro': f1_macros,\n",
    "    })\n",
    "    \n",
    "    sampling_dur.insert(0, 0)\n",
    "    results['Sampling Duration'] = sampling_dur\n",
    "    results.to_csv(f'results/{filename}-{i+1}-results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1b32b66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T04:32:10.484178Z",
     "iopub.status.busy": "2025-05-19T04:32:10.483941Z",
     "iopub.status.idle": "2025-05-19T05:25:04.432869Z",
     "shell.execute_reply": "2025-05-19T05:25:04.432150Z"
    },
    "papermill": {
     "duration": 3173.962899,
     "end_time": "2025-05-19T05:25:04.434226",
     "exception": false,
     "start_time": "2025-05-19T04:32:10.471327",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "Init Size 1\n",
      "Random seed: 81\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6716, Accuracy: 0.6763, F1 Micro: 0.7845, F1 Macro: 0.6875\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.623, Accuracy: 0.724, F1 Micro: 0.8277, F1 Macro: 0.7588\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5676, Accuracy: 0.7478, F1 Micro: 0.8485, F1 Macro: 0.8168\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5258, Accuracy: 0.776, F1 Micro: 0.8712, F1 Macro: 0.865\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4874, Accuracy: 0.7932, F1 Micro: 0.884, F1 Macro: 0.8824\n",
      "Epoch 6/10, Train Loss: 0.453, Accuracy: 0.7902, F1 Micro: 0.8826, F1 Macro: 0.8811\n",
      "Epoch 7/10, Train Loss: 0.4214, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 8/10, Train Loss: 0.4196, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 9/10, Train Loss: 0.3868, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Epoch 10/10, Train Loss: 0.3569, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "\n",
      "Aspect detection accuracy: 0.7932, F1 Micro: 0.884, F1 Macro: 0.8824\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.78      1.00      0.88       175\n",
      "      others       0.73      0.99      0.84       158\n",
      "        part       0.71      1.00      0.83       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.79      1.00      0.88      1061\n",
      "   macro avg       0.79      1.00      0.88      1061\n",
      "weighted avg       0.80      1.00      0.89      1061\n",
      " samples avg       0.79      1.00      0.88      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6232, Accuracy: 0.7778, F1 Micro: 0.7778, F1 Macro: 0.4375\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4977, Accuracy: 0.8889, F1 Micro: 0.8889, F1 Macro: 0.4706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3777, Accuracy: 0.8889, F1 Micro: 0.8889, F1 Macro: 0.4706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2928, Accuracy: 0.8889, F1 Micro: 0.8889, F1 Macro: 0.4706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2176, Accuracy: 0.8889, F1 Micro: 0.8889, F1 Macro: 0.4706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1723, Accuracy: 0.8889, F1 Micro: 0.8889, F1 Macro: 0.4706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1318, Accuracy: 0.8889, F1 Micro: 0.8889, F1 Macro: 0.4706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1066, Accuracy: 0.8889, F1 Micro: 0.8889, F1 Macro: 0.4706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0846, Accuracy: 0.8889, F1 Micro: 0.8889, F1 Macro: 0.4706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0711, Accuracy: 0.8889, F1 Micro: 0.8889, F1 Macro: 0.4706\n",
      "\n",
      "Sentiment analysis accuracy: 0.8889, F1 Micro: 0.8889, F1 Macro: 0.4706\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         1\n",
      "    positive       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.89         9\n",
      "   macro avg       0.44      0.50      0.47         9\n",
      "weighted avg       0.79      0.89      0.84         9\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 10: Accuracy: 0.7924, F1 Micro: 0.7924, F1 Macro: 0.305\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.77      1.00      0.87       167\n",
      "    positive       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.77       216\n",
      "   macro avg       0.26      0.33      0.29       216\n",
      "weighted avg       0.60      0.77      0.67       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.72      0.99      0.84       152\n",
      "    positive       0.67      0.12      0.20        52\n",
      "\n",
      "    accuracy                           0.72       216\n",
      "   macro avg       0.46      0.37      0.34       216\n",
      "weighted avg       0.67      0.72      0.64       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        23\n",
      "     neutral       0.70      1.00      0.83       152\n",
      "    positive       0.00      0.00      0.00        41\n",
      "\n",
      "    accuracy                           0.70       216\n",
      "   macro avg       0.23      0.33      0.28       216\n",
      "weighted avg       0.50      0.70      0.58       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 50.87902855873108 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 86\n",
      "Sampling duration: 8.430638074874878 seconds\n",
      "New train size: 96\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6291, Accuracy: 0.7202, F1 Micro: 0.8262, F1 Macro: 0.7461\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5393, Accuracy: 0.7939, F1 Micro: 0.8843, F1 Macro: 0.8828\n",
      "Epoch 3/10, Train Loss: 0.5001, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 4/10, Train Loss: 0.4817, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 5/10, Train Loss: 0.4644, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 6/10, Train Loss: 0.4343, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 7/10, Train Loss: 0.4518, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3749, Accuracy: 0.7991, F1 Micro: 0.8869, F1 Macro: 0.8854\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3642, Accuracy: 0.8103, F1 Micro: 0.8925, F1 Macro: 0.891\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3489, Accuracy: 0.8296, F1 Micro: 0.9022, F1 Macro: 0.9011\n",
      "\n",
      "Aspect detection accuracy: 0.8296, F1 Micro: 0.9022, F1 Macro: 0.9011\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.78      1.00      0.88       175\n",
      "      others       0.81      0.97      0.88       158\n",
      "        part       0.79      1.00      0.88       158\n",
      "       price       0.86      1.00      0.93       192\n",
      "     service       0.86      1.00      0.93       191\n",
      "\n",
      "   micro avg       0.82      1.00      0.90      1061\n",
      "   macro avg       0.82      0.99      0.90      1061\n",
      "weighted avg       0.83      1.00      0.90      1061\n",
      " samples avg       0.83      1.00      0.90      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6609, Accuracy: 0.7213, F1 Micro: 0.7213, F1 Macro: 0.419\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.6008, Accuracy: 0.7213, F1 Micro: 0.7213, F1 Macro: 0.419\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.6231, Accuracy: 0.7213, F1 Micro: 0.7213, F1 Macro: 0.419\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.6088, Accuracy: 0.7213, F1 Micro: 0.7213, F1 Macro: 0.419\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.5486, Accuracy: 0.7213, F1 Micro: 0.7213, F1 Macro: 0.419\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.5002, Accuracy: 0.7213, F1 Micro: 0.7213, F1 Macro: 0.419\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.5201, Accuracy: 0.7377, F1 Micro: 0.7377, F1 Macro: 0.4786\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4664, Accuracy: 0.7705, F1 Micro: 0.7705, F1 Macro: 0.5814\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.4717, Accuracy: 0.7869, F1 Micro: 0.7869, F1 Macro: 0.6908\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3062, Accuracy: 0.8361, F1 Micro: 0.8361, F1 Macro: 0.779\n",
      "\n",
      "Sentiment analysis accuracy: 0.8361, F1 Micro: 0.8361, F1 Macro: 0.779\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.59      0.67        17\n",
      "    positive       0.85      0.93      0.89        44\n",
      "\n",
      "    accuracy                           0.84        61\n",
      "   macro avg       0.81      0.76      0.78        61\n",
      "weighted avg       0.83      0.84      0.83        61\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 96: Accuracy: 0.821, F1 Micro: 0.821, F1 Macro: 0.4181\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.78      1.00      0.87       167\n",
      "    positive       1.00      0.03      0.06        33\n",
      "\n",
      "    accuracy                           0.78       216\n",
      "   macro avg       0.59      0.34      0.31       216\n",
      "weighted avg       0.75      0.78      0.68       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.57      0.33      0.42        12\n",
      "     neutral       0.81      0.97      0.88       152\n",
      "    positive       0.75      0.40      0.53        52\n",
      "\n",
      "    accuracy                           0.80       216\n",
      "   macro avg       0.71      0.57      0.61       216\n",
      "weighted avg       0.78      0.80      0.77       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.26      0.41        23\n",
      "     neutral       0.78      1.00      0.88       152\n",
      "    positive       0.73      0.27      0.39        41\n",
      "\n",
      "    accuracy                           0.78       216\n",
      "   macro avg       0.84      0.51      0.56       216\n",
      "weighted avg       0.79      0.78      0.74       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.87      1.00      0.93       186\n",
      "    positive       1.00      0.06      0.11        17\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.62      0.35      0.35       216\n",
      "weighted avg       0.82      0.87      0.81       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.87      1.00      0.93       185\n",
      "    positive       0.67      0.12      0.20        17\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.51      0.37      0.38       216\n",
      "weighted avg       0.80      0.87      0.81       216\n",
      "\n",
      "Total train time: 57.9907066822052 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 77\n",
      "Sampling duration: 11.219738960266113 seconds\n",
      "New train size: 173\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.604, Accuracy: 0.7932, F1 Micro: 0.8836, F1 Macro: 0.8818\n",
      "Epoch 2/10, Train Loss: 0.4883, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 3/10, Train Loss: 0.496, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4556, Accuracy: 0.7991, F1 Micro: 0.8871, F1 Macro: 0.8857\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4105, Accuracy: 0.8229, F1 Micro: 0.899, F1 Macro: 0.8978\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.378, Accuracy: 0.8624, F1 Micro: 0.9189, F1 Macro: 0.9179\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3211, Accuracy: 0.9033, F1 Micro: 0.9411, F1 Macro: 0.9393\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2769, Accuracy: 0.9152, F1 Micro: 0.9476, F1 Macro: 0.9453\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.234, Accuracy: 0.9211, F1 Micro: 0.9512, F1 Macro: 0.949\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1858, Accuracy: 0.9293, F1 Micro: 0.9561, F1 Macro: 0.954\n",
      "\n",
      "Aspect detection accuracy: 0.9293, F1 Micro: 0.9561, F1 Macro: 0.954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.97      1.00      0.98       187\n",
      "     machine       0.91      0.97      0.94       175\n",
      "      others       0.88      0.93      0.90       158\n",
      "        part       0.93      0.94      0.94       158\n",
      "       price       0.96      1.00      0.98       192\n",
      "     service       0.97      0.99      0.98       191\n",
      "\n",
      "   micro avg       0.94      0.98      0.96      1061\n",
      "   macro avg       0.94      0.97      0.95      1061\n",
      "weighted avg       0.94      0.98      0.96      1061\n",
      " samples avg       0.94      0.98      0.95      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5744, Accuracy: 0.6853, F1 Micro: 0.6853, F1 Macro: 0.4066\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5635, Accuracy: 0.6853, F1 Micro: 0.6853, F1 Macro: 0.4066\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4548, Accuracy: 0.7026, F1 Micro: 0.7026, F1 Macro: 0.557\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.34, Accuracy: 0.819, F1 Micro: 0.819, F1 Macro: 0.7945\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2492, Accuracy: 0.819, F1 Micro: 0.819, F1 Macro: 0.7885\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1655, Accuracy: 0.8621, F1 Micro: 0.8621, F1 Macro: 0.8483\n",
      "Epoch 7/10, Train Loss: 0.0643, Accuracy: 0.8491, F1 Micro: 0.8491, F1 Macro: 0.8231\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0974, Accuracy: 0.8621, F1 Micro: 0.8621, F1 Macro: 0.8401\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0736, Accuracy: 0.875, F1 Micro: 0.875, F1 Macro: 0.8613\n",
      "Epoch 10/10, Train Loss: 0.0936, Accuracy: 0.8707, F1 Micro: 0.8707, F1 Macro: 0.856\n",
      "\n",
      "Sentiment analysis accuracy: 0.875, F1 Micro: 0.875, F1 Macro: 0.8613\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.89      0.82        73\n",
      "    positive       0.95      0.87      0.90       159\n",
      "\n",
      "    accuracy                           0.88       232\n",
      "   macro avg       0.85      0.88      0.86       232\n",
      "weighted avg       0.89      0.88      0.88       232\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 173: Accuracy: 0.9159, F1 Micro: 0.9159, F1 Macro: 0.8253\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.82      0.86        11\n",
      "     neutral       0.97      1.00      0.99       181\n",
      "    positive       0.95      0.79      0.86        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.87      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.50      0.64        16\n",
      "     neutral       0.91      0.97      0.94       167\n",
      "    positive       0.75      0.64      0.69        33\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.85      0.70      0.75       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.75      0.60        12\n",
      "     neutral       0.88      0.93      0.90       152\n",
      "    positive       0.81      0.56      0.66        52\n",
      "\n",
      "    accuracy                           0.83       216\n",
      "   macro avg       0.73      0.75      0.72       216\n",
      "weighted avg       0.84      0.83      0.83       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.68      0.83      0.75        23\n",
      "     neutral       0.93      0.94      0.93       152\n",
      "    positive       0.88      0.73      0.80        41\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.83      0.83      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.96      1.00      0.98       186\n",
      "    positive       0.92      0.65      0.76        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.96      0.81      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.71      0.80        14\n",
      "     neutral       0.97      0.99      0.98       185\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.84      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Total train time: 77.23876667022705 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 70\n",
      "Sampling duration: 14.594876527786255 seconds\n",
      "New train size: 243\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.573, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4705, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4711, Accuracy: 0.7984, F1 Micro: 0.8868, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4263, Accuracy: 0.8185, F1 Micro: 0.8969, F1 Macro: 0.8959\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3684, Accuracy: 0.8661, F1 Micro: 0.9207, F1 Macro: 0.9203\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.32, Accuracy: 0.9152, F1 Micro: 0.9478, F1 Macro: 0.9459\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2519, Accuracy: 0.9219, F1 Micro: 0.9519, F1 Macro: 0.9502\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1945, Accuracy: 0.9249, F1 Micro: 0.9532, F1 Macro: 0.9509\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1665, Accuracy: 0.9301, F1 Micro: 0.9565, F1 Macro: 0.9544\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1476, Accuracy: 0.936, F1 Micro: 0.9601, F1 Macro: 0.9584\n",
      "\n",
      "Aspect detection accuracy: 0.936, F1 Micro: 0.9601, F1 Macro: 0.9584\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.97      1.00      0.98       187\n",
      "     machine       0.94      0.95      0.94       175\n",
      "      others       0.87      0.96      0.91       158\n",
      "        part       0.94      0.95      0.95       158\n",
      "       price       0.97      1.00      0.98       192\n",
      "     service       0.96      0.99      0.98       191\n",
      "\n",
      "   micro avg       0.94      0.98      0.96      1061\n",
      "   macro avg       0.94      0.97      0.96      1061\n",
      "weighted avg       0.95      0.98      0.96      1061\n",
      " samples avg       0.94      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6334, Accuracy: 0.6862, F1 Micro: 0.6862, F1 Macro: 0.4069\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5528, Accuracy: 0.6862, F1 Micro: 0.6862, F1 Macro: 0.4533\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.435, Accuracy: 0.8201, F1 Micro: 0.8201, F1 Macro: 0.8088\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2585, Accuracy: 0.8787, F1 Micro: 0.8787, F1 Macro: 0.865\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1296, Accuracy: 0.9038, F1 Micro: 0.9038, F1 Macro: 0.8895\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0886, Accuracy: 0.9205, F1 Micro: 0.9205, F1 Macro: 0.911\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0758, Accuracy: 0.9205, F1 Micro: 0.9205, F1 Macro: 0.911\n",
      "Epoch 8/10, Train Loss: 0.055, Accuracy: 0.9038, F1 Micro: 0.9038, F1 Macro: 0.8879\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0482, Accuracy: 0.9205, F1 Micro: 0.9205, F1 Macro: 0.911\n",
      "Epoch 10/10, Train Loss: 0.0527, Accuracy: 0.9038, F1 Micro: 0.9038, F1 Macro: 0.8909\n",
      "\n",
      "Sentiment analysis accuracy: 0.9205, F1 Micro: 0.9205, F1 Macro: 0.911\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.95      0.88        75\n",
      "    positive       0.97      0.91      0.94       164\n",
      "\n",
      "    accuracy                           0.92       239\n",
      "   macro avg       0.90      0.93      0.91       239\n",
      "weighted avg       0.93      0.92      0.92       239\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 243: Accuracy: 0.9282, F1 Micro: 0.9282, F1 Macro: 0.8585\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.97      1.00      0.99       181\n",
      "    positive       1.00      0.83      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.99      0.91      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.93      0.95      0.94       167\n",
      "    positive       0.71      0.73      0.72        33\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.85      0.81      0.83       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.75      0.69        12\n",
      "     neutral       0.87      0.96      0.92       152\n",
      "    positive       0.89      0.60      0.71        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.80      0.77      0.77       216\n",
      "weighted avg       0.86      0.86      0.85       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.96      0.83        23\n",
      "     neutral       0.94      0.95      0.94       152\n",
      "    positive       0.94      0.76      0.84        41\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.87      0.89      0.87       216\n",
      "weighted avg       0.92      0.91      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.97      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.84      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.57      0.73        14\n",
      "     neutral       0.96      0.99      0.98       185\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.80      0.84       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Total train time: 89.50354766845703 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 63\n",
      "Sampling duration: 14.548415184020996 seconds\n",
      "New train size: 306\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5695, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.483, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4578, Accuracy: 0.8162, F1 Micro: 0.8957, F1 Macro: 0.8945\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3744, Accuracy: 0.8638, F1 Micro: 0.9196, F1 Macro: 0.9186\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3246, Accuracy: 0.9062, F1 Micro: 0.9423, F1 Macro: 0.9394\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2578, Accuracy: 0.9293, F1 Micro: 0.9558, F1 Macro: 0.9539\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2078, Accuracy: 0.9405, F1 Micro: 0.9628, F1 Macro: 0.961\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1734, Accuracy: 0.9449, F1 Micro: 0.9655, F1 Macro: 0.9633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1239, Accuracy: 0.9494, F1 Micro: 0.9683, F1 Macro: 0.9661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1096, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9714\n",
      "\n",
      "Aspect detection accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.97      0.96       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.94      0.98      0.96       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6129, Accuracy: 0.6944, F1 Micro: 0.6944, F1 Macro: 0.4098\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5159, Accuracy: 0.7421, F1 Micro: 0.7421, F1 Macro: 0.609\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.322, Accuracy: 0.9127, F1 Micro: 0.9127, F1 Macro: 0.9018\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1637, Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9345\n",
      "Epoch 5/10, Train Loss: 0.0956, Accuracy: 0.9246, F1 Micro: 0.9246, F1 Macro: 0.9102\n",
      "Epoch 6/10, Train Loss: 0.1206, Accuracy: 0.9206, F1 Micro: 0.9206, F1 Macro: 0.9117\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0905, Accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9394\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0903, Accuracy: 0.9563, F1 Micro: 0.9563, F1 Macro: 0.9488\n",
      "Epoch 9/10, Train Loss: 0.0427, Accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9407\n",
      "Epoch 10/10, Train Loss: 0.0501, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9125\n",
      "\n",
      "Sentiment analysis accuracy: 0.9563, F1 Micro: 0.9563, F1 Macro: 0.9488\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.94      0.93        77\n",
      "    positive       0.97      0.97      0.97       175\n",
      "\n",
      "    accuracy                           0.96       252\n",
      "   macro avg       0.95      0.95      0.95       252\n",
      "weighted avg       0.96      0.96      0.96       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 306: Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.9054\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.95      0.97      0.96       167\n",
      "    positive       0.79      0.79      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.84      0.86       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.93      0.95      0.94       152\n",
      "    positive       0.84      0.83      0.83        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.89      0.84      0.86       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.87      0.85        23\n",
      "     neutral       0.94      0.98      0.96       152\n",
      "    positive       0.94      0.76      0.84        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.97      1.00      0.99       186\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.99      0.89      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.71      0.83        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.89      1.00      0.94        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.90      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 92.10220241546631 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 56\n",
      "Sampling duration: 13.068957805633545 seconds\n",
      "New train size: 362\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5452, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4762, Accuracy: 0.7939, F1 Micro: 0.8845, F1 Macro: 0.8831\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4171, Accuracy: 0.8296, F1 Micro: 0.9024, F1 Macro: 0.9015\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3513, Accuracy: 0.9092, F1 Micro: 0.9444, F1 Macro: 0.9425\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2753, Accuracy: 0.9308, F1 Micro: 0.957, F1 Macro: 0.9551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2085, Accuracy: 0.9442, F1 Micro: 0.9652, F1 Macro: 0.9634\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1631, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9729\n",
      "Epoch 8/10, Train Loss: 0.1314, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1135, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9746\n",
      "Epoch 10/10, Train Loss: 0.0881, Accuracy: 0.9606, F1 Micro: 0.9754, F1 Macro: 0.9739\n",
      "\n",
      "Aspect detection accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9746\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.95      0.96      0.96       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5347, Accuracy: 0.6798, F1 Micro: 0.6798, F1 Macro: 0.4047\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4607, Accuracy: 0.8498, F1 Micro: 0.8498, F1 Macro: 0.8286\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2166, Accuracy: 0.9209, F1 Micro: 0.9209, F1 Macro: 0.9119\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1547, Accuracy: 0.9209, F1 Micro: 0.9209, F1 Macro: 0.9109\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1253, Accuracy: 0.9368, F1 Micro: 0.9368, F1 Macro: 0.9287\n",
      "Epoch 6/10, Train Loss: 0.1053, Accuracy: 0.9051, F1 Micro: 0.9051, F1 Macro: 0.8872\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0821, Accuracy: 0.9447, F1 Micro: 0.9447, F1 Macro: 0.938\n",
      "Epoch 8/10, Train Loss: 0.0818, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9245\n",
      "Epoch 9/10, Train Loss: 0.0567, Accuracy: 0.9249, F1 Micro: 0.9249, F1 Macro: 0.9151\n",
      "Epoch 10/10, Train Loss: 0.0281, Accuracy: 0.9209, F1 Micro: 0.9209, F1 Macro: 0.9109\n",
      "\n",
      "Sentiment analysis accuracy: 0.9447, F1 Micro: 0.9447, F1 Macro: 0.938\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        81\n",
      "    positive       0.98      0.94      0.96       172\n",
      "\n",
      "    accuracy                           0.94       253\n",
      "   macro avg       0.93      0.95      0.94       253\n",
      "weighted avg       0.95      0.94      0.95       253\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 362: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9125\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       1.00      0.88      0.93        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.93      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.96      0.99      0.97       167\n",
      "    positive       0.90      0.82      0.86        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.87      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.92      0.96      0.94       152\n",
      "    positive       0.88      0.81      0.84        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.90      0.84      0.87       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.96      0.85        23\n",
      "     neutral       0.95      0.96      0.95       152\n",
      "    positive       0.94      0.76      0.84        41\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.88      0.89      0.88       216\n",
      "weighted avg       0.93      0.92      0.92       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 93.56784296035767 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 51\n",
      "Sampling duration: 12.113857746124268 seconds\n",
      "New train size: 413\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5641, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4696, Accuracy: 0.7939, F1 Micro: 0.8844, F1 Macro: 0.8829\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4361, Accuracy: 0.8504, F1 Micro: 0.912, F1 Macro: 0.9108\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3489, Accuracy: 0.9182, F1 Micro: 0.9486, F1 Macro: 0.9463\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2617, Accuracy: 0.942, F1 Micro: 0.9637, F1 Macro: 0.9623\n",
      "Epoch 6/10, Train Loss: 0.2052, Accuracy: 0.9412, F1 Micro: 0.9633, F1 Macro: 0.9612\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1683, Accuracy: 0.9487, F1 Micro: 0.9677, F1 Macro: 0.9651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1356, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.111, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0941, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9755\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9755\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.91      0.97      0.94       158\n",
      "        part       0.96      0.99      0.97       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.98      1061\n",
      "weighted avg       0.96      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5475, Accuracy: 0.7114, F1 Micro: 0.7114, F1 Macro: 0.5816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3699, Accuracy: 0.878, F1 Micro: 0.878, F1 Macro: 0.8703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1909, Accuracy: 0.9431, F1 Micro: 0.9431, F1 Macro: 0.936\n",
      "Epoch 4/10, Train Loss: 0.1291, Accuracy: 0.9187, F1 Micro: 0.9187, F1 Macro: 0.912\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1082, Accuracy: 0.9431, F1 Micro: 0.9431, F1 Macro: 0.9371\n",
      "Epoch 6/10, Train Loss: 0.0881, Accuracy: 0.939, F1 Micro: 0.939, F1 Macro: 0.9328\n",
      "Epoch 7/10, Train Loss: 0.0693, Accuracy: 0.939, F1 Micro: 0.939, F1 Macro: 0.9328\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0569, Accuracy: 0.9593, F1 Micro: 0.9593, F1 Macro: 0.9545\n",
      "Epoch 9/10, Train Loss: 0.0446, Accuracy: 0.9187, F1 Micro: 0.9187, F1 Macro: 0.912\n",
      "Epoch 10/10, Train Loss: 0.0174, Accuracy: 0.9309, F1 Micro: 0.9309, F1 Macro: 0.9238\n",
      "\n",
      "Sentiment analysis accuracy: 0.9593, F1 Micro: 0.9593, F1 Macro: 0.9545\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.96      0.94        81\n",
      "    positive       0.98      0.96      0.97       165\n",
      "\n",
      "    accuracy                           0.96       246\n",
      "   macro avg       0.95      0.96      0.95       246\n",
      "weighted avg       0.96      0.96      0.96       246\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 413: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9181\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.85      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.91      0.97      0.94       152\n",
      "    positive       0.91      0.77      0.83        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.91      0.83      0.86       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.96      0.99      0.97       152\n",
      "    positive       0.97      0.76      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.90      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.97      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.97      0.87      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 100.23830056190491 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 46\n",
      "Sampling duration: 10.978839874267578 seconds\n",
      "New train size: 459\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5425, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4732, Accuracy: 0.8177, F1 Micro: 0.8965, F1 Macro: 0.8953\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3931, Accuracy: 0.8981, F1 Micro: 0.938, F1 Macro: 0.9362\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.306, Accuracy: 0.9308, F1 Micro: 0.9571, F1 Macro: 0.9551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2187, Accuracy: 0.9464, F1 Micro: 0.9665, F1 Macro: 0.9646\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1796, Accuracy: 0.9554, F1 Micro: 0.9721, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1347, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1043, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.975\n",
      "Epoch 9/10, Train Loss: 0.0852, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9728\n",
      "Epoch 10/10, Train Loss: 0.0745, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9739\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.98       175\n",
      "      others       0.92      0.92      0.92       158\n",
      "        part       0.95      0.99      0.97       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5888, Accuracy: 0.6772, F1 Micro: 0.6772, F1 Macro: 0.4038\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3658, Accuracy: 0.9094, F1 Micro: 0.9094, F1 Macro: 0.9008\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2014, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9331\n",
      "Epoch 4/10, Train Loss: 0.1429, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.914\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1083, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9318\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0976, Accuracy: 0.9528, F1 Micro: 0.9528, F1 Macro: 0.9456\n",
      "Epoch 7/10, Train Loss: 0.0929, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9385\n",
      "Epoch 8/10, Train Loss: 0.0436, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9301\n",
      "Epoch 9/10, Train Loss: 0.0571, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.92\n",
      "Epoch 10/10, Train Loss: 0.035, Accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.9099\n",
      "\n",
      "Sentiment analysis accuracy: 0.9528, F1 Micro: 0.9528, F1 Macro: 0.9456\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.91      0.93        82\n",
      "    positive       0.96      0.97      0.97       172\n",
      "\n",
      "    accuracy                           0.95       254\n",
      "   macro avg       0.95      0.94      0.95       254\n",
      "weighted avg       0.95      0.95      0.95       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 459: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9113\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.99      0.98       167\n",
      "    positive       0.93      0.79      0.85        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.94      0.89      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.79      0.81      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.85      0.83      0.84       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        23\n",
      "     neutral       0.94      0.99      0.97       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.94      0.90      0.92       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.89      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.71      0.83        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.89      1.00      0.94        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.90      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 103.77960634231567 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 41\n",
      "Sampling duration: 9.892764329910278 seconds\n",
      "New train size: 500\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5362, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4804, Accuracy: 0.8192, F1 Micro: 0.8973, F1 Macro: 0.8961\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3803, Accuracy: 0.9018, F1 Micro: 0.9384, F1 Macro: 0.9354\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2803, Accuracy: 0.9368, F1 Micro: 0.9605, F1 Macro: 0.9589\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2155, Accuracy: 0.9464, F1 Micro: 0.9665, F1 Macro: 0.9644\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1652, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1264, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.099, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0795, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9744\n",
      "Epoch 10/10, Train Loss: 0.0699, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9721\n",
      "\n",
      "Aspect detection accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9744\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.94      0.98      0.96       175\n",
      "      others       0.96      0.91      0.93       158\n",
      "        part       0.95      1.00      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5802, Accuracy: 0.6858, F1 Micro: 0.6858, F1 Macro: 0.4292\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3666, Accuracy: 0.8966, F1 Micro: 0.8966, F1 Macro: 0.8875\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2012, Accuracy: 0.931, F1 Micro: 0.931, F1 Macro: 0.9224\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1709, Accuracy: 0.9387, F1 Micro: 0.9387, F1 Macro: 0.9318\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1239, Accuracy: 0.9617, F1 Micro: 0.9617, F1 Macro: 0.9564\n",
      "Epoch 6/10, Train Loss: 0.1134, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9273\n",
      "Epoch 7/10, Train Loss: 0.1038, Accuracy: 0.9425, F1 Micro: 0.9425, F1 Macro: 0.9355\n",
      "Epoch 8/10, Train Loss: 0.0463, Accuracy: 0.9502, F1 Micro: 0.9502, F1 Macro: 0.9438\n",
      "Epoch 9/10, Train Loss: 0.0533, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9261\n",
      "Epoch 10/10, Train Loss: 0.057, Accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.94\n",
      "\n",
      "Sentiment analysis accuracy: 0.9617, F1 Micro: 0.9617, F1 Macro: 0.9564\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.96      0.94        83\n",
      "    positive       0.98      0.96      0.97       178\n",
      "\n",
      "    accuracy                           0.96       261\n",
      "   macro avg       0.95      0.96      0.96       261\n",
      "weighted avg       0.96      0.96      0.96       261\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 500: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9228\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       1.00      0.96      0.98        24\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.99      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.85      0.70      0.77        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.91      0.83      0.86       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.97      0.91      0.94       152\n",
      "    positive       0.77      0.90      0.83        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.86      0.88      0.87       216\n",
      "weighted avg       0.91      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.96      0.94        23\n",
      "     neutral       0.94      1.00      0.97       152\n",
      "    positive       1.00      0.76      0.86        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.95      0.90      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.95      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 109.58963227272034 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 37\n",
      "Sampling duration: 9.22080397605896 seconds\n",
      "New train size: 537\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5485, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4509, Accuracy: 0.8304, F1 Micro: 0.9028, F1 Macro: 0.9022\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3596, Accuracy: 0.9107, F1 Micro: 0.9441, F1 Macro: 0.9392\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2708, Accuracy: 0.9449, F1 Micro: 0.9657, F1 Macro: 0.964\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2049, Accuracy: 0.9554, F1 Micro: 0.9722, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1529, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1172, Accuracy: 0.9695, F1 Micro: 0.9809, F1 Macro: 0.9799\n",
      "Epoch 8/10, Train Loss: 0.0956, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9764\n",
      "Epoch 9/10, Train Loss: 0.0802, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9762\n",
      "Epoch 10/10, Train Loss: 0.0634, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.979\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9809, F1 Macro: 0.9799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.97      0.95       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5706, Accuracy: 0.6706, F1 Micro: 0.6706, F1 Macro: 0.4014\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3897, Accuracy: 0.9255, F1 Micro: 0.9255, F1 Macro: 0.9182\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1862, Accuracy: 0.9255, F1 Micro: 0.9255, F1 Macro: 0.9154\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.137, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9396\n",
      "Epoch 5/10, Train Loss: 0.0955, Accuracy: 0.9255, F1 Micro: 0.9255, F1 Macro: 0.9149\n",
      "Epoch 6/10, Train Loss: 0.1046, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9191\n",
      "Epoch 7/10, Train Loss: 0.0911, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9294\n",
      "Epoch 8/10, Train Loss: 0.0451, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9354\n",
      "Epoch 9/10, Train Loss: 0.0755, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9351\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0508, Accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.9435\n",
      "\n",
      "Sentiment analysis accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.9435\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.96      0.93        84\n",
      "    positive       0.98      0.94      0.96       171\n",
      "\n",
      "    accuracy                           0.95       255\n",
      "   macro avg       0.94      0.95      0.94       255\n",
      "weighted avg       0.95      0.95      0.95       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 537: Accuracy: 0.9622, F1 Micro: 0.9622, F1 Macro: 0.9239\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.86      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.93      0.97      0.95       152\n",
      "    positive       0.91      0.77      0.83        52\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.87      0.86      0.86       216\n",
      "weighted avg       0.92      0.92      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.83      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 108.10657167434692 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 3\n",
      "Sampling duration: 8.287410736083984 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5337, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4515, Accuracy: 0.8304, F1 Micro: 0.9027, F1 Macro: 0.9018\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3562, Accuracy: 0.9085, F1 Micro: 0.9426, F1 Macro: 0.9393\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2673, Accuracy: 0.9464, F1 Micro: 0.9668, F1 Macro: 0.9652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2001, Accuracy: 0.9516, F1 Micro: 0.9698, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1532, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1205, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0976, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9775\n",
      "Epoch 9/10, Train Loss: 0.0783, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0612, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9777\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9777\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.93      0.94      0.94       158\n",
      "        part       0.96      1.00      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.538, Accuracy: 0.7391, F1 Micro: 0.7391, F1 Macro: 0.6115\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3138, Accuracy: 0.8735, F1 Micro: 0.8735, F1 Macro: 0.8672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2219, Accuracy: 0.9249, F1 Micro: 0.9249, F1 Macro: 0.9187\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1789, Accuracy: 0.9289, F1 Micro: 0.9289, F1 Macro: 0.9212\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1299, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9272\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1214, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9265\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0959, Accuracy: 0.9368, F1 Micro: 0.9368, F1 Macro: 0.9303\n",
      "Epoch 8/10, Train Loss: 0.0723, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9272\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0298, Accuracy: 0.9368, F1 Micro: 0.9368, F1 Macro: 0.9307\n",
      "Epoch 10/10, Train Loss: 0.0523, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9265\n",
      "\n",
      "Sentiment analysis accuracy: 0.9368, F1 Micro: 0.9368, F1 Macro: 0.9307\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.95      0.91        85\n",
      "    positive       0.97      0.93      0.95       168\n",
      "\n",
      "    accuracy                           0.94       253\n",
      "   macro avg       0.92      0.94      0.93       253\n",
      "weighted avg       0.94      0.94      0.94       253\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9134\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.83      0.73      0.77        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.82      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.94      0.95      0.94       152\n",
      "    positive       0.85      0.79      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.83      0.86      0.84       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.96      1.00      0.98       152\n",
      "    positive       1.00      0.73      0.85        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.94      0.91      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 118.49431729316711 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 33\n",
      "Sampling duration: 8.404736995697021 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5332, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4666, Accuracy: 0.8445, F1 Micro: 0.91, F1 Macro: 0.9089\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3545, Accuracy: 0.9182, F1 Micro: 0.9491, F1 Macro: 0.9466\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2557, Accuracy: 0.9487, F1 Micro: 0.9681, F1 Macro: 0.9666\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.189, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1388, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9759\n",
      "Epoch 7/10, Train Loss: 0.1128, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.095, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.978\n",
      "Epoch 9/10, Train Loss: 0.0723, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0639, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.979\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.979\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5494, Accuracy: 0.8308, F1 Micro: 0.8308, F1 Macro: 0.797\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2929, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.904\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.204, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9283\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1467, Accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9395\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1477, Accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9388\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1026, Accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.944\n",
      "Epoch 7/10, Train Loss: 0.1254, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9139\n",
      "Epoch 8/10, Train Loss: 0.079, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9338\n",
      "Epoch 9/10, Train Loss: 0.0557, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9235\n",
      "Epoch 10/10, Train Loss: 0.058, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9259\n",
      "\n",
      "Sentiment analysis accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.944\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.93        85\n",
      "    positive       0.98      0.95      0.96       175\n",
      "\n",
      "    accuracy                           0.95       260\n",
      "   macro avg       0.94      0.95      0.94       260\n",
      "weighted avg       0.95      0.95      0.95       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9234\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.82      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.87      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.93      0.95      0.94       152\n",
      "    positive       0.84      0.81      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.86      0.84      0.85       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.78      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.92      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 117.5124340057373 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 30\n",
      "Sampling duration: 7.537431955337524 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5444, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4483, Accuracy: 0.8534, F1 Micro: 0.9146, F1 Macro: 0.914\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3333, Accuracy: 0.9286, F1 Micro: 0.9554, F1 Macro: 0.9524\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2393, Accuracy: 0.9442, F1 Micro: 0.9651, F1 Macro: 0.9626\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1839, Accuracy: 0.9583, F1 Micro: 0.974, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1453, Accuracy: 0.9606, F1 Micro: 0.9754, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1045, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0811, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9788\n",
      "Epoch 9/10, Train Loss: 0.0699, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9756\n",
      "Epoch 10/10, Train Loss: 0.0612, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9727\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9788\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.95      0.93       158\n",
      "        part       0.98      1.00      0.99       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5392, Accuracy: 0.8726, F1 Micro: 0.8726, F1 Macro: 0.856\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2869, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.8998\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1949, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9319\n",
      "Epoch 4/10, Train Loss: 0.1414, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9274\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.093, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9401\n",
      "Epoch 6/10, Train Loss: 0.1191, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.936\n",
      "Epoch 7/10, Train Loss: 0.0795, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9262\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0716, Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9426\n",
      "Epoch 9/10, Train Loss: 0.0411, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9144\n",
      "Epoch 10/10, Train Loss: 0.0507, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.93\n",
      "\n",
      "Sentiment analysis accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9426\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.91      0.92        85\n",
      "    positive       0.95      0.97      0.96       174\n",
      "\n",
      "    accuracy                           0.95       259\n",
      "   macro avg       0.95      0.94      0.94       259\n",
      "weighted avg       0.95      0.95      0.95       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9179\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.96      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.81      0.76      0.78        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.83      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.75      0.86        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.86      0.83      0.84        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.93      0.84      0.88       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.97      1.00      0.99       152\n",
      "    positive       1.00      0.83      0.91        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.94      0.94       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 116.71826887130737 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 27\n",
      "Sampling duration: 6.881983518600464 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5246, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4449, Accuracy: 0.8876, F1 Micro: 0.9324, F1 Macro: 0.9309\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3197, Accuracy: 0.9382, F1 Micro: 0.9615, F1 Macro: 0.9598\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2276, Accuracy: 0.9531, F1 Micro: 0.9709, F1 Macro: 0.9696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1684, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1191, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9765\n",
      "Epoch 7/10, Train Loss: 0.0953, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.078, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9793\n",
      "Epoch 9/10, Train Loss: 0.0656, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.055, Accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9802\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9802\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.96      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5491, Accuracy: 0.8833, F1 Micro: 0.8833, F1 Macro: 0.8682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2738, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9268\n",
      "Epoch 3/10, Train Loss: 0.1933, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9227\n",
      "Epoch 4/10, Train Loss: 0.145, Accuracy: 0.9183, F1 Micro: 0.9183, F1 Macro: 0.9117\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1188, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9319\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0767, Accuracy: 0.9416, F1 Micro: 0.9416, F1 Macro: 0.935\n",
      "Epoch 7/10, Train Loss: 0.08, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9268\n",
      "Epoch 8/10, Train Loss: 0.0588, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9279\n",
      "Epoch 9/10, Train Loss: 0.0424, Accuracy: 0.9066, F1 Micro: 0.9066, F1 Macro: 0.8918\n",
      "Epoch 10/10, Train Loss: 0.0488, Accuracy: 0.9027, F1 Micro: 0.9027, F1 Macro: 0.8891\n",
      "\n",
      "Sentiment analysis accuracy: 0.9416, F1 Micro: 0.9416, F1 Macro: 0.935\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.94      0.91        85\n",
      "    positive       0.97      0.94      0.96       172\n",
      "\n",
      "    accuracy                           0.94       257\n",
      "   macro avg       0.93      0.94      0.94       257\n",
      "weighted avg       0.94      0.94      0.94       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9172\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.96      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.88      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.93      0.96      0.94       152\n",
      "    positive       0.88      0.81      0.84        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.87      0.84      0.86       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.78      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.92      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 122.17464828491211 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 18\n",
      "Sampling duration: 6.264763355255127 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5273, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4231, Accuracy: 0.9018, F1 Micro: 0.9397, F1 Macro: 0.9374\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.291, Accuracy: 0.9368, F1 Micro: 0.9608, F1 Macro: 0.9583\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2224, Accuracy: 0.9539, F1 Micro: 0.9714, F1 Macro: 0.9701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1519, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9743\n",
      "Epoch 6/10, Train Loss: 0.1164, Accuracy: 0.9561, F1 Micro: 0.9725, F1 Macro: 0.9704\n",
      "Epoch 7/10, Train Loss: 0.0939, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0772, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0615, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.978\n",
      "Epoch 10/10, Train Loss: 0.0541, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9746\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.93      0.93      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5538, Accuracy: 0.7769, F1 Micro: 0.7769, F1 Macro: 0.6962\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2596, Accuracy: 0.8923, F1 Micro: 0.8923, F1 Macro: 0.8854\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1998, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9115\n",
      "Epoch 4/10, Train Loss: 0.1629, Accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.9123\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1493, Accuracy: 0.9538, F1 Micro: 0.9538, F1 Macro: 0.9479\n",
      "Epoch 6/10, Train Loss: 0.0825, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9364\n",
      "Epoch 7/10, Train Loss: 0.0922, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9368\n",
      "Epoch 8/10, Train Loss: 0.077, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9255\n",
      "Epoch 9/10, Train Loss: 0.0695, Accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9405\n",
      "Epoch 10/10, Train Loss: 0.0439, Accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9405\n",
      "\n",
      "Sentiment analysis accuracy: 0.9538, F1 Micro: 0.9538, F1 Macro: 0.9479\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        86\n",
      "    positive       0.97      0.97      0.97       174\n",
      "\n",
      "    accuracy                           0.95       260\n",
      "   macro avg       0.95      0.95      0.95       260\n",
      "weighted avg       0.95      0.95      0.95       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9248\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.93      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.81      0.83      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.88      0.86      0.87       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.83      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.95      0.94      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.93      0.89      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 124.32724404335022 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.852828741073608 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.523, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4158, Accuracy: 0.8966, F1 Micro: 0.9368, F1 Macro: 0.9348\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2851, Accuracy: 0.9412, F1 Micro: 0.9634, F1 Macro: 0.9619\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.202, Accuracy: 0.9531, F1 Micro: 0.9708, F1 Macro: 0.9695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1444, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1112, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0912, Accuracy: 0.9658, F1 Micro: 0.9783, F1 Macro: 0.9766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0719, Accuracy: 0.9695, F1 Micro: 0.9809, F1 Macro: 0.9798\n",
      "Epoch 9/10, Train Loss: 0.0554, Accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9783\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0531, Accuracy: 0.971, F1 Micro: 0.9818, F1 Macro: 0.9808\n",
      "\n",
      "Aspect detection accuracy: 0.971, F1 Micro: 0.9818, F1 Macro: 0.9808\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.97      0.97       175\n",
      "      others       0.93      0.97      0.95       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5688, Accuracy: 0.7846, F1 Micro: 0.7846, F1 Macro: 0.7334\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3485, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9207\n",
      "Epoch 3/10, Train Loss: 0.2362, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.8992\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1451, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.928\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1252, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.933\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1161, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9327\n",
      "Epoch 7/10, Train Loss: 0.1105, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.925\n",
      "Epoch 8/10, Train Loss: 0.0847, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9276\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.067, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9364\n",
      "Epoch 10/10, Train Loss: 0.0459, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9327\n",
      "\n",
      "Sentiment analysis accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9364\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.95      0.92        87\n",
      "    positive       0.98      0.94      0.96       173\n",
      "\n",
      "    accuracy                           0.94       260\n",
      "   macro avg       0.93      0.95      0.94       260\n",
      "weighted avg       0.94      0.94      0.94       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9226\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.97      0.96       167\n",
      "    positive       0.81      0.79      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.88      0.89       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.94      0.97      0.95       152\n",
      "    positive       0.88      0.81      0.84        52\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.91      0.87      0.89       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.76      0.86        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.92      0.90       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.86      0.71      0.77        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.85      0.87       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 132.68519830703735 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.254485607147217 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5261, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4287, Accuracy: 0.9025, F1 Micro: 0.9412, F1 Macro: 0.9394\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2903, Accuracy: 0.9435, F1 Micro: 0.9649, F1 Macro: 0.9633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2045, Accuracy: 0.9554, F1 Micro: 0.9722, F1 Macro: 0.9707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.157, Accuracy: 0.9568, F1 Micro: 0.9728, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1183, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0905, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0728, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0596, Accuracy: 0.9658, F1 Micro: 0.9783, F1 Macro: 0.9766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0571, Accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9781\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.91      0.95      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5461, Accuracy: 0.8863, F1 Micro: 0.8863, F1 Macro: 0.8732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2881, Accuracy: 0.902, F1 Micro: 0.902, F1 Macro: 0.8954\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1762, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9317\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1523, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9317\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1184, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9393\n",
      "Epoch 6/10, Train Loss: 0.0815, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9336\n",
      "Epoch 7/10, Train Loss: 0.1101, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9235\n",
      "Epoch 8/10, Train Loss: 0.0902, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9354\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0693, Accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.9435\n",
      "Epoch 10/10, Train Loss: 0.0465, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9393\n",
      "\n",
      "Sentiment analysis accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.9435\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.93        85\n",
      "    positive       0.98      0.95      0.96       170\n",
      "\n",
      "    accuracy                           0.95       255\n",
      "   macro avg       0.94      0.95      0.94       255\n",
      "weighted avg       0.95      0.95      0.95       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.923\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.85      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.75      0.86        12\n",
      "     neutral       0.92      0.95      0.93       152\n",
      "    positive       0.84      0.81      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.92      0.84      0.87       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.76      0.86        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.92      0.91       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.90      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 131.90086317062378 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.741512060165405 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5231, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4078, Accuracy: 0.9055, F1 Micro: 0.941, F1 Macro: 0.9379\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2715, Accuracy: 0.9501, F1 Micro: 0.9691, F1 Macro: 0.9677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1941, Accuracy: 0.9554, F1 Micro: 0.972, F1 Macro: 0.9703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1373, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1122, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9774\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0862, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9795\n",
      "Epoch 8/10, Train Loss: 0.0676, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.979\n",
      "Epoch 9/10, Train Loss: 0.0557, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "Epoch 10/10, Train Loss: 0.0489, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9778\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9795\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5492, Accuracy: 0.8973, F1 Micro: 0.8973, F1 Macro: 0.8869\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2809, Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9402\n",
      "Epoch 3/10, Train Loss: 0.1979, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9368\n",
      "Epoch 4/10, Train Loss: 0.1262, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9365\n",
      "Epoch 5/10, Train Loss: 0.1039, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9365\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1202, Accuracy: 0.9544, F1 Micro: 0.9544, F1 Macro: 0.9479\n",
      "Epoch 7/10, Train Loss: 0.1078, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9358\n",
      "Epoch 8/10, Train Loss: 0.0829, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9361\n",
      "Epoch 9/10, Train Loss: 0.0698, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9248\n",
      "Epoch 10/10, Train Loss: 0.0574, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.924\n",
      "\n",
      "Sentiment analysis accuracy: 0.9544, F1 Micro: 0.9544, F1 Macro: 0.9479\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.92      0.93        86\n",
      "    positive       0.96      0.97      0.97       177\n",
      "\n",
      "    accuracy                           0.95       263\n",
      "   macro avg       0.95      0.95      0.95       263\n",
      "weighted avg       0.95      0.95      0.95       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.963, F1 Micro: 0.963, F1 Macro: 0.9281\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.93      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.86      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.93      0.94      0.93       152\n",
      "    positive       0.84      0.81      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.87      0.86      0.86       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.96      0.94        23\n",
      "     neutral       0.98      0.99      0.99       152\n",
      "    positive       0.97      0.90      0.94        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.96      0.95      0.95       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.93      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 127.87556767463684 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.158890008926392 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5371, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4104, Accuracy: 0.9062, F1 Micro: 0.9416, F1 Macro: 0.9392\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.272, Accuracy: 0.9487, F1 Micro: 0.968, F1 Macro: 0.9662\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1819, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1306, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1038, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.977\n",
      "Epoch 7/10, Train Loss: 0.0835, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0681, Accuracy: 0.9702, F1 Micro: 0.9812, F1 Macro: 0.98\n",
      "Epoch 9/10, Train Loss: 0.0574, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.976\n",
      "Epoch 10/10, Train Loss: 0.0492, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9792\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9812, F1 Macro: 0.98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.94      0.94      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5459, Accuracy: 0.875, F1 Micro: 0.875, F1 Macro: 0.8564\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2373, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9233\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1902, Accuracy: 0.9508, F1 Micro: 0.9508, F1 Macro: 0.9434\n",
      "Epoch 4/10, Train Loss: 0.1728, Accuracy: 0.9432, F1 Micro: 0.9432, F1 Macro: 0.9359\n",
      "Epoch 5/10, Train Loss: 0.1154, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9293\n",
      "Epoch 6/10, Train Loss: 0.1037, Accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.941\n",
      "Epoch 7/10, Train Loss: 0.0754, Accuracy: 0.9242, F1 Micro: 0.9242, F1 Macro: 0.9174\n",
      "Epoch 8/10, Train Loss: 0.0833, Accuracy: 0.9432, F1 Micro: 0.9432, F1 Macro: 0.9373\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0537, Accuracy: 0.9508, F1 Micro: 0.9508, F1 Macro: 0.9451\n",
      "Epoch 10/10, Train Loss: 0.0323, Accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.9407\n",
      "\n",
      "Sentiment analysis accuracy: 0.9508, F1 Micro: 0.9508, F1 Macro: 0.9451\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.97      0.93        86\n",
      "    positive       0.98      0.94      0.96       178\n",
      "\n",
      "    accuracy                           0.95       264\n",
      "   macro avg       0.94      0.95      0.95       264\n",
      "weighted avg       0.95      0.95      0.95       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9622, F1 Micro: 0.9622, F1 Macro: 0.9257\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.99      0.97       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.88      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.94      0.94      0.94       152\n",
      "    positive       0.83      0.83      0.83        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.87      0.87      0.87       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.88      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 133.6877462863922 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 8\n",
      "Sampling duration: 3.5690059661865234 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5235, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4014, Accuracy: 0.9033, F1 Micro: 0.9393, F1 Macro: 0.9356\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2595, Accuracy: 0.9479, F1 Micro: 0.9677, F1 Macro: 0.9659\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1833, Accuracy: 0.9539, F1 Micro: 0.9712, F1 Macro: 0.9696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1361, Accuracy: 0.9621, F1 Micro: 0.9763, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1018, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0854, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0649, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0535, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9793\n",
      "Epoch 10/10, Train Loss: 0.0464, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9789\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5087, Accuracy: 0.9027, F1 Micro: 0.9027, F1 Macro: 0.8911\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2285, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9186\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1389, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9279\n",
      "Epoch 4/10, Train Loss: 0.1381, Accuracy: 0.9105, F1 Micro: 0.9105, F1 Macro: 0.9004\n",
      "Epoch 5/10, Train Loss: 0.1385, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9177\n",
      "Epoch 6/10, Train Loss: 0.1323, Accuracy: 0.9183, F1 Micro: 0.9183, F1 Macro: 0.9117\n",
      "Epoch 7/10, Train Loss: 0.0594, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9194\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.071, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9305\n",
      "Epoch 9/10, Train Loss: 0.0672, Accuracy: 0.9183, F1 Micro: 0.9183, F1 Macro: 0.9113\n",
      "Epoch 10/10, Train Loss: 0.0434, Accuracy: 0.9222, F1 Micro: 0.9222, F1 Macro: 0.9149\n",
      "\n",
      "Sentiment analysis accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9305\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.92      0.91        86\n",
      "    positive       0.96      0.95      0.95       171\n",
      "\n",
      "    accuracy                           0.94       257\n",
      "   macro avg       0.93      0.93      0.93       257\n",
      "weighted avg       0.94      0.94      0.94       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.9141\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.84      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.83      0.77      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.89      0.85      0.87       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.99      0.99       152\n",
      "    positive       1.00      0.85      0.92        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.95      0.94       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.86      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 135.79776120185852 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.377317190170288 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5086, Accuracy: 0.7946, F1 Micro: 0.8849, F1 Macro: 0.8834\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.385, Accuracy: 0.907, F1 Micro: 0.9411, F1 Macro: 0.9373\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2612, Accuracy: 0.9561, F1 Micro: 0.9727, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1767, Accuracy: 0.9583, F1 Micro: 0.974, F1 Macro: 0.9725\n",
      "Epoch 5/10, Train Loss: 0.1291, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0933, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0791, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9787\n",
      "Epoch 8/10, Train Loss: 0.0625, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9776\n",
      "Epoch 9/10, Train Loss: 0.0478, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9772\n",
      "Epoch 10/10, Train Loss: 0.0451, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9768\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9787\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.91      0.96      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5666, Accuracy: 0.8937, F1 Micro: 0.8937, F1 Macro: 0.8829\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2568, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9391\n",
      "Epoch 3/10, Train Loss: 0.2034, Accuracy: 0.9055, F1 Micro: 0.9055, F1 Macro: 0.889\n",
      "Epoch 4/10, Train Loss: 0.1703, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9356\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1438, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9398\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1161, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9366\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.098, Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9565\n",
      "Epoch 8/10, Train Loss: 0.0842, Accuracy: 0.9488, F1 Micro: 0.9488, F1 Macro: 0.943\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0427, Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9565\n",
      "Epoch 10/10, Train Loss: 0.0387, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9391\n",
      "\n",
      "Sentiment analysis accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94        85\n",
      "    positive       0.99      0.95      0.97       169\n",
      "\n",
      "    accuracy                           0.96       254\n",
      "   macro avg       0.95      0.96      0.96       254\n",
      "weighted avg       0.96      0.96      0.96       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9614, F1 Micro: 0.9614, F1 Macro: 0.9296\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.86      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.75      0.86        12\n",
      "     neutral       0.91      0.95      0.93       152\n",
      "    positive       0.85      0.79      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.92      0.83      0.87       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.80      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 136.58235716819763 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.8393912315368652 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5248, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3746, Accuracy: 0.9174, F1 Micro: 0.9483, F1 Macro: 0.9451\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2494, Accuracy: 0.9524, F1 Micro: 0.9703, F1 Macro: 0.969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.163, Accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9775\n",
      "Epoch 5/10, Train Loss: 0.1238, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0911, Accuracy: 0.971, F1 Micro: 0.9818, F1 Macro: 0.9809\n",
      "Epoch 7/10, Train Loss: 0.0727, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9754\n",
      "Epoch 8/10, Train Loss: 0.0617, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9776\n",
      "Epoch 9/10, Train Loss: 0.0516, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9793\n",
      "Epoch 10/10, Train Loss: 0.0441, Accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9804\n",
      "\n",
      "Aspect detection accuracy: 0.971, F1 Micro: 0.9818, F1 Macro: 0.9809\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.91      0.98      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5463, Accuracy: 0.892, F1 Micro: 0.892, F1 Macro: 0.8847\n",
      "Epoch 2/10, Train Loss: 0.2775, Accuracy: 0.88, F1 Micro: 0.88, F1 Macro: 0.8741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1595, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9226\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1412, Accuracy: 0.96, F1 Micro: 0.96, F1 Macro: 0.9559\n",
      "Epoch 5/10, Train Loss: 0.1177, Accuracy: 0.952, F1 Micro: 0.952, F1 Macro: 0.9477\n",
      "Epoch 6/10, Train Loss: 0.1125, Accuracy: 0.948, F1 Micro: 0.948, F1 Macro: 0.9429\n",
      "Epoch 7/10, Train Loss: 0.0905, Accuracy: 0.948, F1 Micro: 0.948, F1 Macro: 0.9429\n",
      "Epoch 8/10, Train Loss: 0.0699, Accuracy: 0.948, F1 Micro: 0.948, F1 Macro: 0.9434\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0517, Accuracy: 0.96, F1 Micro: 0.96, F1 Macro: 0.9557\n",
      "Epoch 10/10, Train Loss: 0.047, Accuracy: 0.912, F1 Micro: 0.912, F1 Macro: 0.9008\n",
      "\n",
      "Sentiment analysis accuracy: 0.96, F1 Micro: 0.96, F1 Macro: 0.9557\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.95      0.94        85\n",
      "    positive       0.98      0.96      0.97       165\n",
      "\n",
      "    accuracy                           0.96       250\n",
      "   macro avg       0.95      0.96      0.96       250\n",
      "weighted avg       0.96      0.96      0.96       250\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9645, F1 Micro: 0.9645, F1 Macro: 0.9308\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.96      0.99      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.86      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.91      0.98      0.94       152\n",
      "    positive       0.93      0.75      0.83        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.91      0.83      0.86       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.85      0.92        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.95      0.95       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 132.90256023406982 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.3448054790496826 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5167, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3864, Accuracy: 0.9167, F1 Micro: 0.9476, F1 Macro: 0.945\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2533, Accuracy: 0.9583, F1 Micro: 0.9741, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1816, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.124, Accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9776\n",
      "Epoch 6/10, Train Loss: 0.0938, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9759\n",
      "Epoch 7/10, Train Loss: 0.0731, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9757\n",
      "Epoch 8/10, Train Loss: 0.068, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0549, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9776\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0455, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.978\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.97      0.97       175\n",
      "      others       0.91      0.94      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4931, Accuracy: 0.8981, F1 Micro: 0.8981, F1 Macro: 0.8873\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2455, Accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.9405\n",
      "Epoch 3/10, Train Loss: 0.156, Accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.9356\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1133, Accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.9411\n",
      "Epoch 5/10, Train Loss: 0.1152, Accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.9371\n",
      "Epoch 6/10, Train Loss: 0.0905, Accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.9367\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0771, Accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.9408\n",
      "Epoch 8/10, Train Loss: 0.0538, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9331\n",
      "Epoch 9/10, Train Loss: 0.0684, Accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.9367\n",
      "Epoch 10/10, Train Loss: 0.0511, Accuracy: 0.9358, F1 Micro: 0.9358, F1 Macro: 0.9287\n",
      "\n",
      "Sentiment analysis accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.9408\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        85\n",
      "    positive       0.98      0.94      0.96       180\n",
      "\n",
      "    accuracy                           0.95       265\n",
      "   macro avg       0.93      0.95      0.94       265\n",
      "weighted avg       0.95      0.95      0.95       265\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.922\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.97      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.96      0.97      0.97       167\n",
      "    positive       0.81      0.79      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.86      0.86      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.92      0.94      0.93       152\n",
      "    positive       0.84      0.79      0.81        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.86      0.83      0.84       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.95      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 140.525630235672 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.7756211757659912 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.516, Accuracy: 0.7999, F1 Micro: 0.8875, F1 Macro: 0.886\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3687, Accuracy: 0.9382, F1 Micro: 0.9615, F1 Macro: 0.9599\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2408, Accuracy: 0.9546, F1 Micro: 0.9718, F1 Macro: 0.9703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1599, Accuracy: 0.965, F1 Micro: 0.9783, F1 Macro: 0.9775\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1154, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9794\n",
      "Epoch 6/10, Train Loss: 0.09, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9789\n",
      "Epoch 7/10, Train Loss: 0.0757, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9759\n",
      "Epoch 8/10, Train Loss: 0.0611, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.979\n",
      "Epoch 9/10, Train Loss: 0.048, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9779\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0452, Accuracy: 0.9717, F1 Micro: 0.9823, F1 Macro: 0.9812\n",
      "\n",
      "Aspect detection accuracy: 0.9717, F1 Micro: 0.9823, F1 Macro: 0.9812\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.97      0.95       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4734, Accuracy: 0.9137, F1 Micro: 0.9137, F1 Macro: 0.9056\n",
      "Epoch 2/10, Train Loss: 0.2388, Accuracy: 0.898, F1 Micro: 0.898, F1 Macro: 0.8923\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1748, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9351\n",
      "Epoch 4/10, Train Loss: 0.1283, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9191\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1079, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9382\n",
      "Epoch 6/10, Train Loss: 0.1059, Accuracy: 0.9059, F1 Micro: 0.9059, F1 Macro: 0.8998\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0995, Accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.9438\n",
      "Epoch 8/10, Train Loss: 0.0725, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9399\n",
      "Epoch 9/10, Train Loss: 0.0659, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9358\n",
      "Epoch 10/10, Train Loss: 0.0515, Accuracy: 0.9255, F1 Micro: 0.9255, F1 Macro: 0.9174\n",
      "\n",
      "Sentiment analysis accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.9438\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.94      0.93        87\n",
      "    positive       0.97      0.95      0.96       168\n",
      "\n",
      "    accuracy                           0.95       255\n",
      "   macro avg       0.94      0.95      0.94       255\n",
      "weighted avg       0.95      0.95      0.95       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9637, F1 Micro: 0.9637, F1 Macro: 0.9286\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.88      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.93      0.97      0.95       152\n",
      "    positive       0.89      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.88      0.86      0.87       216\n",
      "weighted avg       0.92      0.92      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.96      0.99      0.98       152\n",
      "    positive       1.00      0.80      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 142.68799591064453 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 8\n",
      "Sampling duration: 1.016906499862671 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5222, Accuracy: 0.8013, F1 Micro: 0.8882, F1 Macro: 0.8868\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3587, Accuracy: 0.9397, F1 Micro: 0.9625, F1 Macro: 0.9608\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2236, Accuracy: 0.9554, F1 Micro: 0.9724, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1529, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1244, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.976\n",
      "Epoch 6/10, Train Loss: 0.0909, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0693, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9766\n",
      "Epoch 8/10, Train Loss: 0.0613, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0534, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9788\n",
      "Epoch 10/10, Train Loss: 0.0433, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.976\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9788\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.94      0.93      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4651, Accuracy: 0.9321, F1 Micro: 0.9321, F1 Macro: 0.9251\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2171, Accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.9377\n",
      "Epoch 3/10, Train Loss: 0.1537, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.9219\n",
      "Epoch 4/10, Train Loss: 0.1357, Accuracy: 0.9321, F1 Micro: 0.9321, F1 Macro: 0.9255\n",
      "Epoch 5/10, Train Loss: 0.1146, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9323\n",
      "Epoch 6/10, Train Loss: 0.1073, Accuracy: 0.9245, F1 Micro: 0.9245, F1 Macro: 0.9163\n",
      "Epoch 7/10, Train Loss: 0.0827, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9334\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0853, Accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.9364\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0689, Accuracy: 0.9623, F1 Micro: 0.9623, F1 Macro: 0.9572\n",
      "Epoch 10/10, Train Loss: 0.0527, Accuracy: 0.8943, F1 Micro: 0.8943, F1 Macro: 0.8851\n",
      "\n",
      "Sentiment analysis accuracy: 0.9623, F1 Micro: 0.9623, F1 Macro: 0.9572\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        87\n",
      "    positive       0.97      0.97      0.97       178\n",
      "\n",
      "    accuracy                           0.96       265\n",
      "   macro avg       0.96      0.96      0.96       265\n",
      "weighted avg       0.96      0.96      0.96       265\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9622, F1 Micro: 0.9622, F1 Macro: 0.9344\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.81      0.79      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.86      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.83      0.91        12\n",
      "     neutral       0.94      0.93      0.93       152\n",
      "    positive       0.79      0.85      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.91      0.87      0.89       216\n",
      "weighted avg       0.91      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.83      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.95      0.94      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 142.22838973999023 s\n",
      "Total runtime: 3173.0837321281433 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "initial_train_size = int(0.01 * total_data)\n",
    "active_learning(81, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e12d41f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T05:25:04.732554Z",
     "iopub.status.busy": "2025-05-19T05:25:04.732246Z",
     "iopub.status.idle": "2025-05-19T06:14:46.722121Z",
     "shell.execute_reply": "2025-05-19T06:14:46.721379Z"
    },
    "papermill": {
     "duration": 2982.138918,
     "end_time": "2025-05-19T06:14:46.723489",
     "exception": false,
     "start_time": "2025-05-19T05:25:04.584571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "Init Size 10\n",
      "Random seed: 81\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6328, Accuracy: 0.7493, F1 Micro: 0.85, F1 Macro: 0.8204\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5334, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4951, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4625, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 5/10, Train Loss: 0.4453, Accuracy: 0.7894, F1 Micro: 0.8822, F1 Macro: 0.8807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4135, Accuracy: 0.7999, F1 Micro: 0.8872, F1 Macro: 0.8857\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3939, Accuracy: 0.8177, F1 Micro: 0.8959, F1 Macro: 0.8944\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3601, Accuracy: 0.846, F1 Micro: 0.91, F1 Macro: 0.9084\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3088, Accuracy: 0.872, F1 Micro: 0.9234, F1 Macro: 0.9213\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2824, Accuracy: 0.8772, F1 Micro: 0.9256, F1 Macro: 0.9223\n",
      "\n",
      "Aspect detection accuracy: 0.8772, F1 Micro: 0.9256, F1 Macro: 0.9223\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.87      1.00      0.93       187\n",
      "     machine       0.90      0.98      0.94       175\n",
      "      others       0.86      0.84      0.85       158\n",
      "        part       0.79      0.99      0.88       158\n",
      "       price       0.95      0.99      0.97       192\n",
      "     service       0.94      0.99      0.96       191\n",
      "\n",
      "   micro avg       0.89      0.97      0.93      1061\n",
      "   macro avg       0.89      0.96      0.92      1061\n",
      "weighted avg       0.89      0.97      0.93      1061\n",
      " samples avg       0.89      0.97      0.92      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.647, Accuracy: 0.743, F1 Micro: 0.743, F1 Macro: 0.4466\n",
      "Epoch 2/10, Train Loss: 0.5679, Accuracy: 0.7374, F1 Micro: 0.7374, F1 Macro: 0.4244\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5035, Accuracy: 0.743, F1 Micro: 0.743, F1 Macro: 0.4466\n",
      "Epoch 4/10, Train Loss: 0.4771, Accuracy: 0.7318, F1 Micro: 0.7318, F1 Macro: 0.5318\n",
      "Epoch 5/10, Train Loss: 0.4109, Accuracy: 0.7263, F1 Micro: 0.7263, F1 Macro: 0.622\n",
      "Epoch 6/10, Train Loss: 0.3137, Accuracy: 0.7263, F1 Micro: 0.7263, F1 Macro: 0.6489\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.267, Accuracy: 0.743, F1 Micro: 0.743, F1 Macro: 0.704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1947, Accuracy: 0.7821, F1 Micro: 0.7821, F1 Macro: 0.7454\n",
      "Epoch 9/10, Train Loss: 0.1264, Accuracy: 0.7765, F1 Micro: 0.7765, F1 Macro: 0.7258\n",
      "Epoch 10/10, Train Loss: 0.0975, Accuracy: 0.7542, F1 Micro: 0.7542, F1 Macro: 0.7018\n",
      "\n",
      "Sentiment analysis accuracy: 0.7821, F1 Micro: 0.7821, F1 Macro: 0.7454\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.56      0.77      0.65        47\n",
      "    positive       0.90      0.79      0.84       132\n",
      "\n",
      "    accuracy                           0.78       179\n",
      "   macro avg       0.73      0.78      0.75       179\n",
      "weighted avg       0.81      0.78      0.79       179\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 108: Accuracy: 0.8565, F1 Micro: 0.8565, F1 Macro: 0.6623\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.27      0.43        11\n",
      "     neutral       0.88      1.00      0.94       181\n",
      "    positive       1.00      0.29      0.45        24\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.96      0.52      0.61       216\n",
      "weighted avg       0.90      0.88      0.86       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.56      0.72        16\n",
      "     neutral       0.90      0.98      0.93       167\n",
      "    positive       0.76      0.58      0.66        33\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.89      0.70      0.77       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.21      0.58      0.31        12\n",
      "     neutral       0.86      0.84      0.85       152\n",
      "    positive       0.63      0.42      0.51        52\n",
      "\n",
      "    accuracy                           0.72       216\n",
      "   macro avg       0.57      0.61      0.55       216\n",
      "weighted avg       0.77      0.72      0.73       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.09      0.15        23\n",
      "     neutral       0.79      0.99      0.88       152\n",
      "    positive       0.78      0.44      0.56        41\n",
      "\n",
      "    accuracy                           0.79       216\n",
      "   macro avg       0.75      0.50      0.53       216\n",
      "weighted avg       0.78      0.79      0.74       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.46      0.63        13\n",
      "     neutral       0.95      0.99      0.97       186\n",
      "    positive       0.62      0.59      0.61        17\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.86      0.68      0.74       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.64      0.75        14\n",
      "     neutral       0.93      0.99      0.96       185\n",
      "    positive       0.89      0.47      0.62        17\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.91      0.70      0.78       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Total train time: 62.44337034225464 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 76\n",
      "Sampling duration: 15.59114122390747 seconds\n",
      "New train size: 184\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6122, Accuracy: 0.7924, F1 Micro: 0.8834, F1 Macro: 0.8817\n",
      "Epoch 2/10, Train Loss: 0.5142, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 3/10, Train Loss: 0.4935, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 4/10, Train Loss: 0.4374, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4339, Accuracy: 0.8266, F1 Micro: 0.9005, F1 Macro: 0.8991\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3763, Accuracy: 0.8631, F1 Micro: 0.9193, F1 Macro: 0.9178\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3262, Accuracy: 0.9018, F1 Micro: 0.9399, F1 Macro: 0.9381\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2714, Accuracy: 0.9182, F1 Micro: 0.9496, F1 Macro: 0.9475\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.238, Accuracy: 0.9263, F1 Micro: 0.9544, F1 Macro: 0.952\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1996, Accuracy: 0.9338, F1 Micro: 0.9588, F1 Macro: 0.9563\n",
      "\n",
      "Aspect detection accuracy: 0.9338, F1 Micro: 0.9588, F1 Macro: 0.9563\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.97      1.00      0.99       187\n",
      "     machine       0.94      0.97      0.96       175\n",
      "      others       0.89      0.89      0.89       158\n",
      "        part       0.92      0.97      0.94       158\n",
      "       price       0.96      1.00      0.98       192\n",
      "     service       0.96      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.94      0.98      0.96      1061\n",
      "   macro avg       0.94      0.97      0.96      1061\n",
      "weighted avg       0.94      0.98      0.96      1061\n",
      " samples avg       0.94      0.98      0.95      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6232, Accuracy: 0.6835, F1 Micro: 0.6835, F1 Macro: 0.406\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.54, Accuracy: 0.6835, F1 Micro: 0.6835, F1 Macro: 0.406\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4291, Accuracy: 0.7046, F1 Micro: 0.7046, F1 Macro: 0.5356\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3679, Accuracy: 0.8397, F1 Micro: 0.8397, F1 Macro: 0.8207\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2355, Accuracy: 0.8776, F1 Micro: 0.8776, F1 Macro: 0.8601\n",
      "Epoch 6/10, Train Loss: 0.143, Accuracy: 0.8734, F1 Micro: 0.8734, F1 Macro: 0.8585\n",
      "Epoch 7/10, Train Loss: 0.0743, Accuracy: 0.865, F1 Micro: 0.865, F1 Macro: 0.8461\n",
      "Epoch 8/10, Train Loss: 0.0752, Accuracy: 0.8734, F1 Micro: 0.8734, F1 Macro: 0.8557\n",
      "Epoch 9/10, Train Loss: 0.0612, Accuracy: 0.865, F1 Micro: 0.865, F1 Macro: 0.8461\n",
      "Epoch 10/10, Train Loss: 0.0426, Accuracy: 0.8523, F1 Micro: 0.8523, F1 Macro: 0.8344\n",
      "\n",
      "Sentiment analysis accuracy: 0.8776, F1 Micro: 0.8776, F1 Macro: 0.8601\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.83      0.81        75\n",
      "    positive       0.92      0.90      0.91       162\n",
      "\n",
      "    accuracy                           0.88       237\n",
      "   macro avg       0.86      0.86      0.86       237\n",
      "weighted avg       0.88      0.88      0.88       237\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 184: Accuracy: 0.9174, F1 Micro: 0.9174, F1 Macro: 0.8263\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       1.00      0.88      0.93        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.99      0.93      0.96       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.69      0.79        16\n",
      "     neutral       0.94      0.97      0.95       167\n",
      "    positive       0.77      0.73      0.75        33\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.88      0.79      0.83       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.43      0.75      0.55        12\n",
      "     neutral       0.88      0.89      0.89       152\n",
      "    positive       0.76      0.60      0.67        52\n",
      "\n",
      "    accuracy                           0.81       216\n",
      "   macro avg       0.69      0.75      0.70       216\n",
      "weighted avg       0.83      0.81      0.82       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.65      0.73        23\n",
      "     neutral       0.91      0.97      0.94       152\n",
      "    positive       0.81      0.71      0.75        41\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.85      0.78      0.81       216\n",
      "weighted avg       0.88      0.89      0.88       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.46      0.63        13\n",
      "     neutral       0.96      1.00      0.98       186\n",
      "    positive       0.71      0.71      0.71        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.72      0.77       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.96      1.00      0.98       185\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.96      0.83      0.89       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Total train time: 71.02266597747803 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 68\n",
      "Sampling duration: 15.493294954299927 seconds\n",
      "New train size: 252\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5956, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.491, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4833, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4403, Accuracy: 0.8192, F1 Micro: 0.8971, F1 Macro: 0.8958\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3853, Accuracy: 0.8795, F1 Micro: 0.9279, F1 Macro: 0.9262\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3182, Accuracy: 0.9115, F1 Micro: 0.9451, F1 Macro: 0.9429\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2557, Accuracy: 0.9286, F1 Micro: 0.9557, F1 Macro: 0.9536\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2174, Accuracy: 0.936, F1 Micro: 0.9602, F1 Macro: 0.9578\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1651, Accuracy: 0.9427, F1 Micro: 0.9642, F1 Macro: 0.9621\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1606, Accuracy: 0.9479, F1 Micro: 0.9675, F1 Macro: 0.9654\n",
      "\n",
      "Aspect detection accuracy: 0.9479, F1 Micro: 0.9675, F1 Macro: 0.9654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.97      1.00      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.89      0.93      0.91       158\n",
      "        part       0.93      0.97      0.95       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.95      0.98      0.97      1061\n",
      "   macro avg       0.95      0.98      0.97      1061\n",
      "weighted avg       0.95      0.98      0.97      1061\n",
      " samples avg       0.95      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6522, Accuracy: 0.6694, F1 Micro: 0.6694, F1 Macro: 0.401\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5648, Accuracy: 0.6694, F1 Micro: 0.6694, F1 Macro: 0.401\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.421, Accuracy: 0.8802, F1 Micro: 0.8802, F1 Macro: 0.8659\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.244, Accuracy: 0.8884, F1 Micro: 0.8884, F1 Macro: 0.8766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1631, Accuracy: 0.8926, F1 Micro: 0.8926, F1 Macro: 0.8762\n",
      "Epoch 6/10, Train Loss: 0.0929, Accuracy: 0.8884, F1 Micro: 0.8884, F1 Macro: 0.8803\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1176, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8966\n",
      "Epoch 8/10, Train Loss: 0.0696, Accuracy: 0.9008, F1 Micro: 0.9008, F1 Macro: 0.8906\n",
      "Epoch 9/10, Train Loss: 0.0933, Accuracy: 0.9008, F1 Micro: 0.9008, F1 Macro: 0.89\n",
      "Epoch 10/10, Train Loss: 0.0704, Accuracy: 0.8884, F1 Micro: 0.8884, F1 Macro: 0.8798\n",
      "\n",
      "Sentiment analysis accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8966\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.85      0.86        80\n",
      "    positive       0.93      0.94      0.93       162\n",
      "\n",
      "    accuracy                           0.91       242\n",
      "   macro avg       0.90      0.89      0.90       242\n",
      "weighted avg       0.91      0.91      0.91       242\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 252: Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.873\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       1.00      0.88      0.93        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.99      0.93      0.96       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.84      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.75      0.72        12\n",
      "     neutral       0.89      0.93      0.91       152\n",
      "    positive       0.84      0.69      0.76        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.81      0.79      0.80       216\n",
      "weighted avg       0.86      0.87      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.78      0.78        23\n",
      "     neutral       0.92      0.97      0.95       152\n",
      "    positive       0.88      0.73      0.80        41\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.86      0.83      0.84       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.69      0.82        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.84      0.87       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.71      0.83        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.87      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 88.08222079277039 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 62\n",
      "Sampling duration: 14.144376039505005 seconds\n",
      "New train size: 314\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5768, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4871, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4599, Accuracy: 0.8103, F1 Micro: 0.8927, F1 Macro: 0.8913\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.384, Accuracy: 0.8921, F1 Micro: 0.935, F1 Macro: 0.9335\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.316, Accuracy: 0.9152, F1 Micro: 0.9477, F1 Macro: 0.9451\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2468, Accuracy: 0.9293, F1 Micro: 0.9558, F1 Macro: 0.9527\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1876, Accuracy: 0.9368, F1 Micro: 0.9603, F1 Macro: 0.9575\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1672, Accuracy: 0.9479, F1 Micro: 0.9675, F1 Macro: 0.9656\n",
      "Epoch 9/10, Train Loss: 0.1414, Accuracy: 0.9479, F1 Micro: 0.9673, F1 Macro: 0.9645\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1035, Accuracy: 0.9494, F1 Micro: 0.9682, F1 Macro: 0.9655\n",
      "\n",
      "Aspect detection accuracy: 0.9494, F1 Micro: 0.9682, F1 Macro: 0.9655\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.92      0.87      0.90       158\n",
      "        part       0.93      0.98      0.95       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.97      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.97      0.97      1061\n",
      "   macro avg       0.96      0.97      0.97      1061\n",
      "weighted avg       0.96      0.97      0.97      1061\n",
      " samples avg       0.96      0.97      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5798, Accuracy: 0.6858, F1 Micro: 0.6858, F1 Macro: 0.4068\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4985, Accuracy: 0.8736, F1 Micro: 0.8736, F1 Macro: 0.8547\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3055, Accuracy: 0.9119, F1 Micro: 0.9119, F1 Macro: 0.9\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1534, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9105\n",
      "Epoch 5/10, Train Loss: 0.158, Accuracy: 0.9042, F1 Micro: 0.9042, F1 Macro: 0.8943\n",
      "Epoch 6/10, Train Loss: 0.149, Accuracy: 0.8659, F1 Micro: 0.8659, F1 Macro: 0.8561\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1268, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9092\n",
      "Epoch 8/10, Train Loss: 0.1217, Accuracy: 0.9004, F1 Micro: 0.9004, F1 Macro: 0.8898\n",
      "Epoch 9/10, Train Loss: 0.1265, Accuracy: 0.9195, F1 Micro: 0.9195, F1 Macro: 0.9092\n",
      "Epoch 10/10, Train Loss: 0.0886, Accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.9046\n",
      "\n",
      "Sentiment analysis accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9092\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.84      0.87        82\n",
      "    positive       0.93      0.96      0.95       179\n",
      "\n",
      "    accuracy                           0.92       261\n",
      "   macro avg       0.92      0.90      0.91       261\n",
      "weighted avg       0.92      0.92      0.92       261\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 314: Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.8768\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.79      0.82      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.85      0.87       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.92      0.87      0.89       152\n",
      "    positive       0.70      0.83      0.76        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.79      0.82      0.80       216\n",
      "weighted avg       0.86      0.85      0.85       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.83      0.84        23\n",
      "     neutral       0.93      0.98      0.95       152\n",
      "    positive       0.91      0.73      0.81        41\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.90      0.85      0.87       216\n",
      "weighted avg       0.92      0.92      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.86      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.71      0.83        14\n",
      "     neutral       0.97      1.00      0.99       185\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.85      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 88.32059597969055 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 55\n",
      "Sampling duration: 12.993748903274536 seconds\n",
      "New train size: 369\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5554, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4647, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4283, Accuracy: 0.8609, F1 Micro: 0.9185, F1 Macro: 0.9174\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3162, Accuracy: 0.9204, F1 Micro: 0.9508, F1 Macro: 0.9485\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2542, Accuracy: 0.9368, F1 Micro: 0.9606, F1 Macro: 0.9584\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1918, Accuracy: 0.9435, F1 Micro: 0.9646, F1 Macro: 0.9621\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1598, Accuracy: 0.9524, F1 Micro: 0.9702, F1 Macro: 0.9684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.123, Accuracy: 0.9539, F1 Micro: 0.971, F1 Macro: 0.9687\n",
      "Epoch 9/10, Train Loss: 0.1017, Accuracy: 0.9516, F1 Micro: 0.9696, F1 Macro: 0.967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0844, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9737\n",
      "\n",
      "Aspect detection accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9737\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.91      0.94      0.92       158\n",
      "        part       0.96      0.99      0.97       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6017, Accuracy: 0.6798, F1 Micro: 0.6798, F1 Macro: 0.4047\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4464, Accuracy: 0.8775, F1 Micro: 0.8775, F1 Macro: 0.8667\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.307, Accuracy: 0.9249, F1 Micro: 0.9249, F1 Macro: 0.9166\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1389, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9334\n",
      "Epoch 5/10, Train Loss: 0.203, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.924\n",
      "Epoch 6/10, Train Loss: 0.0937, Accuracy: 0.9209, F1 Micro: 0.9209, F1 Macro: 0.9119\n",
      "Epoch 7/10, Train Loss: 0.118, Accuracy: 0.9249, F1 Micro: 0.9249, F1 Macro: 0.911\n",
      "Epoch 8/10, Train Loss: 0.0431, Accuracy: 0.9289, F1 Micro: 0.9289, F1 Macro: 0.9188\n",
      "Epoch 9/10, Train Loss: 0.0662, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9245\n",
      "Epoch 10/10, Train Loss: 0.0481, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8959\n",
      "\n",
      "Sentiment analysis accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.95      0.91        81\n",
      "    positive       0.98      0.94      0.96       172\n",
      "\n",
      "    accuracy                           0.94       253\n",
      "   macro avg       0.93      0.94      0.93       253\n",
      "weighted avg       0.94      0.94      0.94       253\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 369: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9079\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.82      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.75      0.72        12\n",
      "     neutral       0.92      0.94      0.93       152\n",
      "    positive       0.83      0.75      0.79        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.81      0.81      0.81       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.91      0.84        23\n",
      "     neutral       0.96      0.99      0.97       152\n",
      "    positive       0.97      0.76      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.89      0.89       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.71      0.83        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.89      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 95.32700109481812 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 50\n",
      "Sampling duration: 11.851115226745605 seconds\n",
      "New train size: 419\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5559, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4629, Accuracy: 0.7991, F1 Micro: 0.8871, F1 Macro: 0.8856\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3982, Accuracy: 0.8876, F1 Micro: 0.9324, F1 Macro: 0.9314\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3117, Accuracy: 0.936, F1 Micro: 0.9603, F1 Macro: 0.9583\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2266, Accuracy: 0.9397, F1 Micro: 0.9627, F1 Macro: 0.9611\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1823, Accuracy: 0.9539, F1 Micro: 0.9712, F1 Macro: 0.9695\n",
      "Epoch 7/10, Train Loss: 0.1365, Accuracy: 0.9531, F1 Micro: 0.9707, F1 Macro: 0.9692\n",
      "Epoch 8/10, Train Loss: 0.108, Accuracy: 0.9539, F1 Micro: 0.9711, F1 Macro: 0.9695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0955, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0759, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9711\n",
      "\n",
      "Aspect detection accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9711\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.90      0.89      0.90       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5774, Accuracy: 0.6943, F1 Micro: 0.6943, F1 Macro: 0.4325\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3694, Accuracy: 0.8981, F1 Micro: 0.8981, F1 Macro: 0.8855\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2291, Accuracy: 0.9358, F1 Micro: 0.9358, F1 Macro: 0.9271\n",
      "Epoch 4/10, Train Loss: 0.161, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.9194\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1052, Accuracy: 0.9358, F1 Micro: 0.9358, F1 Macro: 0.9266\n",
      "Epoch 6/10, Train Loss: 0.1191, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.919\n",
      "Epoch 7/10, Train Loss: 0.0713, Accuracy: 0.9321, F1 Micro: 0.9321, F1 Macro: 0.923\n",
      "Epoch 8/10, Train Loss: 0.0843, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.9185\n",
      "Epoch 9/10, Train Loss: 0.0346, Accuracy: 0.9208, F1 Micro: 0.9208, F1 Macro: 0.9104\n",
      "Epoch 10/10, Train Loss: 0.0406, Accuracy: 0.8868, F1 Micro: 0.8868, F1 Macro: 0.8657\n",
      "\n",
      "Sentiment analysis accuracy: 0.9358, F1 Micro: 0.9358, F1 Macro: 0.9266\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.94      0.90        82\n",
      "    positive       0.97      0.93      0.95       183\n",
      "\n",
      "    accuracy                           0.94       265\n",
      "   macro avg       0.92      0.94      0.93       265\n",
      "weighted avg       0.94      0.94      0.94       265\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 419: Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9031\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.97      0.98      0.97       167\n",
      "    positive       0.82      0.85      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.88      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.75      0.69        12\n",
      "     neutral       0.91      0.89      0.90       152\n",
      "    positive       0.75      0.75      0.75        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.77      0.80      0.78       216\n",
      "weighted avg       0.85      0.85      0.85       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       1.00      0.85      0.92        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.89      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.71      0.83        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.89      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 98.42071676254272 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 45\n",
      "Sampling duration: 10.99336051940918 seconds\n",
      "New train size: 464\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5526, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4685, Accuracy: 0.808, F1 Micro: 0.8916, F1 Macro: 0.8902\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.379, Accuracy: 0.9033, F1 Micro: 0.9412, F1 Macro: 0.94\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2822, Accuracy: 0.9435, F1 Micro: 0.9648, F1 Macro: 0.963\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2096, Accuracy: 0.9479, F1 Micro: 0.9674, F1 Macro: 0.9654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1687, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9714\n",
      "Epoch 7/10, Train Loss: 0.1271, Accuracy: 0.9509, F1 Micro: 0.9691, F1 Macro: 0.9665\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.11, Accuracy: 0.9606, F1 Micro: 0.9754, F1 Macro: 0.9741\n",
      "Epoch 9/10, Train Loss: 0.0891, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9738\n",
      "Epoch 10/10, Train Loss: 0.0744, Accuracy: 0.9524, F1 Micro: 0.97, F1 Macro: 0.9674\n",
      "\n",
      "Aspect detection accuracy: 0.9606, F1 Micro: 0.9754, F1 Macro: 0.9741\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.91      0.96      0.93       158\n",
      "        part       0.96      0.99      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.97      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.97      1061\n",
      "weighted avg       0.96      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5672, Accuracy: 0.6829, F1 Micro: 0.6829, F1 Macro: 0.4058\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3856, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9134\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1777, Accuracy: 0.9268, F1 Micro: 0.9268, F1 Macro: 0.9187\n",
      "Epoch 4/10, Train Loss: 0.1221, Accuracy: 0.9146, F1 Micro: 0.9146, F1 Macro: 0.9054\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1168, Accuracy: 0.9268, F1 Micro: 0.9268, F1 Macro: 0.9177\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1435, Accuracy: 0.9309, F1 Micro: 0.9309, F1 Macro: 0.9229\n",
      "Epoch 7/10, Train Loss: 0.0819, Accuracy: 0.9146, F1 Micro: 0.9146, F1 Macro: 0.9064\n",
      "Epoch 8/10, Train Loss: 0.072, Accuracy: 0.9187, F1 Micro: 0.9187, F1 Macro: 0.9106\n",
      "Epoch 9/10, Train Loss: 0.0658, Accuracy: 0.8984, F1 Micro: 0.8984, F1 Macro: 0.8778\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0507, Accuracy: 0.935, F1 Micro: 0.935, F1 Macro: 0.9277\n",
      "\n",
      "Sentiment analysis accuracy: 0.935, F1 Micro: 0.935, F1 Macro: 0.9277\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.97      0.90        78\n",
      "    positive       0.99      0.92      0.95       168\n",
      "\n",
      "    accuracy                           0.93       246\n",
      "   macro avg       0.92      0.95      0.93       246\n",
      "weighted avg       0.94      0.93      0.94       246\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 464: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.8997\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.97      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.81      0.90        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.95      0.86      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.75      0.69        12\n",
      "     neutral       0.91      0.95      0.93       152\n",
      "    positive       0.91      0.75      0.82        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.82      0.82      0.82       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.91      0.84        23\n",
      "     neutral       0.96      0.99      0.97       152\n",
      "    positive       1.00      0.78      0.88        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.71      0.83        14\n",
      "     neutral       0.97      1.00      0.98       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.99      0.87      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 102.31306576728821 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 40\n",
      "Sampling duration: 9.906551837921143 seconds\n",
      "New train size: 504\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.544, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4679, Accuracy: 0.8244, F1 Micro: 0.8998, F1 Macro: 0.8988\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3705, Accuracy: 0.9196, F1 Micro: 0.9502, F1 Macro: 0.9478\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2681, Accuracy: 0.9464, F1 Micro: 0.9666, F1 Macro: 0.9651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2013, Accuracy: 0.9539, F1 Micro: 0.9712, F1 Macro: 0.9698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1531, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9712\n",
      "Epoch 7/10, Train Loss: 0.1296, Accuracy: 0.9554, F1 Micro: 0.9719, F1 Macro: 0.9698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1061, Accuracy: 0.9628, F1 Micro: 0.9768, F1 Macro: 0.9756\n",
      "Epoch 9/10, Train Loss: 0.0874, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9754\n",
      "Epoch 10/10, Train Loss: 0.0715, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9752\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9768, F1 Macro: 0.9756\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.89      0.97      0.93       158\n",
      "        part       0.96      0.99      0.97       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.98      1061\n",
      "weighted avg       0.96      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6023, Accuracy: 0.6639, F1 Micro: 0.6639, F1 Macro: 0.399\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4177, Accuracy: 0.9303, F1 Micro: 0.9303, F1 Macro: 0.9239\n",
      "Epoch 3/10, Train Loss: 0.1735, Accuracy: 0.9221, F1 Micro: 0.9221, F1 Macro: 0.9096\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1639, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9261\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1158, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9278\n",
      "Epoch 6/10, Train Loss: 0.0537, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.8949\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0808, Accuracy: 0.9467, F1 Micro: 0.9467, F1 Macro: 0.9405\n",
      "Epoch 8/10, Train Loss: 0.0822, Accuracy: 0.9262, F1 Micro: 0.9262, F1 Macro: 0.9152\n",
      "Epoch 9/10, Train Loss: 0.0543, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9261\n",
      "Epoch 10/10, Train Loss: 0.0613, Accuracy: 0.9426, F1 Micro: 0.9426, F1 Macro: 0.9372\n",
      "\n",
      "Sentiment analysis accuracy: 0.9467, F1 Micro: 0.9467, F1 Macro: 0.9405\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.93      0.92        82\n",
      "    positive       0.96      0.96      0.96       162\n",
      "\n",
      "    accuracy                           0.95       244\n",
      "   macro avg       0.94      0.94      0.94       244\n",
      "weighted avg       0.95      0.95      0.95       244\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 504: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9112\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.86      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.89      0.98      0.93       152\n",
      "    positive       0.92      0.65      0.76        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.87      0.79      0.83       216\n",
      "weighted avg       0.89      0.89      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.91      0.87        23\n",
      "     neutral       0.96      0.99      0.97       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.90      0.91       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.89      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.93      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 105.67022228240967 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 36\n",
      "Sampling duration: 9.108866453170776 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5404, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4553, Accuracy: 0.8229, F1 Micro: 0.8991, F1 Macro: 0.898\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3523, Accuracy: 0.9234, F1 Micro: 0.9525, F1 Macro: 0.95\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2642, Accuracy: 0.9435, F1 Micro: 0.9649, F1 Macro: 0.9636\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1986, Accuracy: 0.9524, F1 Micro: 0.9704, F1 Macro: 0.9691\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1515, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1199, Accuracy: 0.965, F1 Micro: 0.9782, F1 Macro: 0.9773\n",
      "Epoch 8/10, Train Loss: 0.0997, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9769\n",
      "Epoch 9/10, Train Loss: 0.0858, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9722\n",
      "Epoch 10/10, Train Loss: 0.0646, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9747\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.9782, F1 Macro: 0.9773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.89      0.99      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      1.00      0.98      1061\n",
      "   macro avg       0.96      1.00      0.98      1061\n",
      "weighted avg       0.96      1.00      0.98      1061\n",
      " samples avg       0.96      1.00      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5606, Accuracy: 0.8319, F1 Micro: 0.8319, F1 Macro: 0.8197\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2766, Accuracy: 0.9202, F1 Micro: 0.9202, F1 Macro: 0.9137\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1329, Accuracy: 0.9202, F1 Micro: 0.9202, F1 Macro: 0.9124\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1339, Accuracy: 0.9202, F1 Micro: 0.9202, F1 Macro: 0.9114\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0922, Accuracy: 0.9202, F1 Micro: 0.9202, F1 Macro: 0.9133\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.075, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9264\n",
      "Epoch 7/10, Train Loss: 0.0834, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.9042\n",
      "Epoch 8/10, Train Loss: 0.0543, Accuracy: 0.916, F1 Micro: 0.916, F1 Macro: 0.9085\n",
      "Epoch 9/10, Train Loss: 0.0355, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9228\n",
      "Epoch 10/10, Train Loss: 0.0399, Accuracy: 0.916, F1 Micro: 0.916, F1 Macro: 0.9098\n",
      "\n",
      "Sentiment analysis accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9264\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.94      0.90        81\n",
      "    positive       0.97      0.93      0.95       157\n",
      "\n",
      "    accuracy                           0.93       238\n",
      "   macro avg       0.92      0.93      0.93       238\n",
      "weighted avg       0.94      0.93      0.93       238\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9045\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.83      0.87       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.89      0.99      0.94       152\n",
      "    positive       0.97      0.65      0.78        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.89      0.80      0.83       216\n",
      "weighted avg       0.90      0.90      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.78      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.92      0.91       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.89      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.71      0.83        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.98      0.90      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 110.10746622085571 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 33\n",
      "Sampling duration: 8.497576236724854 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5322, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4397, Accuracy: 0.8482, F1 Micro: 0.9118, F1 Macro: 0.9113\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3439, Accuracy: 0.9323, F1 Micro: 0.9579, F1 Macro: 0.9562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2345, Accuracy: 0.9494, F1 Micro: 0.9685, F1 Macro: 0.9672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1815, Accuracy: 0.9531, F1 Micro: 0.9708, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1408, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1079, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0885, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9782\n",
      "Epoch 9/10, Train Loss: 0.0769, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9722\n",
      "Epoch 10/10, Train Loss: 0.0648, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9766\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9782\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.93      0.95      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5784, Accuracy: 0.8192, F1 Micro: 0.8192, F1 Macro: 0.7649\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3199, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.9039\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.182, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9354\n",
      "Epoch 4/10, Train Loss: 0.1303, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9199\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.107, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.935\n",
      "Epoch 6/10, Train Loss: 0.1101, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9239\n",
      "Epoch 7/10, Train Loss: 0.0746, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9199\n",
      "Epoch 8/10, Train Loss: 0.0971, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9204\n",
      "Epoch 9/10, Train Loss: 0.0607, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9223\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0536, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9347\n",
      "\n",
      "Sentiment analysis accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9347\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.93      0.91        84\n",
      "    positive       0.97      0.95      0.96       176\n",
      "\n",
      "    accuracy                           0.94       260\n",
      "   macro avg       0.93      0.94      0.93       260\n",
      "weighted avg       0.94      0.94      0.94       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.919\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.75      0.86        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.80      0.85      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.86      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.94      0.95      0.94       152\n",
      "    positive       0.86      0.83      0.84        52\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.90      0.87      0.89       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.96      0.86        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.94      0.76      0.84        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.90      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.95      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 118.17749738693237 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 30\n",
      "Sampling duration: 7.48605751991272 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5365, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4482, Accuracy: 0.8638, F1 Micro: 0.92, F1 Macro: 0.9187\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.324, Accuracy: 0.9293, F1 Micro: 0.9555, F1 Macro: 0.9531\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2304, Accuracy: 0.9509, F1 Micro: 0.9694, F1 Macro: 0.9679\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1764, Accuracy: 0.9606, F1 Micro: 0.9754, F1 Macro: 0.9743\n",
      "Epoch 6/10, Train Loss: 0.131, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1071, Accuracy: 0.9665, F1 Micro: 0.9791, F1 Macro: 0.9779\n",
      "Epoch 8/10, Train Loss: 0.0853, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9771\n",
      "Epoch 9/10, Train Loss: 0.0702, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9768\n",
      "Epoch 10/10, Train Loss: 0.0638, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9776\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9791, F1 Macro: 0.9779\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.91      0.97      0.94       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5696, Accuracy: 0.6721, F1 Micro: 0.6721, F1 Macro: 0.4245\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3327, Accuracy: 0.919, F1 Micro: 0.919, F1 Macro: 0.9087\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1613, Accuracy: 0.9352, F1 Micro: 0.9352, F1 Macro: 0.9282\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1303, Accuracy: 0.9393, F1 Micro: 0.9393, F1 Macro: 0.9333\n",
      "Epoch 5/10, Train Loss: 0.1236, Accuracy: 0.8988, F1 Micro: 0.8988, F1 Macro: 0.8808\n",
      "Epoch 6/10, Train Loss: 0.0888, Accuracy: 0.9352, F1 Micro: 0.9352, F1 Macro: 0.9297\n",
      "Epoch 7/10, Train Loss: 0.093, Accuracy: 0.9352, F1 Micro: 0.9352, F1 Macro: 0.9297\n",
      "Epoch 8/10, Train Loss: 0.0795, Accuracy: 0.9352, F1 Micro: 0.9352, F1 Macro: 0.9294\n",
      "Epoch 9/10, Train Loss: 0.0686, Accuracy: 0.9271, F1 Micro: 0.9271, F1 Macro: 0.9206\n",
      "Epoch 10/10, Train Loss: 0.0368, Accuracy: 0.9352, F1 Micro: 0.9352, F1 Macro: 0.929\n",
      "\n",
      "Sentiment analysis accuracy: 0.9393, F1 Micro: 0.9393, F1 Macro: 0.9333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.95      0.91        83\n",
      "    positive       0.97      0.93      0.95       164\n",
      "\n",
      "    accuracy                           0.94       247\n",
      "   macro avg       0.93      0.94      0.93       247\n",
      "weighted avg       0.94      0.94      0.94       247\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.9119\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.96      0.99      0.97       167\n",
      "    positive       0.90      0.82      0.86        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.87      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.91      0.97      0.94       152\n",
      "    positive       0.90      0.73      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.86      0.82      0.83       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.96      0.99      0.97       152\n",
      "    positive       0.97      0.76      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.90      0.91       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.89      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 113.50912714004517 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 27\n",
      "Sampling duration: 6.859154939651489 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5363, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4261, Accuracy: 0.8839, F1 Micro: 0.931, F1 Macro: 0.9302\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3121, Accuracy: 0.9382, F1 Micro: 0.9615, F1 Macro: 0.9596\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2269, Accuracy: 0.9531, F1 Micro: 0.9708, F1 Macro: 0.9692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1691, Accuracy: 0.9621, F1 Micro: 0.9763, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1323, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9762\n",
      "Epoch 7/10, Train Loss: 0.0985, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0823, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0641, Accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9784\n",
      "Epoch 10/10, Train Loss: 0.0568, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9761\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9784\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.96      1.00      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5388, Accuracy: 0.7352, F1 Micro: 0.7352, F1 Macro: 0.603\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2875, Accuracy: 0.8972, F1 Micro: 0.8972, F1 Macro: 0.8909\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1709, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9358\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1678, Accuracy: 0.9486, F1 Micro: 0.9486, F1 Macro: 0.9441\n",
      "Epoch 5/10, Train Loss: 0.1148, Accuracy: 0.9447, F1 Micro: 0.9447, F1 Macro: 0.9399\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0757, Accuracy: 0.9486, F1 Micro: 0.9486, F1 Macro: 0.9441\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0756, Accuracy: 0.9486, F1 Micro: 0.9486, F1 Macro: 0.9438\n",
      "Epoch 8/10, Train Loss: 0.0675, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9334\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0479, Accuracy: 0.9526, F1 Micro: 0.9526, F1 Macro: 0.9474\n",
      "Epoch 10/10, Train Loss: 0.0264, Accuracy: 0.9447, F1 Micro: 0.9447, F1 Macro: 0.9399\n",
      "\n",
      "Sentiment analysis accuracy: 0.9526, F1 Micro: 0.9526, F1 Macro: 0.9474\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.94      0.93        86\n",
      "    positive       0.97      0.96      0.96       167\n",
      "\n",
      "    accuracy                           0.95       253\n",
      "   macro avg       0.95      0.95      0.95       253\n",
      "weighted avg       0.95      0.95      0.95       253\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9228\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.86      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.92      0.96      0.94       152\n",
      "    positive       0.87      0.79      0.83        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.90      0.86      0.88       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.96      1.00      0.98       152\n",
      "    positive       0.97      0.76      0.85        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.89      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 127.45386052131653 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 18\n",
      "Sampling duration: 6.32422137260437 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5403, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4264, Accuracy: 0.9025, F1 Micro: 0.9407, F1 Macro: 0.939\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2985, Accuracy: 0.9405, F1 Micro: 0.9633, F1 Macro: 0.9617\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.22, Accuracy: 0.9501, F1 Micro: 0.9687, F1 Macro: 0.9663\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1686, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9757\n",
      "Epoch 6/10, Train Loss: 0.1186, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0944, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.979\n",
      "Epoch 8/10, Train Loss: 0.0849, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0681, Accuracy: 0.9725, F1 Micro: 0.9827, F1 Macro: 0.9819\n",
      "Epoch 10/10, Train Loss: 0.0518, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.979\n",
      "\n",
      "Aspect detection accuracy: 0.9725, F1 Micro: 0.9827, F1 Macro: 0.9819\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.92      0.98      0.95       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5429, Accuracy: 0.874, F1 Micro: 0.874, F1 Macro: 0.8643\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2655, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9144\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1878, Accuracy: 0.9488, F1 Micro: 0.9488, F1 Macro: 0.943\n",
      "Epoch 4/10, Train Loss: 0.1598, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.919\n",
      "Epoch 5/10, Train Loss: 0.1186, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9274\n",
      "Epoch 6/10, Train Loss: 0.1062, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9274\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1008, Accuracy: 0.9528, F1 Micro: 0.9528, F1 Macro: 0.9478\n",
      "Epoch 8/10, Train Loss: 0.066, Accuracy: 0.9488, F1 Micro: 0.9488, F1 Macro: 0.9436\n",
      "Epoch 9/10, Train Loss: 0.0677, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9312\n",
      "Epoch 10/10, Train Loss: 0.0355, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.9067\n",
      "\n",
      "Sentiment analysis accuracy: 0.9528, F1 Micro: 0.9528, F1 Macro: 0.9478\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.96      0.93        85\n",
      "    positive       0.98      0.95      0.96       169\n",
      "\n",
      "    accuracy                           0.95       254\n",
      "   macro avg       0.94      0.96      0.95       254\n",
      "weighted avg       0.95      0.95      0.95       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9645, F1 Micro: 0.9645, F1 Macro: 0.9292\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.96      0.99      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.86      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.92      0.98      0.95       152\n",
      "    positive       0.93      0.77      0.84        52\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.89      0.83      0.86       216\n",
      "weighted avg       0.92      0.92      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.90      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 123.94095826148987 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.915945053100586 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5404, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4176, Accuracy: 0.9033, F1 Micro: 0.9417, F1 Macro: 0.9403\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2965, Accuracy: 0.9516, F1 Micro: 0.9699, F1 Macro: 0.9688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2134, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1511, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9755\n",
      "Epoch 6/10, Train Loss: 0.118, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0927, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9761\n",
      "Epoch 8/10, Train Loss: 0.0749, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0612, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9782\n",
      "Epoch 10/10, Train Loss: 0.0513, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.975\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9782\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.93      0.94      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5323, Accuracy: 0.8783, F1 Micro: 0.8783, F1 Macro: 0.8669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.27, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9328\n",
      "Epoch 3/10, Train Loss: 0.1641, Accuracy: 0.9278, F1 Micro: 0.9278, F1 Macro: 0.9182\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1437, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9321\n",
      "Epoch 5/10, Train Loss: 0.1021, Accuracy: 0.9278, F1 Micro: 0.9278, F1 Macro: 0.9195\n",
      "Epoch 6/10, Train Loss: 0.088, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9244\n",
      "Epoch 7/10, Train Loss: 0.0783, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9288\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0543, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9317\n",
      "Epoch 9/10, Train Loss: 0.0653, Accuracy: 0.9202, F1 Micro: 0.9202, F1 Macro: 0.9116\n",
      "Epoch 10/10, Train Loss: 0.0412, Accuracy: 0.9278, F1 Micro: 0.9278, F1 Macro: 0.9204\n",
      "\n",
      "Sentiment analysis accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9317\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.93      0.91        86\n",
      "    positive       0.97      0.94      0.95       177\n",
      "\n",
      "    accuracy                           0.94       263\n",
      "   macro avg       0.93      0.94      0.93       263\n",
      "weighted avg       0.94      0.94      0.94       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9136\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.96      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.84      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.93      0.94      0.94       152\n",
      "    positive       0.83      0.83      0.83        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.89      0.87      0.88       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 127.53639101982117 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.308811664581299 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5317, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4304, Accuracy: 0.8973, F1 Micro: 0.9371, F1 Macro: 0.9352\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2982, Accuracy: 0.9449, F1 Micro: 0.9658, F1 Macro: 0.9641\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2095, Accuracy: 0.9606, F1 Micro: 0.9754, F1 Macro: 0.9743\n",
      "Epoch 5/10, Train Loss: 0.1529, Accuracy: 0.9583, F1 Micro: 0.974, F1 Macro: 0.9727\n",
      "Epoch 6/10, Train Loss: 0.1126, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0937, Accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9782\n",
      "Epoch 8/10, Train Loss: 0.0758, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9747\n",
      "Epoch 9/10, Train Loss: 0.0589, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9779\n",
      "Epoch 10/10, Train Loss: 0.0517, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9762\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9782\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.90      0.96      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5747, Accuracy: 0.7569, F1 Micro: 0.7569, F1 Macro: 0.6407\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3045, Accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.9047\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1537, Accuracy: 0.9569, F1 Micro: 0.9569, F1 Macro: 0.9522\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1459, Accuracy: 0.9569, F1 Micro: 0.9569, F1 Macro: 0.9522\n",
      "Epoch 5/10, Train Loss: 0.1107, Accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.944\n",
      "Epoch 6/10, Train Loss: 0.1016, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9399\n",
      "Epoch 7/10, Train Loss: 0.065, Accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.9438\n",
      "Epoch 8/10, Train Loss: 0.0558, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9248\n",
      "Epoch 9/10, Train Loss: 0.0644, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9256\n",
      "Epoch 10/10, Train Loss: 0.058, Accuracy: 0.9255, F1 Micro: 0.9255, F1 Macro: 0.9143\n",
      "\n",
      "Sentiment analysis accuracy: 0.9569, F1 Micro: 0.9569, F1 Macro: 0.9522\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        85\n",
      "    positive       0.98      0.95      0.97       170\n",
      "\n",
      "    accuracy                           0.96       255\n",
      "   macro avg       0.95      0.96      0.95       255\n",
      "weighted avg       0.96      0.96      0.96       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9268\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.86      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.91      0.95      0.93       152\n",
      "    positive       0.84      0.73      0.78        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.86      0.81      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.80      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 123.54522156715393 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.7525634765625 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.532, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.408, Accuracy: 0.9144, F1 Micro: 0.947, F1 Macro: 0.9445\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2681, Accuracy: 0.9501, F1 Micro: 0.9692, F1 Macro: 0.9677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2065, Accuracy: 0.9546, F1 Micro: 0.9716, F1 Macro: 0.9701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1444, Accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9787\n",
      "Epoch 6/10, Train Loss: 0.1135, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9778\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0851, Accuracy: 0.9702, F1 Micro: 0.9814, F1 Macro: 0.9803\n",
      "Epoch 8/10, Train Loss: 0.0692, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9766\n",
      "Epoch 9/10, Train Loss: 0.0591, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9781\n",
      "Epoch 10/10, Train Loss: 0.0507, Accuracy: 0.9688, F1 Micro: 0.9802, F1 Macro: 0.9787\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9814, F1 Macro: 0.9803\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.91      0.97      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5245, Accuracy: 0.8845, F1 Micro: 0.8845, F1 Macro: 0.8741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2417, Accuracy: 0.9203, F1 Micro: 0.9203, F1 Macro: 0.9094\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1793, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.919\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1407, Accuracy: 0.9402, F1 Micro: 0.9402, F1 Macro: 0.9342\n",
      "Epoch 5/10, Train Loss: 0.1314, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9228\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1042, Accuracy: 0.9602, F1 Micro: 0.9602, F1 Macro: 0.9558\n",
      "Epoch 7/10, Train Loss: 0.0801, Accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9374\n",
      "Epoch 8/10, Train Loss: 0.0614, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.93\n",
      "Epoch 9/10, Train Loss: 0.0575, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9242\n",
      "Epoch 10/10, Train Loss: 0.0539, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9307\n",
      "\n",
      "Sentiment analysis accuracy: 0.9602, F1 Micro: 0.9602, F1 Macro: 0.9558\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.96      0.94        84\n",
      "    positive       0.98      0.96      0.97       167\n",
      "\n",
      "    accuracy                           0.96       251\n",
      "   macro avg       0.95      0.96      0.96       251\n",
      "weighted avg       0.96      0.96      0.96       251\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9645, F1 Micro: 0.9645, F1 Macro: 0.931\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       1.00      0.96      0.98        24\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.99      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.99      0.97       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.88      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.91      0.97      0.94       152\n",
      "    positive       0.91      0.77      0.83        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.91      0.83      0.86       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.83      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.95      0.94      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 128.76266646385193 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.2782979011535645 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5279, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4036, Accuracy: 0.9167, F1 Micro: 0.9481, F1 Macro: 0.9454\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2659, Accuracy: 0.9487, F1 Micro: 0.9682, F1 Macro: 0.9671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1863, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1328, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9778\n",
      "Epoch 6/10, Train Loss: 0.1015, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9756\n",
      "Epoch 7/10, Train Loss: 0.0806, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9746\n",
      "Epoch 8/10, Train Loss: 0.0655, Accuracy: 0.9613, F1 Micro: 0.9755, F1 Macro: 0.9735\n",
      "Epoch 9/10, Train Loss: 0.0595, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9775\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.048, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9781\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.97      0.97       175\n",
      "      others       0.93      0.95      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5581, Accuracy: 0.8631, F1 Micro: 0.8631, F1 Macro: 0.848\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2493, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9335\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1615, Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.9452\n",
      "Epoch 4/10, Train Loss: 0.1356, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9309\n",
      "Epoch 5/10, Train Loss: 0.1216, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9291\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0816, Accuracy: 0.9544, F1 Micro: 0.9544, F1 Macro: 0.9491\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0658, Accuracy: 0.9544, F1 Micro: 0.9544, F1 Macro: 0.9491\n",
      "Epoch 8/10, Train Loss: 0.0491, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9291\n",
      "Epoch 9/10, Train Loss: 0.0392, Accuracy: 0.9278, F1 Micro: 0.9278, F1 Macro: 0.9177\n",
      "Epoch 10/10, Train Loss: 0.0481, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9331\n",
      "\n",
      "Sentiment analysis accuracy: 0.9544, F1 Micro: 0.9544, F1 Macro: 0.9491\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93        87\n",
      "    positive       0.98      0.95      0.97       176\n",
      "\n",
      "    accuracy                           0.95       263\n",
      "   macro avg       0.94      0.95      0.95       263\n",
      "weighted avg       0.96      0.95      0.95       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9291\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.96      0.97      0.96       167\n",
      "    positive       0.81      0.79      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.86      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.93      0.95      0.94       152\n",
      "    positive       0.82      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.89      0.86      0.87       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.80      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 134.72542238235474 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 8\n",
      "Sampling duration: 3.5888900756835938 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5226, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4025, Accuracy: 0.9122, F1 Micro: 0.9448, F1 Macro: 0.942\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2609, Accuracy: 0.9494, F1 Micro: 0.9684, F1 Macro: 0.9666\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1852, Accuracy: 0.9554, F1 Micro: 0.9721, F1 Macro: 0.9701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1427, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1055, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0858, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0637, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9783\n",
      "Epoch 9/10, Train Loss: 0.0561, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9766\n",
      "Epoch 10/10, Train Loss: 0.0475, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9776\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9783\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.98       175\n",
      "      others       0.91      0.96      0.93       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5369, Accuracy: 0.856, F1 Micro: 0.856, F1 Macro: 0.8265\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2548, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9259\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1556, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9275\n",
      "Epoch 4/10, Train Loss: 0.1267, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9157\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1093, Accuracy: 0.9494, F1 Micro: 0.9494, F1 Macro: 0.9437\n",
      "Epoch 6/10, Train Loss: 0.0956, Accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9392\n",
      "Epoch 7/10, Train Loss: 0.0709, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9309\n",
      "Epoch 8/10, Train Loss: 0.0475, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9301\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0494, Accuracy: 0.9494, F1 Micro: 0.9494, F1 Macro: 0.9434\n",
      "Epoch 10/10, Train Loss: 0.0689, Accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9395\n",
      "\n",
      "Sentiment analysis accuracy: 0.9494, F1 Micro: 0.9494, F1 Macro: 0.9434\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.92        84\n",
      "    positive       0.98      0.95      0.96       173\n",
      "\n",
      "    accuracy                           0.95       257\n",
      "   macro avg       0.94      0.95      0.94       257\n",
      "weighted avg       0.95      0.95      0.95       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9196\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.99      0.98       167\n",
      "    positive       0.93      0.79      0.85        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.94      0.89      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.91      0.95      0.93       152\n",
      "    positive       0.85      0.77      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.89      0.82      0.85       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.94      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.87      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 137.36699843406677 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.626634359359741 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5314, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.399, Accuracy: 0.9129, F1 Micro: 0.9462, F1 Macro: 0.9443\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2565, Accuracy: 0.9539, F1 Micro: 0.9713, F1 Macro: 0.9703\n",
      "Epoch 4/10, Train Loss: 0.1802, Accuracy: 0.9516, F1 Micro: 0.9698, F1 Macro: 0.9679\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.136, Accuracy: 0.9613, F1 Micro: 0.9759, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1012, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0818, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0647, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9792\n",
      "Epoch 9/10, Train Loss: 0.0528, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9758\n",
      "Epoch 10/10, Train Loss: 0.0461, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9773\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9792\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.97      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4949, Accuracy: 0.9004, F1 Micro: 0.9004, F1 Macro: 0.8924\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2633, Accuracy: 0.9387, F1 Micro: 0.9387, F1 Macro: 0.9325\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.191, Accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.9403\n",
      "Epoch 4/10, Train Loss: 0.1784, Accuracy: 0.9425, F1 Micro: 0.9425, F1 Macro: 0.9355\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1207, Accuracy: 0.9502, F1 Micro: 0.9502, F1 Macro: 0.9441\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1219, Accuracy: 0.954, F1 Micro: 0.954, F1 Macro: 0.9489\n",
      "Epoch 7/10, Train Loss: 0.089, Accuracy: 0.931, F1 Micro: 0.931, F1 Macro: 0.9248\n",
      "Epoch 8/10, Train Loss: 0.0943, Accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.9386\n",
      "Epoch 9/10, Train Loss: 0.0954, Accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.9389\n",
      "Epoch 10/10, Train Loss: 0.0741, Accuracy: 0.9502, F1 Micro: 0.9502, F1 Macro: 0.9435\n",
      "\n",
      "Sentiment analysis accuracy: 0.954, F1 Micro: 0.954, F1 Macro: 0.9489\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.93        86\n",
      "    positive       0.98      0.95      0.97       175\n",
      "\n",
      "    accuracy                           0.95       261\n",
      "   macro avg       0.94      0.96      0.95       261\n",
      "weighted avg       0.96      0.95      0.95       261\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9614, F1 Micro: 0.9614, F1 Macro: 0.9282\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.97      0.97       167\n",
      "    positive       0.84      0.82      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.92      0.96      0.94       152\n",
      "    positive       0.85      0.77      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.86      0.83      0.84       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.90      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 137.87334656715393 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.8743441104888916 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5199, Accuracy: 0.8095, F1 Micro: 0.8923, F1 Macro: 0.8913\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3764, Accuracy: 0.9226, F1 Micro: 0.9515, F1 Macro: 0.9488\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2384, Accuracy: 0.9524, F1 Micro: 0.9704, F1 Macro: 0.9691\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1706, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1181, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9782\n",
      "Epoch 6/10, Train Loss: 0.1012, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9754\n",
      "Epoch 7/10, Train Loss: 0.0748, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9761\n",
      "Epoch 8/10, Train Loss: 0.0607, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9769\n",
      "Epoch 9/10, Train Loss: 0.0508, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9779\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0424, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9784\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9784\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.95      0.92      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5233, Accuracy: 0.9288, F1 Micro: 0.9288, F1 Macro: 0.9197\n",
      "Epoch 2/10, Train Loss: 0.2796, Accuracy: 0.8989, F1 Micro: 0.8989, F1 Macro: 0.88\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.19, Accuracy: 0.9401, F1 Micro: 0.9401, F1 Macro: 0.9337\n",
      "Epoch 4/10, Train Loss: 0.127, Accuracy: 0.9251, F1 Micro: 0.9251, F1 Macro: 0.9157\n",
      "Epoch 5/10, Train Loss: 0.1351, Accuracy: 0.9288, F1 Micro: 0.9288, F1 Macro: 0.9218\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0996, Accuracy: 0.9401, F1 Micro: 0.9401, F1 Macro: 0.9326\n",
      "Epoch 7/10, Train Loss: 0.0952, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.929\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0751, Accuracy: 0.9401, F1 Micro: 0.9401, F1 Macro: 0.9337\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0495, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9363\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0624, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9373\n",
      "\n",
      "Sentiment analysis accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9373\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.95      0.92        87\n",
      "    positive       0.98      0.94      0.96       180\n",
      "\n",
      "    accuracy                           0.94       267\n",
      "   macro avg       0.93      0.95      0.94       267\n",
      "weighted avg       0.95      0.94      0.94       267\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9229\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.97      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.87      0.86      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.92      0.88        12\n",
      "     neutral       0.95      0.93      0.94       152\n",
      "    positive       0.78      0.83      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.86      0.89      0.87       216\n",
      "weighted avg       0.91      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.80      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.90      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 139.53341841697693 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.287818193435669 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5211, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3741, Accuracy: 0.9211, F1 Micro: 0.9507, F1 Macro: 0.9473\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2416, Accuracy: 0.9539, F1 Micro: 0.9714, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1641, Accuracy: 0.9598, F1 Micro: 0.975, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1324, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9774\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0926, Accuracy: 0.968, F1 Micro: 0.98, F1 Macro: 0.9789\n",
      "Epoch 7/10, Train Loss: 0.079, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9757\n",
      "Epoch 8/10, Train Loss: 0.0644, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9788\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0527, Accuracy: 0.9754, F1 Micro: 0.9846, F1 Macro: 0.9836\n",
      "Epoch 10/10, Train Loss: 0.0452, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9779\n",
      "\n",
      "Aspect detection accuracy: 0.9754, F1 Micro: 0.9846, F1 Macro: 0.9836\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.93      0.97      0.95       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.98      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.98      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5285, Accuracy: 0.8915, F1 Micro: 0.8915, F1 Macro: 0.8779\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2635, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9287\n",
      "Epoch 3/10, Train Loss: 0.1593, Accuracy: 0.9186, F1 Micro: 0.9186, F1 Macro: 0.9127\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1502, Accuracy: 0.9496, F1 Micro: 0.9496, F1 Macro: 0.9441\n",
      "Epoch 5/10, Train Loss: 0.1428, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9321\n",
      "Epoch 6/10, Train Loss: 0.0934, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9362\n",
      "Epoch 7/10, Train Loss: 0.1128, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9284\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0911, Accuracy: 0.9496, F1 Micro: 0.9496, F1 Macro: 0.9421\n",
      "Epoch 9/10, Train Loss: 0.0702, Accuracy: 0.9109, F1 Micro: 0.9109, F1 Macro: 0.9048\n",
      "Epoch 10/10, Train Loss: 0.0601, Accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.9199\n",
      "\n",
      "Sentiment analysis accuracy: 0.9496, F1 Micro: 0.9496, F1 Macro: 0.9421\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.87      0.92        87\n",
      "    positive       0.94      0.99      0.96       171\n",
      "\n",
      "    accuracy                           0.95       258\n",
      "   macro avg       0.96      0.93      0.94       258\n",
      "weighted avg       0.95      0.95      0.95       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9668, F1 Micro: 0.9668, F1 Macro: 0.9252\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       0.88      0.96      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.90      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.96      0.99      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.86      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.83      0.91        12\n",
      "     neutral       0.94      0.97      0.95       152\n",
      "    positive       0.88      0.83      0.85        52\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.94      0.88      0.90       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      1.00      0.98        23\n",
      "     neutral       0.98      0.99      0.99       152\n",
      "    positive       1.00      0.93      0.96        41\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.88      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.89      1.00      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 140.46642637252808 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.7212622165679932 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5158, Accuracy: 0.8013, F1 Micro: 0.8881, F1 Macro: 0.8868\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3805, Accuracy: 0.9286, F1 Micro: 0.9554, F1 Macro: 0.9527\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2409, Accuracy: 0.9576, F1 Micro: 0.9737, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1663, Accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9775\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.119, Accuracy: 0.9695, F1 Micro: 0.9809, F1 Macro: 0.98\n",
      "Epoch 6/10, Train Loss: 0.0918, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9782\n",
      "Epoch 7/10, Train Loss: 0.0743, Accuracy: 0.968, F1 Micro: 0.9797, F1 Macro: 0.9781\n",
      "Epoch 8/10, Train Loss: 0.0608, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9768\n",
      "Epoch 9/10, Train Loss: 0.0511, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9792\n",
      "Epoch 10/10, Train Loss: 0.0456, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9776\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9809, F1 Macro: 0.98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.89      0.99      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.509, Accuracy: 0.8849, F1 Micro: 0.8849, F1 Macro: 0.8787\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2149, Accuracy: 0.9008, F1 Micro: 0.9008, F1 Macro: 0.8942\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1567, Accuracy: 0.9206, F1 Micro: 0.9206, F1 Macro: 0.9144\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1594, Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9392\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1379, Accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9434\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1113, Accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9428\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.085, Accuracy: 0.9524, F1 Micro: 0.9524, F1 Macro: 0.947\n",
      "Epoch 8/10, Train Loss: 0.0836, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.935\n",
      "Epoch 9/10, Train Loss: 0.0773, Accuracy: 0.9246, F1 Micro: 0.9246, F1 Macro: 0.9185\n",
      "Epoch 10/10, Train Loss: 0.0558, Accuracy: 0.9206, F1 Micro: 0.9206, F1 Macro: 0.9144\n",
      "\n",
      "Sentiment analysis accuracy: 0.9524, F1 Micro: 0.9524, F1 Macro: 0.947\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93        84\n",
      "    positive       0.98      0.95      0.96       168\n",
      "\n",
      "    accuracy                           0.95       252\n",
      "   macro avg       0.94      0.95      0.95       252\n",
      "weighted avg       0.95      0.95      0.95       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.963, F1 Micro: 0.963, F1 Macro: 0.9291\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.90      0.82      0.86        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.67      0.73        12\n",
      "     neutral       0.89      0.99      0.94       152\n",
      "    positive       0.97      0.71      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.89      0.79      0.83       216\n",
      "weighted avg       0.91      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.91      0.87        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.92      0.85      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.93      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 141.6057493686676 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 8\n",
      "Sampling duration: 0.9487266540527344 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5126, Accuracy: 0.7969, F1 Micro: 0.886, F1 Macro: 0.8845\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.37, Accuracy: 0.9323, F1 Micro: 0.9578, F1 Macro: 0.9548\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.23, Accuracy: 0.9516, F1 Micro: 0.9698, F1 Macro: 0.968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1671, Accuracy: 0.9539, F1 Micro: 0.9709, F1 Macro: 0.9686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1263, Accuracy: 0.9665, F1 Micro: 0.9791, F1 Macro: 0.9782\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0891, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9784\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0758, Accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9802\n",
      "Epoch 8/10, Train Loss: 0.0655, Accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9783\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0485, Accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9802\n",
      "Epoch 10/10, Train Loss: 0.0442, Accuracy: 0.9702, F1 Micro: 0.9812, F1 Macro: 0.98\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9802\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.97      0.97       175\n",
      "      others       0.92      0.97      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5055, Accuracy: 0.8973, F1 Micro: 0.8973, F1 Macro: 0.888\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2346, Accuracy: 0.9278, F1 Micro: 0.9278, F1 Macro: 0.9208\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1545, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9251\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.15, Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9384\n",
      "Epoch 5/10, Train Loss: 0.1366, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9346\n",
      "Epoch 6/10, Train Loss: 0.0984, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9368\n",
      "Epoch 7/10, Train Loss: 0.0824, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9368\n",
      "Epoch 8/10, Train Loss: 0.0715, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9368\n",
      "Epoch 9/10, Train Loss: 0.0662, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9324\n",
      "Epoch 10/10, Train Loss: 0.0581, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.924\n",
      "\n",
      "Sentiment analysis accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9384\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.88      0.92        86\n",
      "    positive       0.95      0.98      0.96       177\n",
      "\n",
      "    accuracy                           0.95       263\n",
      "   macro avg       0.95      0.93      0.94       263\n",
      "weighted avg       0.95      0.95      0.95       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9194\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.96      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.89      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.96      0.97      0.97       167\n",
      "    positive       0.79      0.82      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.92      0.97      0.95       152\n",
      "    positive       0.87      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.87      0.83      0.85       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.91      0.93        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.90      0.93      0.92        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.95      0.94      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 145.20960235595703 s\n",
      "Total runtime: 2981.210210084915 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "initial_train_size = int(0.1 * total_data)\n",
    "active_learning(81, 0, 10)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6159439,
     "sourceId": 10801903,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6186.54103,
   "end_time": "2025-05-19T06:14:49.952862",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-19T04:31:43.411832",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0496022baca84e6a8506635b32cf7584": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "0809bce2a74d421e820af0a7f7f2e227": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "19474738ceac4a1aac15c54c4208ed9b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_95057cb9a51a4dd5971b99ecd26db273",
       "placeholder": "​",
       "style": "IPY_MODEL_3acf8d55e7954fcdabcd6339eaaf7e49",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.txt: 100%"
      }
     },
     "1d9d1d0eeca641e39e38ec8561a79a70": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1f7f0ecc408146089fecf3a366bd474d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6233fb3c1c71407186d1e42848a7740f",
       "placeholder": "​",
       "style": "IPY_MODEL_0496022baca84e6a8506635b32cf7584",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json: 100%"
      }
     },
     "267764cb4c72468f83f60b68b75bade2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e90de9512f454719961ea757b1aa3204",
       "placeholder": "​",
       "style": "IPY_MODEL_394fcd7799cb4072821a2400470cd096",
       "tabbable": null,
       "tooltip": null,
       "value": " 1.53k/1.53k [00:00&lt;00:00, 151kB/s]"
      }
     },
     "3185204ee5f44ac5a40f460c3c93db4f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "31ebf65bdac649b98389c5a450cf412e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "374a2c497f3140319d95e8e44df71073": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6334f71636ec4fcb953190bd682e96a1",
       "max": 1534.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c71eb61afc294b9d8d337f2fc4b8ec38",
       "tabbable": null,
       "tooltip": null,
       "value": 1534.0
      }
     },
     "394fcd7799cb4072821a2400470cd096": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3acf8d55e7954fcdabcd6339eaaf7e49": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3bca1e4147164e109e27e2059ca6bab4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "506c5b56955d4849b856dbe3e4cceb4c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1d9d1d0eeca641e39e38ec8561a79a70",
       "max": 229167.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_52fc518a033f4517a24c97438dc87240",
       "tabbable": null,
       "tooltip": null,
       "value": 229167.0
      }
     },
     "52fc518a033f4517a24c97438dc87240": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "603324d320c048d88a00af64e72392da": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3185204ee5f44ac5a40f460c3c93db4f",
       "placeholder": "​",
       "style": "IPY_MODEL_a9688ce060424c628b0bded6e2684709",
       "tabbable": null,
       "tooltip": null,
       "value": " 2.00/2.00 [00:00&lt;00:00, 172B/s]"
      }
     },
     "6233fb3c1c71407186d1e42848a7740f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6334f71636ec4fcb953190bd682e96a1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "726f7623692040268323167b339ccf56": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "72e8f21c0e5944889eacaac98417dd85": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "83572deb152a416faf5c41974c91fd00": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "84001cf3ccb94b08a4fa877365b923ab": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_83572deb152a416faf5c41974c91fd00",
       "max": 2.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a0f672faa28b48c3809d457f11fb2a26",
       "tabbable": null,
       "tooltip": null,
       "value": 2.0
      }
     },
     "85938f820bfd44e3ac8e0777e94d1e87": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_eb5d4286749c47e5ae71a8f6231da98e",
        "IPY_MODEL_9c2c2132412b40b991cdc87b5bdc25db",
        "IPY_MODEL_9e00c78f2f4e47cda49d6ec47f4421a2"
       ],
       "layout": "IPY_MODEL_cdb7825f0b18435ab6e23a41cd635738",
       "tabbable": null,
       "tooltip": null
      }
     },
     "95057cb9a51a4dd5971b99ecd26db273": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9c2c2132412b40b991cdc87b5bdc25db": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_72e8f21c0e5944889eacaac98417dd85",
       "max": 112.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3bca1e4147164e109e27e2059ca6bab4",
       "tabbable": null,
       "tooltip": null,
       "value": 112.0
      }
     },
     "9e00c78f2f4e47cda49d6ec47f4421a2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_726f7623692040268323167b339ccf56",
       "placeholder": "​",
       "style": "IPY_MODEL_31ebf65bdac649b98389c5a450cf412e",
       "tabbable": null,
       "tooltip": null,
       "value": " 112/112 [00:00&lt;00:00, 12.2kB/s]"
      }
     },
     "a0f672faa28b48c3809d457f11fb2a26": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a2f94f7f50b54777b57935fa8d9f6cfc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ff989d4e4f794f2f9d4330901b1355c7",
       "placeholder": "​",
       "style": "IPY_MODEL_f571b6be1a5b42bbbd6699c6aa074c34",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: 100%"
      }
     },
     "a61c89a6f3a24ccc995482cdf813df95": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a9688ce060424c628b0bded6e2684709": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "adbc4c60caab47bf8cdeb0e7cc998e07": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "bea7efe0809240b1b620cee411914328": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c1a96c1215ea48c0ac5ee11ab7e9a30b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a2f94f7f50b54777b57935fa8d9f6cfc",
        "IPY_MODEL_374a2c497f3140319d95e8e44df71073",
        "IPY_MODEL_267764cb4c72468f83f60b68b75bade2"
       ],
       "layout": "IPY_MODEL_ed0793098b274039864298775a32d04d",
       "tabbable": null,
       "tooltip": null
      }
     },
     "c71eb61afc294b9d8d337f2fc4b8ec38": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "cdb7825f0b18435ab6e23a41cd635738": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ce2891ca32d34dda8f0e2bb4f530731c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_19474738ceac4a1aac15c54c4208ed9b",
        "IPY_MODEL_506c5b56955d4849b856dbe3e4cceb4c",
        "IPY_MODEL_ec80d65b1fe64bbf95dec73fa463cfca"
       ],
       "layout": "IPY_MODEL_bea7efe0809240b1b620cee411914328",
       "tabbable": null,
       "tooltip": null
      }
     },
     "e90de9512f454719961ea757b1aa3204": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "eb5d4286749c47e5ae71a8f6231da98e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0809bce2a74d421e820af0a7f7f2e227",
       "placeholder": "​",
       "style": "IPY_MODEL_adbc4c60caab47bf8cdeb0e7cc998e07",
       "tabbable": null,
       "tooltip": null,
       "value": "special_tokens_map.json: 100%"
      }
     },
     "ec80d65b1fe64bbf95dec73fa463cfca": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a61c89a6f3a24ccc995482cdf813df95",
       "placeholder": "​",
       "style": "IPY_MODEL_f610152212284d5ab997cf60e5fb5688",
       "tabbable": null,
       "tooltip": null,
       "value": " 229k/229k [00:00&lt;00:00, 3.54MB/s]"
      }
     },
     "ed0793098b274039864298775a32d04d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f571b6be1a5b42bbbd6699c6aa074c34": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f610152212284d5ab997cf60e5fb5688": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "fe2ca17af5024721a70aa798fdde8b8f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1f7f0ecc408146089fecf3a366bd474d",
        "IPY_MODEL_84001cf3ccb94b08a4fa877365b923ab",
        "IPY_MODEL_603324d320c048d88a00af64e72392da"
       ],
       "layout": "IPY_MODEL_feace50a3a2043a5875ff2a2d807ff79",
       "tabbable": null,
       "tooltip": null
      }
     },
     "feace50a3a2043a5875ff2a2d807ff79": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ff989d4e4f794f2f9d4330901b1355c7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
