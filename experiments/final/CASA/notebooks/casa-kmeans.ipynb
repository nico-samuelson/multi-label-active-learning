{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32509839",
   "metadata": {
    "papermill": {
     "duration": 0.013417,
     "end_time": "2025-03-25T14:34:41.695563",
     "exception": false,
     "start_time": "2025-03-25T14:34:41.682146",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72d89a02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T14:34:41.720646Z",
     "iopub.status.busy": "2025-03-25T14:34:41.720326Z",
     "iopub.status.idle": "2025-03-25T14:35:08.757365Z",
     "shell.execute_reply": "2025-03-25T14:35:08.756618Z"
    },
    "papermill": {
     "duration": 27.051471,
     "end_time": "2025-03-25T14:35:08.759240",
     "exception": false,
     "start_time": "2025-03-25T14:34:41.707769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score, classification_report\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "from torch.multiprocessing import Manager\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel, BertPreTrainedModel, BertConfig, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e17926",
   "metadata": {
    "papermill": {
     "duration": 0.011986,
     "end_time": "2025-03-25T14:35:08.784628",
     "exception": false,
     "start_time": "2025-03-25T14:35:08.772642",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48227469",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T14:35:08.811421Z",
     "iopub.status.busy": "2025-03-25T14:35:08.810780Z",
     "iopub.status.idle": "2025-03-25T14:35:08.814807Z",
     "shell.execute_reply": "2025-03-25T14:35:08.814087Z"
    },
    "papermill": {
     "duration": 0.019321,
     "end_time": "2025-03-25T14:35:08.816185",
     "exception": false,
     "start_time": "2025-03-25T14:35:08.796864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c7998c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T14:35:08.842571Z",
     "iopub.status.busy": "2025-03-25T14:35:08.842194Z",
     "iopub.status.idle": "2025-03-25T14:35:08.846499Z",
     "shell.execute_reply": "2025-03-25T14:35:08.845782Z"
    },
    "papermill": {
     "duration": 0.019206,
     "end_time": "2025-03-25T14:35:08.847710",
     "exception": false,
     "start_time": "2025-03-25T14:35:08.828504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists('/kaggle/working/results') == False:\n",
    "    os.mkdir('/kaggle/working/results')\n",
    "\n",
    "if os.path.exists('/kaggle/working/acquired_data') == False:\n",
    "    os.mkdir('/kaggle/working/acquired_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47f99e19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T14:35:08.874377Z",
     "iopub.status.busy": "2025-03-25T14:35:08.874061Z",
     "iopub.status.idle": "2025-03-25T14:35:08.885806Z",
     "shell.execute_reply": "2025-03-25T14:35:08.884868Z"
    },
    "papermill": {
     "duration": 0.02685,
     "end_time": "2025-03-25T14:35:08.887351",
     "exception": false,
     "start_time": "2025-03-25T14:35:08.860501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "    torch.backends.cudnn.benchmark=False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10646c84",
   "metadata": {
    "papermill": {
     "duration": 0.011675,
     "end_time": "2025-03-25T14:35:08.911984",
     "exception": false,
     "start_time": "2025-03-25T14:35:08.900309",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# GLOBAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0f19cb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T14:35:08.936711Z",
     "iopub.status.busy": "2025-03-25T14:35:08.936393Z",
     "iopub.status.idle": "2025-03-25T14:35:09.003831Z",
     "shell.execute_reply": "2025-03-25T14:35:09.002123Z"
    },
    "papermill": {
     "duration": 0.082019,
     "end_time": "2025-03-25T14:35:09.005877",
     "exception": false,
     "start_time": "2025-03-25T14:35:08.923858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "\n",
    "# Shared resources\n",
    "aspect_accuracies = manager.list()\n",
    "aspect_f1_micros = manager.list()\n",
    "aspect_f1_macros = manager.list()\n",
    "sentiment_accuracies = manager.list()\n",
    "sentiment_f1_micros = manager.list()\n",
    "sentiment_f1_macros = manager.list()\n",
    "accuracies = manager.list()\n",
    "f1_micros = manager.list()\n",
    "f1_macros = manager.list()\n",
    "\n",
    "# Non shared resources\n",
    "filename = 'casa-kmeans'\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "sequence_length = 48\n",
    "\n",
    "aspect_list = ['fuel', 'machine', 'others', 'part', 'price', 'service']\n",
    "aspect_mapping = {'fuel': 0, 'machine': 1, 'others': 2, 'part': 3, 'price': 4, 'service': 5 }\n",
    "label_mapping = {\"negative\": 0, \"neutral\": 1, 'positive': 2}\n",
    "ignored_keys = ['labels', 'ori_text', 'ori_label', 'ori_indices', 'aspect']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c1c53d",
   "metadata": {
    "papermill": {
     "duration": 0.011798,
     "end_time": "2025-03-25T14:35:09.029993",
     "exception": false,
     "start_time": "2025-03-25T14:35:09.018195",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LOAD AND PREPROCESS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e3c8212",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T14:35:09.055056Z",
     "iopub.status.busy": "2025-03-25T14:35:09.054767Z",
     "iopub.status.idle": "2025-03-25T14:35:09.135093Z",
     "shell.execute_reply": "2025-03-25T14:35:09.134212Z"
    },
    "papermill": {
     "duration": 0.094742,
     "end_time": "2025-03-25T14:35:09.136525",
     "exception": false,
     "start_time": "2025-03-25T14:35:09.041783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>fuel</th>\n",
       "      <th>machine</th>\n",
       "      <th>others</th>\n",
       "      <th>part</th>\n",
       "      <th>price</th>\n",
       "      <th>service</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saya memakai Honda Jazz GK5 tahun 2014 ( perta...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Avanza kenapa jadi boros bensin begini dah ah....</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saran ku dan pengalaman ku , mending beli mobi...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dari segi harga juga pajero lebih mahal 30 jut...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kalo menurut gw enak pajero si</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence      fuel   machine  \\\n",
       "0  Saya memakai Honda Jazz GK5 tahun 2014 ( perta...   neutral   neutral   \n",
       "1  Avanza kenapa jadi boros bensin begini dah ah....  negative   neutral   \n",
       "2  saran ku dan pengalaman ku , mending beli mobi...  positive  positive   \n",
       "3  Dari segi harga juga pajero lebih mahal 30 jut...   neutral   neutral   \n",
       "4                     Kalo menurut gw enak pajero si   neutral   neutral   \n",
       "\n",
       "     others     part     price  service  \n",
       "0  positive  neutral   neutral  neutral  \n",
       "1   neutral  neutral   neutral  neutral  \n",
       "2   neutral  neutral   neutral  neutral  \n",
       "3   neutral  neutral  positive  neutral  \n",
       "4  positive  neutral   neutral  neutral  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('/kaggle/input/casa-dataset/train_preprocess.csv', encoding='latin-1')\n",
    "val_data = pd.read_csv('/kaggle/input/casa-dataset/valid_preprocess.csv', encoding='latin-1')\n",
    "test_data = pd.read_csv('/kaggle/input/casa-dataset/test_preprocess.csv', encoding='latin-1')\n",
    "\n",
    "data = pd.concat([train_data, val_data, test_data], ignore_index=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07b19616",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T14:35:09.162674Z",
     "iopub.status.busy": "2025-03-25T14:35:09.162359Z",
     "iopub.status.idle": "2025-03-25T14:35:09.172618Z",
     "shell.execute_reply": "2025-03-25T14:35:09.171727Z"
    },
    "papermill": {
     "duration": 0.024972,
     "end_time": "2025-03-25T14:35:09.174039",
     "exception": false,
     "start_time": "2025-03-25T14:35:09.149067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>fuel</th>\n",
       "      <th>machine</th>\n",
       "      <th>others</th>\n",
       "      <th>part</th>\n",
       "      <th>price</th>\n",
       "      <th>service</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saya memakai Honda Jazz GK5 tahun 2014 ( perta...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Avanza kenapa jadi boros bensin begini dah ah....</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saran ku dan pengalaman ku , mending beli mobi...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dari segi harga juga pajero lebih mahal 30 jut...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kalo menurut gw enak pajero si</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence      fuel   machine  \\\n",
       "0  Saya memakai Honda Jazz GK5 tahun 2014 ( perta...   neutral   neutral   \n",
       "1  Avanza kenapa jadi boros bensin begini dah ah....  negative   neutral   \n",
       "2  saran ku dan pengalaman ku , mending beli mobi...  positive  positive   \n",
       "3  Dari segi harga juga pajero lebih mahal 30 jut...   neutral   neutral   \n",
       "4                     Kalo menurut gw enak pajero si   neutral   neutral   \n",
       "\n",
       "     others     part     price  service  \n",
       "0  positive  neutral   neutral  neutral  \n",
       "1   neutral  neutral   neutral  neutral  \n",
       "2   neutral  neutral   neutral  neutral  \n",
       "3   neutral  neutral  positive  neutral  \n",
       "4  positive  neutral   neutral  neutral  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85931a5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T14:35:09.201164Z",
     "iopub.status.busy": "2025-03-25T14:35:09.200892Z",
     "iopub.status.idle": "2025-03-25T14:35:09.209721Z",
     "shell.execute_reply": "2025-03-25T14:35:09.209017Z"
    },
    "papermill": {
     "duration": 0.023993,
     "end_time": "2025-03-25T14:35:09.211122",
     "exception": false,
     "start_time": "2025-03-25T14:35:09.187129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5365543",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T14:35:09.237988Z",
     "iopub.status.busy": "2025-03-25T14:35:09.237738Z",
     "iopub.status.idle": "2025-03-25T14:35:09.254974Z",
     "shell.execute_reply": "2025-03-25T14:35:09.254214Z"
    },
    "papermill": {
     "duration": 0.032288,
     "end_time": "2025-03-25T14:35:09.256451",
     "exception": false,
     "start_time": "2025-03-25T14:35:09.224163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(864,) (864, 6)\n",
      "(216,) (216, 6)\n"
     ]
    }
   ],
   "source": [
    "train_labels = train_data.columns[1:]\n",
    "val_labels = val_data.columns[1:]\n",
    "\n",
    "# Extract features and labels for training and validation\n",
    "X_train = train_data['sentence'].values\n",
    "y_train = train_data[train_labels].values\n",
    "X_val = val_data['sentence'].values\n",
    "y_val = val_data[val_labels].values\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71925d4e",
   "metadata": {
    "papermill": {
     "duration": 0.012928,
     "end_time": "2025-03-25T14:35:09.283165",
     "exception": false,
     "start_time": "2025-03-25T14:35:09.270237",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BUILD DATASET & DATALOADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8f763d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T14:35:09.310543Z",
     "iopub.status.busy": "2025-03-25T14:35:09.310241Z",
     "iopub.status.idle": "2025-03-25T14:35:09.316806Z",
     "shell.execute_reply": "2025-03-25T14:35:09.315986Z"
    },
    "papermill": {
     "duration": 0.021969,
     "end_time": "2025-03-25T14:35:09.318223",
     "exception": false,
     "start_time": "2025-03-25T14:35:09.296254",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AspectDetectionDataset(Dataset):\n",
    "    def __init__(self, texts, labels, label_mapping, tokenizer, max_length=sequence_length, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.use_float = use_float\n",
    "        self.label_mapping = label_mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "        \n",
    "        original_labels = [self.label_mapping[label] for label in self.labels[idx]]\n",
    "        encoded_labels = [1 if label == 1 else 0 for label in original_labels]\n",
    "        \n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['ori_indices'] = idx\n",
    "        item['ori_text'] = self.texts[idx]\n",
    "        item['ori_label'] = torch.tensor(original_labels, dtype=torch.float)\n",
    "        item['labels'] = torch.tensor(encoded_labels, dtype=torch.float if self.use_float else torch.long)\n",
    "        \n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc15a5ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T14:35:09.344643Z",
     "iopub.status.busy": "2025-03-25T14:35:09.344339Z",
     "iopub.status.idle": "2025-03-25T14:35:09.351861Z",
     "shell.execute_reply": "2025-03-25T14:35:09.351015Z"
    },
    "papermill": {
     "duration": 0.022005,
     "end_time": "2025-03-25T14:35:09.353200",
     "exception": false,
     "start_time": "2025-03-25T14:35:09.331195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SentimentAnalysisDataset(Dataset):\n",
    "    def __init__(self, texts, labels, aspects, indices, label_mapping, tokenizer, max_length=96, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.aspects = aspects\n",
    "        self.indices = indices\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.use_float = use_float\n",
    "        self.label_mapping = label_mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = aspect_token + ' ' + self.aspects[idx] + ' ' + review_token + ' ' + self.texts[idx] \n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "\n",
    "        if isinstance(self.labels[idx], str):\n",
    "            self.labels[idx] = self.label_mapping[self.labels[idx]]\n",
    "        elif torch.is_tensor(self.labels[idx]):\n",
    "            self.labels[idx] = int(self.labels[idx].item())\n",
    "\n",
    "        encoded_label = 1 if self.labels[idx] == 2 else self.labels[idx]\n",
    "        one_hot_label = F.one_hot(torch.tensor(encoded_label, dtype=torch.long), num_classes=2).float()\n",
    "\n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['aspect'] = self.aspects[idx]\n",
    "        item['labels'] = one_hot_label\n",
    "        item['ori_indices'] = self.indices[idx]\n",
    "        item['ori_text'] = self.texts[idx]\n",
    "        item['ori_label'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a214676",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T14:35:09.379344Z",
     "iopub.status.busy": "2025-03-25T14:35:09.379111Z",
     "iopub.status.idle": "2025-03-25T14:35:10.985172Z",
     "shell.execute_reply": "2025-03-25T14:35:10.984249Z"
    },
    "papermill": {
     "duration": 1.62082,
     "end_time": "2025-03-25T14:35:10.986840",
     "exception": false,
     "start_time": "2025-03-25T14:35:09.366020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aed8755e7c04da49b9c8913b4b1a6d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d60270ec545446c792b323202ba5128b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/229k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d6e32ef9e6147d7ba878360e7ad711b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a3dd52d3b31442a8eb97dc58ebec638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p1')\n",
    "review_token = '[REVIEW]'\n",
    "aspect_token = '[ASPECT]'\n",
    "special_tokens_dict = {'additional_special_tokens': [review_token, aspect_token]}\n",
    "num_added_tokens = tokenizer.add_special_tokens(special_tokens_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6a1fdd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T14:35:11.015470Z",
     "iopub.status.busy": "2025-03-25T14:35:11.015152Z",
     "iopub.status.idle": "2025-03-25T14:35:11.020084Z",
     "shell.execute_reply": "2025-03-25T14:35:11.019201Z"
    },
    "papermill": {
     "duration": 0.021184,
     "end_time": "2025-03-25T14:35:11.021350",
     "exception": false,
     "start_time": "2025-03-25T14:35:11.000166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_aspect_dataset(X_train, y_train, X_val, y_val, sequence_length, num_workers=4):\n",
    "    train_dataset = AspectDetectionDataset(X_train, y_train, label_mapping, tokenizer, max_length=sequence_length)\n",
    "    val_dataset = AspectDetectionDataset(X_val, y_val, label_mapping, tokenizer, max_length=sequence_length)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=num_workers,\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=num_workers, \n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93923e98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T14:35:11.047946Z",
     "iopub.status.busy": "2025-03-25T14:35:11.047713Z",
     "iopub.status.idle": "2025-03-25T14:35:11.058278Z",
     "shell.execute_reply": "2025-03-25T14:35:11.057473Z"
    },
    "papermill": {
     "duration": 0.025524,
     "end_time": "2025-03-25T14:35:11.059658",
     "exception": false,
     "start_time": "2025-03-25T14:35:11.034134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_sentiment_dataset(device, train_dataset, val_dataset, aspect_detection_model, tokenizer, max_length=sequence_length):\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "\n",
    "    aspect_detection_model.to(device)\n",
    "    aspect_detection_model.eval()\n",
    "\n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "    train_aspects = []\n",
    "    train_indices = []\n",
    "\n",
    "    val_data = []\n",
    "    val_labels = []\n",
    "    val_aspects = []\n",
    "    val_indices = []\n",
    "\n",
    "    # Transform train set\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        for batch in train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = aspect_detection_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            for i in range(len(preds)):\n",
    "                for j in range(len(preds[i])):\n",
    "                    if int(preds[i][j]) != 1:\n",
    "                        train_aspects.append(aspect_list[j])\n",
    "                        train_data.append(batch['ori_text'][i])\n",
    "                        train_labels.append(batch['ori_label'][i][j])\n",
    "                        train_indices.append(batch['ori_indices'][i])\n",
    "            \n",
    "        # Transform validation set\n",
    "        for batch in val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = aspect_detection_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            for i in range(len(preds)):\n",
    "                for j in range(len(preds[i])):\n",
    "                    if int(preds[i][j]) != 1:\n",
    "                        val_aspects.append(aspect_list[j])\n",
    "                        val_data.append(batch['ori_text'][i])\n",
    "                        val_labels.append(batch['ori_label'][i][j])\n",
    "                        val_indices.append(batch['ori_indices'][i])\n",
    "\n",
    "    train_dataset = SentimentAnalysisDataset(train_data, train_labels, train_aspects, train_indices, label_mapping, tokenizer, max_length=max_length)\n",
    "    val_dataset = SentimentAnalysisDataset(val_data, val_labels, val_aspects, val_indices, label_mapping, tokenizer, max_length=max_length)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae444c1",
   "metadata": {
    "papermill": {
     "duration": 0.012777,
     "end_time": "2025-03-25T14:35:11.085520",
     "exception": false,
     "start_time": "2025-03-25T14:35:11.072743",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35580c4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T14:35:11.111978Z",
     "iopub.status.busy": "2025-03-25T14:35:11.111764Z",
     "iopub.status.idle": "2025-03-25T14:35:11.115272Z",
     "shell.execute_reply": "2025-03-25T14:35:11.114687Z"
    },
    "papermill": {
     "duration": 0.018105,
     "end_time": "2025-03-25T14:35:11.116673",
     "exception": false,
     "start_time": "2025-03-25T14:35:11.098568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_data = len(X_train) + len(X_val)\n",
    "initial_train_size = int(0.05 * total_data)\n",
    "checkpoints = [\n",
    "    int(0.5 * total_data), \n",
    "    int(0.6 * total_data), \n",
    "    int(0.7 * total_data),\n",
    "    len(X_train)\n",
    "]\n",
    "min_increment = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9279100a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T14:35:11.143698Z",
     "iopub.status.busy": "2025-03-25T14:35:11.143480Z",
     "iopub.status.idle": "2025-03-25T14:35:11.147915Z",
     "shell.execute_reply": "2025-03-25T14:35:11.147294Z"
    },
    "papermill": {
     "duration": 0.019189,
     "end_time": "2025-03-25T14:35:11.149148",
     "exception": false,
     "start_time": "2025-03-25T14:35:11.129959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p, label, classes):\n",
    "    preds = torch.tensor(p.predictions) # Sigmoid and threshold for multi-label\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Hamming accuracy: proportion of correctly predicted labels over total labels\n",
    "    hamming_accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Standard multi-label precision, recall, and F1 metrics\n",
    "    precision, recall, f1_micro, _ = precision_recall_fscore_support(labels, preds, average='micro', zero_division=0)\n",
    "    _, _, f1_macro, _ = precision_recall_fscore_support(labels, preds, average='macro', zero_division=0)\n",
    "\n",
    "    report = classification_report(\n",
    "        labels, \n",
    "        preds, \n",
    "        labels=label,\n",
    "        target_names=classes,\n",
    "        zero_division=0\n",
    "    ) \n",
    "\n",
    "    return {\n",
    "        'accuracy': hamming_accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'report': report\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d214bac6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T14:35:11.175814Z",
     "iopub.status.busy": "2025-03-25T14:35:11.175582Z",
     "iopub.status.idle": "2025-03-25T14:35:11.182300Z",
     "shell.execute_reply": "2025-03-25T14:35:11.181487Z"
    },
    "papermill": {
     "duration": 0.02159,
     "end_time": "2025-03-25T14:35:11.183664",
     "exception": false,
     "start_time": "2025-03-25T14:35:11.162074",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics_overall(p, classes):\n",
    "    preds = torch.tensor(p.predictions)\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Ensure it's in the correct shape\n",
    "    if preds.shape != labels.shape:\n",
    "        raise ValueError(\"Shape mismatch: predictions and labels must have the same shape.\")\n",
    "\n",
    "    # Hamming accuracy: proportion of correctly predicted labels over total labels\n",
    "    hamming_accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Compute per-label (column-wise) precision, recall, F1\n",
    "    precision_list, recall_list, f1_micro_list, f1_macro_list = [], [], [], []\n",
    "    \n",
    "    for i in range(labels.shape[1]):  # Loop through each column (multi-output)\n",
    "        prec, rec, f1_micro, _ = precision_recall_fscore_support(\n",
    "            labels[:, i], preds[:, i], average='micro', zero_division=0\n",
    "        )\n",
    "        _, _, f1_macro, _ = precision_recall_fscore_support(\n",
    "            labels[:, i], preds[:, i], average='macro', zero_division=0\n",
    "        )\n",
    "\n",
    "        precision_list.append(prec)\n",
    "        recall_list.append(rec)\n",
    "        f1_micro_list.append(f1_micro)\n",
    "        f1_macro_list.append(f1_macro)\n",
    "\n",
    "    # Compute average metrics across all outputs\n",
    "    precision = sum(precision_list) / len(precision_list)\n",
    "    recall = sum(recall_list) / len(recall_list)\n",
    "    f1_micro = sum(f1_micro_list) / len(f1_micro_list)\n",
    "    f1_macro = sum(f1_macro_list) / len(f1_macro_list)\n",
    "\n",
    "    # Generate classification report per output\n",
    "    reports = [classification_report(labels[:, i], preds[:, i], target_names=classes, zero_division=0) for i in range(labels.shape[1])]\n",
    "\n",
    "    return {\n",
    "        'accuracy': hamming_accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'reports': reports  # Returns list of reports, one for each output label\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63d52e50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T14:35:11.211125Z",
     "iopub.status.busy": "2025-03-25T14:35:11.210915Z",
     "iopub.status.idle": "2025-03-25T14:35:11.239128Z",
     "shell.execute_reply": "2025-03-25T14:35:11.238484Z"
    },
    "papermill": {
     "duration": 0.043597,
     "end_time": "2025-03-25T14:35:11.240406",
     "exception": false,
     "start_time": "2025-03-25T14:35:11.196809",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(current_train_size, train_indices, aspect_metrics, sentiment_metrics, metrics, trials, seed):\n",
    "    accelerator = Accelerator(mixed_precision='fp16')  # Initialize the accelerator\n",
    "    device = accelerator.device\n",
    "\n",
    "    aspect_model = BertForSequenceClassification.from_pretrained(\n",
    "        'indobenchmark/indobert-base-p1',\n",
    "        num_labels=len(train_labels),\n",
    "        problem_type=\"multi_label_classification\"\n",
    "    )\n",
    "\n",
    "    # Freeze the first few layers of the encoder\n",
    "    for name, param in aspect_model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    # Define optimizer and loss function\n",
    "    aspect_optimizer = torch.optim.AdamW(aspect_model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Define DataLoaders\n",
    "    current_X_train = [X_train[i] for i in train_indices]\n",
    "    current_y_train = [y_train[i] for i in train_indices]\n",
    "    aspect_train_loader, aspect_val_loader, aspect_train_dataset, aspect_val_dataset = build_aspect_dataset(current_X_train, current_y_train, X_val, y_val, sequence_length)\n",
    "\n",
    "    # Prepare everything with Accelerator\n",
    "    aspect_model, aspect_optimizer, aspect_train_loader, aspect_val_loader = accelerator.prepare(\n",
    "        aspect_model, aspect_optimizer, aspect_train_loader, aspect_val_loader\n",
    "    )\n",
    "\n",
    "    aspect_result = None\n",
    "    start_time = time.time()\n",
    "\n",
    "    # ASPECT DETECTION\n",
    "    accelerator.print(\"ASPECT DETECTION\")\n",
    "    for epoch in range(epochs):\n",
    "        aspect_model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for batch in aspect_train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels']\n",
    "        \n",
    "            aspect_optimizer.zero_grad()\n",
    "            outputs = aspect_model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            aspect_optimizer.step()\n",
    "        \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "        aspect_model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in aspect_val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "                labels = batch['labels']\n",
    "                \n",
    "                outputs = aspect_model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                # Gather predictions and labels from all devices\n",
    "                all_preds.append(accelerator.gather(preds))\n",
    "                all_labels.append(accelerator.gather(labels))\n",
    "\n",
    "        all_preds = torch.cat(all_preds).cpu().numpy()\n",
    "        all_labels = torch.cat(all_labels).cpu().numpy()\n",
    "\n",
    "        result = compute_metrics(\n",
    "            type('EvalOutput', (object,), {'predictions': all_preds, 'label_ids': all_labels}),\n",
    "            None,\n",
    "            ['fuel', 'machine', 'others', 'part', 'price', 'service']\n",
    "        )\n",
    "\n",
    "        if aspect_result is None or result['f1_micro'] >= aspect_result['f1_micro']:\n",
    "            accelerator.print(\"Higher F1 achieved, saving model\")\n",
    "            \n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(aspect_model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                f'{filename}-aspect-{trials + 1}-model',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "            aspect_result = result\n",
    "\n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(aspect_train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "\n",
    "    accelerator.print(f\"\\nAspect detection accuracy: {round(aspect_result['accuracy'], 4)}, F1 Micro: {round(aspect_result['f1_micro'], 4)}, F1 Macro: {round(aspect_result['f1_macro'], 4)}\")\n",
    "    accelerator.print(aspect_result['report'])\n",
    "\n",
    "    best_aspect_model = BertForSequenceClassification.from_pretrained(f'{filename}-aspect-{trials + 1}-model')\n",
    "    best_aspect_model = accelerator.prepare(best_aspect_model)\n",
    "\n",
    "    # SENTIMENT ANALYSIS ON NON NEUTRAL ASPECTS\n",
    "    accelerator.print(\"--------------------------------------------------\")\n",
    "    accelerator.print(\"SENTIMENT ANALYSIS\")\n",
    "\n",
    "    sentiment_model = BertForSequenceClassification.from_pretrained(\n",
    "        'indobenchmark/indobert-base-p1',\n",
    "        num_labels=2,\n",
    "    )\n",
    "    sentiment_optimizer = torch.optim.AdamW(sentiment_model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "\n",
    "    for name, param in sentiment_model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    sentiment_train_loader, sentiment_val_loader, sentiment_train_dataset, sentiment_val_dataset = build_sentiment_dataset(\n",
    "        device, aspect_train_dataset, aspect_val_dataset, best_aspect_model, tokenizer, max_length=sequence_length\n",
    "    )\n",
    "    sentiment_model, sentiment_optimizer, sentiment_train_loader, sentiment_val_loader = accelerator.prepare(\n",
    "        sentiment_model, sentiment_optimizer, sentiment_train_loader, sentiment_val_loader\n",
    "    )\n",
    "    sentiment_result = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        sentiment_model.train()\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for batch in sentiment_train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels']\n",
    "        \n",
    "            sentiment_optimizer.zero_grad()\n",
    "            outputs = sentiment_model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            sentiment_optimizer.step()\n",
    "        \n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        sentiment_model.eval()\n",
    "        sentiment_val_outputs = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in sentiment_val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "                \n",
    "                outputs = sentiment_model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                for i in range(len(preds)):\n",
    "                    val_output = {\n",
    "                        'label': batch['labels'][i],\n",
    "                        'aspect': batch['aspect'][i],\n",
    "                        'ori_indices': batch['ori_indices'][i],\n",
    "                        'pred': np.argmax(preds[i].cpu().numpy()),\n",
    "                    }\n",
    "                    sentiment_val_outputs.append(val_output)\n",
    "\n",
    "        sentiment_val_outputs = accelerator.gather_for_metrics(sentiment_val_outputs)\n",
    "        unique_val_outputs = {(x['ori_indices'].item(), x['aspect']): x for x in sentiment_val_outputs}\n",
    "        sentiment_val_outputs = list(unique_val_outputs.values())\n",
    "\n",
    "        result = compute_metrics(\n",
    "            type('EvalOutput', (object,), {'predictions': [item['pred'] for item in sentiment_val_outputs], 'label_ids': [np.argmax(item['label'].cpu().numpy()) for item in sentiment_val_outputs]}),\n",
    "            [0, 1],\n",
    "            ['negative', 'positive']\n",
    "        )\n",
    "\n",
    "        if sentiment_result is None or result['f1_micro'] >= sentiment_result['f1_micro']:\n",
    "            accelerator.print(\"Higher F1 achieved, saving model\")\n",
    "            sentiment_result = result\n",
    "            \n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(sentiment_model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                 f'{filename}-sentiment-{trials + 1}-model',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "\n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(sentiment_train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "\n",
    "    accelerator.print(f\"\\nSentiment analysis accuracy: {round(sentiment_result['accuracy'], 4)}, F1 Micro: {round(sentiment_result['f1_micro'], 4)}, F1 Macro: {round(sentiment_result['f1_macro'], 4)}\")\n",
    "    accelerator.print(sentiment_result['report'])\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    best_sentiment_model = BertForSequenceClassification.from_pretrained( f'{filename}-sentiment-{trials + 1}-model')\n",
    "    best_sentiment_model = accelerator.prepare(best_sentiment_model)\n",
    "\n",
    "    # Compute overall metrics\n",
    "    aspect_labels = []\n",
    "    aspect_indices = []\n",
    "    aspect_preds = []\n",
    "\n",
    "    aspect_outputs = {}\n",
    "    sentiment_outputs = []\n",
    "    \n",
    "    best_aspect_model.eval()\n",
    "    best_sentiment_model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in aspect_val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            outputs = best_aspect_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            aspect_indices.append(accelerator.gather(batch['ori_indices']))\n",
    "            aspect_labels.append(accelerator.gather(batch['ori_label']))\n",
    "            aspect_preds.append(accelerator.gather(preds))\n",
    "\n",
    "        aspect_indices = torch.cat(aspect_indices).cpu().numpy()\n",
    "        aspect_labels = torch.cat(aspect_labels).cpu().numpy()\n",
    "        aspect_preds = torch.cat(aspect_preds).cpu().numpy()\n",
    "\n",
    "        accelerator.wait_for_everyone()\n",
    "        aspect_outputs = [\n",
    "            {'ori_indices': aspect_indices[i], \n",
    "             'ori_labels': aspect_labels[i], \n",
    "             'pred': aspect_preds[i]}\n",
    "            for i in range(len(aspect_preds))\n",
    "        ]\n",
    "        aspect_outputs = {x['ori_indices'].item(): x for x in aspect_outputs}\n",
    "    \n",
    "        for batch in sentiment_val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            outputs = best_sentiment_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "    \n",
    "            for i in range(len(preds)):\n",
    "                output = {\n",
    "                    'aspect': batch['aspect'][i],\n",
    "                    'ori_indices': batch['ori_indices'][i],\n",
    "                    'pred': np.argmax(preds[i].cpu().numpy()),\n",
    "                }\n",
    "                sentiment_outputs.append(output)\n",
    "\n",
    "        sentiment_outputs = accelerator.gather_for_metrics(sentiment_outputs)\n",
    "        sentiment_outputs = {(x['ori_indices'].item(), x['aspect']): x for x in sentiment_outputs}\n",
    "\n",
    "    # Replcae non neutral aspect to its predicted sentiment\n",
    "    accelerator.wait_for_everyone()\n",
    "    if accelerator.is_main_process:\n",
    "        i = -1\n",
    "        for (ori_index, aspect), value in sentiment_outputs.items():\n",
    "            aspect = aspect_mapping[aspect]\n",
    "            aspect_outputs[ori_index]['pred'][aspect] = 2 if value['pred'] == 1.0 else value['pred']\n",
    "\n",
    "        result = compute_metrics_overall(\n",
    "            type('EvalOutput', (object,), {'predictions': [output['pred'] for output in aspect_outputs.values()], 'label_ids': [output['ori_labels'] for output in aspect_outputs.values()]}),\n",
    "            ['negative', 'neutral', 'positive'],\n",
    "        )\n",
    "\n",
    "        accelerator.print(\"--------------------------------------------------\")\n",
    "        accelerator.print(f\"Iteration {current_train_size}: Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "        accelerator.print(\"--------------------------------------------------\")\n",
    "        for i in range(len(train_labels)):\n",
    "            accelerator.print(f\"Aspect {aspect_list[i]} report:\")\n",
    "            accelerator.print(result['reports'][i])\n",
    "       \n",
    "        \n",
    "        aspect_metrics[0].append(aspect_result['accuracy'])\n",
    "        aspect_metrics[1].append(aspect_result['f1_micro'])\n",
    "        aspect_metrics[2].append(aspect_result['f1_macro'])\n",
    "        sentiment_metrics[0].append(sentiment_result['accuracy'])\n",
    "        sentiment_metrics[1].append(sentiment_result['f1_micro'])\n",
    "        sentiment_metrics[2].append(sentiment_result['f1_macro'])\n",
    "        metrics[0].append(current_train_size)\n",
    "        metrics[1].append(result['accuracy'])\n",
    "        metrics[2].append(result['f1_micro'])\n",
    "        metrics[3].append(result['f1_macro'])\n",
    "        \n",
    "    accelerator.print(f\"Total train time: {duration} s\")\n",
    "    accelerator.end_training()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7990d49",
   "metadata": {
    "papermill": {
     "duration": 0.013335,
     "end_time": "2025-03-25T14:35:11.267504",
     "exception": false,
     "start_time": "2025-03-25T14:35:11.254169",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PLOT THE RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "345ccf6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T14:35:11.294617Z",
     "iopub.status.busy": "2025-03-25T14:35:11.294266Z",
     "iopub.status.idle": "2025-03-25T14:35:11.300598Z",
     "shell.execute_reply": "2025-03-25T14:35:11.299906Z"
    },
    "papermill": {
     "duration": 0.021294,
     "end_time": "2025-03-25T14:35:11.301954",
     "exception": false,
     "start_time": "2025-03-25T14:35:11.280660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_result(data_used, accuracies, f1_micros, f1_macros):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(21, 5))\n",
    "    data_used = [round(data / total_data * 100, 1) for data in data_used]\n",
    "\n",
    "    # Plot for Accuracy\n",
    "    axs[0].plot(data_used, accuracies, label=\"Accuracy\", color=\"blue\")\n",
    "    axs[0].set_xlabel(\"Percentage of data used\")\n",
    "    axs[0].set_title(\"Accuracy\")\n",
    "    axs[0].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Micro\n",
    "    axs[1].plot(data_used, f1_micros, label=\"F1 Micro\", color=\"orange\")\n",
    "    axs[1].set_xlabel(\"Percentage of data used\")\n",
    "    axs[1].set_title(\"F1 Micro\")\n",
    "    axs[1].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Macro\n",
    "    axs[2].plot(data_used, f1_macros, label=\"F1 Macro\", color=\"green\")\n",
    "    axs[2].set_xlabel(\"Percentage of data used\")\n",
    "    axs[2].set_title(\"F1 Macro\")\n",
    "    axs[2].set_xticks(data_used)\n",
    "\n",
    "    # Adjust layout and show the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4648c0d",
   "metadata": {
    "papermill": {
     "duration": 0.012638,
     "end_time": "2025-03-25T14:35:11.327333",
     "exception": false,
     "start_time": "2025-03-25T14:35:11.314695",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# QUERY STRATEGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e878b17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T14:35:11.354051Z",
     "iopub.status.busy": "2025-03-25T14:35:11.353784Z",
     "iopub.status.idle": "2025-03-25T14:35:11.374437Z",
     "shell.execute_reply": "2025-03-25T14:35:11.373784Z"
    },
    "papermill": {
     "duration": 0.03573,
     "end_time": "2025-03-25T14:35:11.375828",
     "exception": false,
     "start_time": "2025-03-25T14:35:11.340098",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def kmeans_clustering_sampling(aspect_model, sentiment_model, X_pool, train_indices, remaining_indices, sampling_dur, new_samples, trials, n_clusters=min_increment):\n",
    "    accelerator = Accelerator(mixed_precision=\"fp16\")\n",
    "    device = accelerator.device\n",
    "\n",
    "    aspect_model.to(device)\n",
    "    aspect_model.eval()\n",
    "    sentiment_model.to(device)\n",
    "    sentiment_model.eval()\n",
    "\n",
    "    current_train_size = len(train_indices)\n",
    "    aspect_dataset = AspectDetectionDataset(\n",
    "        X_pool, \n",
    "        [['neutral' for i in range(len(train_labels))] for x in range(len(X_pool))], \n",
    "        label_mapping, \n",
    "        tokenizer, \n",
    "        max_length=sequence_length\n",
    "    )\n",
    "    aspect_loader = DataLoader(\n",
    "        aspect_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    \n",
    "    aspect_outputs = {}\n",
    "    sentiment_outputs = {}\n",
    "\n",
    "    aspects = []\n",
    "    data = []\n",
    "    labels = []\n",
    "    indices = []\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Pass through aspect detction model\n",
    "    for batch in aspect_loader:\n",
    "        token_type_ids = batch['token_type_ids'].to(device, non_blocking=True)\n",
    "        input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "        attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = aspect_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids).logits\n",
    "            embeddings = aspect_model.base_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "\n",
    "        for i in range(len(outputs)):\n",
    "            aspect_outputs[batch['ori_indices'][i].item()] = embeddings.last_hidden_state[i].mean(dim=1).cpu().numpy()\n",
    "            \n",
    "            for j in range(len(outputs[i])):\n",
    "                if int(outputs[i][j].round()) != 1:\n",
    "                    aspects.append(aspect_list[j])\n",
    "                    data.append(batch['ori_text'][i])\n",
    "                    labels.append(batch['ori_label'][i][j])\n",
    "                    indices.append(batch['ori_indices'][i])\n",
    "\n",
    "    if len(data) > 0:\n",
    "        sentiment_dataset = SentimentAnalysisDataset(data, labels, aspects, indices, label_mapping, tokenizer, max_length=sequence_length)\n",
    "        sentiment_loader = torch.utils.data.DataLoader(\n",
    "            sentiment_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4,\n",
    "        )\n",
    "    \n",
    "        # Pass through sentiment analysis model\n",
    "        for batch in sentiment_loader:\n",
    "            token_type_ids = batch['token_type_ids'].to(device, non_blocking=True)\n",
    "            input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "            attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "    \n",
    "            with torch.no_grad():\n",
    "                outputs = sentiment_model.base_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "    \n",
    "            for i in range(len(outputs.last_hidden_state)):\n",
    "                ori_index = batch['ori_indices'][i].item()\n",
    "                if ori_index in sentiment_outputs.keys():\n",
    "                    sentiment_outputs[ori_index].append(outputs.last_hidden_state[i].mean(dim=1).cpu().numpy())\n",
    "                else:\n",
    "                    sentiment_outputs[ori_index] = [outputs.last_hidden_state[i].mean(dim=1).cpu().numpy()]\n",
    "\n",
    "    for key, val in sentiment_outputs.items():\n",
    "        sentiment_outputs[key] = np.mean(val, axis=0)\n",
    "\n",
    "    collected_indices = set()  # Initialize set to store selected indices\n",
    "    thresholds = []\n",
    "\n",
    "    if accelerator.is_main_process:\n",
    "        aspect_outputs = dict(sorted(aspect_outputs.items()))\n",
    "\n",
    "        if len(data) > 0:\n",
    "            for key, val in sentiment_outputs.items():\n",
    "                aspect_outputs[key] = np.mean([val, aspect_outputs[key]], axis=0)\n",
    "\n",
    "        embeddings = np.array(list(aspect_outputs.values()))\n",
    "        target_samples = len(embeddings[:math.ceil(0.1 * len(embeddings))])\n",
    "    \n",
    "        # Check nearest checkpoint\n",
    "        nearest_cp = 0\n",
    "        arrived_at_cp = False\n",
    "        for cp in checkpoints:\n",
    "            if cp > current_train_size:\n",
    "                nearest_cp = cp\n",
    "                break\n",
    "                \n",
    "        # Determine number of maximum samples to be acquired\n",
    "        if target_samples <= n_clusters and n_clusters < nearest_cp - current_train_size:\n",
    "            target_samples = n_clusters\n",
    "        elif target_samples > n_clusters and target_samples < nearest_cp - current_train_size:\n",
    "            target_samples = target_samples\n",
    "        else:\n",
    "            arrived_at_cp = True\n",
    "            target_samples = nearest_cp - current_train_size\n",
    "\n",
    "        # No clustering needed when there's little data left\n",
    "        if current_train_size >= checkpoints[len(checkpoints)-1] - min_increment:\n",
    "            end_time = time.time()\n",
    "            duration = end_time - start_time\n",
    "            \n",
    "            temp = train_indices.copy()\n",
    "            temp.extend(remaining_indices)\n",
    "            \n",
    "            # Save acquired data up to checkpoint\n",
    "            acquired_data = pd.DataFrame({\n",
    "                'processed_text': [X_train[i] for i in temp],\n",
    "                'fuel': [y_train[i][0] for i in temp],\n",
    "                'machine': [y_train[i][1] for i in temp],\n",
    "                'others': [y_train[i][2] for i in temp],\n",
    "                'part': [y_train[i][3] for i in temp],\n",
    "                'price': [y_train[i][4] for i in temp],\n",
    "                'service': [y_train[i][5] for i in temp],\n",
    "            })\n",
    "            acquired_data.to_csv(f'acquired_data/{filename}-{trials+1}-data-{nearest_cp}.csv', index=False)\n",
    "\n",
    "            print(\"Nearest checkpoint:\", nearest_cp)\n",
    "            print(\"Acquired samples:\", len(remaining_indices))\n",
    "            print(f\"Sampling duration: {duration} seconds\")\n",
    "            \n",
    "            sampling_dur.append(duration)\n",
    "            for i in remaining_indices:\n",
    "                new_samples.append(i)\n",
    "        else:\n",
    "            # Cluster the data based on its embeddings\n",
    "            kmeans=KMeans(n_clusters=n_clusters, n_init=1)\n",
    "            kmeans.fit(embeddings)\n",
    "            \n",
    "            for cluster_id in range(n_clusters):\n",
    "                # Cluster center and indices of samples in the current cluster\n",
    "                cluster_center = kmeans.cluster_centers_[cluster_id]\n",
    "                cluster_indices = np.where(kmeans.labels_ == cluster_id)[0]\n",
    "            \n",
    "                if cluster_indices.size == 0:\n",
    "                    # Skip clusters with no members\n",
    "                    print(f\"Cluster {cluster_id} has no members, skipping.\")\n",
    "                    continue\n",
    "            \n",
    "                # Calculate distances of each point in the cluster from the cluster center\n",
    "                cluster_distances = np.linalg.norm(embeddings[cluster_indices] - cluster_center, axis=1)\n",
    "            \n",
    "                # Determine the local threshold (10th percentile of closest distances to cluster center)\n",
    "                local_threshold = np.percentile(cluster_distances, 10)\n",
    "                thresholds.append(local_threshold)\n",
    "            \n",
    "                below_threshold_indices = cluster_indices[cluster_distances <= local_threshold]\n",
    "                collected_indices.update(below_threshold_indices)\n",
    "\n",
    "            # To handle multiple points with same distance\n",
    "            if len(collected_indices) > target_samples:\n",
    "                collected_indices = np.array(list(collected_indices))\n",
    "                np.random.shuffle(collected_indices)\n",
    "                collected_indices = collected_indices[:target_samples]\n",
    "                \n",
    "            end_time = time.time() \n",
    "            duration = end_time - start_time \n",
    "    \n",
    "            if arrived_at_cp:\n",
    "                temp = train_indices.copy()\n",
    "                temp.extend(collected_indices)\n",
    "                \n",
    "                # Save acquired data up to checkpoint\n",
    "                acquired_data = pd.DataFrame({\n",
    "                    'processed_text': [X_train[i] for i in temp],\n",
    "                    'fuel': [y_train[i][0] for i in temp],\n",
    "                    'machine': [y_train[i][1] for i in temp],\n",
    "                    'others': [y_train[i][2] for i in temp],\n",
    "                    'part': [y_train[i][3] for i in temp],\n",
    "                    'price': [y_train[i][4] for i in temp],\n",
    "                    'service': [y_train[i][5] for i in temp],\n",
    "                })\n",
    "        \n",
    "                acquired_data.to_csv(f'acquired_data/{filename}-{trials+1}-data-{nearest_cp}.csv', index=False)\n",
    "            \n",
    "            print(\"Nearest checkpoint:\", nearest_cp)\n",
    "            print(\"Acquired samples:\", len(collected_indices))\n",
    "            print(f\"Sampling duration: {duration} seconds\")\n",
    "        \n",
    "            sampling_dur.append(duration)\n",
    "            for i in collected_indices:\n",
    "                new_samples.append(remaining_indices[i])\n",
    "\n",
    "        threshold_data = pd.DataFrame({\n",
    "            'Threshold': thresholds\n",
    "        })\n",
    "        threshold_data.to_csv(f\"results/{filename}-thresholds-{trials+1}-{current_train_size}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5781260e",
   "metadata": {
    "papermill": {
     "duration": 0.0126,
     "end_time": "2025-03-25T14:35:11.401105",
     "exception": false,
     "start_time": "2025-03-25T14:35:11.388505",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MAIN LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c69723d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T14:35:11.427878Z",
     "iopub.status.busy": "2025-03-25T14:35:11.427624Z",
     "iopub.status.idle": "2025-03-25T14:35:11.437287Z",
     "shell.execute_reply": "2025-03-25T14:35:11.436597Z"
    },
    "papermill": {
     "duration": 0.024633,
     "end_time": "2025-03-25T14:35:11.438468",
     "exception": false,
     "start_time": "2025-03-25T14:35:11.413835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def active_learning(seed, i):\n",
    "    aspect_accuracies = manager.list()\n",
    "    aspect_f1_micros = manager.list()\n",
    "    aspect_f1_macros = manager.list()\n",
    "    sentiment_accuracies = manager.list()\n",
    "    sentiment_f1_micros = manager.list()\n",
    "    sentiment_f1_macros = manager.list()\n",
    "    accuracies = manager.list()\n",
    "    f1_micros = manager.list()\n",
    "    f1_macros = manager.list()\n",
    "    data_used = manager.list()\n",
    "    sampling_dur = manager.list()\n",
    "    new_samples = manager.list()\n",
    "\n",
    "    set_seed(seed)\n",
    "    \n",
    "    print(\"===============================================\")\n",
    "    print(\"TRIAL {}\".format(i+1))\n",
    "    print(\"Random seed:\", seed)\n",
    "    \n",
    "    train_indices = np.random.choice(range(len(X_train)), initial_train_size, replace=False).tolist()\n",
    "    remaining_indices = list(set(range(len(X_train))) - set(train_indices))\n",
    "    \n",
    "    current_train_size = initial_train_size\n",
    "    \n",
    "    start_time = time.time()\n",
    "    while current_train_size < checkpoints[len(checkpoints) - 1]:\n",
    "        # Train the model\n",
    "        args = (\n",
    "            current_train_size, \n",
    "            train_indices, \n",
    "            (aspect_accuracies, aspect_f1_micros, aspect_f1_macros), \n",
    "            (sentiment_accuracies, sentiment_f1_micros, sentiment_f1_macros),\n",
    "            (data_used, accuracies, f1_micros, f1_macros), \n",
    "            i,\n",
    "            seed\n",
    "        )\n",
    "        notebook_launcher(train_model, args, num_processes=2)\n",
    "\n",
    "        aspect_model = BertForSequenceClassification.from_pretrained(f'{filename}-aspect-{i+1}-model')\n",
    "        sentiment_model = BertForSequenceClassification.from_pretrained(f'{filename}-sentiment-{i+1}-model')\n",
    "    \n",
    "        # Perform query strategy to select new samples\n",
    "        new_samples = manager.list()\n",
    "        sampling_args = (\n",
    "            aspect_model, \n",
    "            sentiment_model, \n",
    "            [X_train[i] for i in remaining_indices], \n",
    "            train_indices, \n",
    "            remaining_indices, \n",
    "            sampling_dur, \n",
    "            new_samples, \n",
    "            i\n",
    "        )\n",
    "        notebook_launcher(kmeans_clustering_sampling, sampling_args, num_processes=2)\n",
    "        new_samples = list(new_samples)\n",
    "        train_indices.extend(new_samples)\n",
    "        remaining_indices = list(set(remaining_indices) - set(new_samples))\n",
    "    \n",
    "        # Update current training size\n",
    "        current_train_size = len(train_indices)\n",
    "        print(\"New train size: {}\".format(current_train_size))\n",
    "    \n",
    "    # Train last epoch\n",
    "    args = (\n",
    "        current_train_size, \n",
    "        train_indices, \n",
    "        (aspect_accuracies, aspect_f1_micros, aspect_f1_macros), \n",
    "        (sentiment_accuracies, sentiment_f1_micros, sentiment_f1_macros),\n",
    "        (data_used, accuracies, f1_micros, f1_macros), \n",
    "        i,\n",
    "        seed\n",
    "    )\n",
    "    notebook_launcher(train_model, args, num_processes=2)\n",
    "    data_used, accuracies, f1_micros, f1_macros, sampling_dur = list(data_used), list(accuracies), list(f1_micros), list(f1_macros), list(sampling_dur)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    # print(f\"Total sampling time: {np.array(sampling_dur).sum().round(2)} seconds\")\n",
    "    print(f\"Total runtime: {duration} seconds\")\n",
    "    \n",
    "    plot_result(data_used, accuracies, f1_micros, f1_macros)\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        'Data Used': data_used,\n",
    "        'Aspect Accuracy': aspect_accuracies,\n",
    "        'Aspect F1 Micro': aspect_f1_micros,\n",
    "        'Aspect F1 Macro': aspect_f1_macros,\n",
    "        'Sentiment Accuracy': sentiment_accuracies,\n",
    "        'Sentiment F1 Micro': sentiment_f1_micros,\n",
    "        'Sentiment F1 Macro': sentiment_f1_macros,\n",
    "        'Accuracy': accuracies,\n",
    "        'F1 Micro': f1_micros,\n",
    "        'F1 Macro': f1_macros,\n",
    "    })\n",
    "    \n",
    "    sampling_dur.insert(0, 0)\n",
    "    results['Sampling Duration'] = sampling_dur\n",
    "    results.to_csv(f'results/{filename}-{i+1}-results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2bccd91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T14:35:11.465200Z",
     "iopub.status.busy": "2025-03-25T14:35:11.464953Z",
     "iopub.status.idle": "2025-03-25T14:35:11.468370Z",
     "shell.execute_reply": "2025-03-25T14:35:11.467709Z"
    },
    "papermill": {
     "duration": 0.018053,
     "end_time": "2025-03-25T14:35:11.469597",
     "exception": false,
     "start_time": "2025-03-25T14:35:11.451544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seeds = [50, 81, 14, 3, 94]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bd3ee3",
   "metadata": {
    "papermill": {
     "duration": 0.013691,
     "end_time": "2025-03-25T14:35:11.495901",
     "exception": false,
     "start_time": "2025-03-25T14:35:11.482210",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0df40b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T14:35:11.523463Z",
     "iopub.status.busy": "2025-03-25T14:35:11.523111Z",
     "iopub.status.idle": "2025-03-25T15:22:37.007078Z",
     "shell.execute_reply": "2025-03-25T15:22:37.006207Z"
    },
    "papermill": {
     "duration": 2845.499848,
     "end_time": "2025-03-25T15:22:37.008699",
     "exception": false,
     "start_time": "2025-03-25T14:35:11.508851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 1\n",
      "Random seed: 50\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6756, Accuracy: 0.7731, F1 Micro: 0.8711, F1 Macro: 0.8698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5958, Accuracy: 0.7887, F1 Micro: 0.8819, F1 Macro: 0.8804\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5785, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.513, Accuracy: 0.7939, F1 Micro: 0.8843, F1 Macro: 0.8828\n",
      "Epoch 5/10, Train Loss: 0.5006, Accuracy: 0.7924, F1 Micro: 0.8829, F1 Macro: 0.881\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4695, Accuracy: 0.7954, F1 Micro: 0.8846, F1 Macro: 0.8828\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4328, Accuracy: 0.7969, F1 Micro: 0.8857, F1 Macro: 0.8842\n",
      "Epoch 8/10, Train Loss: 0.4369, Accuracy: 0.7932, F1 Micro: 0.8832, F1 Macro: 0.8812\n",
      "Epoch 9/10, Train Loss: 0.415, Accuracy: 0.7917, F1 Micro: 0.8816, F1 Macro: 0.8789\n",
      "Epoch 10/10, Train Loss: 0.3884, Accuracy: 0.7894, F1 Micro: 0.88, F1 Macro: 0.8769\n",
      "\n",
      "Aspect detection accuracy: 0.7969, F1 Micro: 0.8857, F1 Macro: 0.8842\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.78      1.00      0.88       175\n",
      "      others       0.71      1.00      0.83       158\n",
      "        part       0.75      0.98      0.85       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.80      1.00      0.89      1061\n",
      "   macro avg       0.80      1.00      0.88      1061\n",
      "weighted avg       0.80      1.00      0.89      1061\n",
      " samples avg       0.80      1.00      0.88      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7162, Accuracy: 0.2857, F1 Micro: 0.2857, F1 Macro: 0.2222\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.6764, Accuracy: 0.5, F1 Micro: 0.5, F1 Macro: 0.4974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.6621, Accuracy: 0.7143, F1 Micro: 0.7143, F1 Macro: 0.65\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.6053, Accuracy: 0.7857, F1 Micro: 0.7857, F1 Macro: 0.7143\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.5803, Accuracy: 0.7857, F1 Micro: 0.7857, F1 Macro: 0.7143\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.5674, Accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.825\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4789, Accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.825\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4895, Accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.825\n",
      "Epoch 9/10, Train Loss: 0.4054, Accuracy: 0.7143, F1 Micro: 0.7143, F1 Macro: 0.6889\n",
      "Epoch 10/10, Train Loss: 0.3482, Accuracy: 0.5, F1 Micro: 0.5, F1 Macro: 0.4974\n",
      "\n",
      "Sentiment analysis accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.825\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75         4\n",
      "    positive       0.90      0.90      0.90        10\n",
      "\n",
      "    accuracy                           0.86        14\n",
      "   macro avg       0.82      0.82      0.82        14\n",
      "weighted avg       0.86      0.86      0.86        14\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.794, F1 Micro: 0.794, F1 Macro: 0.3199\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.77      1.00      0.87       167\n",
      "    positive       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.77       216\n",
      "   macro avg       0.26      0.33      0.29       216\n",
      "weighted avg       0.60      0.77      0.67       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.70      1.00      0.83       152\n",
      "    positive       0.00      0.00      0.00        52\n",
      "\n",
      "    accuracy                           0.70       216\n",
      "   macro avg       0.23      0.33      0.28       216\n",
      "weighted avg       0.50      0.70      0.58       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.13      0.22        23\n",
      "     neutral       0.74      0.98      0.84       152\n",
      "    positive       0.60      0.15      0.24        41\n",
      "\n",
      "    accuracy                           0.73       216\n",
      "   macro avg       0.70      0.42      0.43       216\n",
      "weighted avg       0.71      0.73      0.66       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 55.842485189437866 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 81\n",
      "Sampling duration: 9.887312173843384 seconds\n",
      "New train size: 135\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6396, Accuracy: 0.7887, F1 Micro: 0.8819, F1 Macro: 0.8804\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5592, Accuracy: 0.7917, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5227, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Epoch 4/10, Train Loss: 0.5045, Accuracy: 0.7917, F1 Micro: 0.8833, F1 Macro: 0.8819\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4576, Accuracy: 0.8051, F1 Micro: 0.8898, F1 Macro: 0.8885\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4176, Accuracy: 0.817, F1 Micro: 0.8954, F1 Macro: 0.8943\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.412, Accuracy: 0.8371, F1 Micro: 0.9046, F1 Macro: 0.9035\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3537, Accuracy: 0.8549, F1 Micro: 0.9141, F1 Macro: 0.913\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3009, Accuracy: 0.8735, F1 Micro: 0.9246, F1 Macro: 0.9234\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2784, Accuracy: 0.904, F1 Micro: 0.9415, F1 Macro: 0.94\n",
      "\n",
      "Aspect detection accuracy: 0.904, F1 Micro: 0.9415, F1 Macro: 0.94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.92      0.99      0.96       187\n",
      "     machine       0.94      0.93      0.93       175\n",
      "      others       0.82      0.99      0.90       158\n",
      "        part       0.87      0.96      0.92       158\n",
      "       price       0.93      0.99      0.96       192\n",
      "     service       0.95      1.00      0.97       191\n",
      "\n",
      "   micro avg       0.91      0.98      0.94      1061\n",
      "   macro avg       0.91      0.98      0.94      1061\n",
      "weighted avg       0.91      0.98      0.94      1061\n",
      " samples avg       0.91      0.98      0.94      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6601, Accuracy: 0.7053, F1 Micro: 0.7053, F1 Macro: 0.4136\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4924, Accuracy: 0.7053, F1 Micro: 0.7053, F1 Macro: 0.4136\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4551, Accuracy: 0.8895, F1 Micro: 0.8895, F1 Macro: 0.8649\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3052, Accuracy: 0.8947, F1 Micro: 0.8947, F1 Macro: 0.8771\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2396, Accuracy: 0.9, F1 Micro: 0.9, F1 Macro: 0.8827\n",
      "Epoch 6/10, Train Loss: 0.1603, Accuracy: 0.8895, F1 Micro: 0.8895, F1 Macro: 0.8758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1073, Accuracy: 0.9053, F1 Micro: 0.9053, F1 Macro: 0.8894\n",
      "Epoch 8/10, Train Loss: 0.1067, Accuracy: 0.8789, F1 Micro: 0.8789, F1 Macro: 0.8629\n",
      "Epoch 9/10, Train Loss: 0.0612, Accuracy: 0.9, F1 Micro: 0.9, F1 Macro: 0.8764\n",
      "Epoch 10/10, Train Loss: 0.0557, Accuracy: 0.8421, F1 Micro: 0.8421, F1 Macro: 0.8304\n",
      "\n",
      "Sentiment analysis accuracy: 0.9053, F1 Micro: 0.9053, F1 Macro: 0.8894\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.89      0.85        56\n",
      "    positive       0.95      0.91      0.93       134\n",
      "\n",
      "    accuracy                           0.91       190\n",
      "   macro avg       0.88      0.90      0.89       190\n",
      "weighted avg       0.91      0.91      0.91       190\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 135: Accuracy: 0.892, F1 Micro: 0.892, F1 Macro: 0.753\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.27      0.40        11\n",
      "     neutral       0.92      0.99      0.96       181\n",
      "    positive       0.94      0.67      0.78        24\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.87      0.64      0.71       216\n",
      "weighted avg       0.92      0.92      0.91       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.69      0.76        16\n",
      "     neutral       0.93      0.93      0.93       167\n",
      "    positive       0.67      0.73      0.70        33\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.82      0.78      0.80       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.54      0.58      0.56        12\n",
      "     neutral       0.83      0.99      0.90       152\n",
      "    positive       0.95      0.37      0.53        52\n",
      "\n",
      "    accuracy                           0.82       216\n",
      "   macro avg       0.77      0.65      0.66       216\n",
      "weighted avg       0.84      0.82      0.79       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.57      0.67        23\n",
      "     neutral       0.87      0.96      0.91       152\n",
      "    positive       0.78      0.61      0.68        41\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.82      0.71      0.75       216\n",
      "weighted avg       0.85      0.85      0.84       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.38      0.56        13\n",
      "     neutral       0.93      0.99      0.96       186\n",
      "    positive       0.77      0.59      0.67        17\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.90      0.65      0.73       216\n",
      "weighted avg       0.92      0.92      0.91       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.95      1.00      0.97       185\n",
      "    positive       1.00      0.59      0.74        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.98      0.79      0.86       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Total train time: 71.09954714775085 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 73\n",
      "Sampling duration: 13.892317771911621 seconds\n",
      "New train size: 208\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6055, Accuracy: 0.7887, F1 Micro: 0.8819, F1 Macro: 0.8804\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5367, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5003, Accuracy: 0.7946, F1 Micro: 0.8848, F1 Macro: 0.8833\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4741, Accuracy: 0.814, F1 Micro: 0.8943, F1 Macro: 0.8936\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4156, Accuracy: 0.8549, F1 Micro: 0.915, F1 Macro: 0.9149\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3722, Accuracy: 0.8943, F1 Micro: 0.9365, F1 Macro: 0.9355\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3215, Accuracy: 0.9182, F1 Micro: 0.9498, F1 Macro: 0.9481\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.263, Accuracy: 0.933, F1 Micro: 0.9584, F1 Macro: 0.9567\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2193, Accuracy: 0.9435, F1 Micro: 0.965, F1 Macro: 0.9635\n",
      "Epoch 10/10, Train Loss: 0.1865, Accuracy: 0.942, F1 Micro: 0.9639, F1 Macro: 0.962\n",
      "\n",
      "Aspect detection accuracy: 0.9435, F1 Micro: 0.965, F1 Macro: 0.9635\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      0.98      0.96       175\n",
      "      others       0.89      0.96      0.92       158\n",
      "        part       0.91      0.99      0.95       158\n",
      "       price       0.96      0.99      0.98       192\n",
      "     service       0.97      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.94      0.99      0.96      1061\n",
      "   macro avg       0.94      0.99      0.96      1061\n",
      "weighted avg       0.94      0.99      0.97      1061\n",
      " samples avg       0.95      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6454, Accuracy: 0.6696, F1 Micro: 0.6696, F1 Macro: 0.4011\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4976, Accuracy: 0.7093, F1 Micro: 0.7093, F1 Macro: 0.5266\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3915, Accuracy: 0.8987, F1 Micro: 0.8987, F1 Macro: 0.888\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2361, Accuracy: 0.9251, F1 Micro: 0.9251, F1 Macro: 0.9182\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.207, Accuracy: 0.9295, F1 Micro: 0.9295, F1 Macro: 0.9214\n",
      "Epoch 6/10, Train Loss: 0.1298, Accuracy: 0.9031, F1 Micro: 0.9031, F1 Macro: 0.8961\n",
      "Epoch 7/10, Train Loss: 0.0807, Accuracy: 0.9075, F1 Micro: 0.9075, F1 Macro: 0.8936\n",
      "Epoch 8/10, Train Loss: 0.1123, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.9086\n",
      "Epoch 9/10, Train Loss: 0.0736, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.9075\n",
      "Epoch 10/10, Train Loss: 0.0894, Accuracy: 0.9207, F1 Micro: 0.9207, F1 Macro: 0.9141\n",
      "\n",
      "Sentiment analysis accuracy: 0.9295, F1 Micro: 0.9295, F1 Macro: 0.9214\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.92      0.90        75\n",
      "    positive       0.96      0.93      0.95       152\n",
      "\n",
      "    accuracy                           0.93       227\n",
      "   macro avg       0.92      0.93      0.92       227\n",
      "weighted avg       0.93      0.93      0.93       227\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 208: Accuracy: 0.9329, F1 Micro: 0.9329, F1 Macro: 0.8676\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.98      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.88      0.93        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.85      0.70      0.77        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.93      0.85      0.89       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.75      0.67        12\n",
      "     neutral       0.89      0.95      0.92       152\n",
      "    positive       0.84      0.62      0.71        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.78      0.77      0.77       216\n",
      "weighted avg       0.86      0.86      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.70      0.76        23\n",
      "     neutral       0.90      0.99      0.95       152\n",
      "    positive       0.90      0.66      0.76        41\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.88      0.78      0.82       216\n",
      "weighted avg       0.90      0.90      0.89       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.69      0.78        13\n",
      "     neutral       0.96      0.99      0.98       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.82      0.86       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.97      1.00      0.99       185\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.99      0.89      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 78.46437668800354 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 66\n",
      "Sampling duration: 15.656381368637085 seconds\n",
      "New train size: 274\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5965, Accuracy: 0.7887, F1 Micro: 0.8819, F1 Macro: 0.8804\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5105, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4865, Accuracy: 0.7961, F1 Micro: 0.8855, F1 Macro: 0.8841\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4198, Accuracy: 0.8393, F1 Micro: 0.9067, F1 Macro: 0.9059\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3625, Accuracy: 0.8876, F1 Micro: 0.933, F1 Macro: 0.9319\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3094, Accuracy: 0.9256, F1 Micro: 0.9541, F1 Macro: 0.9525\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.238, Accuracy: 0.9427, F1 Micro: 0.9645, F1 Macro: 0.963\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2012, Accuracy: 0.9457, F1 Micro: 0.9663, F1 Macro: 0.9647\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1626, Accuracy: 0.9501, F1 Micro: 0.9688, F1 Macro: 0.9673\n",
      "Epoch 10/10, Train Loss: 0.1302, Accuracy: 0.9494, F1 Micro: 0.9681, F1 Macro: 0.9663\n",
      "\n",
      "Aspect detection accuracy: 0.9501, F1 Micro: 0.9688, F1 Macro: 0.9673\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.94      0.98      0.96       175\n",
      "      others       0.89      0.94      0.92       158\n",
      "        part       0.97      0.96      0.97       158\n",
      "       price       0.98      0.99      0.98       192\n",
      "     service       0.97      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5724, Accuracy: 0.6827, F1 Micro: 0.6827, F1 Macro: 0.4057\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3991, Accuracy: 0.8755, F1 Micro: 0.8755, F1 Macro: 0.8558\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2216, Accuracy: 0.8956, F1 Micro: 0.8956, F1 Macro: 0.8874\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.154, Accuracy: 0.9237, F1 Micro: 0.9237, F1 Macro: 0.911\n",
      "Epoch 5/10, Train Loss: 0.1064, Accuracy: 0.8996, F1 Micro: 0.8996, F1 Macro: 0.8915\n",
      "Epoch 6/10, Train Loss: 0.1075, Accuracy: 0.9116, F1 Micro: 0.9116, F1 Macro: 0.9023\n",
      "Epoch 7/10, Train Loss: 0.1114, Accuracy: 0.8675, F1 Micro: 0.8675, F1 Macro: 0.8593\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.075, Accuracy: 0.9317, F1 Micro: 0.9317, F1 Macro: 0.9247\n",
      "Epoch 9/10, Train Loss: 0.0758, Accuracy: 0.9116, F1 Micro: 0.9116, F1 Macro: 0.9038\n",
      "Epoch 10/10, Train Loss: 0.076, Accuracy: 0.9076, F1 Micro: 0.9076, F1 Macro: 0.8997\n",
      "\n",
      "Sentiment analysis accuracy: 0.9317, F1 Micro: 0.9317, F1 Macro: 0.9247\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.99      0.90        79\n",
      "    positive       0.99      0.91      0.95       170\n",
      "\n",
      "    accuracy                           0.93       249\n",
      "   macro avg       0.91      0.95      0.92       249\n",
      "weighted avg       0.94      0.93      0.93       249\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 274: Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.8857\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       1.00      0.88      0.93        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.93      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.85      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.75      0.69        12\n",
      "     neutral       0.89      0.95      0.92       152\n",
      "    positive       0.83      0.65      0.73        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.79      0.78      0.78       216\n",
      "weighted avg       0.86      0.87      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.97      0.96      0.96       152\n",
      "    positive       0.92      0.80      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.92      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.98      0.99      0.98       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.88      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.97      1.00      0.99       185\n",
      "    positive       1.00      0.71      0.83        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.97      0.88      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 83.05916929244995 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 59\n",
      "Sampling duration: 15.385445833206177 seconds\n",
      "New train size: 333\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5842, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Epoch 2/10, Train Loss: 0.5095, Accuracy: 0.7887, F1 Micro: 0.8819, F1 Macro: 0.8804\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4421, Accuracy: 0.8333, F1 Micro: 0.9029, F1 Macro: 0.9023\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3902, Accuracy: 0.8914, F1 Micro: 0.9346, F1 Macro: 0.934\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2999, Accuracy: 0.9368, F1 Micro: 0.9608, F1 Macro: 0.9593\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2368, Accuracy: 0.9457, F1 Micro: 0.9663, F1 Macro: 0.9649\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1916, Accuracy: 0.9487, F1 Micro: 0.968, F1 Macro: 0.9661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1546, Accuracy: 0.9524, F1 Micro: 0.9701, F1 Macro: 0.9685\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1264, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9723\n",
      "Epoch 10/10, Train Loss: 0.1046, Accuracy: 0.9531, F1 Micro: 0.9706, F1 Macro: 0.9694\n",
      "\n",
      "Aspect detection accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9723\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.89      0.97      0.93       158\n",
      "        part       0.97      0.97      0.97       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.97      1061\n",
      "   macro avg       0.96      0.99      0.97      1061\n",
      "weighted avg       0.96      0.99      0.97      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5716, Accuracy: 0.7439, F1 Micro: 0.7439, F1 Macro: 0.6076\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.27, Accuracy: 0.8943, F1 Micro: 0.8943, F1 Macro: 0.8871\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1422, Accuracy: 0.939, F1 Micro: 0.939, F1 Macro: 0.932\n",
      "Epoch 4/10, Train Loss: 0.1485, Accuracy: 0.9187, F1 Micro: 0.9187, F1 Macro: 0.912\n",
      "Epoch 5/10, Train Loss: 0.1389, Accuracy: 0.8943, F1 Micro: 0.8943, F1 Macro: 0.8876\n",
      "Epoch 6/10, Train Loss: 0.1057, Accuracy: 0.9106, F1 Micro: 0.9106, F1 Macro: 0.9041\n",
      "Epoch 7/10, Train Loss: 0.072, Accuracy: 0.9268, F1 Micro: 0.9268, F1 Macro: 0.92\n",
      "Epoch 8/10, Train Loss: 0.0636, Accuracy: 0.9309, F1 Micro: 0.9309, F1 Macro: 0.9242\n",
      "Epoch 9/10, Train Loss: 0.0687, Accuracy: 0.9268, F1 Micro: 0.9268, F1 Macro: 0.9195\n",
      "Epoch 10/10, Train Loss: 0.057, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9166\n",
      "\n",
      "Sentiment analysis accuracy: 0.939, F1 Micro: 0.939, F1 Macro: 0.932\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.94      0.91        81\n",
      "    positive       0.97      0.94      0.95       165\n",
      "\n",
      "    accuracy                           0.94       246\n",
      "   macro avg       0.93      0.94      0.93       246\n",
      "weighted avg       0.94      0.94      0.94       246\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 333: Accuracy: 0.9491, F1 Micro: 0.9491, F1 Macro: 0.9\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.69      0.81        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.93      0.82      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.90      0.97      0.93       152\n",
      "    positive       0.90      0.69      0.78        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.85      0.80      0.82       216\n",
      "weighted avg       0.89      0.89      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.91      0.84        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       0.89      0.83      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.90      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.84      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.94      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 83.44068598747253 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 54\n",
      "Sampling duration: 13.85227656364441 seconds\n",
      "New train size: 387\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5672, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4924, Accuracy: 0.8095, F1 Micro: 0.892, F1 Macro: 0.891\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4181, Accuracy: 0.8586, F1 Micro: 0.9172, F1 Macro: 0.9164\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3292, Accuracy: 0.9256, F1 Micro: 0.9541, F1 Macro: 0.9524\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2498, Accuracy: 0.9442, F1 Micro: 0.9653, F1 Macro: 0.9635\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1868, Accuracy: 0.9531, F1 Micro: 0.9708, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1417, Accuracy: 0.9561, F1 Micro: 0.9725, F1 Macro: 0.9712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1263, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9714\n",
      "Epoch 9/10, Train Loss: 0.1041, Accuracy: 0.9554, F1 Micro: 0.972, F1 Macro: 0.9703\n",
      "Epoch 10/10, Train Loss: 0.0871, Accuracy: 0.9561, F1 Micro: 0.9726, F1 Macro: 0.9716\n",
      "\n",
      "Aspect detection accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.97      0.96       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.96      0.97      0.97       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5818, Accuracy: 0.8224, F1 Micro: 0.8224, F1 Macro: 0.7561\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2782, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.9058\n",
      "Epoch 3/10, Train Loss: 0.1659, Accuracy: 0.8919, F1 Micro: 0.8919, F1 Macro: 0.8826\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1604, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.9063\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1324, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9239\n",
      "Epoch 6/10, Train Loss: 0.1316, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9221\n",
      "Epoch 7/10, Train Loss: 0.1044, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9144\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.085, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9249\n",
      "Epoch 9/10, Train Loss: 0.0788, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9189\n",
      "Epoch 10/10, Train Loss: 0.072, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9176\n",
      "\n",
      "Sentiment analysis accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9249\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.93      0.90        81\n",
      "    positive       0.97      0.94      0.95       178\n",
      "\n",
      "    accuracy                           0.93       259\n",
      "   macro avg       0.92      0.93      0.92       259\n",
      "weighted avg       0.94      0.93      0.93       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 387: Accuracy: 0.9452, F1 Micro: 0.9452, F1 Macro: 0.8893\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.75      0.86        16\n",
      "     neutral       0.95      0.96      0.96       167\n",
      "    positive       0.77      0.82      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.91      0.84      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.93      0.94      0.93       152\n",
      "    positive       0.82      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.83      0.83      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.87      0.85        23\n",
      "     neutral       0.95      0.97      0.96       152\n",
      "    positive       0.86      0.78      0.82        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.87      0.88       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.89      0.84      0.86       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 91.3796751499176 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 48\n",
      "Sampling duration: 12.748272180557251 seconds\n",
      "New train size: 435\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5701, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5011, Accuracy: 0.814, F1 Micro: 0.8942, F1 Macro: 0.8934\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4083, Accuracy: 0.8958, F1 Micro: 0.9373, F1 Macro: 0.9366\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3085, Accuracy: 0.9405, F1 Micro: 0.9632, F1 Macro: 0.9617\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2334, Accuracy: 0.9501, F1 Micro: 0.9688, F1 Macro: 0.9671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1771, Accuracy: 0.9509, F1 Micro: 0.9692, F1 Macro: 0.9671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1424, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9776\n",
      "Epoch 8/10, Train Loss: 0.1084, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9746\n",
      "Epoch 9/10, Train Loss: 0.0931, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9728\n",
      "Epoch 10/10, Train Loss: 0.0814, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9737\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9776\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.98      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5434, Accuracy: 0.8386, F1 Micro: 0.8386, F1 Macro: 0.797\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2848, Accuracy: 0.9055, F1 Micro: 0.9055, F1 Macro: 0.8973\n",
      "Epoch 3/10, Train Loss: 0.1324, Accuracy: 0.8622, F1 Micro: 0.8622, F1 Macro: 0.8554\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1213, Accuracy: 0.9055, F1 Micro: 0.9055, F1 Macro: 0.8967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1363, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9153\n",
      "Epoch 6/10, Train Loss: 0.1131, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.9063\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0948, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9293\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1046, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9293\n",
      "Epoch 9/10, Train Loss: 0.065, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9218\n",
      "Epoch 10/10, Train Loss: 0.0681, Accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.9107\n",
      "\n",
      "Sentiment analysis accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9293\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.93      0.91        83\n",
      "    positive       0.96      0.94      0.95       171\n",
      "\n",
      "    accuracy                           0.94       254\n",
      "   macro avg       0.92      0.93      0.93       254\n",
      "weighted avg       0.94      0.94      0.94       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 435: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9076\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.84      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.92      0.97      0.95       152\n",
      "    positive       0.89      0.79      0.84        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.88      0.84      0.85       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.91      0.89        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.92      0.88      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.99      0.98      0.99       186\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.90      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 94.73536324501038 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 43\n",
      "Sampling duration: 11.499959468841553 seconds\n",
      "New train size: 478\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5563, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.476, Accuracy: 0.8192, F1 Micro: 0.8971, F1 Macro: 0.8963\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3795, Accuracy: 0.9174, F1 Micro: 0.9498, F1 Macro: 0.9485\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2712, Accuracy: 0.9472, F1 Micro: 0.9672, F1 Macro: 0.9656\n",
      "Epoch 5/10, Train Loss: 0.2126, Accuracy: 0.9472, F1 Micro: 0.967, F1 Macro: 0.9645\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1516, Accuracy: 0.9561, F1 Micro: 0.9726, F1 Macro: 0.9712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1297, Accuracy: 0.9568, F1 Micro: 0.9728, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1093, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9732\n",
      "Epoch 9/10, Train Loss: 0.0914, Accuracy: 0.9539, F1 Micro: 0.9709, F1 Macro: 0.9688\n",
      "Epoch 10/10, Train Loss: 0.075, Accuracy: 0.9576, F1 Micro: 0.9732, F1 Macro: 0.9713\n",
      "\n",
      "Aspect detection accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9732\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      0.99      0.96       175\n",
      "      others       0.92      0.95      0.93       158\n",
      "        part       0.96      0.99      0.97       158\n",
      "       price       0.98      0.98      0.98       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5837, Accuracy: 0.8849, F1 Micro: 0.8849, F1 Macro: 0.8629\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2681, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9343\n",
      "Epoch 3/10, Train Loss: 0.1865, Accuracy: 0.9008, F1 Micro: 0.9008, F1 Macro: 0.8932\n",
      "Epoch 4/10, Train Loss: 0.1268, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9256\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1225, Accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9425\n",
      "Epoch 6/10, Train Loss: 0.0852, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.9099\n",
      "Epoch 7/10, Train Loss: 0.0911, Accuracy: 0.9365, F1 Micro: 0.9365, F1 Macro: 0.929\n",
      "Epoch 8/10, Train Loss: 0.0758, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9264\n",
      "Epoch 9/10, Train Loss: 0.0603, Accuracy: 0.9365, F1 Micro: 0.9365, F1 Macro: 0.9305\n",
      "Epoch 10/10, Train Loss: 0.0538, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9343\n",
      "\n",
      "Sentiment analysis accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9425\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.96      0.92        82\n",
      "    positive       0.98      0.94      0.96       170\n",
      "\n",
      "    accuracy                           0.95       252\n",
      "   macro avg       0.93      0.95      0.94       252\n",
      "weighted avg       0.95      0.95      0.95       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 478: Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.9053\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.93      0.99      0.96       167\n",
      "    positive       0.88      0.67      0.76        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.91      0.82      0.86       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.83      0.77      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.84      0.82      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.96      0.99      0.97       152\n",
      "    positive       0.94      0.78      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.91      0.91       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.98      0.98      0.98       186\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.91      0.88      0.89       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 94.56864595413208 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 39\n",
      "Sampling duration: 10.578590869903564 seconds\n",
      "New train size: 517\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5549, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4568, Accuracy: 0.8519, F1 Micro: 0.914, F1 Macro: 0.9137\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3568, Accuracy: 0.9338, F1 Micro: 0.9593, F1 Macro: 0.9577\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2433, Accuracy: 0.9405, F1 Micro: 0.9629, F1 Macro: 0.9613\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1865, Accuracy: 0.9546, F1 Micro: 0.9717, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1454, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1188, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9773\n",
      "Epoch 8/10, Train Loss: 0.0916, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9755\n",
      "Epoch 9/10, Train Loss: 0.0813, Accuracy: 0.9583, F1 Micro: 0.9737, F1 Macro: 0.9717\n",
      "Epoch 10/10, Train Loss: 0.066, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.97      0.94       158\n",
      "        part       0.99      0.97      0.98       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5418, Accuracy: 0.8452, F1 Micro: 0.8452, F1 Macro: 0.8027\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.27, Accuracy: 0.9365, F1 Micro: 0.9365, F1 Macro: 0.9277\n",
      "Epoch 3/10, Train Loss: 0.1659, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9252\n",
      "Epoch 4/10, Train Loss: 0.1543, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9252\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1163, Accuracy: 0.9365, F1 Micro: 0.9365, F1 Macro: 0.9294\n",
      "Epoch 6/10, Train Loss: 0.1004, Accuracy: 0.9127, F1 Micro: 0.9127, F1 Macro: 0.8971\n",
      "Epoch 7/10, Train Loss: 0.0761, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9229\n",
      "Epoch 8/10, Train Loss: 0.0756, Accuracy: 0.9246, F1 Micro: 0.9246, F1 Macro: 0.9164\n",
      "Epoch 9/10, Train Loss: 0.0644, Accuracy: 0.9246, F1 Micro: 0.9246, F1 Macro: 0.9173\n",
      "Epoch 10/10, Train Loss: 0.0603, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9243\n",
      "\n",
      "Sentiment analysis accuracy: 0.9365, F1 Micro: 0.9365, F1 Macro: 0.9294\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.96      0.91        81\n",
      "    positive       0.98      0.92      0.95       171\n",
      "\n",
      "    accuracy                           0.94       252\n",
      "   macro avg       0.92      0.94      0.93       252\n",
      "weighted avg       0.94      0.94      0.94       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 517: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9019\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.84      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.92      0.97      0.95       152\n",
      "    positive       0.91      0.75      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.86      0.82      0.84       216\n",
      "weighted avg       0.91      0.91      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.99      0.97      0.98       152\n",
      "    positive       0.90      0.88      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.94      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.91      0.84      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 97.83898973464966 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 23\n",
      "Sampling duration: 9.60245418548584 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5546, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4683, Accuracy: 0.8296, F1 Micro: 0.9025, F1 Macro: 0.9019\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3603, Accuracy: 0.9308, F1 Micro: 0.9573, F1 Macro: 0.9555\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2584, Accuracy: 0.9516, F1 Micro: 0.9697, F1 Macro: 0.9678\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1893, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9733\n",
      "Epoch 6/10, Train Loss: 0.1513, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1212, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9762\n",
      "Epoch 8/10, Train Loss: 0.0955, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0805, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9775\n",
      "Epoch 10/10, Train Loss: 0.072, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9751\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9775\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5142, Accuracy: 0.8911, F1 Micro: 0.8911, F1 Macro: 0.8692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2793, Accuracy: 0.8988, F1 Micro: 0.8988, F1 Macro: 0.89\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.17, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9231\n",
      "Epoch 4/10, Train Loss: 0.1428, Accuracy: 0.9105, F1 Micro: 0.9105, F1 Macro: 0.9029\n",
      "Epoch 5/10, Train Loss: 0.1384, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9186\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1127, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9259\n",
      "Epoch 7/10, Train Loss: 0.1093, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.919\n",
      "Epoch 8/10, Train Loss: 0.0832, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9218\n",
      "Epoch 9/10, Train Loss: 0.0778, Accuracy: 0.9066, F1 Micro: 0.9066, F1 Macro: 0.8984\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0367, Accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9381\n",
      "\n",
      "Sentiment analysis accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9381\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        82\n",
      "    positive       0.97      0.95      0.96       175\n",
      "\n",
      "    accuracy                           0.95       257\n",
      "   macro avg       0.93      0.94      0.94       257\n",
      "weighted avg       0.95      0.95      0.95       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.913\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.91      0.88      0.89        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.84      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.75      0.86        12\n",
      "     neutral       0.92      0.96      0.94       152\n",
      "    positive       0.88      0.81      0.84        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.93      0.84      0.88       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.92      0.83      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.90      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.88      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 104.60869550704956 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 33\n",
      "Sampling duration: 9.099173307418823 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.557, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4661, Accuracy: 0.8311, F1 Micro: 0.9032, F1 Macro: 0.9022\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3465, Accuracy: 0.9345, F1 Micro: 0.9593, F1 Macro: 0.9578\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2511, Accuracy: 0.9554, F1 Micro: 0.9722, F1 Macro: 0.9707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.176, Accuracy: 0.9583, F1 Micro: 0.974, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1388, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.975\n",
      "Epoch 7/10, Train Loss: 0.1088, Accuracy: 0.9606, F1 Micro: 0.9755, F1 Macro: 0.9744\n",
      "Epoch 8/10, Train Loss: 0.0913, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0736, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.066, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9756\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9756\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.94      0.92      0.93       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5229, Accuracy: 0.8496, F1 Micro: 0.8496, F1 Macro: 0.7985\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2253, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.924\n",
      "Epoch 3/10, Train Loss: 0.1736, Accuracy: 0.906, F1 Micro: 0.906, F1 Macro: 0.8969\n",
      "Epoch 4/10, Train Loss: 0.1449, Accuracy: 0.8985, F1 Micro: 0.8985, F1 Macro: 0.8897\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1307, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9321\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1147, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9313\n",
      "Epoch 7/10, Train Loss: 0.1107, Accuracy: 0.9211, F1 Micro: 0.9211, F1 Macro: 0.913\n",
      "Epoch 8/10, Train Loss: 0.0847, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.92\n",
      "Epoch 9/10, Train Loss: 0.0719, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.924\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.043, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9321\n",
      "\n",
      "Sentiment analysis accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9321\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.96      0.91        83\n",
      "    positive       0.98      0.93      0.96       183\n",
      "\n",
      "    accuracy                           0.94       266\n",
      "   macro avg       0.92      0.95      0.93       266\n",
      "weighted avg       0.94      0.94      0.94       266\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9073\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.85      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.95      0.92      0.93       152\n",
      "    positive       0.80      0.83      0.81        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.82      0.86      0.84       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.97      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.84      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 107.80040955543518 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 30\n",
      "Sampling duration: 8.254045963287354 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5432, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4528, Accuracy: 0.8348, F1 Micro: 0.9051, F1 Macro: 0.9046\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3375, Accuracy: 0.9368, F1 Micro: 0.9608, F1 Macro: 0.9588\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2272, Accuracy: 0.9509, F1 Micro: 0.9696, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1709, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.132, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.105, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9777\n",
      "Epoch 8/10, Train Loss: 0.0871, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9752\n",
      "Epoch 9/10, Train Loss: 0.0702, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9758\n",
      "Epoch 10/10, Train Loss: 0.0607, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9772\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9777\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.94      0.93      0.94       158\n",
      "        part       0.99      0.98      0.98       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4567, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.9025\n",
      "Epoch 2/10, Train Loss: 0.2661, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.9007\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1493, Accuracy: 0.9278, F1 Micro: 0.9278, F1 Macro: 0.92\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.151, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9354\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1098, Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.9437\n",
      "Epoch 6/10, Train Loss: 0.1151, Accuracy: 0.9202, F1 Micro: 0.9202, F1 Macro: 0.9125\n",
      "Epoch 7/10, Train Loss: 0.0918, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9358\n",
      "Epoch 8/10, Train Loss: 0.0869, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9358\n",
      "Epoch 9/10, Train Loss: 0.0745, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9276\n",
      "Epoch 10/10, Train Loss: 0.0509, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9276\n",
      "\n",
      "Sentiment analysis accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.9437\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.92        83\n",
      "    positive       0.98      0.95      0.96       180\n",
      "\n",
      "    accuracy                           0.95       263\n",
      "   macro avg       0.94      0.95      0.94       263\n",
      "weighted avg       0.95      0.95      0.95       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9211\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.95      0.93      0.94       152\n",
      "    positive       0.81      0.83      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.84      0.86      0.85       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.99      0.98      0.98       152\n",
      "    positive       0.95      0.88      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.94      0.92       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.97      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.97      0.86      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 105.58814668655396 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 27\n",
      "Sampling duration: 7.719442844390869 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5557, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4484, Accuracy: 0.8519, F1 Micro: 0.9138, F1 Macro: 0.9132\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3199, Accuracy: 0.9368, F1 Micro: 0.9608, F1 Macro: 0.9589\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2144, Accuracy: 0.9531, F1 Micro: 0.9708, F1 Macro: 0.9697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1601, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1211, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9779\n",
      "Epoch 7/10, Train Loss: 0.1045, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9747\n",
      "Epoch 8/10, Train Loss: 0.0823, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9769\n",
      "Epoch 9/10, Train Loss: 0.0681, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9776\n",
      "Epoch 10/10, Train Loss: 0.0566, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9766\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9779\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.95      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4965, Accuracy: 0.8858, F1 Micro: 0.8858, F1 Macro: 0.8644\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.201, Accuracy: 0.8858, F1 Micro: 0.8858, F1 Macro: 0.8773\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.146, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9181\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1402, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9255\n",
      "Epoch 5/10, Train Loss: 0.1413, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9185\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.106, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9327\n",
      "Epoch 7/10, Train Loss: 0.0855, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9185\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.082, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9388\n",
      "Epoch 9/10, Train Loss: 0.0533, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.9058\n",
      "Epoch 10/10, Train Loss: 0.0724, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9343\n",
      "\n",
      "Sentiment analysis accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9388\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.98      0.92        82\n",
      "    positive       0.99      0.93      0.96       172\n",
      "\n",
      "    accuracy                           0.94       254\n",
      "   macro avg       0.93      0.95      0.94       254\n",
      "weighted avg       0.95      0.94      0.95       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.9139\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.96      0.73      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.87      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.83      0.77      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.84      0.82      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.86      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 110.8467423915863 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 18\n",
      "Sampling duration: 6.886552333831787 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5358, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4432, Accuracy: 0.8996, F1 Micro: 0.9395, F1 Macro: 0.9384\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3037, Accuracy: 0.9405, F1 Micro: 0.9629, F1 Macro: 0.9612\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2076, Accuracy: 0.9568, F1 Micro: 0.9731, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1534, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1216, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0918, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9762\n",
      "Epoch 8/10, Train Loss: 0.0773, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9739\n",
      "Epoch 9/10, Train Loss: 0.0628, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0552, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9771\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.97      0.97       175\n",
      "      others       0.92      0.97      0.94       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5033, Accuracy: 0.8915, F1 Micro: 0.8915, F1 Macro: 0.8723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2183, Accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.9128\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1552, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9252\n",
      "Epoch 4/10, Train Loss: 0.1568, Accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.9151\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1081, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9348\n",
      "Epoch 6/10, Train Loss: 0.1038, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9314\n",
      "Epoch 7/10, Train Loss: 0.0944, Accuracy: 0.9147, F1 Micro: 0.9147, F1 Macro: 0.9071\n",
      "Epoch 8/10, Train Loss: 0.086, Accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.9151\n",
      "Epoch 9/10, Train Loss: 0.0702, Accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.9192\n",
      "Epoch 10/10, Train Loss: 0.0492, Accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.9179\n",
      "\n",
      "Sentiment analysis accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9348\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.95      0.91        83\n",
      "    positive       0.98      0.94      0.96       175\n",
      "\n",
      "    accuracy                           0.94       258\n",
      "   macro avg       0.93      0.94      0.93       258\n",
      "weighted avg       0.94      0.94      0.94       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9148\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.97      0.96       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.88      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.92      0.97      0.95       152\n",
      "    positive       0.91      0.75      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.86      0.82      0.84       216\n",
      "weighted avg       0.91      0.91      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.92      0.85      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.86      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 114.36845326423645 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 6.475177764892578 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5453, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4398, Accuracy: 0.9122, F1 Micro: 0.9467, F1 Macro: 0.9453\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3049, Accuracy: 0.9479, F1 Micro: 0.9678, F1 Macro: 0.9662\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2053, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1495, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1177, Accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9785\n",
      "Epoch 7/10, Train Loss: 0.0898, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9737\n",
      "Epoch 8/10, Train Loss: 0.0762, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.976\n",
      "Epoch 9/10, Train Loss: 0.0637, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9765\n",
      "Epoch 10/10, Train Loss: 0.0524, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9785\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.93      0.96      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5117, Accuracy: 0.9249, F1 Micro: 0.9249, F1 Macro: 0.9129\n",
      "Epoch 2/10, Train Loss: 0.1833, Accuracy: 0.9051, F1 Micro: 0.9051, F1 Macro: 0.8975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1692, Accuracy: 0.9486, F1 Micro: 0.9486, F1 Macro: 0.9415\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.123, Accuracy: 0.9486, F1 Micro: 0.9486, F1 Macro: 0.9415\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.098, Accuracy: 0.9486, F1 Micro: 0.9486, F1 Macro: 0.9426\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1062, Accuracy: 0.9526, F1 Micro: 0.9526, F1 Macro: 0.9465\n",
      "Epoch 7/10, Train Loss: 0.0847, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9345\n",
      "Epoch 8/10, Train Loss: 0.0777, Accuracy: 0.913, F1 Micro: 0.913, F1 Macro: 0.9061\n",
      "Epoch 9/10, Train Loss: 0.0874, Accuracy: 0.9486, F1 Micro: 0.9486, F1 Macro: 0.9423\n",
      "Epoch 10/10, Train Loss: 0.0741, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9345\n",
      "\n",
      "Sentiment analysis accuracy: 0.9526, F1 Micro: 0.9526, F1 Macro: 0.9465\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93        82\n",
      "    positive       0.98      0.95      0.96       171\n",
      "\n",
      "    accuracy                           0.95       253\n",
      "   macro avg       0.94      0.95      0.95       253\n",
      "weighted avg       0.95      0.95      0.95       253\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9177\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.93      0.96      0.94       152\n",
      "    positive       0.87      0.79      0.83        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.85      0.83      0.84       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.95      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.97      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.97      0.86      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 113.73651385307312 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.802679061889648 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5391, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4472, Accuracy: 0.9055, F1 Micro: 0.9432, F1 Macro: 0.9424\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2981, Accuracy: 0.9464, F1 Micro: 0.9667, F1 Macro: 0.9649\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2033, Accuracy: 0.9531, F1 Micro: 0.9707, F1 Macro: 0.9687\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1398, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9748\n",
      "Epoch 6/10, Train Loss: 0.1164, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0947, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.073, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9774\n",
      "Epoch 9/10, Train Loss: 0.0633, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0566, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9786\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9786\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.95      0.93      0.94       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4668, Accuracy: 0.9179, F1 Micro: 0.9179, F1 Macro: 0.909\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2302, Accuracy: 0.9179, F1 Micro: 0.9179, F1 Macro: 0.9099\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1874, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9255\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1371, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9371\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1475, Accuracy: 0.9515, F1 Micro: 0.9515, F1 Macro: 0.9452\n",
      "Epoch 6/10, Train Loss: 0.1179, Accuracy: 0.9254, F1 Micro: 0.9254, F1 Macro: 0.9177\n",
      "Epoch 7/10, Train Loss: 0.0852, Accuracy: 0.9254, F1 Micro: 0.9254, F1 Macro: 0.9172\n",
      "Epoch 8/10, Train Loss: 0.0727, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.9287\n",
      "Epoch 9/10, Train Loss: 0.0653, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9212\n",
      "Epoch 10/10, Train Loss: 0.0573, Accuracy: 0.9254, F1 Micro: 0.9254, F1 Macro: 0.9172\n",
      "\n",
      "Sentiment analysis accuracy: 0.9515, F1 Micro: 0.9515, F1 Macro: 0.9452\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.93        86\n",
      "    positive       0.98      0.95      0.96       182\n",
      "\n",
      "    accuracy                           0.95       268\n",
      "   macro avg       0.94      0.95      0.95       268\n",
      "weighted avg       0.95      0.95      0.95       268\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9272\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.95      0.93      0.94       152\n",
      "    positive       0.78      0.83      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.83      0.86      0.85       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.98      0.99      0.99       152\n",
      "    positive       1.00      0.88      0.94        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.96      0.96      0.95       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 120.51801657676697 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.196437120437622 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5445, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.429, Accuracy: 0.904, F1 Micro: 0.9416, F1 Macro: 0.9404\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2836, Accuracy: 0.9479, F1 Micro: 0.9676, F1 Macro: 0.9663\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1964, Accuracy: 0.9516, F1 Micro: 0.9696, F1 Macro: 0.9677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1404, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9747\n",
      "Epoch 6/10, Train Loss: 0.1129, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9724\n",
      "Epoch 7/10, Train Loss: 0.0908, Accuracy: 0.9591, F1 Micro: 0.9741, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0716, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9767\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0595, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.979\n",
      "Epoch 10/10, Train Loss: 0.0535, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9739\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.979\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.96      0.94       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5055, Accuracy: 0.9109, F1 Micro: 0.9109, F1 Macro: 0.9006\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2211, Accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.9183\n",
      "Epoch 3/10, Train Loss: 0.1431, Accuracy: 0.907, F1 Micro: 0.907, F1 Macro: 0.8991\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1512, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9261\n",
      "Epoch 5/10, Train Loss: 0.1279, Accuracy: 0.907, F1 Micro: 0.907, F1 Macro: 0.8991\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1066, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9314\n",
      "Epoch 7/10, Train Loss: 0.0939, Accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.9187\n",
      "Epoch 8/10, Train Loss: 0.0989, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.922\n",
      "Epoch 9/10, Train Loss: 0.0587, Accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.9187\n",
      "Epoch 10/10, Train Loss: 0.047, Accuracy: 0.9109, F1 Micro: 0.9109, F1 Macro: 0.9031\n",
      "\n",
      "Sentiment analysis accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9314\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.98      0.91        83\n",
      "    positive       0.99      0.92      0.95       175\n",
      "\n",
      "    accuracy                           0.94       258\n",
      "   macro avg       0.92      0.95      0.93       258\n",
      "weighted avg       0.94      0.94      0.94       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.9159\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.85      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.93      0.96      0.94       152\n",
      "    positive       0.87      0.75      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.84      0.85      0.84       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.99      0.99       152\n",
      "    positive       1.00      0.83      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.86      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 118.0717453956604 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.668586730957031 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5317, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4175, Accuracy: 0.9062, F1 Micro: 0.9432, F1 Macro: 0.9418\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.27, Accuracy: 0.9501, F1 Micro: 0.9689, F1 Macro: 0.9669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1806, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1299, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9784\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0993, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9795\n",
      "Epoch 7/10, Train Loss: 0.0866, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9744\n",
      "Epoch 8/10, Train Loss: 0.0654, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9782\n",
      "Epoch 9/10, Train Loss: 0.0598, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9752\n",
      "Epoch 10/10, Train Loss: 0.0501, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9778\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9795\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.97      0.95       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4795, Accuracy: 0.9189, F1 Micro: 0.9189, F1 Macro: 0.9099\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2072, Accuracy: 0.9189, F1 Micro: 0.9189, F1 Macro: 0.9121\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1753, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9253\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.133, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9398\n",
      "Epoch 5/10, Train Loss: 0.1424, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9197\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1079, Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9439\n",
      "Epoch 7/10, Train Loss: 0.081, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9291\n",
      "Epoch 8/10, Train Loss: 0.0747, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9201\n",
      "Epoch 9/10, Train Loss: 0.0745, Accuracy: 0.9189, F1 Micro: 0.9189, F1 Macro: 0.9054\n",
      "Epoch 10/10, Train Loss: 0.064, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9262\n",
      "\n",
      "Sentiment analysis accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9439\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.93        85\n",
      "    positive       0.98      0.95      0.96       174\n",
      "\n",
      "    accuracy                           0.95       259\n",
      "   macro avg       0.94      0.95      0.94       259\n",
      "weighted avg       0.95      0.95      0.95       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9614, F1 Micro: 0.9614, F1 Macro: 0.9251\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.94      0.97      0.95       152\n",
      "    positive       0.91      0.79      0.85        52\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.87      0.87      0.87       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 122.1550612449646 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 8\n",
      "Sampling duration: 4.173225402832031 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5396, Accuracy: 0.7946, F1 Micro: 0.8849, F1 Macro: 0.8834\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4195, Accuracy: 0.9167, F1 Micro: 0.9494, F1 Macro: 0.9481\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2652, Accuracy: 0.9524, F1 Micro: 0.9705, F1 Macro: 0.9692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.185, Accuracy: 0.9621, F1 Micro: 0.9764, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1361, Accuracy: 0.9635, F1 Micro: 0.9773, F1 Macro: 0.9762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1061, Accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9805\n",
      "Epoch 7/10, Train Loss: 0.0863, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9798\n",
      "Epoch 8/10, Train Loss: 0.0692, Accuracy: 0.9695, F1 Micro: 0.9809, F1 Macro: 0.98\n",
      "Epoch 9/10, Train Loss: 0.0581, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9791\n",
      "Epoch 10/10, Train Loss: 0.0505, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9785\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9805\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.99      0.95       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4777, Accuracy: 0.8735, F1 Micro: 0.8735, F1 Macro: 0.8646\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2118, Accuracy: 0.913, F1 Micro: 0.913, F1 Macro: 0.8988\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1769, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9269\n",
      "Epoch 4/10, Train Loss: 0.1356, Accuracy: 0.9249, F1 Micro: 0.9249, F1 Macro: 0.9187\n",
      "Epoch 5/10, Train Loss: 0.1386, Accuracy: 0.9289, F1 Micro: 0.9289, F1 Macro: 0.9228\n",
      "Epoch 6/10, Train Loss: 0.0959, Accuracy: 0.913, F1 Micro: 0.913, F1 Macro: 0.9061\n",
      "Epoch 7/10, Train Loss: 0.0771, Accuracy: 0.9249, F1 Micro: 0.9249, F1 Macro: 0.9187\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0709, Accuracy: 0.9447, F1 Micro: 0.9447, F1 Macro: 0.9387\n",
      "Epoch 9/10, Train Loss: 0.0466, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9345\n",
      "Epoch 10/10, Train Loss: 0.0577, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9249\n",
      "\n",
      "Sentiment analysis accuracy: 0.9447, F1 Micro: 0.9447, F1 Macro: 0.9387\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.95      0.92        84\n",
      "    positive       0.98      0.94      0.96       169\n",
      "\n",
      "    accuracy                           0.94       253\n",
      "   macro avg       0.93      0.95      0.94       253\n",
      "weighted avg       0.95      0.94      0.95       253\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9622, F1 Micro: 0.9622, F1 Macro: 0.9217\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.88      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.93      0.99      0.96       152\n",
      "    positive       0.95      0.77      0.85        52\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.88      0.84      0.85       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.92      0.93       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 121.3640685081482 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.696061611175537 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5349, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4195, Accuracy: 0.9115, F1 Micro: 0.9467, F1 Macro: 0.9458\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2597, Accuracy: 0.9501, F1 Micro: 0.969, F1 Macro: 0.9673\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1764, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1238, Accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9776\n",
      "Epoch 6/10, Train Loss: 0.099, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9756\n",
      "Epoch 7/10, Train Loss: 0.081, Accuracy: 0.9621, F1 Micro: 0.9759, F1 Macro: 0.9736\n",
      "Epoch 8/10, Train Loss: 0.0712, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9765\n",
      "Epoch 9/10, Train Loss: 0.0569, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0465, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9784\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9784\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.94      0.93      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4593, Accuracy: 0.8872, F1 Micro: 0.8872, F1 Macro: 0.8783\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2031, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9335\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1442, Accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9415\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1495, Accuracy: 0.9511, F1 Micro: 0.9511, F1 Macro: 0.9446\n",
      "Epoch 5/10, Train Loss: 0.1146, Accuracy: 0.9361, F1 Micro: 0.9361, F1 Macro: 0.9292\n",
      "Epoch 6/10, Train Loss: 0.1161, Accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9402\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0996, Accuracy: 0.9586, F1 Micro: 0.9586, F1 Macro: 0.9532\n",
      "Epoch 8/10, Train Loss: 0.0727, Accuracy: 0.8985, F1 Micro: 0.8985, F1 Macro: 0.8902\n",
      "Epoch 9/10, Train Loss: 0.0789, Accuracy: 0.9248, F1 Micro: 0.9248, F1 Macro: 0.916\n",
      "Epoch 10/10, Train Loss: 0.0644, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9299\n",
      "\n",
      "Sentiment analysis accuracy: 0.9586, F1 Micro: 0.9586, F1 Macro: 0.9532\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        87\n",
      "    positive       0.97      0.97      0.97       179\n",
      "\n",
      "    accuracy                           0.96       266\n",
      "   macro avg       0.95      0.95      0.95       266\n",
      "weighted avg       0.96      0.96      0.96       266\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9297\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.88      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.94      0.93      0.93       152\n",
      "    positive       0.78      0.81      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.85      0.86      0.85       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.96      0.95      0.95       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 123.0459144115448 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.1442723274230957 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5226, Accuracy: 0.7939, F1 Micro: 0.8845, F1 Macro: 0.8831\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4111, Accuracy: 0.9234, F1 Micro: 0.9531, F1 Macro: 0.9516\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2517, Accuracy: 0.9561, F1 Micro: 0.9727, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1683, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9764\n",
      "Epoch 5/10, Train Loss: 0.1285, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0983, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9781\n",
      "Epoch 7/10, Train Loss: 0.0799, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9746\n",
      "Epoch 8/10, Train Loss: 0.0623, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0543, Accuracy: 0.9688, F1 Micro: 0.9802, F1 Macro: 0.9789\n",
      "Epoch 10/10, Train Loss: 0.0479, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9802, F1 Macro: 0.9789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4675, Accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.8951\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2066, Accuracy: 0.9446, F1 Micro: 0.9446, F1 Macro: 0.9381\n",
      "Epoch 3/10, Train Loss: 0.1657, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9306\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1658, Accuracy: 0.9446, F1 Micro: 0.9446, F1 Macro: 0.9381\n",
      "Epoch 5/10, Train Loss: 0.1274, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9291\n",
      "Epoch 6/10, Train Loss: 0.1082, Accuracy: 0.9299, F1 Micro: 0.9299, F1 Macro: 0.9212\n",
      "Epoch 7/10, Train Loss: 0.0942, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9295\n",
      "Epoch 8/10, Train Loss: 0.0773, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9243\n",
      "Epoch 9/10, Train Loss: 0.0603, Accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.8994\n",
      "Epoch 10/10, Train Loss: 0.0554, Accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.9143\n",
      "\n",
      "Sentiment analysis accuracy: 0.9446, F1 Micro: 0.9446, F1 Macro: 0.9381\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.97      0.92        87\n",
      "    positive       0.98      0.93      0.96       184\n",
      "\n",
      "    accuracy                           0.94       271\n",
      "   macro avg       0.93      0.95      0.94       271\n",
      "weighted avg       0.95      0.94      0.95       271\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9301\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.88      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.80      0.77      0.78        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.82      0.85      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.95      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 121.6546413898468 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.564054250717163 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5307, Accuracy: 0.7954, F1 Micro: 0.8853, F1 Macro: 0.8838\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3947, Accuracy: 0.9308, F1 Micro: 0.9575, F1 Macro: 0.9563\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.256, Accuracy: 0.9546, F1 Micro: 0.9718, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1657, Accuracy: 0.9643, F1 Micro: 0.9777, F1 Macro: 0.9765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.132, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9774\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1011, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9789\n",
      "Epoch 7/10, Train Loss: 0.0809, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9782\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0644, Accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9805\n",
      "Epoch 9/10, Train Loss: 0.0565, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9793\n",
      "Epoch 10/10, Train Loss: 0.0492, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9775\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9805\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.98      0.95       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.486, Accuracy: 0.8696, F1 Micro: 0.8696, F1 Macro: 0.8628\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2762, Accuracy: 0.9289, F1 Micro: 0.9289, F1 Macro: 0.9212\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1473, Accuracy: 0.9289, F1 Micro: 0.9289, F1 Macro: 0.9224\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1117, Accuracy: 0.9447, F1 Micro: 0.9447, F1 Macro: 0.9387\n",
      "Epoch 5/10, Train Loss: 0.1054, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9334\n",
      "Epoch 6/10, Train Loss: 0.1262, Accuracy: 0.8893, F1 Micro: 0.8893, F1 Macro: 0.8825\n",
      "Epoch 7/10, Train Loss: 0.1066, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9345\n",
      "Epoch 8/10, Train Loss: 0.0531, Accuracy: 0.9368, F1 Micro: 0.9368, F1 Macro: 0.9283\n",
      "Epoch 9/10, Train Loss: 0.0606, Accuracy: 0.9051, F1 Micro: 0.9051, F1 Macro: 0.898\n",
      "Epoch 10/10, Train Loss: 0.0499, Accuracy: 0.9012, F1 Micro: 0.9012, F1 Macro: 0.8925\n",
      "\n",
      "Sentiment analysis accuracy: 0.9447, F1 Micro: 0.9447, F1 Macro: 0.9387\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        83\n",
      "    positive       0.98      0.94      0.96       170\n",
      "\n",
      "    accuracy                           0.94       253\n",
      "   macro avg       0.93      0.95      0.94       253\n",
      "weighted avg       0.95      0.94      0.95       253\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9622, F1 Micro: 0.9622, F1 Macro: 0.9218\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.85      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.75      0.69        12\n",
      "     neutral       0.93      0.98      0.95       152\n",
      "    positive       0.95      0.75      0.84        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.84      0.83      0.83       216\n",
      "weighted avg       0.92      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 126.94990062713623 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.8712897300720215 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.524, Accuracy: 0.7961, F1 Micro: 0.8856, F1 Macro: 0.8842\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3784, Accuracy: 0.9271, F1 Micro: 0.955, F1 Macro: 0.9527\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2385, Accuracy: 0.9546, F1 Micro: 0.9718, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1614, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9765\n",
      "Epoch 5/10, Train Loss: 0.1157, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0943, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9783\n",
      "Epoch 7/10, Train Loss: 0.0762, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9759\n",
      "Epoch 8/10, Train Loss: 0.0616, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9776\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0512, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9791\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0463, Accuracy: 0.971, F1 Micro: 0.9817, F1 Macro: 0.9807\n",
      "\n",
      "Aspect detection accuracy: 0.971, F1 Micro: 0.9817, F1 Macro: 0.9807\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.93      0.96      0.95       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.98      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4647, Accuracy: 0.9436, F1 Micro: 0.9436, F1 Macro: 0.9369\n",
      "Epoch 2/10, Train Loss: 0.2141, Accuracy: 0.9135, F1 Micro: 0.9135, F1 Macro: 0.9061\n",
      "Epoch 3/10, Train Loss: 0.1546, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9317\n",
      "Epoch 4/10, Train Loss: 0.1381, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9335\n",
      "Epoch 5/10, Train Loss: 0.1473, Accuracy: 0.8872, F1 Micro: 0.8872, F1 Macro: 0.8793\n",
      "Epoch 6/10, Train Loss: 0.0891, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9335\n",
      "Epoch 7/10, Train Loss: 0.1047, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9213\n",
      "Epoch 8/10, Train Loss: 0.0761, Accuracy: 0.9361, F1 Micro: 0.9361, F1 Macro: 0.9296\n",
      "Epoch 9/10, Train Loss: 0.065, Accuracy: 0.9211, F1 Micro: 0.9211, F1 Macro: 0.9134\n",
      "Epoch 10/10, Train Loss: 0.0794, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9256\n",
      "\n",
      "Sentiment analysis accuracy: 0.9436, F1 Micro: 0.9436, F1 Macro: 0.9369\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.95      0.92        86\n",
      "    positive       0.98      0.94      0.96       180\n",
      "\n",
      "    accuracy                           0.94       266\n",
      "   macro avg       0.93      0.95      0.94       266\n",
      "weighted avg       0.95      0.94      0.94       266\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9622, F1 Micro: 0.9622, F1 Macro: 0.9249\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.82      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.94      0.96      0.95       152\n",
      "    positive       0.89      0.79      0.84        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.85      0.86      0.85       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.93      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 124.82272529602051 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 8\n",
      "Sampling duration: 1.0128886699676514 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.529, Accuracy: 0.8006, F1 Micro: 0.8879, F1 Macro: 0.8865\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3937, Accuracy: 0.9338, F1 Micro: 0.9589, F1 Macro: 0.9568\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2506, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1657, Accuracy: 0.9606, F1 Micro: 0.9754, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1227, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.09, Accuracy: 0.9702, F1 Micro: 0.9812, F1 Macro: 0.9801\n",
      "Epoch 7/10, Train Loss: 0.0771, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9798\n",
      "Epoch 8/10, Train Loss: 0.0637, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0484, Accuracy: 0.9747, F1 Micro: 0.9841, F1 Macro: 0.9833\n",
      "Epoch 10/10, Train Loss: 0.0457, Accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9795\n",
      "\n",
      "Aspect detection accuracy: 0.9747, F1 Micro: 0.9841, F1 Macro: 0.9833\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.94      0.97      0.96       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.98      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.98      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.479, Accuracy: 0.9245, F1 Micro: 0.9245, F1 Macro: 0.9159\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2153, Accuracy: 0.9321, F1 Micro: 0.9321, F1 Macro: 0.9251\n",
      "Epoch 3/10, Train Loss: 0.1706, Accuracy: 0.9208, F1 Micro: 0.9208, F1 Macro: 0.9137\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1419, Accuracy: 0.9321, F1 Micro: 0.9321, F1 Macro: 0.9243\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1132, Accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.9371\n",
      "Epoch 6/10, Train Loss: 0.1059, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.9215\n",
      "Epoch 7/10, Train Loss: 0.089, Accuracy: 0.9321, F1 Micro: 0.9321, F1 Macro: 0.9255\n",
      "Epoch 8/10, Train Loss: 0.0749, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.9215\n",
      "Epoch 9/10, Train Loss: 0.0745, Accuracy: 0.9321, F1 Micro: 0.9321, F1 Macro: 0.9243\n",
      "Epoch 10/10, Train Loss: 0.0593, Accuracy: 0.9321, F1 Micro: 0.9321, F1 Macro: 0.9247\n",
      "\n",
      "Sentiment analysis accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.9371\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.95      0.92        87\n",
      "    positive       0.98      0.94      0.96       178\n",
      "\n",
      "    accuracy                           0.94       265\n",
      "   macro avg       0.93      0.95      0.94       265\n",
      "weighted avg       0.95      0.94      0.94       265\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9668, F1 Micro: 0.9668, F1 Macro: 0.9342\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.89      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.94      0.97      0.96       152\n",
      "    positive       0.91      0.81      0.86        52\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.87      0.87       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.99      0.99       152\n",
      "    positive       1.00      0.83      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.89      0.94      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.95      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 128.9869487285614 s\n",
      "Total runtime: 2844.4728820323944 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAACCoAAAHqCAYAAADInz0eAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAADmRElEQVR4nOzdeXhV9dmv8XsnkIF5HgIBBBEUFUQggBS1oiCKE+JcFKdqxfaIVsFZW0tbW6p1rq8oFXBAcUJFFIc6ICggoAgyyBQIM4QpIcne548VEiJByUB2Qu7Pda0ra6+19trPoj2n3zf7ye8JRSKRCJIkSZIkSZIkSZIkSWUgJtoFSJIkSZIkSZIkSZKkysNGBUmSJEmSJEmSJEmSVGZsVJAkSZIkSZIkSZIkSWXGRgVJkiRJkiRJkiRJklRmbFSQJEmSJEmSJEmSJEllxkYFSZIkSZIkSZIkSZJUZmxUkCRJkiRJkiRJkiRJZcZGBUmSJEmSJEmSJEmSVGZsVJAkSZIkSZIkSZIkSWXGRgVJkiRJklThXHHFFbRq1SraZUiSJEmSpGKwUUGSStHjjz9OKBQiJSUl2qVIkiRJJfLcc88RCoUK3YYPH5533ZQpU7jqqqs4+uijiY2NLXLzwJ57Xn311YWev+OOO/Ku2bBhQ0keSZIkSZWIeVaSyrcq0S5Akg4l48aNo1WrVsyYMYPFixdz+OGHR7skSZIkqUTuv/9+DjvssALHjj766Lz98ePH89JLL9G5c2eSkpKK9RkJCQm8+uqrPP7448TFxRU498ILL5CQkEBGRkaB408//TThcLhYnydJkqTKo7zmWUmq7FxRQZJKyY8//sgXX3zBqFGjaNiwIePGjYt2SYXasWNHtEuQJElSBXL66adz2WWXFdg6deqUd/4vf/kL6enpfP7553Ts2LFYn9GvXz/S09N59913Cxz/4osv+PHHHznjjDP2eU/VqlWJj48v1uftLRwO+0tjSZKkQ1h5zbMHm78HllTe2aggSaVk3Lhx1K1blzPOOIPzzz+/0EaFLVu2cNNNN9GqVSvi4+Np3rw5gwcPLrDkV0ZGBvfeey9HHHEECQkJNG3alPPOO48lS5YA8PHHHxMKhfj4448L3HvZsmWEQiGee+65vGNXXHEFNWrUYMmSJfTv35+aNWty6aWXAvDpp58yaNAgWrRoQXx8PMnJydx0003s2rVrn7oXLFjABRdcQMOGDUlMTKRdu3bccccdAHz00UeEQiFee+21fd43fvx4QqEQ06ZNK/K/pyRJkiqGpKQkqlatWqJ7NGvWjN69ezN+/PgCx8eNG8cxxxxT4C/e9rjiiiv2WZY3HA7z8MMPc8wxx5CQkEDDhg3p168fX3/9dd41oVCIoUOHMm7cODp06EB8fDyTJ08GYPbs2Zx++unUqlWLGjVqcMopp/Dll1+W6NkkSZJUvkUrz5bW72cB7r33XkKhEPPnz+eSSy6hbt269OrVC4Ds7Gz+9Kc/0aZNG+Lj42nVqhW33347mZmZJXpmSSopRz9IUikZN24c5513HnFxcVx88cU88cQTfPXVV3Tt2hWA7du386tf/Yrvv/+eK6+8ks6dO7NhwwbefPNNVq1aRYMGDcjJyeHMM89k6tSpXHTRRfzhD39g27ZtvP/++3z77be0adOmyHVlZ2fTt29fevXqxT/+8Q+qVasGwIQJE9i5cyfXX3899evXZ8aMGTzyyCOsWrWKCRMm5L1/7ty5/OpXv6Jq1apce+21tGrViiVLlvDWW2/xwAMPcNJJJ5GcnMy4ceM499xz9/k3adOmDT169CjBv6wkSZKiaevWrfvM0m3QoEGpf84ll1zCH/7wB7Zv306NGjXIzs5mwoQJDBs27IBXPLjqqqt47rnnOP3007n66qvJzs7m008/5csvv6RLly5513344Ye8/PLLDB06lAYNGtCqVSu+++47fvWrX1GrVi1uvfVWqlatylNPPcVJJ53EJ598QkpKSqk/syRJkg6+8ppnS+v3s3sbNGgQbdu25S9/+QuRSASAq6++mjFjxnD++edz8803M336dEaOHMn3339f6B+fSVJZsVFBkkrBzJkzWbBgAY888ggAvXr1onnz5owbNy6vUeHBBx/k22+/ZeLEiQW+0L/zzjvzQuN///tfpk6dyqhRo7jpppvyrhk+fHjeNUWVmZnJoEGDGDlyZIHjf/vb30hMTMx7fe2113L44Ydz++23s2LFClq0aAHAjTfeSCQSYdasWXnHAP76178CwV+kXXbZZYwaNYqtW7dSu3ZtANavX8+UKVMKdPZKkiSp4unTp88+x4qbTX/O+eefz9ChQ3n99de57LLLmDJlChs2bODiiy/m2Wef/cX3f/TRRzz33HP8/ve/5+GHH847fvPNN+9T78KFC5k3bx5HHXVU3rFzzz2XrKwsPvvsM1q3bg3A4MGDadeuHbfeeiuffPJJKT2pJEmSylJ5zbOl9fvZvXXs2LHAqg5z5sxhzJgxXH311Tz99NMA/O53v6NRo0b84x//4KOPPuLkk08utX8DSSoKRz9IUikYN24cjRs3zgt1oVCICy+8kBdffJGcnBwAXn31VTp27LjPqgN7rt9zTYMGDbjxxhv3e01xXH/99fsc2zsE79ixgw0bNtCzZ08ikQizZ88GgmaD//3vf1x55ZUFQvBP6xk8eDCZmZm88sorecdeeuklsrOzueyyy4pdtyRJkqLvscce4/333y+wHQx169alX79+vPDCC0AwRqxnz560bNnygN7/6quvEgqFuOeee/Y599MsfeKJJxZoUsjJyWHKlCmcc845eU0KAE2bNuWSSy7hs88+Iz09vTiPJUmSpCgrr3m2NH8/u8d1111X4PU777wDwLBhwwocv/nmmwF4++23i/KIklSqXFFBkkooJyeHF198kZNPPpkff/wx73hKSgr//Oc/mTp1KqeddhpLlixh4MCBP3uvJUuW0K5dO6pUKb3/77lKlSo0b958n+MrVqzg7rvv5s0332Tz5s0Fzm3duhWApUuXAhQ6Q21v7du3p2vXrowbN46rrroKCJo3unfvzuGHH14ajyFJkqQo6datW4GxCQfTJZdcwm9+8xtWrFjB66+/zt///vcDfu+SJUtISkqiXr16v3jtYYcdVuD1+vXr2blzJ+3atdvn2iOPPJJwOMzKlSvp0KHDAdcjSZKk8qG85tnS/P3sHj/NucuXLycmJmaf39E2adKEOnXqsHz58gO6ryQdDDYqSFIJffjhh6xZs4YXX3yRF198cZ/z48aN47TTTiu1z9vfygp7Vm74qfj4eGJiYva59tRTT2XTpk3cdttttG/fnurVq5OamsoVV1xBOBwucl2DBw/mD3/4A6tWrSIzM5Mvv/ySRx99tMj3kSRJUuV11llnER8fz+WXX05mZiYXXHDBQfmcvf96TZIkSSotB5pnD8bvZ2H/Obckq/VK0sFio4IkldC4ceNo1KgRjz322D7nJk6cyGuvvcaTTz5JmzZt+Pbbb3/2Xm3atGH69OlkZWVRtWrVQq+pW7cuAFu2bClwvCjdr/PmzeOHH35gzJgxDB48OO/4T5c927Ps7S/VDXDRRRcxbNgwXnjhBXbt2kXVqlW58MILD7gmSZIkKTExkXPOOYexY8dy+umn06BBgwN+b5s2bXjvvffYtGnTAa2qsLeGDRtSrVo1Fi5cuM+5BQsWEBMTQ3JycpHuKUmSpMrnQPPswfj9bGFatmxJOBxm0aJFHHnkkXnH165dy5YtWw54zJokHQwxv3yJJGl/du3axcSJEznzzDM5//zz99mGDh3Ktm3bePPNNxk4cCBz5szhtdde2+c+kUgEgIEDB7Jhw4ZCVyLYc03Lli2JjY3lf//7X4Hzjz/++AHXHRsbW+Cee/YffvjhAtc1bNiQ3r17M3r0aFasWFFoPXs0aNCA008/nbFjxzJu3Dj69etXpF8sS5IkSQC33HIL99xzD3fddVeR3jdw4EAikQj33XffPud+ml1/KjY2ltNOO4033niDZcuW5R1fu3Yt48ePp1evXtSqVatI9UiSJKlyOpA8ezB+P1uY/v37A/DQQw8VOD5q1CgAzjjjjF+8hyQdLK6oIEkl8Oabb7Jt2zbOOuusQs93796dhg0bMm7cOMaPH88rr7zCoEGDuPLKKzn++OPZtGkTb775Jk8++SQdO3Zk8ODB/Pe//2XYsGHMmDGDX/3qV+zYsYMPPviA3/3ud5x99tnUrl2bQYMG8cgjjxAKhWjTpg2TJk1i3bp1B1x3+/btadOmDbfccgupqanUqlWLV199dZ9ZaAD//ve/6dWrF507d+baa6/lsMMOY9myZbz99tt88803Ba4dPHgw559/PgB/+tOfDvwfUpIkSRXW3LlzefPNNwFYvHgxW7du5c9//jMAHTt2ZMCAAUW6X8eOHenYsWOR6zj55JP5zW9+w7///W8WLVpEv379CIfDfPrpp5x88skMHTr0Z9//5z//mffff59evXrxu9/9jipVqvDUU0+RmZn5s7OFJUmSVLFFI88erN/PFlbL5Zdfzn/+8x+2bNnCiSeeyIwZMxgzZgznnHMOJ598cpGeTZJKk40KklQC48aNIyEhgVNPPbXQ8zExMZxxxhmMGzeOzMxMPv30U+655x5ee+01xowZQ6NGjTjllFNo3rw5EHTSvvPOOzzwwAOMHz+eV199lfr169OrVy+OOeaYvPs+8sgjZGVl8eSTTxIfH88FF1zAgw8+yNFHH31AdVetWpW33nqL3//+94wcOZKEhATOPfdchg4duk+I7tixI19++SV33XUXTzzxBBkZGbRs2bLQ+WoDBgygbt26hMPh/TZvSJIk6dAya9asff5abM/ryy+/vMi/2C2JZ599lmOPPZZnnnmGP/7xj9SuXZsuXbrQs2fPX3xvhw4d+PTTTxkxYgQjR44kHA6TkpLC2LFjSUlJKYPqJUmSFA3RyLMH6/ezhfm///s/WrduzXPPPcdrr71GkyZNGDFiBPfcc0+pP5ckFUUociBrw0iSdACys7NJSkpiwIABPPPMM9EuR5IkSZIkSZIkSeVQTLQLkCQdOl5//XXWr1/P4MGDo12KJEmSJEmSJEmSyilXVJAkldj06dOZO3cuf/rTn2jQoAGzZs2KdkmSJEmSJEmSJEkqp1xRQZJUYk888QTXX389jRo14r///W+0y5EkSZIkSZIkSVI55ooKkiRJkiRJkiRJkiSpzBRrRYXHHnuMVq1akZCQQEpKCjNmzNjvtVlZWdx///20adOGhIQEOnbsyOTJkwtc06pVK0Kh0D7bDTfckHfNSSedtM/56667rjjlS5IkSXnMtpIkSZIkSZJUtorcqPDSSy8xbNgw7rnnHmbNmkXHjh3p27cv69atK/T6O++8k6eeeopHHnmE+fPnc91113Huuecye/bsvGu++uor1qxZk7e9//77AAwaNKjAva655poC1/39738vavmSJElSHrOtJEmSJEmSJJW9Io9+SElJoWvXrjz66KMAhMNhkpOTufHGGxk+fPg+1yclJXHHHXcU+AuygQMHkpiYyNixYwv9jP/3//4fkyZNYtGiRYRCISD4q7NOnTrx0EMPFaXcPOFwmNWrV1OzZs28e0qSJKliikQibNu2jaSkJGJiirVIGGC2lSRJUvSVVratqMy2kiRJh46iZNsqRbnx7t27mTlzJiNGjMg7FhMTQ58+fZg2bVqh78nMzCQhIaHAscTERD777LP9fsbYsWMZNmzYPsF03LhxjB07liZNmjBgwADuuusuqlWrtt/PzczMzHudmprKUUcddUDPKUmSpIph5cqVNG/evFjvNdtKkiSpPClJtq3IVq9eTXJycrTLkCRJUik6kGxbpEaFDRs2kJOTQ+PGjQscb9y4MQsWLCj0PX379mXUqFH07t2bNm3aMHXqVCZOnEhOTk6h17/++uts2bKFK664osDxSy65hJYtW5KUlMTcuXO57bbbWLhwIRMnTiz0PiNHjuS+++7b5/jKlSupVavWATytJEmSyqv09HSSk5OpWbNmse9htpUkSVJ5UBrZtiLb89xmW0mSpIqvKNm2SI0KxfHwww9zzTXX0L59e0KhEG3atGHIkCGMHj260OufeeYZTj/9dJKSkgocv/baa/P2jznmGJo2bcopp5zCkiVLaNOmzT73GTFiBMOGDct7vecfpVatWgZeSZKkQ0RZLw1rtpUkSdLBUlnHHux5brOtJEnSoeNAsm2Rhp41aNCA2NhY1q5dW+D42rVradKkSaHvadiwIa+//jo7duxg+fLlLFiwgBo1atC6det9rl2+fDkffPABV1999S/WkpKSAsDixYsLPR8fH58Xbg25kiRJ+imzrSRJkiRJkiRFR5EaFeLi4jj++OOZOnVq3rFwOMzUqVPp0aPHz743ISGBZs2akZ2dzauvvsrZZ5+9zzXPPvssjRo14owzzvjFWr755hsAmjZtWpRHkCRJkgCzrSRJkiRJkiRFS5FHPwwbNozLL7+cLl260K1bNx566CF27NjBkCFDABg8eDDNmjVj5MiRAEyfPp3U1FQ6depEamoq9957L+FwmFtvvbXAfcPhMM8++yyXX345VaoULGvJkiWMHz+e/v37U79+febOnctNN91E7969OfbYY4v77JIkSarkzLaSJEmSJEmSVPaK3Khw4YUXsn79eu6++27S0tLo1KkTkydPpnHjxgCsWLGCmJj8hRoyMjK48847Wbp0KTVq1KB///48//zz1KlTp8B9P/jgA1asWMGVV165z2fGxcXxwQcf5P3iODk5mYEDB3LnnXcWtXxJkiQpj9lWkiRJkiRJkspeKBKJRKJdRFlIT0+ndu3abN261Zm+kiRJFVxlz3aV/fklSZIOJZU921X255ckSTqUFCXbxfzsWUmSJEmSJEmSJEmSpFJko4IkSZIkSZIkSZIkSSozNipIkiRJkiRJkiRJkqQyY6OCJEmSJEmSJEmSJEkqMzYqSJIkSZIkSZIkSZKkMmOjgiRJkiRJkiRJkiRJKjM2KkiSJEmSJEmSJEmSpDJjo4IkSZIkSZIkSZIkSSozNipIkiRJkiRJkiRJkqQyY6OCJEmSSmTWLBg9GnJyol2JJEmSVEKbZsGS0RA23EqSJKliW7NtDX/59C9EIpFol1KoKtEuQJIkSRVXJAI33wwffwyLFsHIkdGuSJIkSSqmSARm3QzrPoZti6CT4VaSJEkV0/od6+nzfB/mr59PRnYG9598f7RL2ocrKkiSJKnY3n03aFKIj4frrot2NZIkSVIJrH43aFKIiYe2hltJkiRVTJt3bebU509l/vr5NKvZjCGdhkS7pEK5ooIkSZKKJScHbrst2L/xRmjZMrr1SJIkScUWzoFvcsNtuxuhuuFWkiTpULN8y3LeX/o+M1JnkJmTSXY4m5xwDjmRnAL7OeHc17+w37hGY05rfRr9Du9HpyadCIVC0X5E0jPT6TeuH3PWzqFx9cZ8ePmHHFb3sGiXVSgbFSRJklQszz8P334LderAiBHRrkaSJEkqgWXPw9ZvoWodOMpwK0mSKp/0zHRqxtUsF1+2l5Ztmdv4eNnHTFkyhSlLp/DDxh9K9f7fb/iej5d9zO0f3k6TGk3o26Yv/Q7vx6mtT6V+tfql+lkHYsfuHZwx/gxmpM6gfmJ9Phj8AUfUP6LM6zhQNipIkiSpyHbtgrvuCvZvvx3q1YtuPZIkSVKxZe+CubnhtsPtEG+4lSRJh75IJMK3677llfmv8Or3r/Ld+u84ov4RXNnpSgZ3HEzTmk2jXWKR5YRz+Hr117y/9H2mLJnCtFXTyA5n552PDcXSvXl3Tmp1ErXjaxMbE0uVmCrEhmL32Y8N5b7ez35MKIbvN3zP5MWT+fDHD0nbnsaYOWMYM2cMIUJ0a9aNfof3o9/h/eia1JXYmNiD+uy7snZx1otn8dmKz6gdX5v3f/M+Rzc6+qB+ZkmFIpFIJNpFlIX09HRq167N1q1bqVWrVrTLkSRJqtD+9jcYPhySk+GHHyAhoWw/v7Jnu8r+/JIkSaVq/t/gm+FQLRkG/ACxZRtuK3u2q+zPL0lSWYpEIsxcM5NX57/Kq9+/yqJNiwq9LjYUy+ltT+fKTldyxhFnEBcbVyb1bd+9nQ+WfsBbC99iVtosftXiV1x53JV0atJpv+9ZtmUZ7y95nylLpzB16VQ2Z2wucP7weodzWuvTOLXNqZzc6mRqJ9Qu9bozszP5fOXnTF48mcmLJzNv3bwC5+sm1OW0NsGIiL5t+ha7CSQrJ4u07Wmkbktl9bbVeVvqtlRmr5nNvHXzqBFXg/d/8z7dm3cvjUcrsqJkOxsVJEmSVCQbN0KbNrB1K4wZA4MHl30NlT3bVfbnlyRJKjWZG+HNNpC1FbqPgdZlH24re7ar7M8vSdLBFo6EmbZyGq9+/yoTv5/I8q3L887Fx8bT9/C+DDxyICe3Opn3l77PM7Of4YuVX+Rd07BaQwZ3HMyQTkPo0KhDqde3fMtyJv0wiUmLJvHRjx+RmZO5zzXHNTmOK4+7kkuOuYQqMVX46MeP8lZN+GmzRZ2EOpxy2Cmc2vpUTm1zKq3rti71mn/JqvRVvLf4PSYvmcz7S95na+bWAuc7Nu7I6YefTr/D+9EjuQdVYqqwfsf6fZoPfvp6/Y71RNj/V/uJVRKZfNlkerfsfbAfcb9sVCiEgVeSJKl03HwzjBoFxx4Ls2ZB7MFdtaxQlT3bVfbnlyRJKjWzboYFo6DOsdBvFhzkJXkLU9mzXWV/fklSdIQjYT5e9jFz186lU5NOdE3qSvW46tEuq9Rkh7P5dPmnec0Ja7avyTtXrWo1zmh7BgOPHEj/tv2pGV9zn/cv2LCAZ2c/y5g5Y1i7Y23e8ZRmKVx53JVc2OHCYq9MkBPOYUbqDCb9MIm3fnhrn9UHWtdtzYAjBtAlqQtvLnyTNxa+we6c3QDExcaRE84hJ5KTd31sKJYeyT3yVk3oktSFKjFVilXbwZAdzmb6qunBagtLJvP16q8LnE+skkhWOKvAiIqfUzWmKk1rNqVZzWYk1UwiqWZS3n7vlr1pWaflwXiMA2ajQiEMvJIkSSW3bBm0awe7d8O770K/ftGpo7Jnu8r+/JIkSaVi+zKY1A7Cu+GkdyEpOuG2sme7yv78kqSytW7HOp775jmenvU0izctzjseG4rluKbH0bN5T05ocQI9k3vSvFbzKFZadLtzdvPhjx/y6vxXeX3h62zYuSHvXK34WpzV7iwGHjmQvm36klg18YDumZWTxeTFkxn9zWgm/TAp78v0xCqJnH/U+Vx53JX0btmbmFDMz94nPTOd95e8z1s/vMU7i95h/c71eediQjGckHwCZx5xJgOOGED7Bu0JhUJ55zfu3Mj4eeN5ZvYzzFk7B4C29dpyWpvTOLX1qZx82MnUiq84GWLdjnVMWTKFyYsn896S9/L+cwoRolH1RjSrlduAUCO3CaFWwYaE+tXq/+K/dzTZqFAIA68kSToQK1fC5MnBKgGdOkGHDhAfH+2qiicSgTVr4Jtv4LvvguaCkvrgA/j4Y/j1r4P9vf5vhjJV2bNdZX9+SZJ0gHashDWTIRQLdTtB7Q4QW4HD7a41sPkb2Ppd0FxQUmkfwLqPofGv4dfRC7eVPdtV9ueXJB184UiYj378iP/M+g+vff8aWeEsAGrG1eRXLX/F3LVzWZW+ap/3JddKDpoWcpsXjm18bLn4S/1IJMLGXRtZs20Na7avYfW21Xy07CPeXPgmWzK25F1XP7E+Z7c7m4FHDeSUw04hvkrJcuDa7WsZO3csz8x+hu83fJ93vHXd1lzZ6Uou73R5geaOHzf/yFs/vMWkHybx8bKP8/7dAWrH16bf4f0YcMQA+h3ej/rV6h9QDQs3LCS+Sjyt6rQq0bOUF+FImB82/kD1qtVpUqMJVWOrRrukErNRoRAGXkmSVJhIJPgi/8034Y03YPbsguerVIEjj4SOHYPGhU6dgv0GDaJQ7M/IyoKFC2HOnOB59mwbNvzCG4vp66/h+OMPzr0PRGXPdpX9+SVJ0n5EIsEX+alvwqo3YPNPwm2oCtQ+Eup0DBoX6nYK9hPKWbgNZ0H6Qtg8B7Z8EzzT5m8g8yCF235fQ73ohdvKnu0q+/NLkg6e/a2e0K1ZN67tfC0XHX1R3riHlVtX8vnKz/li5Rd8vvJz5qTNKTBeAIKRCSnNUjghOVhxoXvz7tRNrFtq9WaHs1m3Y11eA8I+P3P307anFfjSf2+NqzfmvCPPY+CRAzmx1YkHpbEiEokwI3UGo2eP5oVvX2Db7m1AsDLCaW1Oo0PDDry7+F3mr59f4H1t67VlwBEDOPOIM+nVotch8aW89mWjQiEMvJIkaY9IBObOhXHj4KWXYMWK/HOhEPTsGayi8M03sGlT4fdo1iy/cWFP80KbNhBTBqtubd0a1P/NN/mNCd9+C5mZ+14bEwPt28Mxx0DNfcfNFUuvXnD55aVzr+Kq7Nmusj+/JEnaSyQCW+bCsnGw/CXYuVe4JQQNe0JMfPBF/+79hNvEZvmNC3uaF2q2gbJYUnb31qD+zd/Aljm5P7+FcCHhNhQLtdpDnWOgSimF24a9oPXg0rlXMVX2bFfZn1+SVLr2rJ7w1MyneH3B6wVWT7js2Mu49vhr6dSk0y/eZ/vu7XyV+lVe88K0VdMKrFawR4eGHeiZ3JMTkk/guKbHEY6E2bF7Bzuydvzyz6wdpGemk7Y9jTXb1rB+53rCkfABP2v9xPo0rdmUpjWa0qFhB8478jx6JvckNib2gO9RUjt272Di9xN5ZvYzfLL8kwLnYkOx/Krlrziz7ZkMaDeAI+ofUWZ1KXpsVCiEgVeSpOjKzoZ164Iv/tu2jc44hRUrYPz4oEHh22/zj1erBqedBmefDWecAQ0bBscjEVi1at9VCpYsKfz+NWrAscfmNy506AAJCSWrORKB1avzP3vOHFi6tPBra9bM//w9W4cOkHhgI+cqlMqe7Sr780uSFHXhbMhYF3zxX7NtdMYp7FgBy8YHDQpb9wq3sdWg6WnQ/GxIOgMS9gq3O1flNwPs2bbvJ9xWqQF1js1tXuiYOzaiFMLtrtX5n71lDmzfT7itUjP43L2bJ2p3gCqHXrit7Nmusj+/JB0qlmxawnPfPMfmjM20rdeWw+sdTtv6bTmszmFl8pfz63as49nZz/L0rKdZsjk/33Rr1o3fHv9bLuxwYd7qCcURjoT5fv33eSsufLHyCxZtWlQapRcQE4qhcfXGeQ0ITWs0zd/f62eTGk2Ii40r9c8viSWbljBmzhhWb1vNKYedQr/D+5XqihOqGGxUKISBV5Kk0heJBI0HaWn739auDX5u2BBcD0FjwMknQ79+0LcvHH74wRsHu3kzvPIKjB0L//tf/vG4OBgwAC69NKijKF/mp6fDvHkFmwfmzYOMjNKufv+Sk/MbIvY0JRx2WNms6FAeVPZsV9mfX5KkgyISCRoPdqVBRlr+zwL7a4P9zA1AbriNrQaNT4am/aBpX6h5EMPt7s2w4hVYNhbW7RVuY+Kg2QBodWlQR1G+zM9Khy3z9mpemANb50FOGYbbasn7ruhQ47CyWdGhHKjs2a6yP78kVWQ54RzeWfQOj3/9OJMXTy70mthQLC3rtKRtvbbBVj+3iaFeW1rVaVWiJoZwJMyHP37If2b+p8DqCbXia3HZMZdxzfHXHNDqCcW1bsc6pq2clte8MH/9fOKrxFO9anWqx1Uv/OdPjtWMq0njGo3zGhAaVmtYpisiSKXNRoVCGHglSSq+tWvhxReDL+P3bkJYtw6yCh+HVqjY2KBJYdu2gsdbt85vWjj55JKPKMjIgHfeCZoT3n4bdu/OP3fSSXDZZTBwINSpU7LP2Vt2NvzwQ8FxDAsXQk7OL73zl9WrV3CVhGOPhfr1S37fiqyyZ7vK/vySJJXIrrWw/MXgy/i9mxIy18F+Zv0WKhQbNClk/yTc1mid37TQ+GSoWsJwm5MBq9+BH8fC6rchvFe4bXQSHHYZJA+EuDol+5y9hbNh2w/5jQubv4FtCyFSCuE2rt6+TQnx9Up+3wqssme7yv78klQRrd2+lmdmP8NTM59ixdb8sVP9Du/HsY2OZfHmxSzeFGw7s3bu9z6xoVha1WlF2/pt8xoZ9qzE0KpOK6rEVNnv5z/3zXMHbfUEScVno0IhDLySJBVNZiZMmgTPPQfvvvvzX7jXrw9NmhTcGjfe91j9+sEfl82bB5MnB9tnnxVsdqhaFXr1CpoW+vULvpQ/kD9IC4eDFRPGjYMJE2Dr1vxzxxwTNCdcfHGwEoEqvsqe7Sr780uSVGQ5mZA6CZY+B2ve/fkv3OPrQ0KTYEvM/ZnQOH9/z8/4+kAoWI1gzeRgW/9ZwWaHmKrQsFfQtNC0XzBK4UDCbSQcrJiwbBysmABZe4XbOsdAq8ug5cVQ3XB7KKjs2a6yP7+k8m9b5jY+/PFDdmbtpHpcdWrE1aB61dyfe71OqJJA6GCtqlQORCIRPlvxGY9//Tivzn81b/WCeon1uOq4q/jt8b+lTb02+7xn9bbVLN60mEWbFrFo4yIWb14c/Ny0mF3Zu/b7eVViqgRNDHs1MDSq3ohXv381KqsnSDowNioUwsArSYqGVavg7ruDL9Bbt4ajj87fjjoKatSIdoUFRSLw9dcwZgy88EIw1mGP7t3h9NOhWbOCjQiNGgVjFIpr+3b46KP8xoWlPxlR27Rp0LTQty+ceuq+KwnMmxesnPDCC7ByZf7x5s3hkkuC0Q7HHlv8+lQ+VfZsV9mfX5IUJTtXwdy7gy/Qa7SG2kdDnaODn7WPgqrlMNxu+hqWjoHlLwRjHfao3x2STodqzQo2IsQ3gpLM+s3aDms/ym9c2P6TcJvYNGhaaNIXmp6a2+ywly3zgpUTlr8AO/cKt9WaQ8tLgtEOdQ23h5rKnu0q+/NLKp/W71jPmwvf5LUFr/H+0vfZnbP7F98TE4optIFhn+aGQq75udfVqlYjJorjkLZlbmPs3LE8/vXjfLvu27zj3Zt35/ou1zPoqEEkVi3C2Klc4UiYNdvW5DUwLNq0KK+hYfGmxWRk//wYqpRmKVx7/LWuniCVMzYqFMLAK0kqS9u2wd/+BqNGwa79NwZz2GEFmxeOPhratYP4+LKrFWD16uDL/jFjYP78/OPNmsFvfgOXXw7t25dNLYsXBw0L770HH34IO/daHS4Ugm7dgqaFatVg/HiYOzf/fO3acP75weoJvXtDTOUYaVspVfZsV9mfX5JUxrK2wfy/wYJRkPMz4bb6YfmNC3t+1moHsWUcbneuhmVj4ccxsHWvcJvYDA77DRx2OdQuo3C7bTGsngxr3oO1H0LO3ksfh6B+t6BxoUo1WDYetuwVbqvWhhbnB6snNOoNUfyCQgdXect2jz32GA8++CBpaWl07NiRRx55hG7duhV6bVZWFiNHjmTMmDGkpqbSrl07/va3v9GvX78D/rzy9vySKq/lW5bz+oLXeW3Ba3y64lPCkXDeubb12pJcO5ntu7ezY/eO4GdW8POXvlAvqRAh6iTUoX61+tRLrEf9xPyf+xzb63Wt+FolWuFh3tp5PPH1Ezw/93m2794OQGKVRC495lKu73o9nZt2Lq1H3Ec4Emb1ttX7NDCs3Loyb7xDxyYdD9rnSyo+GxUKYeCVJJWF7Gx45plgFYV164JjvXrBH/8I69fDt9/mb2lphd8jNhaOOGLfBoY2bYJzpSUjA954I2hOeO+9YHQCQEICnHsuXHEFnHJK6X5mUWVmBqMh3nsvaF6YN2/fa6pWhTPPDFZOOOOMoH4d+ip7tqvszy9JKiPhbFjyDMy7GzJyw23DXnDkHyFzPWz5FrZ+G/zM2E+4DcVCzSP2bWCo0QZiSjFo5mTAqjeC1RPS3gtGJwDEJkDzc6H1FdD4lNL9zCLXmBmMhljzXrDawpZCwm1MVUg6M1g5odkZQf065JWnbPfSSy8xePBgnnzySVJSUnjooYeYMGECCxcupFGjRvtcf9tttzF27Fiefvpp2rdvz3vvvcewYcP44osvOO644w7oM8vT80uqXCKRCN9v+J7Xvn+NiQsmMmvNrALnOzftzLntz+Xc9udyVMOj9vulf044hx1ZO/ZpYPjF14Uc/+k1JREbit2neeGXGhxqxddi8uLJPP7V43y64tO8e7Wr347fdf0dgzsOpk5CnRLVJenQZqNCIQy8kqSDKRKBd98NGhL2rEhw+OHw97/DOecUPoZ2wwb47ruCzQvz5sHWrfteC8EX8EceGYyMaNMGWrXK35KToUqVA6tz+vSgOeHFF2HLlvxzJ5wQrJxwwQXBygTlUWoqTJkSNC2kpwcNFeefD/XqRbsylbXKnu0q+/NLkg6ySARWvwvf/DF/RYIah8Nxf4fm5xQebjM2wNbv8hsXtn4bfBGftZ9wG5sAtY4MRkbUaAPVW0GNVsHPaskQc4DhduP03NEOL0LWlvxzDU8IVk5ocQHEldNwuzMV1kwJmhay0iH5XEg+H+INt5VNecp2KSkpdO3alUcffRSAcDhMcnIyN954I8OHD9/n+qSkJO644w5uuOGGvGMDBw4kMTGRsWPHHtBnlqfnl3ToC0fCfL36ayZ+P5HXFrzGDxt/yDsXE4qhV4tenNv+XM5pfw6t6rSKXqEEjRS7sneRnpnOpl2b2LRrExt3bmTjro15+5t2bcp/vWtj3rFd2T+zCtYBig3Fck77c/hd199xcquTS7Q6g6TKoyjZ7gD+rz5JkvRz5syBW26BDz4IXterB/fcA9ddB3E/M962QQM48cRg2yMSCcYw7N288O23QUPDrl0we3aw/VRsLDRvHjQtHHZYfgPDnn2AceOCBoWFC/Pfl5wMgwcHDQpt25bs36EsNGsGQ4YEmyRJkg6CzXNg9i2Qlhtu4+rBMffA4ddB7M+E24QGkHAiNP5JuN21Or9xIa+J4btghMTm2cH2U6FYqNY8t3nhsODn3vsAy8YFox3S9wq31ZLhsMFBg0KtChBuqzWDNkOCTSoHdu/ezcyZMxkxYkTesZiYGPr06cO0adMKfU9mZiYJP1nWLjExkc8++2y/n5OZmUlmZmbe6/T09BJWLqk40ran8VXqV3y1+iu+Xv01WzK20L5Bezo07ECHRh04quFRJNdKPiS+nM7KyeJ/y//Hawte4/UFr5O6LTXvXFxsHH1a9+Hc9udyVruzaFR939VjoiUUClGtajWqVa1GkxpNivTeXVm7CjYxHGCDQ1Y4i6SaSVzb+Vqu7nw1zWo1O0hPJ0k2KkhSufH663DjjcGXzTfeGPyV+M99yV3ZZGTAhx8GowreeSf4Yv7UU6Fv32A8Qd26ZV/T6tVw553w3HPB72Dj4uD3v4c77oA6dYp3z1Ao+DK+WbPg2fbIyYFly4Kmhe+/hx9/DF7v2XbvhuXLg+2TT37+MxITYeDAYLTDySdDjKNuJUlSaVv5Osy8ERKbQ7sbg78S/7kvuSubnAxI+xBS34DV7wRfzDc5FZr2hSanQFwUwu3O1TD3Tlj6HBCBmDho93vocAfE1SnePUOh4Mv4as0gaa9wG86BHctymxe+hx0/wvZlwbEdyyC8G3YsD7Z1vxBuYxMheWDuaIeTIWS4lYprw4YN5OTk0Lhx4wLHGzduzIIFCwp9T9++fRk1ahS9e/emTZs2TJ06lYkTJ5KTk7Pfzxk5ciT33XdfqdYu6edt3rWZr1d/zderv+ar1UFzwqr0VftcN21VwaakmnE1OarhURzV8KgK18CwK2sXU5ZM4bUFr/HWD2+xademvHM14mrQv21/zmt/Hqe3PZ1a8Yfeai6JVRNpVrVZkRoNIpEIO7J2UK1qNWLMVJLKgKMfJCnKduyAYcPgP/8peLxJE7j+evjtb+EnvyOoNDZsgLffhjffhPfeC/6tChMTA926BV/s9+0b7McexNGz27fDgw/CP/4BO3cGxy68EEaODFYwKGvhMKSlFWxc2LuRYflyyMqC3r2DlRPOPx/8n0JVdJU921X255dUjmXvgFnDYPFPwm1CE2h7PRz+W0ispOE2YwOsfhtS34Q17wX/VoUJxUC9bkHTQtO+UL8bxBzEcJu1Hb5/EL7/B+TkhtsWF0KnkcEKBmUtEoZdaflNCzuWwfYfc38ug53LIZwFjXrnjnY4H6r6v4Wq2MpLtlu9ejXNmjXjiy++oEePHnnHb731Vj755BOmT5++z3vWr1/PNddcw1tvvUUoFKJNmzb06dOH0aNHs2tX4cuOF7aiQnJyctSfXzpU7Ni9g1lrZhVoSli8afE+14UIcVTDo+jarCtdmnahQbUGLNiwgO/Wf8d367/jh40/kB3OLvQzasTVyG9eaBg0L3Ro1CHqDQxbMrbw9g9v89qC13h38bvszNqZd65BtQac3e5szm1/Lqe0PoWEKgk/cydJUnEVJdvaqCBJUTR7Nlx8cbAUfygEN98cfIH8xBOwZk1wTVxc8CX4738PXbpEt96ysGhR0Jjwxhvw+efBl/B7NGsGZ50VbJFI0LwwZUqwwsDe6tSBPn3yGxeSk0untpwcePZZuOuuoDEAoGdP+Oc/oXv30vmMgyEnJxgbUaNGtCuRSk9lz3aV/fkllVObZsMXF+cuxR+CI2+GKrVg8ROwKzfcxsQFX4K3+z3UrwThNn1R0Jiw6g3Y8HnwJfweic2g+VnQ7CwgEjQvrJkC6T8Jt1XrQJM++Y0L1Usp3IZzYOmzMPcuyMgNtw16Qud/QoNyHG7DOcHYiKqGWx06yku22717N9WqVeOVV17hnHPOyTt++eWXs2XLFt544439vjcjI4ONGzeSlJTE8OHDmTRpEt99990BfW55eX6pItqds5u5a+fmjXD4avVXzF8/n/DemSNXm7pt6JLUha5JXenarCudm3amRtz+//c0KyeLRZsW8d2675i/fn65bWBI257GGwve4LUFr/Hhjx+SFc7KO9eidgvObX8u57Y/lxNanECVGBcZl6SDzUaFQhh4JZUn4TD8618wYkTwl+5JSfD88/DrXwfnd++GiRPh3/+GvcdA9ugRjIUYOPDQGQsRDsP06UFjwptv7tt00LEjnH120JzQuXPQ0PFTK1YEDQvvvQcffABbthQ8f+SR+U0LvXtDtWpFr/O99+CWW4LRCwBt2sDf/gbnnVd4TZIOrsqe7Sr780sqZyJhWPAvmDMi+Ev3xCTo8Tw0yQ23Obth5UT44d+wYa9w26AHHHFjsGz/oTIWIhKGDdODkQ6r3ty36aBOR2h+dtCgUHc/4XbHiqBhYc17kPYBZG0peL7WkflNC416Q5VihNvV78HsW4LRCwA12kCnv0Gy4VaKhvKU7VJSUujWrRuPPPIIAOFwmBYtWjB06FCGDx/+i+/PysriyCOP5IILLuAvf/nLAX1meXp+qTzLCefw/YbvCzQlzF07l905u/e5NqlmUtCQkNuU0CWpC/US65VKHXsaGOavn89364Lmhfnr57Nw48Iya2BYunkpr33/Gq8teI0vVn5BhPyvuY5qeFRec0Lnpp3L/YgKSTrU2KhQCAOvpPJi9Wq44gp4//3g9TnnwP/9H9SvX/j1X30FjzwCL74YNDUANG0ajIW49tqKORZi586goeDNN+Gtt2DduvxzVarASSflr5zQsmXR7p2dHfybvfdesM2YUXBVhvh4+NWv8hsXjj76538XO28e/PGPwb0A6taFu++G3/3u0GkWkSqiyp7tKvvzSypHdq6GL6+AtNxw2/wcSPk/iN9PuN34FSx8BFa8GDQ1ACQ2hcOvh8OvrZhjIbJ3Bg0FqW9C6luQsVe4DVWBxicFqyY0PwuqFzHchrODf7M17wXbphkFV2WIiYdGv8pvXKj9C+F2yzyY/cfgXgBxdeHou6Ht7w6dZhGpAipP2e6ll17i8ssv56mnnqJbt2489NBDvPzyyyxYsIDGjRszePBgmjVrxsiRIwGYPn06qampdOrUidTUVO69915+/PFHZs2aRZ06dQ7oM8vT80vlRSQSYcnmJQWaEmatmVVglMEe9RLr7dOUkFQzqcxr3l8Dww8bfyiwysHeDrSBIRKJMG/dPF77/jUmLpjI3LVzC9ynW7NunNf+PM498lyOqH/EQX1OSdLPs1GhEAZeSeXBm2/ClVfCxo2QmAgPPQTXXHNgf7SUlgb/+U8wFmLP2IG4OLjoomAsxPHHH9TSSyw1FSZNCrapU4NRBHvUqgX9+wcrJ/TrF4xuKC2bNweft6dxYeXKgueTkuC004KmhVNPzW8YWbMmaEgYPTpodKhaNVjN4o47oF7pNKBLKoHKnu0q+/NLKidWvQnTr4TMjRCbCMc/BG0OMNzuSoPF/4FFT+SPHYiJg5YXBWMh6pXzcLszFVInBdvaqcEogj2q1oKk/tDsbEjqB3F1Su9zd2+GtKn5jQs7fxJuE5Og6WnQpC80PTW/YWTXGph7NywdHTQ6xFQNVrPocAfEG26laCtv2e7RRx/lwQcfJC0tjU6dOvHvf/+blJQUAE466SRatWrFc889B8Ann3zC9ddfz9KlS6lRowb9+/fnr3/9K0lJB/4laXl7fqmsRSIRUrel5jUlfL36a75e/TWbMzbvc22NuBoc3/T4Ak0Jh9U5rFyvGpCVk8XiTYuD0RHrvmP+hqCR4UAbGGrG1WTSokks3bw073xsKJYTW53Iee3P4+z2Z9O8VvOyehxJ0i+wUaEQBl5J0bRzZzA24IkngtfHHQfjx0P79kW/1+7d8MorwViI6dPzj/fsGTQsnHde8KV6tIXDMHNmsGLCpEkwe3bB8y1aBCsmnH12MI6hLFYniERgwYL8poVPPinYMBEKQZcucOyxwQoWO3YExwcNgpEjg3EPksqHyp7tKvvzS4qy7J3B2IBFueG27nHQczzULka4zdkNK1+Bhf+GjXuF2wY9g4aF5POCL9WjLRKGTTODFRNSJ8Hmn4Tbai2CFROanw0Ne5fN6gSRCKQvyG9aWPdJwYYJQlCvC9Q9Fpa/CNm54bbFIOg4EmoabqXyorJnu8r+/Kp8NuzcwFepQUPCntUS0ran7XNdfGw8nZp0oktSl7zGhHb12xEbExuFqktfURsYEqok0LdNX85tfy5nHnEm9avtZwUvSVJU2ahQCAOvpGiZMwcuvhi+zx1Pe8st8Oc/ByMISmr69GAsxMsv54+FSEoKxhJcey00bFjyzyiK7duDkRaTJsHbb8PatfnnQiHo3h3OPDPYjjkm+uNvMzLgs8/yGxfmzSt4vnt3+Oc/gyYQSeVLZc92lf35JUXR5jnw+cWQnhtuj7wFjv0zxJZCuN0wHX54BFa8vNdYiKRgLMHh10JCGYfbrO3BSIvUSbD6bcjYK9wSggbdodmZkHQm1CkH4TYnA9Z/lt+4sOUn4bZ+d+j8T2houJXKm8qe7Sr78+vQtjNrJ1+lfsWM1Bl5TQnLtizb57rYUCwdGnUoMMLh6EZHE1cJRzPt3cAwf/181u1Yx8mtTqbf4f2oHlc92uVJkn6BjQqFMPBKKmvhMDz8MAwfHqyC0LQpjBkTjBcobWvWwFNPwZNP5jcHxMcHDRI33gidO5f+Z+6xfHn+qgkffRQ86x41agQjFQYMgNNPh0aNDl4dpWH1apgyJVgJondvOP/86P++WVLhKnu2q+zPLykKImFY+DB8MxzCuyGxKXQfE4wXKG271sCip2Dxk/nNATHx0OriYFxBvYMYbncsh1VvwepJsPaj4Fn3qFIDmvaFZgMg6XRIKOfhdudqSJsSrATRqDckG26l8qqyZ7vK/vw6tKzbsY7PV3zOZys+4/OVnzNzzUyyw9n7XHdE/SMKNCV0atKJalWrRaFiSZJKl40KhTDwSipLaWlw+eXBl94QjDh45hlo0ODgfm5mZjAW4uGH4auv8o+fcEIwFuLcc0s+FiInJ1jJYdKkoEHh228Lnm/dOmhMOPPMshvpIKnyqezZrrI/v6QytisNpl0efOkN0OwsSHkGEg5yuM3JhBWvBA0Sm/YKtw1PgCN+D8nnlnwsRDgnGDmROikY67D1J+G2RuugMaHZmWU30kFSpVPZs11lf35VXJFIhB82/pDXlPDZis9YtGnRPtcl1UyiR/MeeU0JnZt2pk5CnbIvWJKkMlCUbFeljGqSpEpj0iS48kpYvx4SE2HUKPjtb8vmj5fi4+HSS4Nt+nT497+DsRCffx5szZoFYyGuuaZoYyG2bg2aLt56C955BzZuzD8XExM0QuxpTmjf3j/UkiRJOmSkToIvr4TM9RCbCJ1HweFlFG5j4+GwS4Ntw3RY+O9gLMT6z4MtsRkc8Ttoc03RxkLs3ho0Xax6C9a8A5l7hdtQDDQ4Ib85oZbhVpIkBXbn7Gbm6pl5TQmfr/ycDTs37HPd0Y2OpldyL05ocQK9WvSiZe2WhMwTkiTtI6Y4b3rsscdo1aoVCQkJpKSkMGPGjP1em5WVxf3330+bNm1ISEigY8eOTJ48ucA19957L6FQqMDWvn37AtdkZGRwww03UL9+fWrUqMHAgQNZu/fwc0mKsl27YOjQ4Av79euhY8dghMB110Xnd5spKTBuXDCa4e67g7ELqalwxx2QnBw0U8yevf/3L14MDz0EffoEK0FccAE8/3zQpFC7Nlx0UXD/9evhf/+DP/4RjjzS3+NKqnjMtpJUiOxd8NVQ+GRA0KRQpyP0mwltoxRuG6TACePg7OVw9N3B2IVdqTDnDng9OWim2PQz4XbbYljwEEztA682gM8ugGXPB00KVWtDy4ug5zg4bz2c+j846o9Q23ArSVJltnnXZt5Z9A63T72d3s/2pvZfa9NzdE/++P4feWPhG2zYuYGEKgn0btmbEb1G8PYlb7Pp1k3Mu34eT5z5BJcdexmt6rSySUGSpP0o8ooKL730EsOGDePJJ58kJSWFhx56iL59+7Jw4UIaFTJ8/M4772Ts2LE8/fTTtG/fnvfee49zzz2XL774guOOOy7vug4dOvDBBx/kF1alYGk33XQTb7/9NhMmTKB27doMHTqU8847j88//7yojyBJpW7uXLjkEvjuu+D1TTfByJHBCgfRlpQE990Ht98erK7w8MNBA8Wzzwbbr34VjIU488yCIx0WLix4n3btgmsGDICePUs+QkKSygOzrSQVYvNc+OIS2JobbtvdBJ1GBiscRFu1JDj2Puhwe7C6wsKHYdNMWPpssDX8FbT7fbAawobpsDp3pEP6T8JtrXaQdGawckLDniUfISFJkiq0SCTCsi3LCqyW8O26b/e5rkG1BvRq0YsTkoPVEjo37Uyco6EkSSqWUCQSiRTlDSkpKXTt2pVHH30UgHA4THJyMjfeeCPDhw/f5/qkpCTuuOMObrjhhrxjAwcOJDExkbFjxwLBX529/vrrfPPNN4V+5tatW2nYsCHjx4/n/PPPB2DBggUceeSRTJs2je7du/9i3c46k3QwRCLwyCNw662QmQmNG8OYMdC3b7Qr279IBL78Mqh7wgTIzg6Ox8ZCTk7+dVWqQO/eQXPCmWdC27bRqVeSClNa2c5sK0l7iUTgh0dg9q0QzoSExtB9DCSV83C74cug7hUTIJIbbkOxENkr3IaqQKPeQQND0plQy3Arqfyo7Nmusj+/oiM7nM2ctDkFGhNWb1u9z3VH1D8irynhhOQTOKL+Ea6QIEnSzyhKtivSigq7d+9m5syZjBgxIu9YTEwMffr0Ydq0aYW+JzMzk4SEhALHEhMT+eyzzwocW7RoEUlJSSQkJNCjRw9GjhxJixYtAJg5cyZZWVn06dMn7/r27dvTokWL/f4yNzMzk8zMzLzX6enpRXlUSfpFa9fCkCHw7rvB6zPPhNGjoWERxuNGQygEPXoE2z/+AU8+GWzr10P9+tC/f/AsffsGIx4k6VBltpWkvexaC18OgTW54TbpTOg+GhIqQLht2CPYjvsHLH4SFj0ZjKuIrw9N+wfNCU37QpzhVpKkympb5jamp07Pa0qYtnIaO7J2FLimakxVjk86Pq8xoWdyTxpV33elPUmSVDqK1KiwYcMGcnJyaNy4cYHjjRs3ZsGCBYW+p2/fvowaNYrevXvTpk0bpk6dysSJE8nZ6892U1JSeO6552jXrh1r1qzhvvvu41e/+hXffvstNWvWJC0tjbi4OOrUqbPP56alpRX6uSNHjuS+++4ryuNJ0gF7552gSWHdOkhICL7w/93vKt4I26QkuP9+uOMOWLYMDj88WFlBkioDs60k5Up9B6YPgYx1EJsQfOHftgKG22pJcOz90OEO2LEMahwOMYZbSZIqo9T0VD5f+Tmfr/icz1Z+xjdp3xCOhAtcUzu+Nj2Te+atltC1WVeqVa0WpYolSap8itSoUBwPP/ww11xzDe3btycUCtGmTRuGDBnC6NGj8645/fTT8/aPPfZYUlJSaNmyJS+//DJXXXVVsT53xIgRDBs2LO91eno6ycnJxX8QSSWyYUMwZmD1aujcGVJSgi/JK5qMjGDMwyOPBK+POQZeeAE6dIhuXSUVHw/t2kW7Ckkq/8y2kgDI2AArJ8DO1VCvM9RPCb4kr2hyMoIxDz/khts6x0DPF6BOBQ+3sfFQy3ArSVJlEY6Emb9+ft5qCZ+t+IxlW5btc12rOq0KjHHo0KgDMaGYsi9YkiQBRWxUaNCgAbGxsaxdu7bA8bVr19KkSZNC39OwYUNef/11MjIy2LhxI0lJSQwfPpzWrVvv93Pq1KnDEUccweLFiwFo0qQJu3fvZsuWLQX+8uznPjc+Pp74+PiiPJ6kUrZzJ7z1FowdC5MnQ3Z2wfPNmwcNC3u244+H6tWjU+uB+PZbuPji4CfAH/4Af/1rsKKCJKniMdtKKpLsnZD6Fvw4FtZMhshPwm215kHDQv0UaJAC9Y6HKuU43G75Fj6/GLbmhtt2f4BOfw1WVJAkSSrHdmXt4qvVX+WtlvDFyi/YkrGlwDUxoRg6Nu6Y15RwQosTaF6reXQKliRJhSpSo0JcXBzHH388U6dO5ZxzzgEgHA4zdepUhg4d+rPvTUhIoFmzZmRlZfHqq69ywQUX7Pfa7du3s2TJEn7zm98AcPzxx1O1alWmTp3KwIEDAVi4cCErVqygR48eRXkESQdZTg589FHQnPDqq7B9e/65zp2hY0eYOTP4sn/VqmB79dXgfGwsHH10fuNCt25w5JHRH0UQicBjj8Ett0BmJjRqBM89B3v9wawkqQIy20r6ReEcWPdR0Jyw8lXI3ivc1u0MdTvCppnBl/07VwXbytxwG4qF2kcHTQv1U6B+N6h1ZPRHEUQi8MNjMPsWCGdCQiPo/hwkGW4lSVL5tWjjIv4z8z98tvIzZq6eSVY4q8D56lWr071597zGhO7Nu1MzvmaUqpUkSQeiyKMfhg0bxuWXX06XLl3o1q0bDz30EDt27GDIkCEADB48mGbNmjFy5EgApk+fTmpqKp06dSI1NZV7772XcDjMrbfemnfPW265hQEDBtCyZUtWr17NPffcQ2xsLBdffDEAtWvX5qqrrmLYsGHUq1ePWrVqceONN9KjRw+6d+9eGv8OkkogEoHZs2HcuGAMwpo1+edatYJLLw22I4/MP759e9CwMH16/paaCnPmBNt//hNcV7MmdOlScOWFpk3L7tnWrYMrr4S33w5e9+8Po0fDT8aZS5IqKLOtpH1EIrB5NiwbB8tfgF17hdvqraDVpcFWe69wm7U9aFjYOD3YNkyHXamwZU6wLc4Nt1VqQv0uBVdeSCzDcJuxDr68Elbnhtuk/pAyGhINt5IkqfxavW01J4w+gfU71+cda1qjaV5TQq8WvejYpCNVYg76pGtJklSKivy/3BdeeCHr16/n7rvvJi0tjU6dOjF58mQa535rt2LFCmJi8uc6ZWRkcOedd7J06VJq1KhB//79ef755wssc7tq1SouvvhiNm7cSMOGDenVqxdffvklDRs2zLvmX//6FzExMQwcOJDMzEz69u3L448/XoJHl1RSP/4I48cHDQrff59/vF49uOACuOwy6NkTQqF931ujBpx4YrDtkZpasHHh669h27ZghYaPPsq/Ljl535ER1aqV/vNNngxXXAFr10J8PDz4IAwdWvjzSJIqJrOtpDzbf4Rl44MGhfS9wm1cPWhxARx2GTTYT7itWgManxhse+xMzW9a2DgdNn0N2dtg7UfBtke15Pymhfp7RkYchHC7ejJ8eQVkrIWYeDjuQTjCcCtJksq37HA2F71yEet3rqdDww7cdsJt9GrRi1Z1WhEyx0iSVKGFIpFIJNpFlIX09HRq167N1q1bqVWrVrTLkSqsjRthwoSgOeGzz/KPx8fDWWcFzQn9+kFcXMk/KycHvvsuv3FhxozgdThc8LrYWDjmmILNC+3bw17fKxVJRgYMHw4PPxy87tAhWCnimGNK9jySpNJT2bNdZX9+qdRkboQVE4LmhPV7hduYeGh+FrS6DJr2g9hSCLfhHNj6Xf6qCxtnBK8jPwm3oVioc0zBVRdqtYdQMcNtTgZ8MxwW5obb2h3ghBeCz5AklQuVPdtV9ufXzxv+wXD+9vnfqBlXk5nXzqRt/bbRLkmSJP2MomQ7GxUk/aJdu2DSJBg7Ft59F7JyR8CFQnDyyUFzwnnnQe3aB7+Wbdv2HRmxevW+19WqBV27FmxeOJBxDd99B5dcAnPnBq+HDoW//x0SE0v3OSRJJVPZs11lf36pRLJ3wepJ8ONYWPMu5M03DkHjk4PmhOTzIK4Mwm3WtvyREXtWXthVSLitWgvqdc1fdaF+yoGNa9jyHXxxCWzJDbdHDIVOf4cqhltJKk8qe7ar7M+v/Zv0wyQGvDAAgJfPf5lBHQZFuSJJkvRLipLtHNokqVA5OfDJJ0FzwquvQnp6/rlOneDSS+Hii6FZs7Ktq2ZNOOmkYNtj1ap9R0akp8PUqcG2R8uW+U0L3bpB5875IyMiEXjiCbj55mBFhYYN4dln4YwzyvLpJEmSdFCEc2DdJ7BsLKx8FbL2Crd1O0GrS6HlxVCtjMNt1ZrQ+KRg22PnqvymhY3TYePXQb1rpwbbHtVb5jct1O8G9Trnj4yIRGDREzD75mBFhfiG0P1ZaGa4lSRJFcPyLcsZ/NpgAG7sdqNNCpIkHYJsVJCUJxKBOXOCsQ7jxxdcqaBFi6A54dJLg1EI5Unz5sE2cGDwOju74MiI6dNh/nxYvjzYXn45uC42Fo49NmhcWLEC3nknON6vX9Ck0KRJdJ5HkiRJpSASgS1zgrEOy8YXXKmgWougOaHVpVCnnIXbas2hRXNokRtuw9n5IyP2NDBsnQ87lgfbitxwG4qFOscGjQs7V8Dq3HDbtF/QpJBouJUkSRXD7pzdXPDKBWzO2EzXpK48eOqD0S5JkiQdBDYqSGLFiqAxYezY4Av+PerUgQsuCJoTevWCmGKOxS1rVapAx47Bdu21wbH09GClhb2bF9LSYPbsYAOIi4O//Q1+//uK86ySJEn6iR0rgsaEZWODL/j3qFoHWl4QNCc07AWhChL4YqpA3Y7BdnhuuM1KD1Za2LPqwobpkJEGm2cHG0BMHHT6G7T7fcV5VkmSJODW929lRuoM6ibU5eVBLxNfJT7aJUmSpIPARgWpktq8GSZMCFZP+N//8o/HxcGAAXDZZXD66RB/iPzfAbVqwa9/HWwQ/IHdypVBw8KMGbBpU9Cg0LFjdOuUJElSMezeDCsmBKsnrNsr3MbEQbMB0OoySDodYg+RcFu1FjT5dbBBEG53rsxtXJgBmZuCBoW6hltJklSxvDL/FR6e/jAA/z33v7Sq0yq6BUmSpIPGRgWpEsnIgLffDpoT3n4bdu8OjodCcOKJQXPCwIHBSgqHulAoGGfRogUMcsSdJElSxZOTAalvB80Jq9+GcG64JQSNToTDLoPkgRBXJ5pVlo1QCKq3CLYWhltJklQxLd60mCvfuBKAW3veyplHnBnliiRJ0sFko4J0iAuHgxUTxo6FV16BrVvzzx17bDDW4eKLITk5ejVKkiRJByQSDlZMWDYWVrwCWXuF2zrHBmMdWl4M1Q23kiRJFcmurF0MmjCIbbu30atFL/786z9HuyRJknSQ2aggHaLmzQuaE8aPh1Wr8o83bx40J1x6KRxzTPTqkyRJkg7Ylnnw41hYPh527hVuqzUPmhNaXQp1DLeSJEkV1f+b/P/4Ju0bGlRrwIsDX6RqbNVolyRJkg4yGxWkQ8jKlfDCC0GDwrx5+cdr1w7GG1x6KfTuDTEx0atRkiRJOiA7VsLyF4LVE7bsFW6r1g7GG7S6FBr1hpDhVpIkqSIbO3cs/5n1H0KEGH/eeJrVahbtkiRJUhmwUUGq4LKz4Y034PHH4aOPIBIJjsfFwRlnwGWXQf/+kJAQ3TolSZKkXxTOhlVvwKLHYe1HQG64jYmDpDPgsMsgqT/EGm4lSZIOBfPXz+e3k34LwN0n3s2pbU6NckWSJKms2KggVVDr1sHTT8OTTxYc7dC7d9CccP75ULdu9OqTJEmSDljGOlj8NCx+suBoh0a9odVl0OJ8iDPcSpIkHUp27N7BoAmD2Jm1k1MOO4W7et8V7ZIkSVIZslFBqmBmzIBHH4WXXoLdu4NjDRvCtdfCNddAy5bRrU+SJEk6YBtmwA+PwoqXIJwbbuMbwuHXwuHXQHXDrSRJ0qEoEolw/dvXM3/9fJrWaMq488YRGxMb7bIkSVIZslFBqgAyMuDll4MGha++yj+ekgJDh8KgQRAfH736JEmSpAOWkwHLXw4aFDbtFW7rp8ARQ6HFIIg13EqSJB3Knpn9DM/PfZ6YUAwvnv8ijWs0jnZJkiSpjNmoIJVjK1YEox2efho2bAiOxcXBRRcFDQpdu0a3PkmSJOmA7VgBi56EJU9DZm64jYmDlhcFDQr1DbeSJEmVwTdp3zD0naEAPPDrB+jdsneUK5IkSdFgo4JUzkQi8NFHweoJb7wB4XBwPDkZrr8err46GPUgSZIklXuRCKz9KFg9IfUNiOSG22rJ0PZ6aHM1JBhuJUmSKov0zHQGTRhEZk4m/dv259YTbo12SZIkKUpsVJDKie3b4fnngwaF+fPzj//618HqCQMGQBX/X6wkSZIqgqztsOz5oEFh617htvGvg9UTmg2AGMOtJElSZRKJRLjqzatYvGkxLWq34L/n/JeYUEy0y5IkSVHib4akKFu4EB5/HJ57DtLTg2PVq8Pll8PvfgcdOkS1PEmSJOnApS+EHx6HH5+DrNxwW6U6HHY5tP0d1DHcSpIkVVaPzniUV+a/QtWYqrx8/svUr1Y/2iVJkqQoslFBioKcHHjnnWD1hClT8o8fcUSwesLgwVC7dvTqkyRJkg5YOAdWvxOsnpC2V7iteUSwesJhgyHOcCtJklSZzUidwc1TbgbgwVMfJKV5SpQrkiRJ0WajglSGNm2C0aODFRR+/DE4FgrBmWcGDQp9+kCMq51JkiSpIsjcBEtHByso7MgNt4Sg2ZlBg0KTPuBSvpIkSZXepl2buGDCBWSFszjvyPP4fcrvo12SJEkqB2xUkMrA7Nnw2GMwbhxkZATH6taFq6+G66+Hww6Lbn2SJEnSAds0GxY9BsvGQU5uuI2rC22uhrbXQw3DrSRJkgLhSJjLX7+c5VuX07pua0afNZpQKBTtsiRJUjlgo4J0kOzeDRMnBuMdPv88/3inTnDjjXDRRVCtWtTKkyRJkg5czm5YOREWPQrr9wq3dTvBETdCy4ugiuFWkiRJBf3ji38w6YdJxMfG88qgV6id4EgwSZIUsFFBKmWrV8N//gNPPQVpacGxKlVg0KBgvEOPHsG4B0mSJKnc27kaFv8HFj8FGbnhNlQFWgwKxjs0MNxKkiSpcJ8u/5Tbp94OwL9P/zfHNT0uyhVJkqTyxEYFqRREIvDFF8HqCa+8AtnZwfEmTeC66+Daa6Fp0+jWKEmSJB2QSAQ2fAE/PAorXoFIbrhNaAJtr4PDr4VEw60kSZL2b92OdVz06kXkRHK49JhLuabzNdEuSZIklTM2KkglsHMnvPBC0KDwzTf5x3v1ClZPOPdciIuLWnmSJEnSgcveCctfCBoUNn+Tf7xhr2D1hObnQqzhVpIkST8vJ5zDpRMvZfW21bRv0J4nz3ySkKtwSZKkn7BRQSqGpUvhiSfgmWdg8+bgWGIiXHop3HADdOoU1fIkSZKkA7d9KSx6ApY8A7tzw21sIrS6FI64Aep2imp5kiRJqlge+PQBPlj6AYlVEnll0CvUiKsR7ZIkSVI5ZKOCdIDCYXj//WD1hLffDlbEBTjssKA5YcgQqFcvujVKkiRJByQShjXvB6snrH4byA231Q8LmhNaD4F4w60kSZKKZurSqdz78b0APHnmk3Ro1CG6BUmSpHLLRgXpF2zdCmPGwGOPwQ8/5B/v2zcY73D66RAbG736JEmSpAO2eyv8OAZ+eAy27RVum/YNxjs0PR1iDLeSJEkqutXbVnPJxEuIEOHq465mcMfB0S5JkiSVYzYqSPvx3XdBc8J//ws7dgTHatUKVk743e/giCOiW58kSZJ0wLZ8B4segx//C9m54bZqrWDlhLa/g1qGW0mSJBVfdjibi165iHU71nFs42P59+n/jnZJkiSpnLNRQdpLdja8+WYw3uGjj/KPd+gQrJ5w2WVQw5FqkiRJqgjC2ZD6ZjDeYe1e4bZ2h2D1hFaXQVXDrSRJkkrurg/v4tMVn1IzriYTBk0gsWpitEuSJEnlnI0KUq5IBAYODBoVAGJi4JxzggaFk06CUCia1UmSJElFEInApwODRgWAUAw0PydoUGh0kuFWkiRJpebtH97mr5//FYD/O+v/OKK+q3VJkqRfZqOClOuVV4Imhfh4uPlm+O1voUWLaFclSZIkFcPKV4ImhZh4OPJmOPy3UN1wK0mSpNK1fMtyfvPabwAY2nUoF3S4IMoVSZKkisJGBQnYvh2GDQv2b7sN7rsvuvVIkiRJxZa1HWblhtujboNjDbeSJEkqfbtzdnPhKxeyOWMzXZO68o/T/hHtkiRJUgUSE+0CpPLggQdg1Spo1QqGD492NZIkSVIJfPcA7FwF1VvBUYZbSZIkHRy3vn8r01OnUyehDi8Pepn4KvHRLkmSJFUgNiqo0lu4EP75z2D/oYcgMTGq5UiSJEnFl74QFuSG2+MfgiqGW0mSJJW+V+e/ysPTHwZgzDljaFWnVXQLkiRJFY6NCqrUIhH4/e8hKwtOPx3OOivaFUmSJEnFFInA17+HcBY0PR2aGW4lSVLRPfbYY7Rq1YqEhARSUlKYMWPGz17/0EMP0a5dOxITE0lOTuamm24iIyOjjKpVNCzetJgr37wSgD/2/CNntTN3SpKkorNRQZXaa6/BlCkQFwf//jeEQtGuSJIkSSqmVa9B2hSIiYMuhltJklR0L730EsOGDeOee+5h1qxZdOzYkb59+7Ju3bpCrx8/fjzDhw/nnnvu4fvvv+eZZ57hpZde4vbbby/jylVWMrIzGDRhEOmZ6ZyQfAIP/PqBaJckSZIqKBsVVGnt3Ak33RTs//GPcPjh0a1HkiRJKrbsnTAzN9we+UeoabiVJElFN2rUKK655hqGDBnCUUcdxZNPPkm1atUYPXp0odd/8cUXnHDCCVxyySW0atWK0047jYsvvvgXV2FQxfX/Jv8/vkn7hgbVGvDi+S9SNbZqtEuSJEkVlI0KqrT+8hdYsQJatACbvCVJklShffcX2LkCqrWADoZbSZJUdLt372bmzJn06dMn71hMTAx9+vRh2rRphb6nZ8+ezJw5M68xYenSpbzzzjv0799/v5+TmZlJenp6gU0Vw7i543hq5lOECDHuvHE0r9U82iVJkqQKrEq0C5CiYdEiePDBYP9f/4Jq1aJbjyRJklRs6Yvg+9xwe/y/oIrhVpIkFd2GDRvIycmhcePGBY43btyYBQsWFPqeSy65hA0bNtCrVy8ikQjZ2dlcd911Pzv6YeTIkdx3332lWrsOvvnr53PtpGsBuKv3XZzW5rQoVyRJkio6V1RQpROJwB/+ALt3w2mnwbnnRrsiSZIkqZgiEZj5BwjvhianQXPDrSRJKjsff/wxf/nLX3j88ceZNWsWEydO5O233+ZPf/rTft8zYsQItm7dmretXLmyDCtWcezYvYNBEwaxM2snvz7s19x94t3RLkmSJB0CXFFBlc6bb8K770LVqvDIIxAKRbsiSZIkqZhS34Q170JMVehiuJUkScXXoEEDYmNjWbt2bYHja9eupUmTJoW+56677uI3v/kNV199NQDHHHMMO3bs4Nprr+WOO+4gJmbfv5OLj48nPj6+9B9AB0UkEuH6t69n/vr5NKnRhPHnjSc2JjbaZUmSpEOAKyqoUtm1C/7f/wv2b74ZjjgiquVIkiRJxZe9C2b+v2C//c1Qy3ArSZKKLy4ujuOPP56pU6fmHQuHw0ydOpUePXoU+p6dO3fu04wQGxt8iR2JRA5esSozo2eP5vm5zxMTiuHFgS/SuEbjX36TJEnSAShWo8Jjjz1Gq1atSEhIICUlhRkzZuz32qysLO6//37atGlDQkICHTt2ZPLkyQWuGTlyJF27dqVmzZo0atSIc845h4ULFxa45qSTTiIUChXYrrvuuuKUr0rsr3+FZcugeXO4885oVyNJksoDs60qrPl/hR3LoFpzONpwK0mSSm7YsGE8/fTTjBkzhu+//57rr7+eHTt2MGTIEAAGDx7MiBEj8q4fMGAATzzxBC+++CI//vgj77//PnfddRcDBgzIa1hQxTUnbQ5D3x0KwJ9P/jMntjoxyhVJkqRDSZFHP7z00ksMGzaMJ598kpSUFB566CH69u3LwoULadSo0T7X33nnnYwdO5ann36a9u3b895773HuuefyxRdfcNxxxwHwySefcMMNN9C1a1eys7O5/fbbOe2005g/fz7Vq1fPu9c111zD/fffn/e6WrVqxXlmVVJLlsDf/hbsjxoFe/1XS5IkVVJmW1VY25bA/Nxw23kUVDHcSpKkkrvwwgtZv349d999N2lpaXTq1InJkyfTuHHwV/QrVqwosILCnXfeSSgU4s477yQ1NZWGDRsyYMAAHnjggWg9gkpJemY65084n4zsDPq37c9tvW6LdkmSJOkQE4oUcQ2ulJQUunbtyqOPPgoEy38lJydz4403Mnz48H2uT0pK4o477uCGG27IOzZw4EASExMZO3ZsoZ+xfv16GjVqxCeffELv3r2B4K/OOnXqxEMPPVSUcvOkp6dTu3Zttm7dSq1atYp1D1VsAwbApElwyinw/vuO75UkqSIrrWxntlWF9fEAWD0JGp8CvzbcSpJUkVX2bFfZn788ikQiXPjKhUyYP4HkWsnM/u1s6lerH+2yJElSBVCUbFek0Q+7d+9m5syZ9OnTJ/8GMTH06dOHadOmFfqezMxMEhISChxLTEzks88+2+/nbN26FYB69eoVOD5u3DgaNGjA0UcfzYgRI9i5c2dRylclNmlSsFWpAo884u9xJUmS2VYVWOqkoEkhVAW6GG4lSZJUuh776jEmzJ9AlZgqvDzoZZsUJEnSQVGk0Q8bNmwgJycnb6mvPRo3bsyCBQsKfU/fvn0ZNWoUvXv3pk2bNkydOpWJEyeSk5NT6PXhcJj/9//+HyeccAJHH3103vFLLrmEli1bkpSUxNy5c7nttttYuHAhEydOLPQ+mZmZZGZm5r1OT08vyqPqEJKRAX/4Q7B/001w5JHRrUeSJJUPZltVSDkZMDM33La/CWobbiVJklR6vkr9imHvDQPgwVMfpHvz7lGuSJIkHaqK1KhQHA8//DDXXHMN7du3JxQK0aZNG4YMGcLo0aMLvf6GG27g22+/3eev0q699tq8/WOOOYamTZtyyimnsGTJEtq0abPPfUaOHMl9991Xug+jCunvf4elSyEpCe66K9rVSJKkisxsq6ib/3fYvhQSk+Bow60kSZJKz6Zdmxg0YRBZ4SzObX8uf0j5Q7RLkiRJh7AijX5o0KABsbGxrF27tsDxtWvX0qRJk0Lf07BhQ15//XV27NjB8uXLWbBgATVq1KB169b7XDt06FAmTZrERx99RPPmzX+2lpSUFAAWL15c6PkRI0awdevWvG3lypUH8og6xPz4I4wcGeyPGgU1a0a3HkmSVH6YbVXhbP8R5ueG286joKrhVpIkSaUjHAlz+euXs3zrclrXbc3os0cTcsSYJEk6iIrUqBAXF8fxxx/P1KlT846Fw2GmTp1Kjx49fva9CQkJNGvWjOzsbF599VXOPvvsvHORSIShQ4fy2muv8eGHH3LYYYf9Yi3ffPMNAE2bNi30fHx8PLVq1SqwqfK56aZg9MOvfw0XXBDtaiRJUnlitlWFM+umYPRD419DC8OtJEmSSs8/v/gnk36YRHxsPBMGTaBOQp1olyRJkg5xRR79MGzYMC6//HK6dOlCt27deOihh9ixYwdDhgwBYPDgwTRr1oyRuX/GPn36dFJTU+nUqROpqance++9hMNhbr311rx73nDDDYwfP5433niDmjVrkpaWBkDt2rVJTExkyZIljB8/nv79+1O/fn3mzp3LTTfdRO/evTn22GNL499Bh6B334U33oAqVeCRR8AGYEmS9FNmW1UYq9+FVW9AqAp0MdxKkiSp9Hy24jNGTB0BwMP9HqZz085RrkiSJFUGRW5UuPDCC1m/fj133303aWlpdOrUicmTJ9O4cWMAVqxYQUxM/kINGRkZ3HnnnSxdupQaNWrQv39/nn/+eerUqZN3zRNPPAHASSedVOCznn32Wa644gri4uL44IMP8n5xnJyczMCBA7nzzjuL8ciqDDIz4fe/D/b/8Ac46qjo1iNJksons60qhJxM+Do33Lb7A9Q23EqSJKl0rN+xngtfuZCcSA6XHHMJ1x5/bbRLkiRJlUQoEolEol1EWUhPT6d27dps3brVpXIrgQcegDvvhKZNYeFCqOn4XkmSDimVPdtV9uevdL59AObeCYlN4cyFUNVwK0nSoaSyZ7vK/vzRlBPOof/4/kxZMoX2Ddrz1TVfUSOuRrTLkiRJFVhRsl3Mz56VKqDly4NGBYB//MMmBUmSJFVgO5bDd7nh9rh/2KQgSZKkUvPApw8wZckUEqskMmHQBJsUJElSmbJRQYecYcNg1y448US4+OJoVyNJkiSVwKxhkLMLGp0ILQ23kiRJKh1Tl07l3o/vBeCJM57g6EZHR7cgSZJU6diooEPKlCkwcSLExsKjj0IoFO2KJEmSpGJaMwVWToRQLHQx3EqSJKl0rN62mksmXkKECFcddxWXd7o82iVJkqRKyEYFHTIyM+HGG4P9G2+Eo20CliRJUkWVkwlf54bbI26EOoZbSZIklVx2OJuLX72YdTvWcWzjY3nk9EeiXZIkSaqkbFTQIeNf/4IffoDGjeHee6NdjSRJklQCC/4F236AhMZwzL3RrkaSJEmHiLs/upv/Lf8fNeJqMGHQBBKrJka7JEmSVEnZqKBDwsqV8Kc/BfsPPgi1a0e3HkmSJKnYdqyEb3PD7XEPQpzhVpIkSSX39g9vM/KzkQD834D/44j6R0S5IkmSVJnZqKBDws03w86d0KsXXHZZtKuRJEmSSmD2zZCzExr2glaGW0mSJJXc8i3L+c1rvwHghq43cOHRF0a5IkmSVNnZqKAK74MPYMIEiImBRx+FUCjaFUmSJEnFlPYBrJgAoRjoYriVJElSye3O2c2Fr1zI5ozNdEnqwj9P+2e0S5IkSbJRQRXb7t1w443B/g03QMeO0a1HkiRJKrac3fB1brhtewPUNdxKkiSp5G57/zamp06nTkIdXj7/ZeKrxEe7JEmSJBsVVLE9/DAsWACNGsH990e7GkmSJKkEFj4M6QsgoREca7iVJElSyU38fiIPTX8IgDHnjOGwuodFtyBJkqRcNiqowkpNhfvuC/b/9jeoUyeq5UiSJEnFtzMVvs0Nt53+BnF1olqOJEmSKr4lm5Yw5I0hANzS4xbOandWlCuSJEnKZ6OCKqxbboEdO6BHDxg8ONrVSJIkSSUw+xbI3gENesBhhltJkiSVTEZ2BoMmDCI9M52eyT35yyl/iXZJkiRJBdiooArpo4/gxRchJgYeeyz4KUmSJFVIaz+C5S9CKAa6PBb8lCRJkkrg9qm3MzttNvUT6/PS+S9RNbZqtEuSJEkqwN+AqcLJyoKhQ4P9666D446Lbj2SJElSsYWz4OvccHv4dVDPcCtJkqSSiUQijJ07FoCnBzxN81rNo1yRJEnSvmxUUIXzyCMwfz40aAB//nO0q5EkSZJKYOEjsHU+xDeAjoZbSZIkldzSzUtZv3M9VWOqcnrb06NdjiRJUqFsVFCFsmYN3HtvsP/Xv0LdulEtR5IkSSq+XWtg3r3Bfqe/QpzhVpIkSSX35aovAejctDMJVRKiXI0kSVLhbFRQhfLHP8K2bZCSAkOGRLsaSZIkqQRm/xGyt0H9FGhtuJUkSVLpmLZqGgDdm3ePciWSJEn7Z6OCKoz//Q/GjYNQCB59FGL8b68kSZIqqnX/g2XjgBB0eRRChltJkiSVjj2NCj2a94hyJZIkSfvnb8NUIWRnw9Chwf6110KXLtGtR5IkSSq2cDZ8nRtuD78W6htuJUmSVDp2Zu1kTtocAHok26ggSZLKLxsVVCE89hjMmwf16sEDD0S7GkmSJKkEfngMtsyDuHrQ0XArSZKk0vP16q/JieTQtEZTkmslR7scSZKk/bJRQeVeWhrcfXewP3Ik1K8f3XokSZKkYtuVBvNyw22nkRBvuJUkSVLpmbYyd+xDcg9CoVCUq5EkSdo/GxVU7t12G6SnB+Merroq2tVIkiRJJfDNbZCVDvW6QGvDrSRJkkrXl6lfAtCjuWMfJElS+Wajgsq1zz+H//4XQqFg/ENsbLQrkiRJkopp/efw43+BEHR5DGIMt5IkSSo9kUgkb0WF7s27R7kaSZKkn2ejgsqt7Gy44YZg/6qroFu36NYjSZIkFVs4G77KDbdtroIGhltJkiSVrmVblrF2x1qqxFTh+KbHR7scSZKkn2WjgsqtJ5+EOXOgbl0YOTLa1UiSJEklsOhJ2DIH4upCR8OtJEmSSt+Xq4KxD8c1OY7EqolRrkaSJOnn2aigcmntWrjzzmD/gQegQYPo1iNJkiQV2661MDc33HZ8ABIMt5IkSSp901Y59kGSJFUcNiqoXBo+HLZuhc6d4dpro12NJEmSVAJzhkPWVqjbGdoYbiVJknRw7FlRoUfzHlGuRJIk6ZfZqKByZ9o0eO65YP/RRyE2NqrlSJIkScW3fhosfS7Y7/IoxBhuJUmSVPp2Ze1idtpswBUVJElSxWCjgsqVnBy44YZgf8gQ6GHzryRJkiqqcA58nRtuWw+BhoZbSZIkHRwz18wkO5xN4+qNaVWnVbTLkSRJ+kU2KqhceeopmD0b6tSBv/412tVIkiRJJbD4Kdg8G6rWgU6GW0mSJB08eWMfknsQCoWiXI0kSdIvs1FB5cb69XDHHcH+n/4EjRpFtx5JkiSp2DLWw5zccHvsnyDBcCtJkqSDZ9qqaQB0b+bYB0mSVDHYqKByY8QI2LIFOnaE666LdjWSJElSCcwZAVlboE5HaGu4lSRJ0sETiUSYtjJoVOiR7LgxSZJUMdiooHJh+nR45plg/7HHoEqV6NYjSZIkFduG6bAkN9x2fQxiDLeSJEk6eFamr2TN9jXEhmLpktQl2uVIkiQdEBsVFHU5OXDDDcH+4MFwwgnRrUeSJEkqtnAOfJ0bbg8bDA0Nt5IkSTq49qym0LFJR6pVrRblaiRJkg6MjQqKuv/7P5g5E2rVgr//PdrVSJIkSSWw5P9g00yoWgs6GW4lSZJ08H256ksAejR37IMkSao4bFRQVG3cCLffHuzffz80bhzdeiRJkqRiy9wIc3LD7TH3Q6LhVpIkSQfftFXBigrdm3ePciWSJEkHzkYFRdXtt8OmTXDMMfnjHyRJkqQKac7tsHsT1DkGjjDcSpIk6eDLyM5g1ppZgCsqSJKkisVGBUXN11/D008H+48+ClWqRLceSZIkqdg2fg2Lc8Ntl0chxnArSZKkg2/2mtlkhbNoWK0hreu2jnY5kiRJB8xGBUVFOBysoBCJwKWXQu/e0a5IkiRJKqZIGL6+AYhAq0uhkeFWkiRJZWPvsQ+hUCjK1UiSJB04GxUUFaNHw4wZULMmPPhgtKuRJEmSSmDJaNg4A6rUhOMMt5IkSSo7exoVHPsgSZIqGhsVVOY2bYLhw4P9e++Fpk2jWo4kSZJUfJmbYE5uuD3mXkg03EqSpIrtscceo1WrViQkJJCSksKMGTP2e+1JJ51EKBTaZzvjjDPKsOLK7ctVXwLQI9lGBUmSVLHYqKAyd+edsHEjdOgAN94Y7WokSZKkEph7J2RuhNodoJ3hVpIkVWwvvfQSw4YN45577mHWrFl07NiRvn37sm7dukKvnzhxImvWrMnbvv32W2JjYxk0aFAZV145rUpfxar0VcSEYuiS1CXa5UiSJBVJsRoVitJVm5WVxf3330+bNm1ISEigY8eOTJ48ucj3zMjI4IYbbqB+/frUqFGDgQMHsnbt2uKUryiaNQuefDLYf/RRqFo1uvVIkiSZbVVsm2bBotxw2+VRiDHcSpKkim3UqFFcc801DBkyhKOOOoonn3ySatWqMXr06EKvr1evHk2aNMnb3n//fapVq2ajQhmZtjIY+3Bs42OpEVcjytVIkiQVTZEbFYraVXvnnXfy1FNP8cgjjzB//nyuu+46zj33XGbPnl2ke95000289dZbTJgwgU8++YTVq1dz3nnnFeORFS3hMNxwA0QicNFFcNJJ0a5IkiRVdmZbFVskDF/dAESg5UXQ+KRoVyRJklQiu3fvZubMmfTp0yfvWExMDH369GHatGkHdI9nnnmGiy66iOrVqx+sMrWXvLEPzR37IEmSKp5QJBKJFOUNKSkpdO3alUcffRSAcDhMcnIyN954I8OHD9/n+qSkJO644w5uuOGGvGMDBw4kMTGRsWPHHtA9t27dSsOGDRk/fjznn38+AAsWLODII49k2rRpdO/e/RfrTk9Pp3bt2mzdupVatWoV5ZFVSp59Fq68EmrUgAULoFmzaFckSZIqqtLKdmZbFduSZ2H6lVClBpy5AKoZbiVJUvGUl2y3evVqmjVrxhdffEGPHvlffN9666188sknTJ8+/WffP2PGDFJSUpg+fTrdunXb73WZmZlkZmbmvU5PTyc5OTnqz18R9XymJ9NWTWPMOWMY3HFwtMuRJEkqUrYt0ooKxemqzczMJCEhocCxxMREPvvsswO+58yZM8nKyipwTfv27WnRosUBd/MqujZvhttuC/bvuccmBUmSFH1mWxXb7s3wTW64PeYemxQkSZIIVlM45phjfrZJAWDkyJHUrl07b0tOTi6jCg8tmdmZzFozC3BFBUmSVDEVqVFhw4YN5OTk0Lhx4wLHGzduTFpaWqHv6du3L6NGjWLRokWEw2Hef/99Jk6cyJo1aw74nmlpacTFxVGnTp0D/tzMzEzS09MLbIqeu++G9evhyCPhD3+IdjWSJElmW5XA3Lshcz3UOhLaGW4lSdKhoUGDBsTGxrJ27doCx9euXUuTJk1+9r07duzgxRdf5KqrrvrFzxkxYgRbt27N21auXFmiuiurb9K+ITMnk/qJ9Tm83uHRLkeSJKnIitSoUBwPP/wwbdu2pX379sTFxTF06FCGDBlCTMzB/Wg7c8uPb76Bxx8P9h99FKpWjWo5kiRJxWa2FZu/gUW54bbLoxBjuJUkSYeGuLg4jj/+eKZOnZp3LBwOM3Xq1AKjIAozYcIEMjMzueyyy37xc+Lj46lVq1aBTUU3bVWwGlv35t0JhUJRrkaSJKnoivQb1eJ01TZs2JDXX3+dHTt2sHz5chYsWECNGjVo3br1Ad+zSZMm7N69my1bthzw59qZWz5EIjB0KITDcMEF8OtfR7siSZKkgNlWRRaJwNdDIRKGFhdAE8OtJEk6tAwbNoynn36aMWPG8P3333P99dezY8cOhgwZAsDgwYMZMWLEPu975plnOOecc6hfv35Zl1xpfbnqS8CxD5IkqeIqUqNCSbpqExISaNasGdnZ2bz66qucffbZB3zP448/nqpVqxa4ZuHChaxYsWK/n2tnbvnw/PPw+edQvTr885/RrkaSJCmf2VZF9uPzsP5zqFIdOhtuJUnSoefCCy/kH//4B3fffTedOnXim2++YfLkyXmjzVasWJE39myPhQsX8tlnnx3Q2AeVnr1XVJAkSaqIqhT1DcOGDePyyy+nS5cudOvWjYceemifrtpmzZoxcuRIAKZPn05qaiqdOnUiNTWVe++9l3A4zK233nrA96xduzZXXXUVw4YNo169etSqVYsbb7yRHj160L27Qay82roV9vzHfNdd0Lx5dOuRJEn6KbOtDtjurfBN7n/OR98F1Qy3kiTp0DR06FCGDh1a6LmPP/54n2Pt2rUjEokc5Kq0t9XbVrNi6wpiQjF0a9Yt2uVIkiQVS5EbFS688ELWr1/P3XffTVpaGp06ddqnq3bvGb0ZGRnceeedLF26lBo1atC/f3+ef/556tSpc8D3BPjXv/5FTEwMAwcOJDMzk759+/L444+X4NF1sN1zD6xdC+3awU03RbsaSZKkfZltdcDm3QMZa6FWO2hnuJUkSVL07Bn7cHSjo6kZXzPK1UiSJBVPKFJJ2l3T09OpXbs2W7dudancMjBvHhx3HOTkwJQpcOqp0a5IkiQdSip7tqvsz1/mtsyDd4+DSA6cPAWaGm4lSVLpqezZrrI/f3H8ccof+ce0f3Bt52t5asBT0S5HkiQpT1GyXczPnpWKIRKBG24ImhQGDrRJQZIkSRVYJAJf3RA0KSQPtElBkiRJUTdt1TQAeiT3iHIlkiRJxWejgkrd+PHw6adQrRqMGhXtaiRJkqQSWDYe1n8KsdWgs+FWkiRJ0bU7Zzcz18wEoEdzGxUkSVLFZaOCSlV6OtxyS7B/xx3QokV065EkSZKKLSsdZueG26PvgOqGW0mSJEXXnLQ5ZGRnUDehLm3rt412OZIkScVmo4JK1X33QVoatG0LN98c7WokSZKkEph3H2SkQc220N5wK0mSpOj7ctWXAHRv3p2YkL/elyRJFZdJRqXmu+/g4YeD/X//G+Ljo1uPJEmSVGxbvoOFueH2+H9DrOFWkiRJ0Tdt1TQgaFSQJEmqyGxUUKmIRGDoUMjJgXPOgX79ol2RJEmSVEyRCHw9FCI50PwcSDLcSpIkqXzY06jQo3mPKFciSZJUMjYqqFS89BJ8/DEkJMC//hXtaiRJkqQSWP4SrPsYYhOgs+FWkiRJ5UPa9jSWbVlGiBDdmnWLdjmSJEklYqOCSmzbNrg5d2Tv7bdDq1ZRLUeSJEkqvqxtMDs33B51O9RoFdVyJEmSpD2+XPUlAEc1PIraCbWjXI0kSVLJ2KigEvvTn2D1amjTBv74x2hXI0mSJJXAt3+CXauhRhs4ynArSZKk8mPaSsc+SJKkQ4eNCiqR77/PH/Xw8MPB6AdJkiSpQtr6PSzIDbfHPxyMfpAkSZLKiS9TgxUVeiTbqCBJkio+GxVUIiNGQHY2DBgAZ5wR7WokSZKkEpgzAiLZ0GwANDPcSpIkqfzIysniq9SvAOjevHuUq5EkSSo5GxVUbDt3wuTJwf5f/hLdWiRJkqQSyd4Jq3PDbUfDrSRJksqXeevmsSt7F3US6tC+QftolyNJklRiNiqo2P73P8jMhBYtoEOHaFcjSZIklcC6/0E4E6q1gNqGW0mSJJUv01ZOAyClWQoxIX+tL0mSKj4TjYrtvfeCn337QigU3VokSZKkElmTG26bGm4lSZJU/kxbFTQqOPZBkiQdKmxUULFNmRL8PO206NYhSZIklVhabrhtariVJElS+fPlqi8B6NG8R5QrkSRJKh02KqhYVq6E+fMhJgZOOSXa1UiSJEklsGMlbJ0PoRhoYriVJElS+bJuxzqWbF4CQLdm3aJcjSRJUumwUUHF8v77wc9u3aBu3ejWIkmSJJVIWm64rdcN4gy3kiRJKl/2rKZwZIMjqZtoXpUkSYcGGxVULI59kCRJ0iFjjWMfJEmSVH459kGSJB2KbFRQkeXk5K+o0LdvdGuRJEmSSiSck7+iQlPDrSRJksqfaaumAdC9efcoVyJJklR6bFRQkc2aBZs2Qe3awegHSZIkqcLaPAt2b4KqtaG+4VaSJEnlS3Y4mxmpMwDokeyKCpIk6dBho4KK7L33gp+nnAJVqkS3FkmSJKlE1uSG2yanQIzhVpIkSeXLt+u+ZWfWTmrF1+KohkdFuxxJkqRSY6OCimxK7gjf0xzhK0mSpIpuTW64bWK4lSRJUvkzbWUw9qFbs27EhPx1viRJOnSYbFQk6ekwLcjGNipIkiSpYstKhw254bap4VaSJEnlz5epXwLQo7ljHyRJ0qHFRgUVyUcfQXY2tG0Lhx0W7WokSZKkElj7EUSyoWZbqGG4lSRJUvmzZ0UFGxUkSdKhxkYFFYljHyRJknTIcOyDJEmSyrENOzewaNMiAFKap0S5GkmSpNJlo4KK5L33gp99+0a3DkmSJKnE1uSG26aGW0mSJJU/01dNB6Bd/XbUS6wX5WokSZJKl40KOmBLlgRblSpw0knRrkaSJEkqgW1LYPsSCFWBxidFuxpJkiRpH9NWBWMfujfvHuVKJEmSSp+NCjpge8Y+nHAC1KwZ3VokSZKkEknLDbcNT4CqhltJkiSVP3saFXo07xHlSiRJkkqfjQo6YHsaFU5zhK8kSZIqujW54bap4VaSJEnlT044hxmpMwDokWyjgiRJOvTYqKADkpUFU6cG+zYqSJIkqUILZ0FabrhtYriVJElS+fPd+u/Yvns7NeJq0KFhh2iXI0mSVOpsVNABmT4dtm2D+vWhc+doVyNJkiSVwIbpkL0N4utDPcOtJEmSyp8vV30JQLdm3YiNiY1yNZIkSaXPRgUdkD1jH049FWL8b40kSZIqsrTccNvkVAgZbiVJklT+TFs1DYAezR37IEmSDk3+Vk4H5L33gp99+0a3DkmSJKnE1uSG26aGW0mSJJVP01YGjQrdm3ePciWSJEkHh40K+kWbNsFXXwX7p54a3VokSZKkEsncBBtzw20Tw60kSZLKn027NrFw40LARgVJknToslFBv+iDDyASgaOPhmbNol2NJEmSVAJpHwARqH00VDPcSpIkqfyZvmo6AIfXO5wG1RpEuRpJkqSDw0YF/aIpuSN8TzstunVIkiRJJZaWG26bGm4lSZJUPk1bFYx96NG8R5QrkSRJOnhsVNDPikTgvdwRvjYqSJIkqUKLRGBNbrhtYriVJElS+fTlqi8BGxUkSdKhzUYF/awFC2DVKoiPh969o12NJEmSVALpC2DnKoiJh0aGW0mSJJU/4UiY6anB6IfuzbtHuRpJkqSDx0YF/aw9Yx9694bExOjWIkmSJJXImtxw26g3VDHcSpIkqfyZv34+6ZnpVK9anWMaHxPtciRJkg4aGxX0s/aMfejbN7p1SJIkSSW2Z+xDU8OtJEmSyqc9Yx+6NutKlZgqUa5GkiTp4LFRQfuVmQkffxzsn+YIX0mSJFVkOZmw7uNgv6nhVpIkSeXTtJXTAOjezLEPkiTp0Gajgvbrs89g1y5o2hSOPjra1UiSJEklsP4zyNkFiU2htuFWkiRJ5dOXqcGKCj2Se0S5EkmSpIPLRgXt15TcEb6nnQahUHRrkSRJkkpkTW64bWK4lSRJUvm0JWML89fPB6B7c1dUkCRJh7ZiNSo89thjtGrVioSEBFJSUpgxY8bPXv/QQw/Rrl07EhMTSU5O5qabbiIjIyPvfKtWrQiFQvtsN9xwQ941J5100j7nr7vuuuKUrwP0Xu4IX8c+SJKkQ5nZtpJYkxtuHfsgSZKkcmr6qukAtK7bmkbVG0W5GkmSpIOrSlHf8NJLLzFs2DCefPJJUlJSeOihh+jbty8LFy6kUaN9w9P48eMZPnw4o0ePpmfPnvzwww9cccUVhEIhRo0aBcBXX31FTk5O3nu+/fZbTj31VAYNGlTgXtdccw33339/3utq1aoVtXwdoLQ0mDMn2D/11OjWIkmSdLCYbSuJXWmwJTfcNjHcSpIkqXz6clXu2Ifmjn2QJEmHviI3KowaNYprrrmGIUOGAPDkk0/y9ttvM3r0aIYPH77P9V988QUnnHACl1xyCRD8hdnFF1/M9OnT865p2LBhgff89a9/pU2bNpx44okFjlerVo0mTZoUtWQVwwcfBD87d4af/McjSZJ0yDDbVhJpueG2bmdIMNxKkiSpfJq2ahrg2AdJklQ5FGn0w+7du5k5cyZ9+vTJv0FMDH369GHatGmFvqdnz57MnDkzbwndpUuX8s4779C/f//9fsbYsWO58sorCf1kduy4ceNo0KABRx99NCNGjGDnzp37rTXz/7d35+FRlff7x++Z7AQStqwkEARZVDYDhICKSiSijYIWqVhAXNAW6oK2grK4/IRWLWJbLOpXoa2iaItLCyVABCyasAQQF4Swb0kAIQkESCDz/P5IMjJkISHLmUner+uaK8mZOc/5nMPM4TZ+eJ6CAuXl5bk8UHWlyz4kJlpbBwAAQF0h2zYizmUfCLcAAABwTw7jYEYFAADQqFSrUeHo0aMqKipSWFiYy/awsDBlZWWVu8/IkSP1/PPP65prrpGPj486dOig66+/Xk8//XS5r//kk0+Uk5Oje++9t8w47777rlauXKnJkyfrH//4h375y19WWOvMmTMVHBzsfERHR1fnVBs1h0Navrz4+8Es4QsAABoosm0jYRxSVkm4jSDcAgAAXMycOXMUExMjf39/xcXFOZt0K5KTk6Px48crIiJCfn5+6tSpk5YsWVJP1TYc245uU25BrgK8A9Q9rLvV5QAAANS5ai/9UF2rVq3SjBkz9PrrrysuLk47duzQo48+qhdeeEFTp04t8/q3335bQ4YMUWRkpMv2cePGOb/v1q2bIiIiNGjQIO3cuVMdOnQoM87kyZM1ceJE5895eXn8QreKtmyRsrOlwECpf3+rqwEAAHAfZFsPlLNFOpMteQdKrQm3AAAAlVm4cKEmTpyouXPnKi4uTrNnz1ZiYqK2bdum0NDQMq8vLCzUTTfdpNDQUP3zn/9UmzZttHfvXjVv3rz+i/dwpcs+9I7sLR8vH4urAQAAqHvValRo3bq1vLy8lJ2d7bI9Ozu7wvV1p06dqlGjRumBBx6QVPyL2Pz8fI0bN07PPPOM7PafJnXYu3evVqxYoUWLFl20lri4OEnSjh07yv1lrp+fn/z8/Kp8bvjJsmXFX2+4QfL1tbYWAACAukK2bSQyS8Jt6A2SF+EWAACgMrNmzdKDDz6osWPHSpLmzp2rxYsX65133tGkSZPKvP6dd97RsWPH9NVXX8nHp/h/rsfExNRnyQ0Gyz4AAIDGplpLP/j6+io2NlYpKSnObQ6HQykpKYqPLz9AnTp1yuUXtpLk5eUlSTLGuGyfN2+eQkNDdeutt160ls2bN0uSIiIiqnMKqILkkiV8WfYBAAA0ZGTbRiKzJNyy7AMAAEClCgsLlZ6eroSEBOc2u92uhIQEpaamlrvPZ599pvj4eI0fP15hYWG66qqrNGPGDBUVFdVX2Q1G6YwK8dE0KgAAgMah2ks/TJw4UWPGjFHv3r3Vt29fzZ49W/n5+c4u29GjR6tNmzaaOXOmJCkpKUmzZs1Sr169nNPjTp06VUlJSc5f6krFvxSeN2+exowZI29v17J27typBQsW6JZbblGrVq20ZcsWPf7447ruuuvUvTvrddWm/HxpzZri7xMTra0FAACgrpFtG7hz+dKRknAbQbgFAACozNGjR1VUVKSwsDCX7WFhYfrhhx/K3WfXrl36/PPPdc8992jJkiXasWOHfv3rX+vs2bOaPn16ufsUFBSooKDA+XNeXl7tnYSHyj2Tq+8OfydJ6hfVz+JqAAAA6ke1GxVGjBihI0eOaNq0acrKylLPnj21dOlSZ4Ddt2+fy78ymzJlimw2m6ZMmaKDBw8qJCRESUlJevHFF13GXbFihfbt26f77ruvzDF9fX21YsUK5y+Oo6Ojdeedd2rKlCnVLR8X8cUXUmGh1K6ddPnlVlcDAABQt8i2DdzhLyRHoRTYTmpGuAUAAKhtDodDoaGhevPNN+Xl5aXY2FgdPHhQL7/8coWNCjNnztRzzz1Xz5W6t/WH1svIKKZ5jMKblr8MHQAAQENjMxfOUdtA5eXlKTg4WLm5uQoKCrK6HLf12GPSa69J48ZJb7xhdTUAAADla+zZrrGff5WlPyZte03qOE7qS7gFAADuyV2yXWFhoZo0aaJ//vOfGjp0qHP7mDFjlJOTo08//bTMPgMHDpSPj49WrFjh3Pbf//5Xt9xyiwoKCuTr61tmn/JmVIiOjrb8/K30wuoXNG3VNN191d1acOcCq8sBAAC4ZNXJtvZKn0Wjs2xZ8dfBLOELAAAAT5dZEm7DCbcAAAAX4+vrq9jYWKWkpDi3ORwOpaSkKD4+vtx9BgwYoB07dsjhcDi3bd++XREREeU2KUiSn5+fgoKCXB6NXeqBVEks+wAAABoXGhXgtH+/tHWrZLdLgwZZXQ0AAABQA/n7pbytks0uhRNuAQAAqmLixIl666239Le//U1bt27Vr371K+Xn52vs2LGSpNGjR2vy5MnO1//qV7/SsWPH9Oijj2r79u1avHixZsyYofHjx1t1Ch7HGKO0A2mSpPio8htCAAAAGiJvqwuA+yidTSEuTmre3NJSAAAAgJrJKgm3reIk3+aWlgIAAOApRowYoSNHjmjatGnKyspSz549tXTpUoWFhUmS9u3bJ7v9p3/7Fh0dreTkZD3++OPq3r272rRpo0cffVRPPfWUVafgcbb/uF3HzxyXv7e/eoT3sLocAACAekOjApySk4u/suwDAAAAPF5mSbhl2QcAAIBqmTBhgiZMmFDuc6tWrSqzLT4+XmlpaXVcVcNVuuxDbESsfL3KXy4DAACgIWLpB0iSioqkFSuKv09MtLYWAAAAoEYcRVJWSbiNINwCAADAfbHsAwAAaKxoVIAkacMG6fhxKThY6tPH6moAAACAGji2QSo8LvkES60ItwAAAHBfpTMq9IvqZ3ElAAAA9YtGBUiSlpUs4ZuQIHmzIAgAAAA8WWZJuA1PkOyEWwAAALinEwUn9O3hbyVJ8dHMqAAAABoXGhUg6adGhcEs4QsAAABPl1USbiMItwAAAHBf6w+tl8M41Da4rSKbRVpdDgAAQL2iUQHKzZVSi2cYo1EBAAAAnq0wVzpaEm7DCbcAAABwX6n7WfYBAAA0XjQqQCtXSkVFUqdOUkyM1dUAAAAANZC9UjJFUrNOUtMYq6sBAAAAKpR2ME2SFB/Fsg8AAKDxoVEBSk4u/pqYaG0dAAAAQI1lloTbCMItAAAA3JcxRmkHaFQAAACNF40K0LKSJXxZ9gEAAAAeL6sk3EYQbgEAAOC+dhzboaOnjsrXy1c9w3taXQ4AAEC9o1GhkduxQ9q1S/Lxka6/3upqAAAAgBo4sUM6uUuy+0ih11tdDQAAAFCh0tkUYiNi5eftZ3E1AAAA9Y9GhUaudDaFAQOkpk2trQUAAACokcyScNt6gORDuAUAAID7Sj2QKknqF9XP4koAAACsQaNCI8eyDwAAAGgwWPYBAAAAHqK0USE+Kt7iSgAAAKxBo0Ijdvas9Pnnxd8nJlpbCwAAAFAjjrNSVkm4jSDcAgAAwH3lF+ZrS/YWSVJ8NI0KAACgcaJRoRFLS5NOnJBCQqSePa2uBgAAAKiBo2nSuROSX4jUoqfV1QAAAAAVWn9ovRzGoTbN2igqKMrqcgAAACxBo0Ijlpxc/PWmmyQ77wQAAAB4ssyScBt+k2Qj3AIAAMB9pR1Ik8RsCgAAoHHjN3iN2LKSJXwHs4QvAAAAPF1mSbiNINwCAADAvaUeSJUkxUfRqAAAABovGhUaqaNHpQ0bir+/6SZrawEAAABq5MxR6VhJuA0n3AIAAMB9GWOUur+4UaFfVD+LqwEAALAOjQqNVEqKZIzUrZsUGWl1NQAAAEANZKdIMlLzblITwi0AAADc1+6c3Tpy6oh87D66OuJqq8sBAACwDI0KjRTLPgAAAKDBKF32IZxwCwAAAPdWOpvC1RFXy9/b3+JqAAAArEOjQiNkjJScXPx9YqK1tQAAAAA1YoyUWRJuIwi3AAAAcG+pB1j2AQAAQKJRoVHaulU6eFDy95euucbqagAAAIAayNsqnT4oeflLIYRbAAAAuLe0A2mSpPioeIsrAQAAsBaNCo1Q6WwKAwdKAQHW1gIAAADUSOlsCqEDJW/CLQAAANzXqbOn9HX215KYUQEAAIBGhUZoWckSvoNZwhcAAACeLrMk3IYTbgEAAODe0g+l65zjnCKaRqhtcFurywEAALAUjQqNzJkz0urVxd/TqAAAAACPVnRGOlwSbiMItwAAAHBvqQdSJUnx0fGy2WwWVwMAAGAtGhUamTVrpNOnpchI6corra4GAAAAqIEja6Si01JApBRMuAUAAIB7K21U6NeGZR8AAABoVGhkzl/2gaZdAAAAeLTSZR8iCLcAAABwb8YYpR1Ik1Q8owIAAEBjR6NCI5OcXPw1MdHaOgAAAIAayywJt+GEWwAAALi3vbl7lXUyS952b8VGxFpdDgAAgOVoVGhEMjOlLVuK/7FZQoLV1QAAAAA1cDpTytkiySaFE24BAADg3lL3Fy/70DO8pwJ8AiyuBgAAwHo0KjQiy5cXf42NlVq3trYWAAAAoEYyS8Jty1jJn3ALAAAA9+Zc9iGKZR8AAAAkGhUalWUlS/gOHmxtHQAAAECNZZWE2wjCLQAAANxf6oHiGRX6RfWzuBIAAAD3QKNCI+Fw0KgAAACABsI4pMyScBtOuAUAAIB7O332tDZlbZLEjAoAAAClaFRoJL7+WjpyRGraVIonCwMAAMCTHf9aKjgieTeVWhNuAQAA4N42Zm7UOcc5hQWGKaZ5jNXlAAAAuAUaFRqJ0tkUbrhB8vW1thYAAACgRkqXfQi7QfIi3AIAAMC9nb/sg81ms7gaAAAA90CjQiORnFz8NTHR2joAAACAGsssCbcRhFsAAAC4v7QDaZJY9gEAAOB8NCo0Avn50po1xd8PZglfAAAAeLJz+dKRknAbTrgFAACAezPGOGdUiI+mUQEAAKAUjQqNwKpV0tmzUvv2UseOVlcDAAAA1ED2KslxVgpsLzUj3AIAAMC97c/br0MnDsnL5qXYiFirywEAAHAbNCo0AstKlvAdPFhiCTQAAAB4tMyScBtBuAUAAID7K132oUd4DwX6BlpcDQAAgPugUaERSC5ZwpdlHwAAAODxskrCbQThFgAAAO4vdX/Jsg9RLPsAAABwPhoVGri9e6Vt2yQvL+nGG62uBgAAAKiB/L1S3jbJ5iWFEW4BAADg/lIPFDcq9IvqZ3ElAAAA7uWSGhXmzJmjmJgY+fv7Ky4uTuvWrav09bNnz1bnzp0VEBCg6OhoPf744zpz5ozz+WeffVY2m83l0aVLF5cxzpw5o/Hjx6tVq1Zq2rSp7rzzTmVnZ19K+Y3K8uXFX+PipObNLS0FAADALZFtPUhmSbhtFSf5Nre0FAAAAOBiCs4VaFPWJknMqAAAAHChajcqLFy4UBMnTtT06dO1ceNG9ejRQ4mJiTp8+HC5r1+wYIEmTZqk6dOna+vWrXr77be1cOFCPf300y6vu/LKK5WZmel8rFmzxuX5xx9/XP/+97/10UcfafXq1Tp06JDuuOOO6pbf6JQu+5CYaG0dAAAA7ohs62EyS5d9INwCAADA/W3M3KjCokK1btJal7W4zOpyAAAA3Ip3dXeYNWuWHnzwQY0dO1aSNHfuXC1evFjvvPOOJk2aVOb1X331lQYMGKCRI0dKkmJiYnT33Xdr7dq1roV4eys8PLzcY+bm5urtt9/WggULdGPJ+gXz5s1T165dlZaWpn79mDarPEVF0ooVxd8PZglfAACAMsi2HsRRJGWVhNsIwi0AAADcX9qBNEnFsynYbDaLqwEAAHAv1ZpRobCwUOnp6UpISPhpALtdCQkJSk1NLXef/v37Kz093TmF7q5du7RkyRLdcsstLq/LyMhQZGSkLrvsMt1zzz3at2+f87n09HSdPXvW5bhdunRR27ZtKzxuQUGB8vLyXB6Nzfr1Uk5O8ZIPffpYXQ0AAIB7Idt6mGPrpbM5kk9zqSXhFgAAAO4v9UBxvmfZBwAAgLKqNaPC0aNHVVRUpLCwMJftYWFh+uGHH8rdZ+TIkTp69KiuueYaGWN07tw5Pfzwwy7T48bFxWn+/Pnq3LmzMjMz9dxzz+naa6/Vt99+q2bNmikrK0u+vr5q3rx5meNmZWWVe9yZM2fqueeeq87pNTjLlhV/TUiQvLysrQUAAMDdkG09TGZJuA1PkOyEWwAAALi/0kaFflHMmgYAAHChas2ocClWrVqlGTNm6PXXX9fGjRu1aNEiLV68WC+88ILzNUOGDNHw4cPVvXt3JSYmasmSJcrJydGHH354ycedPHmycnNznY/9+/fXxul4lOSSJXxZ9gEAAKB2kG0tlFkSbln2AQAAAB7gQN4BHcg7ILvNrj5tmBEMAADgQtWaUaF169by8vJSdna2y/bs7OwK1+CdOnWqRo0apQceeECS1K1bN+Xn52vcuHF65plnZLeX7ZVo3ry5OnXqpB07dkiSwsPDVVhYqJycHJd/eVbZcf38/OTn51ed02tQcnKk0qWSaVQAAAAoi2zrQQpzpB9Lwi2NCgAAAPAAaQfSJEndw7qrqW9Ti6sBAABwP9WaUcHX11exsbFKSUlxbnM4HEpJSVF8fPnrbJ06darML2y9StYhMMaUu8/Jkye1c+dORURESJJiY2Pl4+Pjctxt27Zp3759FR63sVu5Uioqkjp3ltq1s7oaAAAA90O29SDZKyVTJAV1lgIJtwAAAHB/qftLln1ow7IPAAAA5anWjAqSNHHiRI0ZM0a9e/dW3759NXv2bOXn52vs2LGSpNGjR6tNmzaaOXOmJCkpKUmzZs1Sr169FBcXpx07dmjq1KlKSkpy/lL3ySefVFJSktq1a6dDhw5p+vTp8vLy0t133y1JCg4O1v3336+JEyeqZcuWCgoK0m9+8xvFx8erXz+CXnlKl31ITLS2DgAAAHdGtvUQpcs+hBNuAQAA4BnSDhbPqBAfTTMyAABAeardqDBixAgdOXJE06ZNU1ZWlnr27KmlS5cqLCxMkrRv3z6Xf2U2ZcoU2Ww2TZkyRQcPHlRISIiSkpL04osvOl9z4MAB3X333frxxx8VEhKia665RmlpaQoJCXG+5tVXX5Xdbtedd96pgoICJSYm6vXXX6/JuTdYxvzUqMCyDwAAABUj23oAY35qVGDZBwAAAHiAwqJCpR9KlyTFR9GoAAAAUB6bqWiO2gYmLy9PwcHBys3NVVBQkNXl1KmMDKlTJ8nHRzp+XAoMtLoiAACA2tWYsl15GtX552VI/+kk2X2knx+XvAm3AACgYWlU2a4cDfH81x5Yq35v91OrgFY68tsjstlsVpcEAABQL6qT7eyVPguPtGxZ8ddrrqFJAQAAAB4uqyTchlxDkwIAAEA9mDNnjmJiYuTv76+4uDitW7euwtfOnz9fNpvN5eHv71+P1bqntAPFyz70i+pHkwIAAEAFaFRogFj2AQAAAA1G6bIP4YRbAACAurZw4UJNnDhR06dP18aNG9WjRw8lJibq8OHDFe4TFBSkzMxM52Pv3r31WLF7Sj2QKqm4UQEAAADlo1GhgSkslFauLP4+MdHaWgAAAIAaKSqUskvCbQThFgAAoK7NmjVLDz74oMaOHasrrrhCc+fOVZMmTfTOO+9UuI/NZlN4eLjzERYWVo8Vu6fSGRXio+ItrgQAAMB90ajQwKSmSidPSiEhUo8eVlcDAAAA1MDRVOncSckvRGpBuAUAAKhLhYWFSk9PV0JCgnOb3W5XQkKCUlNTK9zv5MmTateunaKjo3X77bfru+++q49y3VbmiUztzd0rm2zq26av1eUAAAC4LRoVGphlJUv4Dh4s2fnTBQAAgCfLKgm3EYMlG+EWAACgLh09elRFRUVlZkQICwtTVlZWuft07txZ77zzjj799FO9++67cjgc6t+/vw4cOFDhcQoKCpSXl+fyaEhKl324KvQqNfNrZnE1AAAA7ovf9jUw5zcqAAAAAB4tsyTchhNuAQAA3FF8fLxGjx6tnj17auDAgVq0aJFCQkL0xhtvVLjPzJkzFRwc7HxER0fXY8V1j2UfAAAAqoZGhQbk6FEpPb34+5tusrYWAAAAoEbOHJWOlYTbCMItAABAXWvdurW8vLyUnZ3tsj07O1vh4eFVGsPHx0e9evXSjh07KnzN5MmTlZub63zs37+/RnW7m9IZFeKjaVQAAACoDI0KDciKFZIxUvfuUkSE1dUAAAAANZC1QpKRmneXAgi3AAAAdc3X11exsbFKSUlxbnM4HEpJSVF8fNX+p3tRUZG++eYbRVTyy0k/Pz8FBQW5PBqKwqJCbTi0QZLUL6qfxdUAAAC4N2+rC0DtSU4u/sqyDwAAAPB4WSXhNoJwCwAAUF8mTpyoMWPGqHfv3urbt69mz56t/Px8jR07VpI0evRotWnTRjNnzpQkPf/88+rXr586duyonJwcvfzyy9q7d68eeOABK0/DMluyt+jMuTNq4d9CnVp1srocAAAAt0ajQgNhjLSsZAnfxERrawEAAABqxBgpsyTcRhBuAQAA6suIESN05MgRTZs2TVlZWerZs6eWLl2qsLAwSdK+fftkt/80Se/x48f14IMPKisrSy1atFBsbKy++uorXXHFFVadgqVS9xcv+9Avqp/sNiYzBgAAqAyNCg3Ed99Jhw5JAQHSNddYXQ0AAABQA7nfSacPSV4BUgjhFgAAoD5NmDBBEyZMKPe5VatWufz86quv6tVXX62HqjxD2sE0SSz7AAAAUBW0dTYQpbMpDBwo+ftbWwsAAABQI6WzKYQOlLwItwAAAPAMpTMqxEfFW1wJAACA+6NRoYEobVQYzBK+AAAA8HRZpcs+EG4BAADgGbJPZmt3zm7ZZFPfNn2tLgcAAMDt0ajQAJw+La1eXfx9Ikv4AgAAwJOdOy0dLgm3EYRbAAAAeIa0A8XLPlwRcoWC/YMtrgYAAMD90ajQAKxZI505I7VpI3XtanU1AAAAQA0cWSMVnZEC2khBhFsAAAB4htQDLPsAAABQHTQqNADJycVfExMlm83aWgAAAIAaySwJtxGEWwAAAHiO0kaFflH9LK4EAADAM9Co0AAsK1nCdzBL+AIAAMDTZZWE2wjCLQAAADzDOcc5rT+4XpIUH82MCgAAAFVBo4KHO3RI+uab4n9slpBgdTUAAABADZw6JOV8I8kmhRNuAQAA4Bm2ZG/R6XOnFewXrC6tu1hdDgAAgEegUcHDLV9e/LV3b6lVK2trAQAAAGokqyTctuwt+RFuAQAA4BlS9xcv+xAXFSe7jV+5AwAAVAWpycOx7AMAAAAajEyWfQAAAIDnSTuYJkmKj2LZBwAAgKqiUcGDORw/NSokJlpbCwAAAFAjxiFllTYqEG4BAADgOUpnVKBRAQAAoOpoVPBgmzdLR49KzZpJ/fpZXQ0AAABQA8c3SwVHJe9mUmvCLQAAADzDkfwj2nl8pySpb5u+FlcDAADgOWhU8GDJycVfb7xR8vGxthYAAACgRjJLwm34jZKdcAsAAADPkHageNmHrq27qkVAC4urAQAA8Bw0Kniw0mUfBrOELwAAADxdZkm4DSfcAgAAwHOkHihe9qFfFLOCAQAAVAeNCh7q5Enpyy+Lv6dRAQAAAB7t7EnpaEm4jSDcAgAAwHOUzqgQHxVvcSUAAACehUYFD7VqlXT2rHTZZVLHjlZXAwAAANTA4VWS46zU9DKpGeEWAAAAnuGc45zWHVwnSYqPplEBAACgOmhU8FAs+wAAAIAGg2UfAAAA4IG+Pfyt8s/mq5lvM3Vt3dXqcgAAADwKjQoeKjm5+GtiorV1AAAAADWWWRJuIwi3AAAA8Bylyz7ERcXJy+5lcTUAAACehUYFD7Rnj7R9u+TlJd1wg9XVAAAAADVwco90Yrtk85LCCLcAAADwHKkHUiVJ8VEs+wAAAFBdNCp4oNJlH+LjpeBga2sBAAAAaiSrJNy2jpd8CbcAAADwHKn7ixsV+kX1s7gSAAAAz0OjggcqbVQYzBK+AAAA8HSZJeE2nHALAAAAz/HjqR+VcSxDkhTXJs7iagAAADwPjQoe5tw5acWK4u9pVAAAAIBHc5yTskrCbQThFgAAAJ4j7UCaJKlTq05q1aSVxdUAAAB4HhoVPMz69VJurtSihdS7t9XVAAAAADXw43rpbK7k20JqSbgFAACA5yhtVIiPire4EgAAAM9Eo4KHKV32ISFB8vKythYAAACgRrJKl31IkOyEWwAAAHiO1AOpkmhUAAAAuFQ0KniY5OTir4mJ1tYBAAAA1FhmSbiNINwCAADAcxQ5irT24FpJUr+ofhZXAwAA4JloVPAgOTnS2uL8q8Es4QsAAABPVpgj/VgSbsMJtwAAAPAc3x/5XicLT6qpb1NdFXqV1eUAAAB4JBoVPEhKiuRwSF27StHRVlcDAAAA1EBWimQcUlBXKZBwCwAAAM9RuuxD3zZ95cUSZgAAAJeERgUPsqxkCV9mUwAAAIDHyyoJtxGEWwAAAHiW0kaFfm1Y9gEAAOBS0ajgIYyRkkuW8KVRAQAAAB7NGCmzJNyy7AMAAAA8TNqBNElSfHS8xZUAAAB4LhoVPERGhrR3r+TrKw0caHU1AAAAQA2cyJDy90p2XymMcAsAAADPcez0Mf1w9AdJUr8oZlQAAAC4VDQqeIjSZR+uuUYKDLS2FgAAAKBGMkvCbcg1kjfhFgAAAJ5j3cF1kqSOLTuqdZPWFlcDAADguWhU8BClyz4kJlpbBwAAAFBjpcs+RBBuAQAA4FlS96dKkuKjWPYBAACgJi6pUWHOnDmKiYmRv7+/4uLitG7dukpfP3v2bHXu3FkBAQGKjo7W448/rjNnzjifnzlzpvr06aNmzZopNDRUQ4cO1bZt21zGuP7662Wz2VweDz/88KWU73EKC6WVK4u/H8wSvgAAALWKbFvPigqlwyXhNoJwCwAAAM+SeqC4UYFlHwAAAGqm2o0KCxcu1MSJEzV9+nRt3LhRPXr0UGJiog4fPlzu6xcsWKBJkyZp+vTp2rp1q95++20tXLhQTz/9tPM1q1ev1vjx45WWlqbly5fr7NmzGjx4sPLz813GevDBB5WZmel8vPTSS9Ut3yN99ZWUny+FhUndu1tdDQAAQMNBtrXA0a+kc/mSf5jUnHALAAAAz+EwDq09uFYSMyoAAADUlHd1d5g1a5YefPBBjR07VpI0d+5cLV68WO+8844mTZpU5vVfffWVBgwYoJEjR0qSYmJidPfdd2vt2rXO1yxdutRln/nz5ys0NFTp6em67rrrnNubNGmi8PDw6pbs8ZaVLOF7002SncU6AAAAag3Z1gKZJeE2/CbJRrgFAACA59h6ZKvyCvLUxKeJuoV1s7ocAAAAj1at3wwWFhYqPT1dCQkJPw1gtyshIUGpqanl7tO/f3+lp6c7p9DdtWuXlixZoltuuaXC4+Tm5kqSWrZs6bL9vffeU+vWrXXVVVdp8uTJOnXqVIVjFBQUKC8vz+XhqZJLlvBl2QcAAIDaQ7a1SGZJuGXZBwAAAHiY0mUf+kT2kbe92v8GEAAAAOepVpo6evSoioqKFBYW5rI9LCxMP/zwQ7n7jBw5UkePHtU111wjY4zOnTunhx9+2GV63PM5HA499thjGjBggK666iqXcdq1a6fIyEht2bJFTz31lLZt26ZFixaVO87MmTP13HPPVef03NKRI9LGjcXf33STtbUAAAA0JGRbC5w5Ih0vCbfhhFsAAAB4lrQDaZJY9gEAAKA21Hnb56pVqzRjxgy9/vrriouL044dO/Too4/qhRde0NSpU8u8fvz48fr222+1Zs0al+3jxo1zft+tWzdFRERo0KBB2rlzpzp06FBmnMmTJ2vixInOn/Py8hQdHV2LZ1Y/Vqwo/tqjh9QYZwYGAABwJ2TbGsoqCbfNe0gBhFsAAAB4ltIZFeKjaVQAAACoqWo1KrRu3VpeXl7Kzs522Z6dnV3h+rpTp07VqFGj9MADD0gq/kVsfn6+xo0bp2eeeUZ2+0+rT0yYMEH/+c9/9MUXXygqKqrSWuLi4iRJO3bsKPeXuX5+fvLz86vO6bml0mUfEhOtrQMAAKChIdtawLnsA+EWAAAAniXnTI6+P/K9JKlfVD+LqwEAAPB89ou/5Ce+vr6KjY1VSkqKc5vD4VBKSori48vvIj116pTLL2wlycvLS5JkjHF+nTBhgj7++GN9/vnnat++/UVr2bx5syQpIiKiOqfgUYyRli0r/n4wS/gCAADUKrJtPTNGyioJtxGEWwAAAHiWdQfXSZIua3GZQgNDLa4GAADA81V76YeJEydqzJgx6t27t/r27avZs2crPz9fY8eOlSSNHj1abdq00cyZMyVJSUlJmjVrlnr16uWcHnfq1KlKSkpy/lJ3/PjxWrBggT799FM1a9ZMWVlZkqTg4GAFBARo586dWrBggW655Ra1atVKW7Zs0eOPP67rrrtO3bt3r61r4Xa+/VbKzJQCAqRrrrG6GgAAgIaHbFuPcr+VTmdKXgFSCOEWAAAAniV1f8myD1Es+wAAAFAbqt2oMGLECB05ckTTpk1TVlaWevbsqaVLlyosLEyStG/fPpd/ZTZlyhTZbDZNmTJFBw8eVEhIiJKSkvTiiy86X/PXv/5VknT99de7HGvevHm699575evrqxUrVjh/cRwdHa0777xTU6ZMuZRz9hilsylcf73UEGb6BQAAcDdk23qUWRJuQ6+XvAi3AAAA8CxpB9MksewDAABAbbGZ0jlqG7i8vDwFBwcrNzdXQUFBVpdTJYMHS8uXS6++Kj32mNXVAAAAuA9PzHa1ySPP//PBUtZy6epXpS6PWV0NAACA2/DIbFeLPOH8HcahVi+1Us6ZHG14cINiI2OtLgkAAMAtVSfb2St9FpY5fVr64ovi7xMTra0FAAAAqJFzp6XDJeE2gnALAAAAz7Lt6DblnMlRgHeAuoc14OXaAAAA6hGNCm7qiy+kggIpKkrq0sXqagAAAIAaOPyF5CiQmkRJQYRbAAAAeJa0A8XLPvSO7C0fLx+LqwEAAGgYaFRwU8tKlvBNTJRsNmtrAQAAAGokqyTcRhBuAQAA4HlSD6RKkuKj4i2uBAAAoOGgUcFNlTYqDB5sbR0AAABAjWWWhNtwwi0AAAA8T2mjQr+ofhZXAgAA0HDQqOCGDh6Uvv22+B+bJSRYXQ0AAABQA6cOSrnfSrJJ4YRbAAAAeJa8gjx9d/g7SVJ8NDMqAAAA1BYaFdzQ8uXFX/v0kVq2tLYWAAAAoEaySsJtqz6SH+EWAAAAnmXdwXUyMoppHqPwpuFWlwMAANBg0KjghpKTi7+y7AMAAAA8XmZJuGXZBwAAAHigtANpklj2AQAAoLbRqOBmHI6fZlRITLS2FgAAAKBGjOOnGRUiCLcAAACeYM6cOYqJiZG/v7/i4uK0bt26Ku33wQcfyGazaejQoXVbYD1LPZAqSYqPYtkHAACA2kSjgpvZuFH68UepWTMpLs7qagAAAIAaOLZRKvhR8m4mtSbcAgAAuLuFCxdq4sSJmj59ujZu3KgePXooMTFRhw8frnS/PXv26Mknn9S1115bT5XWD2OMc0YFGhUAAABqF40KbmbZsuKvgwZJPj7W1gIAAADUSFZJuA0fJNkJtwAAAO5u1qxZevDBBzV27FhdccUVmjt3rpo0aaJ33nmnwn2Kiop0zz336LnnntNll11Wj9XWvYxjGTp2+pj8vf3VI7yH1eUAAAA0KDQquJnSRoXBLOELAAAAT5dZEm4jCLcAAADurrCwUOnp6UpISHBus9vtSkhIUGpqaoX7Pf/88woNDdX9999fpeMUFBQoLy/P5eGuUvcXn3dsRKx8vXwtrgYAAKBhoVHBjZw4IX35ZfH3iSzhCwAAAE929oR0pCTcRhBuAQAA3N3Ro0dVVFSksLAwl+1hYWHKysoqd581a9bo7bff1ltvvVXl48ycOVPBwcHOR3R0dI3qrkupB4obFfpF9bO4EgAAgIaHRgU3smqVdO6c1KGD1MBmSQMAAEBjk71KMuekph2kpoRbAACAhubEiRMaNWqU3nrrLbVu3brK+02ePFm5ubnOx/79++uwyppJO5AmSYqPire4EgAAgIbH2+oC8JPk5OKvLPsAAAAAj5dZEm5Z9gEAAMAjtG7dWl5eXsrOznbZnp2drfDw8DKv37lzp/bs2aOkpCTnNofDIUny9vbWtm3b1KFDhzL7+fn5yc/Pr5arr30nCk7om8PfSJLio2lUAAAAqG3MqOBGlpUs4cuyDwAAAPB4WSXhlmUfAAAAPIKvr69iY2OVkpLi3OZwOJSSkqL4+LL/o75Lly765ptvtHnzZufjtttu0w033KDNmze79ZIOVbH+0Ho5jEPRQdGKbBZpdTkAAAANDjMquIndu6WMDMnbW7rhBqurAQAAAGrg5G7pRIZk85bCCLcAAACeYuLEiRozZox69+6tvn37avbs2crPz9fYsWMlSaNHj1abNm00c+ZM+fv766qrrnLZv3nz5pJUZrsnci77wGwKAAAAdYJGBTdROptCfLwUFGRtLQAAAECNZJaE29bxkg/hFgAAwFOMGDFCR44c0bRp05SVlaWePXtq6dKlCgsLkyTt27dPdnvjmKQ39UCqJCk+ikYFAACAukCjgpsobVQYzBK+AAAA8HTOZR8ItwAAAJ5mwoQJmjBhQrnPrVq1qtJ958+fX/sFWcAY45xRoV9UP4urAQAAaJgaR/urmzt3Tipd+i2RJXwBAADgyRznpKyScBtBuAUAAIDn2Xl8p46eOipfL1/1Cu9ldTkAAAANEo0KbmDdOik3V2rZUrr6aqurAQAAAGrgx3XS2VzJt6XUgnALAAAAz5O6v3jZh9iIWPl5+1lcDQAAQMNEo4IbSE4u/nrTTZKXl7W1AAAAADWSWRJuw2+S7IRbAAAAeB6WfQAAAKh7NCq4gWUlS/gOZglfAAAAeLrMknAbQbgFAACAZ0o9UDyjQnxUvMWVAAAANFw0Kljs+PHipR8kGhUAAADg4QqPS8dKwi2NCgAAAPBA+YX52pK9RRIzKgAAANQlGhUslpIiORzSFVdIUVFWVwMAAADUQFaKZBxS8BVSE8ItAAAAPM+GQxtUZIrUplkbRQdHW10OAABAg0WjgsVY9gEAAAANRumyD+GEWwAAAHgm57IP0Sz7AAAAUJdoVLCQMVJycvH3iYnW1gIAAADUiDFSZkm4jSDcAgAAwDOlHUiTJPVrw7IPAAAAdYlGBQtt3y7t2yf5+UnXXWd1NQAAAEANnNgundon2f2kUMItAAAAPI8xhhkVAAAA6gmNChYqnU3h2mulJk2srQUAAACokdLZFEKvlbwJtwAAAPA8u3N263D+YfnYfXR1xNVWlwMAANCg0ahgoWUlS/gOZglfAAAAeLrMknAbTrgFAACAZypd9qFXRC/5e/tbXA0AAEDDRqOCRQoKpJUri7+nUQEAAAAerahAyi4JtxGEWwAAAHim1P0lyz5EsewDAABAXaNRwSJffSWdOiWFhUndu1tdDQAAAFADR7+Sik5J/mFSc8ItAAAAPFPqgeJGhX5R/SyuBAAAoOGjUcEi5y/7YLNZWwsAAABQI+cv+0C4BQAAgAc6dfaUvs7+WhIzKgAAANQHGhUskpxc/DUx0do6AAAAgBrLLAm3EYRbAAAAeKb0Q+k65ziniKYRahvc1upyAAAAGjwaFSxw+LC0aVPx9zfdZG0tAAAAQI2cOSwdLwm3EYRbAAAAeKbzl32wMUsYAABAnaNRwQLLlxd/7dVLCg21thYAAACgRjJLwm2LXpI/4RYAAACeKe1AmiSWfQAAAKgvNCpYYFnJEr6DB1tbBwAAAFBjWSXhNoJwCwAAAM9kjHHOqBAfTaMCAABAfaBRoZ4ZQ6MCAAAAGghjpMyScBtOuAUAAIBn2pe7T1kns+Rt91ZsRKzV5QAAADQKNCrUs2++kbKypCZNpAEDrK4GAAAAqIGcb6QzWZJXEymEcAsAAADPVDqbQs/wngrwCbC4GgAAgMaBRoV6VjqbwvXXS35+lpYCAAAA1Ezpsg9h10tehFsAAAB4ptT9Jcs+RLHsAwAAQH2hUaGeJScXf01MtLYOAAAAoMYyS8JtBOEWAAAAnivtYJokqV9UP4srAQAAaDxoVKhHp05J//tf8feDWcIXAAAAnuzcKelwSbgNJ9wCAADAM505d0abMjdJYkYFAACA+kSjQj364gupoEBq21bq3NnqagAAAIAaOPyF5CiQmrSVggi3AAAA8Ezph9J11nFWoYGhimkeY3U5AAAAjcYlNSrMmTNHMTEx8vf3V1xcnNatW1fp62fPnq3OnTsrICBA0dHRevzxx3XmzJlqjXnmzBmNHz9erVq1UtOmTXXnnXcqOzv7Usq3zLKSJXwHD5ZsNmtrAQAAQDGy7SXKLAm3EYRbAAAAeK60A8XLPsRHxctGrgUAAKg31W5UWLhwoSZOnKjp06dr48aN6tGjhxITE3X48OFyX79gwQJNmjRJ06dP19atW/X2229r4cKFevrpp6s15uOPP65///vf+uijj7R69WodOnRId9xxxyWcsnWSS5bwZdkHAAAA90C2rYGsknAbQbgFAACA50o9kCqJZR8AAADqm80YY6qzQ1xcnPr06aO//OUvkiSHw6Ho6Gj95je/0aRJk8q8fsKECdq6datSUlKc25544gmtXbtWa9asqdKYubm5CgkJ0YIFC/Tzn/9ckvTDDz+oa9euSk1NVb9+/S5ad15enoKDg5Wbm6ugoKDqnHKtOHBAio6W7HbpyBGpZct6LwEAAKDBqK1sR7a9RKcOSJ9ESza7dMcRyY9wCwAAcKksz3YWs/r8o2ZF6eCJg1o1ZpUGxgys9+MDAAA0JNXJdtWaUaGwsFDp6elKSEj4aQC7XQkJCUpNTS13n/79+ys9Pd053e2uXbu0ZMkS3XLLLVUeMz09XWfPnnV5TZcuXdS2bdsKj+tuSpd96NOHJgUAAAB3QLatgdJlH1r2oUkBAAAAHmt/7n4dPHFQXjYv9Y7sbXU5AAAAjYp3dV589OhRFRUVKSwszGV7WFiYfvjhh3L3GTlypI4ePaprrrlGxhidO3dODz/8sHN63KqMmZWVJV9fXzVv3rzMa7Kysso9bkFBgQoKCpw/5+XlVedUa11po0JioqVlAAAAoATZtgZKGxUiCLcAAADwXKXLPvQI76FA30CLqwEAAGhcqjWjwqVYtWqVZsyYoddff10bN27UokWLtHjxYr3wwgt1etyZM2cqODjY+YiOjq7T41WmqEhavrz4+8Es4QsAAOCxyLaSHEVSVkm4jSDcAgAAwHOlHUiTJPVrc/Hl1wAAAFC7qtWo0Lp1a3l5eSk7O9tle3Z2tsLDw8vdZ+rUqRo1apQeeOABdevWTcOGDdOMGTM0c+ZMORyOKo0ZHh6uwsJC5eTkVPm4kydPVm5urvOxf//+6pxqrdq4UTp2TAoKkuLiLCsDAAAA5yHbXqLjG6XCY5JPkNSKcAsAAADPVTqjQnx0vMWVAAAAND7ValTw9fVVbGysUlJSnNscDodSUlIUH19+mDt16pTsdtfDeHl5SZKMMVUaMzY2Vj4+Pi6v2bZtm/bt21fhcf38/BQUFOTysErpsg+DBkne1VpsAwAAAHWFbHuJSpd9CBsk2Qm3AAAA8EwF5wq0MXOjJCk+ikYFAACA+lbt3yxOnDhRY8aMUe/evdW3b1/Nnj1b+fn5Gjt2rCRp9OjRatOmjWbOnClJSkpK0qxZs9SrVy/FxcVpx44dmjp1qpKSkpy/1L3YmMHBwbr//vs1ceJEtWzZUkFBQfrNb36j+Ph49evn/tNyJScXf2XZBwAAAPdCtr0EmSXhlmUfAAAA4ME2ZW1SYVGhWjdprctaXGZ1OQAAAI1OtRsVRowYoSNHjmjatGnKyspSz549tXTpUoWFhUmS9u3b5/KvzKZMmSKbzaYpU6bo4MGDCgkJUVJSkl588cUqjylJr776qux2u+68804VFBQoMTFRr7/+ek3OvV7k5UmpxTOIKTHR2loAAADgimxbTWfzpKMl4TaCcAsAAADPlbq/ZNmHqHjZbDaLqwEAAGh8bMYYY3UR9SEvL0/BwcHKzc2t16lyP/1UGjpU6thRysiot8MCAAA0aFZlO3dh2fkf+FT6YqjUtKN0G+EWAACgNpBtrTn/uz66Sx99/5FevPFFPX3t0/V2XAAAgIasOtnOXumzqLFlJUv4MpsCAAAAPF5mSbhlNgUAAAB4uLQDaZKKZ1QAAABA/aNRoY6VNioMZglfAAAAeDpnowLhFgAAAJ7rYN5B7c/bL7vNrj5t+lhdDgAAQKNEo0Id2rVL2rFD8vaWbrjB6moAAACAGji5Szq5Q7J5S2GEWwAAAHiu0tkUuoV2U1PfphZXAwAA0DjRqFCHSmdT6N9fatbM2loAAACAGimdTSGkv+RDuAUAAIDnSj2QKollHwAAAKxEo0IdSk4u/sqyDwAAAPB4mSXhNpxwCwAAAM/mbFSIplEBAADAKjQq1JGzZ6XPPy/+PjHR2loAAACAGnGclbJLwm0E4RYAAACeq7CoUOmH0iVJ/aL6WVwNAABA40WjQh1Zu1bKy5NatZJ69bK6GgAAAKAGjq6VzuZJfq2kFoRbAAAAeK7NWZtVUFSgVgGtdHnLy60uBwAAoNHytrqAhqpHD+njj6Uff5S8vKyuBgAAAKiBFj2kaz+WCn+U7IRbAAAAeK7OrTrrX3f9S8dPH5fNZrO6HAAAgEaLRoU60qyZNHSo1VUAAAAAtcCnmRQ91OoqAAAAgBoL9g/WHV3vsLoMAACARo+lHwAAAAAAAAAAAAAAQL2hUQEAAAAAAAAAAAAAANQbGhUAAAAAAAAAAAAAAEC9oVEBAAAAAAAAAAAAAADUGxoVAAAAAAAAAAAAAABAvaFRAQAAAAAAAAAgSZozZ45iYmLk7++vuLg4rVu3rsLXLlq0SL1791bz5s0VGBionj176h//+Ec9VgsAAABPRaMCAAAAAAAAAEALFy7UxIkTNX36dG3cuFE9evRQYmKiDh8+XO7rW7ZsqWeeeUapqanasmWLxo4dq7Fjxyo5ObmeKwcAAICnoVEBAAAAAAAAAKBZs2bpwQcf1NixY3XFFVdo7ty5atKkid55551yX3/99ddr2LBh6tq1qzp06KBHH31U3bt315o1a+q5cgAAAHgaGhUAAAAAAAAAoJErLCxUenq6EhISnNvsdrsSEhKUmpp60f2NMUpJSdG2bdt03XXXVfi6goIC5eXluTwAAADQ+NCoAAAAAAAAAACN3NGjR1VUVKSwsDCX7WFhYcrKyqpwv9zcXDVt2lS+vr669dZb9ec//1k33XRTha+fOXOmgoODnY/o6OhaOwcAAAB4DhoVAAAAAAAAAACXpFmzZtq8ebPWr1+vF198URMnTtSqVasqfP3kyZOVm5vrfOzfv7/+igUAAIDb8La6AAAAAAAAAACAtVq3bi0vLy9lZ2e7bM/OzlZ4eHiF+9ntdnXs2FGS1LNnT23dulUzZ87U9ddfX+7r/fz85OfnV2t1AwAAwDMxowIAAAAAAAAANHK+vr6KjY1VSkqKc5vD4VBKSori4+OrPI7D4VBBQUFdlAgAAIAGhBkVAAAAAAAAAACaOHGixowZo969e6tv376aPXu28vPzNXbsWEnS6NGj1aZNG82cOVOSNHPmTPXu3VsdOnRQQUGBlixZon/84x/661//auVpAAAAwAPQqAAAAAAAAAAA0IgRI3TkyBFNmzZNWVlZ6tmzp5YuXaqwsDBJ0r59+2S3/zRJb35+vn7961/rwIEDCggIUJcuXfTuu+9qxIgRVp0CAAAAPITNGGOsLqI+5Obmqnnz5tq/f7+CgoKsLgcAAAA1kJeXp+joaOXk5Cg4ONjqcuod2RYAAKDhINuSbQEAABqK6mTbRjOjwokTJyRJ0dHRFlcCAACA2nLixIlG+ctcsi0AAEDDQ7Yl2wIAADQUVcm2jWZGBYfDoUOHDqlZs2ay2Wz1cszSjpGG3A3c0M7Rk8/HE2p31xrdqS6raqnv49b0eHVdb22PX5vjXcpYtXV8dxqnrq+pO9XoCeNYce8yxujEiROKjIx0mXq2sSDb1o2Gdo6efD6eULu71uhOdZFt62f/+h6fbFv745Bt3Wscsm39I9vWjYZ2jp58Pp5Qu7vW6E51kW3rZ//6Hp9sW/vjkG3daxx3z7aNZkYFu92uqKgoS44dFBRk+V+ida2hnaMnn48n1O6uNbpTXVbVUt/Hrenx6rre2h6/Nse7lLFq6/juNE5dX1N3qtETxqnve0hj/Ndmpci2dauhnaMnn48n1O6uNbpTXWTb+tm/vscn29b+OGRb9xqHbFt/yLZ1q6GdoyefjyfU7q41ulNdZNv62b++xyfb1v44ZFv3Gsdds23ja9EFAAAAAAAAAAAAAACWoVEBAAAAAAAAAAAAAADUGxoV6pCfn5+mT58uPz8/q0upMw3tHD35fDyhdnet0Z3qsqqW+j5uTY9X1/XW9vi1Od6ljFVbx3encer6mrpTjZ4wjjvdR1F3GsOfc0M7R08+H0+o3V1rdKe6yLb1s399j0+2rf1xyLbuNY473UdRdxrDn3NDO0dPPh9PqN1da3Snusi29bN/fY9Ptq39cci27jWOO91Hy2MzxhiriwAAAAAAAAAAAAAAAI0DMyoAAAAAAAAAAAAAAIB6Q6MCAAAAAAAAAAAAAACoNzQqAAAAAAAAAAAAAACAekOjwiV69tlnZbPZXB5dunSpdJ+PPvpIXbp0kb+/v7p166YlS5bUU7VV88UXXygpKUmRkZGy2Wz65JNPnM+dPXtWTz31lLp166bAwEBFRkZq9OjROnToUKVjXsp1qi2VnY8kZWdn695771VkZKSaNGmim2++WRkZGZWOuWjRIvXu3VvNmzdXYGCgevbsqX/84x+1XvvMmTPVp08fNWvWTKGhoRo6dKi2bdvm8prrr7++zLV9+OGHq3yMhx9+WDabTbNnz76kGv/617+qe/fuCgoKUlBQkOLj4/Xf//7X+fyZM2c0fvx4tWrVSk2bNtWdd96p7OzsSsc8efKkJkyYoKioKAUEBOiKK67Q3Llza7WuS7lutVHX73//e9lsNj322GPObZdyjZ599ll16dJFgYGBatGihRISErR27dpqH7uUMUZDhgwp9zNyKce+8Fh79uwpc71LHx999JFz3Aufu/zyy52fz4CAALVt21YtWrSo8nUyxmjatGlq2rRppfeghx56SB06dFBAQIBCQkJ0++2364cffqh07BEjRlQ6ZnXeY+Wdu91ud77HsrKyNGrUKIWHhyswMFBXX321/vWvf+ngwYP65S9/qVatWikgIEDdunXThg0bJBV/Brp16yY/Pz/Z7XbZ7Xb16tWr3PvbheNERkYqIiJC/v7+6tOnj0aPHn3R+/6FY7Rp00YdO3Ys9zNY2X3nwnG6dOmiIUOGuJzjRx99pNtuu03BwcEKDAxUnz59tG/fvkrHCQsLk7e3d7nvQW9vb91888369ttvK/0sLlq0SH5+fuWOERgYKH9/f0VHR+uyyy5zvl8feeQR5ebmljnPmJiYcsfx8/Nz+UxV9tmsaIz27ds7r03Xrl3Vv39/BQYGKigoSNddd51Onz5d5XqaNm2qyMhI+fv7KzAwUIGBgWrWrJnuuusuZWdnOz9jERERCggIUEJCgvM9Vtl9eM6cOYqJiZG/v7/i4uK0bt26MjXBGmRbsi3ZlmxbHWRbsm1F15RsW/44ZFuyLeoX2ZZsS7Yl21YH2ZZsW9E1JduWPw7Zlmxbm2hUqIErr7xSmZmZzseaNWsqfO1XX32lu+++W/fff782bdqkoUOHaujQofr222/rseLK5efnq0ePHpozZ06Z506dOqWNGzdq6tSp2rhxoxYtWqRt27bptttuu+i41blOtamy8zHGaOjQodq1a5c+/fRTbdq0Se3atVNCQoLy8/MrHLNly5Z65plnlJqaqi1btmjs2LEaO3askpOTa7X21atXa/z48UpLS9Py5ct19uxZDR48uExtDz74oMu1femll6o0/scff6y0tDRFRkZeco1RUVH6/e9/r/T0dG3YsEE33nijbr/9dn333XeSpMcff1z//ve/9dFHH2n16tU6dOiQ7rjjjkrHnDhxopYuXap3331XW7du1WOPPaYJEybos88+q7W6pOpft5rWtX79er3xxhvq3r27y/ZLuUadOnXSX/7yF33zzTdas2aNYmJiNHjwYB05cqRaxy41e/Zs2Wy2Kp3HxY5d3rGio6NdrnVmZqaee+45NW3aVEOGDHG+7vz7xKFDhxQcHOz8fA4dOlTHjh2Tr6+vli5dWqXr9NJLL+lPf/qTfvazn6lDhw4aPHiwoqOjtXv3bpd7UGxsrObNm6etW7cqOTlZxhgNHjxYRUVFFY5dWFio0NBQvfLKK5Kk5cuXl7mvVec9duWVV+qee+5Ru3bt9K9//UsbNmxwvseGDBmibdu26bPPPtM333yjO+64Q8OHD1efPn3k4+Oj//73v/r+++/1xz/+US1atJBU/Bno3bu3/Pz89Je//EX333+/vv76a9144406c+aM87jHjx/XgAEDnOO89NJLOnLkiB577DFt3LhRV155pd5//3098sgjFd73Lxzj+++/10MPPaTJkyeX+Qy+9tprFd53LhwnNTVVx48fV5MmTZzjPvHEExo3bpy6dOmiVatWacuWLZo6dar8/f0rHGf06NE6d+6cXnnlFaWlpWnGjBmSpA4dOkiS3nnnHbVr107x8fH67LPPKvwstmzZUm+88YZWr16t1NRUPf/8887nJk+erPfee09FRUU6deqU0tPTNX/+fC1dulT3339/mXNdv369830xZ84c/eEPf5AkzZ071+UzVdln8/wxMjMz9be//U2SFBcXp1WrVmn+/Pnat2+fbrzxRq1bt07r16/XhAkTZLeXjX2lYyUlJalTp0764x//KEk6d+6ccnJy1Lp1a1111VWSpPHjx6uwsFBJSUn6wx/+oD/96U+aO3eu1q5dq8DAQCUmJurMmTMV3odfeeUVTZw4UdOnT9fGjRvVo0cPJSYm6vDhw+WeJ+of2ZZsS7Yl21YF2ZZsS7Yl25Yi25Jt3RnZlmxLtiXbVgXZlmxLtiXbliLbWpRtDS7J9OnTTY8ePar8+rvuusvceuutLtvi4uLMQw89VMuV1Q5J5uOPP670NevWrTOSzN69eyt8TXWvU1258Hy2bdtmJJlvv/3Wua2oqMiEhISYt956q1pj9+rVy0yZMqW2Si3X4cOHjSSzevVq57aBAweaRx99tNpjHThwwLRp08Z8++23pl27dubVV1+ttTpbtGhh/u///s/k5OQYHx8f89FHHzmf27p1q5FkUlNTK9z/yiuvNM8//7zLtquvvto888wztVKXMZd23WpS14kTJ8zll19uli9f7nLsS71GF8rNzTWSzIoVK6p87FKbNm0ybdq0MZmZmVX6zFd27Isd63w9e/Y09913n/PnC+8T538+S6/TwoULnZ/Pi10nh8NhwsPDzcsvv+wcOycnx/j5+Zn333+/0nP6+uuvjSSzY8eOCl9TOubu3buNJLNp0yaX56vzHisdq6L3mI+Pj/n73//ust3f39907NixwjHPP/9SzZs3N97e3i7n/9RTT5lrrrnG+XPfvn3N+PHjnT8XFRWZyMhIM3PmTOe2C+/7F45RkeDgYNOiRYsK7zsXjlPeuCNGjDC//OUvKz3OhftFRESYv/zlL86fS99bMTExpkOHDsbhcJhjx44ZSebhhx92vq4q7zGbzWYCAgKMw+Ewxpgy77EPP/zQ+Pr6mrNnz1Za86OPPuqspfQzNXfu3Gp9Ni+//HLTtGlTZy1xcXHV+nvp1KlTxsvLy/znP/8xjz76qGnSpIkZO3as6dixo7HZbCY3N9fccccd5p577jE5OTlGkmnZsqXLe+xin7EWLVqY9u3bX/Q9BuuQbcm2pci2PyHblkW2LYtsW3Yssi3ZlmwLq5FtybalyLY/IduWRbYti2xbdiyyLdmWbFu3mFGhBjIyMhQZGanLLrtM99xzT5lpTM6XmpqqhIQEl22JiYlKTU2t6zLrTG5urmw2m5o3b17p66pznepLQUGBJLl0dNntdvn5+VW5c9gYo5SUFG3btk3XXXddndRZqnQampYtW7psf++995xdU5MnT9apU6cqHcfhcGjUqFH67W9/qyuvvLLW6isqKtIHH3yg/Px8xcfHKz09XWfPnnV5z3fp0kVt27at9D3fv39/ffbZZzp48KCMMVq5cqW2b9+uwYMH10pdpap73WpS1/jx43XrrbeW+fxf6jU6X2Fhod58800FBwerR48eVT62VNxtP3LkSM2ZM0fh4eFVOl5lx67sWOdLT0/X5s2by3Qsnn+fePzxxyUVfz5Lr9PgwYOdn8+LXafdu3crKyvLWUtGRoa6du0qm82mZ599tsJ7UH5+vubNm6f27dsrOjq60vPIyMhQXFycJOnpp58uM2Z13mMZGRnavXu3/t//+38aNmyY9u7d63yP9ejRQwsXLtSxY8fkcDj0wQcfqKCgQNdcc42GDx+u0NBQ9erVS2+99Va551/6GTh16pR69uzpcs0+++wz9e7d2znOunXr5HA4nM/b7XYlJCS47HPhff/CMS6spaioSAsWLFBeXp4eeuihCu87F44ze/Zs+fn5OX/u2bOnPvnkE3Xq1EmJiYkKDQ1VXFxcmam1Lhzn8OHDLlNUld779+3bp/vuu082m02bNm1ynlupyt5jxhjNnz9fxhjddNNNzu7Z4OBgxcXFOffJzc1VUFCQvL29yz1nqfhz9O677+q+++7T2bNn9eabbyooKEizZs2q8mfzzJkzzvfjzTffrNatW2vt2rXKyspS//79FRYWpoEDB1b6d9u5c+dUVFQkLy8vvfvuuxowYIA+//xzORwOGWO0bds2rVmzRkOGDJG/v7/sdruOHTvm8nm/8PxLlb4HT548qX379rnsU957DNYi25JtybbFyLYVI9u6ItuWPxbZlmxLtoU7INuSbcm2xci2FSPbuiLblj8W2ZZsS7atY3XeCtFALVmyxHz44Yfm66+/NkuXLjXx8fGmbdu2Ji8vr9zX+/j4mAULFrhsmzNnjgkNDa2PcqtNF+kEOn36tLn66qvNyJEjKx2nuteprlx4PoWFhaZt27Zm+PDh5tixY6agoMD8/ve/N5LM4MGDKx0rJyfHBAYGGm9vb+Pn52fefvvtOq29qKjI3HrrrWbAgAEu29944w2zdOlSs2XLFvPuu++aNm3amGHDhlU61owZM8xNN93k7N6qaWfuli1bTGBgoPHy8jLBwcFm8eLFxhhj3nvvPePr61vm9X369DG/+93vKhzvzJkzZvTo0UaS8fb2Nr6+vuZvf/tbrdVlzKVdt0ut6/333zdXXXWVOX36tDHGtWPzUq+RMcb8+9//NoGBgcZms5nIyEizbt26ah3bGGPGjRtn7r//fufPF/vMV3bsix3rfL/61a9M165dXbZdeJ/o16+f8fLyMkOHDjVvvvmm8fX1LfP5rOw6ffnll0aSOXTokMvY1157rWnVqlWZe9CcOXNMYGCgkWQ6d+5caVfu+fUuWbLESDLdu3d3GbM677HSsdavX28GDRpkJBlJxsfHx/ztb38zx48fN4MHD3a+94KCgoyPj4/x8/MzkydPNhs3bjRvvPGG8ff3N/Pnz3c5/4CAAJfPwPDhw81dd93lPLafn59znOTkZCPJ+Pr6Oscxxpjf/va3pm/fvsaY8u/7549xfi0vvPCC8zPo5+dnevXqVel958JxvL29jSRz6623mo0bN5qXXnrJWd+sWbPMpk2bzMyZM43NZjOrVq2qcJw+ffoYm81mfv/735uioiLnn5kk891335mCggLzi1/8otx7/4XvsfPv/V5eXkaS2bhxo8s+pdf4yJEjpm3btubpp5+u9L20cOFCY7fbTUBAgPMzNWzYsGp9Nt944w0jyfj7+5tZs2aZv/3tb85zfOqpp8zGjRvNY489Znx9fc327dsrHCc+Pt507drVeHl5mT179pif/exnznEkmWeffdacPHnSTJgwwbnt0KFD5Z6/MWXvw3//+9+NJPPVV1+57HP+ewzWItuSbcm2ZNuLIduWRbYtfyyyLdmWbAurkW3JtmRbsu3FkG3LItuWPxbZlmxLtq1bNCrUkuPHj5ugoCDnNEUXakiBt7Cw0CQlJZlevXqZ3Nzcao17setUV8o7nw0bNpgePXoYScbLy8skJiaaIUOGmJtvvrnSsYqKikxGRobZtGmTeeWVV0xwcLBZuXJlndX+8MMPm3bt2pn9+/dX+rqUlJRKpz7asGGDCQsLMwcPHnRuq2ngLSgoMBkZGWbDhg1m0qRJpnXr1ua777675DD38ssvm06dOpnPPvvMfP311+bPf/6zadq0qVm+fHmt1FWei123S61r3759JjQ01Hz99dfObbUVeE+ePGkyMjJMamqque+++0xMTIzJzs6u8rE//fRT07FjR3PixAnn81UNvBceOyoqyrRu3brCY53v1KlTJjg42LzyyiuVHuP48eMmMDDQREVFOf9ivfDzWdXAe77hw4eboUOHlrkH5eTkmO3bt5vVq1ebpKQkc/XVVzvDe2VKpxD74osvKr2vVec9tmDBAtO0aVMzcuRI07RpU3P77bebvn37mhUrVpjNmzebZ5991kgqMzXjb37zG9OvXz+X8//yyy9dPgOJiYkugdfHx8fEx8cbY4w5ePCgkWR+/vOfO8cx5qcwUtF9//wxzq8lLi7OZGRkmH/84x8mMDDQtGjRwvkZLO++c+E4Pj4+Jjw83FlLaX2tWrVy2S8pKcn84he/qHCcw4cPm/bt2zvv8506dTJhYWHO95WXl5fp1q2bsdlsZe79F77Hzr/3R0dHG0nmn//8p8s+w4cPN8OGDTN9+/Y1N998syksLDSVGTx4sBkyZIjzM5WQkGC8vb3Nrl27nK+52Gdz4MCBRpK5++67jTE//fl37NjR5dp069bNTJo0qcJxduzYYVq0aGEkGZvNZnx8fMyAAQNMWFiYCQkJcW7/5S9/aTp16nTRwHvhfbh0bH6Z6znItlVDtq0+si3Z9kJkW7It2bYY2ZZsi7pDtq0asm31kW3Jthci25JtybbFyLZk26qiUaEW9e7du8I3U3R0dJkP+LRp00z37t3robLqq+gDVlhYaIYOHWq6d+9ujh49ekljV3ad6kplN4ycnBxz+PBhY0zxWj+//vWvqzX2/ffff9Fu3ks1fvx4ExUV5XLzq8jJkyeNJLN06dJyn3/11VeNzWYzXl5ezockY7fbTbt27Wql3kGDBplx48Y5/4I/fvy4y/Nt27Y1s2bNKnffU6dOGR8fH/Of//zHZfv9999vEhMTa6Wu8lzsul1qXR9//LHzL9Tzr3fpn8GKFSuqfY0q0rFjRzNjxowqH3vChAkVvhcGDhxYrWOHh4dXeqxz5845X/v3v//d+Pj4OD9vlSm9T3z66afO63T+57Oy67Rz504jlV2D7LrrrjOPPPJIpfeggoIC06RJkzK/oCjP+WudVTZmdd9jpWMNHz7cSK5rMhpTvNZZly5dXLa9/vrrJjIyssLzHzRokImIiDCPPPKIc1vbtm2dHaAFBQXGy8vLPPTQQ85xjDFm9OjR5mc/+1mF9/3zxyivltL7TumjovvOheO0bdvW9O/f3zlOQUGBsdvtplmzZi7H+t3vfmf69+9/0XoiIiLMgQMHzO7du43NZjPR0dHOe3/p/erC/Sp6j+3Zs8fY7XYjyeU/Dowxpn///iY8PNwMGjToov/RVDrOJ5984tz26KOPOq9PVT6bpWPY7XbzwgsvGGOM2bVrl7Or+fxrc9ddd1X6r2lKx/rggw+ca8Tddddd5pZbbjHGGDNp0iRz+eWXG2OMadWqVaWfsfLccMMNxmazlfm7ePTo0ea2226rsC5Yi2xbNWTbqiPbkm2rgmzrimxLtr2wHrIt2RaXhmxbNWTbqiPbkm2rgmzrimxLtr2wHrIt2dYu1IqTJ09q586dioiIKPf5+Ph4paSkuGxbvny5y/pL7u7s2bO66667lJGRoRUrVqhVq1bVHuNi18kKwcHBCgkJUUZGhjZs2KDbb7+9Wvs7HA7n+jm1xRijCRMm6OOPP9bnn3+u9u3bX3SfzZs3S1KF13bUqFHasmWLNm/e7HxERkbqt7/9rZKTk2ul7tJrERsbKx8fH5f3/LZt27Rv374K3/Nnz57V2bNnZbe73pa8vLxc1l+qSV3ludh1u9S6Bg0apG+++cblevfu3Vv33HOP8/vqXqOqnt/Fjv3MM8+UeS9I0quvvqp58+ZV69j+/v761a9+VeGxvLy8nK99++23ddtttykkJKTSMc+/TwwcOFA+Pj569913nZ/Pi12n9u3bKzw83OXa5uXlae3aterVq1el9yBT3MBXrc/0qVOnKh2zOu+x88/dGCNJZd57zZs31/Hjx122bd++Xe3atZNU/vkXFhYqOzvb5ZoNGDBA27ZtkyT5+voqNjZWaWlpznEcDodWrFihXbt2VXjfP3+M8mopve/07t1bSUlJFd53LhxnwIAB2rNnj3McX19fhYWFyc/Pr8JjVVZPTEyM2rRpo7ffflt2u10jR4503vtL1207/8+nsvfYvHnzFBoaKn9/fx0+fNi5/cCBA0pNTVWLFi302WefuaylWZ7ScW699VbntkmTJikqKkoPPfRQlT6bpWP07dvXed4xMTGKjIxURkaGy7W58FpVNNadd96pgoICnTlzRsnJyc6/E4OCgiRJn3/+uX788UeFhISU+xmr7P7VqlUrl30cDodSUlI8Kgs1JmTbqiHbVg3Z9idk2+qfH9mWbEu2dX0N2ZZsi+oj21YN2bZqyLY/IdtW//zItmRbsq3ra8i2ZFtmVLhETzzxhFm1apXZvXu3+fLLL01CQoJp3bq1s+Ns1KhRLl1aX375pfH29javvPKK2bp1q5k+fbrx8fEx33zzjVWnUMaJEyfMpk2bzKZNm4wk53oye/fuNYWFhea2224zUVFRZvPmzSYzM9P5KCgocI5x4403mj//+c/Ony92naw6H2OM+fDDD83KlSvNzp07zSeffGLatWtn7rjjDpcxLvxznDFjhlm2bJnZuXOn+f77780rr7xivL29zVtvvVWrtf/qV78ywcHBZtWqVS7X+tSpU8aY4qlenn/+ebNhwwaze/du8+mnn5rLLrvMXHfddS7jdO7c2SxatKjC49RkCrFJkyaZ1atXm927d5stW7aYSZMmGZvNZpYtW2aMKZ76rG3btubzzz83GzZsMPHx8WWmGrqwvoEDB5orr7zSrFy50uzatcvMmzfP+Pv7m9dff71W6rrU61YbdZWOc/7UWtW9RidPnjSTJ082qampZs+ePWbDhg1m7Nixxs/Pr0z35sWOfSGV071+qccu71gZGRnGZrOZ//73v2WO/cQTT5jo6Ggzd+5c532iWbNm5uOPPzY7d+40N998s/Hy8jLXXnttld9Lv//9703z5s3N0KFDzTvvvGNuuukmExERYW688UbnPWjnzp1mxowZZsOGDWbv3r3myy+/NElJSaZly5YuU7JdOPb48ePNW2+9Zd555x0jyXTr1s00b97cfPPNN9V+j5XeI+Pi4kz79u1NbGysadmypXnttdeMn5+fCQkJMddee61Zu3at2bFjh3nllVecndAvvviiycjIMFdccYXx9fU17777rjGm+DPw0EMPmaCgIPPaa6+Z++67z0gy4eHhLt2ivXv3Nna73TlO6RpW48aNM99//7154IEHjLe3t4mMjKzwvr9u3Tpjs9nMz372M5ORkWHee+894+PjY6ZMmVLhvaG8+86FtTz//PNGkhk+fLhzXF9fX+Pl5WXefPNNk5GRYf785z8bLy8v87///c85zpAhQ1zGee6554yfn5+ZNWuWWbVqlfHz8zNNmjQx//73v13u/e3bt3f5LIaEhJg2bdo4x50xY4aJiooyf/nLX0xERIS54YYbjN1uN02aNDGffvqp+eqrr0yLFi2Mj4+P+e6771yu1fnd6aV/7kVFRSY6Otr069fvop+pij6b//znP03btm3NU089ZRYtWmR8fHyc1+aOO+4wkszzzz9vMjIyzJQpU4y/v7/LNHbn/31dVFRkQkNDzfDhw82uXbvMTTfdZHx8fEynTp3MzJkzzcyZM02LFi3Mrbfealq2bGkmTpzo/Ix9+umnpm/fvqZbt26mffv25vTp0877cP/+/c3kyZOd74Gnn37a+Pn5mfnz55vvv//ejBs3zjRv3txkZWUZWI9sS7Yl25JtybZkW7It2ZZsS7ZtKMi2ZFuyLdmWbEu2JduSbcm2npFtaVS4RCNGjDARERHG19fXtGnTxowYMcLljTRw4EAzZswYl30+/PBD06lTJ+Pr62uuvPJKs3jx4nquunIrV640Kln/5fzHmDFjnFPllPc4f52vdu3amenTpzt/vth1sup8jDHmtddeM1FRUcbHx8e0bdvWTJkyxSW8G1P2z/GZZ54xHTt2NP7+/qZFixYmPj7efPDBB7Vee0XXet68ecaY4rWsrrvuOtOyZUvj5+dnOnbsaH7729+WWXvu/H3KU5PAe99995l27doZX19fExISYgYNGuT8C80YY06fPm1+/etfmxYtWpgmTZqYYcOGmczMzErry8zMNPfee6+JjIw0/v7+pnPnzuaPf/yjcTgctVLXpV632qjLmLJBsLrX6PTp02bYsGEmMjLS+Pr6moiICHPbbbeZdevWVfvYFyrvL9VLPXZ5x5o8ebKJjo42RUVFZV4/YsQII8l4e3s77xNTp051fj6jo6NNbGxstd5LDofDTJ061fj5+TmnNAsLC3O5Bx08eNAMGTLEhIaGGh8fHxMVFWVGjhxpfvjhh0rH7tu3b7mfz+nTp1f7PXb+PbJJkybG39/f+Pr6Ot9j27ZtM3fccYcJDQ01TZo0Md27dzd///vfzb///W9z1VVXGT8/P+Pt7W1+9rOfOce+7777TNu2bY3dbjc2m83Y7XbTq1cvs23bNpca2rVrZ+6++27nOF26dDG/+MUvTNu2bY2vr69zLciL3fdDQkJMaGioc4wBAwZUem8o775TXi0TJkxw+fnNN980b7/9tvMe3KNHD5fpt4wpfu/deOONzv3atm1rwsPDjZ+fn2nWrJmRZB555JEy9/7c3FyXz2Lr1q1d1oV75plnnFN5STI9e/Y077//vpk6daoJCwszPj4+FV6r3bt3l/lzT05ONpJMQkLCRT9TFX02n3jiCSPJ+ed64bUZNWqUiYqKMk2aNDHx8fEu/2FQes1L/74urScqKsr4+vqa0NBQ0717dxMVFWW8vb2Nl5eXsdvtpmPHjs57X+lnrHTtuPbt2ztrKb0PSzJNmjRxeQ/8+c9/dr7H+vbta9LS0gzcA9mWbEu2JduSbcm2ZFuyLdmWbNtQkG3JtmRbsi3ZlmxLtiXbkm09I9vaSi4cAAAAAAAAAAAAAABAnbNf/CUAAAAAAAAAAAAAAAC1g0YFAAAAAAAAAAAAAABQb2hUAAAAAAAAAAAAAAAA9YZGBQAAAAAAAAAAAAAAUG9oVAAAAAAAAAAAAAAAAPWGRgUAAAAAAAAAAAAAAFBvaFQAAAAAAAAAAAAAAAD1hkYFAAAAAAAAAAAAAABQb2hUAIBG6Nlnn1VYWJhsNps++eSTKu2zatUq2Ww25eTk1Glt7iQmJkazZ8+2ugwAAABUgmxbNWRbAAAA90e2rRqyLdAw0KgAwC3ce++9stlsstls8vX1VceOHfX888/r3LlzVpd2UdUJje5g69ateu655/TGG28oMzNTQ4YMqbNjXX/99XrsscfqbHwAAAB3RLatP2RbAACAukW2rT9kWwCNjbfVBQBAqZtvvlnz5s1TQUGBlixZovHjx8vHx0eTJ0+u9lhFRUWy2Wyy2+nHutDOnTslSbfffrtsNpvF1QAAADRMZNv6QbYFAACoe2Tb+kG2BdDY8DcBALfh5+en8PBwtWvXTr/61a+UkJCgzz77TJJUUFCgJ598Um3atFFgYKDi4uK0atUq577z589X8+bN9dlnn+mKK66Qn5+f9u3bp4KCAj311FOKjo6Wn5+fOnbsqLffftu537fffqshQ4aoadOmCgsL06hRo3T06FHn89dff70eeeQR/e53v1PLli0VHh6uZ5991vl8TEyMJGnYsGGy2WzOn3fu3Knbb79dYWFhatq0qfr06aMVK1a4nG9mZqZuvfVWBQQEqH379lqwYEGZKatycnL0wAMPKCQkREFBQbrxxhv19ddfV3odv/nmG914440KCAhQq1atNG7cOJ08eVJS8dRhSUlJkiS73V5p4F2yZIk6deqkgIAA3XDDDdqzZ4/L8z/++KPuvvtutWnTRk2aNFG3bt30/vvvO5+/9957tXr1ar322mvOrus9e/aoqKhI999/v9q3b6+AgAB17txZr732WqXnVPrne75PPvnEpf6vv/5aN9xwg5o1a6agoCDFxsZqw4YNzufXrFmja6+9VgEBAYqOjtYjjzyi/Px85/OHDx9WUlKS88/jvffeq7QmAACAypBtybYVIdsCAABPQ7Yl21aEbAugJmhUAOC2AgICVFhYKEmaMGGCUlNT9cEHH2jLli0aPny4br75ZmVkZDhff+rUKf3hD3/Q//3f/+m7775TaGioRo8erffff19/+tOftHXrVr3xxhtq2rSppOIweeONN6pXr17asGGDli5dquzsbN11110udfztb39TYGCg1q5dq5deeknPP/+8li9fLklav369JGnevHnKzMx0/nzy5EndcsstSklJ0aZNm3TzzTcrKSlJ+/btc447evRoHTp0SKtWrdK//vUvvfnmmzp8+LDLsYcPH67Dhw/rv//9r9LT03X11Vdr0KBBOnbsWLnXLD8/X4mJiWrRooXWr1+vjz76SCtWrNCECRMkSU8++aTmzZsnqThwZ2ZmljvO/v37dccddygpKUmbN2/WAw88oEmTJrm85syZM4qNjdXixYv17bffaty4cRo1apTWrVsnSXrttdcUHx+vBx980Hms6OhoORwORUVF6aOPPtL333+vadOm6emnn9aHH35Ybi1Vdc899ygqKkrr169Xenq6Jk2aJB8fH0nF/wFy8803684779SWLVu0cOFCrVmzxnldpOKAvn//fq1cuVL//Oc/9frrr5f58wAAALhUZFuybXWQbQEAgDsj25Jtq4NsC6BCBgDcwJgxY8ztt99ujDHG4XCY5cuXGz8/P/Pkk0+avXv3Gi8vL3Pw4EGXfQYNGmQmT55sjDFm3rx5RpLZvHmz8/lt27YZSWb58uXlHvOFF14wgwcPdtm2f/9+I8ls27bNGGPMwIEDzTXXXOPymj59+pinnnrK+bMk8/HHH1/0HK+88krz5z//2RhjzNatW40ks379eufzGRkZRpJ59dVXjTHG/O9//zNBQUHmzJkzLuN06NDBvPHGG+Ue48033zQtWrQwJ0+edG5bvHixsdvtJisryxhjzMcff2wudvufPHmyueKKK1y2PfXUU0aSOX78eIX73XrrreaJJ55w/jxw4EDz6KOPVnosY4wZP368ufPOOyt8ft68eSY4ONhl24Xn0axZMzN//vxy97///vvNuHHjXLb973//M3a73Zw+fdr5Xlm3bp3z+dI/o9I/DwAAgKoi25JtybYAAKChINuSbcm2AOqKd513QgBAFf3nP/9R06ZNdfbsWTkcDo0cOVLPPvusVq1apaKiInXq1Mnl9QUFBWrVqpXzZ19fX3Xv3t358+bNm+Xl5aWBAweWe7yvv/5aK1eudHbqnm/nzp3O450/piRFRERctGPz5MmTevbZZ7V48WJlZmbq3LlzOn36tLMzd9u2bfL29tbVV1/t3Kdjx45q0aKFS30nT550OUdJOn36tHO9sgtt3bpVPXr0UGBgoHPbgAED5HA4tG3bNoWFhVVa9/njxMXFuWyLj493+bmoqEgzZszQhx9+qIMHD6qwsFAFBQVq0qTJRcefM2eO3nnnHe3bt0+nT59WYWGhevbsWaXaKjJx4kQ98MAD+sc//qGEhAQNHz5cHTp0kFR8Lbds2eIyLZgxRg6HQ7t379b27dvl7e2t2NhY5/NdunQpM20ZAABAVZFtybY1QbYFAADuhGxLtq0Jsi2AitCoAMBt3HDDDfrrX/8qX19fRUZGytu7+BZ18uRJeXl5KT09XV5eXi77nB9WAwICXNa+CggIqPR4J0+eVFJSkv7whz+UeS4iIsL5fek0VKVsNpscDkelYz/55JNavny5XnnlFXXs2FEBAQH6+c9/7pwSrSpOnjypiIgIlzXdSrlDEHv55Zf12muvafbs2erWrZsCAwP12GOPXfQcP/jgAz355JP64x//qPj4eDVr1kwvv/yy1q5dW+E+drtdxhiXbWfPnnX5+dlnn9XIkSO1ePFi/fe//9X06dP1wQcfaNiwYTp58qQeeughPfLII2XGbtu2rbZv316NMwcAALg4sm3Z+si2xci2AADA05Bty9ZHti1GtgVQEzQqAHAbgYGB6tixY5ntvXr1UlFRkQ4fPqxrr722yuN169ZNDodDq1evVkJCQpnnr776av3rX/9STEyMM1xfCh8fHxUVFbls+/LLL3Xvvfdq2LBhkorD6549e5zPd+7cWefOndOmTZuc3aA7duzQ8ePHXerLysqSt7e3YmJiqlRL165dNX/+fOXn5zu7c7/88kvZ7XZ17ty5yufUtWtXffbZZy7b0tLSypzj7bffrl/+8peSJIfDoe3bt+uKK65wvsbX17fca9O/f3/9+te/dm6rqNO4VEhIiE6cOOFyXps3by7zuk6dOqlTp056/PHHdffdd2vevHkaNmyYrr76an3//fflvr+k4i7cc+fOKT09XX369JFU3D2dk5NTaV0AAAAVIduSbStCtgUAAJ6GbEu2rQjZFkBN2K0uAAAuplOnTrrnnns0evRoLVq0SLt379a6des0c+ZMLV68uML9YmJiNGbMGN1333365JNPtHv3bq1atUoffvihJGn8+PE6duyY7r77bq1fv147d+5UcnKyxo4dWyakVSYmJkYpKSnKyspyBtbLL79cixYt0ubNm/X1119r5MiRLt28Xbp0UUJCgsaNG6d169Zp06ZNGjdunEt3cUJCguLj4zV06FAtW7ZMe/bs0VdffaVnnnlGGzZsKLeWe+65R/7+/hozZoy+/fZbrVy5Ur/5zW80atSoKk8fJkkPP/ywMjIy9Nvf/lbbtm3TggULNH/+fJfXXH755Vq+fLm++uorbd26VQ899JCys7PLXJu1a9dqz549Onr0qBwOhy6//HJt2LBBycnJ2r59u6ZOnar169dXWk9cXJyaNGmip59+Wjt37ixTz+nTpzVhwgStWrVKe/fu1Zdffqn169era9eukqSnnnpKX331lSZMmKDNmzcrIyNDn376qSZMmCCp+D9Abr75Zj300ENau3at0tPT9cADD1y0uxsAAKC6yLZkW7ItAABoKMi2ZFuyLYCaoFEBgEeYN2+eRo8erSeeeEKdO3fW0KFDtX79erVt27bS/f7617/q5z//uX7961+rS5cuevDBB5Wfny9JioyM1JdffqmioiINHjxY3bp102OPPabmzZvLbq/67fGPf/yjli9frujoaPXq1UuSNGvWLLVo0UL9+/dXUlKSEhMTXdY1k6S///3vCgsL03XXXadhw4bpwQcfVLNmzeTv7y+peKqyJUuW6LrrrtPYsWPVqVMn/eIXv9DevXsrDK9NmjRRcnKyjh07pj59+ujnP/+5Bg0apL/85S9VPh+peFqtf/3rX/rkk0/Uo0cPzZ07VzNmzHB5zZQpU3T11VcrMTFR119/vcLDwzV06FCX1zz55JPy8vLSFVdcoZCQEO3bt08PPfSQ7rjjDo0YMUJxcXH68ccfXbp0y9OyZUu9++67WrJkibp166b3339fzz77rPN5Ly8v/fjjjxo9erQ6deqku+66S0OGDNFzzz0nqXi9utWrV2v79u269tpr1atXL02bNk2RkZHOMebNm6fIyEgNHDhQd9xxh8aNG6fQ0NBqXTcAAICqINuSbcm2AACgoSDbkm3JtgAulc1cuHgMAMASBw4cUHR0tFasWKFBgwZZXQ4AAABwyci2AAAAaCjItgBQN2hUAACLfP755zp58qS6deumzMxM/e53v9PBgwe1fft2+fj4WF0eAAAAUGVkWwAAADQUZFsAqB/eVhcAAI3V2bNn9fTTT2vXrl1q1qyZ+vfvr/fee4+wCwAAAI9DtgUAAEBDQbYFgPrBjAoAAAAAAAAAAAAAAKDe2K0uAAAAAAAAAAAAAAAANB40KgAAAAAAAAAAAAAAgHpDowIAAAAAAAAAAAAAAKg3NCoAAAAAAAAAAAAAAIB6Q6MCAAAAAAAAAAAAAACoNzQqAAAAAAAAAAAAAACAekOjAgAAAAAAAAAAAAAAqDc0KgAAAAAAAAAAAAAAgHpDowIAAAAAAAAAAAAAAKg3/x9EQItAfz/ooQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[0], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95148a9c",
   "metadata": {
    "papermill": {
     "duration": 0.150893,
     "end_time": "2025-03-25T15:22:37.312535",
     "exception": false,
     "start_time": "2025-03-25T15:22:37.161642",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a19a119",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T15:22:37.615400Z",
     "iopub.status.busy": "2025-03-25T15:22:37.615077Z",
     "iopub.status.idle": "2025-03-25T16:11:12.861460Z",
     "shell.execute_reply": "2025-03-25T16:11:12.860379Z"
    },
    "papermill": {
     "duration": 2915.399987,
     "end_time": "2025-03-25T16:11:12.863208",
     "exception": false,
     "start_time": "2025-03-25T15:22:37.463221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 2\n",
      "Random seed: 81\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.647, Accuracy: 0.7054, F1 Micro: 0.8127, F1 Macro: 0.7262\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5731, Accuracy: 0.7374, F1 Micro: 0.8408, F1 Macro: 0.7949\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5493, Accuracy: 0.7917, F1 Micro: 0.8824, F1 Macro: 0.8802\n",
      "Epoch 4/10, Train Loss: 0.5049, Accuracy: 0.7894, F1 Micro: 0.8822, F1 Macro: 0.8807\n",
      "Epoch 5/10, Train Loss: 0.4781, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 6/10, Train Loss: 0.4364, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4061, Accuracy: 0.7902, F1 Micro: 0.8826, F1 Macro: 0.8811\n",
      "Epoch 8/10, Train Loss: 0.4421, Accuracy: 0.7902, F1 Micro: 0.8825, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.4208, Accuracy: 0.7939, F1 Micro: 0.8842, F1 Macro: 0.8826\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3864, Accuracy: 0.8036, F1 Micro: 0.8886, F1 Macro: 0.8869\n",
      "\n",
      "Aspect detection accuracy: 0.8036, F1 Micro: 0.8886, F1 Macro: 0.8869\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.79      1.00      0.88       175\n",
      "      others       0.78      0.95      0.86       158\n",
      "        part       0.71      1.00      0.83       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.80      0.99      0.89      1061\n",
      "   macro avg       0.80      0.99      0.89      1061\n",
      "weighted avg       0.81      0.99      0.89      1061\n",
      " samples avg       0.81      0.99      0.89      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6351, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5577, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5004, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4905, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4593, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4341, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4188, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2323, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2613, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2353, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "\n",
      "Sentiment analysis accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         3\n",
      "    positive       0.91      1.00      0.95        31\n",
      "\n",
      "    accuracy                           0.91        34\n",
      "   macro avg       0.46      0.50      0.48        34\n",
      "weighted avg       0.83      0.91      0.87        34\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.8009, F1 Micro: 0.8009, F1 Macro: 0.3313\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.78      1.00      0.88       167\n",
      "    positive       1.00      0.06      0.11        33\n",
      "\n",
      "    accuracy                           0.78       216\n",
      "   macro avg       0.59      0.35      0.33       216\n",
      "weighted avg       0.76      0.78      0.70       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.78      0.95      0.85       152\n",
      "    positive       0.65      0.38      0.48        52\n",
      "\n",
      "    accuracy                           0.76       216\n",
      "   macro avg       0.47      0.44      0.45       216\n",
      "weighted avg       0.70      0.76      0.72       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        23\n",
      "     neutral       0.71      1.00      0.83       152\n",
      "    positive       1.00      0.02      0.05        41\n",
      "\n",
      "    accuracy                           0.71       216\n",
      "   macro avg       0.57      0.34      0.29       216\n",
      "weighted avg       0.69      0.71      0.59       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 61.391650438308716 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 81\n",
      "Sampling duration: 17.139429092407227 seconds\n",
      "New train size: 135\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6019, Accuracy: 0.7939, F1 Micro: 0.8843, F1 Macro: 0.8828\n",
      "Epoch 2/10, Train Loss: 0.5087, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 3/10, Train Loss: 0.4912, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 4/10, Train Loss: 0.4678, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4064, Accuracy: 0.8013, F1 Micro: 0.8882, F1 Macro: 0.8868\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3727, Accuracy: 0.8408, F1 Micro: 0.9079, F1 Macro: 0.907\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3457, Accuracy: 0.8735, F1 Micro: 0.9244, F1 Macro: 0.9227\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2998, Accuracy: 0.8862, F1 Micro: 0.9306, F1 Macro: 0.9286\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2753, Accuracy: 0.907, F1 Micro: 0.9432, F1 Macro: 0.9413\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2221, Accuracy: 0.9137, F1 Micro: 0.9469, F1 Macro: 0.945\n",
      "\n",
      "Aspect detection accuracy: 0.9137, F1 Micro: 0.9469, F1 Macro: 0.945\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.94      1.00      0.97       187\n",
      "     machine       0.94      0.98      0.96       175\n",
      "      others       0.84      0.95      0.89       158\n",
      "        part       0.93      0.91      0.92       158\n",
      "       price       0.91      0.99      0.95       192\n",
      "     service       0.95      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.92      0.97      0.95      1061\n",
      "   macro avg       0.92      0.97      0.94      1061\n",
      "weighted avg       0.92      0.97      0.95      1061\n",
      " samples avg       0.92      0.97      0.94      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6965, Accuracy: 0.6901, F1 Micro: 0.6901, F1 Macro: 0.4225\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5869, Accuracy: 0.6901, F1 Micro: 0.6901, F1 Macro: 0.4225\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5192, Accuracy: 0.8122, F1 Micro: 0.8122, F1 Macro: 0.7577\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3838, Accuracy: 0.8404, F1 Micro: 0.8404, F1 Macro: 0.8251\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.26, Accuracy: 0.8592, F1 Micro: 0.8592, F1 Macro: 0.8437\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2092, Accuracy: 0.8826, F1 Micro: 0.8826, F1 Macro: 0.8645\n",
      "Epoch 7/10, Train Loss: 0.1656, Accuracy: 0.8498, F1 Micro: 0.8498, F1 Macro: 0.8363\n",
      "Epoch 8/10, Train Loss: 0.1089, Accuracy: 0.8732, F1 Micro: 0.8732, F1 Macro: 0.8579\n",
      "Epoch 9/10, Train Loss: 0.1778, Accuracy: 0.8638, F1 Micro: 0.8638, F1 Macro: 0.8494\n",
      "Epoch 10/10, Train Loss: 0.0705, Accuracy: 0.8685, F1 Micro: 0.8685, F1 Macro: 0.855\n",
      "\n",
      "Sentiment analysis accuracy: 0.8826, F1 Micro: 0.8826, F1 Macro: 0.8645\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.82      0.81        67\n",
      "    positive       0.92      0.91      0.91       146\n",
      "\n",
      "    accuracy                           0.88       213\n",
      "   macro avg       0.86      0.87      0.86       213\n",
      "weighted avg       0.88      0.88      0.88       213\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 135: Accuracy: 0.9012, F1 Micro: 0.9012, F1 Macro: 0.7761\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.95      1.00      0.97       181\n",
      "    positive       1.00      0.62      0.77        24\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.98      0.84      0.90       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.69      0.79        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.79      0.70      0.74        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.88      0.79      0.83       216\n",
      "weighted avg       0.91      0.92      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.46      0.50      0.48        12\n",
      "     neutral       0.85      0.95      0.90       152\n",
      "    positive       0.84      0.52      0.64        52\n",
      "\n",
      "    accuracy                           0.82       216\n",
      "   macro avg       0.72      0.66      0.67       216\n",
      "weighted avg       0.83      0.82      0.81       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.61      0.68        23\n",
      "     neutral       0.93      0.91      0.92       152\n",
      "    positive       0.69      0.80      0.74        41\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.80      0.78      0.78       216\n",
      "weighted avg       0.87      0.86      0.86       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.31      0.44        13\n",
      "     neutral       0.91      0.99      0.95       186\n",
      "    positive       0.67      0.35      0.46        17\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.79      0.55      0.62       216\n",
      "weighted avg       0.88      0.90      0.88       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.71      0.83        14\n",
      "     neutral       0.95      1.00      0.98       185\n",
      "    positive       0.92      0.65      0.76        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.96      0.79      0.86       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Total train time: 66.71389937400818 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 73\n",
      "Sampling duration: 17.797743797302246 seconds\n",
      "New train size: 208\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5969, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5152, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.496, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4594, Accuracy: 0.8088, F1 Micro: 0.8917, F1 Macro: 0.8904\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3922, Accuracy: 0.8653, F1 Micro: 0.9202, F1 Macro: 0.9191\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3328, Accuracy: 0.8884, F1 Micro: 0.9318, F1 Macro: 0.9297\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.281, Accuracy: 0.9122, F1 Micro: 0.9461, F1 Macro: 0.9441\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2356, Accuracy: 0.9256, F1 Micro: 0.954, F1 Macro: 0.9521\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2049, Accuracy: 0.9308, F1 Micro: 0.957, F1 Macro: 0.9551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1609, Accuracy: 0.9368, F1 Micro: 0.9605, F1 Macro: 0.959\n",
      "\n",
      "Aspect detection accuracy: 0.9368, F1 Micro: 0.9605, F1 Macro: 0.959\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.97      1.00      0.99       187\n",
      "     machine       0.94      0.97      0.95       175\n",
      "      others       0.87      0.94      0.90       158\n",
      "        part       0.96      0.96      0.96       158\n",
      "       price       0.98      0.97      0.98       192\n",
      "     service       0.95      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.95      0.97      0.96      1061\n",
      "   macro avg       0.95      0.97      0.96      1061\n",
      "weighted avg       0.95      0.97      0.96      1061\n",
      " samples avg       0.95      0.97      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5866, Accuracy: 0.6831, F1 Micro: 0.6831, F1 Macro: 0.4059\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5052, Accuracy: 0.8272, F1 Micro: 0.8272, F1 Macro: 0.7911\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2931, Accuracy: 0.8765, F1 Micro: 0.8765, F1 Macro: 0.8611\n",
      "Epoch 4/10, Train Loss: 0.1783, Accuracy: 0.8724, F1 Micro: 0.8724, F1 Macro: 0.8629\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1554, Accuracy: 0.893, F1 Micro: 0.893, F1 Macro: 0.8764\n",
      "Epoch 6/10, Train Loss: 0.1139, Accuracy: 0.8848, F1 Micro: 0.8848, F1 Macro: 0.8753\n",
      "Epoch 7/10, Train Loss: 0.1028, Accuracy: 0.8889, F1 Micro: 0.8889, F1 Macro: 0.8788\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.077, Accuracy: 0.9012, F1 Micro: 0.9012, F1 Macro: 0.8908\n",
      "Epoch 9/10, Train Loss: 0.1269, Accuracy: 0.8971, F1 Micro: 0.8971, F1 Macro: 0.8878\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0972, Accuracy: 0.9053, F1 Micro: 0.9053, F1 Macro: 0.8945\n",
      "\n",
      "Sentiment analysis accuracy: 0.9053, F1 Micro: 0.9053, F1 Macro: 0.8945\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.92      0.86        77\n",
      "    positive       0.96      0.90      0.93       166\n",
      "\n",
      "    accuracy                           0.91       243\n",
      "   macro avg       0.88      0.91      0.89       243\n",
      "weighted avg       0.91      0.91      0.91       243\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 208: Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.8531\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       1.00      0.83      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.94      0.96      0.95       167\n",
      "    positive       0.76      0.67      0.71        33\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.85      0.81      0.83       216\n",
      "weighted avg       0.90      0.91      0.90       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.75      0.67        12\n",
      "     neutral       0.87      0.94      0.91       152\n",
      "    positive       0.81      0.58      0.67        52\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.76      0.76      0.75       216\n",
      "weighted avg       0.84      0.84      0.84       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      0.78      0.75        23\n",
      "     neutral       0.95      0.96      0.96       152\n",
      "    positive       0.87      0.80      0.84        41\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.85      0.85      0.85       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.98      0.97      0.98       186\n",
      "    positive       0.75      0.88      0.81        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.88      0.87      0.87       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.95      1.00      0.98       185\n",
      "    positive       1.00      0.65      0.79        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.98      0.81      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Total train time: 79.31771636009216 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 66\n",
      "Sampling duration: 16.238224983215332 seconds\n",
      "New train size: 274\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5829, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5029, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4577, Accuracy: 0.8125, F1 Micro: 0.8938, F1 Macro: 0.8925\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4008, Accuracy: 0.8787, F1 Micro: 0.9278, F1 Macro: 0.9269\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3299, Accuracy: 0.9077, F1 Micro: 0.9434, F1 Macro: 0.9413\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2676, Accuracy: 0.9256, F1 Micro: 0.9542, F1 Macro: 0.9528\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2201, Accuracy: 0.9397, F1 Micro: 0.9627, F1 Macro: 0.9613\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1737, Accuracy: 0.9449, F1 Micro: 0.9658, F1 Macro: 0.9644\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1505, Accuracy: 0.9464, F1 Micro: 0.9666, F1 Macro: 0.9651\n",
      "Epoch 10/10, Train Loss: 0.1323, Accuracy: 0.9464, F1 Micro: 0.9665, F1 Macro: 0.9649\n",
      "\n",
      "Aspect detection accuracy: 0.9464, F1 Micro: 0.9666, F1 Macro: 0.9651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.94      0.99      0.96       175\n",
      "      others       0.88      0.93      0.90       158\n",
      "        part       0.95      0.99      0.97       158\n",
      "       price       0.97      0.98      0.98       192\n",
      "     service       0.97      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.95      0.98      0.97      1061\n",
      "   macro avg       0.95      0.98      0.97      1061\n",
      "weighted avg       0.95      0.98      0.97      1061\n",
      " samples avg       0.95      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6264, Accuracy: 0.6681, F1 Micro: 0.6681, F1 Macro: 0.4005\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5044, Accuracy: 0.8613, F1 Micro: 0.8613, F1 Macro: 0.8494\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2748, Accuracy: 0.9076, F1 Micro: 0.9076, F1 Macro: 0.9004\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1622, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9296\n",
      "Epoch 5/10, Train Loss: 0.133, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9256\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0887, Accuracy: 0.9496, F1 Micro: 0.9496, F1 Macro: 0.9448\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0934, Accuracy: 0.9496, F1 Micro: 0.9496, F1 Macro: 0.9435\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0653, Accuracy: 0.9538, F1 Micro: 0.9538, F1 Macro: 0.949\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.099, Accuracy: 0.9538, F1 Micro: 0.9538, F1 Macro: 0.9481\n",
      "Epoch 10/10, Train Loss: 0.0371, Accuracy: 0.9454, F1 Micro: 0.9454, F1 Macro: 0.94\n",
      "\n",
      "Sentiment analysis accuracy: 0.9538, F1 Micro: 0.9538, F1 Macro: 0.9481\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.93        79\n",
      "    positive       0.97      0.96      0.97       159\n",
      "\n",
      "    accuracy                           0.95       238\n",
      "   macro avg       0.95      0.95      0.95       238\n",
      "weighted avg       0.95      0.95      0.95       238\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 274: Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.8906\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.94      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.93      0.99      0.96       167\n",
      "    positive       0.85      0.67      0.75        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.90      0.80      0.84       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.88      0.93      0.91       152\n",
      "    positive       0.79      0.65      0.72        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.84      0.81      0.82       216\n",
      "weighted avg       0.86      0.86      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87        23\n",
      "     neutral       0.95      0.99      0.97       152\n",
      "    positive       0.91      0.78      0.84        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.88      0.89       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.97      0.98      0.98       186\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.86      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.97      1.00      0.99       185\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.99      0.89      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 89.2984139919281 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 59\n",
      "Sampling duration: 15.23207950592041 seconds\n",
      "New train size: 333\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5751, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.491, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4383, Accuracy: 0.8348, F1 Micro: 0.9051, F1 Macro: 0.9043\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3501, Accuracy: 0.9085, F1 Micro: 0.9444, F1 Macro: 0.9432\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2697, Accuracy: 0.9286, F1 Micro: 0.9563, F1 Macro: 0.9548\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2178, Accuracy: 0.9427, F1 Micro: 0.9644, F1 Macro: 0.9629\n",
      "Epoch 7/10, Train Loss: 0.169, Accuracy: 0.942, F1 Micro: 0.9637, F1 Macro: 0.9623\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.138, Accuracy: 0.9531, F1 Micro: 0.9707, F1 Macro: 0.9694\n",
      "Epoch 9/10, Train Loss: 0.1125, Accuracy: 0.9531, F1 Micro: 0.9707, F1 Macro: 0.9692\n",
      "Epoch 10/10, Train Loss: 0.095, Accuracy: 0.9531, F1 Micro: 0.9706, F1 Macro: 0.9689\n",
      "\n",
      "Aspect detection accuracy: 0.9531, F1 Micro: 0.9707, F1 Macro: 0.9694\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.94      0.99      0.96       175\n",
      "      others       0.90      0.93      0.92       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.97      0.98      0.98       192\n",
      "     service       0.97      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.581, Accuracy: 0.6816, F1 Micro: 0.6816, F1 Macro: 0.4288\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4285, Accuracy: 0.8816, F1 Micro: 0.8816, F1 Macro: 0.869\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.234, Accuracy: 0.9184, F1 Micro: 0.9184, F1 Macro: 0.9118\n",
      "Epoch 4/10, Train Loss: 0.1804, Accuracy: 0.8653, F1 Micro: 0.8653, F1 Macro: 0.8584\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1576, Accuracy: 0.9388, F1 Micro: 0.9388, F1 Macro: 0.9306\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.106, Accuracy: 0.9469, F1 Micro: 0.9469, F1 Macro: 0.9402\n",
      "Epoch 7/10, Train Loss: 0.1503, Accuracy: 0.8857, F1 Micro: 0.8857, F1 Macro: 0.8787\n",
      "Epoch 8/10, Train Loss: 0.096, Accuracy: 0.9388, F1 Micro: 0.9388, F1 Macro: 0.9326\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0928, Accuracy: 0.9551, F1 Micro: 0.9551, F1 Macro: 0.95\n",
      "Epoch 10/10, Train Loss: 0.0577, Accuracy: 0.8939, F1 Micro: 0.8939, F1 Macro: 0.8869\n",
      "\n",
      "Sentiment analysis accuracy: 0.9551, F1 Micro: 0.9551, F1 Macro: 0.95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.93        80\n",
      "    positive       0.99      0.95      0.97       165\n",
      "\n",
      "    accuracy                           0.96       245\n",
      "   macro avg       0.94      0.96      0.95       245\n",
      "weighted avg       0.96      0.96      0.96       245\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 333: Accuracy: 0.9483, F1 Micro: 0.9483, F1 Macro: 0.9015\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.88      0.93        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.96      0.70      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.90      0.93      0.92       152\n",
      "    positive       0.81      0.75      0.78        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.85      0.81      0.83       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.91      0.89        23\n",
      "     neutral       0.96      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.94      0.91      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.97      0.98      0.98       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.90      0.86      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.97      1.00      0.99       185\n",
      "    positive       1.00      0.76      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.99      0.90      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 85.41610312461853 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 54\n",
      "Sampling duration: 13.991450071334839 seconds\n",
      "New train size: 387\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5509, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4727, Accuracy: 0.7991, F1 Micro: 0.8871, F1 Macro: 0.8857\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3843, Accuracy: 0.8876, F1 Micro: 0.9324, F1 Macro: 0.9308\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.294, Accuracy: 0.9271, F1 Micro: 0.9552, F1 Macro: 0.9533\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2287, Accuracy: 0.9427, F1 Micro: 0.9644, F1 Macro: 0.9627\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1722, Accuracy: 0.9464, F1 Micro: 0.9665, F1 Macro: 0.9643\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1346, Accuracy: 0.9554, F1 Micro: 0.9721, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1101, Accuracy: 0.9561, F1 Micro: 0.9724, F1 Macro: 0.9713\n",
      "Epoch 9/10, Train Loss: 0.0912, Accuracy: 0.9546, F1 Micro: 0.9716, F1 Macro: 0.9707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0763, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.972\n",
      "\n",
      "Aspect detection accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.972\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.92      0.92      0.92       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.97      0.98      0.98       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.557, Accuracy: 0.6897, F1 Micro: 0.6897, F1 Macro: 0.4309\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2971, Accuracy: 0.9004, F1 Micro: 0.9004, F1 Macro: 0.8919\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1968, Accuracy: 0.9502, F1 Micro: 0.9502, F1 Macro: 0.9431\n",
      "Epoch 4/10, Train Loss: 0.1723, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9265\n",
      "Epoch 5/10, Train Loss: 0.1346, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.8998\n",
      "Epoch 6/10, Train Loss: 0.1087, Accuracy: 0.9425, F1 Micro: 0.9425, F1 Macro: 0.9344\n",
      "Epoch 7/10, Train Loss: 0.0939, Accuracy: 0.9272, F1 Micro: 0.9272, F1 Macro: 0.9201\n",
      "Epoch 8/10, Train Loss: 0.1249, Accuracy: 0.8927, F1 Micro: 0.8927, F1 Macro: 0.8847\n",
      "Epoch 9/10, Train Loss: 0.0706, Accuracy: 0.931, F1 Micro: 0.931, F1 Macro: 0.922\n",
      "Epoch 10/10, Train Loss: 0.0528, Accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.9081\n",
      "\n",
      "Sentiment analysis accuracy: 0.9502, F1 Micro: 0.9502, F1 Macro: 0.9431\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.94      0.92        83\n",
      "    positive       0.97      0.96      0.96       178\n",
      "\n",
      "    accuracy                           0.95       261\n",
      "   macro avg       0.94      0.95      0.94       261\n",
      "weighted avg       0.95      0.95      0.95       261\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 387: Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.9101\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.92      0.92      0.92       152\n",
      "    positive       0.80      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.83      0.85      0.84       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.90      0.88      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.91      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.97      0.98      0.98       186\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.90      0.86      0.87       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 91.77834010124207 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 48\n",
      "Sampling duration: 12.897379636764526 seconds\n",
      "New train size: 435\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5508, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4743, Accuracy: 0.8088, F1 Micro: 0.892, F1 Macro: 0.8906\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3719, Accuracy: 0.9077, F1 Micro: 0.9438, F1 Macro: 0.9421\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.288, Accuracy: 0.9338, F1 Micro: 0.9592, F1 Macro: 0.9577\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2154, Accuracy: 0.9516, F1 Micro: 0.97, F1 Macro: 0.969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.17, Accuracy: 0.9531, F1 Micro: 0.9707, F1 Macro: 0.9695\n",
      "Epoch 7/10, Train Loss: 0.1285, Accuracy: 0.9509, F1 Micro: 0.9692, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1043, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0842, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0737, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9741\n",
      "\n",
      "Aspect detection accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9741\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.91      0.93      0.92       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.97      0.98      0.98       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5163, Accuracy: 0.7004, F1 Micro: 0.7004, F1 Macro: 0.4768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3216, Accuracy: 0.9183, F1 Micro: 0.9183, F1 Macro: 0.9105\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2055, Accuracy: 0.9222, F1 Micro: 0.9222, F1 Macro: 0.9126\n",
      "Epoch 4/10, Train Loss: 0.1576, Accuracy: 0.8599, F1 Micro: 0.8599, F1 Macro: 0.8527\n",
      "Epoch 5/10, Train Loss: 0.0983, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.9069\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.146, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9147\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0704, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9231\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0953, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9255\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0735, Accuracy: 0.9416, F1 Micro: 0.9416, F1 Macro: 0.9347\n",
      "Epoch 10/10, Train Loss: 0.0514, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9268\n",
      "\n",
      "Sentiment analysis accuracy: 0.9416, F1 Micro: 0.9416, F1 Macro: 0.9347\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.95      0.91        83\n",
      "    positive       0.98      0.94      0.96       174\n",
      "\n",
      "    accuracy                           0.94       257\n",
      "   macro avg       0.93      0.94      0.93       257\n",
      "weighted avg       0.94      0.94      0.94       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 435: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9074\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.83      0.71        12\n",
      "     neutral       0.92      0.93      0.93       152\n",
      "    positive       0.82      0.71      0.76        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.79      0.83      0.80       216\n",
      "weighted avg       0.88      0.88      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.98      0.99      0.99       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.97      0.98      0.98       186\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.90      0.86      0.87       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.96      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 103.38444638252258 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 43\n",
      "Sampling duration: 12.08749794960022 seconds\n",
      "New train size: 478\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5427, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4614, Accuracy: 0.811, F1 Micro: 0.8931, F1 Macro: 0.8919\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3556, Accuracy: 0.9219, F1 Micro: 0.9519, F1 Macro: 0.9501\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2728, Accuracy: 0.9435, F1 Micro: 0.965, F1 Macro: 0.9641\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2028, Accuracy: 0.9531, F1 Micro: 0.9708, F1 Macro: 0.9695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1623, Accuracy: 0.9546, F1 Micro: 0.9716, F1 Macro: 0.9703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1287, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9733\n",
      "Epoch 8/10, Train Loss: 0.1015, Accuracy: 0.9561, F1 Micro: 0.9725, F1 Macro: 0.9709\n",
      "Epoch 9/10, Train Loss: 0.0792, Accuracy: 0.9516, F1 Micro: 0.9695, F1 Macro: 0.9666\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0709, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9734\n",
      "\n",
      "Aspect detection accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9734\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.91      0.93      0.92       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.98      0.98      0.98       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5895, Accuracy: 0.686, F1 Micro: 0.686, F1 Macro: 0.4185\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3294, Accuracy: 0.9031, F1 Micro: 0.9031, F1 Macro: 0.8947\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1879, Accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.9142\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1559, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.922\n",
      "Epoch 5/10, Train Loss: 0.1195, Accuracy: 0.9147, F1 Micro: 0.9147, F1 Macro: 0.9071\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.091, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9269\n",
      "Epoch 7/10, Train Loss: 0.0712, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.9173\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1056, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9298\n",
      "Epoch 9/10, Train Loss: 0.0788, Accuracy: 0.9186, F1 Micro: 0.9186, F1 Macro: 0.9102\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0627, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.934\n",
      "\n",
      "Sentiment analysis accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.934\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.94      0.91        82\n",
      "    positive       0.97      0.94      0.96       176\n",
      "\n",
      "    accuracy                           0.94       258\n",
      "   macro avg       0.93      0.94      0.93       258\n",
      "weighted avg       0.94      0.94      0.94       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 478: Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.9064\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.84      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.92      0.93      0.93       152\n",
      "    positive       0.80      0.75      0.77        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.82      0.81      0.82       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.98      0.98      0.98       186\n",
      "    positive       0.80      0.94      0.86        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.90      0.90      0.89       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.96      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 101.19026517868042 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 39\n",
      "Sampling duration: 10.769817113876343 seconds\n",
      "New train size: 517\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5452, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4553, Accuracy: 0.8534, F1 Micro: 0.9147, F1 Macro: 0.9138\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.325, Accuracy: 0.9226, F1 Micro: 0.9524, F1 Macro: 0.9503\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2355, Accuracy: 0.9472, F1 Micro: 0.9671, F1 Macro: 0.9653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1801, Accuracy: 0.9509, F1 Micro: 0.9695, F1 Macro: 0.9684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.132, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0967, Accuracy: 0.9583, F1 Micro: 0.9737, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0775, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9727\n",
      "Epoch 9/10, Train Loss: 0.0681, Accuracy: 0.9568, F1 Micro: 0.9728, F1 Macro: 0.9715\n",
      "Epoch 10/10, Train Loss: 0.0595, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9723\n",
      "\n",
      "Aspect detection accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9727\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.93      0.91      0.92       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.98      0.98       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5568, Accuracy: 0.683, F1 Micro: 0.683, F1 Macro: 0.4058\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.349, Accuracy: 0.9358, F1 Micro: 0.9358, F1 Macro: 0.9266\n",
      "Epoch 3/10, Train Loss: 0.1856, Accuracy: 0.8981, F1 Micro: 0.8981, F1 Macro: 0.889\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1643, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9303\n",
      "Epoch 5/10, Train Loss: 0.139, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.9207\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1096, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9298\n",
      "Epoch 7/10, Train Loss: 0.1253, Accuracy: 0.9245, F1 Micro: 0.9245, F1 Macro: 0.9168\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0737, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9319\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0846, Accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.9367\n",
      "Epoch 10/10, Train Loss: 0.0728, Accuracy: 0.9208, F1 Micro: 0.9208, F1 Macro: 0.9128\n",
      "\n",
      "Sentiment analysis accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.9367\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.98      0.92        84\n",
      "    positive       0.99      0.93      0.96       181\n",
      "\n",
      "    accuracy                           0.94       265\n",
      "   macro avg       0.93      0.95      0.94       265\n",
      "weighted avg       0.95      0.94      0.94       265\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 517: Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.9092\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.86      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.94      0.91      0.92       152\n",
      "    positive       0.76      0.81      0.79        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.81      0.85      0.83       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.93      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.98      0.98       186\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.89      0.88      0.89       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 105.53500843048096 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 23\n",
      "Sampling duration: 9.842418909072876 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5426, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4544, Accuracy: 0.8571, F1 Micro: 0.9167, F1 Macro: 0.9159\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3336, Accuracy: 0.9211, F1 Micro: 0.9515, F1 Macro: 0.9502\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2395, Accuracy: 0.9479, F1 Micro: 0.9676, F1 Macro: 0.9659\n",
      "Epoch 5/10, Train Loss: 0.1781, Accuracy: 0.9472, F1 Micro: 0.9668, F1 Macro: 0.9643\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1366, Accuracy: 0.9539, F1 Micro: 0.9711, F1 Macro: 0.9701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.105, Accuracy: 0.9568, F1 Micro: 0.9728, F1 Macro: 0.9714\n",
      "Epoch 8/10, Train Loss: 0.088, Accuracy: 0.9539, F1 Micro: 0.9709, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0689, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0621, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9749\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.89      0.97      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.97      0.98       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5574, Accuracy: 0.6824, F1 Micro: 0.6824, F1 Macro: 0.4387\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3232, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9348\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1864, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9399\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1792, Accuracy: 0.9569, F1 Micro: 0.9569, F1 Macro: 0.9516\n",
      "Epoch 5/10, Train Loss: 0.1429, Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9479\n",
      "Epoch 6/10, Train Loss: 0.1184, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9228\n",
      "Epoch 7/10, Train Loss: 0.0857, Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9479\n",
      "Epoch 8/10, Train Loss: 0.0826, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9393\n",
      "Epoch 9/10, Train Loss: 0.0694, Accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.9113\n",
      "Epoch 10/10, Train Loss: 0.0433, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9389\n",
      "\n",
      "Sentiment analysis accuracy: 0.9569, F1 Micro: 0.9569, F1 Macro: 0.9516\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.95      0.94        84\n",
      "    positive       0.98      0.96      0.97       171\n",
      "\n",
      "    accuracy                           0.96       255\n",
      "   macro avg       0.95      0.96      0.95       255\n",
      "weighted avg       0.96      0.96      0.96       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9175\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.87      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.90      0.97      0.93       152\n",
      "    positive       0.88      0.71      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.89      0.81      0.85       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.95      0.88      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.99      0.97      0.98       186\n",
      "    positive       0.71      0.88      0.79        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.87      0.90      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.96      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 103.36098575592041 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 33\n",
      "Sampling duration: 9.099307775497437 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5387, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4443, Accuracy: 0.8683, F1 Micro: 0.9223, F1 Macro: 0.9213\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3231, Accuracy: 0.9323, F1 Micro: 0.958, F1 Macro: 0.9565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2248, Accuracy: 0.9516, F1 Micro: 0.9701, F1 Macro: 0.9692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1756, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9724\n",
      "Epoch 6/10, Train Loss: 0.1276, Accuracy: 0.9561, F1 Micro: 0.9724, F1 Macro: 0.9711\n",
      "Epoch 7/10, Train Loss: 0.0998, Accuracy: 0.9546, F1 Micro: 0.9715, F1 Macro: 0.9697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0816, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9746\n",
      "Epoch 9/10, Train Loss: 0.0707, Accuracy: 0.9554, F1 Micro: 0.9718, F1 Macro: 0.9702\n",
      "Epoch 10/10, Train Loss: 0.0621, Accuracy: 0.9568, F1 Micro: 0.9728, F1 Macro: 0.9714\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9746\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.97      0.97       175\n",
      "      others       0.92      0.94      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      0.98      0.98       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5462, Accuracy: 0.8721, F1 Micro: 0.8721, F1 Macro: 0.8539\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2623, Accuracy: 0.8915, F1 Micro: 0.8915, F1 Macro: 0.8834\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1838, Accuracy: 0.907, F1 Micro: 0.907, F1 Macro: 0.8996\n",
      "Epoch 4/10, Train Loss: 0.1823, Accuracy: 0.8915, F1 Micro: 0.8915, F1 Macro: 0.8844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1262, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9277\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1183, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.928\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0904, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.928\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0881, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9273\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0682, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9273\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0742, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9277\n",
      "\n",
      "Sentiment analysis accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9277\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.98      0.91        84\n",
      "    positive       0.99      0.91      0.95       174\n",
      "\n",
      "    accuracy                           0.93       258\n",
      "   macro avg       0.92      0.94      0.93       258\n",
      "weighted avg       0.94      0.93      0.94       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9056\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.94      0.91        16\n",
      "     neutral       0.96      0.97      0.96       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.90      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.85      0.75      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.83      0.84      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.96      0.86        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.91      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.98      0.98       186\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.88      0.86      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 111.6228244304657 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 30\n",
      "Sampling duration: 8.450629472732544 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.542, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4391, Accuracy: 0.8891, F1 Micro: 0.934, F1 Macro: 0.9328\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3131, Accuracy: 0.939, F1 Micro: 0.9622, F1 Macro: 0.9608\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2195, Accuracy: 0.9546, F1 Micro: 0.9716, F1 Macro: 0.9701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1662, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.976\n",
      "Epoch 6/10, Train Loss: 0.1281, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9726\n",
      "Epoch 7/10, Train Loss: 0.0951, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9744\n",
      "Epoch 8/10, Train Loss: 0.079, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.975\n",
      "Epoch 9/10, Train Loss: 0.0673, Accuracy: 0.9561, F1 Micro: 0.9722, F1 Macro: 0.97\n",
      "Epoch 10/10, Train Loss: 0.0594, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9753\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.92      0.95      0.93       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.98      0.98      0.98       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5408, Accuracy: 0.8532, F1 Micro: 0.8532, F1 Macro: 0.8434\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2495, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.906\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.166, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9243\n",
      "Epoch 4/10, Train Loss: 0.1531, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9226\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1347, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9353\n",
      "Epoch 6/10, Train Loss: 0.1154, Accuracy: 0.9206, F1 Micro: 0.9206, F1 Macro: 0.9144\n",
      "Epoch 7/10, Train Loss: 0.0824, Accuracy: 0.9365, F1 Micro: 0.9365, F1 Macro: 0.9309\n",
      "Epoch 8/10, Train Loss: 0.0525, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9226\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0879, Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9392\n",
      "Epoch 10/10, Train Loss: 0.0653, Accuracy: 0.9365, F1 Micro: 0.9365, F1 Macro: 0.9309\n",
      "\n",
      "Sentiment analysis accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9392\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.98      0.92        84\n",
      "    positive       0.99      0.93      0.96       168\n",
      "\n",
      "    accuracy                           0.94       252\n",
      "   macro avg       0.93      0.95      0.94       252\n",
      "weighted avg       0.95      0.94      0.95       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9099\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.88      0.93        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.85      0.79      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.84      0.83      0.84       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.96      0.99      0.98       152\n",
      "    positive       1.00      0.78      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.94      0.92      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.98      0.98      0.98       186\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.88      0.89      0.89       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 102.13813018798828 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 27\n",
      "Sampling duration: 7.401491403579712 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5417, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4269, Accuracy: 0.8854, F1 Micro: 0.9313, F1 Macro: 0.93\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2989, Accuracy: 0.942, F1 Micro: 0.9643, F1 Macro: 0.9627\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2136, Accuracy: 0.9524, F1 Micro: 0.9704, F1 Macro: 0.9692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1529, Accuracy: 0.9598, F1 Micro: 0.9751, F1 Macro: 0.9743\n",
      "Epoch 6/10, Train Loss: 0.1176, Accuracy: 0.9583, F1 Micro: 0.9737, F1 Macro: 0.9718\n",
      "Epoch 7/10, Train Loss: 0.0907, Accuracy: 0.9583, F1 Micro: 0.9737, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0789, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9739\n",
      "Epoch 9/10, Train Loss: 0.0646, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0537, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9744\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9744\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.91      0.94      0.93       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5431, Accuracy: 0.8764, F1 Micro: 0.8764, F1 Macro: 0.8499\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3086, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.9077\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1862, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9398\n",
      "Epoch 4/10, Train Loss: 0.166, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9239\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1306, Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9436\n",
      "Epoch 6/10, Train Loss: 0.1211, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9356\n",
      "Epoch 7/10, Train Loss: 0.0791, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9401\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0841, Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9433\n",
      "Epoch 9/10, Train Loss: 0.0681, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9304\n",
      "Epoch 10/10, Train Loss: 0.0481, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9312\n",
      "\n",
      "Sentiment analysis accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9433\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.94      0.92        84\n",
      "    positive       0.97      0.95      0.96       175\n",
      "\n",
      "    accuracy                           0.95       259\n",
      "   macro avg       0.94      0.95      0.94       259\n",
      "weighted avg       0.95      0.95      0.95       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9099\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.86      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.92      0.94      0.93       152\n",
      "    positive       0.81      0.75      0.78        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.83      0.81      0.82       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.93      0.91      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.93      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 112.13460564613342 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 18\n",
      "Sampling duration: 6.954620838165283 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5442, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4096, Accuracy: 0.9025, F1 Micro: 0.9406, F1 Macro: 0.9389\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2834, Accuracy: 0.9464, F1 Micro: 0.9669, F1 Macro: 0.9655\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1994, Accuracy: 0.9561, F1 Micro: 0.9726, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1395, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1117, Accuracy: 0.9665, F1 Micro: 0.9791, F1 Macro: 0.9782\n",
      "Epoch 7/10, Train Loss: 0.0888, Accuracy: 0.9591, F1 Micro: 0.9741, F1 Macro: 0.9723\n",
      "Epoch 8/10, Train Loss: 0.0747, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9745\n",
      "Epoch 9/10, Train Loss: 0.0576, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.973\n",
      "Epoch 10/10, Train Loss: 0.0509, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9732\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9791, F1 Macro: 0.9782\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.91      0.97      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5308, Accuracy: 0.8548, F1 Micro: 0.8548, F1 Macro: 0.8209\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2716, Accuracy: 0.9435, F1 Micro: 0.9435, F1 Macro: 0.9384\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1817, Accuracy: 0.9476, F1 Micro: 0.9476, F1 Macro: 0.9417\n",
      "Epoch 4/10, Train Loss: 0.1683, Accuracy: 0.9435, F1 Micro: 0.9435, F1 Macro: 0.9374\n",
      "Epoch 5/10, Train Loss: 0.153, Accuracy: 0.9435, F1 Micro: 0.9435, F1 Macro: 0.9354\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1586, Accuracy: 0.9556, F1 Micro: 0.9556, F1 Macro: 0.9512\n",
      "Epoch 7/10, Train Loss: 0.1139, Accuracy: 0.9476, F1 Micro: 0.9476, F1 Macro: 0.9423\n",
      "Epoch 8/10, Train Loss: 0.0875, Accuracy: 0.9315, F1 Micro: 0.9315, F1 Macro: 0.9261\n",
      "Epoch 9/10, Train Loss: 0.1074, Accuracy: 0.9435, F1 Micro: 0.9435, F1 Macro: 0.9387\n",
      "Epoch 10/10, Train Loss: 0.087, Accuracy: 0.9435, F1 Micro: 0.9435, F1 Macro: 0.9387\n",
      "\n",
      "Sentiment analysis accuracy: 0.9556, F1 Micro: 0.9556, F1 Macro: 0.9512\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        84\n",
      "    positive       0.98      0.95      0.97       164\n",
      "\n",
      "    accuracy                           0.96       248\n",
      "   macro avg       0.95      0.96      0.95       248\n",
      "weighted avg       0.96      0.96      0.96       248\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9225\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.94      0.99      0.97       167\n",
      "    positive       0.92      0.70      0.79        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.86      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.91      0.97      0.94       152\n",
      "    positive       0.91      0.75      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.88      0.82      0.85       216\n",
      "weighted avg       0.91      0.91      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.92      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.91      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.96      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 108.44592642784119 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 6.535298824310303 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5405, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4114, Accuracy: 0.9055, F1 Micro: 0.9427, F1 Macro: 0.9415\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2796, Accuracy: 0.9516, F1 Micro: 0.9699, F1 Macro: 0.969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.197, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9732\n",
      "Epoch 5/10, Train Loss: 0.1357, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1099, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0907, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9746\n",
      "Epoch 8/10, Train Loss: 0.0714, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0554, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9768\n",
      "Epoch 10/10, Train Loss: 0.0488, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.95      0.93       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5359, Accuracy: 0.8828, F1 Micro: 0.8828, F1 Macro: 0.8586\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2775, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9291\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1709, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9304\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1351, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9352\n",
      "Epoch 5/10, Train Loss: 0.1619, Accuracy: 0.918, F1 Micro: 0.918, F1 Macro: 0.9061\n",
      "Epoch 6/10, Train Loss: 0.1565, Accuracy: 0.9258, F1 Micro: 0.9258, F1 Macro: 0.9192\n",
      "Epoch 7/10, Train Loss: 0.1213, Accuracy: 0.9297, F1 Micro: 0.9297, F1 Macro: 0.9203\n",
      "Epoch 8/10, Train Loss: 0.0949, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9307\n",
      "Epoch 9/10, Train Loss: 0.073, Accuracy: 0.9219, F1 Micro: 0.9219, F1 Macro: 0.9152\n",
      "Epoch 10/10, Train Loss: 0.0474, Accuracy: 0.9258, F1 Micro: 0.9258, F1 Macro: 0.918\n",
      "\n",
      "Sentiment analysis accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9352\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.96      0.92        84\n",
      "    positive       0.98      0.93      0.96       172\n",
      "\n",
      "    accuracy                           0.94       256\n",
      "   macro avg       0.93      0.95      0.94       256\n",
      "weighted avg       0.95      0.94      0.94       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9178\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.86      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.75      0.72        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.85      0.77      0.81        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.82      0.82      0.82       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.96      0.85        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.94      0.78      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.91      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 116.12340545654297 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.957765817642212 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5342, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4244, Accuracy: 0.91, F1 Micro: 0.9445, F1 Macro: 0.9427\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2857, Accuracy: 0.9494, F1 Micro: 0.9687, F1 Macro: 0.9675\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1917, Accuracy: 0.9568, F1 Micro: 0.9732, F1 Macro: 0.9722\n",
      "Epoch 5/10, Train Loss: 0.1361, Accuracy: 0.9531, F1 Micro: 0.9704, F1 Macro: 0.9676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1091, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0872, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9762\n",
      "Epoch 8/10, Train Loss: 0.0743, Accuracy: 0.9576, F1 Micro: 0.9732, F1 Macro: 0.9716\n",
      "Epoch 9/10, Train Loss: 0.0618, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9745\n",
      "Epoch 10/10, Train Loss: 0.0519, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9744\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.90      0.97      0.93       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      0.98      0.98       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5653, Accuracy: 0.8373, F1 Micro: 0.8373, F1 Macro: 0.7886\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3013, Accuracy: 0.8889, F1 Micro: 0.8889, F1 Macro: 0.8822\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1929, Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9392\n",
      "Epoch 4/10, Train Loss: 0.1847, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9267\n",
      "Epoch 5/10, Train Loss: 0.1306, Accuracy: 0.9246, F1 Micro: 0.9246, F1 Macro: 0.9185\n",
      "Epoch 6/10, Train Loss: 0.1444, Accuracy: 0.9365, F1 Micro: 0.9365, F1 Macro: 0.9309\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0813, Accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9434\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0737, Accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9434\n",
      "Epoch 9/10, Train Loss: 0.0739, Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9382\n",
      "Epoch 10/10, Train Loss: 0.0469, Accuracy: 0.9246, F1 Micro: 0.9246, F1 Macro: 0.9185\n",
      "\n",
      "Sentiment analysis accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9434\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.98      0.93        84\n",
      "    positive       0.99      0.93      0.96       168\n",
      "\n",
      "    accuracy                           0.95       252\n",
      "   macro avg       0.93      0.96      0.94       252\n",
      "weighted avg       0.95      0.95      0.95       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9161\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.88      0.93        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.86      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.90      0.97      0.93       152\n",
      "    positive       0.90      0.71      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.85      0.81      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.94      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.98      0.98      0.98       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 116.00338983535767 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.306028366088867 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5222, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3932, Accuracy: 0.9129, F1 Micro: 0.9456, F1 Macro: 0.9433\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2653, Accuracy: 0.9539, F1 Micro: 0.9714, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1893, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1441, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9758\n",
      "Epoch 6/10, Train Loss: 0.1058, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9751\n",
      "Epoch 7/10, Train Loss: 0.081, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9741\n",
      "Epoch 8/10, Train Loss: 0.0634, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0553, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0458, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.978\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.98      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5357, Accuracy: 0.8808, F1 Micro: 0.8808, F1 Macro: 0.8657\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.25, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9272\n",
      "Epoch 3/10, Train Loss: 0.1572, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.9084\n",
      "Epoch 4/10, Train Loss: 0.1397, Accuracy: 0.8885, F1 Micro: 0.8885, F1 Macro: 0.881\n",
      "Epoch 5/10, Train Loss: 0.1683, Accuracy: 0.9038, F1 Micro: 0.9038, F1 Macro: 0.8966\n",
      "Epoch 6/10, Train Loss: 0.1225, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9243\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1061, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9313\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1236, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9317\n",
      "Epoch 9/10, Train Loss: 0.0719, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9283\n",
      "Epoch 10/10, Train Loss: 0.0829, Accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.9005\n",
      "\n",
      "Sentiment analysis accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9317\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.95      0.91        85\n",
      "    positive       0.98      0.93      0.95       175\n",
      "\n",
      "    accuracy                           0.94       260\n",
      "   macro avg       0.92      0.94      0.93       260\n",
      "weighted avg       0.94      0.94      0.94       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.913\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.82      0.70      0.75        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.86      0.83      0.84       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.92      0.96      0.94       152\n",
      "    positive       0.87      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.85      0.83      0.84       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.95      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.98      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.91      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 118.3618893623352 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.585570812225342 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5187, Accuracy: 0.7961, F1 Micro: 0.8856, F1 Macro: 0.8842\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3861, Accuracy: 0.9189, F1 Micro: 0.9498, F1 Macro: 0.9479\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.27, Accuracy: 0.9435, F1 Micro: 0.9646, F1 Macro: 0.9627\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1872, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1332, Accuracy: 0.9621, F1 Micro: 0.9763, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1044, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0888, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0693, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9777\n",
      "Epoch 9/10, Train Loss: 0.0582, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9756\n",
      "Epoch 10/10, Train Loss: 0.0478, Accuracy: 0.9628, F1 Micro: 0.9764, F1 Macro: 0.9746\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9777\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.98      1.00      0.99       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5261, Accuracy: 0.8962, F1 Micro: 0.8962, F1 Macro: 0.8844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2515, Accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9402\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1863, Accuracy: 0.9538, F1 Micro: 0.9538, F1 Macro: 0.9487\n",
      "Epoch 4/10, Train Loss: 0.1416, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9324\n",
      "Epoch 5/10, Train Loss: 0.1382, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9343\n",
      "Epoch 6/10, Train Loss: 0.125, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9364\n",
      "Epoch 7/10, Train Loss: 0.1037, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9324\n",
      "Epoch 8/10, Train Loss: 0.0904, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9292\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0767, Accuracy: 0.9577, F1 Micro: 0.9577, F1 Macro: 0.9518\n",
      "Epoch 10/10, Train Loss: 0.074, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9324\n",
      "\n",
      "Sentiment analysis accuracy: 0.9577, F1 Micro: 0.9577, F1 Macro: 0.9518\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.93        85\n",
      "    positive       0.97      0.97      0.97       175\n",
      "\n",
      "    accuracy                           0.96       260\n",
      "   macro avg       0.95      0.95      0.95       260\n",
      "weighted avg       0.96      0.96      0.96       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9235\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.86      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.81      0.83      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.88      0.84      0.86       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        23\n",
      "     neutral       0.97      1.00      0.99       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.92      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.93      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 123.0600209236145 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 8\n",
      "Sampling duration: 4.067659139633179 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.53, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3987, Accuracy: 0.9189, F1 Micro: 0.9497, F1 Macro: 0.9471\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2578, Accuracy: 0.9554, F1 Micro: 0.9721, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1737, Accuracy: 0.9583, F1 Micro: 0.9741, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1336, Accuracy: 0.9635, F1 Micro: 0.9773, F1 Macro: 0.9766\n",
      "Epoch 6/10, Train Loss: 0.1046, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9733\n",
      "Epoch 7/10, Train Loss: 0.0762, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9749\n",
      "Epoch 8/10, Train Loss: 0.0619, Accuracy: 0.9583, F1 Micro: 0.9737, F1 Macro: 0.9721\n",
      "Epoch 9/10, Train Loss: 0.0527, Accuracy: 0.9613, F1 Micro: 0.9755, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0441, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.978\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.90      0.96      0.93       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5164, Accuracy: 0.8828, F1 Micro: 0.8828, F1 Macro: 0.8694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.275, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.927\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1963, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9394\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1675, Accuracy: 0.9531, F1 Micro: 0.9531, F1 Macro: 0.9475\n",
      "Epoch 5/10, Train Loss: 0.1272, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9287\n",
      "Epoch 6/10, Train Loss: 0.1202, Accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9436\n",
      "Epoch 7/10, Train Loss: 0.114, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9397\n",
      "Epoch 8/10, Train Loss: 0.0813, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9341\n",
      "Epoch 9/10, Train Loss: 0.1049, Accuracy: 0.9258, F1 Micro: 0.9258, F1 Macro: 0.9184\n",
      "Epoch 10/10, Train Loss: 0.0685, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9311\n",
      "\n",
      "Sentiment analysis accuracy: 0.9531, F1 Micro: 0.9531, F1 Macro: 0.9475\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93        84\n",
      "    positive       0.98      0.95      0.96       172\n",
      "\n",
      "    accuracy                           0.95       256\n",
      "   macro avg       0.94      0.95      0.95       256\n",
      "weighted avg       0.95      0.95      0.95       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9216\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.88      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.91      0.96      0.93       152\n",
      "    positive       0.88      0.73      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.85      0.81      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.98      0.99      0.99       152\n",
      "    positive       1.00      0.88      0.94        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.96      0.96      0.95       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.91      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 119.2636034488678 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.7849230766296387 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.521, Accuracy: 0.7961, F1 Micro: 0.8856, F1 Macro: 0.8842\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3788, Accuracy: 0.9256, F1 Micro: 0.9537, F1 Macro: 0.9516\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2419, Accuracy: 0.9524, F1 Micro: 0.9705, F1 Macro: 0.9694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1697, Accuracy: 0.9554, F1 Micro: 0.9721, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1297, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0927, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9763\n",
      "Epoch 7/10, Train Loss: 0.0775, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0643, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9763\n",
      "Epoch 9/10, Train Loss: 0.0516, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9735\n",
      "Epoch 10/10, Train Loss: 0.0451, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9763\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.94      0.92      0.93       158\n",
      "        part       0.98      0.97      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5184, Accuracy: 0.8963, F1 Micro: 0.8963, F1 Macro: 0.8774\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2799, Accuracy: 0.9148, F1 Micro: 0.9148, F1 Macro: 0.9003\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1843, Accuracy: 0.9296, F1 Micro: 0.9296, F1 Macro: 0.9223\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1357, Accuracy: 0.9296, F1 Micro: 0.9296, F1 Macro: 0.9223\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1332, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.933\n",
      "Epoch 6/10, Train Loss: 0.1288, Accuracy: 0.9111, F1 Micro: 0.9111, F1 Macro: 0.8976\n",
      "Epoch 7/10, Train Loss: 0.1183, Accuracy: 0.9296, F1 Micro: 0.9296, F1 Macro: 0.9219\n",
      "Epoch 8/10, Train Loss: 0.0674, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.929\n",
      "Epoch 9/10, Train Loss: 0.0764, Accuracy: 0.9296, F1 Micro: 0.9296, F1 Macro: 0.9223\n",
      "Epoch 10/10, Train Loss: 0.0444, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9262\n",
      "\n",
      "Sentiment analysis accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.933\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.93      0.91        87\n",
      "    positive       0.97      0.95      0.96       183\n",
      "\n",
      "    accuracy                           0.94       270\n",
      "   macro avg       0.93      0.94      0.93       270\n",
      "weighted avg       0.94      0.94      0.94       270\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9174\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.87      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.95      0.91      0.93       152\n",
      "    positive       0.75      0.81      0.78        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.82      0.85      0.84       216\n",
      "weighted avg       0.89      0.88      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.91      0.86        23\n",
      "     neutral       0.98      0.97      0.97       152\n",
      "    positive       0.88      0.85      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.91      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.93      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 129.73186993598938 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.140702247619629 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5187, Accuracy: 0.7939, F1 Micro: 0.8845, F1 Macro: 0.883\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3755, Accuracy: 0.933, F1 Micro: 0.9584, F1 Macro: 0.9565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2446, Accuracy: 0.9561, F1 Micro: 0.9728, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1667, Accuracy: 0.9635, F1 Micro: 0.9773, F1 Macro: 0.9765\n",
      "Epoch 5/10, Train Loss: 0.1288, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0982, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.976\n",
      "Epoch 7/10, Train Loss: 0.0727, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0616, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9767\n",
      "Epoch 9/10, Train Loss: 0.0504, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.045, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9771\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.91      0.94      0.92       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5189, Accuracy: 0.8931, F1 Micro: 0.8931, F1 Macro: 0.8859\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2364, Accuracy: 0.9466, F1 Micro: 0.9466, F1 Macro: 0.9408\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1786, Accuracy: 0.9504, F1 Micro: 0.9504, F1 Macro: 0.9448\n",
      "Epoch 4/10, Train Loss: 0.1616, Accuracy: 0.9427, F1 Micro: 0.9427, F1 Macro: 0.9367\n",
      "Epoch 5/10, Train Loss: 0.1161, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.9327\n",
      "Epoch 6/10, Train Loss: 0.1079, Accuracy: 0.9275, F1 Micro: 0.9275, F1 Macro: 0.921\n",
      "Epoch 7/10, Train Loss: 0.1046, Accuracy: 0.9427, F1 Micro: 0.9427, F1 Macro: 0.936\n",
      "Epoch 8/10, Train Loss: 0.1014, Accuracy: 0.9466, F1 Micro: 0.9466, F1 Macro: 0.9411\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0597, Accuracy: 0.9618, F1 Micro: 0.9618, F1 Macro: 0.957\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0757, Accuracy: 0.9656, F1 Micro: 0.9656, F1 Macro: 0.9614\n",
      "\n",
      "Sentiment analysis accuracy: 0.9656, F1 Micro: 0.9656, F1 Macro: 0.9614\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.97      0.95        86\n",
      "    positive       0.98      0.97      0.97       176\n",
      "\n",
      "    accuracy                           0.97       262\n",
      "   macro avg       0.96      0.97      0.96       262\n",
      "weighted avg       0.97      0.97      0.97       262\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9328\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.88      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.92      0.94      0.93       152\n",
      "    positive       0.82      0.77      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.88      0.85      0.86       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.99      0.99       152\n",
      "    positive       1.00      0.85      0.92        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.95      0.94       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.93      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 130.13414478302002 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.494032382965088 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5285, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3708, Accuracy: 0.9315, F1 Micro: 0.9578, F1 Macro: 0.9561\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2353, Accuracy: 0.9561, F1 Micro: 0.9728, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1741, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1201, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9748\n",
      "Epoch 6/10, Train Loss: 0.0923, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0789, Accuracy: 0.9658, F1 Micro: 0.9783, F1 Macro: 0.9766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0617, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9797\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0494, Accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.98\n",
      "Epoch 10/10, Train Loss: 0.0447, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.978\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5067, Accuracy: 0.9278, F1 Micro: 0.9278, F1 Macro: 0.9186\n",
      "Epoch 2/10, Train Loss: 0.1924, Accuracy: 0.9049, F1 Micro: 0.9049, F1 Macro: 0.8977\n",
      "Epoch 3/10, Train Loss: 0.1504, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9114\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.159, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9288\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1362, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9372\n",
      "Epoch 6/10, Train Loss: 0.1094, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9331\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0896, Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.9452\n",
      "Epoch 8/10, Train Loss: 0.079, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9342\n",
      "Epoch 9/10, Train Loss: 0.0967, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9372\n",
      "Epoch 10/10, Train Loss: 0.0802, Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9409\n",
      "\n",
      "Sentiment analysis accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.9452\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.98      0.93        86\n",
      "    positive       0.99      0.94      0.96       177\n",
      "\n",
      "    accuracy                           0.95       263\n",
      "   macro avg       0.94      0.96      0.95       263\n",
      "weighted avg       0.95      0.95      0.95       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9622, F1 Micro: 0.9622, F1 Macro: 0.9278\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.97      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.99      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.87      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.93      0.94      0.93       152\n",
      "    positive       0.84      0.79      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.84      0.85      0.85       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.95      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 130.33216667175293 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.8159005641937256 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5165, Accuracy: 0.7984, F1 Micro: 0.8868, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3663, Accuracy: 0.9442, F1 Micro: 0.9654, F1 Macro: 0.9641\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2378, Accuracy: 0.9554, F1 Micro: 0.9724, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1669, Accuracy: 0.9673, F1 Micro: 0.9796, F1 Macro: 0.9786\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1156, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9787\n",
      "Epoch 6/10, Train Loss: 0.0932, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0684, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9797\n",
      "Epoch 8/10, Train Loss: 0.0611, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9768\n",
      "Epoch 9/10, Train Loss: 0.0491, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0421, Accuracy: 0.971, F1 Micro: 0.9817, F1 Macro: 0.9804\n",
      "\n",
      "Aspect detection accuracy: 0.971, F1 Micro: 0.9817, F1 Macro: 0.9804\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.93      0.94      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.98      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.98      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.464, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9206\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2117, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9201\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1768, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9245\n",
      "Epoch 4/10, Train Loss: 0.172, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9201\n",
      "Epoch 5/10, Train Loss: 0.1197, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9206\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0877, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9241\n",
      "Epoch 7/10, Train Loss: 0.1002, Accuracy: 0.9205, F1 Micro: 0.9205, F1 Macro: 0.9131\n",
      "Epoch 8/10, Train Loss: 0.0835, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9206\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0473, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9285\n",
      "Epoch 10/10, Train Loss: 0.0629, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.9048\n",
      "\n",
      "Sentiment analysis accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9285\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.94      0.91        87\n",
      "    positive       0.97      0.93      0.95       177\n",
      "\n",
      "    accuracy                           0.94       264\n",
      "   macro avg       0.92      0.94      0.93       264\n",
      "weighted avg       0.94      0.94      0.94       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9193\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.89      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.93      0.94      0.94       152\n",
      "    positive       0.81      0.81      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.88      0.86      0.87       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.78      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.92      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 133.6864402294159 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 8\n",
      "Sampling duration: 1.108445644378662 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5149, Accuracy: 0.7984, F1 Micro: 0.8868, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3683, Accuracy: 0.9278, F1 Micro: 0.9549, F1 Macro: 0.9522\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2338, Accuracy: 0.9531, F1 Micro: 0.9708, F1 Macro: 0.9691\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1567, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.122, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9762\n",
      "Epoch 6/10, Train Loss: 0.0922, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.073, Accuracy: 0.971, F1 Micro: 0.9818, F1 Macro: 0.9806\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0611, Accuracy: 0.9717, F1 Micro: 0.9822, F1 Macro: 0.981\n",
      "Epoch 9/10, Train Loss: 0.05, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9777\n",
      "Epoch 10/10, Train Loss: 0.0424, Accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9793\n",
      "\n",
      "Aspect detection accuracy: 0.9717, F1 Micro: 0.9822, F1 Macro: 0.981\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.92      0.95      0.93       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.512, Accuracy: 0.8919, F1 Micro: 0.8919, F1 Macro: 0.8802\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2201, Accuracy: 0.9035, F1 Micro: 0.9035, F1 Macro: 0.8968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1716, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9234\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1258, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9241\n",
      "Epoch 5/10, Train Loss: 0.1015, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9161\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.093, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9238\n",
      "Epoch 7/10, Train Loss: 0.1136, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9161\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0843, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9315\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0582, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9312\n",
      "Epoch 10/10, Train Loss: 0.0529, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9197\n",
      "\n",
      "Sentiment analysis accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9312\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.93      0.91        86\n",
      "    positive       0.96      0.94      0.95       173\n",
      "\n",
      "    accuracy                           0.94       259\n",
      "   macro avg       0.93      0.94      0.93       259\n",
      "weighted avg       0.94      0.94      0.94       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9174\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.93      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.99      0.97       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.88      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.82      0.77      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.85      0.82      0.84       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.99      0.99       152\n",
      "    positive       1.00      0.83      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 134.49555110931396 s\n",
      "Total runtime: 2914.3883776664734 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5130d350",
   "metadata": {
    "papermill": {
     "duration": 0.287836,
     "end_time": "2025-03-25T16:11:13.441660",
     "exception": false,
     "start_time": "2025-03-25T16:11:13.153824",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174fb765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 3\n",
      "Random seed: 14\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1042ee0b180b4af7900b6f524f1137ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6791, Accuracy: 0.7746, F1 Micro: 0.8722, F1 Macro: 0.8703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5752, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.512, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4609, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4635, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4127, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3898, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4151, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.396, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3746, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "\n",
      "Aspect detection accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.78      1.00      0.88       175\n",
      "      others       0.71      1.00      0.83       158\n",
      "        part       0.71      1.00      0.83       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.79      1.00      0.88      1061\n",
      "   macro avg       0.79      1.00      0.88      1061\n",
      "weighted avg       0.80      1.00      0.89      1061\n",
      " samples avg       0.79      1.00      0.88      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.8159, Accuracy: 0.3333, F1 Micro: 0.3333, F1 Macro: 0.25\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.6264, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5442, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5154, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4038, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3617, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3192, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2942, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3391, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2952, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "\n",
      "Sentiment analysis accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         1\n",
      "    positive       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.67         3\n",
      "   macro avg       0.33      0.50      0.40         3\n",
      "weighted avg       0.44      0.67      0.53         3\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.7909, F1 Micro: 0.7909, F1 Macro: 0.298\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.77      1.00      0.87       167\n",
      "    positive       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.77       216\n",
      "   macro avg       0.26      0.33      0.29       216\n",
      "weighted avg       0.60      0.77      0.67       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.71      1.00      0.83       152\n",
      "    positive       0.67      0.04      0.07        52\n",
      "\n",
      "    accuracy                           0.71       216\n",
      "   macro avg       0.46      0.35      0.30       216\n",
      "weighted avg       0.66      0.71      0.60       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        23\n",
      "     neutral       0.70      1.00      0.83       152\n",
      "    positive       0.00      0.00      0.00        41\n",
      "\n",
      "    accuracy                           0.70       216\n",
      "   macro avg       0.23      0.33      0.28       216\n",
      "weighted avg       0.50      0.70      0.58       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 69.26458263397217 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 81\n",
      "Sampling duration: 12.757587194442749 seconds\n",
      "New train size: 135\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6229, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5204, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4987, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.456, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4338, Accuracy: 0.8006, F1 Micro: 0.8877, F1 Macro: 0.8862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.411, Accuracy: 0.8199, F1 Micro: 0.8972, F1 Macro: 0.8957\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.355, Accuracy: 0.8467, F1 Micro: 0.91, F1 Macro: 0.9085\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3133, Accuracy: 0.8571, F1 Micro: 0.915, F1 Macro: 0.9134\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2677, Accuracy: 0.8787, F1 Micro: 0.9267, F1 Macro: 0.9251\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2293, Accuracy: 0.8862, F1 Micro: 0.9308, F1 Macro: 0.9285\n",
      "\n",
      "Aspect detection accuracy: 0.8862, F1 Micro: 0.9308, F1 Macro: 0.9285\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.89      1.00      0.94       187\n",
      "     machine       0.91      0.98      0.94       175\n",
      "      others       0.86      0.89      0.87       158\n",
      "        part       0.86      0.95      0.90       158\n",
      "       price       0.88      1.00      0.94       192\n",
      "     service       0.95      0.99      0.97       191\n",
      "\n",
      "   micro avg       0.89      0.97      0.93      1061\n",
      "   macro avg       0.89      0.97      0.93      1061\n",
      "weighted avg       0.90      0.97      0.93      1061\n",
      " samples avg       0.90      0.97      0.93      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6133, Accuracy: 0.7473, F1 Micro: 0.7473, F1 Macro: 0.4277\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5203, Accuracy: 0.7473, F1 Micro: 0.7473, F1 Macro: 0.4277\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4413, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.6684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3048, Accuracy: 0.8441, F1 Micro: 0.8441, F1 Macro: 0.7789\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2526, Accuracy: 0.8763, F1 Micro: 0.8763, F1 Macro: 0.8417\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1459, Accuracy: 0.8763, F1 Micro: 0.8763, F1 Macro: 0.8491\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0697, Accuracy: 0.8763, F1 Micro: 0.8763, F1 Macro: 0.8396\n",
      "Epoch 8/10, Train Loss: 0.0552, Accuracy: 0.8656, F1 Micro: 0.8656, F1 Macro: 0.8279\n",
      "Epoch 9/10, Train Loss: 0.0745, Accuracy: 0.8602, F1 Micro: 0.8602, F1 Macro: 0.8265\n",
      "Epoch 10/10, Train Loss: 0.0675, Accuracy: 0.8602, F1 Micro: 0.8602, F1 Macro: 0.8244\n",
      "\n",
      "Sentiment analysis accuracy: 0.8763, F1 Micro: 0.8763, F1 Macro: 0.8396\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.79      0.76        47\n",
      "    positive       0.93      0.91      0.92       139\n",
      "\n",
      "    accuracy                           0.88       186\n",
      "   macro avg       0.83      0.85      0.84       186\n",
      "weighted avg       0.88      0.88      0.88       186\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 135: Accuracy: 0.8758, F1 Micro: 0.8758, F1 Macro: 0.6757\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.18      0.31        11\n",
      "     neutral       0.90      1.00      0.95       181\n",
      "    positive       0.85      0.46      0.59        24\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.92      0.55      0.62       216\n",
      "weighted avg       0.90      0.90      0.88       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.56      0.67        16\n",
      "     neutral       0.91      0.98      0.95       167\n",
      "    positive       0.88      0.67      0.76        33\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.87      0.74      0.79       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.41      0.58      0.48        12\n",
      "     neutral       0.86      0.89      0.87       152\n",
      "    positive       0.71      0.58      0.64        52\n",
      "\n",
      "    accuracy                           0.80       216\n",
      "   macro avg       0.66      0.68      0.66       216\n",
      "weighted avg       0.80      0.80      0.80       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.52      0.67        23\n",
      "     neutral       0.86      0.95      0.90       152\n",
      "    positive       0.71      0.61      0.66        41\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.83      0.69      0.74       216\n",
      "weighted avg       0.84      0.84      0.83       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.88      1.00      0.94       186\n",
      "    positive       0.80      0.24      0.36        17\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.56      0.41      0.43       216\n",
      "weighted avg       0.82      0.88      0.84       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.50      0.67        14\n",
      "     neutral       0.95      0.99      0.97       185\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.75      0.81       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Total train time: 80.23441076278687 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 73\n",
      "Sampling duration: 14.438080310821533 seconds\n",
      "New train size: 208\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5929, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5209, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4726, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4472, Accuracy: 0.8006, F1 Micro: 0.8877, F1 Macro: 0.8862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3857, Accuracy: 0.843, F1 Micro: 0.9085, F1 Macro: 0.9072\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3391, Accuracy: 0.8743, F1 Micro: 0.9253, F1 Macro: 0.9242\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2844, Accuracy: 0.9025, F1 Micro: 0.941, F1 Macro: 0.9394\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2317, Accuracy: 0.9226, F1 Micro: 0.9524, F1 Macro: 0.95\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1887, Accuracy: 0.936, F1 Micro: 0.9604, F1 Macro: 0.9584\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1622, Accuracy: 0.9368, F1 Micro: 0.9609, F1 Macro: 0.959\n",
      "\n",
      "Aspect detection accuracy: 0.9368, F1 Micro: 0.9609, F1 Macro: 0.959\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.96      0.99      0.98       187\n",
      "     machine       0.94      0.99      0.96       175\n",
      "      others       0.89      0.92      0.90       158\n",
      "        part       0.91      0.99      0.95       158\n",
      "       price       0.96      0.99      0.98       192\n",
      "     service       0.96      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.94      0.98      0.96      1061\n",
      "   macro avg       0.94      0.98      0.96      1061\n",
      "weighted avg       0.94      0.98      0.96      1061\n",
      " samples avg       0.94      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5903, Accuracy: 0.683, F1 Micro: 0.683, F1 Macro: 0.4058\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5251, Accuracy: 0.683, F1 Micro: 0.683, F1 Macro: 0.4058\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3671, Accuracy: 0.875, F1 Micro: 0.875, F1 Macro: 0.8389\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2177, Accuracy: 0.9509, F1 Micro: 0.9509, F1 Macro: 0.9443\n",
      "Epoch 5/10, Train Loss: 0.1864, Accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.9361\n",
      "Epoch 6/10, Train Loss: 0.1074, Accuracy: 0.942, F1 Micro: 0.942, F1 Macro: 0.9351\n",
      "Epoch 7/10, Train Loss: 0.0989, Accuracy: 0.933, F1 Micro: 0.933, F1 Macro: 0.9246\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0823, Accuracy: 0.9509, F1 Micro: 0.9509, F1 Macro: 0.9422\n",
      "Epoch 9/10, Train Loss: 0.0731, Accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.939\n",
      "Epoch 10/10, Train Loss: 0.0617, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9278\n",
      "\n",
      "Sentiment analysis accuracy: 0.9509, F1 Micro: 0.9509, F1 Macro: 0.9422\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.89      0.92        71\n",
      "    positive       0.95      0.98      0.96       153\n",
      "\n",
      "    accuracy                           0.95       224\n",
      "   macro avg       0.95      0.93      0.94       224\n",
      "weighted avg       0.95      0.95      0.95       224\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 208: Accuracy: 0.9306, F1 Micro: 0.9306, F1 Macro: 0.8548\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.55      0.67        11\n",
      "     neutral       0.96      0.99      0.98       181\n",
      "    positive       0.86      0.79      0.83        24\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.89      0.78      0.82       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.75      0.86        16\n",
      "     neutral       0.93      0.99      0.96       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.95      0.82      0.88       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.89      0.92      0.91       152\n",
      "    positive       0.79      0.71      0.75        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.84      0.82      0.83       216\n",
      "weighted avg       0.86      0.87      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.70      0.82        23\n",
      "     neutral       0.91      0.99      0.95       152\n",
      "    positive       0.91      0.76      0.83        41\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.94      0.82      0.87       216\n",
      "weighted avg       0.92      0.92      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.96      0.99      0.98       186\n",
      "    positive       0.86      0.71      0.77        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.82      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.64      0.78        14\n",
      "     neutral       0.96      1.00      0.98       185\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.80      0.86       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Total train time: 84.26369571685791 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 66\n",
      "Sampling duration: 14.582766056060791 seconds\n",
      "New train size: 274\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5847, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5013, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4559, Accuracy: 0.7991, F1 Micro: 0.887, F1 Macro: 0.8856\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4086, Accuracy: 0.8497, F1 Micro: 0.9109, F1 Macro: 0.9091\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3385, Accuracy: 0.8958, F1 Micro: 0.9378, F1 Macro: 0.9365\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2695, Accuracy: 0.9338, F1 Micro: 0.9593, F1 Macro: 0.9579\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2067, Accuracy: 0.9382, F1 Micro: 0.9619, F1 Macro: 0.9605\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1684, Accuracy: 0.9405, F1 Micro: 0.9631, F1 Macro: 0.9614\n",
      "Epoch 9/10, Train Loss: 0.1417, Accuracy: 0.9368, F1 Micro: 0.9608, F1 Macro: 0.9586\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1163, Accuracy: 0.9479, F1 Micro: 0.9673, F1 Macro: 0.9654\n",
      "\n",
      "Aspect detection accuracy: 0.9479, F1 Micro: 0.9673, F1 Macro: 0.9654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.89      0.89      0.89       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.97      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.97      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.97      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6018, Accuracy: 0.6953, F1 Micro: 0.6953, F1 Macro: 0.4101\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4179, Accuracy: 0.8672, F1 Micro: 0.8672, F1 Macro: 0.8282\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2545, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9235\n",
      "Epoch 4/10, Train Loss: 0.1304, Accuracy: 0.9297, F1 Micro: 0.9297, F1 Macro: 0.9145\n",
      "Epoch 5/10, Train Loss: 0.1614, Accuracy: 0.8633, F1 Micro: 0.8633, F1 Macro: 0.8532\n",
      "Epoch 6/10, Train Loss: 0.1452, Accuracy: 0.9258, F1 Micro: 0.9258, F1 Macro: 0.9078\n",
      "Epoch 7/10, Train Loss: 0.1359, Accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.8923\n",
      "Epoch 8/10, Train Loss: 0.0895, Accuracy: 0.9102, F1 Micro: 0.9102, F1 Macro: 0.8984\n",
      "Epoch 9/10, Train Loss: 0.1385, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8909\n",
      "Epoch 10/10, Train Loss: 0.0647, Accuracy: 0.9141, F1 Micro: 0.9141, F1 Macro: 0.9007\n",
      "\n",
      "Sentiment analysis accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9235\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.94      0.90        78\n",
      "    positive       0.97      0.93      0.95       178\n",
      "\n",
      "    accuracy                           0.93       256\n",
      "   macro avg       0.91      0.93      0.92       256\n",
      "weighted avg       0.94      0.93      0.93       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 274: Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.8846\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.98      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.93      0.79      0.85        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.84      0.87       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.83      0.74        12\n",
      "     neutral       0.89      0.89      0.89       152\n",
      "    positive       0.73      0.69      0.71        52\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.77      0.81      0.78       216\n",
      "weighted avg       0.84      0.84      0.84       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.87      0.83        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.90      0.88      0.89        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.91      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.84      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.97      1.00      0.99       185\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.97      0.87      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 87.40634894371033 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 59\n",
      "Sampling duration: 13.398532152175903 seconds\n",
      "New train size: 333\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5594, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5027, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4404, Accuracy: 0.8333, F1 Micro: 0.9039, F1 Macro: 0.9029\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3638, Accuracy: 0.8966, F1 Micro: 0.9382, F1 Macro: 0.9369\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.267, Accuracy: 0.9405, F1 Micro: 0.9633, F1 Macro: 0.9619\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2073, Accuracy: 0.9472, F1 Micro: 0.9672, F1 Macro: 0.9657\n",
      "Epoch 7/10, Train Loss: 0.1719, Accuracy: 0.9472, F1 Micro: 0.9671, F1 Macro: 0.9653\n",
      "Epoch 8/10, Train Loss: 0.1402, Accuracy: 0.9457, F1 Micro: 0.9661, F1 Macro: 0.9641\n",
      "Epoch 9/10, Train Loss: 0.1125, Accuracy: 0.9472, F1 Micro: 0.9668, F1 Macro: 0.9644\n",
      "Epoch 10/10, Train Loss: 0.1001, Accuracy: 0.9464, F1 Micro: 0.9663, F1 Macro: 0.9638\n",
      "\n",
      "Aspect detection accuracy: 0.9472, F1 Micro: 0.9672, F1 Macro: 0.9657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.94      1.00      0.97       175\n",
      "      others       0.87      0.96      0.91       158\n",
      "        part       0.96      0.96      0.96       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.96      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.95      0.99      0.97      1061\n",
      "   macro avg       0.95      0.98      0.97      1061\n",
      "weighted avg       0.95      0.99      0.97      1061\n",
      " samples avg       0.95      0.99      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6137, Accuracy: 0.6652, F1 Micro: 0.6652, F1 Macro: 0.3995\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4007, Accuracy: 0.8755, F1 Micro: 0.8755, F1 Macro: 0.8579\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2262, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9275\n",
      "Epoch 4/10, Train Loss: 0.188, Accuracy: 0.9099, F1 Micro: 0.9099, F1 Macro: 0.9035\n",
      "Epoch 5/10, Train Loss: 0.1762, Accuracy: 0.927, F1 Micro: 0.927, F1 Macro: 0.9149\n",
      "Epoch 6/10, Train Loss: 0.1518, Accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.9069\n",
      "Epoch 7/10, Train Loss: 0.08, Accuracy: 0.9227, F1 Micro: 0.9227, F1 Macro: 0.9095\n",
      "Epoch 8/10, Train Loss: 0.1284, Accuracy: 0.9185, F1 Micro: 0.9185, F1 Macro: 0.9109\n",
      "Epoch 9/10, Train Loss: 0.1347, Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.9219\n",
      "Epoch 10/10, Train Loss: 0.0959, Accuracy: 0.9185, F1 Micro: 0.9185, F1 Macro: 0.9118\n",
      "\n",
      "Sentiment analysis accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9275\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.90      0.90        78\n",
      "    positive       0.95      0.95      0.95       155\n",
      "\n",
      "    accuracy                           0.94       233\n",
      "   macro avg       0.93      0.93      0.93       233\n",
      "weighted avg       0.94      0.94      0.94       233\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 333: Accuracy: 0.9383, F1 Micro: 0.9383, F1 Macro: 0.877\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.94      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.93      1.00      0.97       167\n",
      "    positive       0.96      0.70      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.94      0.82      0.87       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.87      0.96      0.92       152\n",
      "    positive       0.89      0.63      0.74        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.84      0.78      0.80       216\n",
      "weighted avg       0.87      0.87      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.78      0.82        23\n",
      "     neutral       0.96      0.95      0.96       152\n",
      "    positive       0.77      0.83      0.80        41\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.86      0.86      0.86       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.84      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.96      1.00      0.98       185\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.96      0.83      0.89       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Total train time: 90.79930329322815 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 54\n",
      "Sampling duration: 11.728398084640503 seconds\n",
      "New train size: 387\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5556, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4814, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4321, Accuracy: 0.8557, F1 Micro: 0.9157, F1 Macro: 0.9147\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.332, Accuracy: 0.9182, F1 Micro: 0.9503, F1 Macro: 0.9497\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.249, Accuracy: 0.9449, F1 Micro: 0.966, F1 Macro: 0.9647\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1891, Accuracy: 0.9524, F1 Micro: 0.9705, F1 Macro: 0.9692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1497, Accuracy: 0.9531, F1 Micro: 0.9707, F1 Macro: 0.9692\n",
      "Epoch 8/10, Train Loss: 0.1174, Accuracy: 0.9494, F1 Micro: 0.9683, F1 Macro: 0.9666\n",
      "Epoch 9/10, Train Loss: 0.1039, Accuracy: 0.9531, F1 Micro: 0.9705, F1 Macro: 0.9687\n",
      "Epoch 10/10, Train Loss: 0.0855, Accuracy: 0.9524, F1 Micro: 0.9702, F1 Macro: 0.9687\n",
      "\n",
      "Aspect detection accuracy: 0.9531, F1 Micro: 0.9707, F1 Macro: 0.9692\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.93      1.00      0.96       175\n",
      "      others       0.90      0.92      0.91       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.544, Accuracy: 0.6816, F1 Micro: 0.6816, F1 Macro: 0.4174\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3703, Accuracy: 0.9102, F1 Micro: 0.9102, F1 Macro: 0.8998\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1761, Accuracy: 0.9429, F1 Micro: 0.9429, F1 Macro: 0.9366\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1407, Accuracy: 0.9551, F1 Micro: 0.9551, F1 Macro: 0.9481\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.105, Accuracy: 0.9592, F1 Micro: 0.9592, F1 Macro: 0.9527\n",
      "Epoch 6/10, Train Loss: 0.1071, Accuracy: 0.9469, F1 Micro: 0.9469, F1 Macro: 0.9413\n",
      "Epoch 7/10, Train Loss: 0.0676, Accuracy: 0.9306, F1 Micro: 0.9306, F1 Macro: 0.9241\n",
      "Epoch 8/10, Train Loss: 0.0765, Accuracy: 0.951, F1 Micro: 0.951, F1 Macro: 0.9457\n",
      "Epoch 9/10, Train Loss: 0.0601, Accuracy: 0.9265, F1 Micro: 0.9265, F1 Macro: 0.9198\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.049, Accuracy: 0.9633, F1 Micro: 0.9633, F1 Macro: 0.9586\n",
      "\n",
      "Sentiment analysis accuracy: 0.9633, F1 Micro: 0.9633, F1 Macro: 0.9586\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.97      0.94        79\n",
      "    positive       0.99      0.96      0.97       166\n",
      "\n",
      "    accuracy                           0.96       245\n",
      "   macro avg       0.95      0.97      0.96       245\n",
      "weighted avg       0.96      0.96      0.96       245\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 387: Accuracy: 0.9491, F1 Micro: 0.9491, F1 Macro: 0.9053\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.93      1.00      0.96       167\n",
      "    positive       1.00      0.64      0.78        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.93      0.82      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.90      0.93      0.91       152\n",
      "    positive       0.80      0.75      0.77        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.86      0.81      0.83       216\n",
      "weighted avg       0.87      0.88      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.95      0.88      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.84      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.99      0.91      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 98.98026919364929 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 48\n",
      "Sampling duration: 11.032200336456299 seconds\n",
      "New train size: 435\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5525, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4823, Accuracy: 0.7976, F1 Micro: 0.8864, F1 Macro: 0.8849\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3973, Accuracy: 0.8862, F1 Micro: 0.932, F1 Macro: 0.9308\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3002, Accuracy: 0.939, F1 Micro: 0.9625, F1 Macro: 0.9612\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2153, Accuracy: 0.9494, F1 Micro: 0.9686, F1 Macro: 0.9673\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.173, Accuracy: 0.9516, F1 Micro: 0.9698, F1 Macro: 0.9685\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1439, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9727\n",
      "Epoch 8/10, Train Loss: 0.1137, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9724\n",
      "Epoch 9/10, Train Loss: 0.0879, Accuracy: 0.9501, F1 Micro: 0.9686, F1 Macro: 0.9664\n",
      "Epoch 10/10, Train Loss: 0.0768, Accuracy: 0.9561, F1 Micro: 0.9724, F1 Macro: 0.9708\n",
      "\n",
      "Aspect detection accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9727\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.97      0.97       175\n",
      "      others       0.89      0.96      0.93       158\n",
      "        part       0.98      0.97      0.97       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5807, Accuracy: 0.7619, F1 Micro: 0.7619, F1 Macro: 0.6465\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3595, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8963\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2043, Accuracy: 0.9246, F1 Micro: 0.9246, F1 Macro: 0.9154\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2165, Accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9421\n",
      "Epoch 5/10, Train Loss: 0.1744, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9248\n",
      "Epoch 6/10, Train Loss: 0.0971, Accuracy: 0.9206, F1 Micro: 0.9206, F1 Macro: 0.9131\n",
      "Epoch 7/10, Train Loss: 0.0972, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.909\n",
      "Epoch 8/10, Train Loss: 0.1302, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0778, Accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9411\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0761, Accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9414\n",
      "\n",
      "Sentiment analysis accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9414\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.95      0.92        80\n",
      "    positive       0.98      0.95      0.96       172\n",
      "\n",
      "    accuracy                           0.95       252\n",
      "   macro avg       0.94      0.95      0.94       252\n",
      "weighted avg       0.95      0.95      0.95       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 435: Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.904\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.91      0.88      0.89        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.81      0.79        16\n",
      "     neutral       0.96      0.97      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.86      0.86      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.90      0.97      0.93       152\n",
      "    positive       0.88      0.71      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.89      0.81      0.85       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.98      0.97      0.97       152\n",
      "    positive       0.90      0.90      0.90        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.97      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.97      0.86      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.99      0.91      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 103.08420300483704 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 43\n",
      "Sampling duration: 10.154228687286377 seconds\n",
      "New train size: 478\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5479, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4719, Accuracy: 0.8036, F1 Micro: 0.889, F1 Macro: 0.8876\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3894, Accuracy: 0.907, F1 Micro: 0.944, F1 Macro: 0.9426\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2881, Accuracy: 0.939, F1 Micro: 0.9624, F1 Macro: 0.961\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2102, Accuracy: 0.9531, F1 Micro: 0.9709, F1 Macro: 0.9696\n",
      "Epoch 6/10, Train Loss: 0.1566, Accuracy: 0.9531, F1 Micro: 0.9707, F1 Macro: 0.9691\n",
      "Epoch 7/10, Train Loss: 0.1283, Accuracy: 0.9531, F1 Micro: 0.9706, F1 Macro: 0.9687\n",
      "Epoch 8/10, Train Loss: 0.1047, Accuracy: 0.9501, F1 Micro: 0.9687, F1 Macro: 0.9668\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.087, Accuracy: 0.9561, F1 Micro: 0.9723, F1 Macro: 0.9705\n",
      "Epoch 10/10, Train Loss: 0.0685, Accuracy: 0.9546, F1 Micro: 0.9714, F1 Macro: 0.9696\n",
      "\n",
      "Aspect detection accuracy: 0.9561, F1 Micro: 0.9723, F1 Macro: 0.9705\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      0.98      0.96       175\n",
      "      others       0.93      0.90      0.91       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      1061\n",
      "   macro avg       0.97      0.97      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.97      0.97      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4882, Accuracy: 0.8717, F1 Micro: 0.8717, F1 Macro: 0.8499\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2512, Accuracy: 0.9208, F1 Micro: 0.9208, F1 Macro: 0.9119\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1844, Accuracy: 0.9509, F1 Micro: 0.9509, F1 Macro: 0.9416\n",
      "Epoch 4/10, Train Loss: 0.1785, Accuracy: 0.9094, F1 Micro: 0.9094, F1 Macro: 0.9001\n",
      "Epoch 5/10, Train Loss: 0.1419, Accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.939\n",
      "Epoch 6/10, Train Loss: 0.125, Accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.9369\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1075, Accuracy: 0.9509, F1 Micro: 0.9509, F1 Macro: 0.9416\n",
      "Epoch 8/10, Train Loss: 0.1358, Accuracy: 0.9358, F1 Micro: 0.9358, F1 Macro: 0.9275\n",
      "Epoch 9/10, Train Loss: 0.0754, Accuracy: 0.9358, F1 Micro: 0.9358, F1 Macro: 0.9266\n",
      "Epoch 10/10, Train Loss: 0.061, Accuracy: 0.9358, F1 Micro: 0.9358, F1 Macro: 0.9271\n",
      "\n",
      "Sentiment analysis accuracy: 0.9509, F1 Micro: 0.9509, F1 Macro: 0.9416\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.89      0.92        82\n",
      "    positive       0.95      0.98      0.96       183\n",
      "\n",
      "    accuracy                           0.95       265\n",
      "   macro avg       0.95      0.93      0.94       265\n",
      "weighted avg       0.95      0.95      0.95       265\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 478: Accuracy: 0.9483, F1 Micro: 0.9483, F1 Macro: 0.9058\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.83      0.73      0.77        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.84      0.87       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        12\n",
      "     neutral       0.93      0.90      0.92       152\n",
      "    positive       0.75      0.83      0.79        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.87      0.88      0.87       216\n",
      "weighted avg       0.89      0.88      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.83      0.86        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.84      0.90      0.87        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.90      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.88      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.98      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 105.66184592247009 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 39\n",
      "Sampling duration: 9.427097797393799 seconds\n",
      "New train size: 517\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.547, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4596, Accuracy: 0.8311, F1 Micro: 0.9029, F1 Macro: 0.9019\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3551, Accuracy: 0.9263, F1 Micro: 0.9549, F1 Macro: 0.9533\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2484, Accuracy: 0.9487, F1 Micro: 0.9682, F1 Macro: 0.9668\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1779, Accuracy: 0.9561, F1 Micro: 0.9727, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1489, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9715\n",
      "Epoch 7/10, Train Loss: 0.1102, Accuracy: 0.9539, F1 Micro: 0.9709, F1 Macro: 0.9688\n",
      "Epoch 8/10, Train Loss: 0.0884, Accuracy: 0.9546, F1 Micro: 0.9715, F1 Macro: 0.9699\n",
      "Epoch 9/10, Train Loss: 0.0761, Accuracy: 0.9546, F1 Micro: 0.9715, F1 Macro: 0.9701\n",
      "Epoch 10/10, Train Loss: 0.0618, Accuracy: 0.9546, F1 Micro: 0.9715, F1 Macro: 0.9695\n",
      "\n",
      "Aspect detection accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9715\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      0.98      0.96       175\n",
      "      others       0.91      0.94      0.92       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5382, Accuracy: 0.8024, F1 Micro: 0.8024, F1 Macro: 0.726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2797, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9102\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1709, Accuracy: 0.9315, F1 Micro: 0.9315, F1 Macro: 0.9228\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1534, Accuracy: 0.9476, F1 Micro: 0.9476, F1 Macro: 0.939\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0946, Accuracy: 0.9476, F1 Micro: 0.9476, F1 Macro: 0.9394\n",
      "Epoch 6/10, Train Loss: 0.1033, Accuracy: 0.9355, F1 Micro: 0.9355, F1 Macro: 0.9284\n",
      "Epoch 7/10, Train Loss: 0.0827, Accuracy: 0.9435, F1 Micro: 0.9435, F1 Macro: 0.9358\n",
      "Epoch 8/10, Train Loss: 0.0563, Accuracy: 0.9435, F1 Micro: 0.9435, F1 Macro: 0.9366\n",
      "Epoch 9/10, Train Loss: 0.05, Accuracy: 0.9355, F1 Micro: 0.9355, F1 Macro: 0.9262\n",
      "Epoch 10/10, Train Loss: 0.0485, Accuracy: 0.9355, F1 Micro: 0.9355, F1 Macro: 0.9262\n",
      "\n",
      "Sentiment analysis accuracy: 0.9476, F1 Micro: 0.9476, F1 Macro: 0.9394\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.91      0.92        79\n",
      "    positive       0.96      0.96      0.96       169\n",
      "\n",
      "    accuracy                           0.95       248\n",
      "   macro avg       0.94      0.94      0.94       248\n",
      "weighted avg       0.95      0.95      0.95       248\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 517: Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9046\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.75      0.77        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.83      0.85       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.91      0.94      0.93       152\n",
      "    positive       0.82      0.77      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.88      0.82      0.85       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.83      0.86        23\n",
      "     neutral       0.96      0.99      0.97       152\n",
      "    positive       0.89      0.80      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.97      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.97      0.86      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.95      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 110.45091271400452 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 23\n",
      "Sampling duration: 8.451883316040039 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5512, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.457, Accuracy: 0.8207, F1 Micro: 0.8977, F1 Macro: 0.8962\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3547, Accuracy: 0.9256, F1 Micro: 0.9545, F1 Macro: 0.9532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2555, Accuracy: 0.9501, F1 Micro: 0.9692, F1 Macro: 0.9678\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1867, Accuracy: 0.9568, F1 Micro: 0.9732, F1 Macro: 0.9722\n",
      "Epoch 6/10, Train Loss: 0.1458, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1121, Accuracy: 0.9621, F1 Micro: 0.9763, F1 Macro: 0.9754\n",
      "Epoch 8/10, Train Loss: 0.088, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9739\n",
      "Epoch 9/10, Train Loss: 0.0745, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0661, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9754\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9754\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.99      0.98      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5157, Accuracy: 0.8721, F1 Micro: 0.8721, F1 Macro: 0.8417\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2802, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9275\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1728, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9314\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1738, Accuracy: 0.9535, F1 Micro: 0.9535, F1 Macro: 0.947\n",
      "Epoch 5/10, Train Loss: 0.1598, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9327\n",
      "Epoch 6/10, Train Loss: 0.0961, Accuracy: 0.9496, F1 Micro: 0.9496, F1 Macro: 0.9428\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0928, Accuracy: 0.9574, F1 Micro: 0.9574, F1 Macro: 0.9522\n",
      "Epoch 8/10, Train Loss: 0.1074, Accuracy: 0.9186, F1 Micro: 0.9186, F1 Macro: 0.9111\n",
      "Epoch 9/10, Train Loss: 0.0805, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9265\n",
      "Epoch 10/10, Train Loss: 0.0685, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9336\n",
      "\n",
      "Sentiment analysis accuracy: 0.9574, F1 Micro: 0.9574, F1 Macro: 0.9522\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94        83\n",
      "    positive       0.99      0.95      0.97       175\n",
      "\n",
      "    accuracy                           0.96       258\n",
      "   macro avg       0.94      0.96      0.95       258\n",
      "weighted avg       0.96      0.96      0.96       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.921\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.84      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.92      0.88        12\n",
      "     neutral       0.93      0.94      0.93       152\n",
      "    positive       0.82      0.77      0.79        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.86      0.88      0.87       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.99      0.98      0.98       152\n",
      "    positive       0.95      0.88      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.95      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.88      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 115.21955251693726 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 33\n",
      "Sampling duration: 8.121254444122314 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5327, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4623, Accuracy: 0.84, F1 Micro: 0.9075, F1 Macro: 0.9063\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3482, Accuracy: 0.9293, F1 Micro: 0.9563, F1 Macro: 0.9546\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2409, Accuracy: 0.9516, F1 Micro: 0.97, F1 Macro: 0.9683\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1723, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1331, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1102, Accuracy: 0.9621, F1 Micro: 0.9763, F1 Macro: 0.9749\n",
      "Epoch 8/10, Train Loss: 0.0825, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9738\n",
      "Epoch 9/10, Train Loss: 0.0701, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0599, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9765\n",
      "\n",
      "Aspect detection accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.91      0.96      0.94       158\n",
      "        part       0.99      0.97      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5238, Accuracy: 0.9008, F1 Micro: 0.9008, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2272, Accuracy: 0.9206, F1 Micro: 0.9206, F1 Macro: 0.9131\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1953, Accuracy: 0.9365, F1 Micro: 0.9365, F1 Macro: 0.9298\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1729, Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9382\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1274, Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9355\n",
      "Epoch 6/10, Train Loss: 0.1032, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9256\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0943, Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9382\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.107, Accuracy: 0.9524, F1 Micro: 0.9524, F1 Macro: 0.9451\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0741, Accuracy: 0.9563, F1 Micro: 0.9563, F1 Macro: 0.9495\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.063, Accuracy: 0.9563, F1 Micro: 0.9563, F1 Macro: 0.9507\n",
      "\n",
      "Sentiment analysis accuracy: 0.9563, F1 Micro: 0.9563, F1 Macro: 0.9507\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.93        81\n",
      "    positive       0.98      0.95      0.97       171\n",
      "\n",
      "    accuracy                           0.96       252\n",
      "   macro avg       0.94      0.96      0.95       252\n",
      "weighted avg       0.96      0.96      0.96       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.9154\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.88      0.70      0.78        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.83      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.91      0.97      0.94       152\n",
      "    positive       0.89      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.90      0.83      0.86       216\n",
      "weighted avg       0.91      0.91      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.99      0.97      0.98       152\n",
      "    positive       0.92      0.88      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.95      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.69      0.82        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.86      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 127.24943447113037 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 30\n",
      "Sampling duration: 7.399203538894653 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5406, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4501, Accuracy: 0.8333, F1 Micro: 0.9044, F1 Macro: 0.903\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3214, Accuracy: 0.9338, F1 Micro: 0.9595, F1 Macro: 0.958\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2299, Accuracy: 0.9568, F1 Micro: 0.9732, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1639, Accuracy: 0.9583, F1 Micro: 0.974, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1269, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9754\n",
      "Epoch 7/10, Train Loss: 0.0985, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.975\n",
      "Epoch 8/10, Train Loss: 0.0828, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9749\n",
      "Epoch 9/10, Train Loss: 0.0679, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9741\n",
      "Epoch 10/10, Train Loss: 0.0613, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9742\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9754\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5107, Accuracy: 0.8898, F1 Micro: 0.8898, F1 Macro: 0.8723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2465, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9335\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1813, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9388\n",
      "Epoch 4/10, Train Loss: 0.1437, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9304\n",
      "Epoch 5/10, Train Loss: 0.1418, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9222\n",
      "Epoch 6/10, Train Loss: 0.107, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9263\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0742, Accuracy: 0.9567, F1 Micro: 0.9567, F1 Macro: 0.9512\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.086, Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.955\n",
      "Epoch 9/10, Train Loss: 0.0686, Accuracy: 0.9488, F1 Micro: 0.9488, F1 Macro: 0.9409\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0609, Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9547\n",
      "\n",
      "Sentiment analysis accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.93      0.94        82\n",
      "    positive       0.97      0.98      0.97       172\n",
      "\n",
      "    accuracy                           0.96       254\n",
      "   macro avg       0.96      0.95      0.95       254\n",
      "weighted avg       0.96      0.96      0.96       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9179\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.93      0.95      0.94       152\n",
      "    positive       0.84      0.81      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.89      0.86      0.88       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.92      0.85      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.92      0.93       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.97      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.97      0.86      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.93      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 120.67059254646301 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 27\n",
      "Sampling duration: 6.705903768539429 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5496, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4508, Accuracy: 0.8757, F1 Micro: 0.9261, F1 Macro: 0.9246\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.313, Accuracy: 0.9442, F1 Micro: 0.9655, F1 Macro: 0.9641\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2194, Accuracy: 0.9561, F1 Micro: 0.9727, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1529, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1152, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9746\n",
      "Epoch 7/10, Train Loss: 0.0935, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0811, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9757\n",
      "Epoch 9/10, Train Loss: 0.0665, Accuracy: 0.9613, F1 Micro: 0.9754, F1 Macro: 0.9732\n",
      "Epoch 10/10, Train Loss: 0.0564, Accuracy: 0.9591, F1 Micro: 0.9741, F1 Macro: 0.9721\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9757\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.91      0.94      0.93       158\n",
      "        part       0.99      0.97      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5021, Accuracy: 0.9042, F1 Micro: 0.9042, F1 Macro: 0.8869\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.208, Accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.94\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2121, Accuracy: 0.9502, F1 Micro: 0.9502, F1 Macro: 0.9435\n",
      "Epoch 4/10, Train Loss: 0.142, Accuracy: 0.9425, F1 Micro: 0.9425, F1 Macro: 0.9348\n",
      "Epoch 5/10, Train Loss: 0.1225, Accuracy: 0.9387, F1 Micro: 0.9387, F1 Macro: 0.9289\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1072, Accuracy: 0.9579, F1 Micro: 0.9579, F1 Macro: 0.9524\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1164, Accuracy: 0.9617, F1 Micro: 0.9617, F1 Macro: 0.9566\n",
      "Epoch 8/10, Train Loss: 0.1093, Accuracy: 0.9579, F1 Micro: 0.9579, F1 Macro: 0.9524\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0919, Accuracy: 0.9617, F1 Micro: 0.9617, F1 Macro: 0.9566\n",
      "Epoch 10/10, Train Loss: 0.0575, Accuracy: 0.9502, F1 Micro: 0.9502, F1 Macro: 0.9431\n",
      "\n",
      "Sentiment analysis accuracy: 0.9617, F1 Micro: 0.9617, F1 Macro: 0.9566\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.96      0.94        84\n",
      "    positive       0.98      0.96      0.97       177\n",
      "\n",
      "    accuracy                           0.96       261\n",
      "   macro avg       0.95      0.96      0.96       261\n",
      "weighted avg       0.96      0.96      0.96       261\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.923\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.92      0.95      0.93       152\n",
      "    positive       0.84      0.79      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.88      0.83      0.85       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.99      0.97      0.98       152\n",
      "    positive       0.93      0.90      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.96      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.90      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 127.4435498714447 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 18\n",
      "Sampling duration: 6.213900327682495 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5368, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.435, Accuracy: 0.878, F1 Micro: 0.9271, F1 Macro: 0.9254\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2987, Accuracy: 0.9457, F1 Micro: 0.9663, F1 Macro: 0.9651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2164, Accuracy: 0.9568, F1 Micro: 0.9731, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1515, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9741\n",
      "Epoch 6/10, Train Loss: 0.1097, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0892, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9769\n",
      "Epoch 8/10, Train Loss: 0.0776, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9734\n",
      "Epoch 9/10, Train Loss: 0.0595, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9743\n",
      "Epoch 10/10, Train Loss: 0.0513, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9762\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.99      0.99      0.99       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4748, Accuracy: 0.9105, F1 Micro: 0.9105, F1 Macro: 0.8998\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2195, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9309\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1562, Accuracy: 0.9533, F1 Micro: 0.9533, F1 Macro: 0.9476\n",
      "Epoch 4/10, Train Loss: 0.147, Accuracy: 0.9416, F1 Micro: 0.9416, F1 Macro: 0.9331\n",
      "Epoch 5/10, Train Loss: 0.1392, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9293\n",
      "Epoch 6/10, Train Loss: 0.0993, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9181\n",
      "Epoch 7/10, Train Loss: 0.083, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9305\n",
      "Epoch 8/10, Train Loss: 0.0773, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9309\n",
      "Epoch 9/10, Train Loss: 0.0836, Accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9388\n",
      "Epoch 10/10, Train Loss: 0.0843, Accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9388\n",
      "\n",
      "Sentiment analysis accuracy: 0.9533, F1 Micro: 0.9533, F1 Macro: 0.9476\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.93        82\n",
      "    positive       0.99      0.94      0.96       175\n",
      "\n",
      "    accuracy                           0.95       257\n",
      "   macro avg       0.94      0.96      0.95       257\n",
      "weighted avg       0.96      0.95      0.95       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.9207\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.83      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.93      0.94      0.93       152\n",
      "    positive       0.83      0.77      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.83      0.85      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.99      0.99      0.99       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.95      0.93       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.97      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.97      0.86      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 122.35004591941833 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.826090574264526 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.535, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4322, Accuracy: 0.8862, F1 Micro: 0.9323, F1 Macro: 0.931\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2977, Accuracy: 0.9472, F1 Micro: 0.9673, F1 Macro: 0.9661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2045, Accuracy: 0.9576, F1 Micro: 0.9737, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1411, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1172, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9766\n",
      "Epoch 7/10, Train Loss: 0.0814, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9729\n",
      "Epoch 8/10, Train Loss: 0.0724, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0579, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0516, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.979\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.979\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.99      0.98      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5384, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.8973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2801, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.9327\n",
      "Epoch 3/10, Train Loss: 0.1351, Accuracy: 0.9198, F1 Micro: 0.9198, F1 Macro: 0.9127\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1547, Accuracy: 0.9466, F1 Micro: 0.9466, F1 Macro: 0.9401\n",
      "Epoch 5/10, Train Loss: 0.1242, Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.9246\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1017, Accuracy: 0.9466, F1 Micro: 0.9466, F1 Macro: 0.9401\n",
      "Epoch 7/10, Train Loss: 0.097, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9262\n",
      "Epoch 8/10, Train Loss: 0.0905, Accuracy: 0.9275, F1 Micro: 0.9275, F1 Macro: 0.921\n",
      "Epoch 9/10, Train Loss: 0.0465, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.933\n",
      "Epoch 10/10, Train Loss: 0.0531, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9286\n",
      "\n",
      "Sentiment analysis accuracy: 0.9466, F1 Micro: 0.9466, F1 Macro: 0.9401\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        86\n",
      "    positive       0.97      0.95      0.96       176\n",
      "\n",
      "    accuracy                           0.95       262\n",
      "   macro avg       0.94      0.95      0.94       262\n",
      "weighted avg       0.95      0.95      0.95       262\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9252\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.94      0.88      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.93      0.94      0.93       152\n",
      "    positive       0.83      0.77      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.83      0.85      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.99      0.98      0.98       152\n",
      "    positive       0.92      0.88      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 134.89515495300293 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.245213270187378 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5268, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4357, Accuracy: 0.9055, F1 Micro: 0.9422, F1 Macro: 0.94\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2845, Accuracy: 0.9516, F1 Micro: 0.9701, F1 Macro: 0.9689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.202, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1455, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1158, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0913, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "Epoch 8/10, Train Loss: 0.0752, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9771\n",
      "Epoch 9/10, Train Loss: 0.0633, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9741\n",
      "Epoch 10/10, Train Loss: 0.0522, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9738\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      0.99      0.97       175\n",
      "      others       0.91      0.96      0.94       158\n",
      "        part       0.99      0.97      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4901, Accuracy: 0.898, F1 Micro: 0.898, F1 Macro: 0.8872\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2142, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9319\n",
      "Epoch 3/10, Train Loss: 0.1855, Accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.9096\n",
      "Epoch 4/10, Train Loss: 0.1602, Accuracy: 0.9255, F1 Micro: 0.9255, F1 Macro: 0.9169\n",
      "Epoch 5/10, Train Loss: 0.1274, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9227\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1193, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9379\n",
      "Epoch 7/10, Train Loss: 0.0726, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9228\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0863, Accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.9425\n",
      "Epoch 9/10, Train Loss: 0.0635, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9351\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0587, Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9474\n",
      "\n",
      "Sentiment analysis accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9474\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.96      0.93        83\n",
      "    positive       0.98      0.95      0.96       172\n",
      "\n",
      "    accuracy                           0.95       255\n",
      "   macro avg       0.94      0.96      0.95       255\n",
      "weighted avg       0.95      0.95      0.95       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.9204\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.94      0.99      0.97       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.82      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.91      0.96      0.94       152\n",
      "    positive       0.87      0.75      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.87      0.82      0.84       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.99      0.97      0.98       152\n",
      "    positive       0.92      0.88      0.90        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.95      0.93       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 132.2967426776886 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.761023759841919 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5288, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4234, Accuracy: 0.8906, F1 Micro: 0.9348, F1 Macro: 0.9334\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2882, Accuracy: 0.9531, F1 Micro: 0.9709, F1 Macro: 0.9699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2008, Accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9777\n",
      "Epoch 5/10, Train Loss: 0.1411, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9736\n",
      "Epoch 6/10, Train Loss: 0.1085, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "Epoch 7/10, Train Loss: 0.0832, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9746\n",
      "Epoch 8/10, Train Loss: 0.0718, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9725\n",
      "Epoch 9/10, Train Loss: 0.0587, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9751\n",
      "Epoch 10/10, Train Loss: 0.0495, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9769\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9777\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      1.00      0.97       175\n",
      "      others       0.90      0.97      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4992, Accuracy: 0.8852, F1 Micro: 0.8852, F1 Macro: 0.8609\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2557, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9278\n",
      "Epoch 3/10, Train Loss: 0.1968, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.9036\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1169, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9285\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1015, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9274\n",
      "Epoch 6/10, Train Loss: 0.0912, Accuracy: 0.9262, F1 Micro: 0.9262, F1 Macro: 0.9168\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0967, Accuracy: 0.9467, F1 Micro: 0.9467, F1 Macro: 0.9415\n",
      "Epoch 8/10, Train Loss: 0.0731, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9328\n",
      "Epoch 9/10, Train Loss: 0.0594, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9325\n",
      "Epoch 10/10, Train Loss: 0.057, Accuracy: 0.9303, F1 Micro: 0.9303, F1 Macro: 0.9231\n",
      "\n",
      "Sentiment analysis accuracy: 0.9467, F1 Micro: 0.9467, F1 Macro: 0.9415\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.98      0.92        81\n",
      "    positive       0.99      0.93      0.96       163\n",
      "\n",
      "    accuracy                           0.95       244\n",
      "   macro avg       0.93      0.95      0.94       244\n",
      "weighted avg       0.95      0.95      0.95       244\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.9138\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.94      1.00      0.97       167\n",
      "    positive       0.96      0.70      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.82      0.86       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.67      0.73        12\n",
      "     neutral       0.90      0.98      0.94       152\n",
      "    positive       0.93      0.73      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.88      0.79      0.83       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 128.5729570388794 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint:756 \n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.034613609313965 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5301, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4085, Accuracy: 0.9159, F1 Micro: 0.9486, F1 Macro: 0.9466\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2691, Accuracy: 0.9524, F1 Micro: 0.9705, F1 Macro: 0.9689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.182, Accuracy: 0.9554, F1 Micro: 0.972, F1 Macro: 0.9706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1371, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1023, Accuracy: 0.968, F1 Micro: 0.98, F1 Macro: 0.9791\n",
      "Epoch 7/10, Train Loss: 0.0893, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9764\n",
      "Epoch 8/10, Train Loss: 0.067, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9772\n",
      "Epoch 9/10, Train Loss: 0.0569, Accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9784\n",
      "Epoch 10/10, Train Loss: 0.0476, Accuracy: 0.9658, F1 Micro: 0.9783, F1 Macro: 0.9766\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.98, F1 Macro: 0.9791\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.89      0.99      0.93       158\n",
      "        part       0.99      0.98      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4777, Accuracy: 0.9146, F1 Micro: 0.9146, F1 Macro: 0.9031\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2365, Accuracy: 0.935, F1 Micro: 0.935, F1 Macro: 0.9296\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1841, Accuracy: 0.9431, F1 Micro: 0.9431, F1 Macro: 0.9371\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1272, Accuracy: 0.9431, F1 Micro: 0.9431, F1 Macro: 0.9371\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1305, Accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.9417\n",
      "Epoch 6/10, Train Loss: 0.0869, Accuracy: 0.939, F1 Micro: 0.939, F1 Macro: 0.9338\n",
      "Epoch 7/10, Train Loss: 0.104, Accuracy: 0.939, F1 Micro: 0.939, F1 Macro: 0.9335\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0759, Accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.9421\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0619, Accuracy: 0.9553, F1 Micro: 0.9553, F1 Macro: 0.951\n",
      "Epoch 10/10, Train Loss: 0.0705, Accuracy: 0.9146, F1 Micro: 0.9146, F1 Macro: 0.9078\n",
      "\n",
      "Sentiment analysis accuracy: 0.9553, F1 Micro: 0.9553, F1 Macro: 0.951\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94        83\n",
      "    positive       0.99      0.94      0.97       163\n",
      "\n",
      "    accuracy                           0.96       246\n",
      "   macro avg       0.94      0.96      0.95       246\n",
      "weighted avg       0.96      0.96      0.96       246\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9252\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.88      0.93        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.89      0.99      0.93       152\n",
      "    positive       0.95      0.67      0.79        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.91      0.80      0.85       216\n",
      "weighted avg       0.90      0.90      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.99      0.98      0.98       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 138.20227122306824 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 8\n",
      "Sampling duration: 3.651885747909546 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5291, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4243, Accuracy: 0.8891, F1 Micro: 0.933, F1 Macro: 0.9312\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2772, Accuracy: 0.9531, F1 Micro: 0.971, F1 Macro: 0.9698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1839, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1312, Accuracy: 0.9665, F1 Micro: 0.9791, F1 Macro: 0.9782\n",
      "Epoch 6/10, Train Loss: 0.0991, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9756\n",
      "Epoch 7/10, Train Loss: 0.0833, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9759\n",
      "Epoch 8/10, Train Loss: 0.0697, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.975\n",
      "Epoch 9/10, Train Loss: 0.0575, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9771\n",
      "Epoch 10/10, Train Loss: 0.0509, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9757\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9791, F1 Macro: 0.9782\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.90      0.98      0.94       158\n",
      "        part       0.96      1.00      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.96      1.00      0.98      1061\n",
      "   macro avg       0.96      0.99      0.98      1061\n",
      "weighted avg       0.96      1.00      0.98      1061\n",
      " samples avg       0.96      1.00      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5101, Accuracy: 0.8917, F1 Micro: 0.8917, F1 Macro: 0.873\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2288, Accuracy: 0.9458, F1 Micro: 0.9458, F1 Macro: 0.9403\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1501, Accuracy: 0.9542, F1 Micro: 0.9542, F1 Macro: 0.95\n",
      "Epoch 4/10, Train Loss: 0.1524, Accuracy: 0.925, F1 Micro: 0.925, F1 Macro: 0.9156\n",
      "Epoch 5/10, Train Loss: 0.0907, Accuracy: 0.925, F1 Micro: 0.925, F1 Macro: 0.9161\n",
      "Epoch 6/10, Train Loss: 0.1269, Accuracy: 0.9458, F1 Micro: 0.9458, F1 Macro: 0.94\n",
      "Epoch 7/10, Train Loss: 0.1133, Accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.9456\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0722, Accuracy: 0.9542, F1 Micro: 0.9542, F1 Macro: 0.9495\n",
      "Epoch 9/10, Train Loss: 0.056, Accuracy: 0.9458, F1 Micro: 0.9458, F1 Macro: 0.9403\n",
      "Epoch 10/10, Train Loss: 0.0533, Accuracy: 0.9417, F1 Micro: 0.9417, F1 Macro: 0.9362\n",
      "\n",
      "Sentiment analysis accuracy: 0.9542, F1 Micro: 0.9542, F1 Macro: 0.9495\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.95      0.93        82\n",
      "    positive       0.97      0.96      0.96       158\n",
      "\n",
      "    accuracy                           0.95       240\n",
      "   macro avg       0.95      0.95      0.95       240\n",
      "weighted avg       0.95      0.95      0.95       240\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.9186\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.84      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.90      0.98      0.94       152\n",
      "    positive       0.92      0.69      0.79        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.86      0.81      0.83       216\n",
      "weighted avg       0.90      0.90      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.96      1.00      0.98       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.94      0.91      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 132.31613397598267 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.41936993598938 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5289, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4117, Accuracy: 0.9152, F1 Micro: 0.9482, F1 Macro: 0.9466\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2635, Accuracy: 0.9583, F1 Micro: 0.9741, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1739, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.131, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0931, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9794\n",
      "Epoch 7/10, Train Loss: 0.0794, Accuracy: 0.968, F1 Micro: 0.98, F1 Macro: 0.9789\n",
      "Epoch 8/10, Train Loss: 0.0644, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9736\n",
      "Epoch 9/10, Train Loss: 0.0544, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9747\n",
      "Epoch 10/10, Train Loss: 0.0493, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9762\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9794\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.97      0.94       158\n",
      "        part       0.99      0.98      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4958, Accuracy: 0.8854, F1 Micro: 0.8854, F1 Macro: 0.877\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2183, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9348\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1736, Accuracy: 0.9447, F1 Micro: 0.9447, F1 Macro: 0.9383\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1651, Accuracy: 0.9565, F1 Micro: 0.9565, F1 Macro: 0.9508\n",
      "Epoch 5/10, Train Loss: 0.1369, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9265\n",
      "Epoch 6/10, Train Loss: 0.0961, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9345\n",
      "Epoch 7/10, Train Loss: 0.0992, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9253\n",
      "Epoch 8/10, Train Loss: 0.0783, Accuracy: 0.9447, F1 Micro: 0.9447, F1 Macro: 0.9372\n",
      "Epoch 9/10, Train Loss: 0.0662, Accuracy: 0.9368, F1 Micro: 0.9368, F1 Macro: 0.9287\n",
      "Epoch 10/10, Train Loss: 0.0542, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9338\n",
      "\n",
      "Sentiment analysis accuracy: 0.9565, F1 Micro: 0.9565, F1 Macro: 0.9508\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.93        84\n",
      "    positive       0.96      0.97      0.97       169\n",
      "\n",
      "    accuracy                           0.96       253\n",
      "   macro avg       0.95      0.95      0.95       253\n",
      "weighted avg       0.96      0.96      0.96       253\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9614, F1 Micro: 0.9614, F1 Macro: 0.9258\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.94      0.99      0.97       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.82      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.92      0.97      0.94       152\n",
      "    positive       0.87      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.90      0.83      0.86       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.99      0.98      0.98       152\n",
      "    positive       0.93      0.90      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.95      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 137.16913485527039 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.931152105331421 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.527, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.398, Accuracy: 0.9234, F1 Micro: 0.9532, F1 Macro: 0.9517\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2441, Accuracy: 0.9546, F1 Micro: 0.9719, F1 Macro: 0.9706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1651, Accuracy: 0.9643, F1 Micro: 0.9777, F1 Macro: 0.9767\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1259, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0901, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9771\n",
      "Epoch 7/10, Train Loss: 0.0745, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9756\n",
      "Epoch 8/10, Train Loss: 0.0611, Accuracy: 0.9606, F1 Micro: 0.975, F1 Macro: 0.9726\n",
      "Epoch 9/10, Train Loss: 0.0534, Accuracy: 0.9613, F1 Micro: 0.9755, F1 Macro: 0.9733\n",
      "Epoch 10/10, Train Loss: 0.0441, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9752\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.92      0.93      0.92       158\n",
      "        part       0.99      0.99      0.99       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4766, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9201\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2158, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9229\n",
      "Epoch 3/10, Train Loss: 0.1744, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9237\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1477, Accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.9396\n",
      "Epoch 5/10, Train Loss: 0.1054, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9246\n",
      "Epoch 6/10, Train Loss: 0.0988, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9273\n",
      "Epoch 7/10, Train Loss: 0.1084, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9219\n",
      "Epoch 8/10, Train Loss: 0.0665, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9314\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0659, Accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.9396\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0561, Accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.9389\n",
      "\n",
      "Sentiment analysis accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.9389\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.93      0.92        83\n",
      "    positive       0.97      0.96      0.96       181\n",
      "\n",
      "    accuracy                           0.95       264\n",
      "   macro avg       0.94      0.94      0.94       264\n",
      "weighted avg       0.95      0.95      0.95       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9111\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.91      0.88      0.89        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.97      0.98      0.97       167\n",
      "    positive       0.85      0.85      0.85        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.88      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.92      0.93      0.93       152\n",
      "    positive       0.78      0.77      0.78        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.84      0.82      0.83       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.99      0.99      0.99       152\n",
      "    positive       0.97      0.90      0.94        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.69      0.82        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.86      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.96      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 143.72699284553528 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.3097946643829346 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5164, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3973, Accuracy: 0.9241, F1 Micro: 0.9536, F1 Macro: 0.9519\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2502, Accuracy: 0.9583, F1 Micro: 0.9742, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1663, Accuracy: 0.9665, F1 Micro: 0.9791, F1 Macro: 0.9783\n",
      "Epoch 5/10, Train Loss: 0.1254, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9748\n",
      "Epoch 6/10, Train Loss: 0.0912, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9774\n",
      "Epoch 7/10, Train Loss: 0.0753, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.975\n",
      "Epoch 8/10, Train Loss: 0.0621, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0499, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9778\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0423, Accuracy: 0.971, F1 Micro: 0.9818, F1 Macro: 0.9809\n",
      "\n",
      "Aspect detection accuracy: 0.971, F1 Micro: 0.9818, F1 Macro: 0.9809\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.99      0.98       175\n",
      "      others       0.90      0.97      0.94       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4774, Accuracy: 0.8976, F1 Micro: 0.8976, F1 Macro: 0.8902\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2531, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9189\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1563, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9167\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1555, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9267\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1262, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9398\n",
      "Epoch 6/10, Train Loss: 0.1026, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9192\n",
      "Epoch 7/10, Train Loss: 0.0688, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9297\n",
      "Epoch 8/10, Train Loss: 0.0695, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9233\n",
      "Epoch 9/10, Train Loss: 0.0619, Accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.9069\n",
      "Epoch 10/10, Train Loss: 0.0695, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9181\n",
      "\n",
      "Sentiment analysis accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9398\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.98      0.92        85\n",
      "    positive       0.99      0.93      0.96       169\n",
      "\n",
      "    accuracy                           0.94       254\n",
      "   macro avg       0.93      0.95      0.94       254\n",
      "weighted avg       0.95      0.94      0.95       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9622, F1 Micro: 0.9622, F1 Macro: 0.9236\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.97      0.99      0.98       167\n",
      "    positive       0.90      0.82      0.86        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.89      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.90      0.97      0.94       152\n",
      "    positive       0.93      0.71      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.86      0.81      0.83       216\n",
      "weighted avg       0.90      0.90      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.99      0.99       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 146.34039068222046 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.8276984691619873 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5299, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3922, Accuracy: 0.9323, F1 Micro: 0.9585, F1 Macro: 0.9574\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.244, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1553, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1205, Accuracy: 0.9643, F1 Micro: 0.9777, F1 Macro: 0.9767\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0926, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9787\n",
      "Epoch 7/10, Train Loss: 0.0762, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9783\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0594, Accuracy: 0.971, F1 Micro: 0.9818, F1 Macro: 0.9807\n",
      "Epoch 9/10, Train Loss: 0.0507, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9753\n",
      "Epoch 10/10, Train Loss: 0.043, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9778\n",
      "\n",
      "Aspect detection accuracy: 0.971, F1 Micro: 0.9818, F1 Macro: 0.9807\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.92      0.97      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4739, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.8979\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2431, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9301\n",
      "Epoch 3/10, Train Loss: 0.1763, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.921\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1477, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9317\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1245, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9297\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.106, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9309\n",
      "Epoch 7/10, Train Loss: 0.0614, Accuracy: 0.9038, F1 Micro: 0.9038, F1 Macro: 0.897\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0753, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9297\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0746, Accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9402\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0619, Accuracy: 0.9538, F1 Micro: 0.9538, F1 Macro: 0.9485\n",
      "\n",
      "Sentiment analysis accuracy: 0.9538, F1 Micro: 0.9538, F1 Macro: 0.9485\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.94      0.93        87\n",
      "    positive       0.97      0.96      0.97       173\n",
      "\n",
      "    accuracy                           0.95       260\n",
      "   macro avg       0.95      0.95      0.95       260\n",
      "weighted avg       0.95      0.95      0.95       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9637, F1 Micro: 0.9637, F1 Macro: 0.9302\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.97      0.98      0.97       167\n",
      "    positive       0.85      0.85      0.85        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.90      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.92      0.97      0.95       152\n",
      "    positive       0.91      0.75      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.89      0.85      0.87       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.95      0.88      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.95      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 156.1470673084259 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 8\n",
      "Sampling duration: 1.0017268657684326 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5299, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4002, Accuracy: 0.9226, F1 Micro: 0.9526, F1 Macro: 0.9512\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2483, Accuracy: 0.9479, F1 Micro: 0.9676, F1 Macro: 0.9658\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1593, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.117, Accuracy: 0.9702, F1 Micro: 0.9814, F1 Macro: 0.9806\n",
      "Epoch 6/10, Train Loss: 0.0953, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9777\n",
      "Epoch 7/10, Train Loss: 0.074, Accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9785\n",
      "Epoch 8/10, Train Loss: 0.0579, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9762\n",
      "Epoch 9/10, Train Loss: 0.0493, Accuracy: 0.9658, F1 Micro: 0.9783, F1 Macro: 0.9765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0429, Accuracy: 0.971, F1 Micro: 0.9817, F1 Macro: 0.9806\n",
      "\n",
      "Aspect detection accuracy: 0.971, F1 Micro: 0.9817, F1 Macro: 0.9806\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.94      0.94      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.98      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4802, Accuracy: 0.9432, F1 Micro: 0.9432, F1 Macro: 0.9363\n",
      "Epoch 2/10, Train Loss: 0.2307, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9326\n",
      "Epoch 3/10, Train Loss: 0.1679, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9289\n",
      "Epoch 4/10, Train Loss: 0.1496, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.9062\n",
      "Epoch 5/10, Train Loss: 0.111, Accuracy: 0.9242, F1 Micro: 0.9242, F1 Macro: 0.9148\n",
      "Epoch 6/10, Train Loss: 0.099, Accuracy: 0.9242, F1 Micro: 0.9242, F1 Macro: 0.9162\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.074, Accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.9393\n",
      "Epoch 8/10, Train Loss: 0.0643, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9201\n",
      "Epoch 9/10, Train Loss: 0.0522, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9326\n",
      "Epoch 10/10, Train Loss: 0.0513, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9197\n",
      "\n",
      "Sentiment analysis accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.9393\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        85\n",
      "    positive       0.96      0.96      0.96       179\n",
      "\n",
      "    accuracy                           0.95       264\n",
      "   macro avg       0.94      0.94      0.94       264\n",
      "weighted avg       0.95      0.95      0.95       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9614, F1 Micro: 0.9614, F1 Macro: 0.9228\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.96      0.99      0.97       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.95      0.94      0.94       152\n",
      "    positive       0.81      0.85      0.83        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.89      0.87      0.88       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 144.12416911125183 s\n",
      "Total runtime: 3175.6659018993378 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAACCoAAAHqCAYAAADInz0eAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAADbgElEQVR4nOzdd3xV9f3H8VcSspgBwt5EBBUFByCKq6I4qlVxV0HcCmiNrUrFVQftrxUnjloHCu7darWIC6sCRUVRwt5LwkggkHnv74+TBAJBEhJyM17Px+M87rnnnnvu56T8fv305p3PNyocDoeRJEmSJEmSJEmSJEmqAtGRLkCSJEmSJEmSJEmSJNUdBhUkSZIkSZIkSZIkSVKVMaggSZIkSZIkSZIkSZKqjEEFSZIkSZIkSZIkSZJUZQwqSJIkSZIkSZIkSZKkKmNQQZIkSZIkSZIkSZIkVRmDCpIkSZIkSZIkSZIkqcoYVJAkSZIkSZIkSZIkSVXGoIIkSZIkSZIkSZIkSaoyBhUkSZIkSVKNc8kll9C5c+dIlyFJkiRJkvaAQQVJqkSPPfYYUVFR9OvXL9KlSJIkSRXy3HPPERUVVep2yy23FJ/3n//8h8suu4yePXsSExNT7vBA0TUvv/zyUl+/9dZbi89JT0+vyC1JkiSpDrGflaTqrV6kC5Ck2mTixIl07tyZadOmMX/+fPbZZ59IlyRJkiRVyJ/+9Ce6dOlS4ljPnj2L91988UVeeeUVDjnkENq2bbtHn5GQkMAbb7zBY489RlxcXInXXnrpJRISEsjOzi5x/KmnniIUCu3R50mSJKnuqK79rCTVdU5UkKRKsmjRIr788kvGjh1LixYtmDhxYqRLKlVWVlakS5AkSVINcvLJJ3PRRReV2Hr37l38+n333UdmZib//e9/6dWr1x59xkknnURmZib//ve/Sxz/8ssvWbRoEaeeeupO74mNjSU+Pn6PPm97oVDIL40lSZJqseraz+5tfg8sqbozqCBJlWTixIk0bdqUU089lbPPPrvUoMLGjRu54YYb6Ny5M/Hx8bRv354hQ4aUGPmVnZ3NnXfeyb777ktCQgJt2rThrLPOYsGCBQB8+umnREVF8emnn5a49uLFi4mKiuK5554rPnbJJZfQsGFDFixYwCmnnEKjRo347W9/C8CUKVM455xz6NixI/Hx8XTo0IEbbriBrVu37lR3Wloa5557Li1atCAxMZHu3btz6623AvDJJ58QFRXFW2+9tdP7XnzxRaKiovjqq6/K/fOUJElSzdC2bVtiY2MrdI127dpx9NFH8+KLL5Y4PnHiRA488MASf/FW5JJLLtlpLG8oFOKhhx7iwAMPJCEhgRYtWnDSSSfxv//9r/icqKgoRowYwcSJEznggAOIj4/ngw8+AODbb7/l5JNPpnHjxjRs2JDjjz+er7/+ukL3JkmSpOotUv1sZX0/C3DnnXcSFRXFTz/9xIUXXkjTpk0ZMGAAAPn5+dx9992kpKQQHx9P586d+eMf/0hOTk6F7lmSKsqlHySpkkycOJGzzjqLuLg4LrjgAh5//HGmT59Onz59ANi8eTNHHXUUs2fP5tJLL+WQQw4hPT2dd999l+XLl5OcnExBQQG//vWvmTx5Mueffz7XX389mzZtYtKkScyaNYuUlJRy15Wfn8+gQYMYMGAAf/vb36hfvz4Ar732Glu2bOGaa66hefPmTJs2jUceeYTly5fz2muvFb//+++/56ijjiI2NpYrr7ySzp07s2DBAv75z39y7733cuyxx9KhQwcmTpzImWeeudPPJCUlhf79+1fgJytJkqRIysjI2Gkt3eTk5Er/nAsvvJDrr7+ezZs307BhQ/Lz83nttddITU0t88SDyy67jOeee46TTz6Zyy+/nPz8fKZMmcLXX3/NYYcdVnzexx9/zKuvvsqIESNITk6mc+fO/Pjjjxx11FE0btyYm266idjYWJ588kmOPfZYPvvsM/r161fp9yxJkqS9r7r2s5X1/ez2zjnnHLp168Z9991HOBwG4PLLL2f8+PGcffbZ3HjjjUydOpUxY8Ywe/bsUv/4TJKqikEFSaoEM2bMIC0tjUceeQSAAQMG0L59eyZOnFgcVPjrX//KrFmzePPNN0v8Qn/06NHFTePzzz/P5MmTGTt2LDfccEPxObfcckvxOeWVk5PDOeecw5gxY0oc/8tf/kJiYmLx8yuvvJJ99tmHP/7xjyxdupSOHTsCMHLkSMLhMN98803xMYA///nPQPAXaRdddBFjx44lIyODJk2aALB27Vr+85//lEj2SpIkqeYZOHDgTsf2tDf9JWeffTYjRozg7bff5qKLLuI///kP6enpXHDBBTz77LO7ff8nn3zCc889x3XXXcdDDz1UfPzGG2/cqd45c+bwww8/sP/++xcfO/PMM8nLy+OLL76ga9euAAwZMoTu3btz00038dlnn1XSnUqSJKkqVdd+trK+n91er169Skx1mDlzJuPHj+fyyy/nqaeeAuDaa6+lZcuW/O1vf+OTTz7huOOOq7SfgSSVh0s/SFIlmDhxIq1atSpu6qKiojjvvPN4+eWXKSgoAOCNN96gV69eO00dKDq/6Jzk5GRGjhy5y3P2xDXXXLPTse2b4KysLNLT0zniiCMIh8N8++23QBA2+Pzzz7n00ktLNME71jNkyBBycnJ4/fXXi4+98sor5Ofnc9FFF+1x3ZIkSYq8cePGMWnSpBLb3tC0aVNOOukkXnrpJSBYRuyII46gU6dOZXr/G2+8QVRUFHfcccdOr+3YSx9zzDElQgoFBQX85z//4YwzzigOKQC0adOGCy+8kC+++ILMzMw9uS1JkiRFWHXtZyvz+9kiV199dYnn77//PgCpqakljt94440AvPfee+W5RUmqVE5UkKQKKigo4OWXX+a4445j0aJFxcf79evH/fffz+TJkznxxBNZsGABgwcP/sVrLViwgO7du1OvXuX9v+d69erRvn37nY4vXbqU22+/nXfffZcNGzaUeC0jIwOAhQsXApS6htr2evToQZ8+fZg4cSKXXXYZEIQ3Dj/8cPbZZ5/KuA1JkiRFSN++fUssm7A3XXjhhVx88cUsXbqUt99+m//7v/8r83sXLFhA27Ztadas2W7P7dKlS4nna9euZcuWLXTv3n2nc/fbbz9CoRDLli3jgAMOKHM9kiRJqh6qaz9bmd/PFtmxz12yZAnR0dE7fUfbunVrkpKSWLJkSZmuK0l7g0EFSaqgjz/+mFWrVvHyyy/z8ssv7/T6xIkTOfHEEyvt83Y1WaFocsOO4uPjiY6O3uncE044gfXr13PzzTfTo0cPGjRowIoVK7jkkksIhULlrmvIkCFcf/31LF++nJycHL7++mseffTRcl9HkiRJddfpp59OfHw8Q4cOJScnh3PPPXevfM72f70mSZIkVZay9rN74/tZ2HWfW5FpvZK0txhUkKQKmjhxIi1btmTcuHE7vfbmm2/y1ltv8cQTT5CSksKsWbN+8VopKSlMnTqVvLw8YmNjSz2nadOmAGzcuLHE8fKkX3/44Qfmzp3L+PHjGTJkSPHxHceeFY293V3dAOeffz6pqam89NJLbN26ldjYWM4777wy1yRJkiQlJiZyxhlnMGHCBE4++WSSk5PL/N6UlBQ+/PBD1q9fX6apCttr0aIF9evXZ86cOTu9lpaWRnR0NB06dCjXNSVJklT3lLWf3Rvfz5amU6dOhEIh5s2bx3777Vd8fM2aNWzcuLHMy6xJ0t4QvftTJEm7snXrVt58801+/etfc/bZZ++0jRgxgk2bNvHuu+8yePBgZs6cyVtvvbXTdcLhMACDBw8mPT291EkERed06tSJmJgYPv/88xKvP/bYY2WuOyYmpsQ1i/YfeuihEue1aNGCo48+mmeeeYalS5eWWk+R5ORkTj75ZCZMmMDEiRM56aSTyvXFsiRJkgTw+9//njvuuIPbbrutXO8bPHgw4XCYu+66a6fXduxddxQTE8OJJ57IO++8w+LFi4uPr1mzhhdffJEBAwbQuHHjctUjSZKkuqks/eze+H62NKeccgoADz74YInjY8eOBeDUU0/d7TUkaW9xooIkVcC7777Lpk2bOP3000t9/fDDD6dFixZMnDiRF198kddff51zzjmHSy+9lEMPPZT169fz7rvv8sQTT9CrVy+GDBnC888/T2pqKtOmTeOoo44iKyuLjz76iGuvvZbf/OY3NGnShHPOOYdHHnmEqKgoUlJS+Ne//sXPP/9c5rp79OhBSkoKv//971mxYgWNGzfmjTfe2GktNICHH36YAQMGcMghh3DllVfSpUsXFi9ezHvvvcd3331X4twhQ4Zw9tlnA3D33XeX/QcpSZKkGuv777/n3XffBWD+/PlkZGRwzz33ANCrVy9OO+20cl2vV69e9OrVq9x1HHfccVx88cU8/PDDzJs3j5NOOolQKMSUKVM47rjjGDFixC++/5577mHSpEkMGDCAa6+9lnr16vHkk0+Sk5Pzi2sLS5IkqWaLRD+7t76fLa2WoUOH8ve//52NGzdyzDHHMG3aNMaPH88ZZ5zBcccdV657k6TKZFBBkipg4sSJJCQkcMIJJ5T6enR0NKeeeioTJ04kJyeHKVOmcMcdd/DWW28xfvx4WrZsyfHHH0/79u2BIEn7/vvvc++99/Liiy/yxhtv0Lx5cwYMGMCBBx5YfN1HHnmEvLw8nnjiCeLj4zn33HP561//Ss+ePctUd2xsLP/85z+57rrrGDNmDAkJCZx55pmMGDFipya6V69efP3119x22208/vjjZGdn06lTp1LXVzvttNNo2rQpoVBol+ENSZIk1S7ffPPNTn8tVvR86NCh5f5ityKeffZZDjroIJ5++mn+8Ic/0KRJEw477DCOOOKI3b73gAMOYMqUKYwaNYoxY8YQCoXo168fEyZMoF+/flVQvSRJkiIhEv3s3vp+tjT/+Mc/6Nq1K8899xxvvfUWrVu3ZtSoUdxxxx2Vfl+SVB5R4bLMhpEkqQzy8/Np27Ytp512Gk8//XSky5EkSZIkSZIkSVI1FB3pAiRJtcfbb7/N2rVrGTJkSKRLkSRJkiRJkiRJUjXlRAVJUoVNnTqV77//nrvvvpvk5GS++eabSJckSZIkSZIkSZKkasqJCpKkCnv88ce55ppraNmyJc8//3yky5EkSZIkSZIkSVI15kQFSZIkSZIkSZIkSZJUZZyoIEmSJEmSJEmSJEmSqoxBBUmSJEmSJEmSJEmSVGXqRbqAqhIKhVi5ciWNGjUiKioq0uVIkiSpAsLhMJs2baJt27ZER9e97K29rSRJUu1hb2tvK0mSVFuUp7etM0GFlStX0qFDh0iXIUmSpEq0bNky2rdvH+kyqpy9rSRJUu1jbytJkqTaoiy9bZ0JKjRq1AgIfiiNGzeOcDWSJEmqiMzMTDp06FDc49U19raSJEm1h72tva0kSVJtUZ7ets4EFYrGhjVu3NiGV5IkqZaoq6Nh7W0lSZJqH3tbe1tJkqTaoiy9bd1b9EySJEmSJEmSJEmSJEWMQQVJkiRJkiRJkiRJklRlDCpIkiRJkiRJkiRJkqQqY1BBkiRJkiRJkiRJkiRVGYMKkiRJkiRJkiRJkiSpyhhUkCRJkiRJkiRJkiRJVcaggiRJkiRJkiRJkiRJqjIGFSRJkiRJkiRJkiRJUpUxqCBJkiRJkiRJkiRJkqqMQQVJkiRJkiRJkiRJklRlDCpIkiRJkiRJkiRJkqQqY1BBkiRJkiRJkiRJkiRVGYMKkiRJkiRJkiRJkiSpyhhUkCRJkiRJkiRJkiRJVcaggiRJkspk7Vr45BNYsSLSlUiSJEkVlL0W1nwCW2xuJUmSVLNl5mTy+ZLPWZqxNNKllEu9SBcgSZKk6iUnB2bPhu+/L7mtWRO8Hh8PL78MZ5wR0TIlSZKk3SvIgczZsOF72Ljdll3Y3EbHw5EvQ4czIlqmJEmSVBY5+TnMXDOT6SumM23lNKavmE5aehphwsRGx/LIyY9w1WFXRbrMMjGoIEmSVEeFw7B8+c6BhDlzoKBg5/OjoiA5OZisMHgw/OMfMGxY1dctSZIk7SQchi3LS4YRNn4PmXMgXEpzSxTEJ0POWvhiMPT9B6TY3EqSJKn6KAgVkJaexvSV05m2YhrTV05n5uqZ5IXydjq3eWJz1m1dx9XvXc2MVTN45ORHiK8XH4Gqy86ggiRJUh2weTPMmrVzKCEjo/TzmzaFgw6CAw8MHg86CA44ABIS4Oqr4emn4dJLIT0d/vCHqr0XSZIk1XF5myFjVhBE2H5SQt4umtu4ppB0ECQdWPh4EDQ5AGISYPrVsOBpmHop5KTD/ja3kiSp+guHw6zevJq56+Yyd91coqKi6JHcg/2S96N5/eaRLq/CFm1YxBdLv+DX+/6apolNK+WaSzOWMmXJFL5Y+gWLNi7irP3O4pLelxAXE1cp16+ocDjMkowlTF8xvTiYMGPVDDbnbt7p3OaJzenbri992vahT7s+9Gnbh5YNWvLnL/7MrR/fylPfPMWsn2fx+rmv07ZR2wjcTdkYVJAkSarFcnLg7rvhr3+F3NydX69XD3r02BZGKAomtGsXTFAozVNPBZMV/vIXuOmmYMLCX/6y6/MlSZKkSlGQA7Puhtl/hVApzW1UPWjcIwgiND0ImhwYPCb+QnPb96lgssJPf4HvbgomLPS2uZUkSeWzNW8rqzavokX9FjSKb1Rp183MySwOIxRtc9bNYe66uaX+AhugRf0W7NdiP/ZLLtwK99s3bk9UNe5x1m9dz2s/vsaEHybwxdIvAGjXqB3Pn/k8v+ryq3JdKxQO8dPan/hi6RdMWTqFKUumsCxzWYlzPlzwIXd/fjc3H3kzlx9yOQn1EirtXspq0YZFTPxhIl8t/4rpK6azdsvanc5pENuAQ9seGoQS2vahb7u+dE7qXOp/lqOOGkXv1r258M0L+Wr5Vxz298N449w36N+hf1XcTrlFhcPhcKSLqAqZmZk0adKEjIwMGjduHOlyJElSLbd4cTCx4JhjoEmTyNTw9dfB1IPZs4PnbdpsCyQUbd27Q/weTgD729+2TVMYNgz+/vcg+FAV6npvV9fvX5IkVbHNi4OJBS2PgbgINbfpX8PXl0JmYXOb2GbbdISirXF3iNnD5nb23+Dbwua26zDo+3eIrprmtq73dnX9/iWptgmHw9X6l+EVEQ6HWblpJXPWzWFO+hzS0tOYsy54XJqxlDDBr1wbxjWkbaO227aGbUs+L9wSYxMByC3IZeGGhcxJn7MtkLB+LnPS57Ama80u64mOiqZzUmf2bb4voXCI2Wtn7/TL+O01jGtYPHVh+wBDSrMU6lVR37Oj7Pxs3pv7HhN+mMB7c98rXtIgiiiS6yezdstaooji90f8nnt+dc8upx/kFuQyY+WM4mDCf5f9l/Vb15c4JyYqhkPaHMJRHY+iWWIzxk0fx6rNqwBo3bA1fzjiD1x16FU0iGuwV++5IFTAhws+ZNz0cfx73r+L/90A1IuuR69WvYoDCX3a9WG/5P2IiY4p12fMXz+fM14+gx/X/khsdCxPnfYUQ3sPrexbKVV5ejuDCpIkSZVk82Z4/XUYPx4+/TQ4lpwMd90FV15Zdb/Ez8qC0aPhoYeCpXpbtYLHHoOzzqr8z3r2WbjiCigoCEIL//d/lf8ZpanrvV1dv39JklQF8jbDstdh4Xj4+dPgWHwyHHgX7HNllf0Sn/wsmDka5jwEhCGhFfR5DDrsheZ2wbMw7QoIF8B+f4CDq6a5reu9XV2/f0mqDcLhMG+lvcUtH93Cqs2rSGmawj7N9iGlaQopzbbtt2/cvty/cI2ErXlbmbd+3k5hhDnr5uxyigFAfEw8OQU5Zf6cpIQkGsc3ZnnmckLh0C7Pa9WgFfs235d9m+9L9+bdi/e7Nu1KfL2SIc3NuZtJS09j9trZwWP6bGanz2b++vnkh/JLvX5sdCzdmndjv+T9OKztYfRr148+7frQMK5hme+lPELhEFOWTGHC9xN47afXyMjZtnxXr1a9uOigi7ig5wUkJSRx439u5MkZTwJwcOuDmXjWRPZrsR+bcjbx1fKvgqUcln3B1OVT2Zq/tcTn1I+tz+HtD+eojkdxVMejOLz94SVCCNn52Tzz7TP8+Ys/Fwc8kusnc2P/G7m2z7U0jq/cviR9SzrPfPsMT/zvCRZtXFR8/MSUE/l1t1/Tt11ferXuVWmTHTbnbmbYO8N4c/abvH/h+wzaZ1ClXHd3DCqUwoZXkqQ9s3w5fPghfPRR8PyEE2DQoGBpgJoqOxv++9/gnr7/Hn7/ezjuuD27VigEn30WhBNefz0ICUAwKbZlS1hTGHreb79g+YVTTtm7U2Q/+QQuvxwWLgyeDxkCDzwAzZrtvc98550gGDFpErRuvfc+Z3t1vber6/cvSdIe27IcVn0Iqwub29YnQJtBUL8GN7cF2bD2v8E9bfwe9vs9tNrD5jYcgp8/C8IJy14PQgIAREFCS8gubG4b7wcH/xXa7uXmds0nMPVy2FzY3HYZAoc8APF7sbld/k4QjPjVJEismua2rvd2df3+Jammm5M+h5H/HsmkhZN2e25cTBxdkroUBxf2abZPcZChc1LnXf61fGXLD+Wzfut61m9dH0xISJ9TIoywZOOSEn/lvr2YqBi6Nu1K9+Tu9GjeI3hM7kH35t1Jrp9MVl4WqzatYuWmlSW3zdv2V2Su2OmX6g3jGhYHEPZttu+2/eb70iSh4hOtcgtyWbB+QRBcWDu7OMCQlp7GlrwtO50fHRVNz5Y96deuH4e3P5zD2x9Oj+QeREdF73ENP639iRdmvsDEHyaWmPzQvnF7fnvgb/ntgb/lwFYH7vS+d9Le4bJ3L2Pd1nUk1kukR3IPZq6ZuVO4I7l+MgM6DmBAhwEc1ekoDm59MLExsbutK7cglxdmvsB9X9zHwg1B39k0oSnX97ue6/pdR9PEpnt8z+FwmKkrpvLY9Md49cdXi4MsTROaMqz3MK4+7Gq6Ne+2x9cv6+cf3v7wvfYZOzKoUAobXkmSyiYnB6ZMgQ8+CAIKs2aVfl7PnnDSScE2YMCeLx9QFUKhIJAwaVIQTvj88yCsUCQuDiZOhLPPLvs1FywIwgnPPw9Llmw73q0bXHIJXHxx8Ev7v/8d7rwT0tOD1wcODJZM6NWrMu5sm4wMuOmm4PMAOnSAJ5+Ek0+u3M/Zlfz8qpsYAfZ2df3+JUkqs4IcWDsFVn4QBBQydtHcNukJbU+CNidBiwF7vnxAVQiHgkDCqklBOGHt50FYoUh0HBwxETqWo7ndtAAWjYdFz0PWds1to27Q9RLofHHwS/v5f4cf7oScwua29UA4+G/QtJKb29wM+O6m4PMA6neAvk9C2ypqbkP5VTcxAnu7un7/klRTbc7dzD2f38PYr8aSF8ojLiaOm464ifN7ns/ijYtZsGEB89fPL35ctGFR8Vj/0kRHRdOxSccS0xiKggwpTVNKHcefH8pnw9YNrN+6nnVb1xWHD9Zt2W5/6877mTmZu72/pISk4gDC9o8pzVIqHKgIh8Nk5mSyctNKNmRvoHNSZ9o0bBORJTNC4RDLMpYxO302P/78I9NWTuPr5V+zNGPpTuc2jm9M33Z9Obzd4fRr349+7frRokGLX7z+qk2reGnWS0z4fgLfrv62xLXO2f8cLjroIo7udPRuAxArN63kkrcvKRGI6ZzUuXhawoCOA+iR3KNCP8P8UD4v/fAS9065lznr5hTXOaLPCG7ofwPJ9ZPLfK2s3CxemvUSj01/rMR9H9rmUIb3Gc55Pc+jfmz9Pa61OjOoUAobXkmSShcOw/z5QTDhgw+CJQu2bBeijY6Gvn2DKQoQnDNtWvC+IvXrBxMJTjopOG+fffbuH1aVxbJlQTBh0iSYPBnWri35eps2wXSIdevgvfeCep94IliiYVcyM+G114KAwpQp2443bgznnx8EFA4/fOd7z8iA++6DBx+E3Nzg9WHD4J57gjoq6v334aqrgukXANdcA3/+c1BXbVXXe7u6fv+SJO1SOAyb5sOqD4JtzadQsF1zGxUNzfoGUxQgOGfdNNj+L+Zi6gcTCdqcFJzXqBo0t1nLYPWkwm0y5OzQ3Ca2CaZD5KyDle8BUdD3iWCJhl3Jy4SlrwXTE9Zu19zGNoZO50OXSyC5lOY2NwN+vA/mPAih3OCzug6DXvcEdVTUivdh+lXB9AuAbtdA7z8HddVSdb23q+v3L0k1TTgc5tUfX+XG/9zIik0rADi126k8eNKD7NNsn12+ryBUwLLMZSxYXzLAUPRY2l/1b691w9Z0SepCbkFucfBg+yUD9kRSQhIt6rcoXlKhR/K2CQkt6reISHCguli5aSVTl09l6oqpfL38a6avnF7qf0YpTVPo174fh7cLpi70at2LnPwc3kp7iwnfT2DyosnFkw9io2M5pdspXHTQRZza7VQSYxPLVVMoHOK9ue+RlZfFgI4DaN+4faXc644KQgW8/tPr3DPlHmb9HASdG8Q24JrDruHGI26kdcNdT92akz6HJ/73BM9+92zxv8+Eegmc3/N8rj3sWvq067NXaq5ODCqUwoZXkqRtNm0KlggoCicsWlTy9TZttk1LGDhw52UD1q0LJhMUTV1Ytark6127BoGFk04KAgyNGu3d+4EgDPDpp9vCCXPnlny9QQM49tggnDBwIOy/f/Cda0EBXHvttkkE990Ht9yy7fvYgoLgZ/Xcc/Dmm7C1cCpbdHRwrUsugd/8BhLL0FcvWgSjRsErr2yr6aab4MYbg/3yWrcOfvc7mDAheJ6SAv/4R3CftV1d7+3q+v1LklRC3qZgiYBVHwSTE7J2aG4T2xSGDk4KJgDsuGxAzrpgMsGqwqkLW3dobht2DQILbU4KAgyxVdDc5mbAz58WTk2YBJt2aG7rNYCWxwbhhNYDoUlhcxsqgP9du20SQa/7YP/tmttQAfz8CSx8Dpa9CQWFzW1UdHCtLpdA+99AvTI0t5sXwXejYOkr22ra7ybY78Zgv7xy1sGM38Hiwua2YQr0+we0Orb816ph6npvV9fvX5Jqkp/W/sTIf4/k40UfA9AlqQsPnfQQp3U/rULXDYfDrMlas8sQw/qt63/x/U3im9AssRnN6zenWWKzYD9xF/uF5yQlJFGvCico1XT5oXxm/TyLqcun8vWKr/l6+dekpaftdF58TDzRUdEllrY4osMRXHTgRZx7wLk0r9+8KsuukFA4xLtz3uXuz+/mm1XfAEHo4MpDruSmI2+iXeNg+bj8UD7/nPNPHvvfY3y08KPi96c0TeGaw67hkt6X1Kj7riiDCqWw4ZUk1WXhMMycuS1Y8N//Qt52k9ZiY+Goo7aFE3r2LPsfjYXD8MMP20IPX3yx87WPPHLbtQ86qHL+IC0vD77+OghMTJoUTHkoKNj2etEkiKJgwuGHB0s87OoeRo8OQgoAN9wQTCh4/vlgK5pUANCjRxBOuOgiaLeHSxl/9RWkpgb1A7RtG3z2xRcHdZfF66/D8OHw88/Be264Af70p2C6RV1Q13u7un7/kqQ6LhyGjTO3LeeQ/l/YfoxwdCy0OCoIFrQ9KVjWoTzN7cYftk1kWPvFztdOPnLbMhFJldTchvIg/esgMLF6UjDlIbxdc1s8CaIwmND8cNjVyOFwGL4fHUw9AOh+A3S7KljWYdHz2yYVADTuUbi0w0VQfw+b27VfwTepsK6wuU1sGwQkulwc1F0WS1+H/w2H7J+D93S/AQ76E9SrG81tXe/t6vr9S1JNkJmTyV2f3sXD0x4mP5RPQr0ERg0YxR+O+EO5/yp+T2zYuoEFGxaweONiEuollAgeNE1sauAgQjZs3cD0ldP5evnXxZMXikIl+zbfl4sOvIgLD7yQlGYpEa60YsLhMP+e/2/u/vxuvl4e9LxxMXEM6z2Mto3a8vcZfy+eLhJFFL/e99dc2+daTkw5cbdLWtRGBhVKYcMrSaqJsrNhzhyYNWvbtnAhhELlu866dTsvfZCSsi08cOyx0LBh5dS8eXPJaQ0LF5Z8vUULaF4JAdLly4PP2l63bkEw4YQTgntKSirfNR94IAgQ7CgpCS64IAgo9OlTOd9Fh8PBMhI33wyLFwfHDj4Y7r8/mEKxK6tXBwGFN98Mnu+/PzzzDPTrV/GaapK63tvV9fuXJNVQBdmQOQc2zoKMWcFj1kIIl7O5zVm389IHDVO2BRNaHguxldTc5m3eNq1h1QeweYfmNr4FxFdCc7tlOeTv0Nw26lY4MeGEYKpAXFL5rpn2QBAg2FFsEnS+IJie0LwSm9ulr8F3N0PW4uBY04PhkPuDKRS7snV1EFBYVtjcNtkf+j0DyXWrua3rvV1dv39Jqs7C4TAv/vAif5j0B1ZtDqZO/ab7b3hg0AN0adolwtWpugmHw8xfP5+cghwOaHFArVs6IxwOM3nRZO7+/G4+X/J5idda1G/B5YdczpWHXknnpM6RKbCaMKhQChteSdIvCYeD5RA2bICNG4Nf2icnQ+PGVbMcbX4+LFhQMpAwaxbMm1dySkBF1K8Pv/pVEEwYNAj22fWScZVq/vxtoYVPPoEtv7zcXLk0bx5MSyiamtCpU8Wv+fzzcOmlwb+Jk04KwgmnnQYJCRW/dmmys+GRR+CeeyAzMzh2+unwf/8H3btvOy8chhdeCJZ62LAB6tULlpG49VaIj987tVVndb23q+v3L0najXAY8jdB7gbI3Qj1GkJ8MsRWUXMbyofNC0oGEjJmwaZ5JacEVERMfWj1q8LJBoOgURU1t5vmF05y+CAIMBRUYnMb3xxaDdw2NaFBJTS3C5+HqZcC4SDI0fUSaHcaxOyl5rYgG+Y8Aj/eA3mFzW270+Hg/4PGOzS3i16Ab34X/DuNqgcHjIIDboWYutfc1vXerq7fvyRVVz+s+YER/x5R/AvZfZrtw8MnPczJ3U6OcGVS5H2+5HPGfjWWLXlbuKT3JQzebzDx9epeH1sagwqlsOGVpLohLy/4Je6GDbB+/bZt++e7eq20QEBsbBBYSE4OJgHsuL/jsebNf/mXxuEwLF26cyBh9mzIySn9PUlJcOCBcMABwZIM++676yUMdiUhAXr3jvwvtHNy4Ntvd32v5dG0afDzKOtSCeWxZEnwM2vVqvKvvStr18Jdd8ETTwT/FuvVg2uugdtvD8IdV10VhD0ADjkkmKLQq1fV1Vfd1PXerq7fvyTVGaG8wrDBBshZD7lF2/bPNwSPOz4vLRAQHRsEFuKTCycB7LCfsOOx5r/8S+NwGLYs3TmQkDEbQrto+GKTIOlAaHIAJPWERvtCdDmb25gEaNo78r/QLsiBDd8GjxUV1zT4eeyN0bBZSyA6ARKrsLnNXgs/3AXznwj+LUbVg27XQM/bg3DHtKuCsAdA00Pg8Gegad1tbut6b1fX71+SdhQOh8nOz2Zr/lay87PJLcglLiaOuJg44mPii/f31l+rb8zeyB2f3MG46eMoCBeQWC+R0UeP5sb+N/qLWEm7ZVChFDa8klQ7hMMwfjx8+WXp4YNNmyp2/bi4IBiwefOe/+V/48Y7Bxqio4MwwqxZOy9XUKR+/W1hhO23Nm2q5g/fVD2kpcFNN8E//xk8b9IkWOpj06YgaHLXXXDjjUGQoS6r671dXb9/Sao1wmFYNB7WfrktYLB9ECG/gs1tdFywXEDe5j3/y//YxjsHGqKigzBCxqydlysoElN/WxihSc9tj4k2t3VKRhp8dxOsKGxuY5sES33kb4LoeDjoLuhxI9TxdaWrW283btw4/vrXv7J69Wp69erFI488Qt++fUs9Ny8vjzFjxjB+/HhWrFhB9+7d+ctf/sJJJ51U5s+rbvcvqXpYsH4B46aPY9LCSUQRVfzL+diY2OAxOrbE8xLHomN3eX6Zr7HDsdiYWPJD+WzN21ocItiat7U4TLC7/TKfl7eVnDKGIItqja8XXyLEsOPzUs/Zxbl5oTzGTR/Hz1k/A3D2/mdz/4n307FJx735H7ekWqQ8vV3d/l8BkqQapaAAhg+HJ5/c/blNmkCzZsFf3Tdrtm3b/nlpryUmbvvedMsWSE/ftq1dW/p+0fN164IaMzODbeHC0muLjYUePXYOJHTuvHemA6hm6dED3n0XPv44CCR8911w/Mgj4emnSy4HIUmSarBQAfxvOMwvQ3Mb2wTimgV/dR/frHB/x+dNg8ftn8ds19zmb4Gc9G1b9trtnq8t+VrOWshZF/wlfF5msG3eRXMbHQuNe5QMIyT1hAad9850ANUsTXrAMe/C6o/h2xthw3fB8RZHQr+nSy4HoWrhlVdeITU1lSeeeIJ+/frx4IMPMmjQIObMmUPLli13On/06NFMmDCBp556ih49evDhhx9y5pln8uWXX3LwwQdH4A4k1WRF678/PPVh/jX3X4SpE39n+4uio6KDAEFBHgU7TMzKC+WRF8ojKy+r0j+3e/PuPHLyI5yQckKlX1uSijhRQZJUI+TkwEUXweuvB9+1Xn89pKSUHjho0iQyf20eCkFGRumBhpycbeGEbt2CsIK0OwUF8NprkJsb/Ps3yLJNXe/t6vr9S1KNV5ADX14Ey14HoqD79dAwpTBk0HRbECG+WRBSiMRfm4dDkJdReqChICcIJyT1hEbdgrCCtDuhAlj6GoRyoctFBlm2U516u379+tGnTx8effRRAEKhEB06dGDkyJHccsstO53ftm1bbr31VoYPH158bPDgwSQmJjJhwoQyfWZ1un9JkZGVm8UL37/AI9Me4ae1PxUfP3mfk7ns4MtoktCEvII8cgtyyS3IJS8U7Jd2bPvjJY7tyXt2OFYvuh6J9RJJjE0koV5CqfuJ9Xb9Wqnn7WY/NmZbn1UQKiiuLacgJ3jMz9nlsfKcU3wslEuftn24+rCriYsp5/JckoQTFSRJtcymTXDWWfDRR8HSDBMnwtlnR7qqnUVHB6GJpk1h330jXY1qg5gYOP/8SFchSZIqVd4mmHIWrP4oWJrhiInQsRo2t1HRhaGJpoDNrSpBdAx0trmtznJzc5kxYwajRo0qPhYdHc3AgQP56quvSn1PTk4OCQkJJY4lJibyxRdf7PJzcnJyyMnZNtY8MzOzgpVLqqkWb1zMo9Me5elvn2Zj9kYAGsY15JJelzCi7wi6Jzt5Z3sx0TEkRgdBB0mqDQwqSJKqtfR0OOUUmD4dGjSAt9+GgQMjXZUkSZK0B7LT4dNTYP10qNcAjn4bWtvcSqoe0tPTKSgooFWrViWOt2rVirS0tFLfM2jQIMaOHcvRRx9NSkoKkydP5s0336SgoKDU8wHGjBnDXXfdVam1S6o5wuEwny7+lIenPcy7c94lFA4BkNI0hZF9R3JJ70toktAkwlVKkqqCQQVJUrW1bBmceCKkpUHz5vD++9C3b6SrkiRJkvZA1jL45ETITIP45nDM+5BscyupZnvooYe44oor6NGjB1FRUaSkpDBs2DCeeeaZXb5n1KhRpKamFj/PzMykQ4cOVVGupAjakreFid9P5OFpDzPr51nFx09MOZHr+l7Hyd1OJtplgSSpTjGoIEmqltLSgpDCsmXQvj385z+w336RrkqSJEnaAxlpQUhhyzKo3x6O+w80sbmVVL0kJycTExPDmjVrShxfs2YNrVu3LvU9LVq04O233yY7O5t169bRtm1bbrnlFrp27brLz4mPjyc+Pr5Sa5dUfS3NWMq4aeN46pun2JC9AYD6sfUZ2msoI/qOYP8W+0e4QklSpBhUkCRVO9Onw8knw7p10KNHEFLwjyskSZJUI62bDp+eDDnroHGPIKTQwOZWUvUTFxfHoYceyuTJkznjjDMACIVCTJ48mREjRvziexMSEmjXrh15eXm88cYbnHvuuVVQsaTqKhwOM2XpFB6e+jBvpb1VvLxDl6QujOg7gksPvpSkhKTIFilJijiDCpKkauWjj+CMMyArC/r0CZZ7SE6OdFWSJEnSHlj9EXx+BuRnQbM+cOz7kGBzK6n6Sk1NZejQoRx22GH07duXBx98kKysLIYNGwbAkCFDaNeuHWPGjAFg6tSprFixgt69e7NixQruvPNOQqEQN910UyRvQ1KEbM3bykuzXuLhqQ8zc83M4uPHdzme6/pdx6ndTiUmOiaCFUqSqhODCpKkauP11+G3v4XcXDj+eHjrLWjUKNJVSZIkSXtg6evw5W8hlAutjoej34JYm1tJ1dt5553H2rVruf3221m9ejW9e/fmgw8+oFWrVgAsXbqU6Ohta8hnZ2czevRoFi5cSMOGDTnllFN44YUXSEpKitAdSIqE5ZnLeWz6Y/x9xt9Zt3UdAIn1Ern4oIsZ2W8kPVv2jHCFkqTqKCocDocjXURVyMzMpEmTJmRkZNC4ceNIlyNJ2sHf/w5XXw3hMJx9NkyYAC5ZKWlX6npvV9fvX5Kqvfl/h2lXA2HocDYcMQFibG4lla6u93Z1/f6lmiocDvPlsi95eNrDvPHTGxSECwDo2KQjI/qM4LJDLqNZYrMIVylJqmrl6e2if/HVXRg3bhydO3cmISGBfv36MW3atF2em5eXx5/+9CdSUlJISEigV69efPDBByXOufPOO4mKiiqx9ejRo8Q52dnZDB8+nObNm9OwYUMGDx7MmjVr9qR8Saq2srMhFIp0FVUrHIb77oOrrgr2r7oKXn7ZkIKkqmNvK0l7SUE2hOtgc/vjfTDtKiAM+1wFR75sSEGSJNUa2fnZjP9uPIc9dRgDnh3Aqz++SkG4gGM7H8ub577JgusW8Icj/2BIQZK0W+Ve+uGVV14hNTWVJ554gn79+vHggw8yaNAg5syZQ8uWLXc6f/To0UyYMIGnnnqKHj168OGHH3LmmWfy5ZdfcvDBBxefd8ABB/DRRx9tK6xeydJuuOEG3nvvPV577TWaNGnCiBEjOOuss/jvf/9b3luQpIjKyoL584Nt3rxgK9pftQqSkqBPH+jXb9vWokWkq947QiH4/e/hgQeC57feCnffDVFRka1LUt1hbytJFZSfBZvmF27zgm1z4f7WVRCbBM37QPN+kNwveEyopc1tOATf/B7mFDa3B9wKB9ncSpJUV23M3sirP77KKz++QnZ+Nu0ataN94/bbHhsHj20btSUuJi7S5e7Wyk0reXz64zw540nWblkLQEK9BH574G8Z2XckvVr3inCFkqSaptxLP/Tr148+ffrw6KOPAhAKhejQoQMjR47klltu2en8tm3bcuuttzJ8+PDiY4MHDyYxMZEJEyYAwV+dvf3223z33XelfmZGRgYtWrTgxRdf5OyzzwYgLS2N/fbbj6+++orDDz98t3U7QkxSVcrKggULSoYQivZXriz/9bp0KRlcOPhgSEio/LqrUl4eXHYZvPBC8HzsWLjhhsjWJKnmqKzezt5WksogPws2LSgZQtg0LwgnbN2D5rZBl22hheb9oNnBEFPDm9tQHnx9GSwubG4PGQs9bG4llU1d7+3q+v2rdskP5TNpwSTGzxzPO3PeITs/u0zva9mg5S6DDEXPG8U32svV7ywcDjN1xVQenvowr/30GvmhfADaN27P8D7DufyQy0mun1zldUmSqq/y9HblmqiQm5vLjBkzGDVqVPGx6OhoBg4cyFdffVXqe3JyckjY4bdpiYmJfPHFFyWOzZs3j7Zt25KQkED//v0ZM2YMHTt2BGDGjBnk5eUxcODA4vN79OhBx44dy/xlriRVti1bdj0ZYXdhhGbNoFs32Gef4LFov2tXWLYMpk7dts2eDYsWBdvLLwfvj42FXr22BRf69g2uEb1HC/pUvS1b4Lzz4F//gpgYeOYZGDIk0lVJqmvsbSVpO/lbguDBjkGETfN2H0aIawaNukGjfQofu0HDfaBhV9iyDNZNDbb0qZA5G7IWBduSwuY2OhaSem03daFvcI2oGtLc5m+BL86Dlf+CqBjo9wx0tbmVJKku+fHnHxk/czwTvp/Aqs2rio/v32J/hvYaStemXVmRuYLlmctZsankY25BLj9n/czPWT/z7epvd/kZjeIalRpg2D7YkFw/mehK6KFy8nN47afXeHjqw0xfOb34+FEdj+K6ftdxRo8zqBdd7oHdkiSVUK7/JklPT6egoIBWrVqVON6qVSvS0tJKfc+gQYMYO3YsRx99NCkpKUyePJk333yTgoKC4nP69evHc889R/fu3Vm1ahV33XUXRx11FLNmzaJRo0asXr2auLg4kpKSdvrc1atXl/q5OTk55OTkFD/PzMwsz61KEhD8Qn1XkxFWrPjl9zZrtnMQoeix2S8s0ZacHExMuPrq4HlGBkyfXjK88PPP8L//Bdu4ccF5SUlBYGH7yQvJEQ40b90KS5cG25Il2x6nTYO0tGAqxKuvwmmnRbZOSXWTva2kOid/C2xeUDKEUDwZYTfNbVyznYMIReGE+F9obhOSg4kJ3Qqb29wMWD89CC0UBRiyf4b1/wu2eYXNbWxSEFjYfvJCQoSb2/ytsGUpZC2FrCWF+0tg3TTITAumQhz5KrS3uZUkqS5I35LOSz+8xPiZ45mxakbx8eaJzbmg5wUM7T2UQ9scStQvLAMVDodZt3VdEFzYRZBhReYKMnIy2JS7idnps5mdPnuX14uLiaNto7a7DDK0b9yeNg3bEBsTW+r7V29ezZP/e5LH//c4a7LWFF/zwgMvZGTfkRzS5pA9/GlJkrSzvR55e+ihh7jiiivo0aMHUVFRpKSkMGzYMJ555pnic04++eTi/YMOOoh+/frRqVMnXn31VS677LI9+twxY8Zw1113Vbh+SbVfOAw//QRz5+4cSNhdGKFp09InI3Tr9sthhPJo0gQGDgy2onqXLCkZXPjmG9i4Ef7zn2Ar0rVryeBC796Vt2REOAzr1pUMIOz4uHbtL9/XP/8JRx1VOfVIUlWwt5VU7YXDkPETbJq7cyBht2GEpjuEELabkvBLYYTyiGsCrQcGW1G9WUu2TVxYNxU2fAN5G2H1f4KtSMOu20ILyf2gae/KWzIiHIacdbBlybYgQtbSks9zfqG5jW0Cx/wTWtrcSpJUm+UW5PL+vPcZP3M87819j7xQHgD1outxardTGdprKKfueypxMXFlul5UVBTJ9ZNJrp9M79a9d3ne5tzNOwcZMlewfNO2gMPPWT+TW5DL4o2LWbxx8a4/kyhaNWy1U5Dhp/SfeGXWK8X31LZRW6497FquOPQKWjZoWeafkSRJZVWuoEJycjIxMTGsWbOmxPE1a9bQunXrUt/TokUL3n77bbKzs1m3bh1t27bllltuoWvXrrv8nKSkJPbdd1/mz58PQOvWrcnNzWXjxo0l/vLslz531KhRpKamFj/PzMykQ4cOZb1VSXXEjBlw7bXBX/jvSlLSthDCjqGEygojlEdUFHTuHGznnRccy8uD778PQgvTpgWPaWmwcGGwvfRScF5sbBBW2D68sM8+wTV3lJcXBDV2DB8U7S9dGkyc2J2GDaFTp2Dr2HHb47HHQtu2lfMzkaQ9YW8rqdZZPwOmXxv8hf+uxCZtF0LYYbmGygojlEdUFDTsHGydCpvbUB5s/L4wuDAtCC9kpsHmhcG2pLC5jY6FpN4lpy402kVzG8qDLSu2TUEoDiMs2TYloaAMzW29htCgU7DV71i43xFaHgv1bW4lSaqNwuEw36z6hvEzx/PSrJdI35Je/NohbQ5haK+hXNDzAlo0aLHXamgY15Duyd3pntx9l+fkFuSyatOqkkGGHSY0rMhcQV4oj9WbV7N68+oSkyCKHNHhCK7rex1n7XfWLicvSJJUGcoVVIiLi+PQQw9l8uTJnHHGGQCEQiEmT57MiBEjfvG9CQkJtGvXjry8PN544w3OPffcXZ67efNmFixYwMUXXwzAoYceSmxsLJMnT2bw4MEAzJkzh6VLl9K/f/9SrxEfH098fHx5bk9SHbJ+Pdx6Kzz5ZPDHU4mJ0LNn6dMRmjePdLW7FxsLhx4abNdeGxzbuHHnJSPWrg2OTZ8Ojz4anNe0abBkxH77wZo12wIJK1dCKLT7z27deucQwvaPSUmlf1csSZFmbyup1shZDzNvhflPAmGISYQmPXcOIjTaB+JrQHMbHQvNDg02Cpvb3I2wbnrJyQs5a4NlJNZPBwqb27imwZIRjfeD7DXbgglbV0K4DM1tQutt4YMdwwgNOgVBD5tbSZLqhFWbVjHxh4k8991z/Lj2x+LjrRu25qIDL2Jo76H0bNkzghWWFBcTR6ekTnRK6rTLc0LhEOlb0ksNMiTWS+TSgy+lT7s+VVi1JKkuK/fSD6mpqQwdOpTDDjuMvn378uCDD5KVlcWwYcMAGDJkCO3atWPMmDEATJ06lRUrVtC7d29WrFjBnXfeSSgU4qabbiq+5u9//3tOO+00OnXqxMqVK7njjjuIiYnhggsuAKBJkyZcdtllpKam0qxZMxo3bszIkSPp378/hx9+eGX8HCTVEaEQPPss3HxzsGwBwG9/C3/9K7RpE9naKltSEpxwQrBBEMhYvHjnJSM2bIAPPwy2HcXFBYGDHcMHRfsdOoC/N5NUk9nbSqrRwiFY+Cx8d3OwbAFA59/CwX+FxFrW3MYlQZsTgg0Kl4xYvC20sG4qrP8GcjfAqg+DbUfRcYXBgx1DCIVBhPodIMbmVpKkuiw7P5t30t5h/MzxfLjgQ0KFQcf4mHjO6HEGQ3sN5YSUE6gXvddX1d4roqOiadmgJS0btOSQNodEuhxJUh1X7v82Pe+881i7di233347q1evpnfv3nzwwQe0atUKgKVLlxIdHV18fnZ2NqNHj2bhwoU0bNiQU045hRdeeKHEmNvly5dzwQUXsG7dOlq0aMGAAQP4+uuvadFi26ikBx54gOjoaAYPHkxOTg6DBg3iscceq8CtS6prvvkmmDYwdWrw/IADYNw4OOaYyNZVVaKioEuXYDv//OBYbu62JSMWLgzCGtuHEVq2hO3+X7ok1Tr2tpJqrPXfFC7zUNjcNjkADhsHrepQc9uwS7B1LmxuC3KDJSPWTQ2WiEhsUzKMkNASomxuJUlSSeFwmK+Wf8X478bzyo+vkJGTUfzaER2OYGivoZx7wLkkJSRFrkhJkmqhqHA4HI50EVUhMzOTJk2akJGRQePGjSNdjqQqtGEDjB4Njz8e/OFVw4Zw110wcmSwZIIkqeap671dXb9/qU7L3QAzR8O8x4Ew1GsIB94F3UcGSyZIkmqcut7b1fX7V+Qs2biEF75/gednPs+89fOKj3ds0pEhBw1hSK8hdGveLYIVSpJU85Snt6uZ84kkqQxCIRg/Hm66CdLTg2MXXhgs89C2bWRrkyRJksolHIKF4+G7myCnsLntdGGwzEN9m1tJkqSy2Jy7mTd+eoPxM8fzyeJPio83iG3A4P0HM7TXUI7tfCzRTmGSJGmvM6ggqVb69lsYPhy++ip4vv/+wTIPxx4b0bIkSZKk8lv/LfxvOKQXNrdN9i9c5uHYiJYlSZJUE4TCIT5d/CnjZ47njZ/eICsvq/i14zofx9BeQxm8/2AaxjWMYJWSJNU9BhUk1SobNsBttwXLPIRCwTIPd94J113nMg+SJEmqYXI3wMzbYP7jwUSFeg3hwDuh+3Uu8yBJkrQb89bN4/mZz/P898+zNGNp8fF9mu3D0F5Dufigi+mU1CmCFUqSVLcZVJBUK4RC8PzzwTIPa9cGx84/H/72N2jXLrK1SZIkSeUSDsGi5+HbmyCnsLntdD4c/Deob3MrSZK0KxuzN/Lqj68yfuZ4vlz2ZfHxJvFNOO+A8xjaeyj92/cnKioqglVKkiQwqCCpFvjuu2CZhy8L/7fHfvsFyzwcd1xEy5IkSZLKb8N3MH04pBc2t433gz7joJXNrSRJUmnyQ/lMWjCJ8TPH83ba2+QU5AAQHRXNoJRBDO01lNO7n05ibGKEK5UkSdszqCCpxtq4MVjm4bHHgokKDRpsW+YhLi7S1UmSJEnlkLsRvr8N5j1WuMxDg2CZh32vgxibW0mSpB3N+nkW478bz4QfJrB68+ri4z1b9mRor6FceOCFtG3UNoIVSpKkX2JQQVKNEwrBCy8Eyzz8/HNw7LzzgmUe2rePbG2SJElSuYRDsOgF+O4myC5sbjueB4f8Derb3EqSJG0vfUs6L/3wEs/NfI5vVn1TfLx5YnMuPPBCLul9CQe3PtilHSRJqgEMKkiqUWbODJZ5+O9/g+c9esCjj8Lxx0e2LkmSJKncNsyE/w2HtYXNbeMecNij0NrmVpIkaXs/rPmB2z+9nffmvkdeKA+A2OhYTt33VIb2Gsop3U4hzilUkiTVKAYVJNUIGzfCHXcEoYSiZR7uuAOuv95lHiRJklTD5G6E7++AeY9uW+ah5x3Q/XqXeZAkSdpBdn42J008iZWbVgJwaJtDGdprKBcceAHJ9ZMjXJ0kSdpTBhUkVWvhcLDMwx/+sG2Zh3PPhfvvd5kHSZIk1TDhcOEyD3/YbpmHc+GQ+13mQZIkaRf+8c0/WLlpJe0bt+eD337AAS0PiHRJkiSpEhhUkFRtff99sMzDF18Ez7t3DyYqDBwY2bokSZKkctvwfeEyD4XNbePuhcs82NxKkiTtSnZ+NmO+GAPArUfdakhBkqRaxKCCpGonI2PbMg8FBVC/Ptx+O9xwg8s8SJIkqYbJzYAf7oC5j0K4AGLqw4G3Q/cbXOZBkiRpN7afpjCs97BIlyNJkiqRQQVJ1UY4DBMnwu9/D2vWBMfOPhvGjoUOHSJbmyRJklQu4TAsngjf/h6yC5vbDmfDIWOhgc2tJEnS7mw/TeGPA/5IfL34CFckSZIqk0EFSdXCDz8EyzxMmRI833dfeOQROPHEyNYlSZIkldvGH2D6cFhb2Nw22hcOewTa2NxKkiSV1fbTFC49+NJIlyNJkiqZQQWpFtiyBd55BzIzITk52Fq0CB6bNYN61fj/0jMz4c474eGHty3zcNttwTIP8YakJUmS6p78LbD8HcjLhPjkYEtoETzGNYPoatzc5mXC93fC3Ie3LfPQ8zbocQPE2NxKkiSVVXZ+Nn/+4s+A0xQkSaqtqvE3PJJ2Z+FCePxxePpp2LCh9HOioqBp050DDL+036hR8L69KRyGF18MlnlYvTo4NnhwsMxDx45797MlSZJUDW1eCPMehwVPQ+4umluiIK7pzgGG+GSI32E/oXC/XhU1t4tfLFzmobC57TC4cJkHm1tJkqTyevqbp1mxaYXTFCRJqsUMKkg1TCgEkybBuHHwr38F34kCdOkCBx0E69bB2rWQng7r1wevr18fbHPnlu0z4uLKF2xITg7eU1azZgXLPHz+efC8W7dgmYdBg8r3s5AkSVINFw7Bqkkwbxys+BdQ2Nw26AJND4KcdZCzFnLSIWd98Hru+mDbVMbmNjqu9DDDLkMOyRBTjuZ24yz433D4ubC5bdQNDn0E2trcSpIk7Yns/GzGfDEGgFEDRjlNQZKkWsqgglRDZGTA+PFBQGH7wMGgQTBiBJx8MsTElHxPfn4waSE9fVt4Yfv90o5t2QK5ubByZbCVVePGuw82NG8Ob74JDz0ULPOQmAijR8ONN7rMgyRJUp2SmwGLxsPccSUDB20Gwb4joM3JEL1DcxvKDyYt5KRvF15Ih+y1uz5WsAVCubB1ZbCVVWzjMgQbmsOyN2HOQ4XLPCRCz9HQ40aXeZAkSaqAomkK7Rq147KDL4t0OZIkaS8xqCBVcz/+GIQTnn8esrKCY40bw7BhcO21sO++u35vvXpBQKBFC9hvv7J93pYtO4cXfinosG5dMOUhMzPYFi4s2+ecdVawzEOnTmU7X5IkSbXAxh+D6QmLnof8wuY2tjF0HQbdroXGv9DcRtcLwgIJLYAyNrf5W0oJNOwQaijaz14LueuCKQ95mcG2uYzNbYezCpd5sLmVJEmqiJz8nOJpCn886o9OU5AkqRYzqCBVQ/n58O678Oij8Mkn244fcEAwPeGii6Bhw73z2fXrQ8eOwVYWoRBs3Fj2iQ3NmsE998BJJ+2d+iVJklTNhPJhxbsw91FYs11z2+SAYHpC54sgdi81t/XqQ72O0KCMzW04BLkbyz6xIb4ZHHQPtLW5lSRJqgxPf+s0BUmS6gqDClI18vPP8I9/wOOPw/LlwbHoaDjjjCCgcOyxEBUVyQp3Fh0dhA+aNYPu3SNdjSRJkqqN7J9hwT9g3uOwpbC5jYqG9mcEAYWWx1a/5jYqOggfxDcDbG4lSZKqUk5+DvdNuQ9wmoIkSXWBQQWpGpg+HR55BF55BXJzg2PJyXDllXDVVWWfbiBJkiRF3LrpMOcRWPoKhAqb2/hk2OdK2Oeqsk83kCRJUp3iNAVJkuoWgwpShGRnw2uvBcs7TJu27XjfvsH0hHPOgYSEyNUnSZIklVlBNix9LVjeYd12zW3zvsH0hI7nQIzNrSRJkkq3/TSFUQNGOU1BkqQ6wKCCVMWWLYMnnoCnnoK1a4NjcXFw/vkwfHgQVJAkSZJqhKxlMP8JmP8U5BQ2t9Fx0Ol86DYckm1uJUmStHslpikc4jQFSZLqAoMKUhUIh+HTT4PpCW+/DaFQcLx9e7jmGrj8cmjZMpIVSpIkSWUUDsPPnwbTE5a/DeHC5rZ+e+h2DaRcDgk2t5IkSSqbnPwcxnwxBgimKSTUcxKXJEl1gUEFaS/avBkmTAgCCj/+uO34cccFyzucfjrU8/8KJUmSVBPkbYbFE4KAQsZ2zW2r44LlHdqdDtE2t5IkSSqfZ759huWZy52mIElSHeO3SNJeMHcuPPYYPPssZGYGxxo0gCFDguUdDjggsvVJkiRJZZY5F+Y9BgufhbzC5rZeA+gyJFjeIcnmVpIkSXsmJz+H+764D3CagiRJdY1BBamSFBTAv/8dTE/48MNtx7t1C6YnDB0KTZpErj5JkiSpzEIFsOrfwfSEVds1t426BdMTugyFOJtbSZIkVUzRNIW2jdo6TUGSpDrGoIJUQevXwzPPBBMUFi0KjkVFwamnBgGFE06A6OjI1ihJkiSVSc56WPgMzH0MsgqbW6Kg7alBQKHNCRBlcytJkqSKc5qCJEl1m0EFaQ99910wPWHiRMjODo41bQqXXQbXXANdu0a0PEmSJKnsNnwXTE9YPBEKCpvbuKaQchl0uwYa2txKkiSpcj373bPF0xQuP+TySJcjSZKqmEEFqRxyc+HNN4OAwn//u+14r14wciRccAHUrx+5+iRJkqQyK8iFZW/CvEdh7XbNbVIv6D4SOl0A9WxuJUmSVPly8nO4b4rTFCRJqssMKkhlsGoV/P3v8OSTwT5AvXpw9tnB8g5HHBEs9yBJkiRVe1tXwfy/w/wng32AqHrQ8exgeYdkm1tJkiTtXc9+9yzLMpc5TUGSpDrMoIK0C+EwfPllMD3h9dchPz843ro1XHVVsLVpE9kaJUmSpDIJhyH9y2B5h6WvQ7iwuU1oDftcBd2ugkSbW0mSJO19209TuOXIW5ymIElSHWVQQdrBli3w0ktBQOG777YdP/LIYHrCWWdBXFzEypMkSZLKLn8LLHkpCChs+G7b8RZHQrcR0OEsiLG5lSRJUtUpmqbQpmEbrjj0ikiXI0mSIsSggrSdiRNh5EjYsCF4npAAv/0tDB8OBx8c2dokSZKkclk0EWaMhNzC5jYmATr/FroNh2Y2t5IkSap6uQW5xdMURg0Y5TQFSZLqMIMKUqGNG4PlHLKyoHNnuPZauPRSaN480pVJkiRJ5ZS7EaZfBflZ0KAzdLsWUi6FeJtbSZIkRc6z3zpNQZIkBaIjXYBUXTz1VBBS6NkT5s+HP/zBkIIkSZJqqPlPBSGFJj3htPmw/x8MKUiSpDIZN24cnTt3JiEhgX79+jFt2rRfPP/BBx+ke/fuJCYm0qFDB2644Qays7OrqFrVJLkFudw75V7AaQqSJMmgggRAXh48/HCwn5oKMTGRrUeSJEnaY6E8mFvY3PZIhWibW0mSVDavvPIKqamp3HHHHXzzzTf06tWLQYMG8fPPP5d6/osvvsgtt9zCHXfcwezZs3n66ad55ZVX+OMf/1jFlasmcJqCJEnankEFCXj9dVi+HFq1ggsvjHQ1kiRJUgUsfR22LIeEVtDZ5laSJJXd2LFjueKKKxg2bBj7778/TzzxBPXr1+eZZ54p9fwvv/ySI488kgsvvJDOnTtz4okncsEFF+x2CoPqntyCXO774j4Abhlwi9MUJEmSQQUpHIb77w/2hw+H+PjI1iNJkiTtsXAY0gqb227DIcbmVpIklU1ubi4zZsxg4MCBxceio6MZOHAgX331VanvOeKII5gxY0ZxMGHhwoW8//77nHLKKbv8nJycHDIzM0tsqv2e++45lmYsDaYpHOI0BUmSBPUiXYAUaVOmwIwZkJAA11wT6WokSZKkClg7BdbPgJgE6GZzK0mSyi49PZ2CggJatWpV4nirVq1IS0sr9T0XXngh6enpDBgwgHA4TH5+PldfffUvLv0wZswY7rrrrkqtXdVbbkEu9065FwimKSTGJka4IkmSVB04UUF13tixwePQoZCcHNlaJEmSpApJK2xuuwyFBJtbSZK0d3366afcd999PPbYY3zzzTe8+eabvPfee9x99927fM+oUaPIyMgo3pYtW1aFFSsSnKYgSZJK40QF1Wnz5sG77wb7v/tdREuRJEmSKiZzHiwvbG67/y6ipUiSpJonOTmZmJgY1qxZU+L4mjVraN26danvue2227j44ou5/PLLATjwwAPJysriyiuv5NZbbyU6eue/k4uPjyfetVfrjO2nKdx85M1OU5AkScX2aKLCuHHj6Ny5MwkJCfTr1694DbLS5OXl8ac//YmUlBQSEhLo1asXH3zwQYlzxowZQ58+fWjUqBEtW7bkjDPOYM6cOSXOOfbYY4mKiiqxXX311XtSvlTswQeDZXxPPRV69Ih0NZIkKRLsbVVrzHkQCEPbU6GJza0kSSqfuLg4Dj30UCZPnlx8LBQKMXnyZPr371/qe7Zs2bJTGCEmJgaAcDi894pVjVE0TaF1w9ZceeiVkS5HkiRVI+UOKrzyyiukpqZyxx138M0339CrVy8GDRrEzz//XOr5o0eP5sknn+SRRx7hp59+4uqrr+bMM8/k22+/LT7ns88+Y/jw4Xz99ddMmjSJvLw8TjzxRLKyskpc64orrmDVqlXF2//93/+Vt3yp2Pr18OyzwX5qamRrkSRJkWFvq1ojZz0sLGxue9jcSpKkPZOamspTTz3F+PHjmT17Ntdccw1ZWVkMGzYMgCFDhjBq1Kji80877TQef/xxXn75ZRYtWsSkSZO47bbbOO2004oDC6q7cgtyuW/KfQDccuQtTlOQJEklRIXLGW3t168fffr04dFHHwWCVG2HDh0YOXIkt9xyy07nt23blltvvZXhw4cXHxs8eDCJiYlMmDCh1M9Yu3YtLVu25LPPPuPoo48Ggr866927Nw8++GB5yi2WmZlJkyZNyMjIoHHjxnt0DdUuY8bAH/8IvXvDN99AVFSkK5IkSWVVWb2dva1qjR/HwMw/QtPecJLNrSRJNUl16+0effRR/vrXv7J69Wp69+7Nww8/TL9+/YCgj+3cuTPPPfccAPn5+dx777288MILrFixghYtWnDaaadx7733kpSUVKbPq273r8rz1IynuPJfV9K6YWsWXrfQoIIkSXVAeXq7ck1UyM3NZcaMGQwcOHDbBaKjGThwIF999VWp78nJySEhIaHEscTERL744otdfk5GRgYAzZo1K3F84sSJJCcn07NnT0aNGsWWLVt2eY2cnBwyMzNLbFKR3Fx45JFgPzXV73ElSaqL7G1VaxTkwtzC5raHza0kSaqYESNGsGTJEnJycpg6dWpxSAHg008/LQ4pANSrV4877riD+fPns3XrVpYuXcq4cePKHFJQ7ZVbkMu9U+4FnKYgSZJKV688J6enp1NQUECrVq1KHG/VqhVpaWmlvmfQoEGMHTuWo48+mpSUFCZPnsybb75JQUFBqeeHQiF+97vfceSRR9KzZ8/i4xdeeCGdOnWibdu2fP/999x8883MmTOHN998s9TrjBkzhrvuuqs8t6c65JVXYNUqaNMGzjsv0tVIkqRIsLdVrbH0Fdi6ChLbQEebW0mSJEXe+O/GsyRjCa0btubKQ6+MdDmSJKkaKldQYU889NBDXHHFFfTo0YOoqChSUlIYNmwYzzzzTKnnDx8+nFmzZu30V2lXXrmtmTnwwANp06YNxx9/PAsWLCAlJWWn64waNYrU1G1rs2ZmZtKhQ4dKuivVZOEw3H9/sD9yJMTFRbYeSZJUc9jbqtoJh2F2YXO770iIsbmVJElSZG0/TeHmI292moIkSSpVuZZ+SE5OJiYmhjVr1pQ4vmbNGlq3bl3qe1q0aMHbb79NVlYWS5YsIS0tjYYNG9K1a9edzh0xYgT/+te/+OSTT2jfvv0v1lI0cmz+/Pmlvh4fH0/jxo1LbBLAJ5/AzJlQvz5cdVWkq5EkSZFib6taYc0nsHEmxNSHfWxuJUmSFHnPz3y+eJrCVYfao0qSpNKVK6gQFxfHoYceyuTJk4uPhUIhJk+eTP/+/X/xvQkJCbRr1478/HzeeOMNfvOb3xS/Fg6HGTFiBG+99RYff/wxXbp02W0t3333HQBt2rQpzy1IjB0bPA4bBjssFS1JkuoQe1vVCmmFzW3XYRBvcytJkqTIcpqCJEkqq3Iv/ZCamsrQoUM57LDD6Nu3Lw8++CBZWVkMGzYMgCFDhtCuXTvGjBkDwNSpU1mxYgW9e/dmxYoV3HnnnYRCIW666abiaw4fPpwXX3yRd955h0aNGrF69WoAmjRpQmJiIgsWLODFF1/klFNOoXnz5nz//ffccMMNHH300Rx00EGV8XNQHZGWBu+9B1FRcP31ka5GkiRFmr2tarSMNFj5HhAF3W1uJUmSFHnPz3yexRsXO01BkiTtVrmDCueddx5r167l9ttvZ/Xq1fTu3ZsPPviAVq1aAbB06VKio7cNasjOzmb06NEsXLiQhg0bcsopp/DCCy+QlJRUfM7jjz8OwLHHHlvis5599lkuueQS4uLi+Oijj4q/OO7QoQODBw9m9OjRe3DLqsseeCB4PP106NYtsrVIkqTIs7dVjTansLltfzo0trmVJElSZG0/TeGmI25ymoIkSfpFUeFwOBzpIqpCZmYmTZo0ISMjwzV966i1a6FjR8jOhs8/h6OOinRFkiRpT9X13q6u37+A7LXwTkcoyIaBn0NLm1tJkmqqut7b1fX7r03+8c0/uOKfV9CqQSsWXr+Q+rH1I12SJEmqYuXp7aJ/8VWpFnniiSCkcNhhMGBApKuRJEmSKmDeE0FIodlh0MLmVpIkSZGVV5BXPE3h5iNvNqQgSZJ2y6CC6oTsbHj00WA/NRWioiJbjyRJkrTHCrJhXmFz28PmVpIkSZH3/MznWbxxMa0atOKqw66KdDmSJKkGMKigOuGll+Dnn6F9ezj77EhXI0mSJFXA4pcg+2eo3x462txKkiQpsvIK8rhnyj2A0xQkSVLZGVRQrRcOw9ixwf5110FsbGTrkSRJkvZYOAxphc3tvtdBtM2tJEmSIstpCpIkaU8YVFCtN2kSzJoFDRvCFVdEuhpJkiSpAlZPgoxZUK8h7GNzK0mSpMjafprCTUfe5DQFSZJUZgYVVOsVTVO47DJISopoKZIkSVLFFE1TSLkM4pIiWookSZL0wvcvsHjjYlo2aMnVh10d6XIkSVINYlBBtdqsWfDhhxAdHSz7IEmSJNVYG2fBqg8hKhq629xKkiQpsvIK8rjn82Caws1H3uw0BUmSVC4GFVSrPfBA8HjmmdC1a2RrkSRJkiokrbC5bX8mNLS5lSRJUmS98P0LLNq4yGkKkiRpjxhUUK21Zg1MmBDs33hjZGuRJEmSKmTrGlhc2Nz2sLmVJElSZG0/TeGmI25ymoIkSSo3gwqqtR57DHJz4fDDoX//SFcjSZIkVcC8xyCUC80PhxY2t5IkSYospylIkqSKMqigWmnr1iCoAJCaGtlaJEmSpArJ3xoEFQD2s7mVJElSZOUV5HHvlHuBYJpCg7gGEa5IkiTVRAYVVCtNmADp6dCpE5x5ZqSrkSRJkipg8QTISYcGnaC9za0kSZIia8L3E1i4YaHTFCRJUoUYVFCtEwrB2LHB/vXXQ716ka1HkiRJ2mPhEKQVNrfdr4dom1tJkiRFTl5BHvdMuQdwmoIkSaoYgwqqdT74ANLSoHFjuOyySFcjSZIkVcDKDyAzDWIbQ4rNrSRJkiKraJpCi/otnKYgSZIqxKCCap2iaQpXXBGEFSRJkqQaq2iaQsoVQVhBkiRJipAS0xSOdJqCJEmqGIMKqlVmzoTJkyEmBkaOjHQ1kiRJUgVsmAlrJkNUDHS3uZUkSVJkbT9N4ZrDrol0OZIkqYYzqKBapWiawtlnQ6dOka1FkiRJqpCiaQodzoYGNreSJEmKnPxQPvdOuRdwmoIkSaocBhVUa6xcCS+9FOynpka2FkmSJKlCtqyEJYXNbQ+bW0mSJEXWhO8nsGDDAqcpSJKkSmNQQbXGuHGQlwcDBkDfvpGuRpIkSaqAeeMglActBkCyza0kSZIiJz+Uzz2f3wPAH474g9MUJElSpTCooFohKwueeCLYd5qCJEmSarT8LJhX2Nw6TUGSJEkRVjRNIbl+Mtf2uTbS5UiSpFrCoIJqheefh/XrISUFTj890tVIkiRJFbDoechdDw1ToJ3NrSRJkiJn+2kKNx1xk9MUJElSpTGooBovFIIHHgj2f/c7iImJaDmSJEnSnguHIK2wue3+O4i2uZUkSVLkTPx+otMUJEnSXmFQQTXev/4F8+ZBUhJcckmkq5EkSZIqYMW/YNM8iE2CrpdEuhpJkiTVYfmhfO7+/G7AaQqSJKnyGVRQjTd2bPB41VXQsGFka5EkSZIqJK2wue12FcTa3EqSJClynKYgSZL2JoMKqtFmzIDPPoN69WDEiEhXI0mSJFXA+hnw82cQVQ/2tbmVJElS5Gw/TeEPR/zBaQqSJKnSGVRQjVY0TeG886B9+8jWIkmSJFXI7MLmttN5UN/mVpIkSZHjNAVJkrS3GVRQjbVsGbz6arCfmhrZWiRJkqQKyVoGSwub2x42t5IkSYqc/FA+90y5BwimKTSMc0kySZJU+QwqqMZ69FHIz4djj4VDDol0NZIkSVIFzH0UwvnQ8lhoZnMrSZKkyHnxhxeZv36+0xQkSdJeZVBBNdLmzfDkk8G+0xQkSZJUo+VthvmFza3TFCRJkhRB+aF87v78bgB+3//3TlOQJEl7jUEF1UjPPgsZGbDvvnDqqZGuRpIkSaqAhc9CXgY02hfa2dxKkiQpcoqmKTRPbM7wvsMjXY4kSarFDCqoxikogAcfDPZvuAGi/VcsSZKkmipUAHMeDPZ73ABRNreSJEmKjO2nKfzhiD84TUGSJO1VfgumGuedd2DhQmjWDIYMiXQ1kiRJUgWseAc2L4S4ZtDF5laSJEmR89IPLzlNQZIkVRmDCqpxxo4NHq+5BurXj2wtkiRJUoWkFTa33a6Beja3kiRJigynKUiSpKpmUEE1ytSp8N//QmwsDDfUK0mSpJosfSqs/S9Ex8K+NreSJEmKnJd+eIl56+c5TUGSJFUZgwqqUYqmKVx4IbRpE9laJEmSpAopmqbQ6UJItLmVJElSZGw/TeH3R/zeaQqSJKlKGFRQjbF4Mbz+erCfmhrRUiRJkqSK2bwYlhU2tz1sbiVJkhQ5JaYp9HGagiRJqhoGFVRjPPIIhEIwcCAcdFCkq5EkSZIqYO4jEA5B64HQ1OZWkiRJkZEfyueeKfcAwTSFRvGNIlyRJEmqKwwqqEbIzISnngr2naYgSZKkGi0vE+YXNrdOU5AkSVIEvTzrZeaum+s0BUmSVOUMKqhGePpp2LQJ9tsPBg2KdDWSJElSBSx4GvI3QeP9oI3NrSRJkiIjP5TP3Z/fDcCN/W90moIkSapSBhVU7eXnw0MPBfupqRDtv1pJkiTVVKF8mFPY3PZIhSibW0mSJEVG0TSFZonNGNF3RKTLkSRJdYzfiqnae/NNWLIEWrSA3/420tVIkiRJFbDsTchaAvEtoLPNrSRJqn7GjRtH586dSUhIoF+/fkybNm2X5x577LFERUXttJ166qlVWLH2REGooHiawu/7/95pCpIkqcoZVFC1Fg7D/fcH+9deC4mJka1HkiRJ2mPhMKQVNrfdroV6NreSJKl6eeWVV0hNTeWOO+7gm2++oVevXgwaNIiff/651PPffPNNVq1aVbzNmjWLmJgYzjnnnCquXOXlNAVJkhRpexRUKE+qNi8vjz/96U+kpKSQkJBAr169+OCDD8p9zezsbIYPH07z5s1p2LAhgwcPZs2aNXtSvmqQr76CadMgPj4IKkiSJFU2e1tVmfSvYN00iI6HfW1uJUlS9TN27FiuuOIKhg0bxv77788TTzxB/fr1eeaZZ0o9v1mzZrRu3bp4mzRpEvXr1zeoUM0VhAr40+d/ApymIEmSIqfcQYXypmpHjx7Nk08+ySOPPMJPP/3E1VdfzZlnnsm3335brmvecMMN/POf/+S1117js88+Y+XKlZx11ll7cMuqSYqmKVx8MbRsGdlaJElS7WNvqypVNE2hy8WQYHMrSZKql9zcXGbMmMHAgQOLj0VHRzNw4EC++uqrMl3j6aef5vzzz6dBgwZ7q0xVAqcpSJKk6iAqHA6Hy/OGfv360adPHx599FEAQqEQHTp0YOTIkdxyyy07nd+2bVtuvfVWhg8fXnxs8ODBJCYmMmHChDJdMyMjgxYtWvDiiy9y9tlnA5CWlsZ+++3HV199xeGHH77bujMzM2nSpAkZGRk0bty4PLesCFmwALp1CybkzpoFBxwQ6YokSVJ1UVm9nb2tqsymBfDPbkAYTpkFSTa3kiQpUF16u5UrV9KuXTu+/PJL+vfvX3z8pptu4rPPPmPq1Km/+P5p06bRr18/pk6dSt++fXd5Xk5ODjk5OcXPMzMz6dChQ8Tvv64oCBWw/2P7M3fdXO791b388ag/RrokSZJUi5Snty3XRIU9SdXm5OSQkJBQ4lhiYiJffPFFma85Y8YM8vLySpzTo0cPOnbs+Iufm5mZWWJTzfLww0FI4aSTDClIkqTKZ2+rKjXnYSAMbU4ypCBJkmqlp59+mgMPPPAXQwoAY8aMoUmTJsVbhw4dqqhCgdMUJElS9VGuoEJ6ejoFBQW0atWqxPFWrVqxevXqUt8zaNAgxo4dy7x58wiFQkyaNIk333yTVatWlfmaq1evJi4ujqSkpDJ/rg1vzbZxIzz9dLCfmhrRUiRJUi1lb6sqk7sRFhY2tz1sbiVJUvWUnJxMTEwMa9asKXF8zZo1tG7d+hffm5WVxcsvv8xll122288ZNWoUGRkZxduyZcsqVLfKriBUwN2f3w3Ajf1vpHG8EywkSVLklCuosCceeughunXrRo8ePYiLi2PEiBEMGzaM6Oi9+9E2vDXbU09BVhYceCBs98eGkiRJEWVvqz0y/ynIz4KkA6G1za0kSaqe4uLiOPTQQ5k8eXLxsVAoxOTJk0ssBVGa1157jZycHC666KLdfk58fDyNGzcusalqvPLjK8xZN8dpCpIkqVoo1zeqe5KqbdGiBW+//TZZWVksWbKEtLQ0GjZsSNeuXct8zdatW5Obm8vGjRvL/Lk2vDVXXl6w7AME0xSioiJbjyRJqp3sbVUlQnkwt7C57WFzK0mSqrfU1FSeeuopxo8fz+zZs7nmmmvIyspi2LBhAAwZMoRRo0bt9L6nn36aM844g+bNm1d1ySqjglABf/rsTwCkHp7qNAVJkhRx5QoqVCRVm5CQQLt27cjPz+eNN97gN7/5TZmveeihhxIbG1vinDlz5rB06dLdfq5qntdeg+XLoVUruOCCSFcjSZJqK3tbVYmlr8GW5ZDQCjrZ3EqSpOrtvPPO429/+xu33347vXv35rvvvuODDz4oXtps6dKlxcueFZkzZw5ffPFFmZZ9UOQUTVNomtCUkf1GRrocSZIk6pX3DampqQwdOpTDDjuMvn378uCDD+6Uqm3Xrh1jxowBYOrUqaxYsYLevXuzYsUK7rzzTkKhEDfddFOZr9mkSRMuu+wyUlNTadasGY0bN2bkyJH079+fww8/vDJ+DqomwmG4//5gf8QIiI+PbD2SJKl2s7fVXhUOw+zC5nbfERBjcytJkqq/ESNGMGJE6csCfPrppzsd6969O+FweC9XpYrYfprCjf1vdJqCJEmqFsodVDjvvPNYu3Ytt99+O6tXr6Z37947pWq3X6M3Ozub0aNHs3DhQho2bMgpp5zCCy+8QFJSUpmvCfDAAw8QHR3N4MGDycnJYdCgQTz22GMVuHVVR1OmwDffQGIiXH11pKuRJEm1nb2t9qq1U2DDNxCTCPvY3EqSJCkyXv3xVacpSJKkaicqXEfirpmZmTRp0oSMjAzX9K3GfvMbePfdIKTw+OORrkaSJFVXdb23q+v3X2N89htY8W4QUuhrcytJkkpX13u7un7/e1tBqICej/ckLT2Ne467h1uPvjXSJUmSpFqsPL1d9C++KlWhuXPhn/8M9n/3u4iWIkmSJFVM5lxYUdjc9vhdREuRJElS3fXqj6+Slp7mNAVJklTtGFRQtfHQQ8Eyvr/+NXTvHulqJEmSpAqY8xAQhra/hsY2t5IkSap6BaEC/vT5nwBI7Z9K43gnVkiSpOrDoIKqhfXr4dlng/3U1MjWIkmSJFVIznpYWNjc7mdzK0mSpMgoMU2hr9MUJElS9WJQQdXCk0/C1q3Quzcce2ykq5EkSZIqYP6TULAVmvaGlsdGuhpJkiTVQQWhAu7+/G4gmKbQJKFJhCuSJEkqyaCCIi43Fx55JNi/8UaIiopsPZIkSdIeK8iFuYXNbQ+bW0mSJEXGaz+9xuz02U5TkCRJ1ZZBBUXcyy/DqlXQti2ce26kq5EkSZIqYMnLsHUVJLaFjja3kiRJiowHvn4AcJqCJEmqvgwqKKLCYRg7NtgfORLi4iJbjyRJkrTHwmFIK2xu9x0JMTa3kiRJqnrrt65n+orpAFx68KURrkaSJKl0BhUUUZ98AjNnQv36cOWVka5GkiRJqoA1n8DGmRBTH/axuZUkSVJkfLr4U8KE2S95P9o2ahvpciRJkkplUEERdf/9weOll0KzZpGtRZIkSaqQtMLmNuVSiLe5lSRJUmR8vOhjAI7vcnyEK5EkSdo1gwqKmNmz4f33ISoKrr8+0tVIkiRJFZAxG1a+D0RBd5tbSZIkRc7kRZMB+FWXX0W4EkmSpF0zqKCIefDB4PE3v4F99oloKZIkSVLFzHkweGz/G2hkcytJkqTIWJG5grT0NKKjojm287GRLkeSJGmXDCooItauheefD/ZTUyNbiyRJklQh2WthUWFz28PmVpIkSZFTtOzDIW0OoWli0whXI0mStGsGFRQRTzwB2dlw2GEwYECkq5EkSZIqYN4TUJANzQ6DFja3kiRJipyiZR+O73J8hCuRJEn6ZQYVVOWys+HRR4P9G2+EqKjI1iNJkiTtsYJsmFfY3PawuZUkSVLkhMNhgwqSJKnGMKigKvfii/Dzz9ChAwweHOlqJEmSpApY/CJk/wz1O0BHm1tJkiRFzvz181meuZy4mDiO7HhkpMuRJEn6RQYVVKXCYRg7Nti/7jqIjY1sPZIkSdIeC4chrbC57X4dRNvcSpIkKXKKpin0b9+f+rH1I1yNJEnSLzOooCo1aRL8+CM0bAiXXx7paiRJkqQKWD0JMn6Eeg0hxeZWkiRJkeWyD5IkqSYxqKAqdf/9wePll0NSUkRLkSRJkipmdmFzm3I5xCVFtBRJkiTVbaFwiE8WfQLA8V0NKkiSpOrPoIKqzKxZ8J//QHR0sOyDJEmSVGNtnAWr/wNR0cGyD5IkSVIEzVw9k3Vb19EwriF92vaJdDmSJEm7ZVBBVeaBB4LHs86CLl0iW4skSZJUIWmFzW37s6Chza0kSZIiq2jZh2M6HUNsTGyEq5EkSdo9gwqqEmvWwIQJwX5qamRrkSRJkipk6xpYXNjc9rC5lSRJUuR9vOhjAH7V5VcRrkSSJKlsDCqoSjz2GOTmQv/+wSZJkiTVWPMeg1AuJPeHFja3kiRJiqzcglw+X/I5AMd3OT7C1UiSJJWNQQXtdVu3BkEFcJqCJEmSarj8rUFQAZymIEmSpGph2oppZOVlkVw/mQNbHRjpciRJksrEoIL2uhdegPR06NwZzjgj0tVIkiRJFbD4BchJhwadof0Zka5GkiRJYvLCyUCw7EN0lF/5S5KkmsGuRXtVKAQPPBDsX3891KsX2XokSZKkPRYOQVphc9v9eoi2uZUkSVLkTV4UBBVc9kGSJNUkBhW0V33wAaSlQePGcOmlka5GkiRJqoCVH0BmGsQ2hhSbW0mSJEVeVm4WXy//GjCoIEmSahaDCtqr7r8/eLzyyiCsIEmSJNVYaYXN7T5XBmEFSZIkKcK+WPoFeaE8OjbpSNemXSNdjiRJUpkZVNBe89138PHHEBMDI0dGuhpJkiSpAjZ8B2s+hqgY2NfmVpIkSdXD9ss+REVFRbgaSZKksjOooL3mgcLle885Bzp2jGwtkiRJUoWkFTa3Hc+BBja3kiRJqh62DypIkiTVJAYVtFesXAkvvRTsp6ZGthZJkiSpQrashCWFzW0Pm1tJkiRVD+u3rufbVd8C8Ksuv4pwNZIkSeVjUEF7xbhxkJcHRx0FffpEuhpJkiSpAuaNg1AetDgKmtvcSpIkqXr4ZNEnhAmzf4v9adOoTaTLkSRJKheDCqp0WVnw+OPBvtMUJEmSVKPlZ8G8wubWaQqSJEmqRlz2QZIk1WQGFVTpxo+HDRsgJQVOOy3S1UiSJEkVsHA85G6AhinQzuZWkiRJ1cfHiz4GXPZBkiTVTAYVVKlCIXjggWD/d7+DmJiIliNJkiTtuXAI0gqb2+6/g2ibW0mSJFUPKzJXMGfdHKKjojm287GRLkeSJKncDCqoUv3rXzB/PiQlwSWXRLoaSZIkqQJW/As2z4fYJOh6SaSrkSRJkooVLftwaJtDSUpIimwxkiRJe8CggirV/fcHj1dfDQ0bRrYWSZIkqULSCpvbbldDrM2tJEmSqo+ioMLxXY6PcCWSJEl7xqCCKs3//geffw716sGIEZGuRpIkSaqAdf+Dnz+HqHqwr82tJEmSqo9wOMzkhYVBha4GFSRJUs1kUEGV5oHC5XvPPx/atYtsLZIkSVKFpBU2t53Oh/o2t5IkSao+5q6by4pNK4iLieOIDkdEuhxJkqQ9YlBBlWLZMnj11WA/NTWytUiSJEkVkrUMlhY2tz1sbiVJklS9fLzoYwCO6HAE9WPrR7gaSZKkPWNQQZXi0UchPx+OOw4OPjjS1UiSJEkVMPdRCOdDq+Ogmc2tJEmSqpfJiwqXfejisg+SJKnmMqigCtu0CZ58Mth3moIkSZJqtLxNML+wuXWagiRJkqqZUDjEJ4s/AQwqSJKkms2ggirs2WchIwP23RdOOSXS1UiSJEkVsPBZyMuARvtCW5tbSZIkVS/frf6O9VvX0yiuEX3a9Yl0OZIkSXtsj4IK48aNo3PnziQkJNCvXz+mTZv2i+c/+OCDdO/encTERDp06MANN9xAdnZ28eudO3cmKipqp2348OHF5xx77LE7vX711VfvSfmqRAUF8OCDwf4NN0C00RdJklTD2NuqWKgA0h4M9nvcAFE2t5IkSapeJi8Mln04pvMx1IuuF+FqJEmS9ly5O5lXXnmF1NRUnnjiCfr168eDDz7IoEGDmDNnDi1bttzp/BdffJFbbrmFZ555hiOOOIK5c+dyySWXEBUVxdixYwGYPn06BQUFxe+ZNWsWJ5xwAuecc06Ja11xxRX86U9/Kn5ev3798pavSvbOO7BoETRvDkOGRLoaSZKk8rG3VQkr3oGsRRDfHLrY3EqSJKn6mbwoCCr8qvOvIlyJJElSxZQ7qDB27FiuuOIKhg0bBsATTzzBe++9xzPPPMMtt9yy0/lffvklRx55JBdeeCEQ/IXZBRdcwNSpU4vPadGiRYn3/PnPfyYlJYVjjjmmxPH69evTunXr8pasveiRR4LHa64Bv1uXJEk1jb2tSphT2Nzucw3Us7mVJElS9ZJbkMuUpVMAOL7r8RGuRpIkqWLKNcs0NzeXGTNmMHDgwG0XiI5m4MCBfPXVV6W+54gjjmDGjBnFI3QXLlzI+++/zymnlL7ea25uLhMmTODSSy8lKiqqxGsTJ04kOTmZnj17MmrUKLZs2bLLWnNycsjMzCyxqXKtWQOffRbsX3FFZGuRJEkqL3tblbB1Dfxc2NzuY3MrSZLqrvIujbZx40aGDx9OmzZtiI+PZ9999+X999+vomrrlqnLp7Ilbwst6regZ8uekS5HkiSpQso1USE9PZ2CggJatWpV4nirVq1IS0sr9T0XXngh6enpDBgwgHA4TH5+PldffTV//OMfSz3/7bffZuPGjVxyySU7XadTp060bduW77//nptvvpk5c+bw5ptvlnqdMWPGcNddd5Xn9lRO774L4TD06QMdO0a6GkmSpPKxt1UJK94FwtCsDzSwuZUkSXVTeZdGy83N5YQTTqBly5a8/vrrtGvXjiVLlpCUlFT1xdcBxcs+dPkV0VHl+htESZKkaqfcSz+U16effsp9993HY489Rr9+/Zg/fz7XX389d999N7fddttO5z/99NOcfPLJtG3btsTxK6+8snj/wAMPpE2bNhx//PEsWLCAlJSUna4zatQoUlNTi59nZmbSoUOHSrwzvfVW8HjmmZGtQ5IkqarY29Ziywqb2w42t5Ikqe4q79JozzzzDOvXr+fLL78kNjYWCJZH095RFFQ4vovLPkiSpJqvXEGF5ORkYmJiWLNmTYnja9as2eX6urfddhsXX3wxl19+ORB8EZuVlcWVV17JrbfeSnT0tuTnkiVL+Oijj3b5l2Tb69evHwDz588v9cvc+Ph44uPjy3xvKp+MDJgc9MUGFSRJUo1kb6tiuRmwprC5bW9zK0mS6qaipdFGjRpVfGx3S6O9++679O/fn+HDh/POO+/QokULLrzwQm6++WZiYmKqqvQ6YXPuZr5e/jUAx3c1qCBJkmq+cs2HiouL49BDD2Vy0W+ogVAoxOTJk+nfv3+p79myZUuJL2yB4iY1HA6XOP7ss8/SsmVLTj311N3W8t133wHQpk2b8tyCKsn770NuLvToEWySJEk1jb2tiq18H0K50LgHNLG5lSRJddMvLY22evXqUt+zcOFCXn/9dQoKCnj//fe57bbbuP/++7nnnnt2+Tk5OTlkZmaW2LR7Xyz9gvxQPp2adKJLUpdIlyNJklRh5V76ITU1laFDh3LYYYfRt29fHnzwQbKysorHgQ0ZMoR27doxZswYAE477TTGjh3LwQcfXDwe97bbbuO0004rkaoNhUI8++yzDB06lHr1Spa1YMECXnzxRU455RSaN2/O999/zw033MDRRx/NQQcdVJH71x4qWvbhrLMiW4ckSVJF2NsKgOVFyz7Y3EqSJJVHKBSiZcuW/P3vfycmJoZDDz2UFStW8Ne//pU77rij1PeMGTOGu+66q4orrfkmL9y27ENUVFSEq5EkSaq4cgcVzjvvPNauXcvtt9/O6tWr6d27Nx988EFx0nbp0qUl/sps9OjRREVFMXr0aFasWEGLFi047bTTuPfee0tc96OPPmLp0qVceumlO31mXFwcH330UfEXxx06dGDw4MGMHj26vOWrEmRnBxMVwGUfJElSzWZvKwqyg4kK4LIPkiSpTtuTpdHatGlDbGxsidDufvvtx+rVq8nNzSUuLm6n94waNYrU1NTi55mZmXTo0KGS7qL2mryoMKjgsg+SJKmWiArvOKO2lsrMzKRJkyZkZGTQuHHjSJdTo/3zn3D66dChAyxZAgZ4JUlSVavrvV1dv/9Ktfyf8PnpUL8D/MbmVpIkVb3q1Nv169ePvn378sgjjwDBxISOHTsyYsQIbrnllp3O/+Mf/8iLL77IwoULiwO+Dz30EH/5y19YuXJlmT6zOt1/dbVuyzpa/LUFYcKsunEVrRuWHhyRJEmKtPL0dtG/+KpUiqJlH8480+9xJUmSVMMVLfvQ3uZWkiQpNTWVp556ivHjxzN79myuueaanZZGGzVqVPH511xzDevXr+f6669n7ty5vPfee9x3330MHz48UrdQK32y+BPChDmgxQGGFCRJUq1R7qUfVLfl58O77wb7LvsgSZKkGi2UDysKm9sONreSJEnlXRqtQ4cOfPjhh9xwww0cdNBBtGvXjuuvv56bb745UrdQK01eWLjsQxeXfZAkSbWHQQWVy5QpsG4dNG8OAwZEuhpJkiSpAtZOgZx1EN8cWtjcSpIkAYwYMYIRI0aU+tqnn36607H+/fvz9ddf7+Wq6raPF38MwK+6/CrClUiSJFUel35QuRQt+/Cb30A9Yy6SJEmqyZYVNrftfgPRNreSJEmqfpZnLmfuurlER0VzTOdjIl2OJElSpTGooDILh7cFFVz2QZIkSTVaOAzLC5tbl32QJElSNVW07MNhbQ8jKSEpssVIkiRVIoMKKrP//Q+WL4eGDWHgwEhXI0mSJFXA+v/BluVQryG0trmVJElS9TR5URBUOL7L8RGuRJIkqXIZVFCZFU1TOOUUSEiIbC2SJElShRQt+9D2FIixuZUkSVL1Ew6HDSpIkqRay6CCysxlHyRJklRrFC370N7mVpIkSdXTnHVzWLlpJfEx8RzR4YhIlyNJklSpDCqoTGbPhrQ0iIsLJipIkiRJNVbGbMhMg+g4aGdzK0mSpOrp40UfA3BEhyNIjE2McDWSJEmVy6CCyqRomsLAgdC4cWRrkSRJkiqkaJpC64EQa3MrSZKk6sllHyRJUm1mUEFl4rIPkiRJqjWWueyDJEmSqreCUAGfLPoEgOO7GlSQJEm1j0EF7dbSpfC//0F0NJx+eqSrkSRJkiogayms/x9ERUN7m1tJkiRVT9+t/o4N2RtoHN+Yw9oeFulyJEmSKp1BBe3W228Hj0ceCS1bRrQUSZIkqWKWvx08Jh8JCTa3kiRJqp6Kln04ptMx1IuuF+FqJEmSKp9BBe1W0bIPZ50V2TokSZKkCita9qGDza0kSZKqr6Kgwq+6/CrClUiSJO0dBhX0i9LT4fPPg/0zzohoKZIkSVLFZKfD2sLmtv0ZES1FkiRJ2pXcglymLJkCwPFdjo9wNZIkSXuHQQX9onffhVAIDj4YOneOdDWSJElSBax4F8IhaHowNOwc6WokSZKkUn29/Gu25m+lZYOW9GzZM9LlSJIk7RUGFfSLXPZBkiRJtYbLPkiSJKkGmLxw27IPUVFREa5GkiRp7zCooF3atAkmTQr2zzwzsrVIkiRJFZK3CVYXNrftbW4lSZJUfU1eFAQVXPZBkiTVZgYVtEv//jfk5EC3brD//pGuRpIkSaqAlf+GUA406gZNbG4lSZJUPW3O3czUFVMBgwqSJKl2M6igXdp+2QcnjEmSJKlGW77dsg82t5IkSaqmPl/yOfmhfDondaZL0y6RLkeSJGmvMaigUuXkwHvvBfsu+yBJkqQarSAHVhQ2ty77IEmSpGrs40UfA05TkCRJtZ9BBZVq8mTYtAnatoU+fSJdjSRJklQBqydD/iZIbAvNbW4lSZJUfU1eNBkwqCBJkmo/gwoqVdGyD2eeCdH+K5EkSVJNVrTsQ/szIcrmVpIkSdVT+pZ0vlv9HQC/6vKryBYjSZK0l/ktnXZSUADvvBPsu+yDJEmSarRQASwvbG472NxKkiSp+vpk0ScA9GzZk1YNW0W4GkmSpL3LoIJ28t//wtq10LQpHH10pKuRJEmSKiD9v5CzFuKaQkubW0mSJFVfLvsgSZLqEoMK2knRsg+nnw6xsZGtRZIkSaqQZYXNbbvTIdrmVpIkSdVXUVDBZR8kSVJdYFBBJYTD24IKLvsgSZKkGi0chuWFza3LPkiSJKkaW5qxlPnr5xMdFc0xnY6JdDmSJEl7nUEFlfDtt7BkCdSvDyeeGOlqJEmSpArY8C1kLYGY+tDa5laSJEnV18eLPgagT9s+NEloEuFqJEmS9j6DCiqhaJrCySdDYmJka5EkSZIqpGjZh7YnQz2bW0mSJFVfRcs+HN/l+AhXIkmSVDUMKqgEl32QJElSrVG07EN7m1tJkqT/b+/Oo6Oq7/+Pv2ayE0jYQkJIIAEEFNlkCQEFTCKLGFksUrGguKAt1AVtBQVB/ZW01iJWcf0q2CqKtgioiMWwtOwQQFwwIIQ9CaAQCEsCmc/vjzAjQxYSEnJnkufjnDlO7tz7ue97M/fyKn1zP/Bcxhil7jrfqNCcRgUAAFAz0KgAl+3bpe++k3x9pYEDra4GAAAAqIDj26Wc7ySbr9SEcAsAAADP9cORH5SZm6kAnwDFR8VbXQ4AAECVoFEBLs6nKSQkSHXrWloKAAAAUDHOpymEJ0j+dS0tBQAAACiNc9qHnk17KsiPKcsAAEDNQKMCXJyNCkOHWlsHAAAAUGH7zofbaMItAAAAPNvSjKWSpMRYpn0AAAA1B40KkCQdOCCtWyfZbNKgQVZXAwAAAFTAqQPST+sk2aQowi0AAAA8V4GjQMt2L5NEowIAAKhZaFSAJGn+/ML/xsdLERGWlgIAAABUzP75hf9tGC8FEW4BAADguTZnbdaxM8cUEhCizpGdrS4HAACgytCoAElM+wAAAIBqhGkfAAAA4CVSd6VKkvrE9JGv3dfiagAAAKoOjQrQzz9Ly5cXvh8yxNJSAAAAgIrJ+1k6tLzwfTThFgAAAJ4tNaOwUSEhJsHiSgAAAKoWjQrQp59KBQVS+/ZS8+ZWVwMAAABUwIFPJVMg1W0v1SbcAgAAwHPlncvTyr0rJUmJzRMtrgYAAKBq0agApn0AAABA9bGfaR8AAADgHdbuX6vT504rPDhcbcPaWl0OAABAlaJRoYY7eVL68svC90z7AAAAAK927qSUeT7cRhFuAQAA4Nlc0z7EJshms1lcDQAAQNWiUaGGW7xYOnOmcMqHdu2srgYAAACogIOLpYIzhVM+1CXcAgAAwLM5GxUSY5n2AQAA1Dw0KtRwF077QNMuAAAAvNqF0z4QbgEAAODBTuSd0PoD6yVJic1pVAAAADXPZTUqzJw5UzExMQoMDFRcXJzWr19f6vozZsxQ69atFRQUpOjoaD366KM6c+aM6/OpU6fKZrO5vdq0aeM2xpkzZzR27Fg1aNBAtWvX1m233abs7OzLKR/n5edLn31W+J5pHwAAQE1Ftq0mCvKlA+fDLdM+AAAAwMP9d89/dc5xTrF1YxVTN8bqcgAAAKpcuRsV5s6dq/Hjx2vKlCnatGmTOnTooH79+unQoUPFrj9nzhxNmDBBU6ZM0bZt2/T2229r7ty5evLJJ93Wa9u2rTIzM12vlStXun3+6KOP6tNPP9XHH3+sFStW6ODBgxo6dGh5y8cFli2TcnKkiAipe3erqwEAAKh6ZNtqJHuZdDZHCoyQGhJuAQAA4NmY9gEAANR0vuXdYPr06br//vs1evRoSdLrr7+uzz//XO+8844mTJhQZP3Vq1erZ8+eGjFihCQpJiZGd9xxh9atW+deiK+vIiIiit1nTk6O3n77bc2ZM0cJCQmSpFmzZunqq6/W2rVr1Z3/l/2yOKd9GDxYsjMJCAAAqIHIttWIc9qHqMGSjXALAAAAz7Y0Y6kkpn0AAAA1V7n+Bi8/P19paWlKSkr6ZQC7XUlJSVqzZk2x2/To0UNpaWmuR+ju2rVLixYt0s033+y23o4dOxQZGanmzZvrzjvv1N69e12fpaWl6ezZs277bdOmjZo2bVriflG6ggJp/vzC90z7AAAAaiKybTXiKJD2zy98H024BQAAgGc7fPKwvs7+WpKUEJtgcTUAAADWKNcTFY4cOaKCggKFh4e7LQ8PD9cPP/xQ7DYjRozQkSNHdP3118sYo3PnzunBBx90ezxuXFycZs+erdatWyszM1PPPPOMbrjhBn377beqU6eOsrKy5O/vr7p16xbZb1ZWVrH7zcvLU15enuvn48ePl+dQq721a6XsbCk0VOrTx+pqAAAAqh7Zthr5aa10JlvyC5Ua9bG6GgAAAKBUy3YvkyS1a9ROjYIbWVwNAACANa74M1GXL1+uadOm6dVXX9WmTZs0b948ff7553ruuedc6wwYMEDDhg1T+/bt1a9fPy1atEjHjh3TRx99dNn7TUlJUWhoqOsVHR1dGYdTbTinfbjlFsnf39paAAAAvAXZ1kPtOx9um9wi+RBuAQAA4NlSd6VK4mkKAACgZitXo0LDhg3l4+Oj7Oxst+XZ2dklzsE7efJkjRw5Uvfdd5/atWunIUOGaNq0aUpJSZHD4Sh2m7p166pVq1b68ccfJUkRERHKz8/XsWPHyrzfiRMnKicnx/Xat29feQ61WjPml0aFoUOtrQUAAMAqZNtqwhhp//lwG024BQAAgOdLzShsVEiMTbS4EgAAAOuUq1HB399fnTt3VmpqqmuZw+FQamqq4uPji93m1KlTstvdd+Pj4yNJMsYUu01ubq527typxo0bS5I6d+4sPz8/t/2mp6dr7969Je43ICBAISEhbi8U2rpV2rVLCgyU+vWzuhoAAABrkG2riWNbpdxdkk+g1JhwCwAAAM+259ge7Ty6Uz42H/WO6W11OQAAAJYp99QP48eP11tvvaV3331X27Zt029/+1udPHlSo0ePliSNGjVKEydOdK2fnJys1157TR9++KEyMjK0ZMkSTZ48WcnJya6/1H388ce1YsUK7d69W6tXr9aQIUPk4+OjO+64Q5IUGhqqe++9V+PHj9eyZcuUlpam0aNHKz4+Xt27d6+M81CjOJ+m0K+fFBxsbS0AAABWIttWA85pHxr3k3wJtwAAABU1c+ZMxcTEKDAwUHFxcVq/fn2J686ePVs2m83tFRgYWIXVep+lGUslSV2bdFVIAA3IAACg5vIt7wbDhw/X4cOH9fTTTysrK0sdO3bU4sWLFR4eLknau3ev278ymzRpkmw2myZNmqQDBw4oLCxMycnJ+tOf/uRaZ//+/brjjjv0008/KSwsTNdff73Wrl2rsLAw1zovvvii7Ha7brvtNuXl5alfv3569dVXK3LsNRbTPgAAABQi21YDzmkfogi3AAAAFTV37lyNHz9er7/+uuLi4jRjxgz169dP6enpatSoUbHbhISEKD093fWzzWarqnK9EtM+AAAAFLKZkp5RW80cP35coaGhysnJqdGPyt25U2rZUvLxkQ4dkurXt7oiAACA8qvp2a6mH7/LiZ3Spy0lm4809JAUQLgFAADex5OyXVxcnLp27apXXnlFUuHUaNHR0fr973+vCRMmFFl/9uzZeuSRR3Ts2LHL3qcnHf+VZoxR5PRIZeVmaemopbox9karSwIAAKhU5cl25Z76Ad7N+TSFPn1oUgAAAICXcz5NoVEfmhQAAAAqKD8/X2lpaUpKSnIts9vtSkpK0po1a0rcLjc3V82aNVN0dLQGDRqk7777rirK9UrbjmxTVm6WAn0DFR8db3U5AAAAlqJRoYZh2gcAAABUG/vOh9towi0AAEBFHTlyRAUFBa5p0JzCw8OVlZVV7DatW7fWO++8owULFui9996Tw+FQjx49tH///hL3k5eXp+PHj7u9aorUXYXTPvSM7qlA30CLqwEAALAWjQo1SGam5Gx+HjTI2loAAACACjmdKR05H26jCLcAAABWiI+P16hRo9SxY0f17t1b8+bNU1hYmN54440St0lJSVFoaKjrFR0dXYUVWys1o7BRITE20eJKAAAArEejQg2yYIFkjBQXJzVpYnU1AAAAQAXsXyDJSA3ipFqEWwAAgIpq2LChfHx8lJ2d7bY8OztbERERZRrDz89PnTp10o8//ljiOhMnTlROTo7rtW/fvgrV7S0KHAVavnu5JCmxOY0KAAAANCrUIEz7AAAAgGqDaR8AAAAqlb+/vzp37qzU1FTXMofDodTUVMXHx5dpjIKCAn3zzTdq3LhxiesEBAQoJCTE7VUTbMrcpJy8HIUGhKpz485WlwMAAGA5X6sLQNU4dkxaurTw/ZAhlpYCAAAAVEz+MSn7fLiNItwCAABUlvHjx+uuu+5Sly5d1K1bN82YMUMnT57U6NGjJUmjRo1SkyZNlJKSIkl69tln1b17d7Vs2VLHjh3TX//6V+3Zs0f33XeflYfhkZzTPvSJ6SMfu4/F1QAAAFiPRoUa4rPPpHPnpLZtpauusroaAAAAoAIOfCaZc1JoWymEcAsAAFBZhg8frsOHD+vpp59WVlaWOnbsqMWLFys8PFyStHfvXtntvzyk9+jRo7r//vuVlZWlevXqqXPnzlq9erWuueYaqw7BYzkbFRJiEyyuBAAAwDPQqFBDMO0DAAAAqo39TPsAAABwpYwbN07jxo0r9rPly5e7/fziiy/qxRdfrIKqvNuZc2e0cu9KSVJibKLF1QAAAHgG+6VXgbc7dUpavLjwPdM+AAAAwKudOyUdPB9umfYBAAAAXmDNvjU6c+6MImpH6JownjYBAAAg0ahQI/znP4XNCs2aSR07Wl0NAAAAUAGZ/5EKTknBzaR6Ha2uBgAAALikpRlLJRVO+2Cz2SyuBgAAwDPQqFADXDjtAzkYAAAAXs057UMU4RYAAADeITUjVRLTPgAAAFyIRoVq7uxZ6dNPC98z7QMAAAC8muOsdOB8uI0m3AIAAMDzHc87rvUH1kuiUQEAAOBCNCpUcytWSEePSmFhUo8eVlcDAAAAVMChFVL+USkgTGpIuAUAAIDn+++e/6rAFKh5veZqVreZ1eUAAAB4DBoVqjnntA+DBkk+PtbWAgAAAFTIPue0D4MkO+EWAAAAni91F9M+AAAAFIdGhWrM4ZDmzy98P3SopaUAAAAAFWMc0v75he+jCbcAAADwDkt3L5VEowIAAMDFaFSoxtavlw4elOrUkRISrK4GAAAAqICf1kunD0q+daRwwi0AAAA836GTh7Q1e6skKSGWDAsAAHAhGhWqMee0DwMHSgEB1tYCAAAAVIhz2ocmAyUfwi0AAAA837KMZZKk9uHtFRYcZnE1AAAAnoVGhWrKGGnevML3TPsAAAAAr2aMtO98uGXaBwAAAHiJ1IxUSVJCDE9TAAAAuBiNCtXUd99JP/5Y+CSFAQOsrgYAAACogJzvpNwfJXuA1JhwCwAAAO/gbFRIbJ5ocSUAAACeh0aFaso57cNNN0m1a1tbCwAAAFAhzmkfIm6S/Ai3AAAA8Hy7j+3WrqO75GPzUa9mvawuBwAAwOPQqFBNORsVmPYBAAAAXm//+XDLtA8AAADwEkszlkqSujXpppCAEIurAQAA8Dw0KlRDu3dLmzdLdruUnGx1NQAAAEAF5O6Wjm6WbHapCeEWAAAA3sE17UMs0z4AAAAUh0aFasj5NIVevaSGDa2tBQAAAKgQ59MUwnpJgYRbAAAAeD5jjOuJConNaVQAAAAoDo0K1RDTPgAAAKDa2Me0DwAAAPAu3x/+Xlm5WQr0DVT3qO5WlwMAAOCRaFSoZrKzpZUrC98PHmxpKQAAAEDFnM6WDp8Pt1GDLS0FAAAAKCvntA/XN71egb6BFlcDAADgmWhUqGYWLpSMkbp0kaKjra4GAAAAqIADCyUZqX4XKZhwCwAAAO/gbFRIjGXaBwAAgJLQqFDNMO0DAAAAqg2mfQAAAICXOec4p+W7l0uiUQEAAKA0NCpUIzk5Umphs66GDLG2FgAAAKBC8nOk7PPhNopwCwAAAO+wKXOTjucdV93Aurqu8XVWlwMAAOCxaFSoRhYtkvLzpTZtCl8AAACA1zq4SHLkSyFtpFDCLQAAALxD6q7CZts+MX3kY/exuBoAAADPRaNCNeKc9oGnKQAAAMDr7T8fbnmaAgAAALxIakZho0JCTILFlQAAAHg2GhWqiTNnCp+oIElDmcIXAAAA3qzgTOETFSQpmnALAAAA73Dm3Bmt2rdKkpTYPNHiagAAADwbjQrVxJIl0smTUnS01Lmz1dUAAAAAFZC5RDp3UqoVLdUn3AIAAMA7rN63WmfOnVHj2o11dcOrrS4HAADAo9GoUE04p30YPFiy2SwtBQAAAKgY17QPgwm3AAAA8BpLM5ZKkhJiE2QjxwIAAJSKRoVq4Nw5aeHCwvdM+wAAAACv5jgnHTgfbpn2AQAAAF4kNSNVkpQYy7QPAAAAl0KjQjXwv/9JP/0kNWggXX+91dUAAAAAFXD4f1LeT1JAAymMcAsAAADvcDzvuDYc2CCp8IkKAAAAKB2NCtWAc9qHW2+VfH2trQUAAACokH3nw22TWyU74RYAAADeYcXuFSowBWpRr4Wa1W1mdTkAAAAej0YFL2fML40KTPsAAAAAr2aMtP98uGXaBwAAAHgRpn0AAAAoHxoVvNzGjdL+/VLt2lJSktXVAAAAABXw80bp1H7Jt7YUQbgFAACA93A1KjSnUQEAAKAsaFTwcs6nKQwYIAUGWlsLAAAAUCHOaR8iB0g+hFsAAAB4h+zcbH176FtJ0o0xN1pcDQAAgHegUcHLMe0DAAAAqg3ntA9RhFsAAAB4j2W7l0mSOoR3UFhwmMXVAAAAeAcaFbzYtm3SDz9I/v7SzTdbXQ0AAABQATnbpOM/SHZ/qQnhFgAAAN4jdVfhtA8JsQkWVwIAAOA9aFTwYs6nKSQmSiEh1tYCAAAAVIjzaQrhiZIf4RYAAADeIzWjsFEhMTbR4koAAAC8x2U1KsycOVMxMTEKDAxUXFyc1q9fX+r6M2bMUOvWrRUUFKTo6Gg9+uijOnPmjOvzlJQUde3aVXXq1FGjRo00ePBgpaenu43Rp08f2Ww2t9eDDz54OeVXG0z7AAAAUHFkWw+x73y4jSbcAgAAwHtkHM1QxrEM+dp91atZL6vLAQAA8BrlblSYO3euxo8frylTpmjTpk3q0KGD+vXrp0OHDhW7/pw5czRhwgRNmTJF27Zt09tvv625c+fqySefdK2zYsUKjR07VmvXrtWSJUt09uxZ9e3bVydPnnQb6/7771dmZqbr9fzzz5e3/Gpj715p40bJbpduvdXqagAAALwT2dZDnNwr/bxRstmlKMItAAAAvIfzaQrdmnRTnYA6FlcDAADgPXzLu8H06dN1//33a/To0ZKk119/XZ9//rneeecdTZgwocj6q1evVs+ePTVixAhJUkxMjO644w6tW7fOtc7ixYvdtpk9e7YaNWqktLQ09er1SxdqrVq1FBERUd6Sq6X58wv/27On1KiRpaUAAAB4LbKth9g/v/C/DXtKgYRbAAAAeI+lGUslMe0DAABAeZXriQr5+flKS0tTUlLSLwPY7UpKStKaNWuK3aZHjx5KS0tzPUJ3165dWrRokW6++eYS95OTkyNJql+/vtvy999/Xw0bNtS1116riRMn6tSpU+Upv1ph2gcAAICKIdt6EKZ9AAAAgBcyxtCoAAAAcJnK9USFI0eOqKCgQOHh4W7Lw8PD9cMPPxS7zYgRI3TkyBFdf/31Msbo3LlzevDBB90ej3shh8OhRx55RD179tS1117rNk6zZs0UGRmprVu36oknnlB6errmzZtX7Dh5eXnKy8tz/Xz8+PHyHKpHO3JE+u9/C98PHmxpKQAAAF6LbOshzhyRDp8Pt1GDLS0FAAAAKI/vDn+n7JPZCvINUveo7laXAwAA4FXKPfVDeS1fvlzTpk3Tq6++qri4OP344496+OGH9dxzz2ny5MlF1h87dqy+/fZbrVy50m35mDFjXO/btWunxo0bKzExUTt37lSLFi2KjJOSkqJnnnmm8g/IAyxcKDkcUqdOUkyM1dUAAADUHGTbK+DAQsk4pHqdpNoxVlcDAAAAlFnqrlRJ0vVNr1eAb4DF1QAAAHiXck390LBhQ/n4+Cg7O9tteXZ2donz606ePFkjR47Ufffdp3bt2mnIkCGaNm2aUlJS5HA43NYdN26cPvvsMy1btkxRUVGl1hIXFydJ+vHHH4v9fOLEicrJyXG99u3bV9bD9HjOaR+GDLG2DgAAAG9GtvUQzmkfogi3AAAA8C6pGYWNCkz7AAAAUH7lalTw9/dX586dlZqa6lrmcDiUmpqq+Pj4Yrc5deqU7Hb33fj4+EgqnMPL+d9x48bpk08+0dKlSxUbG3vJWrZs2SJJaty4cbGfBwQEKCQkxO1VHZw4IS1ZUvh+KFP4AgAAXDayrQc4e0LKOh9uowm3AAAA8B7nHOe0Ys8KSVJicxoVAAAAyqvcUz+MHz9ed911l7p06aJu3bppxowZOnnypEaPHi1JGjVqlJo0aaKUlBRJUnJysqZPn65OnTq5Ho87efJkJScnu/5Sd+zYsZozZ44WLFigOnXqKCsrS5IUGhqqoKAg7dy5U3PmzNHNN9+sBg0aaOvWrXr00UfVq1cvtW/fvrLOhVf44gspL0+66irpmmusrgYAAMC7kW0tdvALyZEn1blKCiXcAgAAwHukHUzT8bzjqhtYV50iOlldDgAAgNcpd6PC8OHDdfjwYT399NPKyspSx44dtXjxYoWHh0uS9u7d6/avzCZNmiSbzaZJkybpwIEDCgsLU3Jysv70pz+51nnttdckSX369HHb16xZs3T33XfL399fX331lesvjqOjo3Xbbbdp0qRJl3PMXu3CaR9sNmtrAQAA8HZkW4vtv2DaB8ItAAAAvIhz2ocbY26Uj93H4moAAAC8j804n1FbzR0/flyhoaHKycnx2kfl5uVJYWGF0z+sXSudn8oYAACgxqkO2a4iqsXxF+RJ/w6Tzp2Q+q6VGhJuAQBAzVQtsl0FeOvxJ/4jUUszlurlAS9rXLdxVpcDAADgEcqT7eylfgqPkppa2KQQGSl17Wp1NQAAAEAFZKUWNikERUoNCLcAAADwHqfPntaqvaskSYmxiRZXAwAA4J1oVPAizmkfBg+W7PzmAAAA4M1c0z4MlmyEWwAAAHiP1ftWK68gT41rN1abhm2sLgcAAMAr8TeCXqKgQFqwoPD90KHW1gIAAABUiKNA2n8+3EYTbgEAAOBdUjNSJUmJzRNls9ksrgYAAMA70ajgJVatkg4flurVk3r1sroaAAAAoAKOrJLyDkv+9aRGhFsAAABPMnPmTMXExCgwMFBxcXFav359mbb78MMPZbPZNHjw4CtboAdYmrFUEtM+AAAAVASNCl7COe1DcrLk52dtLQAAAECF7DsfbpskS3bCLQAAgKeYO3euxo8frylTpmjTpk3q0KGD+vXrp0OHDpW63e7du/X444/rhhtuqKJKrZNzJkcbDm6QJCXEJlhcDQAAgPeiUcELGPNLowLTPgAAAMCrGSPtPx9umfYBAADAo0yfPl3333+/Ro8erWuuuUavv/66atWqpXfeeafEbQoKCnTnnXfqmWeeUfPmzauwWmus2LNCDuNQy/ot1TS0qdXlAAAAeC0aFbzA5s3Snj1SrVpS375WVwMAAABUwNHN0sk9kk8tKYJwCwAA4Cny8/OVlpampKQk1zK73a6kpCStWbOmxO2effZZNWrUSPfee2+Z9pOXl6fjx4+7vbxJ6q5USUz7AAAAUFE0KngB59MU+veXgoKsrQUAAACoEOe0D5H9JV/CLQAAgKc4cuSICgoKFB4e7rY8PDxcWVlZxW6zcuVKvf3223rrrbfKvJ+UlBSFhoa6XtHR0RWqu6qlZtCoAAAAUBloVPACTPsAAACAasM57UMU4RYAAMCbnThxQiNHjtRbb72lhg0blnm7iRMnKicnx/Xat2/fFayycmXlZum7w99Jkm6MvdHiagAAALybr9UFoHTbt0vffSf5+koDB1pdDQAAAFABx7dLOd9JNl+pCeEWAADAkzRs2FA+Pj7Kzs52W56dna2IiIgi6+/cuVO7d+9WcnKya5nD4ZAk+fr6Kj09XS1atCiyXUBAgAICAiq5+qqxLGOZJKljREc1rFX25gwAAAAUxRMVPJzzaQoJCVLdupaWAgAAAFSM82kK4QmSf11LSwEAAIA7f39/de7cWampqa5lDodDqampio+PL7J+mzZt9M0332jLli2u16233qobb7xRW7Zs8bopHcrCOe1DQkyCxZUAAAB4P56o4OGcjQpDhlhbBwAAAFBh+86H22jCLQAAgCcaP3687rrrLnXp0kXdunXTjBkzdPLkSY0ePVqSNGrUKDVp0kQpKSkKDAzUtdde67Z93fP/0uri5dWFs1EhsXmixZUAAAB4PxoVPNiBA9K6dZLNJg0aZHU1AAAAQAWcOiD9tE6STYoi3AIAAHii4cOH6/Dhw3r66aeVlZWljh07avHixQoPD5ck7d27V3Z7zXxI766ju7T72G752n3Vq1kvq8sBAADwejQqeLD58wv/Gx8vNW5saSkAAABAxeyfX/jfhvFSEOEWAADAU40bN07jxo0r9rPly5eXuu3s2bMrvyAPkbqr8GkKcU3iVNu/tsXVAAAAeL+a2f7qJZj2AQAAANUG0z4AAADAi7mmfYhl2gcAAIDKQKOCh/r5Z8nZoEyjAgAAALxa3s/SoeWF76MItwAAAPAuxhgtzVgqSUpsTqMCAABAZaBRwUN9+qlUUCC1by+1aGF1NQAAAEAFHPhUMgVS3fZSHcItAAAAvMu3h77V4VOHFeQbpLgmcVaXAwAAUC3QqOChmPYBAAAA1cb+8+GWpykAAADACzmnfbih2Q0K8A2wuBoAAIDqgUYFD3TypPTll4Xvhw61thYAAACgQs6dlDLPh9towi0AAAC8j7NRITGWaR8AAAAqC40KHmjxYunMGal5c6ldO6urAQAAACrg4GKp4IxUu7lUl3ALAAAA73LOcU4rdq+QRKMCAABAZaJRwQNdOO2DzWZtLQAAAECFXDjtA+EWAAAAXmbDgQ06kX9C9QLrqWNER6vLAQAAqDZoVPAw+fnSZ58VvmfaBwAAAHi1gnzpwPlwy7QPAAAA8EJLM5ZKkm6MvVE+dh+LqwEAAKg+aFTwMMuWSTk5UkSE1L271dUAAAAAFZC9TDqbIwVGSA0JtwAAAPA+qRmpkqSEmASLKwEAAKheaFTwMM5pHwYNkuz8dgAAAODNXNM+DJJshFsAAAB4l9NnT2v1vtWSpMTmiRZXAwAAUL3wt4UepKBAmj+/8D3TPgAAAMCrOQqk/fML3zPtAwAAALzQqn2rlFeQp8g6kWrdoLXV5QAAAFQrNCp4kLVrpexsKTRU6tPH6moAAACACvhprXQmW/ILlRr1sboaAAAAoNxSdxVO+5AYmyibzWZxNQAAANULjQoexDntwy23SP7+1tYCAAAAVMi+8+G2yS2SD+EWAAAA3ic145dGBQAAAFQuGhU8hDG/NCow7QMAAAC8mjHS/vPhlmkfAAAA4IWOnTmmtMw0SVJCbILF1QAAAFQ/NCp4iK1bpV27pMBAqV8/q6sBAAAAKuDYVil3l+QTKDUm3AIAAMD7rNi9Qg7j0FX1r1J0aLTV5QAAAFQ7NCp4COfTFPr1k4KDra0FAAAAqBDntA+N+0m+hFsAAAB4H6Z9AAAAuLJoVPAQzkaFIUOsrQMAAACoMOe0D1GEWwAAAHgnV6NCcxoVAAAArgQaFTzAzp2FUz/4+EjJyVZXAwAAAFTAiZ2FUz/YfKQmhFsAAAB4n8wTmfr+8PeyyaYbY260uhwAAIBqiUYFD+B8mkKfPlL9+paWAgAAAFSM82kKjfpIAYRbAAAAeJ+lGUslSR0jOqpBrQYWVwMAAFA90ajgAZj2AQAAANXGvvPhNppwCwAAAO/kbFRIiE2wuBIAAIDqi0YFi2VmSmvWFL4fPNjSUgAAAICKOZ0pHTkfbqMGW1oKAAAAcDmMMUrNSJUkJcYmWlwNAABA9UWjgsUWLJCMkeLipCZNrK4GAAAAqID9CyQZqUGcVItwCwAAAO+z6+gu7cnZI1+7r25odoPV5QAAAFRbNCpYjGkfAAAAUG0w7QMAAAC8nPNpCt2juqu2f22LqwEAAKi+aFSw0LFj0tLC6c5oVAAAAIB3yz8mZZ8Pt1GEWwAAAHgnpn0AAACoGjQqWOizz6Rz56S2baVWrayuBgAAAKiAA59J5pwU2lYKIdwCAADA+ziMQ8sylkmiUQEAAOBKo1HBQkz7AAAAgGpj//lwy9MUAAAA4KW+PfStDp86rFp+tRQXFWd1OQAAANUajQoWOXVKWry48P3QodbWAgAAAFTIuVPSwfPhNppwCwAAAO+Uuqtw2ocbmt4gfx9/i6sBAACo3mhUsMh//lPYrNCsmdSxo9XVAAAAABWQ+R+p4JQU3Eyq19HqagAAAIDLkppR2KjAtA8AAABX3mU1KsycOVMxMTEKDAxUXFyc1q9fX+r6M2bMUOvWrRUUFKTo6Gg9+uijOnPmTLnGPHPmjMaOHasGDRqodu3auu2225SdnX055XuEC6d9sNmsrQUAAKAmI9tWggunfSDcAgAAwAudLTirFXtWSJISm9OoAAAAcKWVu1Fh7ty5Gj9+vKZMmaJNmzapQ4cO6tevnw4dOlTs+nPmzNGECRM0ZcoUbdu2TW+//bbmzp2rJ598slxjPvroo/r000/18ccfa8WKFTp48KCGeumcCWfPSp9+WvjeSw8BAACgWiDbVgLHWenA+XDLtA8AAADwUhsOblBufq7qB9VXx4iOVpcDAABQ7dmMMaY8G8TFxalr16565ZVXJEkOh0PR0dH6/e9/rwkTJhRZf9y4cdq2bZtSU1Ndyx577DGtW7dOK1euLNOYOTk5CgsL05w5c/SrX/1KkvTDDz/o6quv1po1a9S9e/dL1n38+HGFhoYqJydHISEh5TnkSvfVV9JNN0lhYVJmpuTjY2k5AAAAXqeysh3ZthJkfSUtvUkKCJOGZEp2wi0AAEB5eFS2s4CnHP//++//0+Rlk3Xb1bfpX7f/y7I6AAAAvFl5sl25nqiQn5+vtLQ0JSUl/TKA3a6kpCStWbOm2G169OihtLQ01+Nud+3apUWLFunmm28u85hpaWk6e/as2zpt2rRR06ZNS9yvJ3NO+zBoEE0KAAAAViHbVpJ9zmkfBtGkAAAAAK+VmlHYjJwQm2BxJQAAADWDb3lWPnLkiAoKChQeHu62PDw8XD/88EOx24wYMUJHjhzR9ddfL2OMzp07pwcffND1eNyyjJmVlSV/f3/VrVu3yDpZWVnF7jcvL095eXmun48fP16eQ71iHA5p/vzC90OGWFoKAABAjUa2rQTGIe2fX/g+inALAAAA73Tq7Cmt3rdakpQYm2hxNQAAADVDuZ6ocDmWL1+uadOm6dVXX9WmTZs0b948ff7553ruueeu6H5TUlIUGhrqekVHR1/R/ZXV+vXSwYNSnTpSIpkXAADAq5BtL/LTeun0Qcm3jhRBuAUAAIB3WrV3lfIL8tWkThO1atDK6nIAAABqhHI1KjRs2FA+Pj7Kzs52W56dna2IiIhit5k8ebJGjhyp++67T+3atdOQIUM0bdo0paSkyOFwlGnMiIgI5efn69ixY2Xe78SJE5WTk+N67du3rzyHesU4p30YOFAKCLC2FgAAgJqMbFsJnNM+NBko+RBuAQAA4J2c0z4kNk+UzWazuBoAAICaoVyNCv7+/urcubNSU1NdyxwOh1JTUxUfH1/sNqdOnZLd7r4bH5/CuWuNMWUas3PnzvLz83NbJz09XXv37i1xvwEBAQoJCXF7Wc0Yad68wvdM+wAAAGAtsm0FGSPtOx9umfYBAAAAXszVqMC0DwAAAFXGt7wbjB8/XnfddZe6dOmibt26acaMGTp58qRGjx4tSRo1apSaNGmilJQUSVJycrKmT5+uTp06KS4uTj/++KMmT56s5ORk11/qXmrM0NBQ3XvvvRo/frzq16+vkJAQ/f73v1d8fLy6d+9eWefiivvuO+nHHwufpDBggNXVAAAAgGxbATnfSbk/SvYAKZJwCwAAAO909PRRbcrcJElKiE2wuBoAAICao9yNCsOHD9fhw4f19NNPKysrSx07dtTixYsVHh4uSdq7d6/bvzKbNGmSbDabJk2apAMHDigsLEzJycn605/+VOYxJenFF1+U3W7Xbbfdpry8PPXr10+vvvpqRY69yjmnfbjpJqlOHWtrAQAAANm2QpzTPkTcJPkRbgEAAOCdVuxZIYdxqFWDVooKibK6HAAAgBrDZowxVhdRFY4fP67Q0FDl5ORY9qjc666TNm+W3n5buuceS0oAAACoFjwh21nJI47/i+uko5uluLelFoRbAACAy+UR2c5CVh//7xf9Xq9seEW/7fJbvTrQy5qHAQAAPEx5sp291E9RaXbvLmxSsNulW2+1uhoAAACgAnJ3FzYp2OxSE8ItAAAAvFdqRqokKTE20eJKAAAAahYaFaqIc9qHXr2khg2trQUAAACokP3nw21YLymQcAsAAADvdPDEQW07sk022XRj7I1WlwMAAFCj0KhQRZyNCkOGWFsHAAAAUGH7zofbaMItAAAAvNfSjKWSpE6NO6l+UH2LqwEAAKhZaFSoAtnZ0sqVhe9pVAAAAIBXO50tHT4fbqMItwAAAPBezkaFhJgEiysBAACoeWhUqAILF0rGSF26SNHRVlcDAAAAVMCBhZKMVL+LFEy4BQAAgHcyxig1I1WSlNg80eJqAAAAah4aFaoA0z4AAACg2mDaBwAAAFQDO4/u1N6cvfKz++mGpjdYXQ4AAECNQ6PCFZaTI6UWNuZq6FBrawEAAAAqJD9Hyj4fbqMItwAAAPBeqbsKc233qO4K9g+2uBoAAICah0aFK2zRIik/X2rTpvAFAAAAeK2DiyRHvhTSRgol3AIAAMB7uaZ9iGXaBwAAACvQqHCFMe0DAAAAqo3958NtFOEWAACgupo5c6ZiYmIUGBiouLg4rV+/vsR1582bpy5duqhu3boKDg5Wx44d9c9//rMKq708DuPQ0oylkqTE5jQqAAAAWIFGhSvozJnCJypITPsAAAAAL1dwpvCJCpIUTbgFAACojubOnavx48drypQp2rRpkzp06KB+/frp0KFDxa5fv359PfXUU1qzZo22bt2q0aNHa/To0fryyy+ruPLy+Sb7G/10+ifV8qulbk26WV0OAABAjUSjwhW0ZIl08qQUHS117mx1NQAAAEAFZC6Rzp2UakVL9Qm3AAAA1dH06dN1//33a/To0brmmmv0+uuvq1atWnrnnXeKXb9Pnz4aMmSIrr76arVo0UIPP/yw2rdvr5UrV1Zx5eXjnPahV7Ne8vfxt7gaAACAmolGhSvIOe3D4MGSzWZpKQAAAEDFuKZ9GEy4BQAAqIby8/OVlpampKQk1zK73a6kpCStWbPmktsbY5Samqr09HT16tWrxPXy8vJ0/Phxt1dVczYqJMYy7QMAAIBVaFS4Qs6dkxYuLHw/hCl8AQAA4M0c56QD58NtNOEWAACgOjpy5IgKCgoUHh7utjw8PFxZWVklbpeTk6PatWvL399fAwcO1Msvv6ybbrqpxPVTUlIUGhrqekVHR1faMZTF2YKz+u+e/0qiUQEAAMBKNCpcIf/7n/TTT1KDBtINN1hdDQAAAFABh/8n5f0kBTSQwgi3AAAA+EWdOnW0ZcsWbdiwQX/60580fvx4LV++vMT1J06cqJycHNdr3759VVespPUH1is3P1cNghqoQ0SHKt03AAAAfuFrdQHVVffu0vz50pEjki9nGQAAAN6sQXep13wp74hkJ9wCAABURw0bNpSPj4+ys7PdlmdnZysiIqLE7ex2u1q2bClJ6tixo7Zt26aUlBT16dOn2PUDAgIUEBBQaXWXV/vw9pp3+zz9dPon2W38Oz4AAACr8LeMV0hQkDRokNVVAAAAAJXAN0iKItwCAABUZ/7+/urcubNSU1M1ePBgSZLD4VBqaqrGjRtX5nEcDofy8vKuUJUVVyegjoZczXRmAAAAVqNRAQAAAAAAAACg8ePH66677lKXLl3UrVs3zZgxQydPntTo0aMlSaNGjVKTJk2UkpIiSUpJSVGXLl3UokUL5eXladGiRfrnP/+p1157zcrDAAAAgBegUQEAAAAAAAAAoOHDh+vw4cN6+umnlZWVpY4dO2rx4sUKDw+XJO3du1d2+y/TJZw8eVK/+93vtH//fgUFBalNmzZ67733NHz4cKsOAQAAAF7CZowxVhdRFY4fP67Q0FDl5OQoJCTE6nIAAABQATU929X04wcAAKhOanq2q+nHDwAAUJ2UJ9vZS/0UAAAAAAAAAAAAAACgEtGoAAAAAAAAAAAAAAAAqgyNCgAAAAAAAAAAAAAAoMrQqAAAAAAAAAAAAAAAAKoMjQoAAAAAAAAAAAAAAKDK0KgAAAAAAAAAAAAAAACqDI0KAAAAAAAAAAAAAACgytCoAAAAAAAAAAAAAAAAqgyNCgAAAAAAAAAAAAAAoMrQqAAAAAAAAAAAAAAAAKoMjQoAAAAAAAAAAAAAAKDK0KgAAAAAAAAAAAAAAACqjK/VBVQVY4wk6fjx4xZXAgAAgIpyZjpnxqtpyLYAAADVB9mWbAsAAFBdlCfb1phGhRMnTkiSoqOjLa4EAAAAleXEiRMKDQ21uowqR7YFAACofsi2ZFsAAIDqoizZ1mZqSKuuw+HQwYMHVadOHdlstirZ5/HjxxUdHa19+/YpJCSkSvZZ1arbMXrz8XhD7Z5aoyfVZVUtVb3fiu7vStdb2eNX5niXM1Zl7d+TxrnS59STavSGcay4dxljdOLECUVGRspur3mzmZFtr4zqdozefDzeULun1uhJdZFtq2b7qh6fbFv545BtPWscsm3VI9teGdXtGL35eLyhdk+t0ZPqIttWzfZVPT7ZtvLHIdt61jienm1rzBMV7Ha7oqKiLNl3SEiI5X+IXmnV7Ri9+Xi8oXZPrdGT6rKqlqreb0X3d6XrrezxK3O8yxmrsvbvSeNc6XPqSTV6wzhVfQ+pif/azIlse2VVt2P05uPxhto9tUZPqotsWzXbV/X4ZNvKH4ds61njkG2rDtn2yqpux+jNx+MNtXtqjZ5UF9m2arav6vHJtpU/DtnWs8bx1Gxb81p0AQAAAAAAAAAAAACAZWhUAAAAAAAAAAAAAAAAVYZGhSsoICBAU6ZMUUBAgNWlXDHV7Ri9+Xi8oXZPrdGT6rKqlqreb0X3d6XrrezxK3O8yxmrsvbvSeNc6XPqSTV6wziedB/FlVMTfs/V7Ri9+Xi8oXZPrdGT6iLbVs32VT0+2bbyxyHbetY4nnQfxZVTE37P1e0Yvfl4vKF2T63Rk+oi21bN9lU9Ptm28sch23rWOJ50Hy2OzRhjrC4CAAAAAAAAAAAAAADUDDxRAQAAAAAAAAAAAAAAVBkaFQAAAAAAAAAAAAAAQJWhUQEAAAAAAAAAAAAAAFQZGhUu09SpU2Wz2dxebdq0KXWbjz/+WG3atFFgYKDatWunRYsWVVG1ZfPf//5XycnJioyMlM1m0/z5812fnT17Vk888YTatWun4OBgRUZGatSoUTp48GCpY17OeaospR2PJGVnZ+vuu+9WZGSkatWqpf79+2vHjh2ljjlv3jx16dJFdevWVXBwsDp27Kh//vOflV57SkqKunbtqjp16qhRo0YaPHiw0tPT3dbp06dPkXP74IMPlnkfDz74oGw2m2bMmHFZNb722mtq3769QkJCFBISovj4eH3xxReuz8+cOaOxY8eqQYMGql27tm677TZlZ2eXOmZubq7GjRunqKgoBQUF6ZprrtHrr79eqXVdznmrjLr+/Oc/y2az6ZFHHnEtu5xzNHXqVLVp00bBwcGqV6+ekpKStG7dunLv28kYowEDBhR7jVzOvi/e1+7du4ucb+fr448/do178WdXXXWV6/oMCgpS06ZNVa9evTKfJ2OMnn76adWuXbvUe9ADDzygFi1aKCgoSGFhYRo0aJB++OGHUscePnx4qWOW5ztW3LHb7XbXdywrK0sjR45URESEgoODdd111+nf//63Dhw4oN/85jdq0KCBgoKC1K5dO23cuFFS4TXQrl07BQQEyG63y263q1OnTsXe3y4eJzIyUo0bN1ZgYKC6du2qUaNGXfK+f/EYTZo0UcuWLYu9Bku771w8Tps2bTRgwAC3Y/z444916623KjQ0VMHBweratav27t1b6jjh4eHy9fUt9jvo6+ur/v3769tvvy31Wpw3b54CAgKKHSM4OFiBgYGKjo5W8+bNXd/Xhx56SDk5OUWOMyYmpthxAgIC3K6p0q7NksaIjY11nZurr75aPXr0UHBwsEJCQtSrVy+dPn26zPXUrl1bkZGRCgwMVHBwsIKDg1WnTh3dfvvtys7Odl1jjRs3VlBQkJKSklzfsdLuwzNnzlRMTIwCAwMVFxen9evXF6kJ1iDbkm3JtmTb8iDbkm1LOqdk2+LHIduSbVG1yLZkW7It2bY8yLZk25LOKdm2+HHItmTbykSjQgW0bdtWmZmZrtfKlStLXHf16tW64447dO+992rz5s0aPHiwBg8erG+//bYKKy7dyZMn1aFDB82cObPIZ6dOndKmTZs0efJkbdq0SfPmzVN6erpuvfXWS45bnvNUmUo7HmOMBg8erF27dmnBggXavHmzmjVrpqSkJJ08ebLEMevXr6+nnnpKa9as0datWzV69GiNHj1aX375ZaXWvmLFCo0dO1Zr167VkiVLdPbsWfXt27dIbffff7/buX3++efLNP4nn3yitWvXKjIy8rJrjIqK0p///GelpaVp48aNSkhI0KBBg/Tdd99Jkh599FF9+umn+vjjj7VixQodPHhQQ4cOLXXM8ePHa/HixXrvvfe0bds2PfLIIxo3bpwWLlxYaXVJ5T9vFa1rw4YNeuONN9S+fXu35Zdzjlq1aqVXXnlF33zzjVauXKmYmBj17dtXhw8fLte+nWbMmCGbzVam47jUvovbV3R0tNu5zszM1DPPPKPatWtrwIABrvUuvE8cPHhQoaGhrutz8ODB+vnnn+Xv76/FixeX6Tw9//zz+vvf/65bbrlFLVq0UN++fRUdHa2MjAy3e1Dnzp01a9Ysbdu2TV9++aWMMerbt68KCgpKHDs/P1+NGjXSCy+8IElasmRJkftaeb5jbdu21Z133qlmzZrp3//+tzZu3Oj6jg0YMEDp6elauHChvvnmGw0dOlTDhg1T165d5efnpy+++ELff/+9/va3v6levXqSCq+BLl26KCAgQK+88oruvfdeff3110pISNCZM2dc+z169Kh69uzpGuf555/X4cOH9cgjj2jTpk1q27atPvjgAz300EMl3vcvHuP777/XAw88oIkTJxa5Bl966aUS7zsXj7NmzRodPXpUtWrVco372GOPacyYMWrTpo2WL1+urVu3avLkyQoMDCxxnFGjRuncuXN64YUXtHbtWk2bNk2S1KJFC0nSO++8o2bNmik+Pl4LFy4s8VqsX7++3njjDa1YsUJr1qzRs88+6/ps4sSJev/991VQUKBTp04pLS1Ns2fP1uLFi3XvvfcWOdYNGza4vhczZ87UX/7yF0nS66+/7nZNlXZtXjhGZmam3n33XUlSXFycli9frtmzZ2vv3r1KSEjQ+vXrtWHDBo0bN052e9HY5xwrOTlZrVq10t/+9jdJ0rlz53Ts2DE1bNhQ1157rSRp7Nixys/PV3Jysv7yl7/o73//u15//XWtW7dOwcHB6tevn86cOVPiffiFF17Q+PHjNWXKFG3atEkdOnRQv379dOjQoWKPE1WPbEu2JduSbcuCbEu2JduSbZ3ItmRbT0a2JduSbcm2ZUG2JduSbcm2TmRbi7KtwWWZMmWK6dChQ5nXv/32283AgQPdlsXFxZkHHnigkiurHJLMJ598Uuo669evN5LMnj17SlynvOfpSrn4eNLT040k8+2337qWFRQUmLCwMPPWW2+Va+xOnTqZSZMmVVapxTp06JCRZFasWOFa1rt3b/Pwww+Xe6z9+/ebJk2amG+//dY0a9bMvPjii5VWZ7169cz//d//mWPHjhk/Pz/z8ccfuz7btm2bkWTWrFlT4vZt27Y1zz77rNuy6667zjz11FOVUpcxl3feKlLXiRMnzFVXXWWWLFnitu/LPUcXy8nJMZLMV199VeZ9O23evNk0adLEZGZmlumaL23fl9rXhTp27Gjuuece188X3ycuvD6d52nu3Lmu6/NS58nhcJiIiAjz17/+1TX2sWPHTEBAgPnggw9KPaavv/7aSDI//vhjies4x8zIyDCSzObNm90+L893zDlWSd8xPz8/849//MNteWBgoGnZsmWJY154/E5169Y1vr6+bsf/xBNPmOuvv971c7du3czYsWNdPxcUFJjIyEiTkpLiWnbxff/iMUoSGhpq6tWrV+J95+Jxiht3+PDh5je/+U2p+7l4u8aNG5tXXnnF9bPzuxUTE2NatGhhHA6H+fnnn40k8+CDD7rWK8t3zGazmaCgIONwOIwxpsh37KOPPjL+/v7m7Nmzpdb88MMPu2pxXlOvv/56ua7Nq666ytSuXdtVS1xcXLn+XDp16pTx8fExn332mXn44YdNrVq1zOjRo03Lli2NzWYzOTk5ZujQoebOO+80x44dM5JM/fr13b5jl7rG6tWrZ2JjYy/5HYN1yLZkWyey7S/ItkWRbYsi2xYdi2xLtiXbwmpkW7KtE9n2F2Tbosi2RZFti45FtiXbkm2vLJ6oUAE7duxQZGSkmjdvrjvvvLPIY0wutGbNGiUlJbkt69evn9asWXOly7xicnJyZLPZVLdu3VLXK895qip5eXmS5NbRZbfbFRAQUObOYWOMUlNTlZ6erl69el2ROp2cj6GpX7++2/L333/f1TU1ceJEnTp1qtRxHA6HRo4cqT/84Q9q27ZtpdVXUFCgDz/8UCdPnlR8fLzS0tJ09uxZt+98mzZt1LRp01K/8z169NDChQt14MABGWO0bNkybd++XX379q2UupzKe94qUtfYsWM1cODAItf/5Z6jC+Xn5+vNN99UaGioOnToUOZ9S4Xd9iNGjNDMmTMVERFRpv2Vtu/S9nWhtLQ0bdmypUjH4oX3iUcffVRS4fXpPE99+/Z1XZ+XOk8ZGRnKyspy1bJjxw5dffXVstlsmjp1aon3oJMnT2rWrFmKjY1VdHR0qcexY8cOxcXFSZKefPLJImOW5zu2Y8cOZWRk6P/9v/+nIUOGaM+ePa7vWIcOHTR37lz9/PPPcjgc+vDDD5WXl6frr79ew4YNU6NGjdSpUye99dZbxR6/8xo4deqUOnbs6HbOFi5cqC5durjGWb9+vRwOh+tzu92upKQkt20uvu9fPMbFtRQUFGjOnDk6fvy4HnjggRLvOxePM2PGDAUEBLh+7tixo+bPn69WrVqpX79+atSokeLi4oo8WuvicQ4dOuT2iCrnvX/v3r265557ZLPZtHnzZtexOZX2HTPGaPbs2TLG6KabbnJ1z4aGhiouLs61TU5OjkJCQuTr61vsMUuF19F7772ne+65R2fPntWbb76pkJAQTZ8+vczX5pkzZ1zfx/79+6thw4Zat26dsrKy1KNHD4WHh6t3796l/tl27tw5FRQUyMfHR++995569uyppUuXyuFwyBij9PR0rVy5UgMGDFBgYKDsdrt+/vlnt+v94uN3cn4Hc3NztXfvXrdtivuOwVpkW7It2bYQ2bZkZFt3ZNvixyLbkm3JtvAEZFuyLdm2ENm2ZGRbd2Tb4sci25JtybZX2BVvhaimFi1aZD766CPz9ddfm8WLF5v4+HjTtGlTc/z48WLX9/PzM3PmzHFbNnPmTNOoUaOqKLfcdIlOoNOnT5vrrrvOjBgxotRxynuerpSLjyc/P980bdrUDBs2zPz8888mLy/P/PnPfzaSTN++fUsd69ixYyY4ONj4+vqagIAA8/bbb1/R2gsKCszAgQNNz5493Za/8cYbZvHixWbr1q3mvffeM02aNDFDhgwpdaxp06aZm266ydW9VdHO3K1bt5rg4GDj4+NjQkNDzeeff26MMeb99983/v7+Rdbv2rWr+eMf/1jieGfOnDGjRo0ykoyvr6/x9/c37777bqXVZczlnbfLreuDDz4w1157rTl9+rQxxr1j83LPkTHGfPrppyY4ONjYbDYTGRlp1q9fX659G2PMmDFjzL333uv6+VLXfGn7vtS+LvTb3/7WXH311W7LLr5PdO/e3fj4+JjBgwebN9980/j7+xe5Pks7T6tWrTKSzMGDB93GvuGGG0yDBg2K3INmzpxpgoODjSTTunXrUrtyL6x30aJFRpJp376925jl+Y45x9qwYYNJTEw0kowk4+fnZ959911z9OhR07dvX9d3LyQkxPj5+ZmAgAAzceJEs2nTJvPGG2+YwMBAM3v2bLfjDwoKcrsGhg0bZm6//XbXvgMCAlzjfPnll0aS8ff3d41jjDF/+MMfTLdu3Ywxxd/3Lxzjwlqee+451zUYEBBgOnXqVOp95+JxfH19jSQzcOBAs2nTJvP888+76ps+fbrZvHmzSUlJMTabzSxfvrzEcbp27WpsNpv585//bAoKCly/M0nmu+++M3l5eebXv/51sff+i79jF977fXx8jCSzadMmt22c5/jw4cOmadOm5sknnyz1uzR37lxjt9tNUFCQ65oaMmRIua7NN954w0gygYGBZvr06ebdd991HeMTTzxhNm3aZB555BHj7+9vtm/fXuI48fHx5uqrrzY+Pj5m9+7d5pZbbnGNI8lMnTrV5ObmmnHjxrmWHTx4sNjjN6boffgf//iHkWRWr17tts2F3zFYi2xLtiXbkm0vhWxbFNm2+LHItmRbsi2sRrYl25JtybaXQrYtimxb/FhkW7It2fbKolGhkhw9etSEhIS4HlN0seoUePPz801ycrLp1KmTycnJKde4lzpPV0pxx7Nx40bToUMHI8n4+PiYfv36mQEDBpj+/fuXOlZBQYHZsWOH2bx5s3nhhRdMaGioWbZs2RWr/cEHHzTNmjUz+/btK3W91NTUUh99tHHjRhMeHm4OHDjgWlbRwJuXl2d27NhhNm7caCZMmGAaNmxovvvuu8sOc3/9619Nq1atzMKFC83XX39tXn75ZVO7dm2zZMmSSqmrOJc6b5db1969e02jRo3M119/7VpWWYE3NzfX7Nixw6xZs8bcc889JiYmxmRnZ5d53wsWLDAtW7Y0J06ccH1e1sB78b6joqJMw4YNS9zXhU6dOmVCQ0PNCy+8UOo+jh49aoKDg01UVJTrD9aLr8+yBt4LDRs2zAwePLjIPejYsWNm+/btZsWKFSY5Odlcd911rvBeGucjxP773/+Wel8rz3dszpw5pnbt2mbEiBGmdu3aZtCgQaZbt27mq6++Mlu2bDFTp041koo8mvH3v/+96d69u9vxr1q1yu0a6Nevn1vg9fPzM/Hx8cYYYw4cOGAkmV/96leucYz5JYyUdN+/cIwLa4mLizM7duww//znP01wcLCpV6+e6xos7r5z8Th+fn4mIiLCVYuzvgYNGrhtl5ycbH7961+XOM6hQ4dMbGys6z7fqlUrEx4e7vpe+fj4mHbt2hmbzVbk3n/xd+zCe390dLSRZP71r3+5bTNs2DAzZMgQ061bN9O/f3+Tn59vStO3b18zYMAA1zWVlJRkfH19za5du1zrXOra7N27t5Fk7rjjDmPML7//li1bup2bdu3amQkTJpQ4zo8//mjq1atnJBmbzWb8/PxMz549TXh4uAkLC3Mt/81vfmNatWp1ycB78X3YOTZ/mes9yLZlQ7YtP7It2fZiZFuyLdm2ENmWbIsrh2xbNmTb8iPbkm0vRrYl25JtC5FtybZlRaNCJerSpUuJX6bo6OgiF/jTTz9t2rdvXwWVlV9JF1h+fr4ZPHiwad++vTly5MhljV3aebpSSrthHDt2zBw6dMgYUzjXz+9+97tyjX3vvfdespv3co0dO9ZERUW53fxKkpubaySZxYsXF/v5iy++aGw2m/Hx8XG9JBm73W6aNWtWKfUmJiaaMWPGuP6AP3r0qNvnTZs2NdOnTy9221OnThk/Pz/z2WefuS2/9957Tb9+/SqlruJc6rxdbl2ffPKJ6w/UC8+383fw1VdflfsclaRly5Zm2rRpZd73uHHjSvwu9O7du1z7joiIKHVf586dc637j3/8w/j5+bmut9I47xMLFixwnacLr8/SztPOnTuNVHQOsl69epmHHnqo1HtQXl6eqVWrVpG/oCjOhXOdlTZmeb9jzrGGDRtmJPc5GY0pnOusTZs2bsteffVVExkZWeLxJyYmmsaNG5uHHnrItaxp06auDtC8vDzj4+NjHnjgAdc4xhgzatQoc8stt5R4379wjOJqcd53nK+S7jsXj9O0aVPTo0cP1zh5eXnGbrebOnXquO3rj3/8o+nRo8cl62ncuLHZv3+/ycjIMDabzURHR7vu/c771cXblfQd2717t7Hb7UaS2/84MMaYHj16mIiICJOYmHjJ/9HkHGf+/PmuZQ8//LDr/JTl2nSOYbfbzXPPPWeMMWbXrl2uruYLz83tt99e6r+mcY714YcfuuaIu/32283NN99sjDFmwoQJ5qqrrjLGGNOgQYNSr7Hi3HjjjcZmsxX5s3jUqFHm1ltvLbEuWItsWzZk27Ij25Jty4Js645sS7a9uB6yLdkWl4dsWzZk27Ij25Jty4Js645sS7a9uB6yLdnWLlSK3Nxc7dy5U40bNy728/j4eKWmprotW7Jkidv8S57u7Nmzuv3227Vjxw599dVXatCgQbnHuNR5skJoaKjCwsK0Y8cObdy4UYMGDSrX9g6HwzV/TmUxxmjcuHH65JNPtHTpUsXGxl5ymy1btkhSied25MiR2rp1q7Zs2eJ6RUZG6g9/+IO+/PLLSqnbeS46d+4sPz8/t+98enq69u7dW+J3/uzZszp79qzsdvfbko+Pj9v8SxWpqziXOm+XW1diYqK++eYbt/PdpUsX3Xnnna735T1HZT2+S+37qaeeKvJdkKQXX3xRs2bNKte+AwMD9dvf/rbEffn4+LjWffvtt3XrrbcqLCys1DEvvE/07t1bfn5+eu+991zX56XOU2xsrCIiItzO7fHjx7Vu3Tp16tSp1HuQKWzgK9c1ferUqVLHLM937MJjN8ZIUpHvXt26dXX06FG3Zdu3b1ezZs0kFX/8+fn5ys7OdjtnPXv2VHp6uiTJ399fnTt31tq1a13jOBwOffXVV9q1a1eJ9/0LxyiuFud9p0uXLkpOTi7xvnPxOD179tTu3btd4/j7+ys8PFwBAQEl7qu0emJiYtSkSRO9/fbbstvtGjFihOve75y37cLfT2nfsVmzZqlRo0YKDAzUoUOHXMv379+vNWvWqF69elq4cKHbXJrFcY4zcOBA17IJEyYoKipKDzzwQJmuTecY3bp1cx13TEyMIiMjtWPHDrdzc/G5Kmms2267TXl5eTpz5oy+/PJL15+JISEhkqSlS5fqp59+UlhYWLHXWGn3rwYNGrht43A4lJqa6lVZqCYh25YN2bZsyLa/INuW//jItmRbsq37OmRbsi3Kj2xbNmTbsiHb/oJsW/7jI9uSbcm27uuQbcm2PFHhMj322GNm+fLlJiMjw6xatcokJSWZhg0bujrORo4c6daltWrVKuPr62teeOEFs23bNjNlyhTj5+dnvvnmG6sOoYgTJ06YzZs3m82bNxtJrvlk9uzZY/Lz882tt95qoqKizJYtW0xmZqbrlZeX5xojISHBvPzyy66fL3WerDoeY4z56KOPzLJly8zOnTvN/PnzTbNmzczQoUPdxrj49zht2jTzn//8x+zcudN8//335oUXXjC+vr7mrbfeqtTaf/vb35rQ0FCzfPlyt3N96tQpY0zho16effZZs3HjRpORkWEWLFhgmjdvbnr16uU2TuvWrc28efNK3E9FHiE2YcIEs2LFCpORkWG2bt1qJkyYYGw2m/nPf/5jjCl89FnTpk3N0qVLzcaNG018fHyRRw1dXF/v3r1N27ZtzbJly8yuXbvMrFmzTGBgoHn11Vcrpa7LPW+VUZdznAsfrVXec5Sbm2smTpxo1qxZY3bv3m02btxoRo8ebQICAop0b15q3xdTMd3rl7vv4va1Y8cOY7PZzBdffFFk34899piJjo42r7/+uus+UadOHfPJJ5+YnTt3mv79+xsfHx9zww03lPm79Oc//9nUrVvXDB482LzzzjvmpptuMo0bNzYJCQmue9DOnTvNtGnTzMaNG82ePXvMqlWrTHJysqlfv77bI9kuHnvs2LHmrbfeMu+8846RZNq1a2fq1q1rvvnmm3J/x5z3yLi4OBMbG2s6d+5s6tevb1566SUTEBBgwsLCzA033GDWrVtnfvzxR/PCCy+4OqH/9Kc/mR07dphrrrnG+Pv7m/fee88YU3gNPPDAAyYkJMS89NJL5p577jGSTEREhFu3aJcuXYzdbneN45zDasyYMeb777839913n/H19TWRkZEl3vfXr19vbDabueWWW8yOHTvM+++/b/z8/MykSZNKvDcUd9+5uJZnn33WSDLDhg1zjevv7298fHzMm2++aXbs2GFefvll4+PjY/73v/+5xhkwYIDbOM8884wJCAgw06dPN8uXLzcBAQGmVq1a5tNPP3W798fGxrpdi2FhYaZJkyaucadNm2aioqLMK6+8Yho3bmxuvPFGY7fbTa1atcyCBQvM6tWrTb169Yyfn5/57rvv3M7Vhd3pzt97QUGBiY6ONt27d7/kNVXStfmvf/3LNG3a1DzxxBNm3rx5xs/Pz3Vuhg4daiSZZ5991uzYscNMmjTJBAYGuj3G7sI/rwsKCkyjRo3MsGHDzK5du8xNN91k/Pz8TKtWrUxKSopJSUkx9erVMwMHDjT169c348ePd11jCxYsMN26dTPt2rUzsbGx5vTp0677cI8ePczEiRNd34Enn3zSBAQEmNmzZ5vvv//ejBkzxtStW9dkZWUZWI9sS7Yl25JtybZkW7It2ZZsS7atLsi2ZFuyLdmWbEu2JduSbcm23pFtaVS4TMOHDzeNGzc2/v7+pkmTJmb48OFuX6TevXubu+66y22bjz76yLRq1cr4+/ubtm3bms8//7yKqy7dsmXLjM7P/3Lh66677nI9Kqe414XzfDVr1sxMmTLF9fOlzpNVx2OMMS+99JKJiooyfn5+pmnTpmbSpElu4d2Yor/Hp556yrRs2dIEBgaaevXqmfj4ePPhhx9Weu0lnetZs2YZYwrnsurVq5epX7++CQgIMC1btjR/+MMfisw9d+E2xalI4L3nnntMs2bNjL+/vwkLCzOJiYmuP9CMMeb06dPmd7/7nalXr56pVauWGTJkiMnMzCy1vszMTHP33XebyMhIExgYaFq3bm3+9re/GYfDUSl1Xe55q4y6jCkaBMt7jk6fPm2GDBliIiMjjb+/v2ncuLG59dZbzfr168u974sV94fq5e67uH1NnDjRREdHm4KCgiLrDx8+3Egyvr6+rvvE5MmTXddndHS06dy5c7m+Sw6Hw0yePNkEBAS4HmkWHh7udg86cOCAGTBggGnUqJHx8/MzUVFRZsSIEeaHH34odexu3boVe31OmTKl3N+xC++RtWrVMoGBgcbf39/1HUtPTzdDhw41jRo1MrVq1TLt27c3//jHP8ynn35qrr32WhMQEGB8fX3NLbfc4hr7nnvuMU2bNjV2u93YbDZjt9tNp06dTHp6ulsNzZo1M3fccYdrnDZt2phf//rXpmnTpsbf3981F+Sl7vthYWGmUaNGrjF69uxZ6r2huPtOcbWMGzfO7ec333zTvP322657cIcOHdwev2VM4XcvISHBtV3Tpk1NRESECQgIMHXq1DGSzEMPPVTk3p+Tk+N2LTZs2NBtXrinnnrK9SgvSaZjx47mgw8+MJMnTzbh4eHGz8+vxHOVkZFR5Pf+5ZdfGkkmKSnpktdUSdfmY489ZiS5fq8Xn5uRI0eaqKgoU6tWLRMfH+/2Pwyc59z557WznqioKOPv728aNWpk2rdvb6Kiooyvr6/x8fExdrvdtGzZ0nXvc15jzrnjYmNjXbU478OSTK1atdy+Ay+//LLrO9atWzezdu1aA89AtiXbkm3JtmRbsi3ZlmxLtiXbVhdkW7It2ZZsS7Yl25JtybZkW+/ItrbzJw4AAAAAAAAAAAAAAOCKs196FQAAAAAAAAAAAAAAgMpBowIAAAAAAAAAAAAAAKgyNCoAAAAAAAAAAAAAAIAqQ6MCAAAAAAAAAAAAAACoMjQqAAAAAAAAAAAAAACAKkOjAgAAAAAAAAAAAAAAqDI0KgAAAAAAAAAAAAAAgCpDowIAAAAAAAAAAAAAAKgyNCoAQA00depUhYeHy2azaf78+WXaZvny5bLZbDp27NgVrc2TxMTEaMaMGVaXAQAAgFKQbcuGbAsAAOD5yLZlQ7YFqgcaFQB4hLvvvls2m002m03+/v5q2bKlnn32WZ07d87q0i6pPKHRE2zbtk3PPPOM3njjDWVmZmrAgAFXbF99+vTRI488csXGBwAA8ERk26pDtgUAALiyyLZVh2wLoKbxtboAAHDq37+/Zs2apby8PC1atEhjx46Vn5+fJk6cWO6xCgoKZLPZZLfTj3WxnTt3SpIGDRokm81mcTUAAADVE9m2apBtAQAArjyybdUg2wKoafiTAIDHCAgIUEREhJo1a6bf/va3SkpK0sKFCyVJeXl5evzxx9WkSRMFBwcrLi5Oy5cvd207e/Zs1a1bVwsXLtQ111yjgIAA7d27V3l5eXriiScUHR2tgIAAtWzZUm+//bZru2+//VYDBgxQ7dq1FR4erpEjR+rIkSOuz/v06aOHHnpIf/zjH1W/fn1FRERo6tSprs9jYmIkSUOGDJHNZnP9vHPnTg0aNEjh4eGqXbu2unbtqq+++srteDMzMzVw4EAFBQUpNjZWc+bMKfLIqmPHjum+++5TWFiYQkJClJCQoK+//rrU8/jNN98oISFBQUFBatCggcaMGaPc3FxJhY8OS05OliTZ7fZSA++iRYvUqlUrBQUF6cYbb9Tu3bvdPv/pp590xx13qEmTJqpVq5batWunDz74wPX53XffrRUrVuill15ydV3v3r1bBQUFuvfeexUbG6ugoCC1bt1aL730UqnH5Pz9Xmj+/Plu9X/99de68cYbVadOHYWEhKhz587auHGj6/OVK1fqhhtuUFBQkKKjo/XQQw/p5MmTrs8PHTqk5ORk1+/j/fffL7UmAACA0pBtybYlIdsCAABvQ7Yl25aEbAugImhUAOCxgoKClJ+fL0kaN26c1qxZow8//FBbt27VsGHD1L9/f+3YscO1/qlTp/SXv/xF//d//6fvvvtOjRo10qhRo/TBBx/o73//u7Zt26Y33nhDtWvXllQYJhMSEtSpUydt3LhRixcvVnZ2tm6//Xa3Ot59910FBwdr3bp1ev755/Xss89qyZIlkqQNGzZIkmbNmqXMzEzXz7m5ubr55puVmpqqzZs3q3///kpOTtbevXtd444aNUoHDx7U8uXL9e9//1tvvvmmDh065LbvYcOG6dChQ/riiy+Ulpam6667TomJifr555+LPWcnT55Uv379VK9ePW3YsEEff/yxvvrqK40bN06S9Pjjj2vWrFmSCgN3ZmZmsePs27dPQ4cOVXJysrZs2aL77rtPEyZMcFvnzJkz6ty5sz7//HN9++23GjNmjEaOHKn169dLkl566SXFx8fr/vvvd+0rOjpaDodDUVFR+vjjj/X999/r6aef1pNPPqmPPvqo2FrK6s4771RUVJQ2bNigtLQ0TZgwQX5+fpIK/wdI//79ddttt2nr1q2aO3euVq5c6TovUmFA37dvn5YtW6Z//etfevXVV4v8PgAAAC4X2ZZsWx5kWwAA4MnItmTb8iDbAiiRAQAPcNddd5lBgwYZY4xxOBxmyZIlJiAgwDz++ONmz549xsfHxxw4cMBtm8TERDNx4kRjjDGzZs0yksyWLVtcn6enpxtJZsmSJcXu87nnnjN9+/Z1W7Zv3z4jyaSnpxtjjOndu7e5/vrr3dbp2rWreeKJJ1w/SzKffPLJJY+xbdu25uWXXzbGGLNt2zYjyWzYsMH1+Y4dO4wk8+KLLxpjjPnf//5nQkJCzJkzZ9zGadGihXnjjTeK3cebb75p6tWrZ3Jzc13LPv/8c2O3201WVpYxxphPPvnEXOr2P3HiRHPNNde4LXviiSeMJHP06NEStxs4cKB57LHHXD/37t3bPPzww6Xuyxhjxo4da2677bYSP581a5YJDQ11W3bxcdSpU8fMnj272O3vvfdeM2bMGLdl//vf/4zdbjenT592fVfWr1/v+tz5O3L+PgAAAMqKbEu2JdsCAIDqgmxLtiXbArhSfK94JwQAlNFnn32m2rVr6+zZs3I4HBoxYoSmTp2q5cuXq6CgQK1atXJbPy8vTw0aNHD97O/vr/bt27t+3rJli3x8fNS7d+9i9/f1119r2bJlrk7dC+3cudO1vwvHlKTGjRtfsmMzNzdXU6dO1eeff67MzEydO3dOp0+fdnXmpqeny9fXV9ddd51rm5YtW6pevXpu9eXm5rodoySdPn3aNV/ZxbZt26YOHTooODjYtaxnz55yOBxKT09XeHh4qXVfOE5cXJzbsvj4eLefCwoKNG3aNH300Uc6cOCA8vPzlZeXp1q1al1y/JkzZ+qdd97R3r17dfr0aeXn56tjx45lqq0k48eP13333ad//vOfSkpK0rBhw9SiRQtJhedy69atbo8FM8bI4XAoIyND27dvl6+vrzp37uz6vE2bNkUeWwYAAFBWZFuybUWQbQEAgCch25JtK4JsC6AkNCoA8Bg33nijXnvtNfn7+ysyMlK+voW3qNzcXPn4+CgtLU0+Pj5u21wYVoOCgtzmvgoKCip1f7m5uUpOTtZf/vKXIp81btzY9d75GConm80mh8NR6tiPP/64lixZohdeeEEtW7ZUUFCQfvWrX7keiVYWubm5aty4sducbk6eEMT++te/6qWXXtKMGTPUrl07BQcH65FHHrnkMX744Yd6/PHH9be//U3x8fGqU6eO/vrXv2rdunUlbmO322WMcVt29uxZt5+nTp2qESNG6PPPP9cXX3yhKVOm6MMPP9SQIUOUm5urBx54QA899FCRsZs2bart27eX48gBAAAujWxbtD6ybSGyLQAA8DZk26L1kW0LkW0BVASNCgA8RnBwsFq2bFlkeadOnVRQUKBDhw7phhtuKPN47dq1k8Ph0IoVK5SUlFTk8+uuu07//ve/FRMT4wrXl8PPz08FBQVuy1atWqW7775bQ4YMkVQYXnfv3u36vHXr1jp37pw2b97s6gb98ccfdfToUbf6srKy5Ovrq5iYmDLVcvXVV2v27Nk6efKkqzt31apVstvtat26dZmP6eqrr9bChQvdlq1du7bIMQ4aNEi/+c1vJEkOh0Pbt2/XNddc41rH39+/2HPTo0cP/e53v3MtK6nT2CksLEwnTpxwO64tW7YUWa9Vq1Zq1aqVHn30Ud1xxx2aNWuWhgwZouuuu07ff/99sd8vqbAL99y5c0pLS1PXrl0lFXZPHzt2rNS6AAAASkK2JduWhGwLAAC8DdmWbFsSsi2AirBbXQAAXEqrVq105513atSoUZo3b54yMjK0fv16paSk6PPPPy9xu5iYGN1111265557NH/+fGVkZGj58uX66KOPJEljx47Vzz//rDvuuEMbNmzQzp079eWXX2r06NFFQlppYmJilJqaqqysLFdgveqqqzRv3jxt2bJFX3/9tUaMGOHWzdumTRslJSVpzJgxWr9+vTZv3qwxY8a4dRcnJSUpPj5egwcP1n/+8x/t3r1bq1ev1lNPPaWNGzcWW8udd96pwMBA3XXXXfr222+1bNky/f73v9fIkSPL/PgwSXrwwQe1Y8cO/eEPf1B6errmzJmj2bNnu61z1VVXacmSJVq9erW2bdumBx54QNnZ2UXOzbp167R7924dOXJEDodDV111lTZu3Kgvv/xS27dv1+TJk7Vhw4ZS64mLi1OtWrX05JNPaufOnUXqOX36tMaNG6fly5drz549WrVqlTZs2KCrr75akvTEE09o9erVGjdunLZs2aIdO3ZowYIFGjdunKTC/wHSv39/PfDAA1q3bp3S0tJ03333XbK7GwAAoLzItmRbsi0AAKguyLZkW7ItgIqgUQGAV5g1a5ZGjRqlxx57TK1bt9bgwYO1YcMGNW3atNTtXnvtNf3qV7/S7373O7Vp00b333+/Tp48KUmKjIzUqlWrVFBQoL59+6pdu3Z65JFHVLduXdntZb89/u1vf9OSJUsUHR2tTp06SZKmT5+uevXqqUePHkpOTla/fv3c5jWTpH/84x8KDw9Xr169NGTIEN1///2qU6eOAgMDJRU+qmzRokXq1auXRo8erVatWunXv/619uzZU2J4rVWrlr788kv9/PPP6tq1q371q18pMTFRr7zySpmPRyp8rNa///1vzZ8/Xx06dNDrr7+uadOmua0zadIkXXfdderXr5/69OmjiIgIDR482G2dxx9/XD4+PrrmmmsUFhamvXv36oEHHtDQoUM1fPhwxcXF6aeffnLr0i1O/fr19d5772nRokVq166dPvjgA02dOtX1uY+Pj3766SeNGjVKrVq10u23364BAwbomWeekVQ4X92KFSu0fft23XDDDerUqZOefvppRUZGusaYNWuWIiMj1bt3bw0dOlRjxoxRo0aNynXeAAAAyoJsS7Yl2wIAgOqCbEu2JdsCuFw2c/HkMQAAS+zfv1/R0dH66quvlJiYaHU5AAAAwGUj2wIAAKC6INsCwJVBowIAWGTp0qXKzc1Vu3btlJmZqT/+8Y86cOCAtm/fLj8/P6vLAwAAAMqMbAsAAIDqgmwLAFXD1+oCAKCmOnv2rJ588knt2rVLderUUY8ePfT+++8TdgEAAOB1yLYAAACoLsi2AFA1eKICAAAAAAAAAAAAAACoMnarCwAAAAAAAAAAAAAAADUHjQoAAAAAAAAAAAAAAKDK0KgAAAAAAAAAAAAAAACqDI0KAAAAAAAAAAAAAACgytCoAAAAAAAAAAAAAAAAqgyNCgAAAAAAAAAAAAAAoMrQqAAAAAAAAAAAAAAAAKoMjQoAAAAAAAAAAAAAAKDK0KgAAAAAAAAAAAAAAACqzP8HSEm5yHT0mLUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[2], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4be1b4",
   "metadata": {
    "papermill": {
     "duration": 0.293321,
     "end_time": "2025-03-25T16:11:14.699565",
     "exception": false,
     "start_time": "2025-03-25T16:11:14.406244",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd02be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 4\n",
      "Random seed: 3\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6456, Accuracy: 0.7865, F1 Micro: 0.8804, F1 Macro: 0.8788\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5639, Accuracy: 0.7894, F1 Micro: 0.8822, F1 Macro: 0.8807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5346, Accuracy: 0.7894, F1 Micro: 0.8822, F1 Macro: 0.8807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5259, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4788, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Epoch 6/10, Train Loss: 0.477, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 7/10, Train Loss: 0.4707, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4588, Accuracy: 0.7909, F1 Micro: 0.883, F1 Macro: 0.8814\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.4215, Accuracy: 0.7932, F1 Micro: 0.8839, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3936, Accuracy: 0.7976, F1 Micro: 0.8857, F1 Macro: 0.884\n",
      "\n",
      "Aspect detection accuracy: 0.7976, F1 Micro: 0.8857, F1 Macro: 0.884\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.78      1.00      0.88       175\n",
      "      others       0.76      0.96      0.84       158\n",
      "        part       0.71      1.00      0.83       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.80      0.99      0.89      1061\n",
      "   macro avg       0.80      0.99      0.88      1061\n",
      "weighted avg       0.80      0.99      0.89      1061\n",
      " samples avg       0.80      0.99      0.88      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7056, Accuracy: 0.44, F1 Micro: 0.44, F1 Macro: 0.4318\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5997, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5241, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5185, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.494, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4806, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4617, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.422, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3873, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2944, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "\n",
      "Sentiment analysis accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         4\n",
      "    positive       0.84      1.00      0.91        21\n",
      "\n",
      "    accuracy                           0.84        25\n",
      "   macro avg       0.42      0.50      0.46        25\n",
      "weighted avg       0.71      0.84      0.77        25\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.7948, F1 Micro: 0.7948, F1 Macro: 0.3169\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.78      1.00      0.87       167\n",
      "    positive       1.00      0.03      0.06        33\n",
      "\n",
      "    accuracy                           0.78       216\n",
      "   macro avg       0.59      0.34      0.31       216\n",
      "weighted avg       0.75      0.78      0.68       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.76      0.95      0.84       152\n",
      "    positive       0.54      0.25      0.34        52\n",
      "\n",
      "    accuracy                           0.73       216\n",
      "   macro avg       0.43      0.40      0.40       216\n",
      "weighted avg       0.66      0.73      0.68       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        23\n",
      "     neutral       0.70      1.00      0.83       152\n",
      "    positive       0.00      0.00      0.00        41\n",
      "\n",
      "    accuracy                           0.70       216\n",
      "   macro avg       0.23      0.33      0.28       216\n",
      "weighted avg       0.50      0.70      0.58       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 62.54118061065674 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 81\n",
      "Sampling duration: 12.098292827606201 seconds\n",
      "New train size: 135\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5981, Accuracy: 0.7894, F1 Micro: 0.8822, F1 Macro: 0.8807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5158, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5117, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4848, Accuracy: 0.7969, F1 Micro: 0.8859, F1 Macro: 0.8844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4509, Accuracy: 0.8051, F1 Micro: 0.8894, F1 Macro: 0.8876\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4139, Accuracy: 0.8147, F1 Micro: 0.8935, F1 Macro: 0.8915\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3709, Accuracy: 0.84, F1 Micro: 0.9053, F1 Macro: 0.903\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3202, Accuracy: 0.8564, F1 Micro: 0.9151, F1 Macro: 0.9132\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2921, Accuracy: 0.8832, F1 Micro: 0.9292, F1 Macro: 0.9268\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2409, Accuracy: 0.9033, F1 Micro: 0.9407, F1 Macro: 0.9385\n",
      "\n",
      "Aspect detection accuracy: 0.9033, F1 Micro: 0.9407, F1 Macro: 0.9385\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.97      0.99      0.98       187\n",
      "     machine       0.89      0.98      0.93       175\n",
      "      others       0.88      0.94      0.91       158\n",
      "        part       0.88      0.91      0.90       158\n",
      "       price       0.95      0.99      0.97       192\n",
      "     service       0.90      1.00      0.95       191\n",
      "\n",
      "   micro avg       0.91      0.97      0.94      1061\n",
      "   macro avg       0.91      0.97      0.94      1061\n",
      "weighted avg       0.91      0.97      0.94      1061\n",
      " samples avg       0.92      0.97      0.94      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6026, Accuracy: 0.7136, F1 Micro: 0.7136, F1 Macro: 0.4164\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5883, Accuracy: 0.7136, F1 Micro: 0.7136, F1 Macro: 0.4164\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5417, Accuracy: 0.7282, F1 Micro: 0.7282, F1 Macro: 0.4948\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3579, Accuracy: 0.835, F1 Micro: 0.835, F1 Macro: 0.802\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2238, Accuracy: 0.8495, F1 Micro: 0.8495, F1 Macro: 0.8292\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1322, Accuracy: 0.8641, F1 Micro: 0.8641, F1 Macro: 0.8463\n",
      "Epoch 7/10, Train Loss: 0.0917, Accuracy: 0.8592, F1 Micro: 0.8592, F1 Macro: 0.8447\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.093, Accuracy: 0.8689, F1 Micro: 0.8689, F1 Macro: 0.8476\n",
      "Epoch 9/10, Train Loss: 0.1217, Accuracy: 0.8155, F1 Micro: 0.8155, F1 Macro: 0.803\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0739, Accuracy: 0.8738, F1 Micro: 0.8738, F1 Macro: 0.8603\n",
      "\n",
      "Sentiment analysis accuracy: 0.8738, F1 Micro: 0.8738, F1 Macro: 0.8603\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.98      0.82        59\n",
      "    positive       0.99      0.83      0.90       147\n",
      "\n",
      "    accuracy                           0.87       206\n",
      "   macro avg       0.85      0.91      0.86       206\n",
      "weighted avg       0.91      0.87      0.88       206\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 135: Accuracy: 0.892, F1 Micro: 0.892, F1 Macro: 0.7603\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.97      0.99      0.98       181\n",
      "    positive       0.95      0.79      0.86        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.90      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.50      0.67        16\n",
      "     neutral       0.88      0.98      0.93       167\n",
      "    positive       0.83      0.58      0.68        33\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.90      0.68      0.76       216\n",
      "weighted avg       0.88      0.88      0.87       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.38      0.67      0.48        12\n",
      "     neutral       0.88      0.93      0.90       152\n",
      "    positive       0.85      0.54      0.66        52\n",
      "\n",
      "    accuracy                           0.82       216\n",
      "   macro avg       0.70      0.71      0.68       216\n",
      "weighted avg       0.84      0.82      0.82       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.74      0.68        23\n",
      "     neutral       0.88      0.91      0.89       152\n",
      "    positive       0.81      0.63      0.71        41\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.77      0.76      0.76       216\n",
      "weighted avg       0.84      0.84      0.84       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.69      0.78        13\n",
      "     neutral       0.95      0.99      0.97       186\n",
      "    positive       0.82      0.53      0.64        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.74      0.80       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.43      0.60        14\n",
      "     neutral       0.90      1.00      0.95       185\n",
      "    positive       1.00      0.24      0.38        17\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.97      0.55      0.64       216\n",
      "weighted avg       0.91      0.90      0.88       216\n",
      "\n",
      "Total train time: 80.14895868301392 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 73\n",
      "Sampling duration: 15.032035827636719 seconds\n",
      "New train size: 208\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5867, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Epoch 2/10, Train Loss: 0.5156, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 3/10, Train Loss: 0.4686, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4517, Accuracy: 0.8155, F1 Micro: 0.8947, F1 Macro: 0.8934\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4099, Accuracy: 0.8311, F1 Micro: 0.9028, F1 Macro: 0.9016\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3525, Accuracy: 0.8802, F1 Micro: 0.928, F1 Macro: 0.9263\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3002, Accuracy: 0.9048, F1 Micro: 0.942, F1 Macro: 0.9405\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.245, Accuracy: 0.9167, F1 Micro: 0.9488, F1 Macro: 0.9469\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2086, Accuracy: 0.9338, F1 Micro: 0.9592, F1 Macro: 0.9571\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1671, Accuracy: 0.9405, F1 Micro: 0.9631, F1 Macro: 0.9614\n",
      "\n",
      "Aspect detection accuracy: 0.9405, F1 Micro: 0.9631, F1 Macro: 0.9614\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.97      1.00      0.98       187\n",
      "     machine       0.94      0.99      0.97       175\n",
      "      others       0.87      0.92      0.90       158\n",
      "        part       0.94      0.99      0.97       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.95      1.00      0.97       191\n",
      "\n",
      "   micro avg       0.94      0.98      0.96      1061\n",
      "   macro avg       0.94      0.98      0.96      1061\n",
      "weighted avg       0.94      0.98      0.96      1061\n",
      " samples avg       0.94      0.99      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6486, Accuracy: 0.6814, F1 Micro: 0.6814, F1 Macro: 0.4053\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5304, Accuracy: 0.6991, F1 Micro: 0.6991, F1 Macro: 0.4732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4413, Accuracy: 0.8894, F1 Micro: 0.8894, F1 Macro: 0.8712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2573, Accuracy: 0.9027, F1 Micro: 0.9027, F1 Macro: 0.8879\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1655, Accuracy: 0.9071, F1 Micro: 0.9071, F1 Macro: 0.8975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1735, Accuracy: 0.9159, F1 Micro: 0.9159, F1 Macro: 0.9049\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1431, Accuracy: 0.9159, F1 Micro: 0.9159, F1 Macro: 0.9073\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1047, Accuracy: 0.9159, F1 Micro: 0.9159, F1 Macro: 0.9073\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0692, Accuracy: 0.9159, F1 Micro: 0.9159, F1 Macro: 0.9067\n",
      "Epoch 10/10, Train Loss: 0.0632, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.9027\n",
      "\n",
      "Sentiment analysis accuracy: 0.9159, F1 Micro: 0.9159, F1 Macro: 0.9067\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.94      0.88        72\n",
      "    positive       0.97      0.90      0.94       154\n",
      "\n",
      "    accuracy                           0.92       226\n",
      "   macro avg       0.90      0.92      0.91       226\n",
      "weighted avg       0.92      0.92      0.92       226\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 208: Accuracy: 0.929, F1 Micro: 0.929, F1 Macro: 0.8504\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.97      1.00      0.99       181\n",
      "    positive       1.00      0.79      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.96      0.90      0.93       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.94      0.99      0.97       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.82      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.44      0.67      0.53        12\n",
      "     neutral       0.88      0.92      0.90       152\n",
      "    positive       0.79      0.58      0.67        52\n",
      "\n",
      "    accuracy                           0.82       216\n",
      "   macro avg       0.70      0.72      0.70       216\n",
      "weighted avg       0.83      0.82      0.82       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.83      0.86        23\n",
      "     neutral       0.94      0.99      0.96       152\n",
      "    positive       0.91      0.76      0.83        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.92      0.86      0.89       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.84      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.64      0.78        14\n",
      "     neutral       0.94      1.00      0.97       185\n",
      "    positive       1.00      0.65      0.79        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.98      0.76      0.85       216\n",
      "weighted avg       0.95      0.95      0.94       216\n",
      "\n",
      "Total train time: 86.82528495788574 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 66\n",
      "Sampling duration: 14.19705843925476 seconds\n",
      "New train size: 274\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5769, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Epoch 2/10, Train Loss: 0.5068, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4727, Accuracy: 0.7961, F1 Micro: 0.885, F1 Macro: 0.8831\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4229, Accuracy: 0.8266, F1 Micro: 0.9003, F1 Macro: 0.8988\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3563, Accuracy: 0.8795, F1 Micro: 0.9273, F1 Macro: 0.9251\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2852, Accuracy: 0.904, F1 Micro: 0.941, F1 Macro: 0.9383\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2257, Accuracy: 0.9226, F1 Micro: 0.9517, F1 Macro: 0.9477\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.181, Accuracy: 0.9457, F1 Micro: 0.9664, F1 Macro: 0.9649\n",
      "Epoch 9/10, Train Loss: 0.1492, Accuracy: 0.9449, F1 Micro: 0.9658, F1 Macro: 0.9643\n",
      "Epoch 10/10, Train Loss: 0.1248, Accuracy: 0.9427, F1 Micro: 0.964, F1 Macro: 0.961\n",
      "\n",
      "Aspect detection accuracy: 0.9457, F1 Micro: 0.9664, F1 Macro: 0.9649\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.94      0.99      0.96       175\n",
      "      others       0.88      0.94      0.91       158\n",
      "        part       0.94      1.00      0.97       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       0.95      1.00      0.97       191\n",
      "\n",
      "   micro avg       0.95      0.99      0.97      1061\n",
      "   macro avg       0.94      0.99      0.96      1061\n",
      "weighted avg       0.95      0.99      0.97      1061\n",
      " samples avg       0.95      0.99      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.603, Accuracy: 0.6756, F1 Micro: 0.6756, F1 Macro: 0.4032\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4655, Accuracy: 0.8844, F1 Micro: 0.8844, F1 Macro: 0.8672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2822, Accuracy: 0.9111, F1 Micro: 0.9111, F1 Macro: 0.9013\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1873, Accuracy: 0.92, F1 Micro: 0.92, F1 Macro: 0.9088\n",
      "Epoch 5/10, Train Loss: 0.1717, Accuracy: 0.8889, F1 Micro: 0.8889, F1 Macro: 0.8804\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1146, Accuracy: 0.9378, F1 Micro: 0.9378, F1 Macro: 0.9309\n",
      "Epoch 7/10, Train Loss: 0.144, Accuracy: 0.88, F1 Micro: 0.88, F1 Macro: 0.8721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1419, Accuracy: 0.9556, F1 Micro: 0.9556, F1 Macro: 0.9497\n",
      "Epoch 9/10, Train Loss: 0.0838, Accuracy: 0.8533, F1 Micro: 0.8533, F1 Macro: 0.8463\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1427, Accuracy: 0.9556, F1 Micro: 0.9556, F1 Macro: 0.9497\n",
      "\n",
      "Sentiment analysis accuracy: 0.9556, F1 Micro: 0.9556, F1 Macro: 0.9497\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.95      0.93        73\n",
      "    positive       0.97      0.96      0.97       152\n",
      "\n",
      "    accuracy                           0.96       225\n",
      "   macro avg       0.95      0.95      0.95       225\n",
      "weighted avg       0.96      0.96      0.96       225\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 274: Accuracy: 0.9406, F1 Micro: 0.9406, F1 Macro: 0.879\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.94      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.83      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.67      0.67        12\n",
      "     neutral       0.88      0.94      0.91       152\n",
      "    positive       0.83      0.65      0.73        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.79      0.75      0.77       216\n",
      "weighted avg       0.85      0.86      0.85       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.83      0.90        23\n",
      "     neutral       0.94      1.00      0.97       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.96      0.88      0.91       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.97      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.84      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.71      0.83        14\n",
      "     neutral       0.95      1.00      0.97       185\n",
      "    positive       1.00      0.65      0.79        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.98      0.79      0.86       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Total train time: 89.83606266975403 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 59\n",
      "Sampling duration: 12.989567279815674 seconds\n",
      "New train size: 333\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5594, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Epoch 2/10, Train Loss: 0.5047, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4525, Accuracy: 0.8155, F1 Micro: 0.894, F1 Macro: 0.8918\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3738, Accuracy: 0.8772, F1 Micro: 0.9262, F1 Macro: 0.9247\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2892, Accuracy: 0.9129, F1 Micro: 0.9464, F1 Macro: 0.9435\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2309, Accuracy: 0.9368, F1 Micro: 0.9611, F1 Macro: 0.9596\n",
      "Epoch 7/10, Train Loss: 0.1866, Accuracy: 0.936, F1 Micro: 0.9602, F1 Macro: 0.9571\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1399, Accuracy: 0.9464, F1 Micro: 0.9664, F1 Macro: 0.964\n",
      "Epoch 9/10, Train Loss: 0.1214, Accuracy: 0.942, F1 Micro: 0.9634, F1 Macro: 0.96\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1008, Accuracy: 0.9472, F1 Micro: 0.9669, F1 Macro: 0.9643\n",
      "\n",
      "Aspect detection accuracy: 0.9472, F1 Micro: 0.9669, F1 Macro: 0.9643\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.94      0.99      0.96       175\n",
      "      others       0.93      0.87      0.90       158\n",
      "        part       0.92      1.00      0.96       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.97      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.95      0.98      0.96      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5796, Accuracy: 0.6892, F1 Micro: 0.6892, F1 Macro: 0.408\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4027, Accuracy: 0.9124, F1 Micro: 0.9124, F1 Macro: 0.8929\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2251, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9284\n",
      "Epoch 4/10, Train Loss: 0.1568, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.919\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.122, Accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9358\n",
      "Epoch 6/10, Train Loss: 0.151, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.92\n",
      "Epoch 7/10, Train Loss: 0.117, Accuracy: 0.9402, F1 Micro: 0.9402, F1 Macro: 0.9319\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1197, Accuracy: 0.9602, F1 Micro: 0.9602, F1 Macro: 0.9541\n",
      "Epoch 9/10, Train Loss: 0.0831, Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.946\n",
      "Epoch 10/10, Train Loss: 0.0994, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9246\n",
      "\n",
      "Sentiment analysis accuracy: 0.9602, F1 Micro: 0.9602, F1 Macro: 0.9541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        78\n",
      "    positive       0.98      0.96      0.97       173\n",
      "\n",
      "    accuracy                           0.96       251\n",
      "   macro avg       0.95      0.96      0.95       251\n",
      "weighted avg       0.96      0.96      0.96       251\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 333: Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.8936\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       1.00      0.96      0.98        24\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.99      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.75      0.86        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.94      0.83      0.88       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.94      0.87      0.90       152\n",
      "    positive       0.70      0.83      0.76        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.79      0.84      0.81       216\n",
      "weighted avg       0.87      0.86      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.87      0.89        23\n",
      "     neutral       0.92      1.00      0.96       152\n",
      "    positive       1.00      0.68      0.81        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.94      0.85      0.89       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.90      0.84      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.97      1.00      0.98       185\n",
      "    positive       1.00      0.76      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.99      0.87      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 92.33700847625732 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 54\n",
      "Sampling duration: 12.421247959136963 seconds\n",
      "New train size: 387\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.549, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 2/10, Train Loss: 0.4821, Accuracy: 0.7879, F1 Micro: 0.8805, F1 Macro: 0.8783\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4178, Accuracy: 0.8445, F1 Micro: 0.9083, F1 Macro: 0.9064\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3371, Accuracy: 0.9077, F1 Micro: 0.9428, F1 Macro: 0.9401\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2423, Accuracy: 0.9368, F1 Micro: 0.9606, F1 Macro: 0.9584\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1774, Accuracy: 0.9487, F1 Micro: 0.9681, F1 Macro: 0.9666\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1438, Accuracy: 0.9509, F1 Micro: 0.9692, F1 Macro: 0.9669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1147, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9722\n",
      "Epoch 9/10, Train Loss: 0.0897, Accuracy: 0.9554, F1 Micro: 0.9721, F1 Macro: 0.9703\n",
      "Epoch 10/10, Train Loss: 0.0782, Accuracy: 0.9546, F1 Micro: 0.9715, F1 Macro: 0.9692\n",
      "\n",
      "Aspect detection accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9722\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.94      0.99      0.97       175\n",
      "      others       0.91      0.92      0.91       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5702, Accuracy: 0.7165, F1 Micro: 0.7165, F1 Macro: 0.5139\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3425, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9131\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1889, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9265\n",
      "Epoch 4/10, Train Loss: 0.1472, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9181\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.124, Accuracy: 0.9488, F1 Micro: 0.9488, F1 Macro: 0.942\n",
      "Epoch 6/10, Train Loss: 0.1625, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9366\n",
      "Epoch 7/10, Train Loss: 0.0833, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9297\n",
      "Epoch 8/10, Train Loss: 0.1039, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9327\n",
      "Epoch 9/10, Train Loss: 0.0831, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9237\n",
      "Epoch 10/10, Train Loss: 0.0647, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9331\n",
      "\n",
      "Sentiment analysis accuracy: 0.9488, F1 Micro: 0.9488, F1 Macro: 0.942\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.92        81\n",
      "    positive       0.98      0.95      0.96       173\n",
      "\n",
      "    accuracy                           0.95       254\n",
      "   macro avg       0.94      0.95      0.94       254\n",
      "weighted avg       0.95      0.95      0.95       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 387: Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.8998\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.97      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.94      0.99      0.97       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.82      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.67      0.73        12\n",
      "     neutral       0.92      0.92      0.92       152\n",
      "    positive       0.79      0.81      0.80        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.84      0.80      0.82       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.89      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 97.90524673461914 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 48\n",
      "Sampling duration: 11.122283697128296 seconds\n",
      "New train size: 435\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.557, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4751, Accuracy: 0.7954, F1 Micro: 0.8842, F1 Macro: 0.8821\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4162, Accuracy: 0.8594, F1 Micro: 0.9158, F1 Macro: 0.9122\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3158, Accuracy: 0.9219, F1 Micro: 0.952, F1 Macro: 0.9499\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2252, Accuracy: 0.9435, F1 Micro: 0.9647, F1 Macro: 0.9622\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1728, Accuracy: 0.9516, F1 Micro: 0.9697, F1 Macro: 0.9678\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1382, Accuracy: 0.9583, F1 Micro: 0.974, F1 Macro: 0.9729\n",
      "Epoch 8/10, Train Loss: 0.109, Accuracy: 0.9539, F1 Micro: 0.9709, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0876, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0756, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.974\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.974\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.94      0.91      0.92       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5524, Accuracy: 0.8409, F1 Micro: 0.8409, F1 Macro: 0.794\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2735, Accuracy: 0.9053, F1 Micro: 0.9053, F1 Macro: 0.885\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1627, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9245\n",
      "Epoch 4/10, Train Loss: 0.1336, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9168\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1011, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9285\n",
      "Epoch 6/10, Train Loss: 0.1015, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9241\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0743, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9285\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0586, Accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.9393\n",
      "Epoch 9/10, Train Loss: 0.0613, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9145\n",
      "Epoch 10/10, Train Loss: 0.043, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9204\n",
      "\n",
      "Sentiment analysis accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.9393\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.93      0.92        84\n",
      "    positive       0.97      0.96      0.96       180\n",
      "\n",
      "    accuracy                           0.95       264\n",
      "   macro avg       0.94      0.94      0.94       264\n",
      "weighted avg       0.95      0.95      0.95       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 435: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9079\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.97      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.75      0.86        16\n",
      "     neutral       0.94      0.99      0.97       167\n",
      "    positive       0.93      0.79      0.85        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.96      0.84      0.89       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.95      0.91      0.93       152\n",
      "    positive       0.74      0.83      0.78        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.84      0.86      0.85       216\n",
      "weighted avg       0.89      0.88      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.88      0.86      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 112.47384262084961 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 43\n",
      "Sampling duration: 10.41700553894043 seconds\n",
      "New train size: 478\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5511, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4691, Accuracy: 0.7946, F1 Micro: 0.883, F1 Macro: 0.8801\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4045, Accuracy: 0.8534, F1 Micro: 0.9122, F1 Macro: 0.9101\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.302, Accuracy: 0.9211, F1 Micro: 0.951, F1 Macro: 0.9486\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2203, Accuracy: 0.9487, F1 Micro: 0.9681, F1 Macro: 0.9669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1631, Accuracy: 0.9524, F1 Micro: 0.9703, F1 Macro: 0.969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1307, Accuracy: 0.9561, F1 Micro: 0.9726, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0968, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9762\n",
      "Epoch 9/10, Train Loss: 0.084, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.974\n",
      "Epoch 10/10, Train Loss: 0.0739, Accuracy: 0.9568, F1 Micro: 0.9728, F1 Macro: 0.971\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.91      0.96      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5556, Accuracy: 0.7733, F1 Micro: 0.7733, F1 Macro: 0.6637\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3026, Accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9389\n",
      "Epoch 3/10, Train Loss: 0.1824, Accuracy: 0.9393, F1 Micro: 0.9393, F1 Macro: 0.9279\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1416, Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.9449\n",
      "Epoch 5/10, Train Loss: 0.135, Accuracy: 0.9352, F1 Micro: 0.9352, F1 Macro: 0.929\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0754, Accuracy: 0.9595, F1 Micro: 0.9595, F1 Macro: 0.9544\n",
      "Epoch 7/10, Train Loss: 0.1151, Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.9456\n",
      "Epoch 8/10, Train Loss: 0.0642, Accuracy: 0.9352, F1 Micro: 0.9352, F1 Macro: 0.929\n",
      "Epoch 9/10, Train Loss: 0.0805, Accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9419\n",
      "Epoch 10/10, Train Loss: 0.0571, Accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9408\n",
      "\n",
      "Sentiment analysis accuracy: 0.9595, F1 Micro: 0.9595, F1 Macro: 0.9544\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.96      0.94        80\n",
      "    positive       0.98      0.96      0.97       167\n",
      "\n",
      "    accuracy                           0.96       247\n",
      "   macro avg       0.95      0.96      0.95       247\n",
      "weighted avg       0.96      0.96      0.96       247\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 478: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.9164\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.83      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.91      0.97      0.94       152\n",
      "    positive       0.89      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.90      0.83      0.86       216\n",
      "weighted avg       0.91      0.91      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.92      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.84      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 107.92333197593689 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 39\n",
      "Sampling duration: 9.446954250335693 seconds\n",
      "New train size: 517\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5455, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4718, Accuracy: 0.8132, F1 Micro: 0.8924, F1 Macro: 0.8899\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3664, Accuracy: 0.904, F1 Micro: 0.9418, F1 Macro: 0.9396\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2561, Accuracy: 0.9442, F1 Micro: 0.9653, F1 Macro: 0.9636\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1846, Accuracy: 0.9501, F1 Micro: 0.9687, F1 Macro: 0.9665\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1405, Accuracy: 0.9546, F1 Micro: 0.9714, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1036, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9725\n",
      "Epoch 8/10, Train Loss: 0.0895, Accuracy: 0.9591, F1 Micro: 0.9741, F1 Macro: 0.9723\n",
      "Epoch 9/10, Train Loss: 0.0732, Accuracy: 0.9554, F1 Micro: 0.9719, F1 Macro: 0.9699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0603, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9728\n",
      "\n",
      "Aspect detection accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9728\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.89      0.91       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.97      0.97      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5576, Accuracy: 0.8246, F1 Micro: 0.8246, F1 Macro: 0.7601\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3133, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9315\n",
      "Epoch 3/10, Train Loss: 0.2248, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.9279\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.165, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9315\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1197, Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9483\n",
      "Epoch 6/10, Train Loss: 0.1024, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9331\n",
      "Epoch 7/10, Train Loss: 0.0955, Accuracy: 0.9478, F1 Micro: 0.9478, F1 Macro: 0.9389\n",
      "Epoch 8/10, Train Loss: 0.076, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9371\n",
      "Epoch 9/10, Train Loss: 0.0763, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9352\n",
      "Epoch 10/10, Train Loss: 0.0584, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.9256\n",
      "\n",
      "Sentiment analysis accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9483\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        85\n",
      "    positive       0.97      0.97      0.97       183\n",
      "\n",
      "    accuracy                           0.96       268\n",
      "   macro avg       0.95      0.95      0.95       268\n",
      "weighted avg       0.96      0.96      0.96       268\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 517: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9159\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.92      0.85        12\n",
      "     neutral       0.94      0.89      0.92       152\n",
      "    positive       0.74      0.81      0.77        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.82      0.87      0.84       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.93      0.90      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.93      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.88      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 114.70348119735718 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 23\n",
      "Sampling duration: 8.746089458465576 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5404, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4761, Accuracy: 0.8021, F1 Micro: 0.8879, F1 Macro: 0.8862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3773, Accuracy: 0.8988, F1 Micro: 0.9378, F1 Macro: 0.9354\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2717, Accuracy: 0.9412, F1 Micro: 0.9633, F1 Macro: 0.9615\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1961, Accuracy: 0.9472, F1 Micro: 0.9667, F1 Macro: 0.9641\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1501, Accuracy: 0.9554, F1 Micro: 0.9718, F1 Macro: 0.9696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1094, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0936, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.076, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0646, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.94      0.94      0.94       158\n",
      "        part       0.96      0.99      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.548, Accuracy: 0.8677, F1 Micro: 0.8677, F1 Macro: 0.8387\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2719, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9316\n",
      "Epoch 3/10, Train Loss: 0.1859, Accuracy: 0.8988, F1 Micro: 0.8988, F1 Macro: 0.8924\n",
      "Epoch 4/10, Train Loss: 0.1387, Accuracy: 0.8988, F1 Micro: 0.8988, F1 Macro: 0.8924\n",
      "Epoch 5/10, Train Loss: 0.1321, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9198\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1305, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9301\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0737, Accuracy: 0.9494, F1 Micro: 0.9494, F1 Macro: 0.944\n",
      "Epoch 8/10, Train Loss: 0.0871, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9316\n",
      "Epoch 9/10, Train Loss: 0.0618, Accuracy: 0.9222, F1 Micro: 0.9222, F1 Macro: 0.9131\n",
      "Epoch 10/10, Train Loss: 0.0608, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9319\n",
      "\n",
      "Sentiment analysis accuracy: 0.9494, F1 Micro: 0.9494, F1 Macro: 0.944\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.96      0.93        85\n",
      "    positive       0.98      0.94      0.96       172\n",
      "\n",
      "    accuracy                           0.95       257\n",
      "   macro avg       0.94      0.95      0.94       257\n",
      "weighted avg       0.95      0.95      0.95       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.921\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.92      0.85        12\n",
      "     neutral       0.95      0.94      0.94       152\n",
      "    positive       0.80      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.85      0.88      0.86       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.96      0.99      0.97       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.92      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.93      0.89      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 119.1326425075531 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 33\n",
      "Sampling duration: 8.230613708496094 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5464, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4653, Accuracy: 0.8214, F1 Micro: 0.8966, F1 Macro: 0.8947\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3613, Accuracy: 0.9167, F1 Micro: 0.949, F1 Macro: 0.9471\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2425, Accuracy: 0.9375, F1 Micro: 0.9611, F1 Macro: 0.959\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1766, Accuracy: 0.9457, F1 Micro: 0.9657, F1 Macro: 0.962\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1398, Accuracy: 0.9501, F1 Micro: 0.9685, F1 Macro: 0.9661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1038, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0877, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9728\n",
      "Epoch 9/10, Train Loss: 0.0664, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9722\n",
      "Epoch 10/10, Train Loss: 0.0588, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9715\n",
      "\n",
      "Aspect detection accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9728\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.92      0.92      0.92       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5163, Accuracy: 0.8842, F1 Micro: 0.8842, F1 Macro: 0.8702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2333, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9394\n",
      "Epoch 3/10, Train Loss: 0.1714, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9349\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1709, Accuracy: 0.9575, F1 Micro: 0.9575, F1 Macro: 0.9508\n",
      "Epoch 5/10, Train Loss: 0.1423, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9193\n",
      "Epoch 6/10, Train Loss: 0.0868, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9234\n",
      "Epoch 7/10, Train Loss: 0.1235, Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9439\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0758, Accuracy: 0.9614, F1 Micro: 0.9614, F1 Macro: 0.9557\n",
      "Epoch 9/10, Train Loss: 0.0726, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9274\n",
      "Epoch 10/10, Train Loss: 0.0419, Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9465\n",
      "\n",
      "Sentiment analysis accuracy: 0.9614, F1 Micro: 0.9614, F1 Macro: 0.9557\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.95      0.94        82\n",
      "    positive       0.98      0.97      0.97       177\n",
      "\n",
      "    accuracy                           0.96       259\n",
      "   macro avg       0.95      0.96      0.96       259\n",
      "weighted avg       0.96      0.96      0.96       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9092\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.85      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.93      0.92      0.92       152\n",
      "    positive       0.78      0.83      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.87      0.83      0.85       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.95      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.69      0.78        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.76      0.76      0.76        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.88      0.82      0.84       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 119.81038355827332 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 30\n",
      "Sampling duration: 7.481637954711914 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5417, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4592, Accuracy: 0.8356, F1 Micro: 0.9042, F1 Macro: 0.9022\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3326, Accuracy: 0.9226, F1 Micro: 0.9518, F1 Macro: 0.949\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2224, Accuracy: 0.9449, F1 Micro: 0.9656, F1 Macro: 0.9633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.175, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1298, Accuracy: 0.965, F1 Micro: 0.9782, F1 Macro: 0.9772\n",
      "Epoch 7/10, Train Loss: 0.106, Accuracy: 0.9583, F1 Micro: 0.9737, F1 Macro: 0.9713\n",
      "Epoch 8/10, Train Loss: 0.0807, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9769\n",
      "Epoch 9/10, Train Loss: 0.067, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9738\n",
      "Epoch 10/10, Train Loss: 0.0581, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9763\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.9782, F1 Macro: 0.9772\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.91      0.97      0.94       158\n",
      "        part       0.96      1.00      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.98      1061\n",
      "weighted avg       0.96      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5403, Accuracy: 0.8484, F1 Micro: 0.8484, F1 Macro: 0.8139\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3137, Accuracy: 0.918, F1 Micro: 0.918, F1 Macro: 0.9128\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.173, Accuracy: 0.9508, F1 Micro: 0.9508, F1 Macro: 0.9455\n",
      "Epoch 4/10, Train Loss: 0.0969, Accuracy: 0.9426, F1 Micro: 0.9426, F1 Macro: 0.9378\n",
      "Epoch 5/10, Train Loss: 0.1154, Accuracy: 0.9426, F1 Micro: 0.9426, F1 Macro: 0.9345\n",
      "Epoch 6/10, Train Loss: 0.1319, Accuracy: 0.9426, F1 Micro: 0.9426, F1 Macro: 0.9381\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1097, Accuracy: 0.9508, F1 Micro: 0.9508, F1 Macro: 0.9467\n",
      "Epoch 8/10, Train Loss: 0.0824, Accuracy: 0.9467, F1 Micro: 0.9467, F1 Macro: 0.9424\n",
      "Epoch 9/10, Train Loss: 0.0701, Accuracy: 0.9467, F1 Micro: 0.9467, F1 Macro: 0.9424\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0468, Accuracy: 0.9508, F1 Micro: 0.9508, F1 Macro: 0.9461\n",
      "\n",
      "Sentiment analysis accuracy: 0.9508, F1 Micro: 0.9508, F1 Macro: 0.9461\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.96      0.93        83\n",
      "    positive       0.98      0.94      0.96       161\n",
      "\n",
      "    accuracy                           0.95       244\n",
      "   macro avg       0.94      0.95      0.95       244\n",
      "weighted avg       0.95      0.95      0.95       244\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9119\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.94      0.91        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.89      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.91      0.97      0.94       152\n",
      "    positive       0.90      0.73      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.86      0.82      0.83       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        23\n",
      "     neutral       0.96      1.00      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.95      0.91      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.87      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 124.38576865196228 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 27\n",
      "Sampling duration: 6.684457540512085 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5332, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4605, Accuracy: 0.8356, F1 Micro: 0.903, F1 Macro: 0.9008\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3392, Accuracy: 0.9263, F1 Micro: 0.9541, F1 Macro: 0.9515\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2225, Accuracy: 0.9509, F1 Micro: 0.9695, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1543, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1186, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9754\n",
      "Epoch 7/10, Train Loss: 0.0928, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0772, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9753\n",
      "Epoch 9/10, Train Loss: 0.0609, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9725\n",
      "Epoch 10/10, Train Loss: 0.0551, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9751\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9753\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.94      0.91      0.92       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5357, Accuracy: 0.794, F1 Micro: 0.794, F1 Macro: 0.7061\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2693, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9254\n",
      "Epoch 3/10, Train Loss: 0.1884, Accuracy: 0.9288, F1 Micro: 0.9288, F1 Macro: 0.9218\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1462, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9376\n",
      "Epoch 5/10, Train Loss: 0.1262, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9261\n",
      "Epoch 6/10, Train Loss: 0.0951, Accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.9109\n",
      "Epoch 7/10, Train Loss: 0.0817, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.925\n",
      "Epoch 8/10, Train Loss: 0.0603, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9265\n",
      "Epoch 9/10, Train Loss: 0.0815, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.925\n",
      "Epoch 10/10, Train Loss: 0.04, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9148\n",
      "\n",
      "Sentiment analysis accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9376\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.97      0.92        87\n",
      "    positive       0.98      0.93      0.96       180\n",
      "\n",
      "    accuracy                           0.94       267\n",
      "   macro avg       0.93      0.95      0.94       267\n",
      "weighted avg       0.95      0.94      0.94       267\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9188\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.92      0.81        12\n",
      "     neutral       0.95      0.91      0.93       152\n",
      "    positive       0.76      0.81      0.79        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.81      0.88      0.84       216\n",
      "weighted avg       0.89      0.88      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.88      0.87      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 124.32292485237122 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 18\n",
      "Sampling duration: 6.288407325744629 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5299, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4577, Accuracy: 0.8348, F1 Micro: 0.9037, F1 Macro: 0.902\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3156, Accuracy: 0.9345, F1 Micro: 0.9596, F1 Macro: 0.9581\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2078, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1539, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9738\n",
      "Epoch 6/10, Train Loss: 0.1138, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0908, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9762\n",
      "Epoch 8/10, Train Loss: 0.0744, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.974\n",
      "Epoch 9/10, Train Loss: 0.0614, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.974\n",
      "Epoch 10/10, Train Loss: 0.05, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.976\n",
      "\n",
      "Aspect detection accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.92      0.94      0.93       158\n",
      "        part       0.99      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4954, Accuracy: 0.8943, F1 Micro: 0.8943, F1 Macro: 0.8772\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.264, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9319\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1486, Accuracy: 0.9509, F1 Micro: 0.9509, F1 Macro: 0.9439\n",
      "Epoch 4/10, Train Loss: 0.1506, Accuracy: 0.883, F1 Micro: 0.883, F1 Macro: 0.8742\n",
      "Epoch 5/10, Train Loss: 0.1807, Accuracy: 0.9132, F1 Micro: 0.9132, F1 Macro: 0.9045\n",
      "Epoch 6/10, Train Loss: 0.1155, Accuracy: 0.9094, F1 Micro: 0.9094, F1 Macro: 0.9011\n",
      "Epoch 7/10, Train Loss: 0.1087, Accuracy: 0.9358, F1 Micro: 0.9358, F1 Macro: 0.9279\n",
      "Epoch 8/10, Train Loss: 0.103, Accuracy: 0.9245, F1 Micro: 0.9245, F1 Macro: 0.9159\n",
      "Epoch 9/10, Train Loss: 0.0763, Accuracy: 0.9245, F1 Micro: 0.9245, F1 Macro: 0.9163\n",
      "Epoch 10/10, Train Loss: 0.0634, Accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.936\n",
      "\n",
      "Sentiment analysis accuracy: 0.9509, F1 Micro: 0.9509, F1 Macro: 0.9439\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.92        83\n",
      "    positive       0.98      0.95      0.96       182\n",
      "\n",
      "    accuracy                           0.95       265\n",
      "   macro avg       0.94      0.95      0.94       265\n",
      "weighted avg       0.95      0.95      0.95       265\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9159\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.85      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.92      0.93      0.93       152\n",
      "    positive       0.80      0.77      0.78        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.82      0.82      0.82       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.99      0.98      0.98       152\n",
      "    positive       0.93      0.90      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.95      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.88      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 123.40350008010864 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.810280799865723 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5275, Accuracy: 0.7902, F1 Micro: 0.8826, F1 Macro: 0.8811\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4406, Accuracy: 0.8504, F1 Micro: 0.912, F1 Macro: 0.9102\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.297, Accuracy: 0.9338, F1 Micro: 0.9592, F1 Macro: 0.9576\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2058, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.974\n",
      "Epoch 5/10, Train Loss: 0.1478, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9717\n",
      "Epoch 6/10, Train Loss: 0.1078, Accuracy: 0.9591, F1 Micro: 0.9741, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0882, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0672, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9757\n",
      "Epoch 9/10, Train Loss: 0.0563, Accuracy: 0.9606, F1 Micro: 0.9749, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0479, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9761\n",
      "\n",
      "Aspect detection accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9761\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.93      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.98      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.528, Accuracy: 0.8881, F1 Micro: 0.8881, F1 Macro: 0.8682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2726, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9331\n",
      "Epoch 3/10, Train Loss: 0.1682, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.9291\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1149, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9323\n",
      "Epoch 5/10, Train Loss: 0.1504, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9229\n",
      "Epoch 6/10, Train Loss: 0.1133, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.9287\n",
      "Epoch 7/10, Train Loss: 0.0965, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.927\n",
      "Epoch 8/10, Train Loss: 0.0785, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9189\n",
      "Epoch 9/10, Train Loss: 0.0683, Accuracy: 0.9179, F1 Micro: 0.9179, F1 Macro: 0.9103\n",
      "Epoch 10/10, Train Loss: 0.059, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9212\n",
      "\n",
      "Sentiment analysis accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9323\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.93      0.91        86\n",
      "    positive       0.97      0.95      0.96       182\n",
      "\n",
      "    accuracy                           0.94       268\n",
      "   macro avg       0.93      0.94      0.93       268\n",
      "weighted avg       0.94      0.94      0.94       268\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9154\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.82      0.81      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.84      0.86      0.85       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.92      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.99      0.98      0.99       186\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.90      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.89      1.00      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 129.73061108589172 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.370625734329224 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5306, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4404, Accuracy: 0.8705, F1 Micro: 0.923, F1 Macro: 0.9214\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3121, Accuracy: 0.9375, F1 Micro: 0.9615, F1 Macro: 0.9599\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2175, Accuracy: 0.9546, F1 Micro: 0.9716, F1 Macro: 0.9701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1488, Accuracy: 0.9643, F1 Micro: 0.9777, F1 Macro: 0.9768\n",
      "Epoch 6/10, Train Loss: 0.1172, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9762\n",
      "Epoch 7/10, Train Loss: 0.0896, Accuracy: 0.9568, F1 Micro: 0.9727, F1 Macro: 0.9705\n",
      "Epoch 8/10, Train Loss: 0.074, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9756\n",
      "Epoch 9/10, Train Loss: 0.0581, Accuracy: 0.9583, F1 Micro: 0.9737, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0521, Accuracy: 0.965, F1 Micro: 0.9778, F1 Macro: 0.9761\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.9778, F1 Macro: 0.9761\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.95      0.90      0.93       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.97      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5049, Accuracy: 0.8949, F1 Micro: 0.8949, F1 Macro: 0.8833\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.266, Accuracy: 0.9312, F1 Micro: 0.9312, F1 Macro: 0.9223\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1509, Accuracy: 0.9457, F1 Micro: 0.9457, F1 Macro: 0.9383\n",
      "Epoch 4/10, Train Loss: 0.1591, Accuracy: 0.9275, F1 Micro: 0.9275, F1 Macro: 0.9197\n",
      "Epoch 5/10, Train Loss: 0.1232, Accuracy: 0.942, F1 Micro: 0.942, F1 Macro: 0.9329\n",
      "Epoch 6/10, Train Loss: 0.1024, Accuracy: 0.9203, F1 Micro: 0.9203, F1 Macro: 0.9126\n",
      "Epoch 7/10, Train Loss: 0.1013, Accuracy: 0.9312, F1 Micro: 0.9312, F1 Macro: 0.9205\n",
      "Epoch 8/10, Train Loss: 0.0942, Accuracy: 0.9312, F1 Micro: 0.9312, F1 Macro: 0.9223\n",
      "Epoch 9/10, Train Loss: 0.0724, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.9088\n",
      "Epoch 10/10, Train Loss: 0.0492, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.9088\n",
      "\n",
      "Sentiment analysis accuracy: 0.9457, F1 Micro: 0.9457, F1 Macro: 0.9383\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.95      0.92        87\n",
      "    positive       0.98      0.94      0.96       189\n",
      "\n",
      "    accuracy                           0.95       276\n",
      "   macro avg       0.93      0.95      0.94       276\n",
      "weighted avg       0.95      0.95      0.95       276\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9221\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       1.00      0.96      0.98        24\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.99      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.85      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      1.00      0.86        12\n",
      "     neutral       0.96      0.89      0.93       152\n",
      "    positive       0.76      0.85      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.82      0.91      0.86       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.84      0.94      0.89        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.94      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 129.9806628227234 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.825993061065674 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5214, Accuracy: 0.7909, F1 Micro: 0.883, F1 Macro: 0.8814\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4323, Accuracy: 0.8586, F1 Micro: 0.9154, F1 Macro: 0.9128\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2906, Accuracy: 0.9435, F1 Micro: 0.9649, F1 Macro: 0.9633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1948, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.14, Accuracy: 0.9621, F1 Micro: 0.9763, F1 Macro: 0.9753\n",
      "Epoch 6/10, Train Loss: 0.1051, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9721\n",
      "Epoch 7/10, Train Loss: 0.0821, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0673, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0564, Accuracy: 0.9702, F1 Micro: 0.9812, F1 Macro: 0.9799\n",
      "Epoch 10/10, Train Loss: 0.048, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.978\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9812, F1 Macro: 0.9799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.94      0.93      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4778, Accuracy: 0.9015, F1 Micro: 0.9015, F1 Macro: 0.8892\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2436, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9249\n",
      "Epoch 3/10, Train Loss: 0.1787, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9201\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1514, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9249\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1357, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9289\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.097, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9293\n",
      "Epoch 7/10, Train Loss: 0.0713, Accuracy: 0.9205, F1 Micro: 0.9205, F1 Macro: 0.9135\n",
      "Epoch 8/10, Train Loss: 0.0618, Accuracy: 0.9205, F1 Micro: 0.9205, F1 Macro: 0.9122\n",
      "Epoch 9/10, Train Loss: 0.0618, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9173\n",
      "Epoch 10/10, Train Loss: 0.0675, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.8986\n",
      "\n",
      "Sentiment analysis accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9293\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.97      0.91        87\n",
      "    positive       0.98      0.92      0.95       177\n",
      "\n",
      "    accuracy                           0.94       264\n",
      "   macro avg       0.92      0.94      0.93       264\n",
      "weighted avg       0.94      0.94      0.94       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.923\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.96      0.73      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.87      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.92      0.81        12\n",
      "     neutral       0.95      0.93      0.94       152\n",
      "    positive       0.80      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.83      0.88      0.85       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 139.6718065738678 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.199486255645752 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5273, Accuracy: 0.7902, F1 Micro: 0.8826, F1 Macro: 0.8811\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.422, Accuracy: 0.8854, F1 Micro: 0.9309, F1 Macro: 0.9288\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2771, Accuracy: 0.9487, F1 Micro: 0.968, F1 Macro: 0.9664\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1796, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1343, Accuracy: 0.9591, F1 Micro: 0.9741, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1025, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0791, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0681, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9798\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0613, Accuracy: 0.9725, F1 Micro: 0.9827, F1 Macro: 0.9817\n",
      "Epoch 10/10, Train Loss: 0.0457, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9791\n",
      "\n",
      "Aspect detection accuracy: 0.9725, F1 Micro: 0.9827, F1 Macro: 0.9817\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.96      0.95       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.98      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.98      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4698, Accuracy: 0.8817, F1 Micro: 0.8817, F1 Macro: 0.8729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2101, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.929\n",
      "Epoch 3/10, Train Loss: 0.1949, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.9018\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.141, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.9312\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1341, Accuracy: 0.9466, F1 Micro: 0.9466, F1 Macro: 0.9404\n",
      "Epoch 6/10, Train Loss: 0.1137, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9279\n",
      "Epoch 7/10, Train Loss: 0.0612, Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.9242\n",
      "Epoch 8/10, Train Loss: 0.0739, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9283\n",
      "Epoch 9/10, Train Loss: 0.0775, Accuracy: 0.9237, F1 Micro: 0.9237, F1 Macro: 0.917\n",
      "Epoch 10/10, Train Loss: 0.0533, Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.9242\n",
      "\n",
      "Sentiment analysis accuracy: 0.9466, F1 Micro: 0.9466, F1 Macro: 0.9404\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        87\n",
      "    positive       0.97      0.95      0.96       175\n",
      "\n",
      "    accuracy                           0.95       262\n",
      "   macro avg       0.94      0.95      0.94       262\n",
      "weighted avg       0.95      0.95      0.95       262\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9645, F1 Micro: 0.9645, F1 Macro: 0.9301\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       1.00      0.96      0.98        24\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.99      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.88      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.94      0.96      0.95       152\n",
      "    positive       0.87      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.84      0.85      0.84       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.98      0.99      0.99       152\n",
      "    positive       1.00      0.88      0.94        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.96      0.96      0.95       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 142.1835160255432 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 8\n",
      "Sampling duration: 3.6951394081115723 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5185, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4299, Accuracy: 0.8981, F1 Micro: 0.9378, F1 Macro: 0.9354\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2746, Accuracy: 0.9509, F1 Micro: 0.9693, F1 Macro: 0.9676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1735, Accuracy: 0.9554, F1 Micro: 0.9719, F1 Macro: 0.9699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1353, Accuracy: 0.9613, F1 Micro: 0.9759, F1 Macro: 0.9748\n",
      "Epoch 6/10, Train Loss: 0.1065, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0841, Accuracy: 0.9628, F1 Micro: 0.9764, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0679, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9775\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0554, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9781\n",
      "Epoch 10/10, Train Loss: 0.0441, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9776\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.93      0.94      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.498, Accuracy: 0.9057, F1 Micro: 0.9057, F1 Macro: 0.8921\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2448, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9327\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1798, Accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.936\n",
      "Epoch 4/10, Train Loss: 0.1573, Accuracy: 0.9358, F1 Micro: 0.9358, F1 Macro: 0.9287\n",
      "Epoch 5/10, Train Loss: 0.1255, Accuracy: 0.9321, F1 Micro: 0.9321, F1 Macro: 0.9239\n",
      "Epoch 6/10, Train Loss: 0.086, Accuracy: 0.9358, F1 Micro: 0.9358, F1 Macro: 0.9257\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0857, Accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.936\n",
      "Epoch 8/10, Train Loss: 0.0616, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.9199\n",
      "Epoch 9/10, Train Loss: 0.0768, Accuracy: 0.9208, F1 Micro: 0.9208, F1 Macro: 0.9057\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0622, Accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.9405\n",
      "\n",
      "Sentiment analysis accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.9405\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        84\n",
      "    positive       0.98      0.94      0.96       181\n",
      "\n",
      "    accuracy                           0.95       265\n",
      "   macro avg       0.93      0.95      0.94       265\n",
      "weighted avg       0.95      0.95      0.95       265\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.9177\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.85      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.93      0.94      0.94       152\n",
      "    positive       0.81      0.81      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.85      0.83      0.84       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.94      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.92      0.89      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 142.99218010902405 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.5823559761047363 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5224, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4287, Accuracy: 0.8973, F1 Micro: 0.9383, F1 Macro: 0.9364\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2715, Accuracy: 0.9539, F1 Micro: 0.9713, F1 Macro: 0.9699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1806, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1272, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "Epoch 6/10, Train Loss: 0.0954, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0746, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9783\n",
      "Epoch 8/10, Train Loss: 0.0603, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9756\n",
      "Epoch 9/10, Train Loss: 0.0499, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9763\n",
      "Epoch 10/10, Train Loss: 0.0466, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9775\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9783\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.93      0.95      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4691, Accuracy: 0.9219, F1 Micro: 0.9219, F1 Macro: 0.9119\n",
      "Epoch 2/10, Train Loss: 0.225, Accuracy: 0.918, F1 Micro: 0.918, F1 Macro: 0.9115\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1589, Accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9442\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1445, Accuracy: 0.9531, F1 Micro: 0.9531, F1 Macro: 0.9468\n",
      "Epoch 5/10, Train Loss: 0.1206, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9341\n",
      "Epoch 6/10, Train Loss: 0.1089, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9384\n",
      "Epoch 7/10, Train Loss: 0.0833, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9281\n",
      "Epoch 8/10, Train Loss: 0.1003, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9352\n",
      "Epoch 9/10, Train Loss: 0.0707, Accuracy: 0.9102, F1 Micro: 0.9102, F1 Macro: 0.9035\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.074, Accuracy: 0.9648, F1 Micro: 0.9648, F1 Macro: 0.9603\n",
      "\n",
      "Sentiment analysis accuracy: 0.9648, F1 Micro: 0.9648, F1 Macro: 0.9603\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.94      0.95        85\n",
      "    positive       0.97      0.98      0.97       171\n",
      "\n",
      "    accuracy                           0.96       256\n",
      "   macro avg       0.96      0.96      0.96       256\n",
      "weighted avg       0.96      0.96      0.96       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9622, F1 Micro: 0.9622, F1 Macro: 0.9322\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.83      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        12\n",
      "     neutral       0.93      0.95      0.94       152\n",
      "    positive       0.85      0.79      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.90      0.89      0.89       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.96      0.94        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.95      0.90      0.92        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.95      0.95       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.93      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 138.33100724220276 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.9761548042297363 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.521, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4194, Accuracy: 0.8943, F1 Micro: 0.9344, F1 Macro: 0.93\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2607, Accuracy: 0.9516, F1 Micro: 0.9699, F1 Macro: 0.9682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1687, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.125, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0941, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0744, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.978\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0635, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9799\n",
      "Epoch 9/10, Train Loss: 0.049, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9787\n",
      "Epoch 10/10, Train Loss: 0.046, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9773\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.97      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4653, Accuracy: 0.8846, F1 Micro: 0.8846, F1 Macro: 0.8781\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2349, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.9092\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1561, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9109\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1396, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9327\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1269, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9368\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.096, Accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.9452\n",
      "Epoch 7/10, Train Loss: 0.0879, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9313\n",
      "Epoch 8/10, Train Loss: 0.0662, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9207\n",
      "Epoch 9/10, Train Loss: 0.0521, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.925\n",
      "Epoch 10/10, Train Loss: 0.0554, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9272\n",
      "\n",
      "Sentiment analysis accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.9452\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.93        87\n",
      "    positive       0.99      0.94      0.96       173\n",
      "\n",
      "    accuracy                           0.95       260\n",
      "   macro avg       0.94      0.96      0.95       260\n",
      "weighted avg       0.95      0.95      0.95       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9614, F1 Micro: 0.9614, F1 Macro: 0.9283\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.94      0.91        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.88      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.92      0.97      0.95       152\n",
      "    positive       0.86      0.73      0.79        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.85      0.84      0.85       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.95      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.89      0.94      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.95      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 150.61853551864624 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.363067865371704 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.531, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4167, Accuracy: 0.8958, F1 Micro: 0.9363, F1 Macro: 0.9332\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.267, Accuracy: 0.9516, F1 Micro: 0.97, F1 Macro: 0.9686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1787, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1283, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9771\n",
      "Epoch 6/10, Train Loss: 0.0956, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9764\n",
      "Epoch 7/10, Train Loss: 0.077, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0603, Accuracy: 0.9658, F1 Micro: 0.9783, F1 Macro: 0.9766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0529, Accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9793\n",
      "Epoch 10/10, Train Loss: 0.0436, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9764\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.94      0.93      0.93       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4772, Accuracy: 0.9301, F1 Micro: 0.9301, F1 Macro: 0.919\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2044, Accuracy: 0.9301, F1 Micro: 0.9301, F1 Macro: 0.9179\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1644, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9379\n",
      "Epoch 4/10, Train Loss: 0.1485, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9266\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1148, Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9459\n",
      "Epoch 6/10, Train Loss: 0.1097, Accuracy: 0.9191, F1 Micro: 0.9191, F1 Macro: 0.911\n",
      "Epoch 7/10, Train Loss: 0.0857, Accuracy: 0.9265, F1 Micro: 0.9265, F1 Macro: 0.9187\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0755, Accuracy: 0.9559, F1 Micro: 0.9559, F1 Macro: 0.9493\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0767, Accuracy: 0.9596, F1 Micro: 0.9596, F1 Macro: 0.9531\n",
      "Epoch 10/10, Train Loss: 0.0683, Accuracy: 0.9338, F1 Micro: 0.9338, F1 Macro: 0.9261\n",
      "\n",
      "Sentiment analysis accuracy: 0.9596, F1 Micro: 0.9596, F1 Macro: 0.9531\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.94        86\n",
      "    positive       0.97      0.97      0.97       186\n",
      "\n",
      "    accuracy                           0.96       272\n",
      "   macro avg       0.95      0.95      0.95       272\n",
      "weighted avg       0.96      0.96      0.96       272\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.963, F1 Micro: 0.963, F1 Macro: 0.9336\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.82      0.82      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.85      0.87       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.83      0.91        12\n",
      "     neutral       0.94      0.93      0.93       152\n",
      "    positive       0.80      0.87      0.83        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.91      0.88      0.89       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.95      0.88      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.95      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.95      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 150.04354095458984 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.0075926780700684 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5202, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4065, Accuracy: 0.9196, F1 Micro: 0.9506, F1 Macro: 0.9481\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2473, Accuracy: 0.9568, F1 Micro: 0.9732, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1641, Accuracy: 0.9621, F1 Micro: 0.9763, F1 Macro: 0.9749\n",
      "Epoch 5/10, Train Loss: 0.1286, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9725\n",
      "Epoch 6/10, Train Loss: 0.0983, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0705, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9775\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0611, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9796\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0493, Accuracy: 0.9702, F1 Micro: 0.9812, F1 Macro: 0.9799\n",
      "Epoch 10/10, Train Loss: 0.0431, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9794\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9812, F1 Macro: 0.9799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.94      0.94      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4584, Accuracy: 0.9368, F1 Micro: 0.9368, F1 Macro: 0.9284\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2376, Accuracy: 0.9368, F1 Micro: 0.9368, F1 Macro: 0.9296\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1935, Accuracy: 0.948, F1 Micro: 0.948, F1 Macro: 0.9416\n",
      "Epoch 4/10, Train Loss: 0.1203, Accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9376\n",
      "Epoch 5/10, Train Loss: 0.1068, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9336\n",
      "Epoch 6/10, Train Loss: 0.087, Accuracy: 0.9368, F1 Micro: 0.9368, F1 Macro: 0.9292\n",
      "Epoch 7/10, Train Loss: 0.0862, Accuracy: 0.9257, F1 Micro: 0.9257, F1 Macro: 0.9129\n",
      "Epoch 8/10, Train Loss: 0.0644, Accuracy: 0.9219, F1 Micro: 0.9219, F1 Macro: 0.9139\n",
      "Epoch 9/10, Train Loss: 0.0617, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9324\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.049, Accuracy: 0.948, F1 Micro: 0.948, F1 Macro: 0.9412\n",
      "\n",
      "Sentiment analysis accuracy: 0.948, F1 Micro: 0.948, F1 Macro: 0.9412\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.95      0.92        86\n",
      "    positive       0.98      0.95      0.96       183\n",
      "\n",
      "    accuracy                           0.95       269\n",
      "   macro avg       0.93      0.95      0.94       269\n",
      "weighted avg       0.95      0.95      0.95       269\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9614, F1 Micro: 0.9614, F1 Macro: 0.929\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.97      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.82      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.94      0.94      0.94       152\n",
      "    positive       0.81      0.81      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.86      0.86      0.86       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.94      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.95      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 150.48316287994385 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 8\n",
      "Sampling duration: 1.0104005336761475 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5143, Accuracy: 0.7917, F1 Micro: 0.8833, F1 Macro: 0.8818\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4086, Accuracy: 0.9115, F1 Micro: 0.9456, F1 Macro: 0.9431\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2639, Accuracy: 0.9442, F1 Micro: 0.9649, F1 Macro: 0.962\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1747, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1291, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0903, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9773\n",
      "Epoch 7/10, Train Loss: 0.0716, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0578, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9776\n",
      "Epoch 9/10, Train Loss: 0.0483, Accuracy: 0.9598, F1 Micro: 0.9745, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0438, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9795\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9795\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.94      0.94      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4918, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8941\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2279, Accuracy: 0.9211, F1 Micro: 0.9211, F1 Macro: 0.9142\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1716, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.926\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1489, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9321\n",
      "Epoch 5/10, Train Loss: 0.1145, Accuracy: 0.9248, F1 Micro: 0.9248, F1 Macro: 0.913\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1242, Accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9409\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0707, Accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9402\n",
      "Epoch 8/10, Train Loss: 0.0838, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9308\n",
      "Epoch 9/10, Train Loss: 0.0886, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9213\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0516, Accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9402\n",
      "\n",
      "Sentiment analysis accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9402\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.93      0.92        86\n",
      "    positive       0.97      0.96      0.96       180\n",
      "\n",
      "    accuracy                           0.95       266\n",
      "   macro avg       0.94      0.94      0.94       266\n",
      "weighted avg       0.95      0.95      0.95       266\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9248\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.85      0.85      0.85        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.86      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.94      0.94      0.94       152\n",
      "    positive       0.81      0.81      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.86      0.86      0.86       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 161.4815969467163 s\n",
      "Total runtime: 3232.1523764133453 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[3], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440c3bee",
   "metadata": {
    "papermill": {
     "duration": 0.29141,
     "end_time": "2025-03-25T16:11:15.914372",
     "exception": false,
     "start_time": "2025-03-25T16:11:15.622962",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e840c7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 5\n",
      "Random seed: 94\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6298, Accuracy: 0.7522, F1 Micro: 0.854, F1 Macro: 0.8362\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5654, Accuracy: 0.7887, F1 Micro: 0.8819, F1 Macro: 0.8803\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5262, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4783, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4582, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4326, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4132, Accuracy: 0.7924, F1 Micro: 0.8837, F1 Macro: 0.8822\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4395, Accuracy: 0.7939, F1 Micro: 0.8842, F1 Macro: 0.8826\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.4306, Accuracy: 0.7999, F1 Micro: 0.887, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3956, Accuracy: 0.8036, F1 Micro: 0.8888, F1 Macro: 0.8871\n",
      "\n",
      "Aspect detection accuracy: 0.8036, F1 Micro: 0.8888, F1 Macro: 0.8871\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.78      1.00      0.88       175\n",
      "      others       0.75      0.99      0.85       158\n",
      "        part       0.74      0.97      0.84       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.80      0.99      0.89      1061\n",
      "   macro avg       0.80      0.99      0.89      1061\n",
      "weighted avg       0.81      0.99      0.89      1061\n",
      " samples avg       0.81      0.99      0.89      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7142, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5719, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.6151, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5677, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.5123, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.5138, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4932, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3579, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3098, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2431, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "\n",
      "Sentiment analysis accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         6\n",
      "    positive       0.81      1.00      0.89        25\n",
      "\n",
      "    accuracy                           0.81        31\n",
      "   macro avg       0.40      0.50      0.45        31\n",
      "weighted avg       0.65      0.81      0.72        31\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.7994, F1 Micro: 0.7994, F1 Macro: 0.3298\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.77      1.00      0.87       167\n",
      "    positive       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.77       216\n",
      "   macro avg       0.26      0.33      0.29       216\n",
      "weighted avg       0.60      0.77      0.67       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.75      0.99      0.85       152\n",
      "    positive       0.67      0.19      0.30        52\n",
      "\n",
      "    accuracy                           0.74       216\n",
      "   macro avg       0.47      0.39      0.38       216\n",
      "weighted avg       0.69      0.74      0.67       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        23\n",
      "     neutral       0.74      0.97      0.84       152\n",
      "    positive       0.56      0.22      0.32        41\n",
      "\n",
      "    accuracy                           0.73       216\n",
      "   macro avg       0.43      0.40      0.39       216\n",
      "weighted avg       0.63      0.73      0.65       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 72.74051690101624 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 81\n",
      "Sampling duration: 14.12340259552002 seconds\n",
      "New train size: 135\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6089, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5125, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4697, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4728, Accuracy: 0.7946, F1 Micro: 0.8848, F1 Macro: 0.8833\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4376, Accuracy: 0.808, F1 Micro: 0.8914, F1 Macro: 0.8899\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4025, Accuracy: 0.8199, F1 Micro: 0.896, F1 Macro: 0.894\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3712, Accuracy: 0.8371, F1 Micro: 0.9054, F1 Macro: 0.9045\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3197, Accuracy: 0.8452, F1 Micro: 0.9088, F1 Macro: 0.9068\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2662, Accuracy: 0.8601, F1 Micro: 0.917, F1 Macro: 0.9159\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2484, Accuracy: 0.8743, F1 Micro: 0.9247, F1 Macro: 0.9232\n",
      "\n",
      "Aspect detection accuracy: 0.8743, F1 Micro: 0.9247, F1 Macro: 0.9232\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.92      1.00      0.96       187\n",
      "     machine       0.80      0.99      0.89       175\n",
      "      others       0.85      0.89      0.87       158\n",
      "        part       0.89      0.97      0.93       158\n",
      "       price       0.88      1.00      0.93       192\n",
      "     service       0.92      1.00      0.96       191\n",
      "\n",
      "   micro avg       0.88      0.98      0.92      1061\n",
      "   macro avg       0.88      0.98      0.92      1061\n",
      "weighted avg       0.88      0.98      0.93      1061\n",
      " samples avg       0.88      0.98      0.92      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6708, Accuracy: 0.7368, F1 Micro: 0.7368, F1 Macro: 0.4242\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5905, Accuracy: 0.7368, F1 Micro: 0.7368, F1 Macro: 0.4242\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5498, Accuracy: 0.75, F1 Micro: 0.75, F1 Macro: 0.4751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4716, Accuracy: 0.7697, F1 Micro: 0.7697, F1 Macro: 0.6496\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3896, Accuracy: 0.8224, F1 Micro: 0.8224, F1 Macro: 0.7519\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2417, Accuracy: 0.8684, F1 Micro: 0.8684, F1 Macro: 0.8144\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1442, Accuracy: 0.8816, F1 Micro: 0.8816, F1 Macro: 0.8362\n",
      "Epoch 8/10, Train Loss: 0.0822, Accuracy: 0.8684, F1 Micro: 0.8684, F1 Macro: 0.8144\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0925, Accuracy: 0.9145, F1 Micro: 0.9145, F1 Macro: 0.8906\n",
      "Epoch 10/10, Train Loss: 0.0584, Accuracy: 0.9013, F1 Micro: 0.9013, F1 Macro: 0.8738\n",
      "\n",
      "Sentiment analysis accuracy: 0.9145, F1 Micro: 0.9145, F1 Macro: 0.8906\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.85      0.84        40\n",
      "    positive       0.95      0.94      0.94       112\n",
      "\n",
      "    accuracy                           0.91       152\n",
      "   macro avg       0.89      0.89      0.89       152\n",
      "weighted avg       0.92      0.91      0.91       152\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 135: Accuracy: 0.8642, F1 Micro: 0.8642, F1 Macro: 0.6267\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.36      0.53        11\n",
      "     neutral       0.92      1.00      0.96       181\n",
      "    positive       1.00      0.67      0.80        24\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.97      0.68      0.76       216\n",
      "weighted avg       0.94      0.93      0.92       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.79      0.99      0.88       167\n",
      "    positive       0.83      0.15      0.26        33\n",
      "\n",
      "    accuracy                           0.79       216\n",
      "   macro avg       0.54      0.38      0.38       216\n",
      "weighted avg       0.74      0.79      0.72       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.50      0.57        12\n",
      "     neutral       0.84      0.89      0.87       152\n",
      "    positive       0.64      0.58      0.61        52\n",
      "\n",
      "    accuracy                           0.79       216\n",
      "   macro avg       0.72      0.66      0.68       216\n",
      "weighted avg       0.78      0.79      0.79       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.74      0.77        23\n",
      "     neutral       0.89      0.97      0.93       152\n",
      "    positive       0.87      0.63      0.73        41\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.86      0.78      0.81       216\n",
      "weighted avg       0.88      0.88      0.87       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.08      0.14        13\n",
      "     neutral       0.88      1.00      0.93       186\n",
      "    positive       0.67      0.12      0.20        17\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.85      0.40      0.43       216\n",
      "weighted avg       0.87      0.88      0.83       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.43      0.60        14\n",
      "     neutral       0.92      1.00      0.96       185\n",
      "    positive       0.78      0.41      0.54        17\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.90      0.61      0.70       216\n",
      "weighted avg       0.91      0.92      0.90       216\n",
      "\n",
      "Total train time: 80.16390776634216 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 73\n",
      "Sampling duration: 15.130931615829468 seconds\n",
      "New train size: 208\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5791, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5077, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4855, Accuracy: 0.7939, F1 Micro: 0.8844, F1 Macro: 0.8829\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4425, Accuracy: 0.8073, F1 Micro: 0.8907, F1 Macro: 0.8892\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4026, Accuracy: 0.8452, F1 Micro: 0.9099, F1 Macro: 0.9095\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3609, Accuracy: 0.8519, F1 Micro: 0.9127, F1 Macro: 0.9121\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2962, Accuracy: 0.8817, F1 Micro: 0.929, F1 Macro: 0.9282\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.242, Accuracy: 0.8936, F1 Micro: 0.9351, F1 Macro: 0.9336\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1938, Accuracy: 0.91, F1 Micro: 0.945, F1 Macro: 0.9436\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1635, Accuracy: 0.9122, F1 Micro: 0.9457, F1 Macro: 0.9435\n",
      "\n",
      "Aspect detection accuracy: 0.9122, F1 Micro: 0.9457, F1 Macro: 0.9435\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.96      1.00      0.98       187\n",
      "     machine       0.83      0.98      0.90       175\n",
      "      others       0.88      0.90      0.89       158\n",
      "        part       0.95      0.92      0.93       158\n",
      "       price       0.96      0.99      0.98       192\n",
      "     service       0.96      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.92      0.97      0.95      1061\n",
      "   macro avg       0.92      0.97      0.94      1061\n",
      "weighted avg       0.93      0.97      0.95      1061\n",
      " samples avg       0.93      0.97      0.94      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6377, Accuracy: 0.7072, F1 Micro: 0.7072, F1 Macro: 0.4142\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4991, Accuracy: 0.7072, F1 Micro: 0.7072, F1 Macro: 0.4142\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4556, Accuracy: 0.7207, F1 Micro: 0.7207, F1 Macro: 0.4617\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3448, Accuracy: 0.9009, F1 Micro: 0.9009, F1 Macro: 0.8843\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1927, Accuracy: 0.9009, F1 Micro: 0.9009, F1 Macro: 0.8869\n",
      "Epoch 6/10, Train Loss: 0.1295, Accuracy: 0.8919, F1 Micro: 0.8919, F1 Macro: 0.8784\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.125, Accuracy: 0.9054, F1 Micro: 0.9054, F1 Macro: 0.89\n",
      "Epoch 8/10, Train Loss: 0.16, Accuracy: 0.8739, F1 Micro: 0.8739, F1 Macro: 0.8449\n",
      "Epoch 9/10, Train Loss: 0.0744, Accuracy: 0.9009, F1 Micro: 0.9009, F1 Macro: 0.8843\n",
      "Epoch 10/10, Train Loss: 0.0894, Accuracy: 0.8739, F1 Micro: 0.8739, F1 Macro: 0.8433\n",
      "\n",
      "Sentiment analysis accuracy: 0.9054, F1 Micro: 0.9054, F1 Macro: 0.89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.91      0.85        65\n",
      "    positive       0.96      0.90      0.93       157\n",
      "\n",
      "    accuracy                           0.91       222\n",
      "   macro avg       0.88      0.91      0.89       222\n",
      "weighted avg       0.91      0.91      0.91       222\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 208: Accuracy: 0.9035, F1 Micro: 0.9035, F1 Macro: 0.7968\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.64      0.78        11\n",
      "     neutral       0.97      1.00      0.98       181\n",
      "    positive       0.91      0.83      0.87        24\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.96      0.82      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.25      0.40        16\n",
      "     neutral       0.82      0.98      0.90       167\n",
      "    positive       0.69      0.27      0.39        33\n",
      "\n",
      "    accuracy                           0.82       216\n",
      "   macro avg       0.84      0.50      0.56       216\n",
      "weighted avg       0.82      0.82      0.78       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.75      0.72        12\n",
      "     neutral       0.88      0.89      0.89       152\n",
      "    positive       0.73      0.67      0.70        52\n",
      "\n",
      "    accuracy                           0.83       216\n",
      "   macro avg       0.77      0.77      0.77       216\n",
      "weighted avg       0.83      0.83      0.83       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.87      0.74        23\n",
      "     neutral       0.95      0.92      0.93       152\n",
      "    positive       0.86      0.78      0.82        41\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.82      0.86      0.83       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.96      0.99      0.98       186\n",
      "    positive       0.86      0.71      0.77        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.82      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.64      0.78        14\n",
      "     neutral       0.96      1.00      0.98       185\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.96      0.80      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Total train time: 93.93812274932861 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 66\n",
      "Sampling duration: 16.531806468963623 seconds\n",
      "New train size: 274\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5556, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.488, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4846, Accuracy: 0.7991, F1 Micro: 0.8871, F1 Macro: 0.8857\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4078, Accuracy: 0.8318, F1 Micro: 0.9029, F1 Macro: 0.9019\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3587, Accuracy: 0.8542, F1 Micro: 0.9141, F1 Macro: 0.9133\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2958, Accuracy: 0.8884, F1 Micro: 0.9323, F1 Macro: 0.9307\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2392, Accuracy: 0.9189, F1 Micro: 0.9501, F1 Macro: 0.9483\n",
      "Epoch 8/10, Train Loss: 0.1925, Accuracy: 0.9174, F1 Micro: 0.9492, F1 Macro: 0.9472\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.149, Accuracy: 0.9249, F1 Micro: 0.9534, F1 Macro: 0.951\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1294, Accuracy: 0.9412, F1 Micro: 0.9634, F1 Macro: 0.9613\n",
      "\n",
      "Aspect detection accuracy: 0.9412, F1 Micro: 0.9634, F1 Macro: 0.9613\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.97      1.00      0.99       187\n",
      "     machine       0.93      0.99      0.96       175\n",
      "      others       0.88      0.91      0.89       158\n",
      "        part       0.93      0.99      0.96       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.95      0.98      0.96      1061\n",
      "   macro avg       0.94      0.98      0.96      1061\n",
      "weighted avg       0.95      0.98      0.96      1061\n",
      " samples avg       0.95      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6348, Accuracy: 0.6809, F1 Micro: 0.6809, F1 Macro: 0.4051\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5196, Accuracy: 0.8468, F1 Micro: 0.8468, F1 Macro: 0.8153\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.331, Accuracy: 0.8936, F1 Micro: 0.8936, F1 Macro: 0.8839\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1879, Accuracy: 0.9362, F1 Micro: 0.9362, F1 Macro: 0.9287\n",
      "Epoch 5/10, Train Loss: 0.1369, Accuracy: 0.9277, F1 Micro: 0.9277, F1 Macro: 0.9159\n",
      "Epoch 6/10, Train Loss: 0.1464, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9142\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.118, Accuracy: 0.9404, F1 Micro: 0.9404, F1 Macro: 0.9324\n",
      "Epoch 8/10, Train Loss: 0.0676, Accuracy: 0.9191, F1 Micro: 0.9191, F1 Macro: 0.9108\n",
      "Epoch 9/10, Train Loss: 0.0626, Accuracy: 0.9362, F1 Micro: 0.9362, F1 Macro: 0.9278\n",
      "Epoch 10/10, Train Loss: 0.0413, Accuracy: 0.9362, F1 Micro: 0.9362, F1 Macro: 0.9283\n",
      "\n",
      "Sentiment analysis accuracy: 0.9404, F1 Micro: 0.9404, F1 Macro: 0.9324\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.93      0.91        75\n",
      "    positive       0.97      0.94      0.96       160\n",
      "\n",
      "    accuracy                           0.94       235\n",
      "   macro avg       0.93      0.94      0.93       235\n",
      "weighted avg       0.94      0.94      0.94       235\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 274: Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.8714\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       0.91      0.88      0.89        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.96      0.87      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.69      0.79        16\n",
      "     neutral       0.92      0.99      0.95       167\n",
      "    positive       0.88      0.67      0.76        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.91      0.78      0.83       216\n",
      "weighted avg       0.92      0.92      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.88      0.91      0.90       152\n",
      "    positive       0.77      0.71      0.74        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.80      0.79      0.80       216\n",
      "weighted avg       0.85      0.85      0.85       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.91      0.86        23\n",
      "     neutral       0.93      0.99      0.96       152\n",
      "    positive       0.96      0.66      0.78        41\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.90      0.85      0.87       216\n",
      "weighted avg       0.92      0.92      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.86      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.89      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 97.6897132396698 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 59\n",
      "Sampling duration: 15.164808988571167 seconds\n",
      "New train size: 333\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5509, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4823, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4662, Accuracy: 0.8192, F1 Micro: 0.8969, F1 Macro: 0.8957\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4062, Accuracy: 0.8557, F1 Micro: 0.9151, F1 Macro: 0.9147\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3241, Accuracy: 0.8936, F1 Micro: 0.9355, F1 Macro: 0.9341\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2502, Accuracy: 0.9256, F1 Micro: 0.9538, F1 Macro: 0.9515\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1907, Accuracy: 0.9397, F1 Micro: 0.9627, F1 Macro: 0.9608\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1549, Accuracy: 0.9472, F1 Micro: 0.9673, F1 Macro: 0.966\n",
      "Epoch 9/10, Train Loss: 0.1344, Accuracy: 0.9435, F1 Micro: 0.9647, F1 Macro: 0.9629\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1028, Accuracy: 0.9479, F1 Micro: 0.9676, F1 Macro: 0.9661\n",
      "\n",
      "Aspect detection accuracy: 0.9479, F1 Micro: 0.9676, F1 Macro: 0.9661\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.93      0.98      0.96       175\n",
      "      others       0.89      0.96      0.93       158\n",
      "        part       0.94      0.97      0.95       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.97      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.95      0.99      0.97      1061\n",
      "   macro avg       0.95      0.98      0.97      1061\n",
      "weighted avg       0.95      0.99      0.97      1061\n",
      " samples avg       0.95      0.99      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5807, Accuracy: 0.6851, F1 Micro: 0.6851, F1 Macro: 0.4066\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4908, Accuracy: 0.8723, F1 Micro: 0.8723, F1 Macro: 0.8587\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2875, Accuracy: 0.9149, F1 Micro: 0.9149, F1 Macro: 0.9052\n",
      "Epoch 4/10, Train Loss: 0.1981, Accuracy: 0.9021, F1 Micro: 0.9021, F1 Macro: 0.8926\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1454, Accuracy: 0.9149, F1 Micro: 0.9149, F1 Macro: 0.9058\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1109, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9136\n",
      "Epoch 7/10, Train Loss: 0.0607, Accuracy: 0.9021, F1 Micro: 0.9021, F1 Macro: 0.8926\n",
      "Epoch 8/10, Train Loss: 0.1137, Accuracy: 0.9149, F1 Micro: 0.9149, F1 Macro: 0.9047\n",
      "Epoch 9/10, Train Loss: 0.0544, Accuracy: 0.9064, F1 Micro: 0.9064, F1 Macro: 0.8951\n",
      "Epoch 10/10, Train Loss: 0.0438, Accuracy: 0.9191, F1 Micro: 0.9191, F1 Macro: 0.9091\n",
      "\n",
      "Sentiment analysis accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9136\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.93      0.88        74\n",
      "    positive       0.97      0.92      0.94       161\n",
      "\n",
      "    accuracy                           0.92       235\n",
      "   macro avg       0.90      0.93      0.91       235\n",
      "weighted avg       0.93      0.92      0.92       235\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 333: Accuracy: 0.9383, F1 Micro: 0.9383, F1 Macro: 0.8746\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.98      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.69      0.76        16\n",
      "     neutral       0.93      0.98      0.95       167\n",
      "    positive       0.85      0.67      0.75        33\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.87      0.78      0.82       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.75      0.86        12\n",
      "     neutral       0.90      0.96      0.93       152\n",
      "    positive       0.86      0.73      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.92      0.81      0.86       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.91      0.79        23\n",
      "     neutral       0.94      0.97      0.95       152\n",
      "    positive       0.97      0.68      0.80        41\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.87      0.85      0.85       216\n",
      "weighted avg       0.92      0.91      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.86      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.64      0.78        14\n",
      "     neutral       0.97      1.00      0.98       185\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.97      0.84      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 106.5486147403717 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 54\n",
      "Sampling duration: 14.260348558425903 seconds\n",
      "New train size: 387\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5574, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4891, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4522, Accuracy: 0.8415, F1 Micro: 0.9081, F1 Macro: 0.9076\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3735, Accuracy: 0.8936, F1 Micro: 0.9363, F1 Macro: 0.9357\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.273, Accuracy: 0.9271, F1 Micro: 0.9555, F1 Macro: 0.9546\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2156, Accuracy: 0.9479, F1 Micro: 0.9677, F1 Macro: 0.9664\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1721, Accuracy: 0.9494, F1 Micro: 0.9686, F1 Macro: 0.9672\n",
      "Epoch 8/10, Train Loss: 0.1279, Accuracy: 0.9487, F1 Micro: 0.9681, F1 Macro: 0.9667\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1032, Accuracy: 0.9501, F1 Micro: 0.9688, F1 Macro: 0.9668\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0835, Accuracy: 0.9516, F1 Micro: 0.9698, F1 Macro: 0.968\n",
      "\n",
      "Aspect detection accuracy: 0.9516, F1 Micro: 0.9698, F1 Macro: 0.968\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.93      0.99      0.96       175\n",
      "      others       0.92      0.91      0.91       158\n",
      "        part       0.95      0.99      0.97       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.97      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.95      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.602, Accuracy: 0.6996, F1 Micro: 0.6996, F1 Macro: 0.4367\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.414, Accuracy: 0.9053, F1 Micro: 0.9053, F1 Macro: 0.8945\n",
      "Epoch 3/10, Train Loss: 0.2746, Accuracy: 0.8807, F1 Micro: 0.8807, F1 Macro: 0.8699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1919, Accuracy: 0.9342, F1 Micro: 0.9342, F1 Macro: 0.924\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1634, Accuracy: 0.9383, F1 Micro: 0.9383, F1 Macro: 0.9285\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1329, Accuracy: 0.9424, F1 Micro: 0.9424, F1 Macro: 0.9339\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1112, Accuracy: 0.9424, F1 Micro: 0.9424, F1 Macro: 0.933\n",
      "Epoch 8/10, Train Loss: 0.1052, Accuracy: 0.9342, F1 Micro: 0.9342, F1 Macro: 0.9245\n",
      "Epoch 9/10, Train Loss: 0.0767, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.92\n",
      "Epoch 10/10, Train Loss: 0.0622, Accuracy: 0.9383, F1 Micro: 0.9383, F1 Macro: 0.929\n",
      "\n",
      "Sentiment analysis accuracy: 0.9424, F1 Micro: 0.9424, F1 Macro: 0.933\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.93      0.91        74\n",
      "    positive       0.97      0.95      0.96       169\n",
      "\n",
      "    accuracy                           0.94       243\n",
      "   macro avg       0.93      0.94      0.93       243\n",
      "weighted avg       0.94      0.94      0.94       243\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 387: Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.8859\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.88      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.92      0.99      0.96       167\n",
      "    positive       0.91      0.64      0.75        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.92      0.79      0.84       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.75      0.67        12\n",
      "     neutral       0.93      0.91      0.92       152\n",
      "    positive       0.81      0.81      0.81        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.78      0.82      0.80       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.83      0.86        23\n",
      "     neutral       0.94      0.99      0.97       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.87      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.89      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.71      0.83        14\n",
      "     neutral       0.97      1.00      0.99       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.99      0.89      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 114.0938732624054 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 48\n",
      "Sampling duration: 13.132792472839355 seconds\n",
      "New train size: 435\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5528, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4815, Accuracy: 0.8051, F1 Micro: 0.8899, F1 Macro: 0.8884\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4304, Accuracy: 0.8423, F1 Micro: 0.908, F1 Macro: 0.9066\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3382, Accuracy: 0.9048, F1 Micro: 0.9423, F1 Macro: 0.9413\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.252, Accuracy: 0.9479, F1 Micro: 0.9678, F1 Macro: 0.9664\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1935, Accuracy: 0.9494, F1 Micro: 0.9684, F1 Macro: 0.9664\n",
      "Epoch 7/10, Train Loss: 0.1448, Accuracy: 0.9472, F1 Micro: 0.967, F1 Macro: 0.9645\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1106, Accuracy: 0.9531, F1 Micro: 0.9707, F1 Macro: 0.9688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0915, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9762\n",
      "Epoch 10/10, Train Loss: 0.0805, Accuracy: 0.9606, F1 Micro: 0.9754, F1 Macro: 0.974\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.91      0.96      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6001, Accuracy: 0.7984, F1 Micro: 0.7984, F1 Macro: 0.7368\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3661, Accuracy: 0.9194, F1 Micro: 0.9194, F1 Macro: 0.9105\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2296, Accuracy: 0.9194, F1 Micro: 0.9194, F1 Macro: 0.911\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1467, Accuracy: 0.9274, F1 Micro: 0.9274, F1 Macro: 0.9195\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1642, Accuracy: 0.9556, F1 Micro: 0.9556, F1 Macro: 0.9494\n",
      "Epoch 6/10, Train Loss: 0.1392, Accuracy: 0.9476, F1 Micro: 0.9476, F1 Macro: 0.9398\n",
      "Epoch 7/10, Train Loss: 0.1162, Accuracy: 0.9194, F1 Micro: 0.9194, F1 Macro: 0.911\n",
      "Epoch 8/10, Train Loss: 0.1287, Accuracy: 0.9315, F1 Micro: 0.9315, F1 Macro: 0.9237\n",
      "Epoch 9/10, Train Loss: 0.0936, Accuracy: 0.9355, F1 Micro: 0.9355, F1 Macro: 0.928\n",
      "Epoch 10/10, Train Loss: 0.0482, Accuracy: 0.9435, F1 Micro: 0.9435, F1 Macro: 0.9358\n",
      "\n",
      "Sentiment analysis accuracy: 0.9556, F1 Micro: 0.9556, F1 Macro: 0.9494\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93        79\n",
      "    positive       0.98      0.96      0.97       169\n",
      "\n",
      "    accuracy                           0.96       248\n",
      "   macro avg       0.95      0.95      0.95       248\n",
      "weighted avg       0.96      0.96      0.96       248\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 435: Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.912\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.98      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.86      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.91      0.96      0.94       152\n",
      "    positive       0.86      0.73      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.84      0.81      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.92      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.93      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 116.72624516487122 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 43\n",
      "Sampling duration: 11.841917514801025 seconds\n",
      "New train size: 478\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.549, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4795, Accuracy: 0.8058, F1 Micro: 0.8903, F1 Macro: 0.889\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4143, Accuracy: 0.8571, F1 Micro: 0.9161, F1 Macro: 0.9156\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3217, Accuracy: 0.9129, F1 Micro: 0.9462, F1 Macro: 0.9436\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.23, Accuracy: 0.9449, F1 Micro: 0.9659, F1 Macro: 0.9645\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1818, Accuracy: 0.9561, F1 Micro: 0.9726, F1 Macro: 0.971\n",
      "Epoch 7/10, Train Loss: 0.1315, Accuracy: 0.9539, F1 Micro: 0.9709, F1 Macro: 0.9685\n",
      "Epoch 8/10, Train Loss: 0.1092, Accuracy: 0.9539, F1 Micro: 0.9712, F1 Macro: 0.9698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0884, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.078, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9722\n",
      "\n",
      "Aspect detection accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9722\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.92      0.92       158\n",
      "        part       0.95      0.99      0.97       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5671, Accuracy: 0.8287, F1 Micro: 0.8287, F1 Macro: 0.7685\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3462, Accuracy: 0.8924, F1 Micro: 0.8924, F1 Macro: 0.8834\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2469, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9284\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1349, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9288\n",
      "Epoch 5/10, Train Loss: 0.1397, Accuracy: 0.9203, F1 Micro: 0.9203, F1 Macro: 0.912\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.123, Accuracy: 0.9402, F1 Micro: 0.9402, F1 Macro: 0.9331\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1342, Accuracy: 0.9482, F1 Micro: 0.9482, F1 Macro: 0.9417\n",
      "Epoch 8/10, Train Loss: 0.0777, Accuracy: 0.9402, F1 Micro: 0.9402, F1 Macro: 0.9314\n",
      "Epoch 9/10, Train Loss: 0.0753, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9242\n",
      "Epoch 10/10, Train Loss: 0.0817, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9242\n",
      "\n",
      "Sentiment analysis accuracy: 0.9482, F1 Micro: 0.9482, F1 Macro: 0.9417\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.97      0.92        79\n",
      "    positive       0.99      0.94      0.96       172\n",
      "\n",
      "    accuracy                           0.95       251\n",
      "   macro avg       0.93      0.96      0.94       251\n",
      "weighted avg       0.95      0.95      0.95       251\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 478: Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.9057\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.75      0.69        12\n",
      "     neutral       0.92      0.91      0.92       152\n",
      "    positive       0.78      0.77      0.78        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.78      0.81      0.80       216\n",
      "weighted avg       0.87      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.95      0.99      0.97       152\n",
      "    positive       0.97      0.76      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.89      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.79      0.85        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 109.62799859046936 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 39\n",
      "Sampling duration: 10.507202863693237 seconds\n",
      "New train size: 517\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5293, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4809, Accuracy: 0.8051, F1 Micro: 0.8898, F1 Macro: 0.8885\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4145, Accuracy: 0.872, F1 Micro: 0.924, F1 Macro: 0.9232\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2997, Accuracy: 0.9293, F1 Micro: 0.9565, F1 Macro: 0.9551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2128, Accuracy: 0.9464, F1 Micro: 0.9668, F1 Macro: 0.9655\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1563, Accuracy: 0.9561, F1 Micro: 0.9725, F1 Macro: 0.9712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1196, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9723\n",
      "Epoch 8/10, Train Loss: 0.093, Accuracy: 0.9509, F1 Micro: 0.9691, F1 Macro: 0.9666\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0723, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9737\n",
      "Epoch 10/10, Train Loss: 0.0688, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9718\n",
      "\n",
      "Aspect detection accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9737\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.92      0.93       158\n",
      "        part       0.97      0.98      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5623, Accuracy: 0.8697, F1 Micro: 0.8697, F1 Macro: 0.8534\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2929, Accuracy: 0.9195, F1 Micro: 0.9195, F1 Macro: 0.9075\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1951, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9117\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.18, Accuracy: 0.9272, F1 Micro: 0.9272, F1 Macro: 0.9174\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1539, Accuracy: 0.931, F1 Micro: 0.931, F1 Macro: 0.9189\n",
      "Epoch 6/10, Train Loss: 0.1124, Accuracy: 0.9272, F1 Micro: 0.9272, F1 Macro: 0.9158\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0853, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9252\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0902, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9261\n",
      "Epoch 9/10, Train Loss: 0.0544, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.8977\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0669, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9252\n",
      "\n",
      "Sentiment analysis accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9252\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.95      0.90        79\n",
      "    positive       0.98      0.93      0.95       182\n",
      "\n",
      "    accuracy                           0.93       261\n",
      "   macro avg       0.91      0.94      0.93       261\n",
      "weighted avg       0.94      0.93      0.94       261\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 517: Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.9035\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.81      0.81      0.81        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.84      0.86      0.85       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.91      0.82        23\n",
      "     neutral       0.97      0.98      0.97       152\n",
      "    positive       0.94      0.78      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.89      0.88       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.89      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.93      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 122.7927258014679 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 23\n",
      "Sampling duration: 9.713140726089478 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5474, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4891, Accuracy: 0.8051, F1 Micro: 0.8885, F1 Macro: 0.8867\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.411, Accuracy: 0.8787, F1 Micro: 0.9281, F1 Macro: 0.9276\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2884, Accuracy: 0.9397, F1 Micro: 0.9626, F1 Macro: 0.9609\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1941, Accuracy: 0.9464, F1 Micro: 0.9667, F1 Macro: 0.9646\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1533, Accuracy: 0.9487, F1 Micro: 0.9679, F1 Macro: 0.9654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1173, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9735\n",
      "Epoch 8/10, Train Loss: 0.094, Accuracy: 0.9561, F1 Micro: 0.9726, F1 Macro: 0.9712\n",
      "Epoch 9/10, Train Loss: 0.0772, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0664, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9764\n",
      "\n",
      "Aspect detection accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      0.99      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.97      0.98      0.97       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5753, Accuracy: 0.8566, F1 Micro: 0.8566, F1 Macro: 0.839\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3164, Accuracy: 0.8924, F1 Micro: 0.8924, F1 Macro: 0.8844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2014, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9296\n",
      "Epoch 4/10, Train Loss: 0.1693, Accuracy: 0.9243, F1 Micro: 0.9243, F1 Macro: 0.912\n",
      "Epoch 5/10, Train Loss: 0.1565, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9223\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1301, Accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9381\n",
      "Epoch 7/10, Train Loss: 0.1068, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9218\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1291, Accuracy: 0.9482, F1 Micro: 0.9482, F1 Macro: 0.9409\n",
      "Epoch 9/10, Train Loss: 0.0676, Accuracy: 0.9243, F1 Micro: 0.9243, F1 Macro: 0.9131\n",
      "Epoch 10/10, Train Loss: 0.0581, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.9217\n",
      "\n",
      "Sentiment analysis accuracy: 0.9482, F1 Micro: 0.9482, F1 Macro: 0.9409\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.91      0.92        82\n",
      "    positive       0.96      0.96      0.96       169\n",
      "\n",
      "    accuracy                           0.95       251\n",
      "   macro avg       0.94      0.94      0.94       251\n",
      "weighted avg       0.95      0.95      0.95       251\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9106\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.94      0.99      0.97       167\n",
      "    positive       0.92      0.70      0.79        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.83      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.85      0.79      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.87      0.83      0.85       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87        23\n",
      "     neutral       0.97      0.98      0.97       152\n",
      "    positive       0.90      0.85      0.88        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.90      0.91       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.89      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 116.37941980361938 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 33\n",
      "Sampling duration: 9.005243301391602 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.538, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4815, Accuracy: 0.8296, F1 Micro: 0.9024, F1 Macro: 0.9015\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.37, Accuracy: 0.8943, F1 Micro: 0.9367, F1 Macro: 0.9361\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2692, Accuracy: 0.9516, F1 Micro: 0.9701, F1 Macro: 0.9692\n",
      "Epoch 5/10, Train Loss: 0.1841, Accuracy: 0.9516, F1 Micro: 0.9701, F1 Macro: 0.9688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1382, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1084, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9744\n",
      "Epoch 8/10, Train Loss: 0.0901, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9732\n",
      "Epoch 9/10, Train Loss: 0.0733, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9731\n",
      "Epoch 10/10, Train Loss: 0.0584, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9729\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9744\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.96      0.93       158\n",
      "        part       0.93      0.99      0.96       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.97      1061\n",
      "weighted avg       0.96      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5768, Accuracy: 0.8612, F1 Micro: 0.8612, F1 Macro: 0.8533\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3267, Accuracy: 0.9224, F1 Micro: 0.9224, F1 Macro: 0.9156\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1922, Accuracy: 0.9347, F1 Micro: 0.9347, F1 Macro: 0.9275\n",
      "Epoch 4/10, Train Loss: 0.1465, Accuracy: 0.9306, F1 Micro: 0.9306, F1 Macro: 0.9219\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1749, Accuracy: 0.9388, F1 Micro: 0.9388, F1 Macro: 0.9323\n",
      "Epoch 6/10, Train Loss: 0.1312, Accuracy: 0.9061, F1 Micro: 0.9061, F1 Macro: 0.8997\n",
      "Epoch 7/10, Train Loss: 0.1167, Accuracy: 0.9224, F1 Micro: 0.9224, F1 Macro: 0.9151\n",
      "Epoch 8/10, Train Loss: 0.0808, Accuracy: 0.9265, F1 Micro: 0.9265, F1 Macro: 0.918\n",
      "Epoch 9/10, Train Loss: 0.059, Accuracy: 0.9184, F1 Micro: 0.9184, F1 Macro: 0.9118\n",
      "Epoch 10/10, Train Loss: 0.0421, Accuracy: 0.9184, F1 Micro: 0.9184, F1 Macro: 0.9109\n",
      "\n",
      "Sentiment analysis accuracy: 0.9388, F1 Micro: 0.9388, F1 Macro: 0.9323\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.94      0.91        82\n",
      "    positive       0.97      0.94      0.95       163\n",
      "\n",
      "    accuracy                           0.94       245\n",
      "   macro avg       0.93      0.94      0.93       245\n",
      "weighted avg       0.94      0.94      0.94       245\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.9064\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.88      0.70      0.78        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.85      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.87      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.85      0.82      0.83       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        23\n",
      "     neutral       0.93      0.99      0.96       152\n",
      "    positive       0.90      0.68      0.78        41\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.89      0.83      0.86       216\n",
      "weighted avg       0.92      0.92      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 111.26395559310913 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 30\n",
      "Sampling duration: 8.134328842163086 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5359, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4679, Accuracy: 0.8333, F1 Micro: 0.9041, F1 Macro: 0.9033\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3546, Accuracy: 0.9241, F1 Micro: 0.9536, F1 Macro: 0.952\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2536, Accuracy: 0.9554, F1 Micro: 0.9722, F1 Macro: 0.971\n",
      "Epoch 5/10, Train Loss: 0.1757, Accuracy: 0.9546, F1 Micro: 0.9717, F1 Macro: 0.97\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1317, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1025, Accuracy: 0.9628, F1 Micro: 0.9768, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0826, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9759\n",
      "Epoch 9/10, Train Loss: 0.0693, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0579, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9778\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5661, Accuracy: 0.8281, F1 Micro: 0.8281, F1 Macro: 0.7874\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2977, Accuracy: 0.9258, F1 Micro: 0.9258, F1 Macro: 0.918\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2107, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.927\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1995, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9315\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1217, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9345\n",
      "Epoch 6/10, Train Loss: 0.1168, Accuracy: 0.9258, F1 Micro: 0.9258, F1 Macro: 0.915\n",
      "Epoch 7/10, Train Loss: 0.0873, Accuracy: 0.9219, F1 Micro: 0.9219, F1 Macro: 0.9139\n",
      "Epoch 8/10, Train Loss: 0.0605, Accuracy: 0.9258, F1 Micro: 0.9258, F1 Macro: 0.918\n",
      "Epoch 9/10, Train Loss: 0.0471, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9304\n",
      "Epoch 10/10, Train Loss: 0.0745, Accuracy: 0.9297, F1 Micro: 0.9297, F1 Macro: 0.9216\n",
      "\n",
      "Sentiment analysis accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9345\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.94      0.91        84\n",
      "    positive       0.97      0.94      0.96       172\n",
      "\n",
      "    accuracy                           0.94       256\n",
      "   macro avg       0.93      0.94      0.93       256\n",
      "weighted avg       0.94      0.94      0.94       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.9161\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.94      0.99      0.97       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.84      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.75      0.72        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.87      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.83      0.82      0.82       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.92      0.83      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.92      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 119.57166028022766 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 27\n",
      "Sampling duration: 7.416368007659912 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5268, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4566, Accuracy: 0.8311, F1 Micro: 0.9029, F1 Macro: 0.902\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3426, Accuracy: 0.9174, F1 Micro: 0.9487, F1 Macro: 0.9457\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.231, Accuracy: 0.9531, F1 Micro: 0.971, F1 Macro: 0.9698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1616, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1163, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9741\n",
      "Epoch 7/10, Train Loss: 0.0931, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0783, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9754\n",
      "Epoch 9/10, Train Loss: 0.0624, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0587, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.976\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.91      0.97      0.94       158\n",
      "        part       0.97      0.97      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5246, Accuracy: 0.8819, F1 Micro: 0.8819, F1 Macro: 0.8716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2325, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9144\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2044, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9297\n",
      "Epoch 4/10, Train Loss: 0.1745, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9204\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1436, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9301\n",
      "Epoch 6/10, Train Loss: 0.1101, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9222\n",
      "Epoch 7/10, Train Loss: 0.0794, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9222\n",
      "Epoch 8/10, Train Loss: 0.0793, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9222\n",
      "Epoch 9/10, Train Loss: 0.078, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.9016\n",
      "Epoch 10/10, Train Loss: 0.0426, Accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.909\n",
      "\n",
      "Sentiment analysis accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9301\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.95      0.91        83\n",
      "    positive       0.98      0.93      0.95       171\n",
      "\n",
      "    accuracy                           0.94       254\n",
      "   macro avg       0.92      0.94      0.93       254\n",
      "weighted avg       0.94      0.94      0.94       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9111\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.83      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.75      0.72        12\n",
      "     neutral       0.91      0.97      0.94       152\n",
      "    positive       0.93      0.71      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.84      0.81      0.82       216\n",
      "weighted avg       0.90      0.90      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       0.89      0.83      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.92      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 119.29059886932373 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 18\n",
      "Sampling duration: 6.748985767364502 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5264, Accuracy: 0.7924, F1 Micro: 0.8837, F1 Macro: 0.8822\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.462, Accuracy: 0.8378, F1 Micro: 0.9058, F1 Macro: 0.9045\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3339, Accuracy: 0.9397, F1 Micro: 0.9626, F1 Macro: 0.9608\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2209, Accuracy: 0.9531, F1 Micro: 0.971, F1 Macro: 0.9697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1564, Accuracy: 0.9576, F1 Micro: 0.9736, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1171, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0927, Accuracy: 0.9643, F1 Micro: 0.9777, F1 Macro: 0.9767\n",
      "Epoch 8/10, Train Loss: 0.0754, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0623, Accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9775\n",
      "Epoch 10/10, Train Loss: 0.0521, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9775\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.97      0.94       158\n",
      "        part       0.97      0.98      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5359, Accuracy: 0.8805, F1 Micro: 0.8805, F1 Macro: 0.8713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2639, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.922\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2164, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9254\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1868, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9237\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1697, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.928\n",
      "Epoch 6/10, Train Loss: 0.1216, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9223\n",
      "Epoch 7/10, Train Loss: 0.119, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.9185\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0858, Accuracy: 0.9402, F1 Micro: 0.9402, F1 Macro: 0.9342\n",
      "Epoch 9/10, Train Loss: 0.0734, Accuracy: 0.9203, F1 Micro: 0.9203, F1 Macro: 0.9125\n",
      "Epoch 10/10, Train Loss: 0.0449, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.9217\n",
      "\n",
      "Sentiment analysis accuracy: 0.9402, F1 Micro: 0.9402, F1 Macro: 0.9342\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.96      0.91        83\n",
      "    positive       0.98      0.93      0.95       168\n",
      "\n",
      "    accuracy                           0.94       251\n",
      "   macro avg       0.93      0.95      0.93       251\n",
      "weighted avg       0.94      0.94      0.94       251\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9125\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.94      0.99      0.97       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.84      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.92      0.97      0.95       152\n",
      "    positive       0.91      0.77      0.83        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.87      0.86      0.86       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.97      0.98      0.97       152\n",
      "    positive       0.94      0.78      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.92      0.91       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.85      0.81        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.93      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 128.11386585235596 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 6.374443292617798 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5267, Accuracy: 0.7961, F1 Micro: 0.8856, F1 Macro: 0.8842\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4568, Accuracy: 0.8504, F1 Micro: 0.9116, F1 Macro: 0.91\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3195, Accuracy: 0.9442, F1 Micro: 0.9654, F1 Macro: 0.9637\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2136, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1502, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1129, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9752\n",
      "Epoch 7/10, Train Loss: 0.0904, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.07, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0611, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "Epoch 10/10, Train Loss: 0.0498, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9763\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.96      0.98      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5232, Accuracy: 0.8633, F1 Micro: 0.8633, F1 Macro: 0.8551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2974, Accuracy: 0.9219, F1 Micro: 0.9219, F1 Macro: 0.9129\n",
      "Epoch 3/10, Train Loss: 0.1697, Accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.8991\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1418, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9304\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1404, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9311\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0707, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9307\n",
      "Epoch 7/10, Train Loss: 0.0876, Accuracy: 0.9258, F1 Micro: 0.9258, F1 Macro: 0.9184\n",
      "Epoch 8/10, Train Loss: 0.0479, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.927\n",
      "Epoch 9/10, Train Loss: 0.0534, Accuracy: 0.9258, F1 Micro: 0.9258, F1 Macro: 0.918\n",
      "Epoch 10/10, Train Loss: 0.0816, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9266\n",
      "\n",
      "Sentiment analysis accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9307\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.95      0.91        84\n",
      "    positive       0.98      0.93      0.95       172\n",
      "\n",
      "    accuracy                           0.94       256\n",
      "   macro avg       0.92      0.94      0.93       256\n",
      "weighted avg       0.94      0.94      0.94       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9171\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.87      0.75      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.83      0.85      0.84       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.91      0.86        23\n",
      "     neutral       0.96      0.98      0.97       152\n",
      "    positive       0.91      0.78      0.84        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.95      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 127.78140473365784 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.894716501235962 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.536, Accuracy: 0.8006, F1 Micro: 0.8877, F1 Macro: 0.8862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4399, Accuracy: 0.8631, F1 Micro: 0.9197, F1 Macro: 0.9194\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3232, Accuracy: 0.9375, F1 Micro: 0.9613, F1 Macro: 0.9601\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2226, Accuracy: 0.9539, F1 Micro: 0.9714, F1 Macro: 0.97\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1606, Accuracy: 0.9606, F1 Micro: 0.9754, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1148, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "Epoch 7/10, Train Loss: 0.0893, Accuracy: 0.9643, F1 Micro: 0.9777, F1 Macro: 0.9765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0747, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "Epoch 9/10, Train Loss: 0.0609, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9766\n",
      "Epoch 10/10, Train Loss: 0.0552, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9745\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.96      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5859, Accuracy: 0.8549, F1 Micro: 0.8549, F1 Macro: 0.826\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3257, Accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.9105\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1852, Accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.9109\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.156, Accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.9101\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1538, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9112\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1136, Accuracy: 0.9255, F1 Micro: 0.9255, F1 Macro: 0.9186\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1012, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9227\n",
      "Epoch 8/10, Train Loss: 0.0658, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9137\n",
      "Epoch 9/10, Train Loss: 0.0471, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9141\n",
      "Epoch 10/10, Train Loss: 0.0427, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9128\n",
      "\n",
      "Sentiment analysis accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9227\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.96      0.90        84\n",
      "    positive       0.98      0.91      0.95       171\n",
      "\n",
      "    accuracy                           0.93       255\n",
      "   macro avg       0.91      0.94      0.92       255\n",
      "weighted avg       0.94      0.93      0.93       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9052\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.91      0.88      0.89        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.75      0.72        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.87      0.75      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.83      0.82      0.82       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 131.64329409599304 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.1188859939575195 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5286, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4563, Accuracy: 0.8609, F1 Micro: 0.9177, F1 Macro: 0.9173\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3133, Accuracy: 0.9494, F1 Micro: 0.9687, F1 Macro: 0.9675\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2063, Accuracy: 0.9524, F1 Micro: 0.9703, F1 Macro: 0.9687\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1539, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1126, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0867, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.072, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9771\n",
      "Epoch 9/10, Train Loss: 0.0573, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0537, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9775\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9775\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.95      0.93      0.94       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5354, Accuracy: 0.9, F1 Micro: 0.9, F1 Macro: 0.8878\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.293, Accuracy: 0.9185, F1 Micro: 0.9185, F1 Macro: 0.9043\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1965, Accuracy: 0.9259, F1 Micro: 0.9259, F1 Macro: 0.9176\n",
      "Epoch 4/10, Train Loss: 0.1428, Accuracy: 0.9222, F1 Micro: 0.9222, F1 Macro: 0.9127\n",
      "Epoch 5/10, Train Loss: 0.1393, Accuracy: 0.9111, F1 Micro: 0.9111, F1 Macro: 0.9016\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0999, Accuracy: 0.9296, F1 Micro: 0.9296, F1 Macro: 0.9197\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0589, Accuracy: 0.9296, F1 Micro: 0.9296, F1 Macro: 0.9211\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0588, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9263\n",
      "Epoch 9/10, Train Loss: 0.0485, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9246\n",
      "Epoch 10/10, Train Loss: 0.0324, Accuracy: 0.9222, F1 Micro: 0.9222, F1 Macro: 0.9132\n",
      "\n",
      "Sentiment analysis accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9263\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.89      0.90        84\n",
      "    positive       0.95      0.96      0.95       186\n",
      "\n",
      "    accuracy                           0.94       270\n",
      "   macro avg       0.93      0.92      0.93       270\n",
      "weighted avg       0.94      0.94      0.94       270\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.9116\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.69      0.79        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.82      0.85       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.95      0.93      0.94       152\n",
      "    positive       0.82      0.90      0.86        52\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.90      0.89      0.89       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.92      0.88      0.90        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.94      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.88      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 137.7976233959198 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.462164878845215 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5307, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4347, Accuracy: 0.875, F1 Micro: 0.9258, F1 Macro: 0.9253\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2926, Accuracy: 0.9494, F1 Micro: 0.9685, F1 Macro: 0.9668\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1837, Accuracy: 0.9583, F1 Micro: 0.974, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1384, Accuracy: 0.9621, F1 Micro: 0.9763, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1035, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9765\n",
      "Epoch 7/10, Train Loss: 0.0885, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9762\n",
      "Epoch 8/10, Train Loss: 0.0643, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0569, Accuracy: 0.968, F1 Micro: 0.98, F1 Macro: 0.9791\n",
      "Epoch 10/10, Train Loss: 0.0483, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9727\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.98, F1 Macro: 0.9791\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.91      0.98      0.95       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5251, Accuracy: 0.8968, F1 Micro: 0.8968, F1 Macro: 0.8871\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2768, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9343\n",
      "Epoch 3/10, Train Loss: 0.1492, Accuracy: 0.9206, F1 Micro: 0.9206, F1 Macro: 0.9144\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1527, Accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9428\n",
      "Epoch 5/10, Train Loss: 0.1252, Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9389\n",
      "Epoch 6/10, Train Loss: 0.1018, Accuracy: 0.9365, F1 Micro: 0.9365, F1 Macro: 0.9298\n",
      "Epoch 7/10, Train Loss: 0.0775, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.926\n",
      "Epoch 8/10, Train Loss: 0.0749, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8878\n",
      "Epoch 9/10, Train Loss: 0.0585, Accuracy: 0.9206, F1 Micro: 0.9206, F1 Macro: 0.9084\n",
      "Epoch 10/10, Train Loss: 0.0573, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.9054\n",
      "\n",
      "Sentiment analysis accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9428\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.96      0.92        83\n",
      "    positive       0.98      0.94      0.96       169\n",
      "\n",
      "    accuracy                           0.95       252\n",
      "   macro avg       0.94      0.95      0.94       252\n",
      "weighted avg       0.95      0.95      0.95       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9222\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.84      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.91      0.98      0.95       152\n",
      "    positive       0.93      0.73      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.86      0.82      0.84       216\n",
      "weighted avg       0.91      0.91      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.95      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 131.55724143981934 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 8\n",
      "Sampling duration: 3.821929931640625 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5312, Accuracy: 0.7969, F1 Micro: 0.886, F1 Macro: 0.8846\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4337, Accuracy: 0.8698, F1 Micro: 0.9225, F1 Macro: 0.922\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2942, Accuracy: 0.9375, F1 Micro: 0.9609, F1 Macro: 0.9575\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.196, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1461, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9749\n",
      "Epoch 6/10, Train Loss: 0.1032, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0806, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.978\n",
      "Epoch 8/10, Train Loss: 0.0684, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9778\n",
      "Epoch 9/10, Train Loss: 0.0585, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9773\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0494, Accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9784\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9784\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.97      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5252, Accuracy: 0.8893, F1 Micro: 0.8893, F1 Macro: 0.8815\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2776, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9253\n",
      "Epoch 3/10, Train Loss: 0.2157, Accuracy: 0.9289, F1 Micro: 0.9289, F1 Macro: 0.9228\n",
      "Epoch 4/10, Train Loss: 0.153, Accuracy: 0.917, F1 Micro: 0.917, F1 Macro: 0.9105\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1394, Accuracy: 0.9486, F1 Micro: 0.9486, F1 Macro: 0.9426\n",
      "Epoch 6/10, Train Loss: 0.1029, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9348\n",
      "Epoch 7/10, Train Loss: 0.0766, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9348\n",
      "Epoch 8/10, Train Loss: 0.075, Accuracy: 0.9447, F1 Micro: 0.9447, F1 Macro: 0.9387\n",
      "Epoch 9/10, Train Loss: 0.053, Accuracy: 0.917, F1 Micro: 0.917, F1 Macro: 0.9067\n",
      "Epoch 10/10, Train Loss: 0.051, Accuracy: 0.9368, F1 Micro: 0.9368, F1 Macro: 0.931\n",
      "\n",
      "Sentiment analysis accuracy: 0.9486, F1 Micro: 0.9486, F1 Macro: 0.9426\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.94      0.92        84\n",
      "    positive       0.97      0.95      0.96       169\n",
      "\n",
      "    accuracy                           0.95       253\n",
      "   macro avg       0.94      0.95      0.94       253\n",
      "weighted avg       0.95      0.95      0.95       253\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9225\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.84      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.92      0.97      0.95       152\n",
      "    positive       0.89      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.88      0.86      0.87       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.92      0.93       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 132.04622745513916 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.680593252182007 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5281, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4216, Accuracy: 0.8862, F1 Micro: 0.932, F1 Macro: 0.9312\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2742, Accuracy: 0.9472, F1 Micro: 0.9671, F1 Macro: 0.9655\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1771, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1273, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9771\n",
      "Epoch 6/10, Train Loss: 0.0994, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0746, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9789\n",
      "Epoch 8/10, Train Loss: 0.0634, Accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9785\n",
      "Epoch 9/10, Train Loss: 0.0524, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9764\n",
      "Epoch 10/10, Train Loss: 0.0458, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9782\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.91      0.96      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5085, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.9049\n",
      "Epoch 2/10, Train Loss: 0.2242, Accuracy: 0.9055, F1 Micro: 0.9055, F1 Macro: 0.8987\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1723, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9289\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1433, Accuracy: 0.9488, F1 Micro: 0.9488, F1 Macro: 0.9433\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.125, Accuracy: 0.9488, F1 Micro: 0.9488, F1 Macro: 0.9436\n",
      "Epoch 6/10, Train Loss: 0.0998, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9312\n",
      "Epoch 7/10, Train Loss: 0.0724, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9308\n",
      "Epoch 8/10, Train Loss: 0.0494, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.914\n",
      "Epoch 9/10, Train Loss: 0.0495, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9385\n",
      "Epoch 10/10, Train Loss: 0.0408, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.919\n",
      "\n",
      "Sentiment analysis accuracy: 0.9488, F1 Micro: 0.9488, F1 Macro: 0.9436\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.98      0.93        84\n",
      "    positive       0.99      0.94      0.96       170\n",
      "\n",
      "    accuracy                           0.95       254\n",
      "   macro avg       0.93      0.96      0.94       254\n",
      "weighted avg       0.95      0.95      0.95       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9217\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.84      0.87       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.91      0.96      0.94       152\n",
      "    positive       0.87      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.89      0.83      0.86       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 134.95456409454346 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.056851863861084 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5316, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4149, Accuracy: 0.8936, F1 Micro: 0.9358, F1 Macro: 0.9346\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2534, Accuracy: 0.9531, F1 Micro: 0.9708, F1 Macro: 0.9696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1706, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1208, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9768\n",
      "Epoch 6/10, Train Loss: 0.0909, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.973\n",
      "Epoch 7/10, Train Loss: 0.0775, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.064, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9775\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0536, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9778\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0451, Accuracy: 0.9732, F1 Micro: 0.9832, F1 Macro: 0.9824\n",
      "\n",
      "Aspect detection accuracy: 0.9732, F1 Micro: 0.9832, F1 Macro: 0.9824\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.99      0.96       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4899, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9193\n",
      "Epoch 2/10, Train Loss: 0.2342, Accuracy: 0.8842, F1 Micro: 0.8842, F1 Macro: 0.8769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.145, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9295\n",
      "Epoch 4/10, Train Loss: 0.1135, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.9082\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1262, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9312\n",
      "Epoch 6/10, Train Loss: 0.0764, Accuracy: 0.9189, F1 Micro: 0.9189, F1 Macro: 0.9113\n",
      "Epoch 7/10, Train Loss: 0.0786, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9161\n",
      "Epoch 8/10, Train Loss: 0.0696, Accuracy: 0.8996, F1 Micro: 0.8996, F1 Macro: 0.8899\n",
      "Epoch 9/10, Train Loss: 0.0472, Accuracy: 0.9189, F1 Micro: 0.9189, F1 Macro: 0.9099\n",
      "Epoch 10/10, Train Loss: 0.0529, Accuracy: 0.8996, F1 Micro: 0.8996, F1 Macro: 0.8924\n",
      "\n",
      "Sentiment analysis accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9312\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.94      0.91        85\n",
      "    positive       0.97      0.94      0.95       174\n",
      "\n",
      "    accuracy                           0.94       259\n",
      "   macro avg       0.92      0.94      0.93       259\n",
      "weighted avg       0.94      0.94      0.94       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.963, F1 Micro: 0.963, F1 Macro: 0.9214\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.88      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.93      0.99      0.96       152\n",
      "    positive       0.95      0.79      0.86        52\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.84      0.86       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.92      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 140.19131731987 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.3819775581359863 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5302, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4103, Accuracy: 0.9129, F1 Micro: 0.9472, F1 Macro: 0.9461\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2533, Accuracy: 0.9509, F1 Micro: 0.9694, F1 Macro: 0.9678\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1697, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1152, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "Epoch 6/10, Train Loss: 0.0881, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0727, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9792\n",
      "Epoch 8/10, Train Loss: 0.0637, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9758\n",
      "Epoch 9/10, Train Loss: 0.0547, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9753\n",
      "Epoch 10/10, Train Loss: 0.0458, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9744\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9792\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.95      0.94      0.95       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4932, Accuracy: 0.8914, F1 Micro: 0.8914, F1 Macro: 0.8843\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2358, Accuracy: 0.9026, F1 Micro: 0.9026, F1 Macro: 0.8957\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.133, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.914\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1384, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9102\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.115, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9282\n",
      "Epoch 6/10, Train Loss: 0.1016, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.914\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0776, Accuracy: 0.9401, F1 Micro: 0.9401, F1 Macro: 0.9326\n",
      "Epoch 8/10, Train Loss: 0.0705, Accuracy: 0.9288, F1 Micro: 0.9288, F1 Macro: 0.9202\n",
      "Epoch 9/10, Train Loss: 0.0745, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.914\n",
      "Epoch 10/10, Train Loss: 0.0369, Accuracy: 0.9139, F1 Micro: 0.9139, F1 Macro: 0.9063\n",
      "\n",
      "Sentiment analysis accuracy: 0.9401, F1 Micro: 0.9401, F1 Macro: 0.9326\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.93      0.91        87\n",
      "    positive       0.97      0.94      0.96       180\n",
      "\n",
      "    accuracy                           0.94       267\n",
      "   macro avg       0.93      0.94      0.93       267\n",
      "weighted avg       0.94      0.94      0.94       267\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9169\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.92      0.88        12\n",
      "     neutral       0.95      0.94      0.95       152\n",
      "    positive       0.81      0.83      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.87      0.89      0.88       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.88      0.92        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.95      0.95       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.85      0.81        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 145.37227058410645 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.8161284923553467 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5299, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4119, Accuracy: 0.9137, F1 Micro: 0.9477, F1 Macro: 0.9467\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2628, Accuracy: 0.9494, F1 Micro: 0.9686, F1 Macro: 0.9669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1637, Accuracy: 0.9583, F1 Micro: 0.974, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1191, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.087, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9789\n",
      "Epoch 7/10, Train Loss: 0.0726, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.978\n",
      "Epoch 8/10, Train Loss: 0.0619, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9784\n",
      "Epoch 9/10, Train Loss: 0.0513, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9772\n",
      "Epoch 10/10, Train Loss: 0.0406, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9763\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.93      0.96      0.95       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4276, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9204\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2164, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9235\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1628, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9272\n",
      "Epoch 4/10, Train Loss: 0.127, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9231\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1227, Accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9384\n",
      "Epoch 6/10, Train Loss: 0.0976, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9305\n",
      "Epoch 7/10, Train Loss: 0.0855, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9209\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0756, Accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9388\n",
      "Epoch 9/10, Train Loss: 0.0674, Accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.911\n",
      "Epoch 10/10, Train Loss: 0.0608, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9177\n",
      "\n",
      "Sentiment analysis accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9388\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.93      0.92        84\n",
      "    positive       0.97      0.95      0.96       176\n",
      "\n",
      "    accuracy                           0.95       260\n",
      "   macro avg       0.94      0.94      0.94       260\n",
      "weighted avg       0.95      0.95      0.95       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9187\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.83      0.85       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.94      0.96      0.95       152\n",
      "    positive       0.86      0.81      0.83        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.87      0.84      0.85       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.88      0.92        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.95      0.95       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 142.27718925476074 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 8\n",
      "Sampling duration: 1.0492117404937744 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5221, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4057, Accuracy: 0.9137, F1 Micro: 0.9478, F1 Macro: 0.9466\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2424, Accuracy: 0.9501, F1 Micro: 0.969, F1 Macro: 0.9672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1596, Accuracy: 0.9628, F1 Micro: 0.9768, F1 Macro: 0.9758\n",
      "Epoch 5/10, Train Loss: 0.1205, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9745\n",
      "Epoch 6/10, Train Loss: 0.0929, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0731, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0583, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9784\n",
      "Epoch 9/10, Train Loss: 0.0497, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0414, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9786\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9786\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.94      0.94      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5107, Accuracy: 0.906, F1 Micro: 0.906, F1 Macro: 0.8964\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2443, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9191\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1719, Accuracy: 0.9436, F1 Micro: 0.9436, F1 Macro: 0.9372\n",
      "Epoch 4/10, Train Loss: 0.1475, Accuracy: 0.9361, F1 Micro: 0.9361, F1 Macro: 0.9288\n",
      "Epoch 5/10, Train Loss: 0.098, Accuracy: 0.9211, F1 Micro: 0.9211, F1 Macro: 0.913\n",
      "Epoch 6/10, Train Loss: 0.1156, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9204\n",
      "Epoch 7/10, Train Loss: 0.0905, Accuracy: 0.9211, F1 Micro: 0.9211, F1 Macro: 0.913\n",
      "Epoch 8/10, Train Loss: 0.0557, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.924\n",
      "Epoch 9/10, Train Loss: 0.0649, Accuracy: 0.9211, F1 Micro: 0.9211, F1 Macro: 0.9101\n",
      "Epoch 10/10, Train Loss: 0.0742, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9313\n",
      "\n",
      "Sentiment analysis accuracy: 0.9436, F1 Micro: 0.9436, F1 Macro: 0.9372\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.98      0.92        85\n",
      "    positive       0.99      0.93      0.96       181\n",
      "\n",
      "    accuracy                           0.94       266\n",
      "   macro avg       0.93      0.95      0.94       266\n",
      "weighted avg       0.95      0.94      0.94       266\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9233\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.84      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.94      0.94      0.94       152\n",
      "    positive       0.82      0.81      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.84      0.86      0.85       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.94      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 143.0157208442688 s\n",
      "Total runtime: 3217.5012328624725 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[4], 4)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6175447,
     "sourceId": 10843157,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5800.949196,
   "end_time": "2025-03-25T16:11:19.679030",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-25T14:34:38.729834",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "03209b0a1e014cf3b7be2213c84bb397": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "09ecdab319e24e4d824b09beb4e08dcf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0eec3c29ef0e4cf5b6b75d07c3bdfb5e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_32b9d7478538428191f4c4512c57f11b",
       "placeholder": "",
       "style": "IPY_MODEL_b0da847cc29f42c19ac7d229599476fe",
       "tabbable": null,
       "tooltip": null,
       "value": "2.00/2.00[00:00&lt;00:00,157B/s]"
      }
     },
     "1047a97d0c834ea2b9e35a2f29d16807": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "114843b370764b3ea3f48f8b96655b91": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1afc57319ab145d88dd17fca29d80bce": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_fc000cc11b3844f9a9a7e0216f9b46ed",
       "placeholder": "",
       "style": "IPY_MODEL_c8ed0a5279e24530874211c52b83883e",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json:100%"
      }
     },
     "1ce1573f6fea4ca980bd74cfc4661b03": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "20c4303a42e74c3ea68b31217417fd6b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_827260f5c202420692c5a57c1c3fb13b",
       "max": 112,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_6c92e25dc01744f096501fd0407044c6",
       "tabbable": null,
       "tooltip": null,
       "value": 112
      }
     },
     "22d25a0de9f84e0c9e9fb52ba4c88d62": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2a712c8d7ab740d4a4b582bfbeb2f6e6",
       "placeholder": "",
       "style": "IPY_MODEL_3a67c231cce14a86b5ddf12727dab57f",
       "tabbable": null,
       "tooltip": null,
       "value": "112/112[00:00&lt;00:00,10.5kB/s]"
      }
     },
     "2a3dd52d3b31442a8eb97dc58ebec638": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1afc57319ab145d88dd17fca29d80bce",
        "IPY_MODEL_9f9cf8a0f87e497a93e1dbbae7ade382",
        "IPY_MODEL_4579517ea2fb4217ae33e67354cc0eda"
       ],
       "layout": "IPY_MODEL_d10a6fbb182348e58a59a86b78fc6795",
       "tabbable": null,
       "tooltip": null
      }
     },
     "2a712c8d7ab740d4a4b582bfbeb2f6e6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2d52d9e9501e4a09842046f058bd59df": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "30369523d139433cbdd65d4f90ac224f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "32b9d7478538428191f4c4512c57f11b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "33ff0cd2f94a40baa6a1ccfe906db943": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e5bbbb4ef96b45b5ae6fa4de946317e2",
       "max": 2,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_30369523d139433cbdd65d4f90ac224f",
       "tabbable": null,
       "tooltip": null,
       "value": 2
      }
     },
     "3a67c231cce14a86b5ddf12727dab57f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "419207392eaf4646a6eec8fd315c32b4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "42a199f266684fee837586497cd72f51": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4579517ea2fb4217ae33e67354cc0eda": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_03209b0a1e014cf3b7be2213c84bb397",
       "placeholder": "",
       "style": "IPY_MODEL_92739a46509a4605bff847f0824ef52a",
       "tabbable": null,
       "tooltip": null,
       "value": "1.53k/1.53k[00:00&lt;00:00,138kB/s]"
      }
     },
     "4d6e32ef9e6147d7ba878360e7ad711b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ea14be8ab76d4d84b49dbc74fe4b40ac",
        "IPY_MODEL_20c4303a42e74c3ea68b31217417fd6b",
        "IPY_MODEL_22d25a0de9f84e0c9e9fb52ba4c88d62"
       ],
       "layout": "IPY_MODEL_88eb63d930c4492a9c1343de9bed812a",
       "tabbable": null,
       "tooltip": null
      }
     },
     "50f6f9385e3744199ef410d10588c4cd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "65dd21bbdc9442ec9af3481344fdf12f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_09ecdab319e24e4d824b09beb4e08dcf",
       "max": 229167,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1047a97d0c834ea2b9e35a2f29d16807",
       "tabbable": null,
       "tooltip": null,
       "value": 229167
      }
     },
     "67ffa5cd1d704e82a16f5a1db4b8e58f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6c92e25dc01744f096501fd0407044c6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7aed8755e7c04da49b9c8913b4b1a6d6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_def54f6d32b24fd584bf7f24190bbfaf",
        "IPY_MODEL_33ff0cd2f94a40baa6a1ccfe906db943",
        "IPY_MODEL_0eec3c29ef0e4cf5b6b75d07c3bdfb5e"
       ],
       "layout": "IPY_MODEL_ccb5bc4b6f3a456a82479a56f99f3cfe",
       "tabbable": null,
       "tooltip": null
      }
     },
     "7af534c6515d46cdacc6f40e28bde7fe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9519390d86bd4a19953f8d32b2bed296",
       "placeholder": "",
       "style": "IPY_MODEL_67ffa5cd1d704e82a16f5a1db4b8e58f",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.txt:100%"
      }
     },
     "827260f5c202420692c5a57c1c3fb13b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "85451d2b60034b988eb7d9f8353a6acb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "88eb63d930c4492a9c1343de9bed812a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "92739a46509a4605bff847f0824ef52a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9519390d86bd4a19953f8d32b2bed296": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9e2162fb11344bf3ac599764446b9d8f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9ecbbbe44f08400b9b28e7e418238854",
       "placeholder": "",
       "style": "IPY_MODEL_114843b370764b3ea3f48f8b96655b91",
       "tabbable": null,
       "tooltip": null,
       "value": "229k/229k[00:00&lt;00:00,3.67MB/s]"
      }
     },
     "9ecbbbe44f08400b9b28e7e418238854": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9f9cf8a0f87e497a93e1dbbae7ade382": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_fbf2f09bcc9840f994f68b83ca171152",
       "max": 1534,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1ce1573f6fea4ca980bd74cfc4661b03",
       "tabbable": null,
       "tooltip": null,
       "value": 1534
      }
     },
     "b0da847cc29f42c19ac7d229599476fe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c8ed0a5279e24530874211c52b83883e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ccb5bc4b6f3a456a82479a56f99f3cfe": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d10a6fbb182348e58a59a86b78fc6795": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d60270ec545446c792b323202ba5128b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7af534c6515d46cdacc6f40e28bde7fe",
        "IPY_MODEL_65dd21bbdc9442ec9af3481344fdf12f",
        "IPY_MODEL_9e2162fb11344bf3ac599764446b9d8f"
       ],
       "layout": "IPY_MODEL_419207392eaf4646a6eec8fd315c32b4",
       "tabbable": null,
       "tooltip": null
      }
     },
     "def54f6d32b24fd584bf7f24190bbfaf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_42a199f266684fee837586497cd72f51",
       "placeholder": "",
       "style": "IPY_MODEL_2d52d9e9501e4a09842046f058bd59df",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json:100%"
      }
     },
     "e5bbbb4ef96b45b5ae6fa4de946317e2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ea14be8ab76d4d84b49dbc74fe4b40ac": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_85451d2b60034b988eb7d9f8353a6acb",
       "placeholder": "",
       "style": "IPY_MODEL_50f6f9385e3744199ef410d10588c4cd",
       "tabbable": null,
       "tooltip": null,
       "value": "special_tokens_map.json:100%"
      }
     },
     "fbf2f09bcc9840f994f68b83ca171152": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fc000cc11b3844f9a9a7e0216f9b46ed": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
