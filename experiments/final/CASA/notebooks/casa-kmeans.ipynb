{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f33991f",
   "metadata": {
    "papermill": {
     "duration": 0.012436,
     "end_time": "2025-03-02T16:53:41.535800",
     "exception": false,
     "start_time": "2025-03-02T16:53:41.523364",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5be8bcc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T16:53:41.559156Z",
     "iopub.status.busy": "2025-03-02T16:53:41.558824Z",
     "iopub.status.idle": "2025-03-02T16:54:17.856143Z",
     "shell.execute_reply": "2025-03-02T16:54:17.855170Z"
    },
    "papermill": {
     "duration": 36.311015,
     "end_time": "2025-03-02T16:54:17.858033",
     "exception": false,
     "start_time": "2025-03-02T16:53:41.547018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score, classification_report\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "from torch.multiprocessing import Manager\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel, BertPreTrainedModel, BertConfig, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3e3ba0",
   "metadata": {
    "papermill": {
     "duration": 0.012076,
     "end_time": "2025-03-02T16:54:17.882786",
     "exception": false,
     "start_time": "2025-03-02T16:54:17.870710",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f000dec5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T16:54:17.909615Z",
     "iopub.status.busy": "2025-03-02T16:54:17.908877Z",
     "iopub.status.idle": "2025-03-02T16:54:17.913188Z",
     "shell.execute_reply": "2025-03-02T16:54:17.912356Z"
    },
    "papermill": {
     "duration": 0.01914,
     "end_time": "2025-03-02T16:54:17.914605",
     "exception": false,
     "start_time": "2025-03-02T16:54:17.895465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf7e6643",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T16:54:17.941426Z",
     "iopub.status.busy": "2025-03-02T16:54:17.941093Z",
     "iopub.status.idle": "2025-03-02T16:54:17.945398Z",
     "shell.execute_reply": "2025-03-02T16:54:17.944619Z"
    },
    "papermill": {
     "duration": 0.019297,
     "end_time": "2025-03-02T16:54:17.947028",
     "exception": false,
     "start_time": "2025-03-02T16:54:17.927731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists('/kaggle/working/results') == False:\n",
    "    os.mkdir('/kaggle/working/results')\n",
    "\n",
    "if os.path.exists('/kaggle/working/acquired_data') == False:\n",
    "    os.mkdir('/kaggle/working/acquired_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8afadf79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T16:54:17.974209Z",
     "iopub.status.busy": "2025-03-02T16:54:17.973831Z",
     "iopub.status.idle": "2025-03-02T16:54:17.988729Z",
     "shell.execute_reply": "2025-03-02T16:54:17.987999Z"
    },
    "papermill": {
     "duration": 0.029906,
     "end_time": "2025-03-02T16:54:17.990354",
     "exception": false,
     "start_time": "2025-03-02T16:54:17.960448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "    torch.backends.cudnn.benchmark=False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a1ac8f",
   "metadata": {
    "papermill": {
     "duration": 0.012122,
     "end_time": "2025-03-02T16:54:18.014900",
     "exception": false,
     "start_time": "2025-03-02T16:54:18.002778",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# GLOBAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19832cb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T16:54:18.040622Z",
     "iopub.status.busy": "2025-03-02T16:54:18.040300Z",
     "iopub.status.idle": "2025-03-02T16:54:18.112622Z",
     "shell.execute_reply": "2025-03-02T16:54:18.111066Z"
    },
    "papermill": {
     "duration": 0.087372,
     "end_time": "2025-03-02T16:54:18.114471",
     "exception": false,
     "start_time": "2025-03-02T16:54:18.027099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "\n",
    "# Shared resources\n",
    "aspect_accuracies = manager.list()\n",
    "aspect_f1_micros = manager.list()\n",
    "aspect_f1_macros = manager.list()\n",
    "sentiment_accuracies = manager.list()\n",
    "sentiment_f1_micros = manager.list()\n",
    "sentiment_f1_macros = manager.list()\n",
    "accuracies = manager.list()\n",
    "f1_micros = manager.list()\n",
    "f1_macros = manager.list()\n",
    "\n",
    "# Non shared resources\n",
    "filename = 'casa-kmeans'\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "sequence_length = 48\n",
    "\n",
    "aspect_list = ['fuel', 'machine', 'others', 'part', 'price', 'service']\n",
    "aspect_mapping = {'fuel': 0, 'machine': 1, 'others': 2, 'part': 3, 'price': 4, 'service': 5 }\n",
    "label_mapping = {\"negative\": 0, \"neutral\": 1, 'positive': 2}\n",
    "ignored_keys = ['labels', 'ori_text', 'ori_label', 'ori_indices', 'aspect']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43e1d38",
   "metadata": {
    "papermill": {
     "duration": 0.012019,
     "end_time": "2025-03-02T16:54:18.139345",
     "exception": false,
     "start_time": "2025-03-02T16:54:18.127326",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LOAD AND PREPROCESS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "672df8e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T16:54:18.165331Z",
     "iopub.status.busy": "2025-03-02T16:54:18.164948Z",
     "iopub.status.idle": "2025-03-02T16:54:18.267973Z",
     "shell.execute_reply": "2025-03-02T16:54:18.266811Z"
    },
    "papermill": {
     "duration": 0.11804,
     "end_time": "2025-03-02T16:54:18.269647",
     "exception": false,
     "start_time": "2025-03-02T16:54:18.151607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>fuel</th>\n",
       "      <th>machine</th>\n",
       "      <th>others</th>\n",
       "      <th>part</th>\n",
       "      <th>price</th>\n",
       "      <th>service</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saya memakai Honda Jazz GK5 tahun 2014 ( perta...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Avanza kenapa jadi boros bensin begini dah ah....</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saran ku dan pengalaman ku , mending beli mobi...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dari segi harga juga pajero lebih mahal 30 jut...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kalo menurut gw enak pajero si</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence      fuel   machine  \\\n",
       "0  Saya memakai Honda Jazz GK5 tahun 2014 ( perta...   neutral   neutral   \n",
       "1  Avanza kenapa jadi boros bensin begini dah ah....  negative   neutral   \n",
       "2  saran ku dan pengalaman ku , mending beli mobi...  positive  positive   \n",
       "3  Dari segi harga juga pajero lebih mahal 30 jut...   neutral   neutral   \n",
       "4                     Kalo menurut gw enak pajero si   neutral   neutral   \n",
       "\n",
       "     others     part     price  service  \n",
       "0  positive  neutral   neutral  neutral  \n",
       "1   neutral  neutral   neutral  neutral  \n",
       "2   neutral  neutral   neutral  neutral  \n",
       "3   neutral  neutral  positive  neutral  \n",
       "4  positive  neutral   neutral  neutral  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('/kaggle/input/casa-dataset/train_preprocess.csv', encoding='latin-1')\n",
    "val_data = pd.read_csv('/kaggle/input/casa-dataset/valid_preprocess.csv', encoding='latin-1')\n",
    "test_data = pd.read_csv('/kaggle/input/casa-dataset/test_preprocess.csv', encoding='latin-1')\n",
    "\n",
    "data = pd.concat([train_data, val_data, test_data], ignore_index=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e3a0c33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T16:54:18.297961Z",
     "iopub.status.busy": "2025-03-02T16:54:18.297611Z",
     "iopub.status.idle": "2025-03-02T16:54:18.309310Z",
     "shell.execute_reply": "2025-03-02T16:54:18.308459Z"
    },
    "papermill": {
     "duration": 0.027282,
     "end_time": "2025-03-02T16:54:18.310770",
     "exception": false,
     "start_time": "2025-03-02T16:54:18.283488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>fuel</th>\n",
       "      <th>machine</th>\n",
       "      <th>others</th>\n",
       "      <th>part</th>\n",
       "      <th>price</th>\n",
       "      <th>service</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saya memakai Honda Jazz GK5 tahun 2014 ( perta...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Avanza kenapa jadi boros bensin begini dah ah....</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saran ku dan pengalaman ku , mending beli mobi...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dari segi harga juga pajero lebih mahal 30 jut...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kalo menurut gw enak pajero si</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence      fuel   machine  \\\n",
       "0  Saya memakai Honda Jazz GK5 tahun 2014 ( perta...   neutral   neutral   \n",
       "1  Avanza kenapa jadi boros bensin begini dah ah....  negative   neutral   \n",
       "2  saran ku dan pengalaman ku , mending beli mobi...  positive  positive   \n",
       "3  Dari segi harga juga pajero lebih mahal 30 jut...   neutral   neutral   \n",
       "4                     Kalo menurut gw enak pajero si   neutral   neutral   \n",
       "\n",
       "     others     part     price  service  \n",
       "0  positive  neutral   neutral  neutral  \n",
       "1   neutral  neutral   neutral  neutral  \n",
       "2   neutral  neutral   neutral  neutral  \n",
       "3   neutral  neutral  positive  neutral  \n",
       "4  positive  neutral   neutral  neutral  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdbbe00d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T16:54:18.338330Z",
     "iopub.status.busy": "2025-03-02T16:54:18.338006Z",
     "iopub.status.idle": "2025-03-02T16:54:18.353174Z",
     "shell.execute_reply": "2025-03-02T16:54:18.352420Z"
    },
    "papermill": {
     "duration": 0.030772,
     "end_time": "2025-03-02T16:54:18.354794",
     "exception": false,
     "start_time": "2025-03-02T16:54:18.324022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ede461f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T16:54:18.382880Z",
     "iopub.status.busy": "2025-03-02T16:54:18.382563Z",
     "iopub.status.idle": "2025-03-02T16:54:18.398403Z",
     "shell.execute_reply": "2025-03-02T16:54:18.397540Z"
    },
    "papermill": {
     "duration": 0.032038,
     "end_time": "2025-03-02T16:54:18.399754",
     "exception": false,
     "start_time": "2025-03-02T16:54:18.367716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(864,) (864, 6)\n",
      "(216,) (216, 6)\n"
     ]
    }
   ],
   "source": [
    "train_labels = train_data.columns[1:]\n",
    "val_labels = val_data.columns[1:]\n",
    "\n",
    "# Extract features and labels for training and validation\n",
    "X_train = train_data['sentence'].values\n",
    "y_train = train_data[train_labels].values\n",
    "X_val = val_data['sentence'].values\n",
    "y_val = val_data[val_labels].values\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2492b68b",
   "metadata": {
    "papermill": {
     "duration": 0.012173,
     "end_time": "2025-03-02T16:54:18.424458",
     "exception": false,
     "start_time": "2025-03-02T16:54:18.412285",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BUILD DATASET & DATALOADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b320b01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T16:54:18.451309Z",
     "iopub.status.busy": "2025-03-02T16:54:18.450946Z",
     "iopub.status.idle": "2025-03-02T16:54:18.457696Z",
     "shell.execute_reply": "2025-03-02T16:54:18.456837Z"
    },
    "papermill": {
     "duration": 0.022215,
     "end_time": "2025-03-02T16:54:18.459281",
     "exception": false,
     "start_time": "2025-03-02T16:54:18.437066",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AspectDetectionDataset(Dataset):\n",
    "    def __init__(self, texts, labels, label_mapping, tokenizer, max_length=sequence_length, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.use_float = use_float\n",
    "        self.label_mapping = label_mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "        \n",
    "        original_labels = [self.label_mapping[label] for label in self.labels[idx]]\n",
    "        encoded_labels = [1 if label == 1 else 0 for label in original_labels]\n",
    "        \n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['ori_indices'] = idx\n",
    "        item['ori_text'] = self.texts[idx]\n",
    "        item['ori_label'] = torch.tensor(original_labels, dtype=torch.float)\n",
    "        item['labels'] = torch.tensor(encoded_labels, dtype=torch.float if self.use_float else torch.long)\n",
    "        \n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a60f25eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T16:54:18.487572Z",
     "iopub.status.busy": "2025-03-02T16:54:18.487211Z",
     "iopub.status.idle": "2025-03-02T16:54:18.495759Z",
     "shell.execute_reply": "2025-03-02T16:54:18.494834Z"
    },
    "papermill": {
     "duration": 0.024238,
     "end_time": "2025-03-02T16:54:18.497344",
     "exception": false,
     "start_time": "2025-03-02T16:54:18.473106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SentimentAnalysisDataset(Dataset):\n",
    "    def __init__(self, texts, labels, aspects, indices, label_mapping, tokenizer, max_length=96, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.aspects = aspects\n",
    "        self.indices = indices\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.use_float = use_float\n",
    "        self.label_mapping = label_mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = aspect_token + ' ' + self.aspects[idx] + ' ' + review_token + ' ' + self.texts[idx] \n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "\n",
    "        if isinstance(self.labels[idx], str):\n",
    "            self.labels[idx] = self.label_mapping[self.labels[idx]]\n",
    "        elif torch.is_tensor(self.labels[idx]):\n",
    "            self.labels[idx] = int(self.labels[idx].item())\n",
    "\n",
    "        encoded_label = 1 if self.labels[idx] == 2 else self.labels[idx]\n",
    "        one_hot_label = F.one_hot(torch.tensor(encoded_label, dtype=torch.long), num_classes=2).float()\n",
    "\n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['aspect'] = self.aspects[idx]\n",
    "        item['labels'] = one_hot_label\n",
    "        item['ori_indices'] = self.indices[idx]\n",
    "        item['ori_text'] = self.texts[idx]\n",
    "        item['ori_label'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f21b292f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T16:54:18.525058Z",
     "iopub.status.busy": "2025-03-02T16:54:18.524699Z",
     "iopub.status.idle": "2025-03-02T16:54:19.375377Z",
     "shell.execute_reply": "2025-03-02T16:54:19.374681Z"
    },
    "papermill": {
     "duration": 0.866466,
     "end_time": "2025-03-02T16:54:19.377402",
     "exception": false,
     "start_time": "2025-03-02T16:54:18.510936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "640b7331c3e342f196114513dc3f7ec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69594785e4084477816e4bd616ea2def",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/229k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4497660b777843b6a4604cb2776f7235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59d32dc36a7a401a8f1cbd8862178694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p1')\n",
    "review_token = '[REVIEW]'\n",
    "aspect_token = '[ASPECT]'\n",
    "special_tokens_dict = {'additional_special_tokens': [review_token, aspect_token]}\n",
    "num_added_tokens = tokenizer.add_special_tokens(special_tokens_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2a5d71e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T16:54:19.415026Z",
     "iopub.status.busy": "2025-03-02T16:54:19.414707Z",
     "iopub.status.idle": "2025-03-02T16:54:19.420457Z",
     "shell.execute_reply": "2025-03-02T16:54:19.419452Z"
    },
    "papermill": {
     "duration": 0.025649,
     "end_time": "2025-03-02T16:54:19.421911",
     "exception": false,
     "start_time": "2025-03-02T16:54:19.396262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_aspect_dataset(X_train, y_train, X_val, y_val, sequence_length, num_workers=4):\n",
    "    train_dataset = AspectDetectionDataset(X_train, y_train, label_mapping, tokenizer, max_length=sequence_length)\n",
    "    val_dataset = AspectDetectionDataset(X_val, y_val, label_mapping, tokenizer, max_length=sequence_length)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=num_workers,\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=num_workers, \n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61cad4fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T16:54:19.457653Z",
     "iopub.status.busy": "2025-03-02T16:54:19.457396Z",
     "iopub.status.idle": "2025-03-02T16:54:19.467406Z",
     "shell.execute_reply": "2025-03-02T16:54:19.466747Z"
    },
    "papermill": {
     "duration": 0.029154,
     "end_time": "2025-03-02T16:54:19.468676",
     "exception": false,
     "start_time": "2025-03-02T16:54:19.439522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_sentiment_dataset(device, train_dataset, val_dataset, aspect_detection_model, tokenizer, max_length=sequence_length):\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "\n",
    "    aspect_detection_model.to(device)\n",
    "    aspect_detection_model.eval()\n",
    "\n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "    train_aspects = []\n",
    "    train_indices = []\n",
    "\n",
    "    val_data = []\n",
    "    val_labels = []\n",
    "    val_aspects = []\n",
    "    val_indices = []\n",
    "\n",
    "    # Transform train set\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        for batch in train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = aspect_detection_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            for i in range(len(preds)):\n",
    "                for j in range(len(preds[i])):\n",
    "                    if int(preds[i][j]) != 1:\n",
    "                        train_aspects.append(aspect_list[j])\n",
    "                        train_data.append(batch['ori_text'][i])\n",
    "                        train_labels.append(batch['ori_label'][i][j])\n",
    "                        train_indices.append(batch['ori_indices'][i])\n",
    "            \n",
    "        # Transform validation set\n",
    "        for batch in val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = aspect_detection_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            for i in range(len(preds)):\n",
    "                for j in range(len(preds[i])):\n",
    "                    if int(preds[i][j]) != 1:\n",
    "                        val_aspects.append(aspect_list[j])\n",
    "                        val_data.append(batch['ori_text'][i])\n",
    "                        val_labels.append(batch['ori_label'][i][j])\n",
    "                        val_indices.append(batch['ori_indices'][i])\n",
    "\n",
    "    train_dataset = SentimentAnalysisDataset(train_data, train_labels, train_aspects, train_indices, label_mapping, tokenizer, max_length=max_length)\n",
    "    val_dataset = SentimentAnalysisDataset(val_data, val_labels, val_aspects, val_indices, label_mapping, tokenizer, max_length=max_length)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47aff4a8",
   "metadata": {
    "papermill": {
     "duration": 0.012189,
     "end_time": "2025-03-02T16:54:19.494326",
     "exception": false,
     "start_time": "2025-03-02T16:54:19.482137",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "842e790a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T16:54:19.519367Z",
     "iopub.status.busy": "2025-03-02T16:54:19.519150Z",
     "iopub.status.idle": "2025-03-02T16:54:19.522571Z",
     "shell.execute_reply": "2025-03-02T16:54:19.521902Z"
    },
    "papermill": {
     "duration": 0.017583,
     "end_time": "2025-03-02T16:54:19.523757",
     "exception": false,
     "start_time": "2025-03-02T16:54:19.506174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_data = len(X_train) + len(X_val)\n",
    "initial_train_size = int(0.05 * total_data)\n",
    "checkpoints = [\n",
    "    int(0.5 * total_data), \n",
    "    int(0.6 * total_data), \n",
    "    int(0.7 * total_data),\n",
    "    len(X_train)\n",
    "]\n",
    "min_increment = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c596df6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T16:54:19.548420Z",
     "iopub.status.busy": "2025-03-02T16:54:19.548210Z",
     "iopub.status.idle": "2025-03-02T16:54:19.552529Z",
     "shell.execute_reply": "2025-03-02T16:54:19.551882Z"
    },
    "papermill": {
     "duration": 0.017873,
     "end_time": "2025-03-02T16:54:19.553738",
     "exception": false,
     "start_time": "2025-03-02T16:54:19.535865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p, label, classes):\n",
    "    preds = torch.tensor(p.predictions) # Sigmoid and threshold for multi-label\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Hamming accuracy: proportion of correctly predicted labels over total labels\n",
    "    hamming_accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Standard multi-label precision, recall, and F1 metrics\n",
    "    precision, recall, f1_micro, _ = precision_recall_fscore_support(labels, preds, average='micro', zero_division=0)\n",
    "    _, _, f1_macro, _ = precision_recall_fscore_support(labels, preds, average='macro', zero_division=0)\n",
    "\n",
    "    report = classification_report(\n",
    "        labels, \n",
    "        preds, \n",
    "        labels=label,\n",
    "        target_names=classes,\n",
    "        zero_division=0\n",
    "    ) \n",
    "\n",
    "    return {\n",
    "        'accuracy': hamming_accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'report': report\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50031725",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T16:54:19.578736Z",
     "iopub.status.busy": "2025-03-02T16:54:19.578500Z",
     "iopub.status.idle": "2025-03-02T16:54:19.584678Z",
     "shell.execute_reply": "2025-03-02T16:54:19.583876Z"
    },
    "papermill": {
     "duration": 0.019736,
     "end_time": "2025-03-02T16:54:19.585813",
     "exception": false,
     "start_time": "2025-03-02T16:54:19.566077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics_overall(p, classes):\n",
    "    preds = torch.tensor(p.predictions)\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Ensure it's in the correct shape\n",
    "    if preds.shape != labels.shape:\n",
    "        raise ValueError(\"Shape mismatch: predictions and labels must have the same shape.\")\n",
    "\n",
    "    # Hamming accuracy: proportion of correctly predicted labels over total labels\n",
    "    hamming_accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Compute per-label (column-wise) precision, recall, F1\n",
    "    precision_list, recall_list, f1_micro_list, f1_macro_list = [], [], [], []\n",
    "    \n",
    "    for i in range(labels.shape[1]):  # Loop through each column (multi-output)\n",
    "        prec, rec, f1_micro, _ = precision_recall_fscore_support(\n",
    "            labels[:, i], preds[:, i], average='micro', zero_division=0\n",
    "        )\n",
    "        _, _, f1_macro, _ = precision_recall_fscore_support(\n",
    "            labels[:, i], preds[:, i], average='macro', zero_division=0\n",
    "        )\n",
    "\n",
    "        precision_list.append(prec)\n",
    "        recall_list.append(rec)\n",
    "        f1_micro_list.append(f1_micro)\n",
    "        f1_macro_list.append(f1_macro)\n",
    "\n",
    "    # Compute average metrics across all outputs\n",
    "    precision = sum(precision_list) / len(precision_list)\n",
    "    recall = sum(recall_list) / len(recall_list)\n",
    "    f1_micro = sum(f1_micro_list) / len(f1_micro_list)\n",
    "    f1_macro = sum(f1_macro_list) / len(f1_macro_list)\n",
    "\n",
    "    # Generate classification report per output\n",
    "    reports = [classification_report(labels[:, i], preds[:, i], target_names=classes, zero_division=0) for i in range(labels.shape[1])]\n",
    "\n",
    "    return {\n",
    "        'accuracy': hamming_accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'reports': reports  # Returns list of reports, one for each output label\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e75f4ccb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T16:54:19.610367Z",
     "iopub.status.busy": "2025-03-02T16:54:19.610146Z",
     "iopub.status.idle": "2025-03-02T16:54:19.635826Z",
     "shell.execute_reply": "2025-03-02T16:54:19.635171Z"
    },
    "papermill": {
     "duration": 0.039348,
     "end_time": "2025-03-02T16:54:19.636961",
     "exception": false,
     "start_time": "2025-03-02T16:54:19.597613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(current_train_size, train_indices, aspect_metrics, sentiment_metrics, metrics, trials, seed):\n",
    "    accelerator = Accelerator(mixed_precision='fp16')  # Initialize the accelerator\n",
    "    device = accelerator.device\n",
    "\n",
    "    aspect_model = BertForSequenceClassification.from_pretrained(\n",
    "        'indobenchmark/indobert-base-p1',\n",
    "        num_labels=len(train_labels),\n",
    "        problem_type=\"multi_label_classification\"\n",
    "    )\n",
    "\n",
    "    # Freeze the first few layers of the encoder\n",
    "    for name, param in aspect_model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    # Define optimizer and loss function\n",
    "    aspect_optimizer = torch.optim.AdamW(aspect_model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Define DataLoaders\n",
    "    current_X_train = [X_train[i] for i in train_indices]\n",
    "    current_y_train = [y_train[i] for i in train_indices]\n",
    "    aspect_train_loader, aspect_val_loader, aspect_train_dataset, aspect_val_dataset = build_aspect_dataset(current_X_train, current_y_train, X_val, y_val, sequence_length)\n",
    "\n",
    "    # Prepare everything with Accelerator\n",
    "    aspect_model, aspect_optimizer, aspect_train_loader, aspect_val_loader = accelerator.prepare(\n",
    "        aspect_model, aspect_optimizer, aspect_train_loader, aspect_val_loader\n",
    "    )\n",
    "\n",
    "    aspect_result = None\n",
    "    start_time = time.time()\n",
    "\n",
    "    # ASPECT DETECTION\n",
    "    accelerator.print(\"ASPECT DETECTION\")\n",
    "    for epoch in range(epochs):\n",
    "        aspect_model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for batch in aspect_train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels']\n",
    "        \n",
    "            aspect_optimizer.zero_grad()\n",
    "            outputs = aspect_model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            aspect_optimizer.step()\n",
    "        \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "        aspect_model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in aspect_val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "                labels = batch['labels']\n",
    "                \n",
    "                outputs = aspect_model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                # Gather predictions and labels from all devices\n",
    "                all_preds.append(accelerator.gather(preds))\n",
    "                all_labels.append(accelerator.gather(labels))\n",
    "\n",
    "        all_preds = torch.cat(all_preds).cpu().numpy()\n",
    "        all_labels = torch.cat(all_labels).cpu().numpy()\n",
    "\n",
    "        result = compute_metrics(\n",
    "            type('EvalOutput', (object,), {'predictions': all_preds, 'label_ids': all_labels}),\n",
    "            None,\n",
    "            ['fuel', 'machine', 'others', 'part', 'price', 'service']\n",
    "        )\n",
    "\n",
    "        if aspect_result is None or result['f1_micro'] >= aspect_result['f1_micro']:\n",
    "            accelerator.print(\"Higher F1 achieved, saving model\")\n",
    "            \n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(aspect_model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                f'{filename}-aspect-{trials + 1}-model',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "            aspect_result = result\n",
    "\n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(aspect_train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "\n",
    "    accelerator.print(f\"\\nAspect detection accuracy: {round(aspect_result['accuracy'], 4)}, F1 Micro: {round(aspect_result['f1_micro'], 4)}, F1 Macro: {round(aspect_result['f1_macro'], 4)}\")\n",
    "    accelerator.print(aspect_result['report'])\n",
    "\n",
    "    best_aspect_model = BertForSequenceClassification.from_pretrained(f'{filename}-aspect-{trials + 1}-model')\n",
    "    best_aspect_model = accelerator.prepare(best_aspect_model)\n",
    "\n",
    "    # SENTIMENT ANALYSIS ON NON NEUTRAL ASPECTS\n",
    "    accelerator.print(\"--------------------------------------------------\")\n",
    "    accelerator.print(\"SENTIMENT ANALYSIS\")\n",
    "\n",
    "    sentiment_model = BertForSequenceClassification.from_pretrained(\n",
    "        'indobenchmark/indobert-base-p1',\n",
    "        num_labels=2,\n",
    "    )\n",
    "    sentiment_optimizer = torch.optim.AdamW(sentiment_model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "\n",
    "    for name, param in sentiment_model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    sentiment_train_loader, sentiment_val_loader, sentiment_train_dataset, sentiment_val_dataset = build_sentiment_dataset(\n",
    "        device, aspect_train_dataset, aspect_val_dataset, best_aspect_model, tokenizer, max_length=sequence_length\n",
    "    )\n",
    "    sentiment_model, sentiment_optimizer, sentiment_train_loader, sentiment_val_loader = accelerator.prepare(\n",
    "        sentiment_model, sentiment_optimizer, sentiment_train_loader, sentiment_val_loader\n",
    "    )\n",
    "    sentiment_result = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        sentiment_model.train()\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for batch in sentiment_train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels']\n",
    "        \n",
    "            sentiment_optimizer.zero_grad()\n",
    "            outputs = sentiment_model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            sentiment_optimizer.step()\n",
    "        \n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        sentiment_model.eval()\n",
    "        sentiment_val_outputs = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in sentiment_val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "                \n",
    "                outputs = sentiment_model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                for i in range(len(preds)):\n",
    "                    val_output = {\n",
    "                        'label': batch['labels'][i],\n",
    "                        'aspect': batch['aspect'][i],\n",
    "                        'ori_indices': batch['ori_indices'][i],\n",
    "                        'pred': np.argmax(preds[i].cpu().numpy()),\n",
    "                    }\n",
    "                    sentiment_val_outputs.append(val_output)\n",
    "\n",
    "        sentiment_val_outputs = accelerator.gather_for_metrics(sentiment_val_outputs)\n",
    "        unique_val_outputs = {(x['ori_indices'].item(), x['aspect']): x for x in sentiment_val_outputs}\n",
    "        sentiment_val_outputs = list(unique_val_outputs.values())\n",
    "\n",
    "        result = compute_metrics(\n",
    "            type('EvalOutput', (object,), {'predictions': [item['pred'] for item in sentiment_val_outputs], 'label_ids': [np.argmax(item['label'].cpu().numpy()) for item in sentiment_val_outputs]}),\n",
    "            [0, 1],\n",
    "            ['negative', 'positive']\n",
    "        )\n",
    "\n",
    "        if sentiment_result is None or result['f1_micro'] >= sentiment_result['f1_micro']:\n",
    "            accelerator.print(\"Higher F1 achieved, saving model\")\n",
    "            sentiment_result = result\n",
    "            \n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(sentiment_model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                 f'{filename}-sentiment-{trials + 1}-model',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "\n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(sentiment_train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "\n",
    "    accelerator.print(f\"\\nSentiment analysis accuracy: {round(sentiment_result['accuracy'], 4)}, F1 Micro: {round(sentiment_result['f1_micro'], 4)}, F1 Macro: {round(sentiment_result['f1_macro'], 4)}\")\n",
    "    accelerator.print(sentiment_result['report'])\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    best_sentiment_model = BertForSequenceClassification.from_pretrained( f'{filename}-sentiment-{trials + 1}-model')\n",
    "    best_sentiment_model = accelerator.prepare(best_sentiment_model)\n",
    "\n",
    "    # Compute overall metrics\n",
    "    aspect_labels = []\n",
    "    aspect_indices = []\n",
    "    aspect_preds = []\n",
    "\n",
    "    aspect_outputs = {}\n",
    "    sentiment_outputs = []\n",
    "    \n",
    "    best_aspect_model.eval()\n",
    "    best_sentiment_model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in aspect_val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            outputs = aspect_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            aspect_indices.append(accelerator.gather(batch['ori_indices']))\n",
    "            aspect_labels.append(accelerator.gather(batch['ori_label']))\n",
    "            aspect_preds.append(accelerator.gather(preds))\n",
    "\n",
    "        aspect_indices = torch.cat(aspect_indices).cpu().numpy()\n",
    "        aspect_labels = torch.cat(aspect_labels).cpu().numpy()\n",
    "        aspect_preds = torch.cat(aspect_preds).cpu().numpy()\n",
    "\n",
    "        accelerator.wait_for_everyone()\n",
    "        aspect_outputs = [\n",
    "            {'ori_indices': aspect_indices[i], \n",
    "             'ori_labels': aspect_labels[i], \n",
    "             'pred': aspect_preds[i]}\n",
    "            for i in range(len(aspect_preds))\n",
    "        ]\n",
    "        aspect_outputs = {x['ori_indices'].item(): x for x in aspect_outputs}\n",
    "    \n",
    "        for batch in sentiment_val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            outputs = sentiment_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "    \n",
    "            for i in range(len(preds)):\n",
    "                output = {\n",
    "                    'aspect': batch['aspect'][i],\n",
    "                    'ori_indices': batch['ori_indices'][i],\n",
    "                    'pred': np.argmax(preds[i].cpu().numpy()),\n",
    "                }\n",
    "                sentiment_outputs.append(output)\n",
    "\n",
    "        sentiment_outputs = accelerator.gather_for_metrics(sentiment_outputs)\n",
    "        sentiment_outputs = {(x['ori_indices'].item(), x['aspect']): x for x in sentiment_outputs}\n",
    "\n",
    "    # Replcae non neutral aspect to its predicted sentiment\n",
    "    accelerator.wait_for_everyone()\n",
    "    if accelerator.is_main_process:\n",
    "        i = -1\n",
    "        for (ori_index, aspect), value in sentiment_outputs.items():\n",
    "            aspect = aspect_mapping[aspect]\n",
    "            aspect_outputs[ori_index]['pred'][aspect] = 2 if value['pred'] == 1.0 else value['pred']\n",
    "\n",
    "        result = compute_metrics_overall(\n",
    "            type('EvalOutput', (object,), {'predictions': [output['pred'] for output in aspect_outputs.values()], 'label_ids': [output['ori_labels'] for output in aspect_outputs.values()]}),\n",
    "            ['negative', 'neutral', 'positive'],\n",
    "        )\n",
    "\n",
    "        accelerator.print(\"--------------------------------------------------\")\n",
    "        accelerator.print(f\"Iteration {current_train_size}: Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "        accelerator.print(\"--------------------------------------------------\")\n",
    "        for i in range(len(train_labels)):\n",
    "            accelerator.print(f\"Aspect {aspect_list[i]} report:\")\n",
    "            accelerator.print(result['reports'][i])\n",
    "       \n",
    "        \n",
    "        aspect_metrics[0].append(aspect_result['accuracy'])\n",
    "        aspect_metrics[1].append(aspect_result['f1_micro'])\n",
    "        aspect_metrics[2].append(aspect_result['f1_macro'])\n",
    "        sentiment_metrics[0].append(sentiment_result['accuracy'])\n",
    "        sentiment_metrics[1].append(sentiment_result['f1_micro'])\n",
    "        sentiment_metrics[2].append(sentiment_result['f1_macro'])\n",
    "        metrics[0].append(current_train_size)\n",
    "        metrics[1].append(result['accuracy'])\n",
    "        metrics[2].append(result['f1_micro'])\n",
    "        metrics[3].append(result['f1_macro'])\n",
    "        \n",
    "    accelerator.print(f\"Total train time: {duration} s\")\n",
    "    accelerator.end_training()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31305b5a",
   "metadata": {
    "papermill": {
     "duration": 0.011709,
     "end_time": "2025-03-02T16:54:19.660860",
     "exception": false,
     "start_time": "2025-03-02T16:54:19.649151",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PLOT THE RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d683db22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T16:54:19.685015Z",
     "iopub.status.busy": "2025-03-02T16:54:19.684763Z",
     "iopub.status.idle": "2025-03-02T16:54:19.689819Z",
     "shell.execute_reply": "2025-03-02T16:54:19.689212Z"
    },
    "papermill": {
     "duration": 0.018332,
     "end_time": "2025-03-02T16:54:19.690960",
     "exception": false,
     "start_time": "2025-03-02T16:54:19.672628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_result(data_used, accuracies, f1_micros, f1_macros):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(21, 5))\n",
    "    data_used = [round(data / total_data * 100, 1) for data in data_used]\n",
    "\n",
    "    # Plot for Accuracy\n",
    "    axs[0].plot(data_used, accuracies, label=\"Accuracy\", color=\"blue\")\n",
    "    axs[0].set_xlabel(\"Percentage of data used\")\n",
    "    axs[0].set_title(\"Accuracy\")\n",
    "    axs[0].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Micro\n",
    "    axs[1].plot(data_used, f1_micros, label=\"F1 Micro\", color=\"orange\")\n",
    "    axs[1].set_xlabel(\"Percentage of data used\")\n",
    "    axs[1].set_title(\"F1 Micro\")\n",
    "    axs[1].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Macro\n",
    "    axs[2].plot(data_used, f1_macros, label=\"F1 Macro\", color=\"green\")\n",
    "    axs[2].set_xlabel(\"Percentage of data used\")\n",
    "    axs[2].set_title(\"F1 Macro\")\n",
    "    axs[2].set_xticks(data_used)\n",
    "\n",
    "    # Adjust layout and show the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b0497b",
   "metadata": {
    "papermill": {
     "duration": 0.011576,
     "end_time": "2025-03-02T16:54:19.714341",
     "exception": false,
     "start_time": "2025-03-02T16:54:19.702765",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# QUERY STRATEGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5421dcd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T16:54:19.739193Z",
     "iopub.status.busy": "2025-03-02T16:54:19.738975Z",
     "iopub.status.idle": "2025-03-02T16:54:19.758480Z",
     "shell.execute_reply": "2025-03-02T16:54:19.757862Z"
    },
    "papermill": {
     "duration": 0.033298,
     "end_time": "2025-03-02T16:54:19.759608",
     "exception": false,
     "start_time": "2025-03-02T16:54:19.726310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def kmeans_clustering_sampling(aspect_model, sentiment_model, X_pool, train_indices, remaining_indices, sampling_dur, new_samples, trials, n_clusters=min_increment):\n",
    "    accelerator = Accelerator(mixed_precision=\"fp16\")\n",
    "    device = accelerator.device\n",
    "\n",
    "    aspect_model.to(device)\n",
    "    aspect_model.eval()\n",
    "    sentiment_model.to(device)\n",
    "    sentiment_model.eval()\n",
    "\n",
    "    current_train_size = len(train_indices)\n",
    "    aspect_dataset = AspectDetectionDataset(\n",
    "        X_pool, \n",
    "        [['neutral' for i in range(len(train_labels))] for x in range(len(X_pool))], \n",
    "        label_mapping, \n",
    "        tokenizer, \n",
    "        max_length=sequence_length\n",
    "    )\n",
    "    aspect_loader = DataLoader(\n",
    "        aspect_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    \n",
    "    aspect_outputs = {}\n",
    "    sentiment_outputs = {}\n",
    "\n",
    "    aspects = []\n",
    "    data = []\n",
    "    labels = []\n",
    "    indices = []\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Pass through aspect detction model\n",
    "    for batch in aspect_loader:\n",
    "        token_type_ids = batch['token_type_ids'].to(device, non_blocking=True)\n",
    "        input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "        attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = aspect_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids).logits\n",
    "            embeddings = aspect_model.base_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "\n",
    "        for i in range(len(outputs)):\n",
    "            aspect_outputs[batch['ori_indices'][i].item()] = embeddings.last_hidden_state[i].mean(dim=1).cpu().numpy()\n",
    "            \n",
    "            for j in range(len(outputs[i])):\n",
    "                if int(outputs[i][j].round()) != 1:\n",
    "                    aspects.append(aspect_list[j])\n",
    "                    data.append(batch['ori_text'][i])\n",
    "                    labels.append(batch['ori_label'][i][j])\n",
    "                    indices.append(batch['ori_indices'][i])\n",
    "\n",
    "    if len(data) > 0:\n",
    "        sentiment_dataset = SentimentAnalysisDataset(data, labels, aspects, indices, label_mapping, tokenizer, max_length=sequence_length)\n",
    "        sentiment_loader = torch.utils.data.DataLoader(\n",
    "            sentiment_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4,\n",
    "        )\n",
    "    \n",
    "        # Pass through sentiment analysis model\n",
    "        for batch in sentiment_loader:\n",
    "            token_type_ids = batch['token_type_ids'].to(device, non_blocking=True)\n",
    "            input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "            attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "    \n",
    "            with torch.no_grad():\n",
    "                outputs = sentiment_model.base_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "    \n",
    "            for i in range(len(outputs.last_hidden_state)):\n",
    "                ori_index = batch['ori_indices'][i].item()\n",
    "                if ori_index in sentiment_outputs.keys():\n",
    "                    sentiment_outputs[ori_index].append(outputs.last_hidden_state[i].mean(dim=1).cpu().numpy())\n",
    "                else:\n",
    "                    sentiment_outputs[ori_index] = [outputs.last_hidden_state[i].mean(dim=1).cpu().numpy()]\n",
    "\n",
    "    for key, val in sentiment_outputs.items():\n",
    "        sentiment_outputs[key] = np.mean(val, axis=0)\n",
    "\n",
    "    collected_indices = set()  # Initialize set to store selected indices\n",
    "    thresholds = []\n",
    "\n",
    "    if accelerator.is_main_process:\n",
    "        aspect_outputs = dict(sorted(aspect_outputs.items()))\n",
    "\n",
    "        if len(data) > 0:\n",
    "            for key, val in sentiment_outputs.items():\n",
    "                aspect_outputs[key] = np.mean([val, aspect_outputs[key]], axis=0)\n",
    "\n",
    "        embeddings = np.array(list(aspect_outputs.values()))\n",
    "        target_samples = len(embeddings[:math.ceil(0.1 * len(embeddings))])\n",
    "    \n",
    "        # Check nearest checkpoint\n",
    "        nearest_cp = 0\n",
    "        arrived_at_cp = False\n",
    "        for cp in checkpoints:\n",
    "            if cp > current_train_size:\n",
    "                nearest_cp = cp\n",
    "                break\n",
    "                \n",
    "        # Determine number of maximum samples to be acquired\n",
    "        if target_samples <= n_clusters and n_clusters < nearest_cp - current_train_size:\n",
    "            target_samples = n_clusters\n",
    "        elif target_samples > n_clusters and target_samples < nearest_cp - current_train_size:\n",
    "            target_samples = target_samples\n",
    "        else:\n",
    "            arrived_at_cp = True\n",
    "            target_samples = nearest_cp - current_train_size\n",
    "\n",
    "        # No clustering needed when there's little data left\n",
    "        if current_train_size >= checkpoints[len(checkpoints)-1] - min_increment:\n",
    "            end_time = time.time()\n",
    "            duration = end_time - start_time\n",
    "            \n",
    "            temp = train_indices.copy()\n",
    "            temp.extend(remaining_indices)\n",
    "            \n",
    "            # Save acquired data up to checkpoint\n",
    "            acquired_data = pd.DataFrame({\n",
    "                'processed_text': [X_train[i] for i in temp],\n",
    "                'fuel': [y_train[i][0] for i in temp],\n",
    "                'machine': [y_train[i][1] for i in temp],\n",
    "                'others': [y_train[i][2] for i in temp],\n",
    "                'part': [y_train[i][3] for i in temp],\n",
    "                'price': [y_train[i][4] for i in temp],\n",
    "                'service': [y_train[i][5] for i in temp],\n",
    "            })\n",
    "            acquired_data.to_csv(f'acquired_data/{filename}-{trials+1}-data-{nearest_cp}.csv', index=False)\n",
    "\n",
    "            print(\"Nearest checkpoint:\", nearest_cp)\n",
    "            print(\"Acquired samples:\", len(remaining_indices))\n",
    "            print(f\"Sampling duration: {duration} seconds\")\n",
    "            \n",
    "            sampling_dur.append(duration)\n",
    "            for i in remaining_indices:\n",
    "                new_samples.append(i)\n",
    "        else:\n",
    "            # Cluster the data based on its embeddings\n",
    "            kmeans=KMeans(n_clusters=n_clusters, n_init=1)\n",
    "            kmeans.fit(embeddings)\n",
    "            \n",
    "            for cluster_id in range(n_clusters):\n",
    "                # Cluster center and indices of samples in the current cluster\n",
    "                cluster_center = kmeans.cluster_centers_[cluster_id]\n",
    "                cluster_indices = np.where(kmeans.labels_ == cluster_id)[0]\n",
    "            \n",
    "                if cluster_indices.size == 0:\n",
    "                    # Skip clusters with no members\n",
    "                    print(f\"Cluster {cluster_id} has no members, skipping.\")\n",
    "                    continue\n",
    "            \n",
    "                # Calculate distances of each point in the cluster from the cluster center\n",
    "                cluster_distances = np.linalg.norm(embeddings[cluster_indices] - cluster_center, axis=1)\n",
    "            \n",
    "                # Determine the local threshold (10th percentile of closest distances to cluster center)\n",
    "                local_threshold = np.percentile(cluster_distances, 10)\n",
    "                thresholds.append(local_threshold)\n",
    "            \n",
    "                below_threshold_indices = cluster_indices[cluster_distances <= local_threshold]\n",
    "                collected_indices.update(below_threshold_indices)\n",
    "\n",
    "            # To handle multiple points with same distance\n",
    "            if len(collected_indices) > target_samples:\n",
    "                collected_indices = np.array(list(collected_indices))\n",
    "                np.random.shuffle(collected_indices)\n",
    "                collected_indices = collected_indices[:target_samples]\n",
    "                \n",
    "            end_time = time.time() \n",
    "            duration = end_time - start_time \n",
    "    \n",
    "            if arrived_at_cp:\n",
    "                temp = train_indices.copy()\n",
    "                temp.extend(collected_indices)\n",
    "                \n",
    "                # Save acquired data up to checkpoint\n",
    "                acquired_data = pd.DataFrame({\n",
    "                    'processed_text': [X_train[i] for i in temp],\n",
    "                    'fuel': [y_train[i][0] for i in temp],\n",
    "                    'machine': [y_train[i][1] for i in temp],\n",
    "                    'others': [y_train[i][2] for i in temp],\n",
    "                    'part': [y_train[i][3] for i in temp],\n",
    "                    'price': [y_train[i][4] for i in temp],\n",
    "                    'service': [y_train[i][5] for i in temp],\n",
    "                })\n",
    "        \n",
    "                acquired_data.to_csv(f'acquired_data/{filename}-{trials+1}-data-{nearest_cp}.csv', index=False)\n",
    "            \n",
    "            print(\"Nearest checkpoint:\", nearest_cp)\n",
    "            print(\"Acquired samples:\", len(collected_indices))\n",
    "            print(f\"Sampling duration: {duration} seconds\")\n",
    "        \n",
    "            sampling_dur.append(duration)\n",
    "            for i in collected_indices:\n",
    "                new_samples.append(remaining_indices[i])\n",
    "\n",
    "        threshold_data = pd.DataFrame({\n",
    "            'Threshold': thresholds\n",
    "        })\n",
    "        threshold_data.to_csv(f\"results/{filename}-thresholds-{trials+1}-{current_train_size}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5d3382",
   "metadata": {
    "papermill": {
     "duration": 0.011682,
     "end_time": "2025-03-02T16:54:19.783048",
     "exception": false,
     "start_time": "2025-03-02T16:54:19.771366",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MAIN LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "354087e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T16:54:19.807505Z",
     "iopub.status.busy": "2025-03-02T16:54:19.807294Z",
     "iopub.status.idle": "2025-03-02T16:54:19.815837Z",
     "shell.execute_reply": "2025-03-02T16:54:19.815229Z"
    },
    "papermill": {
     "duration": 0.022209,
     "end_time": "2025-03-02T16:54:19.817074",
     "exception": false,
     "start_time": "2025-03-02T16:54:19.794865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def active_learning(seed, i):\n",
    "    aspect_accuracies = manager.list()\n",
    "    aspect_f1_micros = manager.list()\n",
    "    aspect_f1_macros = manager.list()\n",
    "    sentiment_accuracies = manager.list()\n",
    "    sentiment_f1_micros = manager.list()\n",
    "    sentiment_f1_macros = manager.list()\n",
    "    accuracies = manager.list()\n",
    "    f1_micros = manager.list()\n",
    "    f1_macros = manager.list()\n",
    "    data_used = manager.list()\n",
    "    sampling_dur = manager.list()\n",
    "    new_samples = manager.list()\n",
    "\n",
    "    set_seed(seed)\n",
    "    \n",
    "    print(\"===============================================\")\n",
    "    print(\"TRIAL {}\".format(i+1))\n",
    "    print(\"Random seed:\", seed)\n",
    "    \n",
    "    train_indices = np.random.choice(range(len(X_train)), initial_train_size, replace=False).tolist()\n",
    "    remaining_indices = list(set(range(len(X_train))) - set(train_indices))\n",
    "    \n",
    "    current_train_size = initial_train_size\n",
    "    \n",
    "    start_time = time.time()\n",
    "    while current_train_size < checkpoints[len(checkpoints) - 1]:\n",
    "        # Train the model\n",
    "        args = (\n",
    "            current_train_size, \n",
    "            train_indices, \n",
    "            (aspect_accuracies, aspect_f1_micros, aspect_f1_macros), \n",
    "            (sentiment_accuracies, sentiment_f1_micros, sentiment_f1_macros),\n",
    "            (data_used, accuracies, f1_micros, f1_macros), \n",
    "            i,\n",
    "            seed\n",
    "        )\n",
    "        notebook_launcher(train_model, args, num_processes=2)\n",
    "\n",
    "        aspect_model = BertForSequenceClassification.from_pretrained(f'{filename}-aspect-{i+1}-model')\n",
    "        sentiment_model = BertForSequenceClassification.from_pretrained(f'{filename}-sentiment-{i+1}-model')\n",
    "    \n",
    "        # Perform query strategy to select new samples\n",
    "        new_samples = manager.list()\n",
    "        sampling_args = (\n",
    "            aspect_model, \n",
    "            sentiment_model, \n",
    "            [X_train[i] for i in remaining_indices], \n",
    "            train_indices, \n",
    "            remaining_indices, \n",
    "            sampling_dur, \n",
    "            new_samples, \n",
    "            i\n",
    "        )\n",
    "        notebook_launcher(kmeans_clustering_sampling, sampling_args, num_processes=2)\n",
    "        new_samples = list(new_samples)\n",
    "        train_indices.extend(new_samples)\n",
    "        remaining_indices = list(set(remaining_indices) - set(new_samples))\n",
    "    \n",
    "        # Update current training size\n",
    "        current_train_size = len(train_indices)\n",
    "        print(\"New train size: {}\".format(current_train_size))\n",
    "    \n",
    "    # Train last epoch\n",
    "    args = (\n",
    "        current_train_size, \n",
    "        train_indices, \n",
    "        (aspect_accuracies, aspect_f1_micros, aspect_f1_macros), \n",
    "        (sentiment_accuracies, sentiment_f1_micros, sentiment_f1_macros),\n",
    "        (data_used, accuracies, f1_micros, f1_macros), \n",
    "        i,\n",
    "        seed\n",
    "    )\n",
    "    notebook_launcher(train_model, args, num_processes=2)\n",
    "    data_used, accuracies, f1_micros, f1_macros, sampling_dur = list(data_used), list(accuracies), list(f1_micros), list(f1_macros), list(sampling_dur)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    # print(f\"Total sampling time: {np.array(sampling_dur).sum().round(2)} seconds\")\n",
    "    print(f\"Total runtime: {duration} seconds\")\n",
    "    \n",
    "    plot_result(data_used, accuracies, f1_micros, f1_macros)\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        'Data Used': data_used,\n",
    "        'Aspect Accuracy': aspect_accuracies,\n",
    "        'Aspect F1 Micro': aspect_f1_micros,\n",
    "        'Aspect F1 Macro': aspect_f1_macros,\n",
    "        'Sentiment Accuracy': sentiment_accuracies,\n",
    "        'Sentiment F1 Micro': sentiment_f1_micros,\n",
    "        'Sentiment F1 Macro': sentiment_f1_macros,\n",
    "        'Accuracy': accuracies,\n",
    "        'F1 Micro': f1_micros,\n",
    "        'F1 Macro': f1_macros,\n",
    "    })\n",
    "    \n",
    "    sampling_dur.insert(0, 0)\n",
    "    results['Sampling Duration'] = sampling_dur\n",
    "    results.to_csv(f'results/{filename}-{i+1}-results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9cc8f4bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T16:54:19.841452Z",
     "iopub.status.busy": "2025-03-02T16:54:19.841250Z",
     "iopub.status.idle": "2025-03-02T16:54:19.844017Z",
     "shell.execute_reply": "2025-03-02T16:54:19.843412Z"
    },
    "papermill": {
     "duration": 0.016537,
     "end_time": "2025-03-02T16:54:19.845256",
     "exception": false,
     "start_time": "2025-03-02T16:54:19.828719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seeds = [50, 81, 14, 3, 94]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143b9309",
   "metadata": {
    "papermill": {
     "duration": 0.011928,
     "end_time": "2025-03-02T16:54:19.869276",
     "exception": false,
     "start_time": "2025-03-02T16:54:19.857348",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8e8fb4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T16:54:19.894070Z",
     "iopub.status.busy": "2025-03-02T16:54:19.893787Z",
     "iopub.status.idle": "2025-03-02T17:42:49.607926Z",
     "shell.execute_reply": "2025-03-02T17:42:49.607009Z"
    },
    "papermill": {
     "duration": 2909.728314,
     "end_time": "2025-03-02T17:42:49.609428",
     "exception": false,
     "start_time": "2025-03-02T16:54:19.881114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 1\n",
      "Random seed: 50\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6756, Accuracy: 0.7731, F1 Micro: 0.8711, F1 Macro: 0.8698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5958, Accuracy: 0.7887, F1 Micro: 0.8819, F1 Macro: 0.8804\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5785, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.513, Accuracy: 0.7939, F1 Micro: 0.8843, F1 Macro: 0.8828\n",
      "Epoch 5/10, Train Loss: 0.5006, Accuracy: 0.7924, F1 Micro: 0.8829, F1 Macro: 0.881\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4695, Accuracy: 0.7954, F1 Micro: 0.8846, F1 Macro: 0.8828\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4328, Accuracy: 0.7969, F1 Micro: 0.8857, F1 Macro: 0.8842\n",
      "Epoch 8/10, Train Loss: 0.4369, Accuracy: 0.7932, F1 Micro: 0.8832, F1 Macro: 0.8812\n",
      "Epoch 9/10, Train Loss: 0.415, Accuracy: 0.7917, F1 Micro: 0.8816, F1 Macro: 0.8789\n",
      "Epoch 10/10, Train Loss: 0.3884, Accuracy: 0.7894, F1 Micro: 0.88, F1 Macro: 0.8769\n",
      "\n",
      "Aspect detection accuracy: 0.7969, F1 Micro: 0.8857, F1 Macro: 0.8842\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.78      1.00      0.88       175\n",
      "      others       0.71      1.00      0.83       158\n",
      "        part       0.75      0.98      0.85       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.80      1.00      0.89      1061\n",
      "   macro avg       0.80      1.00      0.88      1061\n",
      "weighted avg       0.80      1.00      0.89      1061\n",
      " samples avg       0.80      1.00      0.88      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7162, Accuracy: 0.2857, F1 Micro: 0.2857, F1 Macro: 0.2222\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.6764, Accuracy: 0.5, F1 Micro: 0.5, F1 Macro: 0.4974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.6621, Accuracy: 0.7143, F1 Micro: 0.7143, F1 Macro: 0.65\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.6053, Accuracy: 0.7857, F1 Micro: 0.7857, F1 Macro: 0.7143\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.5803, Accuracy: 0.7857, F1 Micro: 0.7857, F1 Macro: 0.7143\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.5674, Accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.825\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4789, Accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.825\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4895, Accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.825\n",
      "Epoch 9/10, Train Loss: 0.4054, Accuracy: 0.7143, F1 Micro: 0.7143, F1 Macro: 0.6889\n",
      "Epoch 10/10, Train Loss: 0.3482, Accuracy: 0.5, F1 Micro: 0.5, F1 Macro: 0.4974\n",
      "\n",
      "Sentiment analysis accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.825\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75         4\n",
      "    positive       0.90      0.90      0.90        10\n",
      "\n",
      "    accuracy                           0.86        14\n",
      "   macro avg       0.82      0.82      0.82        14\n",
      "weighted avg       0.86      0.86      0.86        14\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.7793, F1 Micro: 0.7793, F1 Macro: 0.3103\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.77      1.00      0.87       167\n",
      "    positive       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.77       216\n",
      "   macro avg       0.26      0.33      0.29       216\n",
      "weighted avg       0.60      0.77      0.67       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.70      1.00      0.83       152\n",
      "    positive       0.00      0.00      0.00        52\n",
      "\n",
      "    accuracy                           0.70       216\n",
      "   macro avg       0.23      0.33      0.28       216\n",
      "weighted avg       0.50      0.70      0.58       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.16      0.26      0.20        23\n",
      "     neutral       0.75      0.86      0.80       152\n",
      "    positive       0.60      0.07      0.13        41\n",
      "\n",
      "    accuracy                           0.64       216\n",
      "   macro avg       0.50      0.40      0.38       216\n",
      "weighted avg       0.66      0.64      0.61       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 55.75983238220215 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 81\n",
      "Sampling duration: 9.61546277999878 seconds\n",
      "New train size: 135\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6396, Accuracy: 0.7887, F1 Micro: 0.8819, F1 Macro: 0.8804\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5592, Accuracy: 0.7917, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5227, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Epoch 4/10, Train Loss: 0.5045, Accuracy: 0.7917, F1 Micro: 0.8833, F1 Macro: 0.8819\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4576, Accuracy: 0.8051, F1 Micro: 0.8898, F1 Macro: 0.8885\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4176, Accuracy: 0.817, F1 Micro: 0.8954, F1 Macro: 0.8943\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.412, Accuracy: 0.8371, F1 Micro: 0.9046, F1 Macro: 0.9035\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3537, Accuracy: 0.8549, F1 Micro: 0.9141, F1 Macro: 0.913\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3009, Accuracy: 0.8735, F1 Micro: 0.9246, F1 Macro: 0.9234\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2784, Accuracy: 0.904, F1 Micro: 0.9415, F1 Macro: 0.94\n",
      "\n",
      "Aspect detection accuracy: 0.904, F1 Micro: 0.9415, F1 Macro: 0.94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.92      0.99      0.96       187\n",
      "     machine       0.94      0.93      0.93       175\n",
      "      others       0.82      0.99      0.90       158\n",
      "        part       0.87      0.96      0.92       158\n",
      "       price       0.93      0.99      0.96       192\n",
      "     service       0.95      1.00      0.97       191\n",
      "\n",
      "   micro avg       0.91      0.98      0.94      1061\n",
      "   macro avg       0.91      0.98      0.94      1061\n",
      "weighted avg       0.91      0.98      0.94      1061\n",
      " samples avg       0.91      0.98      0.94      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6601, Accuracy: 0.7053, F1 Micro: 0.7053, F1 Macro: 0.4136\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4924, Accuracy: 0.7053, F1 Micro: 0.7053, F1 Macro: 0.4136\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4551, Accuracy: 0.8895, F1 Micro: 0.8895, F1 Macro: 0.8649\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3052, Accuracy: 0.8947, F1 Micro: 0.8947, F1 Macro: 0.8771\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2396, Accuracy: 0.9, F1 Micro: 0.9, F1 Macro: 0.8827\n",
      "Epoch 6/10, Train Loss: 0.1603, Accuracy: 0.8895, F1 Micro: 0.8895, F1 Macro: 0.8758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1073, Accuracy: 0.9053, F1 Micro: 0.9053, F1 Macro: 0.8894\n",
      "Epoch 8/10, Train Loss: 0.1067, Accuracy: 0.8789, F1 Micro: 0.8789, F1 Macro: 0.8629\n",
      "Epoch 9/10, Train Loss: 0.0612, Accuracy: 0.9, F1 Micro: 0.9, F1 Macro: 0.8764\n",
      "Epoch 10/10, Train Loss: 0.0557, Accuracy: 0.8421, F1 Micro: 0.8421, F1 Macro: 0.8304\n",
      "\n",
      "Sentiment analysis accuracy: 0.9053, F1 Micro: 0.9053, F1 Macro: 0.8894\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.89      0.85        56\n",
      "    positive       0.95      0.91      0.93       134\n",
      "\n",
      "    accuracy                           0.91       190\n",
      "   macro avg       0.88      0.90      0.89       190\n",
      "weighted avg       0.91      0.91      0.91       190\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 135: Accuracy: 0.885, F1 Micro: 0.885, F1 Macro: 0.7243\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.27      0.35        11\n",
      "     neutral       0.92      0.99      0.96       181\n",
      "    positive       0.93      0.58      0.72        24\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.79      0.62      0.68       216\n",
      "weighted avg       0.90      0.91      0.90       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.81      0.72        16\n",
      "     neutral       0.93      0.93      0.93       167\n",
      "    positive       0.69      0.61      0.65        33\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.76      0.78      0.77       216\n",
      "weighted avg       0.88      0.88      0.87       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.39      0.58      0.47        12\n",
      "     neutral       0.83      0.99      0.90       152\n",
      "    positive       0.93      0.27      0.42        52\n",
      "\n",
      "    accuracy                           0.80       216\n",
      "   macro avg       0.72      0.62      0.60       216\n",
      "weighted avg       0.83      0.80      0.76       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.70      0.74        23\n",
      "     neutral       0.87      0.96      0.91       152\n",
      "    positive       0.89      0.61      0.72        41\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.85      0.76      0.79       216\n",
      "weighted avg       0.87      0.87      0.86       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.38      0.48        13\n",
      "     neutral       0.93      0.99      0.96       186\n",
      "    positive       0.80      0.47      0.59        17\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.78      0.61      0.68       216\n",
      "weighted avg       0.90      0.91      0.90       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.79      0.85        14\n",
      "     neutral       0.95      1.00      0.97       185\n",
      "    positive       1.00      0.53      0.69        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.96      0.77      0.84       216\n",
      "weighted avg       0.95      0.95      0.94       216\n",
      "\n",
      "Total train time: 70.7015655040741 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 73\n",
      "Sampling duration: 12.921634674072266 seconds\n",
      "New train size: 208\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6055, Accuracy: 0.7887, F1 Micro: 0.8819, F1 Macro: 0.8804\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5367, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5003, Accuracy: 0.7946, F1 Micro: 0.8848, F1 Macro: 0.8833\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4741, Accuracy: 0.814, F1 Micro: 0.8943, F1 Macro: 0.8936\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4156, Accuracy: 0.8549, F1 Micro: 0.915, F1 Macro: 0.9149\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3722, Accuracy: 0.8943, F1 Micro: 0.9365, F1 Macro: 0.9355\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3215, Accuracy: 0.9182, F1 Micro: 0.9498, F1 Macro: 0.9481\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.263, Accuracy: 0.933, F1 Micro: 0.9584, F1 Macro: 0.9567\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2193, Accuracy: 0.9435, F1 Micro: 0.965, F1 Macro: 0.9635\n",
      "Epoch 10/10, Train Loss: 0.1865, Accuracy: 0.942, F1 Micro: 0.9639, F1 Macro: 0.962\n",
      "\n",
      "Aspect detection accuracy: 0.9435, F1 Micro: 0.965, F1 Macro: 0.9635\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      0.98      0.96       175\n",
      "      others       0.89      0.96      0.92       158\n",
      "        part       0.91      0.99      0.95       158\n",
      "       price       0.96      0.99      0.98       192\n",
      "     service       0.97      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.94      0.99      0.96      1061\n",
      "   macro avg       0.94      0.99      0.96      1061\n",
      "weighted avg       0.94      0.99      0.97      1061\n",
      " samples avg       0.95      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6454, Accuracy: 0.6696, F1 Micro: 0.6696, F1 Macro: 0.4011\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4976, Accuracy: 0.7093, F1 Micro: 0.7093, F1 Macro: 0.5266\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3915, Accuracy: 0.8987, F1 Micro: 0.8987, F1 Macro: 0.888\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2361, Accuracy: 0.9251, F1 Micro: 0.9251, F1 Macro: 0.9182\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.207, Accuracy: 0.9295, F1 Micro: 0.9295, F1 Macro: 0.9214\n",
      "Epoch 6/10, Train Loss: 0.1298, Accuracy: 0.9031, F1 Micro: 0.9031, F1 Macro: 0.8961\n",
      "Epoch 7/10, Train Loss: 0.0807, Accuracy: 0.9075, F1 Micro: 0.9075, F1 Macro: 0.8936\n",
      "Epoch 8/10, Train Loss: 0.1123, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.9086\n",
      "Epoch 9/10, Train Loss: 0.0736, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.9075\n",
      "Epoch 10/10, Train Loss: 0.0894, Accuracy: 0.9207, F1 Micro: 0.9207, F1 Macro: 0.9141\n",
      "\n",
      "Sentiment analysis accuracy: 0.9295, F1 Micro: 0.9295, F1 Macro: 0.9214\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.92      0.90        75\n",
      "    positive       0.96      0.93      0.95       152\n",
      "\n",
      "    accuracy                           0.93       227\n",
      "   macro avg       0.92      0.93      0.92       227\n",
      "weighted avg       0.93      0.93      0.93       227\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 208: Accuracy: 0.9267, F1 Micro: 0.9267, F1 Macro: 0.846\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.91      0.88      0.89        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.94      0.86        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.92      0.70      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.87      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.38      0.75      0.50        12\n",
      "     neutral       0.89      0.91      0.90       152\n",
      "    positive       0.83      0.58      0.68        52\n",
      "\n",
      "    accuracy                           0.82       216\n",
      "   macro avg       0.70      0.75      0.69       216\n",
      "weighted avg       0.85      0.82      0.83       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.83      0.78        23\n",
      "     neutral       0.92      0.99      0.95       152\n",
      "    positive       1.00      0.66      0.79        41\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.88      0.82      0.84       216\n",
      "weighted avg       0.92      0.91      0.90       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.69      0.72        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.86      0.71      0.77        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.86      0.80      0.82       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89        14\n",
      "     neutral       0.97      1.00      0.99       185\n",
      "    positive       1.00      0.76      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.97      0.87      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 77.91303181648254 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 66\n",
      "Sampling duration: 13.62617015838623 seconds\n",
      "New train size: 274\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5965, Accuracy: 0.7887, F1 Micro: 0.8819, F1 Macro: 0.8804\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5105, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4865, Accuracy: 0.7961, F1 Micro: 0.8855, F1 Macro: 0.8841\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4198, Accuracy: 0.8393, F1 Micro: 0.9067, F1 Macro: 0.9059\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3625, Accuracy: 0.8876, F1 Micro: 0.933, F1 Macro: 0.9319\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3094, Accuracy: 0.9256, F1 Micro: 0.9541, F1 Macro: 0.9525\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.238, Accuracy: 0.9427, F1 Micro: 0.9645, F1 Macro: 0.963\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2012, Accuracy: 0.9457, F1 Micro: 0.9663, F1 Macro: 0.9647\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1626, Accuracy: 0.9501, F1 Micro: 0.9688, F1 Macro: 0.9673\n",
      "Epoch 10/10, Train Loss: 0.1302, Accuracy: 0.9494, F1 Micro: 0.9681, F1 Macro: 0.9663\n",
      "\n",
      "Aspect detection accuracy: 0.9501, F1 Micro: 0.9688, F1 Macro: 0.9673\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.94      0.98      0.96       175\n",
      "      others       0.89      0.94      0.92       158\n",
      "        part       0.97      0.96      0.97       158\n",
      "       price       0.98      0.99      0.98       192\n",
      "     service       0.97      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5724, Accuracy: 0.6827, F1 Micro: 0.6827, F1 Macro: 0.4057\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3991, Accuracy: 0.8755, F1 Micro: 0.8755, F1 Macro: 0.8558\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2216, Accuracy: 0.8956, F1 Micro: 0.8956, F1 Macro: 0.8874\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.154, Accuracy: 0.9237, F1 Micro: 0.9237, F1 Macro: 0.911\n",
      "Epoch 5/10, Train Loss: 0.1064, Accuracy: 0.8996, F1 Micro: 0.8996, F1 Macro: 0.8915\n",
      "Epoch 6/10, Train Loss: 0.1075, Accuracy: 0.9116, F1 Micro: 0.9116, F1 Macro: 0.9023\n",
      "Epoch 7/10, Train Loss: 0.1114, Accuracy: 0.8675, F1 Micro: 0.8675, F1 Macro: 0.8593\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.075, Accuracy: 0.9317, F1 Micro: 0.9317, F1 Macro: 0.9247\n",
      "Epoch 9/10, Train Loss: 0.0758, Accuracy: 0.9116, F1 Micro: 0.9116, F1 Macro: 0.9038\n",
      "Epoch 10/10, Train Loss: 0.076, Accuracy: 0.9076, F1 Micro: 0.9076, F1 Macro: 0.8997\n",
      "\n",
      "Sentiment analysis accuracy: 0.9317, F1 Micro: 0.9317, F1 Macro: 0.9247\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.99      0.90        79\n",
      "    positive       0.99      0.91      0.95       170\n",
      "\n",
      "    accuracy                           0.93       249\n",
      "   macro avg       0.91      0.95      0.92       249\n",
      "weighted avg       0.94      0.93      0.93       249\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 274: Accuracy: 0.9329, F1 Micro: 0.9329, F1 Macro: 0.8601\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       1.00      0.83      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.88      0.80        16\n",
      "     neutral       0.95      0.97      0.96       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.86      0.86      0.85       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.31      0.75      0.44        12\n",
      "     neutral       0.93      0.91      0.92       152\n",
      "    positive       0.82      0.60      0.69        52\n",
      "\n",
      "    accuracy                           0.82       216\n",
      "   macro avg       0.68      0.75      0.68       216\n",
      "weighted avg       0.87      0.82      0.84       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.97      0.96      0.96       152\n",
      "    positive       0.92      0.80      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.92      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.85      0.81        13\n",
      "     neutral       0.98      0.98      0.98       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.88      0.88      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.97      1.00      0.99       185\n",
      "    positive       1.00      0.71      0.83        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.97      0.88      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 82.14562559127808 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 59\n",
      "Sampling duration: 12.877203702926636 seconds\n",
      "New train size: 333\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5842, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Epoch 2/10, Train Loss: 0.5095, Accuracy: 0.7887, F1 Micro: 0.8819, F1 Macro: 0.8804\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4421, Accuracy: 0.8333, F1 Micro: 0.9029, F1 Macro: 0.9023\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3902, Accuracy: 0.8914, F1 Micro: 0.9346, F1 Macro: 0.934\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2999, Accuracy: 0.9368, F1 Micro: 0.9608, F1 Macro: 0.9593\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2368, Accuracy: 0.9457, F1 Micro: 0.9663, F1 Macro: 0.9649\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1916, Accuracy: 0.9487, F1 Micro: 0.968, F1 Macro: 0.9661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1546, Accuracy: 0.9524, F1 Micro: 0.9701, F1 Macro: 0.9685\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1264, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9723\n",
      "Epoch 10/10, Train Loss: 0.1046, Accuracy: 0.9531, F1 Micro: 0.9706, F1 Macro: 0.9694\n",
      "\n",
      "Aspect detection accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9723\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.89      0.97      0.93       158\n",
      "        part       0.97      0.97      0.97       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.97      1061\n",
      "   macro avg       0.96      0.99      0.97      1061\n",
      "weighted avg       0.96      0.99      0.97      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5716, Accuracy: 0.7439, F1 Micro: 0.7439, F1 Macro: 0.6076\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.27, Accuracy: 0.8943, F1 Micro: 0.8943, F1 Macro: 0.8871\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1422, Accuracy: 0.939, F1 Micro: 0.939, F1 Macro: 0.932\n",
      "Epoch 4/10, Train Loss: 0.1485, Accuracy: 0.9187, F1 Micro: 0.9187, F1 Macro: 0.912\n",
      "Epoch 5/10, Train Loss: 0.1389, Accuracy: 0.8943, F1 Micro: 0.8943, F1 Macro: 0.8876\n",
      "Epoch 6/10, Train Loss: 0.1057, Accuracy: 0.9106, F1 Micro: 0.9106, F1 Macro: 0.9041\n",
      "Epoch 7/10, Train Loss: 0.072, Accuracy: 0.9268, F1 Micro: 0.9268, F1 Macro: 0.92\n",
      "Epoch 8/10, Train Loss: 0.0636, Accuracy: 0.9309, F1 Micro: 0.9309, F1 Macro: 0.9242\n",
      "Epoch 9/10, Train Loss: 0.0687, Accuracy: 0.9268, F1 Micro: 0.9268, F1 Macro: 0.9195\n",
      "Epoch 10/10, Train Loss: 0.057, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9166\n",
      "\n",
      "Sentiment analysis accuracy: 0.939, F1 Micro: 0.939, F1 Macro: 0.932\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.94      0.91        81\n",
      "    positive       0.97      0.94      0.95       165\n",
      "\n",
      "    accuracy                           0.94       246\n",
      "   macro avg       0.93      0.94      0.93       246\n",
      "weighted avg       0.94      0.94      0.94       246\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 333: Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.8689\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       1.00      0.88      0.93        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.58      0.88      0.70        16\n",
      "     neutral       0.96      0.95      0.95       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.82      0.85      0.82       216\n",
      "weighted avg       0.92      0.91      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.53      0.75      0.62        12\n",
      "     neutral       0.90      0.96      0.93       152\n",
      "    positive       0.89      0.63      0.74        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.77      0.78      0.76       216\n",
      "weighted avg       0.88      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.93      0.91       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.77      0.71        13\n",
      "     neutral       0.98      0.98      0.98       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.84      0.84      0.84       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.93        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.76      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 81.60878419876099 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 54\n",
      "Sampling duration: 11.951617240905762 seconds\n",
      "New train size: 387\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5672, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4924, Accuracy: 0.8095, F1 Micro: 0.892, F1 Macro: 0.891\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4181, Accuracy: 0.8586, F1 Micro: 0.9172, F1 Macro: 0.9164\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3292, Accuracy: 0.9256, F1 Micro: 0.9541, F1 Macro: 0.9524\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2498, Accuracy: 0.9442, F1 Micro: 0.9653, F1 Macro: 0.9635\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1868, Accuracy: 0.9531, F1 Micro: 0.9708, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1417, Accuracy: 0.9561, F1 Micro: 0.9725, F1 Macro: 0.9712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1263, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9714\n",
      "Epoch 9/10, Train Loss: 0.1041, Accuracy: 0.9554, F1 Micro: 0.972, F1 Macro: 0.9703\n",
      "Epoch 10/10, Train Loss: 0.0871, Accuracy: 0.9561, F1 Micro: 0.9726, F1 Macro: 0.9716\n",
      "\n",
      "Aspect detection accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.97      0.96       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.96      0.97      0.97       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5818, Accuracy: 0.8224, F1 Micro: 0.8224, F1 Macro: 0.7561\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2782, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.9058\n",
      "Epoch 3/10, Train Loss: 0.1659, Accuracy: 0.8919, F1 Micro: 0.8919, F1 Macro: 0.8826\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1604, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.9063\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1324, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9239\n",
      "Epoch 6/10, Train Loss: 0.1316, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9221\n",
      "Epoch 7/10, Train Loss: 0.1044, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9144\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.085, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9249\n",
      "Epoch 9/10, Train Loss: 0.0788, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9189\n",
      "Epoch 10/10, Train Loss: 0.072, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9176\n",
      "\n",
      "Sentiment analysis accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9249\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.93      0.90        81\n",
      "    positive       0.97      0.94      0.95       178\n",
      "\n",
      "    accuracy                           0.93       259\n",
      "   macro avg       0.92      0.93      0.92       259\n",
      "weighted avg       0.94      0.93      0.93       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 387: Accuracy: 0.9452, F1 Micro: 0.9452, F1 Macro: 0.8828\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       1.00      0.88      0.93        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.95      0.96      0.96       167\n",
      "    positive       0.79      0.82      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.84      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.93      0.94      0.93       152\n",
      "    positive       0.82      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.83      0.83      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.96      0.86        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       0.91      0.78      0.84        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.90      0.89       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.89      0.84      0.86       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      1.00      0.88        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.71      0.83        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.92      0.90      0.90       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 98.08819150924683 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 48\n",
      "Sampling duration: 11.036008358001709 seconds\n",
      "New train size: 435\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5701, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5011, Accuracy: 0.814, F1 Micro: 0.8942, F1 Macro: 0.8934\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4083, Accuracy: 0.8958, F1 Micro: 0.9373, F1 Macro: 0.9366\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3085, Accuracy: 0.9405, F1 Micro: 0.9632, F1 Macro: 0.9617\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2334, Accuracy: 0.9501, F1 Micro: 0.9688, F1 Macro: 0.9671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1771, Accuracy: 0.9509, F1 Micro: 0.9692, F1 Macro: 0.9671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1424, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9776\n",
      "Epoch 8/10, Train Loss: 0.1084, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9746\n",
      "Epoch 9/10, Train Loss: 0.0931, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9728\n",
      "Epoch 10/10, Train Loss: 0.0814, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9737\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9776\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.98      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5434, Accuracy: 0.8386, F1 Micro: 0.8386, F1 Macro: 0.797\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2848, Accuracy: 0.9055, F1 Micro: 0.9055, F1 Macro: 0.8973\n",
      "Epoch 3/10, Train Loss: 0.1324, Accuracy: 0.8622, F1 Micro: 0.8622, F1 Macro: 0.8554\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1213, Accuracy: 0.9055, F1 Micro: 0.9055, F1 Macro: 0.8967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1363, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9153\n",
      "Epoch 6/10, Train Loss: 0.1131, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.9063\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0948, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9293\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1046, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9293\n",
      "Epoch 9/10, Train Loss: 0.065, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9218\n",
      "Epoch 10/10, Train Loss: 0.0681, Accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.9107\n",
      "\n",
      "Sentiment analysis accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9293\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.93      0.91        83\n",
      "    positive       0.96      0.94      0.95       171\n",
      "\n",
      "    accuracy                           0.94       254\n",
      "   macro avg       0.92      0.93      0.93       254\n",
      "weighted avg       0.94      0.94      0.94       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 435: Accuracy: 0.9475, F1 Micro: 0.9475, F1 Macro: 0.8818\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       1.00      0.83      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.94      0.77        16\n",
      "     neutral       0.95      0.96      0.96       167\n",
      "    positive       0.96      0.70      0.81        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.85      0.87      0.84       216\n",
      "weighted avg       0.93      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.56      0.75      0.64        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.89      0.75      0.81        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.79      0.82      0.80       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.91       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.98      0.99       186\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.87      0.89      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 93.75382590293884 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 43\n",
      "Sampling duration: 9.812039136886597 seconds\n",
      "New train size: 478\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5563, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.476, Accuracy: 0.8192, F1 Micro: 0.8971, F1 Macro: 0.8963\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3795, Accuracy: 0.9174, F1 Micro: 0.9498, F1 Macro: 0.9485\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2712, Accuracy: 0.9472, F1 Micro: 0.9672, F1 Macro: 0.9656\n",
      "Epoch 5/10, Train Loss: 0.2126, Accuracy: 0.9472, F1 Micro: 0.967, F1 Macro: 0.9645\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1516, Accuracy: 0.9561, F1 Micro: 0.9726, F1 Macro: 0.9712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1297, Accuracy: 0.9568, F1 Micro: 0.9728, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1093, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9732\n",
      "Epoch 9/10, Train Loss: 0.0914, Accuracy: 0.9539, F1 Micro: 0.9709, F1 Macro: 0.9688\n",
      "Epoch 10/10, Train Loss: 0.075, Accuracy: 0.9576, F1 Micro: 0.9732, F1 Macro: 0.9713\n",
      "\n",
      "Aspect detection accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9732\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      0.99      0.96       175\n",
      "      others       0.92      0.95      0.93       158\n",
      "        part       0.96      0.99      0.97       158\n",
      "       price       0.98      0.98      0.98       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5837, Accuracy: 0.8849, F1 Micro: 0.8849, F1 Macro: 0.8629\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2681, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9343\n",
      "Epoch 3/10, Train Loss: 0.1865, Accuracy: 0.9008, F1 Micro: 0.9008, F1 Macro: 0.8932\n",
      "Epoch 4/10, Train Loss: 0.1268, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9256\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1225, Accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9425\n",
      "Epoch 6/10, Train Loss: 0.0852, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.9099\n",
      "Epoch 7/10, Train Loss: 0.0911, Accuracy: 0.9365, F1 Micro: 0.9365, F1 Macro: 0.929\n",
      "Epoch 8/10, Train Loss: 0.0758, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9264\n",
      "Epoch 9/10, Train Loss: 0.0603, Accuracy: 0.9365, F1 Micro: 0.9365, F1 Macro: 0.9305\n",
      "Epoch 10/10, Train Loss: 0.0538, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9343\n",
      "\n",
      "Sentiment analysis accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9425\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.96      0.92        82\n",
      "    positive       0.98      0.94      0.96       170\n",
      "\n",
      "    accuracy                           0.95       252\n",
      "   macro avg       0.93      0.95      0.94       252\n",
      "weighted avg       0.95      0.95      0.95       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 478: Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.8748\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.91      0.88      0.89        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.88      0.76        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.91      0.64      0.75        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.84      0.83      0.82       216\n",
      "weighted avg       0.93      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.45      0.83      0.59        12\n",
      "     neutral       0.94      0.89      0.92       152\n",
      "    positive       0.84      0.79      0.81        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.74      0.84      0.77       216\n",
      "weighted avg       0.89      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.97      0.98      0.97       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.92      0.91       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        13\n",
      "     neutral       0.98      0.98      0.98       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.88      0.86      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.93        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.94      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 93.34528303146362 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 39\n",
      "Sampling duration: 9.178536891937256 seconds\n",
      "New train size: 517\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5549, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4568, Accuracy: 0.8519, F1 Micro: 0.914, F1 Macro: 0.9137\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3568, Accuracy: 0.9338, F1 Micro: 0.9593, F1 Macro: 0.9577\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2433, Accuracy: 0.9405, F1 Micro: 0.9629, F1 Macro: 0.9613\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1865, Accuracy: 0.9546, F1 Micro: 0.9717, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1454, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1188, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9773\n",
      "Epoch 8/10, Train Loss: 0.0916, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9755\n",
      "Epoch 9/10, Train Loss: 0.0813, Accuracy: 0.9583, F1 Micro: 0.9737, F1 Macro: 0.9717\n",
      "Epoch 10/10, Train Loss: 0.066, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.97      0.94       158\n",
      "        part       0.99      0.97      0.98       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5418, Accuracy: 0.8452, F1 Micro: 0.8452, F1 Macro: 0.8027\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.27, Accuracy: 0.9365, F1 Micro: 0.9365, F1 Macro: 0.9277\n",
      "Epoch 3/10, Train Loss: 0.1659, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9252\n",
      "Epoch 4/10, Train Loss: 0.1543, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9252\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1163, Accuracy: 0.9365, F1 Micro: 0.9365, F1 Macro: 0.9294\n",
      "Epoch 6/10, Train Loss: 0.1004, Accuracy: 0.9127, F1 Micro: 0.9127, F1 Macro: 0.8971\n",
      "Epoch 7/10, Train Loss: 0.0761, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9229\n",
      "Epoch 8/10, Train Loss: 0.0756, Accuracy: 0.9246, F1 Micro: 0.9246, F1 Macro: 0.9164\n",
      "Epoch 9/10, Train Loss: 0.0644, Accuracy: 0.9246, F1 Micro: 0.9246, F1 Macro: 0.9173\n",
      "Epoch 10/10, Train Loss: 0.0603, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9243\n",
      "\n",
      "Sentiment analysis accuracy: 0.9365, F1 Micro: 0.9365, F1 Macro: 0.9294\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.96      0.91        81\n",
      "    positive       0.98      0.92      0.95       171\n",
      "\n",
      "    accuracy                           0.94       252\n",
      "   macro avg       0.92      0.94      0.93       252\n",
      "weighted avg       0.94      0.94      0.94       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 517: Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.887\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.91      0.88      0.89        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.84      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.56      0.75      0.64        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.91      0.77      0.83        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.80      0.82      0.80       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.99      0.97      0.98       152\n",
      "    positive       0.90      0.88      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.94      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.77      0.77        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.89      0.84      0.86       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.93      0.90        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.94      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 93.69522523880005 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 23\n",
      "Sampling duration: 8.129337072372437 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5546, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4683, Accuracy: 0.8296, F1 Micro: 0.9025, F1 Macro: 0.9019\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3603, Accuracy: 0.9308, F1 Micro: 0.9573, F1 Macro: 0.9555\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2584, Accuracy: 0.9516, F1 Micro: 0.9697, F1 Macro: 0.9678\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1893, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9733\n",
      "Epoch 6/10, Train Loss: 0.1513, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1212, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9762\n",
      "Epoch 8/10, Train Loss: 0.0955, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0805, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9775\n",
      "Epoch 10/10, Train Loss: 0.072, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9751\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9775\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5142, Accuracy: 0.8911, F1 Micro: 0.8911, F1 Macro: 0.8692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2793, Accuracy: 0.8988, F1 Micro: 0.8988, F1 Macro: 0.89\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.17, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9231\n",
      "Epoch 4/10, Train Loss: 0.1428, Accuracy: 0.9105, F1 Micro: 0.9105, F1 Macro: 0.9029\n",
      "Epoch 5/10, Train Loss: 0.1384, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9186\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1127, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9259\n",
      "Epoch 7/10, Train Loss: 0.1093, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.919\n",
      "Epoch 8/10, Train Loss: 0.0832, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9218\n",
      "Epoch 9/10, Train Loss: 0.0778, Accuracy: 0.9066, F1 Micro: 0.9066, F1 Macro: 0.8984\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0367, Accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9381\n",
      "\n",
      "Sentiment analysis accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9381\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        82\n",
      "    positive       0.97      0.95      0.96       175\n",
      "\n",
      "    accuracy                           0.95       257\n",
      "   macro avg       0.93      0.94      0.94       257\n",
      "weighted avg       0.95      0.95      0.95       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9005\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.91      0.88      0.89        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.84      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.56      0.75      0.64        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.88      0.81      0.84        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.79      0.83      0.80       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.92      0.83      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.90      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.88      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 102.49220728874207 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 33\n",
      "Sampling duration: 7.830230712890625 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.557, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4661, Accuracy: 0.8311, F1 Micro: 0.9032, F1 Macro: 0.9022\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3465, Accuracy: 0.9345, F1 Micro: 0.9593, F1 Macro: 0.9578\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2511, Accuracy: 0.9554, F1 Micro: 0.9722, F1 Macro: 0.9707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.176, Accuracy: 0.9583, F1 Micro: 0.974, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1388, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.975\n",
      "Epoch 7/10, Train Loss: 0.1088, Accuracy: 0.9606, F1 Micro: 0.9755, F1 Macro: 0.9744\n",
      "Epoch 8/10, Train Loss: 0.0913, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0736, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.066, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9756\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9756\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.94      0.92      0.93       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5229, Accuracy: 0.8496, F1 Micro: 0.8496, F1 Macro: 0.7985\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2253, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.924\n",
      "Epoch 3/10, Train Loss: 0.1736, Accuracy: 0.906, F1 Micro: 0.906, F1 Macro: 0.8969\n",
      "Epoch 4/10, Train Loss: 0.1449, Accuracy: 0.8985, F1 Micro: 0.8985, F1 Macro: 0.8897\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1307, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9321\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1147, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9313\n",
      "Epoch 7/10, Train Loss: 0.1107, Accuracy: 0.9211, F1 Micro: 0.9211, F1 Macro: 0.913\n",
      "Epoch 8/10, Train Loss: 0.0847, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.92\n",
      "Epoch 9/10, Train Loss: 0.0719, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.924\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.043, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9321\n",
      "\n",
      "Sentiment analysis accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9321\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.96      0.91        83\n",
      "    positive       0.98      0.93      0.96       183\n",
      "\n",
      "    accuracy                           0.94       266\n",
      "   macro avg       0.92      0.95      0.93       266\n",
      "weighted avg       0.94      0.94      0.94       266\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9073\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.85      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.95      0.92      0.93       152\n",
      "    positive       0.80      0.83      0.81        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.82      0.86      0.84       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.97      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.84      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 108.85363793373108 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 30\n",
      "Sampling duration: 7.216123819351196 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5432, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4528, Accuracy: 0.8348, F1 Micro: 0.9051, F1 Macro: 0.9046\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3375, Accuracy: 0.9368, F1 Micro: 0.9608, F1 Macro: 0.9588\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2272, Accuracy: 0.9509, F1 Micro: 0.9696, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1709, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.132, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.105, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9777\n",
      "Epoch 8/10, Train Loss: 0.0871, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9752\n",
      "Epoch 9/10, Train Loss: 0.0702, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9758\n",
      "Epoch 10/10, Train Loss: 0.0607, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9772\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9777\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.94      0.93      0.94       158\n",
      "        part       0.99      0.98      0.98       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4567, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.9025\n",
      "Epoch 2/10, Train Loss: 0.2661, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.9007\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1493, Accuracy: 0.9278, F1 Micro: 0.9278, F1 Macro: 0.92\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.151, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9354\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1098, Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.9437\n",
      "Epoch 6/10, Train Loss: 0.1151, Accuracy: 0.9202, F1 Micro: 0.9202, F1 Macro: 0.9125\n",
      "Epoch 7/10, Train Loss: 0.0918, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9358\n",
      "Epoch 8/10, Train Loss: 0.0869, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9358\n",
      "Epoch 9/10, Train Loss: 0.0745, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9276\n",
      "Epoch 10/10, Train Loss: 0.0509, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9276\n",
      "\n",
      "Sentiment analysis accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.9437\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.92        83\n",
      "    positive       0.98      0.95      0.96       180\n",
      "\n",
      "    accuracy                           0.95       263\n",
      "   macro avg       0.94      0.95      0.94       263\n",
      "weighted avg       0.95      0.95      0.95       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.8967\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      0.81      0.76        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.85      0.84      0.84       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.92      0.79        12\n",
      "     neutral       0.96      0.93      0.94       152\n",
      "    positive       0.81      0.83      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.82      0.89      0.85       216\n",
      "weighted avg       0.91      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      1.00      0.85        23\n",
      "     neutral       0.99      0.97      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.90      0.94      0.91       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.77      0.77        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.89      0.84      0.86       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 107.36988234519958 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 27\n",
      "Sampling duration: 6.453370571136475 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5557, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4484, Accuracy: 0.8519, F1 Micro: 0.9138, F1 Macro: 0.9132\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3199, Accuracy: 0.9368, F1 Micro: 0.9608, F1 Macro: 0.9589\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2144, Accuracy: 0.9531, F1 Micro: 0.9708, F1 Macro: 0.9697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1601, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1211, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9779\n",
      "Epoch 7/10, Train Loss: 0.1045, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9747\n",
      "Epoch 8/10, Train Loss: 0.0823, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9769\n",
      "Epoch 9/10, Train Loss: 0.0681, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9776\n",
      "Epoch 10/10, Train Loss: 0.0566, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9766\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9779\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.95      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4965, Accuracy: 0.8858, F1 Micro: 0.8858, F1 Macro: 0.8644\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.201, Accuracy: 0.8858, F1 Micro: 0.8858, F1 Macro: 0.8773\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.146, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9181\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1402, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9255\n",
      "Epoch 5/10, Train Loss: 0.1413, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9185\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.106, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9327\n",
      "Epoch 7/10, Train Loss: 0.0855, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9185\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.082, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9388\n",
      "Epoch 9/10, Train Loss: 0.0533, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.9058\n",
      "Epoch 10/10, Train Loss: 0.0724, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9343\n",
      "\n",
      "Sentiment analysis accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9388\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.98      0.92        82\n",
      "    positive       0.99      0.93      0.96       172\n",
      "\n",
      "    accuracy                           0.94       254\n",
      "   macro avg       0.93      0.95      0.94       254\n",
      "weighted avg       0.95      0.94      0.95       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.8954\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.91      0.87        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.93      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.88      0.80        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.86      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.83      0.62        12\n",
      "     neutral       0.94      0.91      0.93       152\n",
      "    positive       0.83      0.77      0.80        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.76      0.84      0.78       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.77      0.77        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.86      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 109.00021147727966 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 18\n",
      "Sampling duration: 5.950458288192749 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5358, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4432, Accuracy: 0.8996, F1 Micro: 0.9395, F1 Macro: 0.9384\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3037, Accuracy: 0.9405, F1 Micro: 0.9629, F1 Macro: 0.9612\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2076, Accuracy: 0.9568, F1 Micro: 0.9731, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1534, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1216, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0918, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9762\n",
      "Epoch 8/10, Train Loss: 0.0773, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9739\n",
      "Epoch 9/10, Train Loss: 0.0628, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0552, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9771\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.97      0.97       175\n",
      "      others       0.92      0.97      0.94       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5033, Accuracy: 0.8915, F1 Micro: 0.8915, F1 Macro: 0.8723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2183, Accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.9128\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1552, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9252\n",
      "Epoch 4/10, Train Loss: 0.1568, Accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.9151\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1081, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9348\n",
      "Epoch 6/10, Train Loss: 0.1038, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9314\n",
      "Epoch 7/10, Train Loss: 0.0944, Accuracy: 0.9147, F1 Micro: 0.9147, F1 Macro: 0.9071\n",
      "Epoch 8/10, Train Loss: 0.086, Accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.9151\n",
      "Epoch 9/10, Train Loss: 0.0702, Accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.9192\n",
      "Epoch 10/10, Train Loss: 0.0492, Accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.9179\n",
      "\n",
      "Sentiment analysis accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9348\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.95      0.91        83\n",
      "    positive       0.98      0.94      0.96       175\n",
      "\n",
      "    accuracy                           0.94       258\n",
      "   macro avg       0.93      0.94      0.93       258\n",
      "weighted avg       0.94      0.94      0.94       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9028\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.96      0.97      0.96       167\n",
      "    positive       0.81      0.79      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.86      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.92      0.97      0.95       152\n",
      "    positive       0.91      0.75      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.86      0.82      0.84       216\n",
      "weighted avg       0.91      0.91      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.93      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.91      0.84      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 114.42203879356384 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.668186187744141 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5453, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4398, Accuracy: 0.9122, F1 Micro: 0.9467, F1 Macro: 0.9453\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3049, Accuracy: 0.9479, F1 Micro: 0.9678, F1 Macro: 0.9662\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2053, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1495, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1177, Accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9785\n",
      "Epoch 7/10, Train Loss: 0.0898, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9737\n",
      "Epoch 8/10, Train Loss: 0.0762, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.976\n",
      "Epoch 9/10, Train Loss: 0.0637, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9765\n",
      "Epoch 10/10, Train Loss: 0.0524, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9785\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.93      0.96      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5117, Accuracy: 0.9249, F1 Micro: 0.9249, F1 Macro: 0.9129\n",
      "Epoch 2/10, Train Loss: 0.1833, Accuracy: 0.9051, F1 Micro: 0.9051, F1 Macro: 0.8975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1692, Accuracy: 0.9486, F1 Micro: 0.9486, F1 Macro: 0.9415\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.123, Accuracy: 0.9486, F1 Micro: 0.9486, F1 Macro: 0.9415\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.098, Accuracy: 0.9486, F1 Micro: 0.9486, F1 Macro: 0.9426\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1062, Accuracy: 0.9526, F1 Micro: 0.9526, F1 Macro: 0.9465\n",
      "Epoch 7/10, Train Loss: 0.0847, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9345\n",
      "Epoch 8/10, Train Loss: 0.0777, Accuracy: 0.913, F1 Micro: 0.913, F1 Macro: 0.9061\n",
      "Epoch 9/10, Train Loss: 0.0874, Accuracy: 0.9486, F1 Micro: 0.9486, F1 Macro: 0.9423\n",
      "Epoch 10/10, Train Loss: 0.0741, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9345\n",
      "\n",
      "Sentiment analysis accuracy: 0.9526, F1 Micro: 0.9526, F1 Macro: 0.9465\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93        82\n",
      "    positive       0.98      0.95      0.96       171\n",
      "\n",
      "    accuracy                           0.95       253\n",
      "   macro avg       0.94      0.95      0.95       253\n",
      "weighted avg       0.95      0.95      0.95       253\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.899\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.88      0.78        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.86      0.86      0.85       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.83      0.62        12\n",
      "     neutral       0.93      0.92      0.93       152\n",
      "    positive       0.87      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.77      0.84      0.79       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.85      0.79        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.89      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 113.72737431526184 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.150902271270752 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5391, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4472, Accuracy: 0.9055, F1 Micro: 0.9432, F1 Macro: 0.9424\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2981, Accuracy: 0.9464, F1 Micro: 0.9667, F1 Macro: 0.9649\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2033, Accuracy: 0.9531, F1 Micro: 0.9707, F1 Macro: 0.9687\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1398, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9748\n",
      "Epoch 6/10, Train Loss: 0.1164, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0947, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.073, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9774\n",
      "Epoch 9/10, Train Loss: 0.0633, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0566, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9786\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9786\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.95      0.93      0.94       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4668, Accuracy: 0.9179, F1 Micro: 0.9179, F1 Macro: 0.909\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2302, Accuracy: 0.9179, F1 Micro: 0.9179, F1 Macro: 0.9099\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1874, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9255\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1371, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9371\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1475, Accuracy: 0.9515, F1 Micro: 0.9515, F1 Macro: 0.9452\n",
      "Epoch 6/10, Train Loss: 0.1179, Accuracy: 0.9254, F1 Micro: 0.9254, F1 Macro: 0.9177\n",
      "Epoch 7/10, Train Loss: 0.0852, Accuracy: 0.9254, F1 Micro: 0.9254, F1 Macro: 0.9172\n",
      "Epoch 8/10, Train Loss: 0.0727, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.9287\n",
      "Epoch 9/10, Train Loss: 0.0653, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9212\n",
      "Epoch 10/10, Train Loss: 0.0573, Accuracy: 0.9254, F1 Micro: 0.9254, F1 Macro: 0.9172\n",
      "\n",
      "Sentiment analysis accuracy: 0.9515, F1 Micro: 0.9515, F1 Macro: 0.9452\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.93        86\n",
      "    positive       0.98      0.95      0.96       182\n",
      "\n",
      "    accuracy                           0.95       268\n",
      "   macro avg       0.94      0.95      0.95       268\n",
      "weighted avg       0.95      0.95      0.95       268\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9101\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.86      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.95      0.93      0.94       152\n",
      "    positive       0.78      0.83      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.83      0.86      0.85       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.98      0.99      0.99       152\n",
      "    positive       1.00      0.78      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.92      0.91       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 120.53428339958191 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.5912652015686035 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5445, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.429, Accuracy: 0.904, F1 Micro: 0.9416, F1 Macro: 0.9404\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2836, Accuracy: 0.9479, F1 Micro: 0.9676, F1 Macro: 0.9663\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1964, Accuracy: 0.9516, F1 Micro: 0.9696, F1 Macro: 0.9677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1404, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9747\n",
      "Epoch 6/10, Train Loss: 0.1129, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9724\n",
      "Epoch 7/10, Train Loss: 0.0908, Accuracy: 0.9591, F1 Micro: 0.9741, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0716, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9767\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0595, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.979\n",
      "Epoch 10/10, Train Loss: 0.0535, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9739\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.979\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.96      0.94       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5055, Accuracy: 0.9109, F1 Micro: 0.9109, F1 Macro: 0.9006\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2211, Accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.9183\n",
      "Epoch 3/10, Train Loss: 0.1431, Accuracy: 0.907, F1 Micro: 0.907, F1 Macro: 0.8991\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1512, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9261\n",
      "Epoch 5/10, Train Loss: 0.1279, Accuracy: 0.907, F1 Micro: 0.907, F1 Macro: 0.8991\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1066, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9314\n",
      "Epoch 7/10, Train Loss: 0.0939, Accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.9187\n",
      "Epoch 8/10, Train Loss: 0.0989, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.922\n",
      "Epoch 9/10, Train Loss: 0.0587, Accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.9187\n",
      "Epoch 10/10, Train Loss: 0.047, Accuracy: 0.9109, F1 Micro: 0.9109, F1 Macro: 0.9031\n",
      "\n",
      "Sentiment analysis accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9314\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.98      0.91        83\n",
      "    positive       0.99      0.92      0.95       175\n",
      "\n",
      "    accuracy                           0.94       258\n",
      "   macro avg       0.92      0.95      0.93       258\n",
      "weighted avg       0.94      0.94      0.94       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.946, F1 Micro: 0.946, F1 Macro: 0.882\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.96      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.81      0.79        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.86      0.84      0.85       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.45      0.83      0.59        12\n",
      "     neutral       0.93      0.91      0.92       152\n",
      "    positive       0.87      0.75      0.80        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.75      0.83      0.77       216\n",
      "weighted avg       0.89      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      1.00      0.84        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       1.00      0.78      0.88        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.92      0.90       216\n",
      "weighted avg       0.96      0.94      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.85      0.79        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.88      0.85      0.86       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 119.94617009162903 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.1274707317352295 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5317, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4175, Accuracy: 0.9062, F1 Micro: 0.9432, F1 Macro: 0.9418\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.27, Accuracy: 0.9501, F1 Micro: 0.9689, F1 Macro: 0.9669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1806, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1299, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9784\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0993, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9795\n",
      "Epoch 7/10, Train Loss: 0.0866, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9744\n",
      "Epoch 8/10, Train Loss: 0.0654, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9782\n",
      "Epoch 9/10, Train Loss: 0.0598, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9752\n",
      "Epoch 10/10, Train Loss: 0.0501, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9778\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9795\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.97      0.95       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4795, Accuracy: 0.9189, F1 Micro: 0.9189, F1 Macro: 0.9099\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2072, Accuracy: 0.9189, F1 Micro: 0.9189, F1 Macro: 0.9121\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1753, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9253\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.133, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9398\n",
      "Epoch 5/10, Train Loss: 0.1424, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9197\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1079, Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9439\n",
      "Epoch 7/10, Train Loss: 0.081, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9291\n",
      "Epoch 8/10, Train Loss: 0.0747, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9201\n",
      "Epoch 9/10, Train Loss: 0.0745, Accuracy: 0.9189, F1 Micro: 0.9189, F1 Macro: 0.9054\n",
      "Epoch 10/10, Train Loss: 0.064, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9262\n",
      "\n",
      "Sentiment analysis accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9439\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.93        85\n",
      "    positive       0.98      0.95      0.96       174\n",
      "\n",
      "    accuracy                           0.95       259\n",
      "   macro avg       0.94      0.95      0.94       259\n",
      "weighted avg       0.95      0.95      0.95       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9022\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.81      0.76      0.78        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.85      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.53      0.83      0.65        12\n",
      "     neutral       0.93      0.94      0.94       152\n",
      "    positive       0.91      0.77      0.83        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.79      0.85      0.81       216\n",
      "weighted avg       0.91      0.89      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.91      0.89        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.92      0.85      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.92      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 121.5842592716217 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 8\n",
      "Sampling duration: 3.5943684577941895 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5396, Accuracy: 0.7946, F1 Micro: 0.8849, F1 Macro: 0.8834\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4195, Accuracy: 0.9167, F1 Micro: 0.9494, F1 Macro: 0.9481\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2652, Accuracy: 0.9524, F1 Micro: 0.9705, F1 Macro: 0.9692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.185, Accuracy: 0.9621, F1 Micro: 0.9764, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1361, Accuracy: 0.9635, F1 Micro: 0.9773, F1 Macro: 0.9762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1061, Accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9805\n",
      "Epoch 7/10, Train Loss: 0.0863, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9798\n",
      "Epoch 8/10, Train Loss: 0.0692, Accuracy: 0.9695, F1 Micro: 0.9809, F1 Macro: 0.98\n",
      "Epoch 9/10, Train Loss: 0.0581, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9791\n",
      "Epoch 10/10, Train Loss: 0.0505, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9785\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9805\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.99      0.95       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4777, Accuracy: 0.8735, F1 Micro: 0.8735, F1 Macro: 0.8646\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2118, Accuracy: 0.913, F1 Micro: 0.913, F1 Macro: 0.8988\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1769, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9269\n",
      "Epoch 4/10, Train Loss: 0.1356, Accuracy: 0.9249, F1 Micro: 0.9249, F1 Macro: 0.9187\n",
      "Epoch 5/10, Train Loss: 0.1386, Accuracy: 0.9289, F1 Micro: 0.9289, F1 Macro: 0.9228\n",
      "Epoch 6/10, Train Loss: 0.0959, Accuracy: 0.913, F1 Micro: 0.913, F1 Macro: 0.9061\n",
      "Epoch 7/10, Train Loss: 0.0771, Accuracy: 0.9249, F1 Micro: 0.9249, F1 Macro: 0.9187\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0709, Accuracy: 0.9447, F1 Micro: 0.9447, F1 Macro: 0.9387\n",
      "Epoch 9/10, Train Loss: 0.0466, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9345\n",
      "Epoch 10/10, Train Loss: 0.0577, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9249\n",
      "\n",
      "Sentiment analysis accuracy: 0.9447, F1 Micro: 0.9447, F1 Macro: 0.9387\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.95      0.92        84\n",
      "    positive       0.98      0.94      0.96       169\n",
      "\n",
      "    accuracy                           0.94       253\n",
      "   macro avg       0.93      0.95      0.94       253\n",
      "weighted avg       0.95      0.94      0.95       253\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9018\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.86      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.48      0.83      0.61        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.93      0.77      0.84        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.78      0.85      0.79       216\n",
      "weighted avg       0.91      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.91      0.89        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.92      0.83      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.91      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.85      0.81        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 120.87795114517212 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.296614408493042 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5349, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4195, Accuracy: 0.9115, F1 Micro: 0.9467, F1 Macro: 0.9458\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2597, Accuracy: 0.9501, F1 Micro: 0.969, F1 Macro: 0.9673\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1764, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1238, Accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9776\n",
      "Epoch 6/10, Train Loss: 0.099, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9756\n",
      "Epoch 7/10, Train Loss: 0.081, Accuracy: 0.9621, F1 Micro: 0.9759, F1 Macro: 0.9736\n",
      "Epoch 8/10, Train Loss: 0.0712, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9765\n",
      "Epoch 9/10, Train Loss: 0.0569, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0465, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9784\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9784\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.94      0.93      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4593, Accuracy: 0.8872, F1 Micro: 0.8872, F1 Macro: 0.8783\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2031, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9335\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1442, Accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9415\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1495, Accuracy: 0.9511, F1 Micro: 0.9511, F1 Macro: 0.9446\n",
      "Epoch 5/10, Train Loss: 0.1146, Accuracy: 0.9361, F1 Micro: 0.9361, F1 Macro: 0.9292\n",
      "Epoch 6/10, Train Loss: 0.1161, Accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9402\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0996, Accuracy: 0.9586, F1 Micro: 0.9586, F1 Macro: 0.9532\n",
      "Epoch 8/10, Train Loss: 0.0727, Accuracy: 0.8985, F1 Micro: 0.8985, F1 Macro: 0.8902\n",
      "Epoch 9/10, Train Loss: 0.0789, Accuracy: 0.9248, F1 Micro: 0.9248, F1 Macro: 0.916\n",
      "Epoch 10/10, Train Loss: 0.0644, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9299\n",
      "\n",
      "Sentiment analysis accuracy: 0.9586, F1 Micro: 0.9586, F1 Macro: 0.9532\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        87\n",
      "    positive       0.97      0.97      0.97       179\n",
      "\n",
      "    accuracy                           0.96       266\n",
      "   macro avg       0.95      0.95      0.95       266\n",
      "weighted avg       0.96      0.96      0.96       266\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9118\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.92      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.88      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.81      0.79      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.84      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.94      0.93      0.93       152\n",
      "    positive       0.77      0.83      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.87      0.83      0.85       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.96      0.96        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.95      0.88      0.91        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.96      0.94      0.95       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.89      1.00      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 124.62419724464417 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.9026358127593994 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5226, Accuracy: 0.7939, F1 Micro: 0.8845, F1 Macro: 0.8831\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4111, Accuracy: 0.9234, F1 Micro: 0.9531, F1 Macro: 0.9516\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2517, Accuracy: 0.9561, F1 Micro: 0.9727, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1683, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9764\n",
      "Epoch 5/10, Train Loss: 0.1285, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0983, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9781\n",
      "Epoch 7/10, Train Loss: 0.0799, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9746\n",
      "Epoch 8/10, Train Loss: 0.0623, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0543, Accuracy: 0.9688, F1 Micro: 0.9802, F1 Macro: 0.9789\n",
      "Epoch 10/10, Train Loss: 0.0479, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9802, F1 Macro: 0.9789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4675, Accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.8951\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2066, Accuracy: 0.9446, F1 Micro: 0.9446, F1 Macro: 0.9381\n",
      "Epoch 3/10, Train Loss: 0.1657, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9306\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1658, Accuracy: 0.9446, F1 Micro: 0.9446, F1 Macro: 0.9381\n",
      "Epoch 5/10, Train Loss: 0.1274, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9291\n",
      "Epoch 6/10, Train Loss: 0.1082, Accuracy: 0.9299, F1 Micro: 0.9299, F1 Macro: 0.9212\n",
      "Epoch 7/10, Train Loss: 0.0942, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9295\n",
      "Epoch 8/10, Train Loss: 0.0773, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9243\n",
      "Epoch 9/10, Train Loss: 0.0603, Accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.8994\n",
      "Epoch 10/10, Train Loss: 0.0554, Accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.9143\n",
      "\n",
      "Sentiment analysis accuracy: 0.9446, F1 Micro: 0.9446, F1 Macro: 0.9381\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.97      0.92        87\n",
      "    positive       0.98      0.93      0.96       184\n",
      "\n",
      "    accuracy                           0.94       271\n",
      "   macro avg       0.93      0.95      0.94       271\n",
      "weighted avg       0.95      0.94      0.95       271\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.8994\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.97      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.88      0.82        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.87      0.87      0.87       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.48      0.83      0.61        12\n",
      "     neutral       0.93      0.88      0.91       152\n",
      "    positive       0.80      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.74      0.83      0.77       216\n",
      "weighted avg       0.87      0.86      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 124.50388693809509 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.347738027572632 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5307, Accuracy: 0.7954, F1 Micro: 0.8853, F1 Macro: 0.8838\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3947, Accuracy: 0.9308, F1 Micro: 0.9575, F1 Macro: 0.9563\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.256, Accuracy: 0.9546, F1 Micro: 0.9718, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1657, Accuracy: 0.9643, F1 Micro: 0.9777, F1 Macro: 0.9765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.132, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9774\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1011, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9789\n",
      "Epoch 7/10, Train Loss: 0.0809, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9782\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0644, Accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9805\n",
      "Epoch 9/10, Train Loss: 0.0565, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9793\n",
      "Epoch 10/10, Train Loss: 0.0492, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9775\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9805\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.98      0.95       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.486, Accuracy: 0.8696, F1 Micro: 0.8696, F1 Macro: 0.8628\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2762, Accuracy: 0.9289, F1 Micro: 0.9289, F1 Macro: 0.9212\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1473, Accuracy: 0.9289, F1 Micro: 0.9289, F1 Macro: 0.9224\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1117, Accuracy: 0.9447, F1 Micro: 0.9447, F1 Macro: 0.9387\n",
      "Epoch 5/10, Train Loss: 0.1054, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9334\n",
      "Epoch 6/10, Train Loss: 0.1262, Accuracy: 0.8893, F1 Micro: 0.8893, F1 Macro: 0.8825\n",
      "Epoch 7/10, Train Loss: 0.1066, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9345\n",
      "Epoch 8/10, Train Loss: 0.0531, Accuracy: 0.9368, F1 Micro: 0.9368, F1 Macro: 0.9283\n",
      "Epoch 9/10, Train Loss: 0.0606, Accuracy: 0.9051, F1 Micro: 0.9051, F1 Macro: 0.898\n",
      "Epoch 10/10, Train Loss: 0.0499, Accuracy: 0.9012, F1 Micro: 0.9012, F1 Macro: 0.8925\n",
      "\n",
      "Sentiment analysis accuracy: 0.9447, F1 Micro: 0.9447, F1 Macro: 0.9387\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        83\n",
      "    positive       0.98      0.94      0.96       170\n",
      "\n",
      "    accuracy                           0.94       253\n",
      "   macro avg       0.93      0.95      0.94       253\n",
      "weighted avg       0.95      0.94      0.95       253\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9475, F1 Micro: 0.9475, F1 Macro: 0.8769\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.81      0.72        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.83      0.84      0.83       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.45      0.75      0.56        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.91      0.77      0.83        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.76      0.82      0.78       216\n",
      "weighted avg       0.90      0.88      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.96      0.83        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.94      0.78      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.91      0.89       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.92      0.77        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.86      0.87      0.86       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 128.989994764328 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.8295156955718994 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.524, Accuracy: 0.7961, F1 Micro: 0.8856, F1 Macro: 0.8842\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3784, Accuracy: 0.9271, F1 Micro: 0.955, F1 Macro: 0.9527\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2385, Accuracy: 0.9546, F1 Micro: 0.9718, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1614, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9765\n",
      "Epoch 5/10, Train Loss: 0.1157, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0943, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9783\n",
      "Epoch 7/10, Train Loss: 0.0762, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9759\n",
      "Epoch 8/10, Train Loss: 0.0616, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9776\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0512, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9791\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0463, Accuracy: 0.971, F1 Micro: 0.9817, F1 Macro: 0.9807\n",
      "\n",
      "Aspect detection accuracy: 0.971, F1 Micro: 0.9817, F1 Macro: 0.9807\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.93      0.96      0.95       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.98      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4647, Accuracy: 0.9436, F1 Micro: 0.9436, F1 Macro: 0.9369\n",
      "Epoch 2/10, Train Loss: 0.2141, Accuracy: 0.9135, F1 Micro: 0.9135, F1 Macro: 0.9061\n",
      "Epoch 3/10, Train Loss: 0.1546, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9317\n",
      "Epoch 4/10, Train Loss: 0.1381, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9335\n",
      "Epoch 5/10, Train Loss: 0.1473, Accuracy: 0.8872, F1 Micro: 0.8872, F1 Macro: 0.8793\n",
      "Epoch 6/10, Train Loss: 0.0891, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9335\n",
      "Epoch 7/10, Train Loss: 0.1047, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9213\n",
      "Epoch 8/10, Train Loss: 0.0761, Accuracy: 0.9361, F1 Micro: 0.9361, F1 Macro: 0.9296\n",
      "Epoch 9/10, Train Loss: 0.065, Accuracy: 0.9211, F1 Micro: 0.9211, F1 Macro: 0.9134\n",
      "Epoch 10/10, Train Loss: 0.0794, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9256\n",
      "\n",
      "Sentiment analysis accuracy: 0.9436, F1 Micro: 0.9436, F1 Macro: 0.9369\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.95      0.92        86\n",
      "    positive       0.98      0.94      0.96       180\n",
      "\n",
      "    accuracy                           0.94       266\n",
      "   macro avg       0.93      0.95      0.94       266\n",
      "weighted avg       0.95      0.94      0.94       266\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9164\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.97      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.89      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.94      0.96      0.95       152\n",
      "    positive       0.87      0.79      0.83        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.86      0.86      0.86       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 126.31560611724854 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 8\n",
      "Sampling duration: 1.053222417831421 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.529, Accuracy: 0.8006, F1 Micro: 0.8879, F1 Macro: 0.8865\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3937, Accuracy: 0.9338, F1 Micro: 0.9589, F1 Macro: 0.9568\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2506, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1657, Accuracy: 0.9606, F1 Micro: 0.9754, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1227, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.09, Accuracy: 0.9702, F1 Micro: 0.9812, F1 Macro: 0.9801\n",
      "Epoch 7/10, Train Loss: 0.0771, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9798\n",
      "Epoch 8/10, Train Loss: 0.0637, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0484, Accuracy: 0.9747, F1 Micro: 0.9841, F1 Macro: 0.9833\n",
      "Epoch 10/10, Train Loss: 0.0457, Accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9795\n",
      "\n",
      "Aspect detection accuracy: 0.9747, F1 Micro: 0.9841, F1 Macro: 0.9833\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.94      0.97      0.96       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.98      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.98      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.479, Accuracy: 0.9245, F1 Micro: 0.9245, F1 Macro: 0.9159\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2153, Accuracy: 0.9321, F1 Micro: 0.9321, F1 Macro: 0.9251\n",
      "Epoch 3/10, Train Loss: 0.1706, Accuracy: 0.9208, F1 Micro: 0.9208, F1 Macro: 0.9137\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1419, Accuracy: 0.9321, F1 Micro: 0.9321, F1 Macro: 0.9243\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1132, Accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.9371\n",
      "Epoch 6/10, Train Loss: 0.1059, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.9215\n",
      "Epoch 7/10, Train Loss: 0.089, Accuracy: 0.9321, F1 Micro: 0.9321, F1 Macro: 0.9255\n",
      "Epoch 8/10, Train Loss: 0.0749, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.9215\n",
      "Epoch 9/10, Train Loss: 0.0745, Accuracy: 0.9321, F1 Micro: 0.9321, F1 Macro: 0.9243\n",
      "Epoch 10/10, Train Loss: 0.0593, Accuracy: 0.9321, F1 Micro: 0.9321, F1 Macro: 0.9247\n",
      "\n",
      "Sentiment analysis accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.9371\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.95      0.92        87\n",
      "    positive       0.98      0.94      0.96       178\n",
      "\n",
      "    accuracy                           0.94       265\n",
      "   macro avg       0.93      0.95      0.94       265\n",
      "weighted avg       0.95      0.94      0.94       265\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9164\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.89      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.83      0.62        12\n",
      "     neutral       0.95      0.94      0.94       152\n",
      "    positive       0.91      0.79      0.85        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.79      0.85      0.80       216\n",
      "weighted avg       0.91      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       1.00      0.80      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.93      0.91       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.89      0.94      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.95      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 131.8693540096283 s\n",
      "Total runtime: 2908.6184878349304 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[0], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f846dafa",
   "metadata": {
    "papermill": {
     "duration": 0.147339,
     "end_time": "2025-03-02T17:42:49.911739",
     "exception": false,
     "start_time": "2025-03-02T17:42:49.764400",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c1580e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 2\n",
      "Random seed: 81\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.647, Accuracy: 0.7054, F1 Micro: 0.8127, F1 Macro: 0.7262\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5731, Accuracy: 0.7374, F1 Micro: 0.8408, F1 Macro: 0.7949\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5493, Accuracy: 0.7917, F1 Micro: 0.8824, F1 Macro: 0.8802\n",
      "Epoch 4/10, Train Loss: 0.5049, Accuracy: 0.7894, F1 Micro: 0.8822, F1 Macro: 0.8807\n",
      "Epoch 5/10, Train Loss: 0.4781, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 6/10, Train Loss: 0.4364, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4061, Accuracy: 0.7902, F1 Micro: 0.8826, F1 Macro: 0.8811\n",
      "Epoch 8/10, Train Loss: 0.4421, Accuracy: 0.7902, F1 Micro: 0.8825, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.4208, Accuracy: 0.7939, F1 Micro: 0.8842, F1 Macro: 0.8826\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3864, Accuracy: 0.8036, F1 Micro: 0.8886, F1 Macro: 0.8869\n",
      "\n",
      "Aspect detection accuracy: 0.8036, F1 Micro: 0.8886, F1 Macro: 0.8869\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.79      1.00      0.88       175\n",
      "      others       0.78      0.95      0.86       158\n",
      "        part       0.71      1.00      0.83       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.80      0.99      0.89      1061\n",
      "   macro avg       0.80      0.99      0.89      1061\n",
      "weighted avg       0.81      0.99      0.89      1061\n",
      " samples avg       0.81      0.99      0.89      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6351, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5577, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5004, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4905, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4593, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4341, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4188, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2323, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2613, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2353, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "\n",
      "Sentiment analysis accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         3\n",
      "    positive       0.91      1.00      0.95        31\n",
      "\n",
      "    accuracy                           0.91        34\n",
      "   macro avg       0.46      0.50      0.48        34\n",
      "weighted avg       0.83      0.91      0.87        34\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.8009, F1 Micro: 0.8009, F1 Macro: 0.3313\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.78      1.00      0.88       167\n",
      "    positive       1.00      0.06      0.11        33\n",
      "\n",
      "    accuracy                           0.78       216\n",
      "   macro avg       0.59      0.35      0.33       216\n",
      "weighted avg       0.76      0.78      0.70       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.78      0.95      0.85       152\n",
      "    positive       0.65      0.38      0.48        52\n",
      "\n",
      "    accuracy                           0.76       216\n",
      "   macro avg       0.47      0.44      0.45       216\n",
      "weighted avg       0.70      0.76      0.72       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        23\n",
      "     neutral       0.71      1.00      0.83       152\n",
      "    positive       1.00      0.02      0.05        41\n",
      "\n",
      "    accuracy                           0.71       216\n",
      "   macro avg       0.57      0.34      0.29       216\n",
      "weighted avg       0.69      0.71      0.59       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 60.75916934013367 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 81\n",
      "Sampling duration: 12.803752899169922 seconds\n",
      "New train size: 135\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6019, Accuracy: 0.7939, F1 Micro: 0.8843, F1 Macro: 0.8828\n",
      "Epoch 2/10, Train Loss: 0.5087, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 3/10, Train Loss: 0.4912, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 4/10, Train Loss: 0.4678, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4064, Accuracy: 0.8013, F1 Micro: 0.8882, F1 Macro: 0.8868\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3727, Accuracy: 0.8408, F1 Micro: 0.9079, F1 Macro: 0.907\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3457, Accuracy: 0.8735, F1 Micro: 0.9244, F1 Macro: 0.9227\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2998, Accuracy: 0.8862, F1 Micro: 0.9306, F1 Macro: 0.9286\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2753, Accuracy: 0.907, F1 Micro: 0.9432, F1 Macro: 0.9413\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2221, Accuracy: 0.9137, F1 Micro: 0.9469, F1 Macro: 0.945\n",
      "\n",
      "Aspect detection accuracy: 0.9137, F1 Micro: 0.9469, F1 Macro: 0.945\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.94      1.00      0.97       187\n",
      "     machine       0.94      0.98      0.96       175\n",
      "      others       0.84      0.95      0.89       158\n",
      "        part       0.93      0.91      0.92       158\n",
      "       price       0.91      0.99      0.95       192\n",
      "     service       0.95      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.92      0.97      0.95      1061\n",
      "   macro avg       0.92      0.97      0.94      1061\n",
      "weighted avg       0.92      0.97      0.95      1061\n",
      " samples avg       0.92      0.97      0.94      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6965, Accuracy: 0.6901, F1 Micro: 0.6901, F1 Macro: 0.4225\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5869, Accuracy: 0.6901, F1 Micro: 0.6901, F1 Macro: 0.4225\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5192, Accuracy: 0.8122, F1 Micro: 0.8122, F1 Macro: 0.7577\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3838, Accuracy: 0.8404, F1 Micro: 0.8404, F1 Macro: 0.8251\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.26, Accuracy: 0.8592, F1 Micro: 0.8592, F1 Macro: 0.8437\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2092, Accuracy: 0.8826, F1 Micro: 0.8826, F1 Macro: 0.8645\n",
      "Epoch 7/10, Train Loss: 0.1656, Accuracy: 0.8498, F1 Micro: 0.8498, F1 Macro: 0.8363\n",
      "Epoch 8/10, Train Loss: 0.1089, Accuracy: 0.8732, F1 Micro: 0.8732, F1 Macro: 0.8579\n",
      "Epoch 9/10, Train Loss: 0.1778, Accuracy: 0.8638, F1 Micro: 0.8638, F1 Macro: 0.8494\n",
      "Epoch 10/10, Train Loss: 0.0705, Accuracy: 0.8685, F1 Micro: 0.8685, F1 Macro: 0.855\n",
      "\n",
      "Sentiment analysis accuracy: 0.8826, F1 Micro: 0.8826, F1 Macro: 0.8645\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.82      0.81        67\n",
      "    positive       0.92      0.91      0.91       146\n",
      "\n",
      "    accuracy                           0.88       213\n",
      "   macro avg       0.86      0.87      0.86       213\n",
      "weighted avg       0.88      0.88      0.88       213\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 135: Accuracy: 0.8989, F1 Micro: 0.8989, F1 Macro: 0.7758\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.95      1.00      0.97       181\n",
      "    positive       1.00      0.62      0.77        24\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.98      0.84      0.90       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.81      0.67      0.73        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.87      0.80      0.83       216\n",
      "weighted avg       0.91      0.92      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.35      0.50      0.41        12\n",
      "     neutral       0.85      0.95      0.90       152\n",
      "    positive       0.82      0.44      0.57        52\n",
      "\n",
      "    accuracy                           0.81       216\n",
      "   macro avg       0.67      0.63      0.63       216\n",
      "weighted avg       0.81      0.81      0.79       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.74      0.72        23\n",
      "     neutral       0.93      0.91      0.92       152\n",
      "    positive       0.71      0.73      0.72        41\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.78      0.80      0.79       216\n",
      "weighted avg       0.86      0.86      0.86       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.38      0.53        13\n",
      "     neutral       0.91      0.99      0.95       186\n",
      "    positive       0.75      0.35      0.48        17\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.83      0.58      0.65       216\n",
      "weighted avg       0.89      0.90      0.89       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.71      0.83        14\n",
      "     neutral       0.95      1.00      0.98       185\n",
      "    positive       0.92      0.65      0.76        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.96      0.79      0.86       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Total train time: 67.1448438167572 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 73\n",
      "Sampling duration: 14.95168685913086 seconds\n",
      "New train size: 208\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5969, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5152, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.496, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4594, Accuracy: 0.8088, F1 Micro: 0.8917, F1 Macro: 0.8904\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3922, Accuracy: 0.8653, F1 Micro: 0.9202, F1 Macro: 0.9191\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3328, Accuracy: 0.8884, F1 Micro: 0.9318, F1 Macro: 0.9297\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.281, Accuracy: 0.9122, F1 Micro: 0.9461, F1 Macro: 0.9441\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2356, Accuracy: 0.9256, F1 Micro: 0.954, F1 Macro: 0.9521\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2049, Accuracy: 0.9308, F1 Micro: 0.957, F1 Macro: 0.9551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1609, Accuracy: 0.9368, F1 Micro: 0.9605, F1 Macro: 0.959\n",
      "\n",
      "Aspect detection accuracy: 0.9368, F1 Micro: 0.9605, F1 Macro: 0.959\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.97      1.00      0.99       187\n",
      "     machine       0.94      0.97      0.95       175\n",
      "      others       0.87      0.94      0.90       158\n",
      "        part       0.96      0.96      0.96       158\n",
      "       price       0.98      0.97      0.98       192\n",
      "     service       0.95      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.95      0.97      0.96      1061\n",
      "   macro avg       0.95      0.97      0.96      1061\n",
      "weighted avg       0.95      0.97      0.96      1061\n",
      " samples avg       0.95      0.97      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5866, Accuracy: 0.6831, F1 Micro: 0.6831, F1 Macro: 0.4059\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5052, Accuracy: 0.8272, F1 Micro: 0.8272, F1 Macro: 0.7911\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2931, Accuracy: 0.8765, F1 Micro: 0.8765, F1 Macro: 0.8611\n",
      "Epoch 4/10, Train Loss: 0.1783, Accuracy: 0.8724, F1 Micro: 0.8724, F1 Macro: 0.8629\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1554, Accuracy: 0.893, F1 Micro: 0.893, F1 Macro: 0.8764\n",
      "Epoch 6/10, Train Loss: 0.1139, Accuracy: 0.8848, F1 Micro: 0.8848, F1 Macro: 0.8753\n",
      "Epoch 7/10, Train Loss: 0.1028, Accuracy: 0.8889, F1 Micro: 0.8889, F1 Macro: 0.8788\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.077, Accuracy: 0.9012, F1 Micro: 0.9012, F1 Macro: 0.8908\n",
      "Epoch 9/10, Train Loss: 0.1269, Accuracy: 0.8971, F1 Micro: 0.8971, F1 Macro: 0.8878\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0972, Accuracy: 0.9053, F1 Micro: 0.9053, F1 Macro: 0.8945\n",
      "\n",
      "Sentiment analysis accuracy: 0.9053, F1 Micro: 0.9053, F1 Macro: 0.8945\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.92      0.86        77\n",
      "    positive       0.96      0.90      0.93       166\n",
      "\n",
      "    accuracy                           0.91       243\n",
      "   macro avg       0.88      0.91      0.89       243\n",
      "weighted avg       0.91      0.91      0.91       243\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 208: Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.8531\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       1.00      0.83      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.94      0.96      0.95       167\n",
      "    positive       0.76      0.67      0.71        33\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.85      0.81      0.83       216\n",
      "weighted avg       0.90      0.91      0.90       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.75      0.67        12\n",
      "     neutral       0.87      0.94      0.91       152\n",
      "    positive       0.81      0.58      0.67        52\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.76      0.76      0.75       216\n",
      "weighted avg       0.84      0.84      0.84       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      0.78      0.75        23\n",
      "     neutral       0.95      0.96      0.96       152\n",
      "    positive       0.87      0.80      0.84        41\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.85      0.85      0.85       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.98      0.97      0.98       186\n",
      "    positive       0.75      0.88      0.81        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.88      0.87      0.87       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.95      1.00      0.98       185\n",
      "    positive       1.00      0.65      0.79        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.98      0.81      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Total train time: 83.41420722007751 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 66\n",
      "Sampling duration: 16.86156463623047 seconds\n",
      "New train size: 274\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5829, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5029, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4577, Accuracy: 0.8125, F1 Micro: 0.8938, F1 Macro: 0.8925\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4008, Accuracy: 0.8787, F1 Micro: 0.9278, F1 Macro: 0.9269\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3299, Accuracy: 0.9077, F1 Micro: 0.9434, F1 Macro: 0.9413\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2676, Accuracy: 0.9256, F1 Micro: 0.9542, F1 Macro: 0.9528\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2201, Accuracy: 0.9397, F1 Micro: 0.9627, F1 Macro: 0.9613\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1737, Accuracy: 0.9449, F1 Micro: 0.9658, F1 Macro: 0.9644\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1505, Accuracy: 0.9464, F1 Micro: 0.9666, F1 Macro: 0.9651\n",
      "Epoch 10/10, Train Loss: 0.1323, Accuracy: 0.9464, F1 Micro: 0.9665, F1 Macro: 0.9649\n",
      "\n",
      "Aspect detection accuracy: 0.9464, F1 Micro: 0.9666, F1 Macro: 0.9651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.94      0.99      0.96       175\n",
      "      others       0.88      0.93      0.90       158\n",
      "        part       0.95      0.99      0.97       158\n",
      "       price       0.97      0.98      0.98       192\n",
      "     service       0.97      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.95      0.98      0.97      1061\n",
      "   macro avg       0.95      0.98      0.97      1061\n",
      "weighted avg       0.95      0.98      0.97      1061\n",
      " samples avg       0.95      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6264, Accuracy: 0.6681, F1 Micro: 0.6681, F1 Macro: 0.4005\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5044, Accuracy: 0.8613, F1 Micro: 0.8613, F1 Macro: 0.8494\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2748, Accuracy: 0.9076, F1 Micro: 0.9076, F1 Macro: 0.9004\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1622, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9296\n",
      "Epoch 5/10, Train Loss: 0.133, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9256\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0887, Accuracy: 0.9496, F1 Micro: 0.9496, F1 Macro: 0.9448\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0934, Accuracy: 0.9496, F1 Micro: 0.9496, F1 Macro: 0.9435\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0653, Accuracy: 0.9538, F1 Micro: 0.9538, F1 Macro: 0.949\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.099, Accuracy: 0.9538, F1 Micro: 0.9538, F1 Macro: 0.9481\n",
      "Epoch 10/10, Train Loss: 0.0371, Accuracy: 0.9454, F1 Micro: 0.9454, F1 Macro: 0.94\n",
      "\n",
      "Sentiment analysis accuracy: 0.9538, F1 Micro: 0.9538, F1 Macro: 0.9481\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.93        79\n",
      "    positive       0.97      0.96      0.97       159\n",
      "\n",
      "    accuracy                           0.95       238\n",
      "   macro avg       0.95      0.95      0.95       238\n",
      "weighted avg       0.95      0.95      0.95       238\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 274: Accuracy: 0.936, F1 Micro: 0.936, F1 Macro: 0.8727\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.94      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.88      0.64      0.74        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.88      0.81      0.84       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.53      0.83      0.65        12\n",
      "     neutral       0.90      0.92      0.91       152\n",
      "    positive       0.80      0.63      0.71        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.74      0.80      0.75       216\n",
      "weighted avg       0.85      0.85      0.85       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.96      0.86        23\n",
      "     neutral       0.96      0.98      0.97       152\n",
      "    positive       0.97      0.76      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.90      0.89       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        13\n",
      "     neutral       0.97      0.98      0.98       186\n",
      "    positive       0.76      0.76      0.76        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.86      0.84      0.85       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.97      1.00      0.99       185\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.99      0.89      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 91.89216685295105 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 59\n",
      "Sampling duration: 14.794066190719604 seconds\n",
      "New train size: 333\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5751, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.491, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4383, Accuracy: 0.8348, F1 Micro: 0.9051, F1 Macro: 0.9043\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3501, Accuracy: 0.9085, F1 Micro: 0.9444, F1 Macro: 0.9432\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2697, Accuracy: 0.9286, F1 Micro: 0.9563, F1 Macro: 0.9548\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2178, Accuracy: 0.9427, F1 Micro: 0.9644, F1 Macro: 0.9629\n",
      "Epoch 7/10, Train Loss: 0.169, Accuracy: 0.942, F1 Micro: 0.9637, F1 Macro: 0.9623\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.138, Accuracy: 0.9531, F1 Micro: 0.9707, F1 Macro: 0.9694\n",
      "Epoch 9/10, Train Loss: 0.1125, Accuracy: 0.9531, F1 Micro: 0.9707, F1 Macro: 0.9692\n",
      "Epoch 10/10, Train Loss: 0.095, Accuracy: 0.9531, F1 Micro: 0.9706, F1 Macro: 0.9689\n",
      "\n",
      "Aspect detection accuracy: 0.9531, F1 Micro: 0.9707, F1 Macro: 0.9694\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.94      0.99      0.96       175\n",
      "      others       0.90      0.93      0.92       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.97      0.98      0.98       192\n",
      "     service       0.97      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.581, Accuracy: 0.6816, F1 Micro: 0.6816, F1 Macro: 0.4288\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4285, Accuracy: 0.8816, F1 Micro: 0.8816, F1 Macro: 0.869\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.234, Accuracy: 0.9184, F1 Micro: 0.9184, F1 Macro: 0.9118\n",
      "Epoch 4/10, Train Loss: 0.1804, Accuracy: 0.8653, F1 Micro: 0.8653, F1 Macro: 0.8584\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1576, Accuracy: 0.9388, F1 Micro: 0.9388, F1 Macro: 0.9306\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.106, Accuracy: 0.9469, F1 Micro: 0.9469, F1 Macro: 0.9402\n",
      "Epoch 7/10, Train Loss: 0.1503, Accuracy: 0.8857, F1 Micro: 0.8857, F1 Macro: 0.8787\n",
      "Epoch 8/10, Train Loss: 0.096, Accuracy: 0.9388, F1 Micro: 0.9388, F1 Macro: 0.9326\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0928, Accuracy: 0.9551, F1 Micro: 0.9551, F1 Macro: 0.95\n",
      "Epoch 10/10, Train Loss: 0.0577, Accuracy: 0.8939, F1 Micro: 0.8939, F1 Macro: 0.8869\n",
      "\n",
      "Sentiment analysis accuracy: 0.9551, F1 Micro: 0.9551, F1 Macro: 0.95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.93        80\n",
      "    positive       0.99      0.95      0.97       165\n",
      "\n",
      "    accuracy                           0.96       245\n",
      "   macro avg       0.94      0.96      0.95       245\n",
      "weighted avg       0.96      0.96      0.96       245\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 333: Accuracy: 0.9321, F1 Micro: 0.9321, F1 Macro: 0.8491\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      1.00      0.79        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.67      0.80        24\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.88      0.89      0.86       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.88      0.80        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.95      0.61      0.74        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.88      0.82      0.83       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.48      0.83      0.61        12\n",
      "     neutral       0.92      0.90      0.91       152\n",
      "    positive       0.80      0.71      0.76        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.73      0.82      0.76       216\n",
      "weighted avg       0.87      0.85      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.66      1.00      0.79        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       1.00      0.73      0.85        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.90      0.87       216\n",
      "weighted avg       0.95      0.93      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.77      0.77        13\n",
      "     neutral       0.97      0.98      0.98       186\n",
      "    positive       0.80      0.71      0.75        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.85      0.82      0.83       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.97      1.00      0.99       185\n",
      "    positive       1.00      0.76      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.99      0.90      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 89.52635931968689 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 54\n",
      "Sampling duration: 13.813462257385254 seconds\n",
      "New train size: 387\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5509, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4727, Accuracy: 0.7991, F1 Micro: 0.8871, F1 Macro: 0.8857\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3843, Accuracy: 0.8876, F1 Micro: 0.9324, F1 Macro: 0.9308\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.294, Accuracy: 0.9271, F1 Micro: 0.9552, F1 Macro: 0.9533\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2287, Accuracy: 0.9427, F1 Micro: 0.9644, F1 Macro: 0.9627\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1722, Accuracy: 0.9464, F1 Micro: 0.9665, F1 Macro: 0.9643\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1346, Accuracy: 0.9554, F1 Micro: 0.9721, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1101, Accuracy: 0.9561, F1 Micro: 0.9724, F1 Macro: 0.9713\n",
      "Epoch 9/10, Train Loss: 0.0912, Accuracy: 0.9546, F1 Micro: 0.9716, F1 Macro: 0.9707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0763, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.972\n",
      "\n",
      "Aspect detection accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.972\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.92      0.92      0.92       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.97      0.98      0.98       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.557, Accuracy: 0.6897, F1 Micro: 0.6897, F1 Macro: 0.4309\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2971, Accuracy: 0.9004, F1 Micro: 0.9004, F1 Macro: 0.8919\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1968, Accuracy: 0.9502, F1 Micro: 0.9502, F1 Macro: 0.9431\n",
      "Epoch 4/10, Train Loss: 0.1723, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9265\n",
      "Epoch 5/10, Train Loss: 0.1346, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.8998\n",
      "Epoch 6/10, Train Loss: 0.1087, Accuracy: 0.9425, F1 Micro: 0.9425, F1 Macro: 0.9344\n",
      "Epoch 7/10, Train Loss: 0.0939, Accuracy: 0.9272, F1 Micro: 0.9272, F1 Macro: 0.9201\n",
      "Epoch 8/10, Train Loss: 0.1249, Accuracy: 0.8927, F1 Micro: 0.8927, F1 Macro: 0.8847\n",
      "Epoch 9/10, Train Loss: 0.0706, Accuracy: 0.931, F1 Micro: 0.931, F1 Macro: 0.922\n",
      "Epoch 10/10, Train Loss: 0.0528, Accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.9081\n",
      "\n",
      "Sentiment analysis accuracy: 0.9502, F1 Micro: 0.9502, F1 Macro: 0.9431\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.94      0.92        83\n",
      "    positive       0.97      0.96      0.96       178\n",
      "\n",
      "    accuracy                           0.95       261\n",
      "   macro avg       0.94      0.95      0.94       261\n",
      "weighted avg       0.95      0.95      0.95       261\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 387: Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.8917\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.83      0.89        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.94      0.83        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       1.00      0.70      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.59      0.83      0.69        12\n",
      "     neutral       0.92      0.92      0.92       152\n",
      "    positive       0.81      0.73      0.77        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.77      0.83      0.79       216\n",
      "weighted avg       0.88      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.97      0.98      0.98       186\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.89      0.86      0.87       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 96.02003645896912 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 48\n",
      "Sampling duration: 12.569735288619995 seconds\n",
      "New train size: 435\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5508, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4743, Accuracy: 0.8088, F1 Micro: 0.892, F1 Macro: 0.8906\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3719, Accuracy: 0.9077, F1 Micro: 0.9438, F1 Macro: 0.9421\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.288, Accuracy: 0.9338, F1 Micro: 0.9592, F1 Macro: 0.9577\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2154, Accuracy: 0.9516, F1 Micro: 0.97, F1 Macro: 0.969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.17, Accuracy: 0.9531, F1 Micro: 0.9707, F1 Macro: 0.9695\n",
      "Epoch 7/10, Train Loss: 0.1285, Accuracy: 0.9509, F1 Micro: 0.9692, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1043, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0842, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0737, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9741\n",
      "\n",
      "Aspect detection accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9741\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.91      0.93      0.92       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.97      0.98      0.98       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5163, Accuracy: 0.7004, F1 Micro: 0.7004, F1 Macro: 0.4768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3216, Accuracy: 0.9183, F1 Micro: 0.9183, F1 Macro: 0.9105\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2055, Accuracy: 0.9222, F1 Micro: 0.9222, F1 Macro: 0.9126\n",
      "Epoch 4/10, Train Loss: 0.1576, Accuracy: 0.8599, F1 Micro: 0.8599, F1 Macro: 0.8527\n",
      "Epoch 5/10, Train Loss: 0.0983, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.9069\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.146, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9147\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0704, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9231\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0953, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9255\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0735, Accuracy: 0.9416, F1 Micro: 0.9416, F1 Macro: 0.9347\n",
      "Epoch 10/10, Train Loss: 0.0514, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9268\n",
      "\n",
      "Sentiment analysis accuracy: 0.9416, F1 Micro: 0.9416, F1 Macro: 0.9347\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.95      0.91        83\n",
      "    positive       0.98      0.94      0.96       174\n",
      "\n",
      "    accuracy                           0.94       257\n",
      "   macro avg       0.93      0.94      0.93       257\n",
      "weighted avg       0.94      0.94      0.94       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 435: Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.9033\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.88      0.93        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.83      0.74        12\n",
      "     neutral       0.92      0.93      0.93       152\n",
      "    positive       0.83      0.73      0.78        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.80      0.83      0.81       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.99      0.99       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.93      0.92       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.97      0.98      0.98       186\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.89      0.86      0.87       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.96      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 107.53464579582214 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 43\n",
      "Sampling duration: 11.73875880241394 seconds\n",
      "New train size: 478\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5427, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4614, Accuracy: 0.811, F1 Micro: 0.8931, F1 Macro: 0.8919\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3556, Accuracy: 0.9219, F1 Micro: 0.9519, F1 Macro: 0.9501\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2728, Accuracy: 0.9435, F1 Micro: 0.965, F1 Macro: 0.9641\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2028, Accuracy: 0.9531, F1 Micro: 0.9708, F1 Macro: 0.9695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1623, Accuracy: 0.9546, F1 Micro: 0.9716, F1 Macro: 0.9703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1287, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9733\n",
      "Epoch 8/10, Train Loss: 0.1015, Accuracy: 0.9561, F1 Micro: 0.9725, F1 Macro: 0.9709\n",
      "Epoch 9/10, Train Loss: 0.0792, Accuracy: 0.9516, F1 Micro: 0.9695, F1 Macro: 0.9666\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0709, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9734\n",
      "\n",
      "Aspect detection accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9734\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.91      0.93      0.92       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.98      0.98      0.98       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5895, Accuracy: 0.686, F1 Micro: 0.686, F1 Macro: 0.4185\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3294, Accuracy: 0.9031, F1 Micro: 0.9031, F1 Macro: 0.8947\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1879, Accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.9142\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1559, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.922\n",
      "Epoch 5/10, Train Loss: 0.1195, Accuracy: 0.9147, F1 Micro: 0.9147, F1 Macro: 0.9071\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.091, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9269\n",
      "Epoch 7/10, Train Loss: 0.0712, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.9173\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1056, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9298\n",
      "Epoch 9/10, Train Loss: 0.0788, Accuracy: 0.9186, F1 Micro: 0.9186, F1 Macro: 0.9102\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0627, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.934\n",
      "\n",
      "Sentiment analysis accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.934\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.94      0.91        82\n",
      "    positive       0.97      0.94      0.96       176\n",
      "\n",
      "    accuracy                           0.94       258\n",
      "   macro avg       0.93      0.94      0.93       258\n",
      "weighted avg       0.94      0.94      0.94       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 478: Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.9064\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.84      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.92      0.93      0.93       152\n",
      "    positive       0.80      0.75      0.77        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.82      0.81      0.82       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.98      0.98      0.98       186\n",
      "    positive       0.80      0.94      0.86        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.90      0.90      0.89       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.96      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 108.89808988571167 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 39\n",
      "Sampling duration: 10.638688087463379 seconds\n",
      "New train size: 517\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5452, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4553, Accuracy: 0.8534, F1 Micro: 0.9147, F1 Macro: 0.9138\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.325, Accuracy: 0.9226, F1 Micro: 0.9524, F1 Macro: 0.9503\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2355, Accuracy: 0.9472, F1 Micro: 0.9671, F1 Macro: 0.9653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1801, Accuracy: 0.9509, F1 Micro: 0.9695, F1 Macro: 0.9684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.132, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0967, Accuracy: 0.9583, F1 Micro: 0.9737, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0775, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9727\n",
      "Epoch 9/10, Train Loss: 0.0681, Accuracy: 0.9568, F1 Micro: 0.9728, F1 Macro: 0.9715\n",
      "Epoch 10/10, Train Loss: 0.0595, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9723\n",
      "\n",
      "Aspect detection accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9727\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.93      0.91      0.92       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.98      0.98       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5568, Accuracy: 0.683, F1 Micro: 0.683, F1 Macro: 0.4058\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.349, Accuracy: 0.9358, F1 Micro: 0.9358, F1 Macro: 0.9266\n",
      "Epoch 3/10, Train Loss: 0.1856, Accuracy: 0.8981, F1 Micro: 0.8981, F1 Macro: 0.889\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1643, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9303\n",
      "Epoch 5/10, Train Loss: 0.139, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.9207\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1096, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9298\n",
      "Epoch 7/10, Train Loss: 0.1253, Accuracy: 0.9245, F1 Micro: 0.9245, F1 Macro: 0.9168\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0737, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9319\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0846, Accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.9367\n",
      "Epoch 10/10, Train Loss: 0.0728, Accuracy: 0.9208, F1 Micro: 0.9208, F1 Macro: 0.9128\n",
      "\n",
      "Sentiment analysis accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.9367\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.98      0.92        84\n",
      "    positive       0.99      0.93      0.96       181\n",
      "\n",
      "    accuracy                           0.94       265\n",
      "   macro avg       0.93      0.95      0.94       265\n",
      "weighted avg       0.95      0.94      0.94       265\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 517: Accuracy: 0.9483, F1 Micro: 0.9483, F1 Macro: 0.8965\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.92      0.70      0.79        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.85      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.83      0.74        12\n",
      "     neutral       0.94      0.91      0.92       152\n",
      "    positive       0.78      0.81      0.79        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.79      0.85      0.82       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      1.00      0.84        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.97      0.76      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.91      0.89       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.85      0.79        13\n",
      "     neutral       0.98      0.98      0.98       186\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.84      0.86      0.85       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 113.2091977596283 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 23\n",
      "Sampling duration: 9.680122137069702 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5426, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4544, Accuracy: 0.8571, F1 Micro: 0.9167, F1 Macro: 0.9159\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3336, Accuracy: 0.9211, F1 Micro: 0.9515, F1 Macro: 0.9502\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2395, Accuracy: 0.9479, F1 Micro: 0.9676, F1 Macro: 0.9659\n",
      "Epoch 5/10, Train Loss: 0.1781, Accuracy: 0.9472, F1 Micro: 0.9668, F1 Macro: 0.9643\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1366, Accuracy: 0.9539, F1 Micro: 0.9711, F1 Macro: 0.9701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.105, Accuracy: 0.9568, F1 Micro: 0.9728, F1 Macro: 0.9714\n",
      "Epoch 8/10, Train Loss: 0.088, Accuracy: 0.9539, F1 Micro: 0.9709, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0689, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0621, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9749\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.89      0.97      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.97      0.98       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5574, Accuracy: 0.6824, F1 Micro: 0.6824, F1 Macro: 0.4387\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3232, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9348\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1864, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9399\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1792, Accuracy: 0.9569, F1 Micro: 0.9569, F1 Macro: 0.9516\n",
      "Epoch 5/10, Train Loss: 0.1429, Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9479\n",
      "Epoch 6/10, Train Loss: 0.1184, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9228\n",
      "Epoch 7/10, Train Loss: 0.0857, Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9479\n",
      "Epoch 8/10, Train Loss: 0.0826, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9393\n",
      "Epoch 9/10, Train Loss: 0.0694, Accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.9113\n",
      "Epoch 10/10, Train Loss: 0.0433, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9389\n",
      "\n",
      "Sentiment analysis accuracy: 0.9569, F1 Micro: 0.9569, F1 Macro: 0.9516\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.95      0.94        84\n",
      "    positive       0.98      0.96      0.97       171\n",
      "\n",
      "    accuracy                           0.96       255\n",
      "   macro avg       0.95      0.96      0.95       255\n",
      "weighted avg       0.96      0.96      0.96       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9086\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.87      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.90      0.97      0.93       152\n",
      "    positive       0.88      0.67      0.76        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.84      0.80      0.81       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.95      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.99      0.97      0.98       186\n",
      "    positive       0.71      0.88      0.79        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.87      0.90      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.96      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 110.51260685920715 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 33\n",
      "Sampling duration: 8.912781000137329 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5387, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4443, Accuracy: 0.8683, F1 Micro: 0.9223, F1 Macro: 0.9213\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3231, Accuracy: 0.9323, F1 Micro: 0.958, F1 Macro: 0.9565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2248, Accuracy: 0.9516, F1 Micro: 0.9701, F1 Macro: 0.9692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1756, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9724\n",
      "Epoch 6/10, Train Loss: 0.1276, Accuracy: 0.9561, F1 Micro: 0.9724, F1 Macro: 0.9711\n",
      "Epoch 7/10, Train Loss: 0.0998, Accuracy: 0.9546, F1 Micro: 0.9715, F1 Macro: 0.9697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0816, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9746\n",
      "Epoch 9/10, Train Loss: 0.0707, Accuracy: 0.9554, F1 Micro: 0.9718, F1 Macro: 0.9702\n",
      "Epoch 10/10, Train Loss: 0.0621, Accuracy: 0.9568, F1 Micro: 0.9728, F1 Macro: 0.9714\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9746\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.97      0.97       175\n",
      "      others       0.92      0.94      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      0.98      0.98       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5462, Accuracy: 0.8721, F1 Micro: 0.8721, F1 Macro: 0.8539\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2623, Accuracy: 0.8915, F1 Micro: 0.8915, F1 Macro: 0.8834\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1838, Accuracy: 0.907, F1 Micro: 0.907, F1 Macro: 0.8996\n",
      "Epoch 4/10, Train Loss: 0.1823, Accuracy: 0.8915, F1 Micro: 0.8915, F1 Macro: 0.8844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1262, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9277\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1183, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.928\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0904, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.928\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0881, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9273\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0682, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9273\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0742, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9277\n",
      "\n",
      "Sentiment analysis accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9277\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.98      0.91        84\n",
      "    positive       0.99      0.91      0.95       174\n",
      "\n",
      "    accuracy                           0.93       258\n",
      "   macro avg       0.92      0.94      0.93       258\n",
      "weighted avg       0.94      0.93      0.94       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9452, F1 Micro: 0.9452, F1 Macro: 0.8904\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.97      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.94      0.91        16\n",
      "     neutral       0.96      0.97      0.96       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.90      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.53      0.83      0.65        12\n",
      "     neutral       0.93      0.92      0.92       152\n",
      "    positive       0.85      0.75      0.80        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.77      0.83      0.79       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.96      0.80        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.90      0.88       216\n",
      "weighted avg       0.94      0.93      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.92      0.83        13\n",
      "     neutral       0.99      0.98      0.98       186\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.85      0.89      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 119.32661890983582 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 30\n",
      "Sampling duration: 8.201107025146484 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.542, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4391, Accuracy: 0.8891, F1 Micro: 0.934, F1 Macro: 0.9328\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3131, Accuracy: 0.939, F1 Micro: 0.9622, F1 Macro: 0.9608\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2195, Accuracy: 0.9546, F1 Micro: 0.9716, F1 Macro: 0.9701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1662, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.976\n",
      "Epoch 6/10, Train Loss: 0.1281, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9726\n",
      "Epoch 7/10, Train Loss: 0.0951, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9744\n",
      "Epoch 8/10, Train Loss: 0.079, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.975\n",
      "Epoch 9/10, Train Loss: 0.0673, Accuracy: 0.9561, F1 Micro: 0.9722, F1 Macro: 0.97\n",
      "Epoch 10/10, Train Loss: 0.0594, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9753\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.92      0.95      0.93       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.98      0.98      0.98       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5408, Accuracy: 0.8532, F1 Micro: 0.8532, F1 Macro: 0.8434\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2495, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.906\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.166, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9243\n",
      "Epoch 4/10, Train Loss: 0.1531, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9226\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1347, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9353\n",
      "Epoch 6/10, Train Loss: 0.1154, Accuracy: 0.9206, F1 Micro: 0.9206, F1 Macro: 0.9144\n",
      "Epoch 7/10, Train Loss: 0.0824, Accuracy: 0.9365, F1 Micro: 0.9365, F1 Macro: 0.9309\n",
      "Epoch 8/10, Train Loss: 0.0525, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9226\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0879, Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9392\n",
      "Epoch 10/10, Train Loss: 0.0653, Accuracy: 0.9365, F1 Micro: 0.9365, F1 Macro: 0.9309\n",
      "\n",
      "Sentiment analysis accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9392\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.98      0.92        84\n",
      "    positive       0.99      0.93      0.96       168\n",
      "\n",
      "    accuracy                           0.94       252\n",
      "   macro avg       0.93      0.95      0.94       252\n",
      "weighted avg       0.95      0.94      0.95       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.946, F1 Micro: 0.946, F1 Macro: 0.883\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.88      0.93        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.88      0.80        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.86      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.45      0.75      0.56        12\n",
      "     neutral       0.94      0.91      0.93       152\n",
      "    positive       0.85      0.79      0.82        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.75      0.82      0.77       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      1.00      0.82        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       1.00      0.78      0.88        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.92      0.89       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.98      0.98      0.98       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.88      0.89      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.93      0.90        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 112.02521347999573 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 27\n",
      "Sampling duration: 7.24763298034668 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5417, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4269, Accuracy: 0.8854, F1 Micro: 0.9313, F1 Macro: 0.93\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2989, Accuracy: 0.942, F1 Micro: 0.9643, F1 Macro: 0.9627\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2136, Accuracy: 0.9524, F1 Micro: 0.9704, F1 Macro: 0.9692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1529, Accuracy: 0.9598, F1 Micro: 0.9751, F1 Macro: 0.9743\n",
      "Epoch 6/10, Train Loss: 0.1176, Accuracy: 0.9583, F1 Micro: 0.9737, F1 Macro: 0.9718\n",
      "Epoch 7/10, Train Loss: 0.0907, Accuracy: 0.9583, F1 Micro: 0.9737, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0789, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9739\n",
      "Epoch 9/10, Train Loss: 0.0646, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0537, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9744\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9744\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.91      0.94      0.93       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5431, Accuracy: 0.8764, F1 Micro: 0.8764, F1 Macro: 0.8499\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3086, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.9077\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1862, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9398\n",
      "Epoch 4/10, Train Loss: 0.166, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9239\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1306, Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9436\n",
      "Epoch 6/10, Train Loss: 0.1211, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9356\n",
      "Epoch 7/10, Train Loss: 0.0791, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9401\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0841, Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9433\n",
      "Epoch 9/10, Train Loss: 0.0681, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9304\n",
      "Epoch 10/10, Train Loss: 0.0481, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9312\n",
      "\n",
      "Sentiment analysis accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9433\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.94      0.92        84\n",
      "    positive       0.97      0.95      0.96       175\n",
      "\n",
      "    accuracy                           0.95       259\n",
      "   macro avg       0.94      0.95      0.94       259\n",
      "weighted avg       0.95      0.95      0.95       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.9048\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.85      0.70      0.77        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.85      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.92      0.94      0.93       152\n",
      "    positive       0.81      0.75      0.78        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.83      0.81      0.82       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.94      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.96      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 122.59508180618286 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 18\n",
      "Sampling duration: 6.86273193359375 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5442, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4096, Accuracy: 0.9025, F1 Micro: 0.9406, F1 Macro: 0.9389\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2834, Accuracy: 0.9464, F1 Micro: 0.9669, F1 Macro: 0.9655\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1994, Accuracy: 0.9561, F1 Micro: 0.9726, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1395, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1117, Accuracy: 0.9665, F1 Micro: 0.9791, F1 Macro: 0.9782\n",
      "Epoch 7/10, Train Loss: 0.0888, Accuracy: 0.9591, F1 Micro: 0.9741, F1 Macro: 0.9723\n",
      "Epoch 8/10, Train Loss: 0.0747, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9745\n",
      "Epoch 9/10, Train Loss: 0.0576, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.973\n",
      "Epoch 10/10, Train Loss: 0.0509, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9732\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9791, F1 Macro: 0.9782\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.91      0.97      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5308, Accuracy: 0.8548, F1 Micro: 0.8548, F1 Macro: 0.8209\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2716, Accuracy: 0.9435, F1 Micro: 0.9435, F1 Macro: 0.9384\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1817, Accuracy: 0.9476, F1 Micro: 0.9476, F1 Macro: 0.9417\n",
      "Epoch 4/10, Train Loss: 0.1683, Accuracy: 0.9435, F1 Micro: 0.9435, F1 Macro: 0.9374\n",
      "Epoch 5/10, Train Loss: 0.153, Accuracy: 0.9435, F1 Micro: 0.9435, F1 Macro: 0.9354\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1586, Accuracy: 0.9556, F1 Micro: 0.9556, F1 Macro: 0.9512\n",
      "Epoch 7/10, Train Loss: 0.1139, Accuracy: 0.9476, F1 Micro: 0.9476, F1 Macro: 0.9423\n",
      "Epoch 8/10, Train Loss: 0.0875, Accuracy: 0.9315, F1 Micro: 0.9315, F1 Macro: 0.9261\n",
      "Epoch 9/10, Train Loss: 0.1074, Accuracy: 0.9435, F1 Micro: 0.9435, F1 Macro: 0.9387\n",
      "Epoch 10/10, Train Loss: 0.087, Accuracy: 0.9435, F1 Micro: 0.9435, F1 Macro: 0.9387\n",
      "\n",
      "Sentiment analysis accuracy: 0.9556, F1 Micro: 0.9556, F1 Macro: 0.9512\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        84\n",
      "    positive       0.98      0.95      0.97       164\n",
      "\n",
      "    accuracy                           0.96       248\n",
      "   macro avg       0.95      0.96      0.95       248\n",
      "weighted avg       0.96      0.96      0.96       248\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9475, F1 Micro: 0.9475, F1 Macro: 0.8911\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.97      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.88      0.78        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.92      0.67      0.77        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.85      0.84      0.84       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.39      0.75      0.51        12\n",
      "     neutral       0.93      0.91      0.92       152\n",
      "    positive       0.91      0.75      0.82        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.74      0.80      0.75       216\n",
      "weighted avg       0.89      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 120.43697118759155 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 6.218799114227295 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5405, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4114, Accuracy: 0.9055, F1 Micro: 0.9427, F1 Macro: 0.9415\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2796, Accuracy: 0.9516, F1 Micro: 0.9699, F1 Macro: 0.969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.197, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9732\n",
      "Epoch 5/10, Train Loss: 0.1357, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1099, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0907, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9746\n",
      "Epoch 8/10, Train Loss: 0.0714, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0554, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9768\n",
      "Epoch 10/10, Train Loss: 0.0488, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.95      0.93       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5359, Accuracy: 0.8828, F1 Micro: 0.8828, F1 Macro: 0.8586\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2775, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9291\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1709, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9304\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1351, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9352\n",
      "Epoch 5/10, Train Loss: 0.1619, Accuracy: 0.918, F1 Micro: 0.918, F1 Macro: 0.9061\n",
      "Epoch 6/10, Train Loss: 0.1565, Accuracy: 0.9258, F1 Micro: 0.9258, F1 Macro: 0.9192\n",
      "Epoch 7/10, Train Loss: 0.1213, Accuracy: 0.9297, F1 Micro: 0.9297, F1 Macro: 0.9203\n",
      "Epoch 8/10, Train Loss: 0.0949, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9307\n",
      "Epoch 9/10, Train Loss: 0.073, Accuracy: 0.9219, F1 Micro: 0.9219, F1 Macro: 0.9152\n",
      "Epoch 10/10, Train Loss: 0.0474, Accuracy: 0.9258, F1 Micro: 0.9258, F1 Macro: 0.918\n",
      "\n",
      "Sentiment analysis accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9352\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.96      0.92        84\n",
      "    positive       0.98      0.93      0.96       172\n",
      "\n",
      "    accuracy                           0.94       256\n",
      "   macro avg       0.93      0.95      0.94       256\n",
      "weighted avg       0.95      0.94      0.94       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.8879\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.91      0.87        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.84      0.85       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.45      0.75      0.56        12\n",
      "     neutral       0.93      0.91      0.92       152\n",
      "    positive       0.85      0.77      0.81        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.74      0.81      0.76       216\n",
      "weighted avg       0.88      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.96      0.85        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.94      0.78      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.91      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 128.14891743659973 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.593374013900757 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5342, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4244, Accuracy: 0.91, F1 Micro: 0.9445, F1 Macro: 0.9427\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2857, Accuracy: 0.9494, F1 Micro: 0.9687, F1 Macro: 0.9675\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1917, Accuracy: 0.9568, F1 Micro: 0.9732, F1 Macro: 0.9722\n",
      "Epoch 5/10, Train Loss: 0.1361, Accuracy: 0.9531, F1 Micro: 0.9704, F1 Macro: 0.9676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1091, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0872, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9762\n",
      "Epoch 8/10, Train Loss: 0.0743, Accuracy: 0.9576, F1 Micro: 0.9732, F1 Macro: 0.9716\n",
      "Epoch 9/10, Train Loss: 0.0618, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9745\n",
      "Epoch 10/10, Train Loss: 0.0519, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9744\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.90      0.97      0.93       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      0.98      0.98       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5653, Accuracy: 0.8373, F1 Micro: 0.8373, F1 Macro: 0.7886\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3013, Accuracy: 0.8889, F1 Micro: 0.8889, F1 Macro: 0.8822\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1929, Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9392\n",
      "Epoch 4/10, Train Loss: 0.1847, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9267\n",
      "Epoch 5/10, Train Loss: 0.1306, Accuracy: 0.9246, F1 Micro: 0.9246, F1 Macro: 0.9185\n",
      "Epoch 6/10, Train Loss: 0.1444, Accuracy: 0.9365, F1 Micro: 0.9365, F1 Macro: 0.9309\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0813, Accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9434\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0737, Accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9434\n",
      "Epoch 9/10, Train Loss: 0.0739, Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9382\n",
      "Epoch 10/10, Train Loss: 0.0469, Accuracy: 0.9246, F1 Micro: 0.9246, F1 Macro: 0.9185\n",
      "\n",
      "Sentiment analysis accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9434\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.98      0.93        84\n",
      "    positive       0.99      0.93      0.96       168\n",
      "\n",
      "    accuracy                           0.95       252\n",
      "   macro avg       0.93      0.96      0.94       252\n",
      "weighted avg       0.95      0.95      0.95       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9452, F1 Micro: 0.9452, F1 Macro: 0.8829\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.88      0.93        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.88      0.76        16\n",
      "     neutral       0.95      0.97      0.96       167\n",
      "    positive       0.88      0.67      0.76        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.83      0.84      0.83       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.75      0.60        12\n",
      "     neutral       0.91      0.94      0.93       152\n",
      "    positive       0.90      0.71      0.80        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.77      0.80      0.77       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      1.00      0.85        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.94      0.78      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.92      0.89       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.98      0.99       186\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.87      0.89      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 128.02353191375732 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.076412200927734 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5222, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3932, Accuracy: 0.9129, F1 Micro: 0.9456, F1 Macro: 0.9433\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2653, Accuracy: 0.9539, F1 Micro: 0.9714, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1893, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1441, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9758\n",
      "Epoch 6/10, Train Loss: 0.1058, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9751\n",
      "Epoch 7/10, Train Loss: 0.081, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9741\n",
      "Epoch 8/10, Train Loss: 0.0634, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0553, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0458, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.978\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.98      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5357, Accuracy: 0.8808, F1 Micro: 0.8808, F1 Macro: 0.8657\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.25, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9272\n",
      "Epoch 3/10, Train Loss: 0.1572, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.9084\n",
      "Epoch 4/10, Train Loss: 0.1397, Accuracy: 0.8885, F1 Micro: 0.8885, F1 Macro: 0.881\n",
      "Epoch 5/10, Train Loss: 0.1683, Accuracy: 0.9038, F1 Micro: 0.9038, F1 Macro: 0.8966\n",
      "Epoch 6/10, Train Loss: 0.1225, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9243\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1061, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9313\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1236, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9317\n",
      "Epoch 9/10, Train Loss: 0.0719, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9283\n",
      "Epoch 10/10, Train Loss: 0.0829, Accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.9005\n",
      "\n",
      "Sentiment analysis accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9317\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.95      0.91        85\n",
      "    positive       0.98      0.93      0.95       175\n",
      "\n",
      "    accuracy                           0.94       260\n",
      "   macro avg       0.92      0.94      0.93       260\n",
      "weighted avg       0.94      0.94      0.94       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.8967\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.88      0.93        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.88      0.82        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.85      0.67      0.75        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.86      0.84      0.84       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.75      0.69        12\n",
      "     neutral       0.92      0.96      0.94       152\n",
      "    positive       0.89      0.75      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.82      0.82      0.82       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.92      0.91       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.92      0.83        13\n",
      "     neutral       0.99      0.98      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.87      0.89      0.88       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 133.42713809013367 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.4960713386535645 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5187, Accuracy: 0.7961, F1 Micro: 0.8856, F1 Macro: 0.8842\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3861, Accuracy: 0.9189, F1 Micro: 0.9498, F1 Macro: 0.9479\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.27, Accuracy: 0.9435, F1 Micro: 0.9646, F1 Macro: 0.9627\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1872, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1332, Accuracy: 0.9621, F1 Micro: 0.9763, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1044, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0888, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0693, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9777\n",
      "Epoch 9/10, Train Loss: 0.0582, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9756\n",
      "Epoch 10/10, Train Loss: 0.0478, Accuracy: 0.9628, F1 Micro: 0.9764, F1 Macro: 0.9746\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9777\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.98      1.00      0.99       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5261, Accuracy: 0.8962, F1 Micro: 0.8962, F1 Macro: 0.8844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2515, Accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9402\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1863, Accuracy: 0.9538, F1 Micro: 0.9538, F1 Macro: 0.9487\n",
      "Epoch 4/10, Train Loss: 0.1416, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9324\n",
      "Epoch 5/10, Train Loss: 0.1382, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9343\n",
      "Epoch 6/10, Train Loss: 0.125, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9364\n",
      "Epoch 7/10, Train Loss: 0.1037, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9324\n",
      "Epoch 8/10, Train Loss: 0.0904, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9292\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0767, Accuracy: 0.9577, F1 Micro: 0.9577, F1 Macro: 0.9518\n",
      "Epoch 10/10, Train Loss: 0.074, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9324\n",
      "\n",
      "Sentiment analysis accuracy: 0.9577, F1 Micro: 0.9577, F1 Macro: 0.9518\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.93        85\n",
      "    positive       0.97      0.97      0.97       175\n",
      "\n",
      "    accuracy                           0.96       260\n",
      "   macro avg       0.95      0.95      0.95       260\n",
      "weighted avg       0.96      0.96      0.96       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9483, F1 Micro: 0.9483, F1 Macro: 0.8925\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.88      0.93        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.88      0.78        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.88      0.70      0.78        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.85      0.85      0.84       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.43      0.83      0.57        12\n",
      "     neutral       0.95      0.89      0.92       152\n",
      "    positive       0.82      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.74      0.84      0.77       216\n",
      "weighted avg       0.89      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      1.00      0.85        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       1.00      0.80      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.91       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.98      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.91      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 136.1249876022339 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 8\n",
      "Sampling duration: 3.888680934906006 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.53, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3987, Accuracy: 0.9189, F1 Micro: 0.9497, F1 Macro: 0.9471\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2578, Accuracy: 0.9554, F1 Micro: 0.9721, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1737, Accuracy: 0.9583, F1 Micro: 0.9741, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1336, Accuracy: 0.9635, F1 Micro: 0.9773, F1 Macro: 0.9766\n",
      "Epoch 6/10, Train Loss: 0.1046, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9733\n",
      "Epoch 7/10, Train Loss: 0.0762, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9749\n",
      "Epoch 8/10, Train Loss: 0.0619, Accuracy: 0.9583, F1 Micro: 0.9737, F1 Macro: 0.9721\n",
      "Epoch 9/10, Train Loss: 0.0527, Accuracy: 0.9613, F1 Micro: 0.9755, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0441, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.978\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.90      0.96      0.93       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5164, Accuracy: 0.8828, F1 Micro: 0.8828, F1 Macro: 0.8694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.275, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.927\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1963, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9394\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1675, Accuracy: 0.9531, F1 Micro: 0.9531, F1 Macro: 0.9475\n",
      "Epoch 5/10, Train Loss: 0.1272, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9287\n",
      "Epoch 6/10, Train Loss: 0.1202, Accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9436\n",
      "Epoch 7/10, Train Loss: 0.114, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9397\n",
      "Epoch 8/10, Train Loss: 0.0813, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9341\n",
      "Epoch 9/10, Train Loss: 0.1049, Accuracy: 0.9258, F1 Micro: 0.9258, F1 Macro: 0.9184\n",
      "Epoch 10/10, Train Loss: 0.0685, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9311\n",
      "\n",
      "Sentiment analysis accuracy: 0.9531, F1 Micro: 0.9531, F1 Macro: 0.9475\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93        84\n",
      "    positive       0.98      0.95      0.96       172\n",
      "\n",
      "    accuracy                           0.95       256\n",
      "   macro avg       0.94      0.95      0.95       256\n",
      "weighted avg       0.95      0.95      0.95       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9125\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.88      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.91      0.96      0.93       152\n",
      "    positive       0.88      0.73      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.85      0.81      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.99      0.99       152\n",
      "    positive       1.00      0.80      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.93      0.92       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 136.5915994644165 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.6417744159698486 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.521, Accuracy: 0.7961, F1 Micro: 0.8856, F1 Macro: 0.8842\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3788, Accuracy: 0.9256, F1 Micro: 0.9537, F1 Macro: 0.9516\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2419, Accuracy: 0.9524, F1 Micro: 0.9705, F1 Macro: 0.9694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1697, Accuracy: 0.9554, F1 Micro: 0.9721, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1297, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0927, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9763\n",
      "Epoch 7/10, Train Loss: 0.0775, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0643, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9763\n",
      "Epoch 9/10, Train Loss: 0.0516, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9735\n",
      "Epoch 10/10, Train Loss: 0.0451, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9763\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.94      0.92      0.93       158\n",
      "        part       0.98      0.97      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5184, Accuracy: 0.8963, F1 Micro: 0.8963, F1 Macro: 0.8774\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2799, Accuracy: 0.9148, F1 Micro: 0.9148, F1 Macro: 0.9003\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1843, Accuracy: 0.9296, F1 Micro: 0.9296, F1 Macro: 0.9223\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1357, Accuracy: 0.9296, F1 Micro: 0.9296, F1 Macro: 0.9223\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1332, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.933\n",
      "Epoch 6/10, Train Loss: 0.1288, Accuracy: 0.9111, F1 Micro: 0.9111, F1 Macro: 0.8976\n",
      "Epoch 7/10, Train Loss: 0.1183, Accuracy: 0.9296, F1 Micro: 0.9296, F1 Macro: 0.9219\n",
      "Epoch 8/10, Train Loss: 0.0674, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.929\n",
      "Epoch 9/10, Train Loss: 0.0764, Accuracy: 0.9296, F1 Micro: 0.9296, F1 Macro: 0.9223\n",
      "Epoch 10/10, Train Loss: 0.0444, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9262\n",
      "\n",
      "Sentiment analysis accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.933\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.93      0.91        87\n",
      "    positive       0.97      0.95      0.96       183\n",
      "\n",
      "    accuracy                           0.94       270\n",
      "   macro avg       0.93      0.94      0.93       270\n",
      "weighted avg       0.94      0.94      0.94       270\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9491, F1 Micro: 0.9491, F1 Macro: 0.899\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       1.00      0.88      0.93        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.88      0.80        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.92      0.70      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.85      0.85       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.95      0.91      0.93       152\n",
      "    positive       0.75      0.83      0.79        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.82      0.86      0.84       216\n",
      "weighted avg       0.89      0.88      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.98      0.97      0.97       152\n",
      "    positive       0.92      0.80      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.92      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.98      0.99       186\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.87      0.89      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 139.09636569023132 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.109198570251465 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5187, Accuracy: 0.7939, F1 Micro: 0.8845, F1 Macro: 0.883\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3755, Accuracy: 0.933, F1 Micro: 0.9584, F1 Macro: 0.9565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2446, Accuracy: 0.9561, F1 Micro: 0.9728, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1667, Accuracy: 0.9635, F1 Micro: 0.9773, F1 Macro: 0.9765\n",
      "Epoch 5/10, Train Loss: 0.1288, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0982, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.976\n",
      "Epoch 7/10, Train Loss: 0.0727, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0616, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9767\n",
      "Epoch 9/10, Train Loss: 0.0504, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.045, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9771\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.91      0.94      0.92       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5189, Accuracy: 0.8931, F1 Micro: 0.8931, F1 Macro: 0.8859\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2364, Accuracy: 0.9466, F1 Micro: 0.9466, F1 Macro: 0.9408\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1786, Accuracy: 0.9504, F1 Micro: 0.9504, F1 Macro: 0.9448\n",
      "Epoch 4/10, Train Loss: 0.1616, Accuracy: 0.9427, F1 Micro: 0.9427, F1 Macro: 0.9367\n",
      "Epoch 5/10, Train Loss: 0.1161, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.9327\n",
      "Epoch 6/10, Train Loss: 0.1079, Accuracy: 0.9275, F1 Micro: 0.9275, F1 Macro: 0.921\n",
      "Epoch 7/10, Train Loss: 0.1046, Accuracy: 0.9427, F1 Micro: 0.9427, F1 Macro: 0.936\n",
      "Epoch 8/10, Train Loss: 0.1014, Accuracy: 0.9466, F1 Micro: 0.9466, F1 Macro: 0.9411\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0597, Accuracy: 0.9618, F1 Micro: 0.9618, F1 Macro: 0.957\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0757, Accuracy: 0.9656, F1 Micro: 0.9656, F1 Macro: 0.9614\n",
      "\n",
      "Sentiment analysis accuracy: 0.9656, F1 Micro: 0.9656, F1 Macro: 0.9614\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.97      0.95        86\n",
      "    positive       0.98      0.97      0.97       176\n",
      "\n",
      "    accuracy                           0.97       262\n",
      "   macro avg       0.96      0.97      0.96       262\n",
      "weighted avg       0.97      0.97      0.97       262\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9328\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.88      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.92      0.94      0.93       152\n",
      "    positive       0.82      0.77      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.88      0.85      0.86       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.99      0.99       152\n",
      "    positive       1.00      0.85      0.92        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.95      0.94       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.93      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 141.9921259880066 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.4255530834198 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5285, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3708, Accuracy: 0.9315, F1 Micro: 0.9578, F1 Macro: 0.9561\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2353, Accuracy: 0.9561, F1 Micro: 0.9728, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1741, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1201, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9748\n",
      "Epoch 6/10, Train Loss: 0.0923, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0789, Accuracy: 0.9658, F1 Micro: 0.9783, F1 Macro: 0.9766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0617, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9797\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0494, Accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.98\n",
      "Epoch 10/10, Train Loss: 0.0447, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.978\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5067, Accuracy: 0.9278, F1 Micro: 0.9278, F1 Macro: 0.9186\n",
      "Epoch 2/10, Train Loss: 0.1924, Accuracy: 0.9049, F1 Micro: 0.9049, F1 Macro: 0.8977\n",
      "Epoch 3/10, Train Loss: 0.1504, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9114\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.159, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9288\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1362, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9372\n",
      "Epoch 6/10, Train Loss: 0.1094, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9331\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0896, Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.9452\n",
      "Epoch 8/10, Train Loss: 0.079, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9342\n",
      "Epoch 9/10, Train Loss: 0.0967, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9372\n",
      "Epoch 10/10, Train Loss: 0.0802, Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9409\n",
      "\n",
      "Sentiment analysis accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.9452\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.98      0.93        86\n",
      "    positive       0.99      0.94      0.96       177\n",
      "\n",
      "    accuracy                           0.95       263\n",
      "   macro avg       0.94      0.96      0.95       263\n",
      "weighted avg       0.95      0.95      0.95       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9128\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       1.00      0.96      0.98        24\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.99      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.99      0.98       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.88      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.48      0.83      0.61        12\n",
      "     neutral       0.94      0.90      0.92       152\n",
      "    positive       0.84      0.79      0.81        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.75      0.84      0.78       216\n",
      "weighted avg       0.89      0.87      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.91       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 144.00120639801025 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.8690392971038818 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5165, Accuracy: 0.7984, F1 Micro: 0.8868, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3663, Accuracy: 0.9442, F1 Micro: 0.9654, F1 Macro: 0.9641\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2378, Accuracy: 0.9554, F1 Micro: 0.9724, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1669, Accuracy: 0.9673, F1 Micro: 0.9796, F1 Macro: 0.9786\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1156, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9787\n",
      "Epoch 6/10, Train Loss: 0.0932, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0684, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9797\n",
      "Epoch 8/10, Train Loss: 0.0611, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9768\n",
      "Epoch 9/10, Train Loss: 0.0491, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0421, Accuracy: 0.971, F1 Micro: 0.9817, F1 Macro: 0.9804\n",
      "\n",
      "Aspect detection accuracy: 0.971, F1 Micro: 0.9817, F1 Macro: 0.9804\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.93      0.94      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.98      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.98      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.464, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9206\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2117, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9201\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1768, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9245\n",
      "Epoch 4/10, Train Loss: 0.172, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9201\n",
      "Epoch 5/10, Train Loss: 0.1197, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9206\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0877, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9241\n",
      "Epoch 7/10, Train Loss: 0.1002, Accuracy: 0.9205, F1 Micro: 0.9205, F1 Macro: 0.9131\n",
      "Epoch 8/10, Train Loss: 0.0835, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9206\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0473, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9285\n",
      "Epoch 10/10, Train Loss: 0.0629, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.9048\n",
      "\n",
      "Sentiment analysis accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9285\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.94      0.91        87\n",
      "    positive       0.97      0.93      0.95       177\n",
      "\n",
      "    accuracy                           0.94       264\n",
      "   macro avg       0.92      0.94      0.93       264\n",
      "weighted avg       0.94      0.94      0.94       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9027\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.91      0.87        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.88      0.82        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.87      0.87      0.87       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.93      0.94      0.94       152\n",
      "    positive       0.80      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.86      0.85      0.86       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.76      0.86        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.92      0.90       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 146.7133424282074 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 8\n",
      "Sampling duration: 1.0750386714935303 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5149, Accuracy: 0.7984, F1 Micro: 0.8868, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3683, Accuracy: 0.9278, F1 Micro: 0.9549, F1 Macro: 0.9522\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2338, Accuracy: 0.9531, F1 Micro: 0.9708, F1 Macro: 0.9691\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1567, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.122, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9762\n",
      "Epoch 6/10, Train Loss: 0.0922, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.073, Accuracy: 0.971, F1 Micro: 0.9818, F1 Macro: 0.9806\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0611, Accuracy: 0.9717, F1 Micro: 0.9822, F1 Macro: 0.981\n",
      "Epoch 9/10, Train Loss: 0.05, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9777\n",
      "Epoch 10/10, Train Loss: 0.0424, Accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9793\n",
      "\n",
      "Aspect detection accuracy: 0.9717, F1 Micro: 0.9822, F1 Macro: 0.981\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.92      0.95      0.93       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.512, Accuracy: 0.8919, F1 Micro: 0.8919, F1 Macro: 0.8802\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2201, Accuracy: 0.9035, F1 Micro: 0.9035, F1 Macro: 0.8968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1716, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9234\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1258, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9241\n",
      "Epoch 5/10, Train Loss: 0.1015, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9161\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.093, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9238\n",
      "Epoch 7/10, Train Loss: 0.1136, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9161\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0843, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9315\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0582, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9312\n",
      "Epoch 10/10, Train Loss: 0.0529, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9197\n",
      "\n",
      "Sentiment analysis accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9312\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.93      0.91        86\n",
      "    positive       0.96      0.94      0.95       173\n",
      "\n",
      "    accuracy                           0.94       259\n",
      "   macro avg       0.93      0.94      0.93       259\n",
      "weighted avg       0.94      0.94      0.94       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9011\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.88      0.82        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.87      0.87       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.59      0.83      0.69        12\n",
      "     neutral       0.94      0.93      0.93       152\n",
      "    positive       0.82      0.77      0.79        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.78      0.84      0.81       216\n",
      "weighted avg       0.89      0.88      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      1.00      0.84        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       1.00      0.78      0.88        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.92      0.90       216\n",
      "weighted avg       0.96      0.94      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 160.88706517219543 s\n",
      "Total runtime: 3152.5982661247253 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8701ef",
   "metadata": {
    "papermill": {
     "duration": 0.154453,
     "end_time": "2025-03-02T17:42:50.596716",
     "exception": false,
     "start_time": "2025-03-02T17:42:50.442263",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e49dbb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 3\n",
      "Random seed: 14\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6791, Accuracy: 0.7746, F1 Micro: 0.8722, F1 Macro: 0.8703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5752, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.512, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4609, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4635, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4127, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3898, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4151, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.396, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3746, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "\n",
      "Aspect detection accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.78      1.00      0.88       175\n",
      "      others       0.71      1.00      0.83       158\n",
      "        part       0.71      1.00      0.83       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.79      1.00      0.88      1061\n",
      "   macro avg       0.79      1.00      0.88      1061\n",
      "weighted avg       0.80      1.00      0.89      1061\n",
      " samples avg       0.79      1.00      0.88      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.8159, Accuracy: 0.3333, F1 Micro: 0.3333, F1 Macro: 0.25\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.6264, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5442, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5154, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4038, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3617, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3192, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2942, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3391, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2952, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "\n",
      "Sentiment analysis accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         1\n",
      "    positive       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.67         3\n",
      "   macro avg       0.33      0.50      0.40         3\n",
      "weighted avg       0.44      0.67      0.53         3\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.7909, F1 Micro: 0.7909, F1 Macro: 0.298\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.77      1.00      0.87       167\n",
      "    positive       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.77       216\n",
      "   macro avg       0.26      0.33      0.29       216\n",
      "weighted avg       0.60      0.77      0.67       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.71      1.00      0.83       152\n",
      "    positive       0.67      0.04      0.07        52\n",
      "\n",
      "    accuracy                           0.71       216\n",
      "   macro avg       0.46      0.35      0.30       216\n",
      "weighted avg       0.66      0.71      0.60       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        23\n",
      "     neutral       0.70      1.00      0.83       152\n",
      "    positive       0.00      0.00      0.00        41\n",
      "\n",
      "    accuracy                           0.70       216\n",
      "   macro avg       0.23      0.33      0.28       216\n",
      "weighted avg       0.50      0.70      0.58       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 64.2057626247406 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 81\n",
      "Sampling duration: 13.011516571044922 seconds\n",
      "New train size: 135\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6229, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5204, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4987, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.456, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4338, Accuracy: 0.8006, F1 Micro: 0.8877, F1 Macro: 0.8862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.411, Accuracy: 0.8199, F1 Micro: 0.8972, F1 Macro: 0.8957\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.355, Accuracy: 0.8467, F1 Micro: 0.91, F1 Macro: 0.9085\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3133, Accuracy: 0.8571, F1 Micro: 0.915, F1 Macro: 0.9134\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2677, Accuracy: 0.8787, F1 Micro: 0.9267, F1 Macro: 0.9251\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2293, Accuracy: 0.8862, F1 Micro: 0.9308, F1 Macro: 0.9285\n",
      "\n",
      "Aspect detection accuracy: 0.8862, F1 Micro: 0.9308, F1 Macro: 0.9285\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.89      1.00      0.94       187\n",
      "     machine       0.91      0.98      0.94       175\n",
      "      others       0.86      0.89      0.87       158\n",
      "        part       0.86      0.95      0.90       158\n",
      "       price       0.88      1.00      0.94       192\n",
      "     service       0.95      0.99      0.97       191\n",
      "\n",
      "   micro avg       0.89      0.97      0.93      1061\n",
      "   macro avg       0.89      0.97      0.93      1061\n",
      "weighted avg       0.90      0.97      0.93      1061\n",
      " samples avg       0.90      0.97      0.93      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6133, Accuracy: 0.7473, F1 Micro: 0.7473, F1 Macro: 0.4277\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5203, Accuracy: 0.7473, F1 Micro: 0.7473, F1 Macro: 0.4277\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4413, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.6684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3048, Accuracy: 0.8441, F1 Micro: 0.8441, F1 Macro: 0.7789\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2526, Accuracy: 0.8763, F1 Micro: 0.8763, F1 Macro: 0.8417\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1459, Accuracy: 0.8763, F1 Micro: 0.8763, F1 Macro: 0.8491\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0697, Accuracy: 0.8763, F1 Micro: 0.8763, F1 Macro: 0.8396\n",
      "Epoch 8/10, Train Loss: 0.0552, Accuracy: 0.8656, F1 Micro: 0.8656, F1 Macro: 0.8279\n",
      "Epoch 9/10, Train Loss: 0.0745, Accuracy: 0.8602, F1 Micro: 0.8602, F1 Macro: 0.8265\n",
      "Epoch 10/10, Train Loss: 0.0675, Accuracy: 0.8602, F1 Micro: 0.8602, F1 Macro: 0.8244\n",
      "\n",
      "Sentiment analysis accuracy: 0.8763, F1 Micro: 0.8763, F1 Macro: 0.8396\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.79      0.76        47\n",
      "    positive       0.93      0.91      0.92       139\n",
      "\n",
      "    accuracy                           0.88       186\n",
      "   macro avg       0.83      0.85      0.84       186\n",
      "weighted avg       0.88      0.88      0.88       186\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 135: Accuracy: 0.8742, F1 Micro: 0.8742, F1 Macro: 0.6694\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.18      0.29        11\n",
      "     neutral       0.90      1.00      0.95       181\n",
      "    positive       0.83      0.42      0.56        24\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.80      0.53      0.60       216\n",
      "weighted avg       0.88      0.89      0.87       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.56      0.67        16\n",
      "     neutral       0.91      0.98      0.95       167\n",
      "    positive       0.88      0.67      0.76        33\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.87      0.74      0.79       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.41      0.75      0.53        12\n",
      "     neutral       0.86      0.89      0.87       152\n",
      "    positive       0.76      0.54      0.63        52\n",
      "\n",
      "    accuracy                           0.80       216\n",
      "   macro avg       0.68      0.73      0.68       216\n",
      "weighted avg       0.81      0.80      0.80       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.52      0.67        23\n",
      "     neutral       0.86      0.95      0.90       152\n",
      "    positive       0.71      0.61      0.66        41\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.83      0.69      0.74       216\n",
      "weighted avg       0.84      0.84      0.83       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.88      1.00      0.94       186\n",
      "    positive       0.80      0.24      0.36        17\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.56      0.41      0.43       216\n",
      "weighted avg       0.82      0.88      0.84       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.43      0.60        14\n",
      "     neutral       0.95      0.99      0.97       185\n",
      "    positive       0.76      0.76      0.76        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.73      0.78       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Total train time: 74.06825137138367 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 73\n",
      "Sampling duration: 15.112831354141235 seconds\n",
      "New train size: 208\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5929, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5209, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4726, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4472, Accuracy: 0.8006, F1 Micro: 0.8877, F1 Macro: 0.8862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3857, Accuracy: 0.843, F1 Micro: 0.9085, F1 Macro: 0.9072\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3391, Accuracy: 0.8743, F1 Micro: 0.9253, F1 Macro: 0.9242\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2844, Accuracy: 0.9025, F1 Micro: 0.941, F1 Macro: 0.9394\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2317, Accuracy: 0.9226, F1 Micro: 0.9524, F1 Macro: 0.95\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1887, Accuracy: 0.936, F1 Micro: 0.9604, F1 Macro: 0.9584\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1622, Accuracy: 0.9368, F1 Micro: 0.9609, F1 Macro: 0.959\n",
      "\n",
      "Aspect detection accuracy: 0.9368, F1 Micro: 0.9609, F1 Macro: 0.959\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.96      0.99      0.98       187\n",
      "     machine       0.94      0.99      0.96       175\n",
      "      others       0.89      0.92      0.90       158\n",
      "        part       0.91      0.99      0.95       158\n",
      "       price       0.96      0.99      0.98       192\n",
      "     service       0.96      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.94      0.98      0.96      1061\n",
      "   macro avg       0.94      0.98      0.96      1061\n",
      "weighted avg       0.94      0.98      0.96      1061\n",
      " samples avg       0.94      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5903, Accuracy: 0.683, F1 Micro: 0.683, F1 Macro: 0.4058\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5251, Accuracy: 0.683, F1 Micro: 0.683, F1 Macro: 0.4058\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3671, Accuracy: 0.875, F1 Micro: 0.875, F1 Macro: 0.8389\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2177, Accuracy: 0.9509, F1 Micro: 0.9509, F1 Macro: 0.9443\n",
      "Epoch 5/10, Train Loss: 0.1864, Accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.9361\n",
      "Epoch 6/10, Train Loss: 0.1074, Accuracy: 0.942, F1 Micro: 0.942, F1 Macro: 0.9351\n",
      "Epoch 7/10, Train Loss: 0.0989, Accuracy: 0.933, F1 Micro: 0.933, F1 Macro: 0.9246\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0823, Accuracy: 0.9509, F1 Micro: 0.9509, F1 Macro: 0.9422\n",
      "Epoch 9/10, Train Loss: 0.0731, Accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.939\n",
      "Epoch 10/10, Train Loss: 0.0617, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9278\n",
      "\n",
      "Sentiment analysis accuracy: 0.9509, F1 Micro: 0.9509, F1 Macro: 0.9422\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.89      0.92        71\n",
      "    positive       0.95      0.98      0.96       153\n",
      "\n",
      "    accuracy                           0.95       224\n",
      "   macro avg       0.95      0.93      0.94       224\n",
      "weighted avg       0.95      0.95      0.95       224\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 208: Accuracy: 0.9282, F1 Micro: 0.9282, F1 Macro: 0.8462\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.45      0.59        11\n",
      "     neutral       0.96      0.99      0.98       181\n",
      "    positive       0.83      0.79      0.81        24\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.87      0.75      0.79       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.93      0.99      0.96       167\n",
      "    positive       0.92      0.70      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.93      0.81      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.89      0.92      0.91       152\n",
      "    positive       0.78      0.67      0.72        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.79      0.81      0.80       216\n",
      "weighted avg       0.85      0.86      0.85       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.74      0.83        23\n",
      "     neutral       0.91      0.99      0.95       152\n",
      "    positive       0.94      0.73      0.82        41\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.93      0.82      0.87       216\n",
      "weighted avg       0.92      0.92      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.96      0.99      0.98       186\n",
      "    positive       0.86      0.71      0.77        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.82      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.71      0.83        14\n",
      "     neutral       0.96      1.00      0.98       185\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.96      0.83      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Total train time: 77.83418226242065 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 66\n",
      "Sampling duration: 15.522682666778564 seconds\n",
      "New train size: 274\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5847, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5013, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4559, Accuracy: 0.7991, F1 Micro: 0.887, F1 Macro: 0.8856\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4086, Accuracy: 0.8497, F1 Micro: 0.9109, F1 Macro: 0.9091\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3385, Accuracy: 0.8958, F1 Micro: 0.9378, F1 Macro: 0.9365\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2695, Accuracy: 0.9338, F1 Micro: 0.9593, F1 Macro: 0.9579\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2067, Accuracy: 0.9382, F1 Micro: 0.9619, F1 Macro: 0.9605\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1684, Accuracy: 0.9405, F1 Micro: 0.9631, F1 Macro: 0.9614\n",
      "Epoch 9/10, Train Loss: 0.1417, Accuracy: 0.9368, F1 Micro: 0.9608, F1 Macro: 0.9586\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1163, Accuracy: 0.9479, F1 Micro: 0.9673, F1 Macro: 0.9654\n",
      "\n",
      "Aspect detection accuracy: 0.9479, F1 Micro: 0.9673, F1 Macro: 0.9654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.89      0.89      0.89       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.97      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.97      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.97      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6018, Accuracy: 0.6953, F1 Micro: 0.6953, F1 Macro: 0.4101\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4179, Accuracy: 0.8672, F1 Micro: 0.8672, F1 Macro: 0.8282\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2545, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9235\n",
      "Epoch 4/10, Train Loss: 0.1304, Accuracy: 0.9297, F1 Micro: 0.9297, F1 Macro: 0.9145\n",
      "Epoch 5/10, Train Loss: 0.1614, Accuracy: 0.8633, F1 Micro: 0.8633, F1 Macro: 0.8532\n",
      "Epoch 6/10, Train Loss: 0.1452, Accuracy: 0.9258, F1 Micro: 0.9258, F1 Macro: 0.9078\n",
      "Epoch 7/10, Train Loss: 0.1359, Accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.8923\n",
      "Epoch 8/10, Train Loss: 0.0895, Accuracy: 0.9102, F1 Micro: 0.9102, F1 Macro: 0.8984\n",
      "Epoch 9/10, Train Loss: 0.1385, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8909\n",
      "Epoch 10/10, Train Loss: 0.0647, Accuracy: 0.9141, F1 Micro: 0.9141, F1 Macro: 0.9007\n",
      "\n",
      "Sentiment analysis accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9235\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.94      0.90        78\n",
      "    positive       0.97      0.93      0.95       178\n",
      "\n",
      "    accuracy                           0.93       256\n",
      "   macro avg       0.91      0.93      0.92       256\n",
      "weighted avg       0.94      0.93      0.93       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 274: Accuracy: 0.9352, F1 Micro: 0.9352, F1 Macro: 0.8697\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.98      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.88      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.75      0.77        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.83      0.86       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.89      0.89      0.89       152\n",
      "    positive       0.72      0.69      0.71        52\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.78      0.81      0.79       216\n",
      "weighted avg       0.84      0.84      0.84       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.83      0.78        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.87      0.83      0.85        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.86      0.88      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.84      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.97      1.00      0.99       185\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.97      0.87      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 81.781240940094 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 59\n",
      "Sampling duration: 14.26069974899292 seconds\n",
      "New train size: 333\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5594, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5027, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4404, Accuracy: 0.8333, F1 Micro: 0.9039, F1 Macro: 0.9029\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3638, Accuracy: 0.8966, F1 Micro: 0.9382, F1 Macro: 0.9369\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.267, Accuracy: 0.9405, F1 Micro: 0.9633, F1 Macro: 0.9619\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2073, Accuracy: 0.9472, F1 Micro: 0.9672, F1 Macro: 0.9657\n",
      "Epoch 7/10, Train Loss: 0.1719, Accuracy: 0.9472, F1 Micro: 0.9671, F1 Macro: 0.9653\n",
      "Epoch 8/10, Train Loss: 0.1402, Accuracy: 0.9457, F1 Micro: 0.9661, F1 Macro: 0.9641\n",
      "Epoch 9/10, Train Loss: 0.1125, Accuracy: 0.9472, F1 Micro: 0.9668, F1 Macro: 0.9644\n",
      "Epoch 10/10, Train Loss: 0.1001, Accuracy: 0.9464, F1 Micro: 0.9663, F1 Macro: 0.9638\n",
      "\n",
      "Aspect detection accuracy: 0.9472, F1 Micro: 0.9672, F1 Macro: 0.9657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.94      1.00      0.97       175\n",
      "      others       0.87      0.96      0.91       158\n",
      "        part       0.96      0.96      0.96       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.96      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.95      0.99      0.97      1061\n",
      "   macro avg       0.95      0.98      0.97      1061\n",
      "weighted avg       0.95      0.99      0.97      1061\n",
      " samples avg       0.95      0.99      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6137, Accuracy: 0.6652, F1 Micro: 0.6652, F1 Macro: 0.3995\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4007, Accuracy: 0.8755, F1 Micro: 0.8755, F1 Macro: 0.8579\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2262, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9275\n",
      "Epoch 4/10, Train Loss: 0.188, Accuracy: 0.9099, F1 Micro: 0.9099, F1 Macro: 0.9035\n",
      "Epoch 5/10, Train Loss: 0.1762, Accuracy: 0.927, F1 Micro: 0.927, F1 Macro: 0.9149\n",
      "Epoch 6/10, Train Loss: 0.1518, Accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.9069\n",
      "Epoch 7/10, Train Loss: 0.08, Accuracy: 0.9227, F1 Micro: 0.9227, F1 Macro: 0.9095\n",
      "Epoch 8/10, Train Loss: 0.1284, Accuracy: 0.9185, F1 Micro: 0.9185, F1 Macro: 0.9109\n",
      "Epoch 9/10, Train Loss: 0.1347, Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.9219\n",
      "Epoch 10/10, Train Loss: 0.0959, Accuracy: 0.9185, F1 Micro: 0.9185, F1 Macro: 0.9118\n",
      "\n",
      "Sentiment analysis accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9275\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.90      0.90        78\n",
      "    positive       0.95      0.95      0.95       155\n",
      "\n",
      "    accuracy                           0.94       233\n",
      "   macro avg       0.93      0.93      0.93       233\n",
      "weighted avg       0.94      0.94      0.94       233\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 333: Accuracy: 0.9244, F1 Micro: 0.9244, F1 Macro: 0.8368\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.91      0.80        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.79      0.86        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.88      0.90      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.75      0.69        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.96      0.67      0.79        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.85      0.80      0.81       216\n",
      "weighted avg       0.93      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.26      0.83      0.39        12\n",
      "     neutral       0.93      0.87      0.90       152\n",
      "    positive       0.89      0.60      0.71        52\n",
      "\n",
      "    accuracy                           0.80       216\n",
      "   macro avg       0.69      0.77      0.67       216\n",
      "weighted avg       0.88      0.80      0.83       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.97      0.95      0.96       152\n",
      "    positive       0.86      0.78      0.82        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.91      0.88       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.98       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.86      0.86        14\n",
      "     neutral       0.97      1.00      0.99       185\n",
      "    positive       1.00      0.71      0.83        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.85      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 79.09469151496887 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 54\n",
      "Sampling duration: 12.264274835586548 seconds\n",
      "New train size: 387\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5556, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4814, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4321, Accuracy: 0.8557, F1 Micro: 0.9157, F1 Macro: 0.9147\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.332, Accuracy: 0.9182, F1 Micro: 0.9503, F1 Macro: 0.9497\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.249, Accuracy: 0.9449, F1 Micro: 0.966, F1 Macro: 0.9647\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1891, Accuracy: 0.9524, F1 Micro: 0.9705, F1 Macro: 0.9692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1497, Accuracy: 0.9531, F1 Micro: 0.9707, F1 Macro: 0.9692\n",
      "Epoch 8/10, Train Loss: 0.1174, Accuracy: 0.9494, F1 Micro: 0.9683, F1 Macro: 0.9666\n",
      "Epoch 9/10, Train Loss: 0.1039, Accuracy: 0.9531, F1 Micro: 0.9705, F1 Macro: 0.9687\n",
      "Epoch 10/10, Train Loss: 0.0855, Accuracy: 0.9524, F1 Micro: 0.9702, F1 Macro: 0.9687\n",
      "\n",
      "Aspect detection accuracy: 0.9531, F1 Micro: 0.9707, F1 Macro: 0.9692\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.93      1.00      0.96       175\n",
      "      others       0.90      0.92      0.91       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.544, Accuracy: 0.6816, F1 Micro: 0.6816, F1 Macro: 0.4174\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3703, Accuracy: 0.9102, F1 Micro: 0.9102, F1 Macro: 0.8998\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1761, Accuracy: 0.9429, F1 Micro: 0.9429, F1 Macro: 0.9366\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1407, Accuracy: 0.9551, F1 Micro: 0.9551, F1 Macro: 0.9481\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.105, Accuracy: 0.9592, F1 Micro: 0.9592, F1 Macro: 0.9527\n",
      "Epoch 6/10, Train Loss: 0.1071, Accuracy: 0.9469, F1 Micro: 0.9469, F1 Macro: 0.9413\n",
      "Epoch 7/10, Train Loss: 0.0676, Accuracy: 0.9306, F1 Micro: 0.9306, F1 Macro: 0.9241\n",
      "Epoch 8/10, Train Loss: 0.0765, Accuracy: 0.951, F1 Micro: 0.951, F1 Macro: 0.9457\n",
      "Epoch 9/10, Train Loss: 0.0601, Accuracy: 0.9265, F1 Micro: 0.9265, F1 Macro: 0.9198\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.049, Accuracy: 0.9633, F1 Micro: 0.9633, F1 Macro: 0.9586\n",
      "\n",
      "Sentiment analysis accuracy: 0.9633, F1 Micro: 0.9633, F1 Macro: 0.9586\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.97      0.94        79\n",
      "    positive       0.99      0.96      0.97       166\n",
      "\n",
      "    accuracy                           0.96       245\n",
      "   macro avg       0.95      0.97      0.96       245\n",
      "weighted avg       0.96      0.96      0.96       245\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 387: Accuracy: 0.9429, F1 Micro: 0.9429, F1 Macro: 0.884\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.57      0.81      0.67        16\n",
      "     neutral       0.94      0.97      0.96       167\n",
      "    positive       1.00      0.64      0.78        33\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.84      0.81      0.80       216\n",
      "weighted avg       0.92      0.91      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.75      0.67        12\n",
      "     neutral       0.91      0.91      0.91       152\n",
      "    positive       0.80      0.75      0.77        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.77      0.80      0.78       216\n",
      "weighted avg       0.86      0.86      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.95      0.88      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.84      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 93.71303272247314 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 48\n",
      "Sampling duration: 11.885453462600708 seconds\n",
      "New train size: 435\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5525, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4823, Accuracy: 0.7976, F1 Micro: 0.8864, F1 Macro: 0.8849\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3973, Accuracy: 0.8862, F1 Micro: 0.932, F1 Macro: 0.9308\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3002, Accuracy: 0.939, F1 Micro: 0.9625, F1 Macro: 0.9612\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2153, Accuracy: 0.9494, F1 Micro: 0.9686, F1 Macro: 0.9673\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.173, Accuracy: 0.9516, F1 Micro: 0.9698, F1 Macro: 0.9685\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1439, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9727\n",
      "Epoch 8/10, Train Loss: 0.1137, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9724\n",
      "Epoch 9/10, Train Loss: 0.0879, Accuracy: 0.9501, F1 Micro: 0.9686, F1 Macro: 0.9664\n",
      "Epoch 10/10, Train Loss: 0.0768, Accuracy: 0.9561, F1 Micro: 0.9724, F1 Macro: 0.9708\n",
      "\n",
      "Aspect detection accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9727\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.97      0.97       175\n",
      "      others       0.89      0.96      0.93       158\n",
      "        part       0.98      0.97      0.97       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5807, Accuracy: 0.7619, F1 Micro: 0.7619, F1 Macro: 0.6465\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3595, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8963\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2043, Accuracy: 0.9246, F1 Micro: 0.9246, F1 Macro: 0.9154\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2165, Accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9421\n",
      "Epoch 5/10, Train Loss: 0.1744, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9248\n",
      "Epoch 6/10, Train Loss: 0.0971, Accuracy: 0.9206, F1 Micro: 0.9206, F1 Macro: 0.9131\n",
      "Epoch 7/10, Train Loss: 0.0972, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.909\n",
      "Epoch 8/10, Train Loss: 0.1302, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0778, Accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9411\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0761, Accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9414\n",
      "\n",
      "Sentiment analysis accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9414\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.95      0.92        80\n",
      "    positive       0.98      0.95      0.96       172\n",
      "\n",
      "    accuracy                           0.95       252\n",
      "   macro avg       0.94      0.95      0.94       252\n",
      "weighted avg       0.95      0.95      0.95       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 435: Accuracy: 0.946, F1 Micro: 0.946, F1 Macro: 0.8842\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.91      0.88      0.89        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      0.81      0.76        16\n",
      "     neutral       0.96      0.96      0.96       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.84      0.85      0.85       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.47      0.75      0.58        12\n",
      "     neutral       0.91      0.93      0.92       152\n",
      "    positive       0.88      0.71      0.79        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.75      0.80      0.76       216\n",
      "weighted avg       0.88      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.99      0.97      0.98       152\n",
      "    positive       0.90      0.90      0.90        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.94      0.93       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.86      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 98.0140631198883 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 43\n",
      "Sampling duration: 10.978721141815186 seconds\n",
      "New train size: 478\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5479, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4719, Accuracy: 0.8036, F1 Micro: 0.889, F1 Macro: 0.8876\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3894, Accuracy: 0.907, F1 Micro: 0.944, F1 Macro: 0.9426\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2881, Accuracy: 0.939, F1 Micro: 0.9624, F1 Macro: 0.961\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2102, Accuracy: 0.9531, F1 Micro: 0.9709, F1 Macro: 0.9696\n",
      "Epoch 6/10, Train Loss: 0.1566, Accuracy: 0.9531, F1 Micro: 0.9707, F1 Macro: 0.9691\n",
      "Epoch 7/10, Train Loss: 0.1283, Accuracy: 0.9531, F1 Micro: 0.9706, F1 Macro: 0.9687\n",
      "Epoch 8/10, Train Loss: 0.1047, Accuracy: 0.9501, F1 Micro: 0.9687, F1 Macro: 0.9668\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.087, Accuracy: 0.9561, F1 Micro: 0.9723, F1 Macro: 0.9705\n",
      "Epoch 10/10, Train Loss: 0.0685, Accuracy: 0.9546, F1 Micro: 0.9714, F1 Macro: 0.9696\n",
      "\n",
      "Aspect detection accuracy: 0.9561, F1 Micro: 0.9723, F1 Macro: 0.9705\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      0.98      0.96       175\n",
      "      others       0.93      0.90      0.91       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      1061\n",
      "   macro avg       0.97      0.97      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.97      0.97      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4882, Accuracy: 0.8717, F1 Micro: 0.8717, F1 Macro: 0.8499\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2512, Accuracy: 0.9208, F1 Micro: 0.9208, F1 Macro: 0.9119\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1844, Accuracy: 0.9509, F1 Micro: 0.9509, F1 Macro: 0.9416\n",
      "Epoch 4/10, Train Loss: 0.1785, Accuracy: 0.9094, F1 Micro: 0.9094, F1 Macro: 0.9001\n",
      "Epoch 5/10, Train Loss: 0.1419, Accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.939\n",
      "Epoch 6/10, Train Loss: 0.125, Accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.9369\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1075, Accuracy: 0.9509, F1 Micro: 0.9509, F1 Macro: 0.9416\n",
      "Epoch 8/10, Train Loss: 0.1358, Accuracy: 0.9358, F1 Micro: 0.9358, F1 Macro: 0.9275\n",
      "Epoch 9/10, Train Loss: 0.0754, Accuracy: 0.9358, F1 Micro: 0.9358, F1 Macro: 0.9266\n",
      "Epoch 10/10, Train Loss: 0.061, Accuracy: 0.9358, F1 Micro: 0.9358, F1 Macro: 0.9271\n",
      "\n",
      "Sentiment analysis accuracy: 0.9509, F1 Micro: 0.9509, F1 Macro: 0.9416\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.89      0.92        82\n",
      "    positive       0.95      0.98      0.96       183\n",
      "\n",
      "    accuracy                           0.95       265\n",
      "   macro avg       0.95      0.93      0.94       265\n",
      "weighted avg       0.95      0.95      0.95       265\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 478: Accuracy: 0.946, F1 Micro: 0.946, F1 Macro: 0.8928\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.91      0.88      0.89        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      0.81      0.76        16\n",
      "     neutral       0.95      0.97      0.96       167\n",
      "    positive       0.82      0.70      0.75        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.83      0.83      0.83       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.92      0.76        12\n",
      "     neutral       0.93      0.89      0.91       152\n",
      "    positive       0.77      0.79      0.78        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.78      0.87      0.82       216\n",
      "weighted avg       0.88      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.99      0.97      0.98       152\n",
      "    positive       0.92      0.88      0.90        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.94      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.86      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.93      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 101.79452419281006 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 39\n",
      "Sampling duration: 10.025293827056885 seconds\n",
      "New train size: 517\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.547, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4596, Accuracy: 0.8311, F1 Micro: 0.9029, F1 Macro: 0.9019\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3551, Accuracy: 0.9263, F1 Micro: 0.9549, F1 Macro: 0.9533\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2484, Accuracy: 0.9487, F1 Micro: 0.9682, F1 Macro: 0.9668\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1779, Accuracy: 0.9561, F1 Micro: 0.9727, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1489, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9715\n",
      "Epoch 7/10, Train Loss: 0.1102, Accuracy: 0.9539, F1 Micro: 0.9709, F1 Macro: 0.9688\n",
      "Epoch 8/10, Train Loss: 0.0884, Accuracy: 0.9546, F1 Micro: 0.9715, F1 Macro: 0.9699\n",
      "Epoch 9/10, Train Loss: 0.0761, Accuracy: 0.9546, F1 Micro: 0.9715, F1 Macro: 0.9701\n",
      "Epoch 10/10, Train Loss: 0.0618, Accuracy: 0.9546, F1 Micro: 0.9715, F1 Macro: 0.9695\n",
      "\n",
      "Aspect detection accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9715\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      0.98      0.96       175\n",
      "      others       0.91      0.94      0.92       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5382, Accuracy: 0.8024, F1 Micro: 0.8024, F1 Macro: 0.726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2797, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9102\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1709, Accuracy: 0.9315, F1 Micro: 0.9315, F1 Macro: 0.9228\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1534, Accuracy: 0.9476, F1 Micro: 0.9476, F1 Macro: 0.939\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0946, Accuracy: 0.9476, F1 Micro: 0.9476, F1 Macro: 0.9394\n",
      "Epoch 6/10, Train Loss: 0.1033, Accuracy: 0.9355, F1 Micro: 0.9355, F1 Macro: 0.9284\n",
      "Epoch 7/10, Train Loss: 0.0827, Accuracy: 0.9435, F1 Micro: 0.9435, F1 Macro: 0.9358\n",
      "Epoch 8/10, Train Loss: 0.0563, Accuracy: 0.9435, F1 Micro: 0.9435, F1 Macro: 0.9366\n",
      "Epoch 9/10, Train Loss: 0.05, Accuracy: 0.9355, F1 Micro: 0.9355, F1 Macro: 0.9262\n",
      "Epoch 10/10, Train Loss: 0.0485, Accuracy: 0.9355, F1 Micro: 0.9355, F1 Macro: 0.9262\n",
      "\n",
      "Sentiment analysis accuracy: 0.9476, F1 Micro: 0.9476, F1 Macro: 0.9394\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.91      0.92        79\n",
      "    positive       0.96      0.96      0.96       169\n",
      "\n",
      "    accuracy                           0.95       248\n",
      "   macro avg       0.94      0.94      0.94       248\n",
      "weighted avg       0.95      0.95      0.95       248\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 517: Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.8741\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.91      0.88      0.89        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.75      0.73        16\n",
      "     neutral       0.94      0.97      0.96       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.85      0.82      0.83       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.53      0.75      0.62        12\n",
      "     neutral       0.91      0.89      0.90       152\n",
      "    positive       0.82      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.75      0.81      0.78       216\n",
      "weighted avg       0.87      0.86      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.66      0.83      0.73        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.89      0.78      0.83        41\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.84      0.86      0.85       216\n",
      "weighted avg       0.93      0.92      0.92       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.84      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 104.29977011680603 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 23\n",
      "Sampling duration: 9.199293375015259 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5512, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.457, Accuracy: 0.8207, F1 Micro: 0.8977, F1 Macro: 0.8962\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3547, Accuracy: 0.9256, F1 Micro: 0.9545, F1 Macro: 0.9532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2555, Accuracy: 0.9501, F1 Micro: 0.9692, F1 Macro: 0.9678\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1867, Accuracy: 0.9568, F1 Micro: 0.9732, F1 Macro: 0.9722\n",
      "Epoch 6/10, Train Loss: 0.1458, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1121, Accuracy: 0.9621, F1 Micro: 0.9763, F1 Macro: 0.9754\n",
      "Epoch 8/10, Train Loss: 0.088, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9739\n",
      "Epoch 9/10, Train Loss: 0.0745, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0661, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9754\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9754\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.99      0.98      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5157, Accuracy: 0.8721, F1 Micro: 0.8721, F1 Macro: 0.8417\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2802, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9275\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1728, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9314\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1738, Accuracy: 0.9535, F1 Micro: 0.9535, F1 Macro: 0.947\n",
      "Epoch 5/10, Train Loss: 0.1598, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9327\n",
      "Epoch 6/10, Train Loss: 0.0961, Accuracy: 0.9496, F1 Micro: 0.9496, F1 Macro: 0.9428\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0928, Accuracy: 0.9574, F1 Micro: 0.9574, F1 Macro: 0.9522\n",
      "Epoch 8/10, Train Loss: 0.1074, Accuracy: 0.9186, F1 Micro: 0.9186, F1 Macro: 0.9111\n",
      "Epoch 9/10, Train Loss: 0.0805, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9265\n",
      "Epoch 10/10, Train Loss: 0.0685, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9336\n",
      "\n",
      "Sentiment analysis accuracy: 0.9574, F1 Micro: 0.9574, F1 Macro: 0.9522\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94        83\n",
      "    positive       0.99      0.95      0.97       175\n",
      "\n",
      "    accuracy                           0.96       258\n",
      "   macro avg       0.94      0.96      0.95       258\n",
      "weighted avg       0.96      0.96      0.96       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9104\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.84      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        12\n",
      "     neutral       0.93      0.94      0.93       152\n",
      "    positive       0.82      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.89      0.88      0.89       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.87      0.85        23\n",
      "     neutral       0.99      0.98      0.98       152\n",
      "    positive       0.88      0.88      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.90      0.91      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.88      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 108.65271329879761 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 33\n",
      "Sampling duration: 8.774337768554688 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5327, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4623, Accuracy: 0.84, F1 Micro: 0.9075, F1 Macro: 0.9063\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3482, Accuracy: 0.9293, F1 Micro: 0.9563, F1 Macro: 0.9546\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2409, Accuracy: 0.9516, F1 Micro: 0.97, F1 Macro: 0.9683\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1723, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1331, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1102, Accuracy: 0.9621, F1 Micro: 0.9763, F1 Macro: 0.9749\n",
      "Epoch 8/10, Train Loss: 0.0825, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9738\n",
      "Epoch 9/10, Train Loss: 0.0701, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0599, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9765\n",
      "\n",
      "Aspect detection accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.91      0.96      0.94       158\n",
      "        part       0.99      0.97      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5238, Accuracy: 0.9008, F1 Micro: 0.9008, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2272, Accuracy: 0.9206, F1 Micro: 0.9206, F1 Macro: 0.9131\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1953, Accuracy: 0.9365, F1 Micro: 0.9365, F1 Macro: 0.9298\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1729, Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9382\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1274, Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9355\n",
      "Epoch 6/10, Train Loss: 0.1032, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9256\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0943, Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9382\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.107, Accuracy: 0.9524, F1 Micro: 0.9524, F1 Macro: 0.9451\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0741, Accuracy: 0.9563, F1 Micro: 0.9563, F1 Macro: 0.9495\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.063, Accuracy: 0.9563, F1 Micro: 0.9563, F1 Macro: 0.9507\n",
      "\n",
      "Sentiment analysis accuracy: 0.9563, F1 Micro: 0.9563, F1 Macro: 0.9507\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.93        81\n",
      "    positive       0.98      0.95      0.97       171\n",
      "\n",
      "    accuracy                           0.96       252\n",
      "   macro avg       0.94      0.96      0.95       252\n",
      "weighted avg       0.96      0.96      0.96       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.9154\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.88      0.70      0.78        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.83      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.91      0.97      0.94       152\n",
      "    positive       0.89      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.90      0.83      0.86       216\n",
      "weighted avg       0.91      0.91      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.99      0.97      0.98       152\n",
      "    positive       0.92      0.88      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.95      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.69      0.82        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.86      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 121.04051613807678 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 30\n",
      "Sampling duration: 7.8103508949279785 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5406, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4501, Accuracy: 0.8333, F1 Micro: 0.9044, F1 Macro: 0.903\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3214, Accuracy: 0.9338, F1 Micro: 0.9595, F1 Macro: 0.958\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2299, Accuracy: 0.9568, F1 Micro: 0.9732, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1639, Accuracy: 0.9583, F1 Micro: 0.974, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1269, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9754\n",
      "Epoch 7/10, Train Loss: 0.0985, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.975\n",
      "Epoch 8/10, Train Loss: 0.0828, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9749\n",
      "Epoch 9/10, Train Loss: 0.0679, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9741\n",
      "Epoch 10/10, Train Loss: 0.0613, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9742\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9754\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5107, Accuracy: 0.8898, F1 Micro: 0.8898, F1 Macro: 0.8723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2465, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9335\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1813, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9388\n",
      "Epoch 4/10, Train Loss: 0.1437, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9304\n",
      "Epoch 5/10, Train Loss: 0.1418, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9222\n",
      "Epoch 6/10, Train Loss: 0.107, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9263\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0742, Accuracy: 0.9567, F1 Micro: 0.9567, F1 Macro: 0.9512\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.086, Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.955\n",
      "Epoch 9/10, Train Loss: 0.0686, Accuracy: 0.9488, F1 Micro: 0.9488, F1 Macro: 0.9409\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0609, Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9547\n",
      "\n",
      "Sentiment analysis accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.93      0.94        82\n",
      "    positive       0.97      0.98      0.97       172\n",
      "\n",
      "    accuracy                           0.96       254\n",
      "   macro avg       0.96      0.95      0.95       254\n",
      "weighted avg       0.96      0.96      0.96       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9121\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.83      0.71        12\n",
      "     neutral       0.93      0.91      0.92       152\n",
      "    positive       0.84      0.81      0.82        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.80      0.85      0.82       216\n",
      "weighted avg       0.89      0.88      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.91      0.84        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.92      0.85      0.89        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.91      0.90       216\n",
      "weighted avg       0.95      0.94      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 113.45084977149963 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 27\n",
      "Sampling duration: 7.1298828125 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5496, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4508, Accuracy: 0.8757, F1 Micro: 0.9261, F1 Macro: 0.9246\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.313, Accuracy: 0.9442, F1 Micro: 0.9655, F1 Macro: 0.9641\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2194, Accuracy: 0.9561, F1 Micro: 0.9727, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1529, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1152, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9746\n",
      "Epoch 7/10, Train Loss: 0.0935, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0811, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9757\n",
      "Epoch 9/10, Train Loss: 0.0665, Accuracy: 0.9613, F1 Micro: 0.9754, F1 Macro: 0.9732\n",
      "Epoch 10/10, Train Loss: 0.0564, Accuracy: 0.9591, F1 Micro: 0.9741, F1 Macro: 0.9721\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9757\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.91      0.94      0.93       158\n",
      "        part       0.99      0.97      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5021, Accuracy: 0.9042, F1 Micro: 0.9042, F1 Macro: 0.8869\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.208, Accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.94\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2121, Accuracy: 0.9502, F1 Micro: 0.9502, F1 Macro: 0.9435\n",
      "Epoch 4/10, Train Loss: 0.142, Accuracy: 0.9425, F1 Micro: 0.9425, F1 Macro: 0.9348\n",
      "Epoch 5/10, Train Loss: 0.1225, Accuracy: 0.9387, F1 Micro: 0.9387, F1 Macro: 0.9289\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1072, Accuracy: 0.9579, F1 Micro: 0.9579, F1 Macro: 0.9524\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1164, Accuracy: 0.9617, F1 Micro: 0.9617, F1 Macro: 0.9566\n",
      "Epoch 8/10, Train Loss: 0.1093, Accuracy: 0.9579, F1 Micro: 0.9579, F1 Macro: 0.9524\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0919, Accuracy: 0.9617, F1 Micro: 0.9617, F1 Macro: 0.9566\n",
      "Epoch 10/10, Train Loss: 0.0575, Accuracy: 0.9502, F1 Micro: 0.9502, F1 Macro: 0.9431\n",
      "\n",
      "Sentiment analysis accuracy: 0.9617, F1 Micro: 0.9617, F1 Macro: 0.9566\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.96      0.94        84\n",
      "    positive       0.98      0.96      0.97       177\n",
      "\n",
      "    accuracy                           0.96       261\n",
      "   macro avg       0.95      0.96      0.96       261\n",
      "weighted avg       0.96      0.96      0.96       261\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.9491, F1 Micro: 0.9491, F1 Macro: 0.8958\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.81      0.76      0.78        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.85      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.53      0.83      0.65        12\n",
      "     neutral       0.92      0.89      0.91       152\n",
      "    positive       0.84      0.79      0.81        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.76      0.84      0.79       216\n",
      "weighted avg       0.88      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.99      0.97      0.98       152\n",
      "    positive       0.90      0.90      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.92      0.83        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 120.81754517555237 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 18\n",
      "Sampling duration: 6.496376991271973 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5368, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.435, Accuracy: 0.878, F1 Micro: 0.9271, F1 Macro: 0.9254\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2987, Accuracy: 0.9457, F1 Micro: 0.9663, F1 Macro: 0.9651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2164, Accuracy: 0.9568, F1 Micro: 0.9731, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1515, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9741\n",
      "Epoch 6/10, Train Loss: 0.1097, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0892, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9769\n",
      "Epoch 8/10, Train Loss: 0.0776, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9734\n",
      "Epoch 9/10, Train Loss: 0.0595, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9743\n",
      "Epoch 10/10, Train Loss: 0.0513, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9762\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.99      0.99      0.99       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4748, Accuracy: 0.9105, F1 Micro: 0.9105, F1 Macro: 0.8998\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2195, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9309\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1562, Accuracy: 0.9533, F1 Micro: 0.9533, F1 Macro: 0.9476\n",
      "Epoch 4/10, Train Loss: 0.147, Accuracy: 0.9416, F1 Micro: 0.9416, F1 Macro: 0.9331\n",
      "Epoch 5/10, Train Loss: 0.1392, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9293\n",
      "Epoch 6/10, Train Loss: 0.0993, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9181\n",
      "Epoch 7/10, Train Loss: 0.083, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9305\n",
      "Epoch 8/10, Train Loss: 0.0773, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9309\n",
      "Epoch 9/10, Train Loss: 0.0836, Accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9388\n",
      "Epoch 10/10, Train Loss: 0.0843, Accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9388\n",
      "\n",
      "Sentiment analysis accuracy: 0.9533, F1 Micro: 0.9533, F1 Macro: 0.9476\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.93        82\n",
      "    positive       0.99      0.94      0.96       175\n",
      "\n",
      "    accuracy                           0.95       257\n",
      "   macro avg       0.94      0.96      0.95       257\n",
      "weighted avg       0.96      0.95      0.95       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9049\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.88      0.82        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.86      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.83      0.74        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.84      0.79      0.81        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.81      0.85      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.99      0.97      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.94      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.86      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 117.72696256637573 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 6.118969678878784 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.535, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4322, Accuracy: 0.8862, F1 Micro: 0.9323, F1 Macro: 0.931\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2977, Accuracy: 0.9472, F1 Micro: 0.9673, F1 Macro: 0.9661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2045, Accuracy: 0.9576, F1 Micro: 0.9737, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1411, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1172, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9766\n",
      "Epoch 7/10, Train Loss: 0.0814, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9729\n",
      "Epoch 8/10, Train Loss: 0.0724, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0579, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0516, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.979\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.979\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.99      0.98      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5384, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.8973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2801, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.9327\n",
      "Epoch 3/10, Train Loss: 0.1351, Accuracy: 0.9198, F1 Micro: 0.9198, F1 Macro: 0.9127\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1547, Accuracy: 0.9466, F1 Micro: 0.9466, F1 Macro: 0.9401\n",
      "Epoch 5/10, Train Loss: 0.1242, Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.9246\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1017, Accuracy: 0.9466, F1 Micro: 0.9466, F1 Macro: 0.9401\n",
      "Epoch 7/10, Train Loss: 0.097, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9262\n",
      "Epoch 8/10, Train Loss: 0.0905, Accuracy: 0.9275, F1 Micro: 0.9275, F1 Macro: 0.921\n",
      "Epoch 9/10, Train Loss: 0.0465, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.933\n",
      "Epoch 10/10, Train Loss: 0.0531, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9286\n",
      "\n",
      "Sentiment analysis accuracy: 0.9466, F1 Micro: 0.9466, F1 Macro: 0.9401\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        86\n",
      "    positive       0.97      0.95      0.96       176\n",
      "\n",
      "    accuracy                           0.95       262\n",
      "   macro avg       0.94      0.95      0.94       262\n",
      "weighted avg       0.95      0.95      0.95       262\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.917\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.93      0.94      0.93       152\n",
      "    positive       0.83      0.77      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.83      0.85      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.99      0.98      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.94      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 131.0362708568573 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.496626138687134 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5268, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4357, Accuracy: 0.9055, F1 Micro: 0.9422, F1 Macro: 0.94\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2845, Accuracy: 0.9516, F1 Micro: 0.9701, F1 Macro: 0.9689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.202, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1455, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1158, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0913, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "Epoch 8/10, Train Loss: 0.0752, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9771\n",
      "Epoch 9/10, Train Loss: 0.0633, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9741\n",
      "Epoch 10/10, Train Loss: 0.0522, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9738\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      0.99      0.97       175\n",
      "      others       0.91      0.96      0.94       158\n",
      "        part       0.99      0.97      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4901, Accuracy: 0.898, F1 Micro: 0.898, F1 Macro: 0.8872\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2142, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9319\n",
      "Epoch 3/10, Train Loss: 0.1855, Accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.9096\n",
      "Epoch 4/10, Train Loss: 0.1602, Accuracy: 0.9255, F1 Micro: 0.9255, F1 Macro: 0.9169\n",
      "Epoch 5/10, Train Loss: 0.1274, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9227\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1193, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9379\n",
      "Epoch 7/10, Train Loss: 0.0726, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9228\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0863, Accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.9425\n",
      "Epoch 9/10, Train Loss: 0.0635, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9351\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0587, Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9474\n",
      "\n",
      "Sentiment analysis accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9474\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.96      0.93        83\n",
      "    positive       0.98      0.95      0.96       172\n",
      "\n",
      "    accuracy                           0.95       255\n",
      "   macro avg       0.94      0.96      0.95       255\n",
      "weighted avg       0.95      0.95      0.95       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.9062\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.94      0.99      0.97       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.82      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.41      1.00      0.59        12\n",
      "     neutral       0.94      0.88      0.91       152\n",
      "    positive       0.87      0.75      0.80        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.74      0.88      0.77       216\n",
      "weighted avg       0.90      0.86      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.99      0.97      0.98       152\n",
      "    positive       0.92      0.88      0.90        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.95      0.93       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      1.00       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.94      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 126.1373541355133 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.985323429107666 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5288, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4234, Accuracy: 0.8906, F1 Micro: 0.9348, F1 Macro: 0.9334\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2882, Accuracy: 0.9531, F1 Micro: 0.9709, F1 Macro: 0.9699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2008, Accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9777\n",
      "Epoch 5/10, Train Loss: 0.1411, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9736\n",
      "Epoch 6/10, Train Loss: 0.1085, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "Epoch 7/10, Train Loss: 0.0832, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9746\n",
      "Epoch 8/10, Train Loss: 0.0718, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9725\n",
      "Epoch 9/10, Train Loss: 0.0587, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9751\n",
      "Epoch 10/10, Train Loss: 0.0495, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9769\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9777\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      1.00      0.97       175\n",
      "      others       0.90      0.97      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4992, Accuracy: 0.8852, F1 Micro: 0.8852, F1 Macro: 0.8609\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2557, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9278\n",
      "Epoch 3/10, Train Loss: 0.1968, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.9036\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1169, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9285\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1015, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9274\n",
      "Epoch 6/10, Train Loss: 0.0912, Accuracy: 0.9262, F1 Micro: 0.9262, F1 Macro: 0.9168\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0967, Accuracy: 0.9467, F1 Micro: 0.9467, F1 Macro: 0.9415\n",
      "Epoch 8/10, Train Loss: 0.0731, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9328\n",
      "Epoch 9/10, Train Loss: 0.0594, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9325\n",
      "Epoch 10/10, Train Loss: 0.057, Accuracy: 0.9303, F1 Micro: 0.9303, F1 Macro: 0.9231\n",
      "\n",
      "Sentiment analysis accuracy: 0.9467, F1 Micro: 0.9467, F1 Macro: 0.9415\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.98      0.92        81\n",
      "    positive       0.99      0.93      0.96       163\n",
      "\n",
      "    accuracy                           0.95       244\n",
      "   macro avg       0.93      0.95      0.94       244\n",
      "weighted avg       0.95      0.95      0.95       244\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9491, F1 Micro: 0.9491, F1 Macro: 0.888\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.91      0.88      0.89        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.81      0.70        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.92      0.70      0.79        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.83      0.83      0.82       216\n",
      "weighted avg       0.93      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.44      0.92      0.59        12\n",
      "     neutral       0.94      0.93      0.93       152\n",
      "    positive       0.93      0.73      0.82        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.77      0.86      0.78       216\n",
      "weighted avg       0.91      0.88      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.96      0.86        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.90      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.92      0.83        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 122.38821864128113 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.266369104385376 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5301, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4085, Accuracy: 0.9159, F1 Micro: 0.9486, F1 Macro: 0.9466\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2691, Accuracy: 0.9524, F1 Micro: 0.9705, F1 Macro: 0.9689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.182, Accuracy: 0.9554, F1 Micro: 0.972, F1 Macro: 0.9706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1371, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1023, Accuracy: 0.968, F1 Micro: 0.98, F1 Macro: 0.9791\n",
      "Epoch 7/10, Train Loss: 0.0893, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9764\n",
      "Epoch 8/10, Train Loss: 0.067, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9772\n",
      "Epoch 9/10, Train Loss: 0.0569, Accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9784\n",
      "Epoch 10/10, Train Loss: 0.0476, Accuracy: 0.9658, F1 Micro: 0.9783, F1 Macro: 0.9766\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.98, F1 Macro: 0.9791\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.89      0.99      0.93       158\n",
      "        part       0.99      0.98      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4777, Accuracy: 0.9146, F1 Micro: 0.9146, F1 Macro: 0.9031\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2365, Accuracy: 0.935, F1 Micro: 0.935, F1 Macro: 0.9296\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1841, Accuracy: 0.9431, F1 Micro: 0.9431, F1 Macro: 0.9371\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1272, Accuracy: 0.9431, F1 Micro: 0.9431, F1 Macro: 0.9371\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1305, Accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.9417\n",
      "Epoch 6/10, Train Loss: 0.0869, Accuracy: 0.939, F1 Micro: 0.939, F1 Macro: 0.9338\n",
      "Epoch 7/10, Train Loss: 0.104, Accuracy: 0.939, F1 Micro: 0.939, F1 Macro: 0.9335\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0759, Accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.9421\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0619, Accuracy: 0.9553, F1 Micro: 0.9553, F1 Macro: 0.951\n",
      "Epoch 10/10, Train Loss: 0.0705, Accuracy: 0.9146, F1 Micro: 0.9146, F1 Macro: 0.9078\n",
      "\n",
      "Sentiment analysis accuracy: 0.9553, F1 Micro: 0.9553, F1 Macro: 0.951\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94        83\n",
      "    positive       0.99      0.94      0.97       163\n",
      "\n",
      "    accuracy                           0.96       246\n",
      "   macro avg       0.94      0.96      0.95       246\n",
      "weighted avg       0.96      0.96      0.96       246\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.946, F1 Micro: 0.946, F1 Macro: 0.8801\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.91      0.87        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.93      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      0.81      0.76        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.85      0.84      0.84       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.36      1.00      0.53        12\n",
      "     neutral       0.94      0.91      0.92       152\n",
      "    positive       0.94      0.65      0.77        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.75      0.85      0.74       216\n",
      "weighted avg       0.91      0.85      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.99      0.98      0.98       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.90      0.93      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 131.68446946144104 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 8\n",
      "Sampling duration: 3.927428960800171 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5291, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4243, Accuracy: 0.8891, F1 Micro: 0.933, F1 Macro: 0.9312\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2772, Accuracy: 0.9531, F1 Micro: 0.971, F1 Macro: 0.9698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1839, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1312, Accuracy: 0.9665, F1 Micro: 0.9791, F1 Macro: 0.9782\n",
      "Epoch 6/10, Train Loss: 0.0991, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9756\n",
      "Epoch 7/10, Train Loss: 0.0833, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9759\n",
      "Epoch 8/10, Train Loss: 0.0697, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.975\n",
      "Epoch 9/10, Train Loss: 0.0575, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9771\n",
      "Epoch 10/10, Train Loss: 0.0509, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9757\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9791, F1 Macro: 0.9782\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.90      0.98      0.94       158\n",
      "        part       0.96      1.00      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.96      1.00      0.98      1061\n",
      "   macro avg       0.96      0.99      0.98      1061\n",
      "weighted avg       0.96      1.00      0.98      1061\n",
      " samples avg       0.96      1.00      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5101, Accuracy: 0.8917, F1 Micro: 0.8917, F1 Macro: 0.873\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2288, Accuracy: 0.9458, F1 Micro: 0.9458, F1 Macro: 0.9403\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1501, Accuracy: 0.9542, F1 Micro: 0.9542, F1 Macro: 0.95\n",
      "Epoch 4/10, Train Loss: 0.1524, Accuracy: 0.925, F1 Micro: 0.925, F1 Macro: 0.9156\n",
      "Epoch 5/10, Train Loss: 0.0907, Accuracy: 0.925, F1 Micro: 0.925, F1 Macro: 0.9161\n",
      "Epoch 6/10, Train Loss: 0.1269, Accuracy: 0.9458, F1 Micro: 0.9458, F1 Macro: 0.94\n",
      "Epoch 7/10, Train Loss: 0.1133, Accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.9456\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0722, Accuracy: 0.9542, F1 Micro: 0.9542, F1 Macro: 0.9495\n",
      "Epoch 9/10, Train Loss: 0.056, Accuracy: 0.9458, F1 Micro: 0.9458, F1 Macro: 0.9403\n",
      "Epoch 10/10, Train Loss: 0.0533, Accuracy: 0.9417, F1 Micro: 0.9417, F1 Macro: 0.9362\n",
      "\n",
      "Sentiment analysis accuracy: 0.9542, F1 Micro: 0.9542, F1 Macro: 0.9495\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.95      0.93        82\n",
      "    positive       0.97      0.96      0.96       158\n",
      "\n",
      "    accuracy                           0.95       240\n",
      "   macro avg       0.95      0.95      0.95       240\n",
      "weighted avg       0.95      0.95      0.95       240\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.946, F1 Micro: 0.946, F1 Macro: 0.8879\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.97      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.81      0.79        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.86      0.84      0.85       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.34      0.92      0.50        12\n",
      "     neutral       0.94      0.90      0.92       152\n",
      "    positive       0.92      0.69      0.79        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.74      0.84      0.74       216\n",
      "weighted avg       0.91      0.85      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      1.00      0.82        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       1.00      0.76      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.91      0.89       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 126.01719236373901 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.4783780574798584 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5289, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4117, Accuracy: 0.9152, F1 Micro: 0.9482, F1 Macro: 0.9466\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2635, Accuracy: 0.9583, F1 Micro: 0.9741, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1739, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.131, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0931, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9794\n",
      "Epoch 7/10, Train Loss: 0.0794, Accuracy: 0.968, F1 Micro: 0.98, F1 Macro: 0.9789\n",
      "Epoch 8/10, Train Loss: 0.0644, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9736\n",
      "Epoch 9/10, Train Loss: 0.0544, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9747\n",
      "Epoch 10/10, Train Loss: 0.0493, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9762\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9794\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.97      0.94       158\n",
      "        part       0.99      0.98      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4958, Accuracy: 0.8854, F1 Micro: 0.8854, F1 Macro: 0.877\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2183, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9348\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1736, Accuracy: 0.9447, F1 Micro: 0.9447, F1 Macro: 0.9383\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1651, Accuracy: 0.9565, F1 Micro: 0.9565, F1 Macro: 0.9508\n",
      "Epoch 5/10, Train Loss: 0.1369, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9265\n",
      "Epoch 6/10, Train Loss: 0.0961, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9345\n",
      "Epoch 7/10, Train Loss: 0.0992, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9253\n",
      "Epoch 8/10, Train Loss: 0.0783, Accuracy: 0.9447, F1 Micro: 0.9447, F1 Macro: 0.9372\n",
      "Epoch 9/10, Train Loss: 0.0662, Accuracy: 0.9368, F1 Micro: 0.9368, F1 Macro: 0.9287\n",
      "Epoch 10/10, Train Loss: 0.0542, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9338\n",
      "\n",
      "Sentiment analysis accuracy: 0.9565, F1 Micro: 0.9565, F1 Macro: 0.9508\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.93        84\n",
      "    positive       0.96      0.97      0.97       169\n",
      "\n",
      "    accuracy                           0.96       253\n",
      "   macro avg       0.95      0.95      0.95       253\n",
      "weighted avg       0.96      0.96      0.96       253\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9073\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.75      0.77        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.85      0.70      0.77        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.81      0.84       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.53      0.67      0.59        12\n",
      "     neutral       0.92      0.94      0.93       152\n",
      "    positive       0.85      0.75      0.80        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.77      0.79      0.77       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.99      0.98      0.98       152\n",
      "    positive       0.95      0.90      0.92        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.96      0.95       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 130.71529698371887 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.099743127822876 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.527, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.398, Accuracy: 0.9234, F1 Micro: 0.9532, F1 Macro: 0.9517\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2441, Accuracy: 0.9546, F1 Micro: 0.9719, F1 Macro: 0.9706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1651, Accuracy: 0.9643, F1 Micro: 0.9777, F1 Macro: 0.9767\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1259, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0901, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9771\n",
      "Epoch 7/10, Train Loss: 0.0745, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9756\n",
      "Epoch 8/10, Train Loss: 0.0611, Accuracy: 0.9606, F1 Micro: 0.975, F1 Macro: 0.9726\n",
      "Epoch 9/10, Train Loss: 0.0534, Accuracy: 0.9613, F1 Micro: 0.9755, F1 Macro: 0.9733\n",
      "Epoch 10/10, Train Loss: 0.0441, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9752\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.92      0.93      0.92       158\n",
      "        part       0.99      0.99      0.99       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4766, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9201\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2158, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9229\n",
      "Epoch 3/10, Train Loss: 0.1744, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9237\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1477, Accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.9396\n",
      "Epoch 5/10, Train Loss: 0.1054, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9246\n",
      "Epoch 6/10, Train Loss: 0.0988, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9273\n",
      "Epoch 7/10, Train Loss: 0.1084, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9219\n",
      "Epoch 8/10, Train Loss: 0.0665, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9314\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0659, Accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.9396\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0561, Accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.9389\n",
      "\n",
      "Sentiment analysis accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.9389\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.93      0.92        83\n",
      "    positive       0.97      0.96      0.96       181\n",
      "\n",
      "    accuracy                           0.95       264\n",
      "   macro avg       0.94      0.94      0.94       264\n",
      "weighted avg       0.95      0.95      0.95       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9061\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.91      0.88      0.89        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.98      0.97      0.97       167\n",
      "    positive       0.85      0.85      0.85        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.90      0.89       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.56      0.83      0.67        12\n",
      "     neutral       0.93      0.90      0.92       152\n",
      "    positive       0.78      0.77      0.78        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.76      0.83      0.79       216\n",
      "weighted avg       0.88      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.99      0.99      0.99       152\n",
      "    positive       0.97      0.90      0.94        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.99      1.00      1.00       186\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.91      0.88      0.90       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 139.50475788116455 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.348651170730591 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5164, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3973, Accuracy: 0.9241, F1 Micro: 0.9536, F1 Macro: 0.9519\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2502, Accuracy: 0.9583, F1 Micro: 0.9742, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1663, Accuracy: 0.9665, F1 Micro: 0.9791, F1 Macro: 0.9783\n",
      "Epoch 5/10, Train Loss: 0.1254, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9748\n",
      "Epoch 6/10, Train Loss: 0.0912, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9774\n",
      "Epoch 7/10, Train Loss: 0.0753, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.975\n",
      "Epoch 8/10, Train Loss: 0.0621, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0499, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9778\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0423, Accuracy: 0.971, F1 Micro: 0.9818, F1 Macro: 0.9809\n",
      "\n",
      "Aspect detection accuracy: 0.971, F1 Micro: 0.9818, F1 Macro: 0.9809\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.99      0.98       175\n",
      "      others       0.90      0.97      0.94       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4774, Accuracy: 0.8976, F1 Micro: 0.8976, F1 Macro: 0.8902\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2531, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9189\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1563, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9167\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1555, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9267\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1262, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9398\n",
      "Epoch 6/10, Train Loss: 0.1026, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9192\n",
      "Epoch 7/10, Train Loss: 0.0688, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9297\n",
      "Epoch 8/10, Train Loss: 0.0695, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9233\n",
      "Epoch 9/10, Train Loss: 0.0619, Accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.9069\n",
      "Epoch 10/10, Train Loss: 0.0695, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9181\n",
      "\n",
      "Sentiment analysis accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9398\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.98      0.92        85\n",
      "    positive       0.99      0.93      0.96       169\n",
      "\n",
      "    accuracy                           0.94       254\n",
      "   macro avg       0.93      0.95      0.94       254\n",
      "weighted avg       0.95      0.94      0.95       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.907\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.91      0.88      0.89        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.97      0.99      0.98       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.90      0.87      0.89       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.90      0.97      0.94       152\n",
      "    positive       0.90      0.71      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.87      0.81      0.84       216\n",
      "weighted avg       0.90      0.90      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.98      0.99      0.99       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.92      0.91       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.92      0.83        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.87      0.87       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 138.38250613212585 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.7523791790008545 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5299, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3922, Accuracy: 0.9323, F1 Micro: 0.9585, F1 Macro: 0.9574\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.244, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1553, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1205, Accuracy: 0.9643, F1 Micro: 0.9777, F1 Macro: 0.9767\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0926, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9787\n",
      "Epoch 7/10, Train Loss: 0.0762, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9783\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0594, Accuracy: 0.971, F1 Micro: 0.9818, F1 Macro: 0.9807\n",
      "Epoch 9/10, Train Loss: 0.0507, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9753\n",
      "Epoch 10/10, Train Loss: 0.043, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9778\n",
      "\n",
      "Aspect detection accuracy: 0.971, F1 Micro: 0.9818, F1 Macro: 0.9807\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.92      0.97      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4739, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.8979\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2431, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9301\n",
      "Epoch 3/10, Train Loss: 0.1763, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.921\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1477, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9317\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1245, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9297\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.106, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9309\n",
      "Epoch 7/10, Train Loss: 0.0614, Accuracy: 0.9038, F1 Micro: 0.9038, F1 Macro: 0.897\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0753, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9297\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0746, Accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9402\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0619, Accuracy: 0.9538, F1 Micro: 0.9538, F1 Macro: 0.9485\n",
      "\n",
      "Sentiment analysis accuracy: 0.9538, F1 Micro: 0.9538, F1 Macro: 0.9485\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.94      0.93        87\n",
      "    positive       0.97      0.96      0.97       173\n",
      "\n",
      "    accuracy                           0.95       260\n",
      "   macro avg       0.95      0.95      0.95       260\n",
      "weighted avg       0.95      0.95      0.95       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.9132\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.97      0.98      0.97       167\n",
      "    positive       0.85      0.85      0.85        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.90      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.40      0.83      0.54        12\n",
      "     neutral       0.95      0.92      0.93       152\n",
      "    positive       0.91      0.75      0.82        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.75      0.83      0.76       216\n",
      "weighted avg       0.91      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.95      0.88      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.95      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 148.57624125480652 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 8\n",
      "Sampling duration: 0.9809949398040771 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5299, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4002, Accuracy: 0.9226, F1 Micro: 0.9526, F1 Macro: 0.9512\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2483, Accuracy: 0.9479, F1 Micro: 0.9676, F1 Macro: 0.9658\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1593, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.117, Accuracy: 0.9702, F1 Micro: 0.9814, F1 Macro: 0.9806\n",
      "Epoch 6/10, Train Loss: 0.0953, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9777\n",
      "Epoch 7/10, Train Loss: 0.074, Accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9785\n",
      "Epoch 8/10, Train Loss: 0.0579, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9762\n",
      "Epoch 9/10, Train Loss: 0.0493, Accuracy: 0.9658, F1 Micro: 0.9783, F1 Macro: 0.9765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0429, Accuracy: 0.971, F1 Micro: 0.9817, F1 Macro: 0.9806\n",
      "\n",
      "Aspect detection accuracy: 0.971, F1 Micro: 0.9817, F1 Macro: 0.9806\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.94      0.94      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.98      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4802, Accuracy: 0.9432, F1 Micro: 0.9432, F1 Macro: 0.9363\n",
      "Epoch 2/10, Train Loss: 0.2307, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9326\n",
      "Epoch 3/10, Train Loss: 0.1679, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9289\n",
      "Epoch 4/10, Train Loss: 0.1496, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.9062\n",
      "Epoch 5/10, Train Loss: 0.111, Accuracy: 0.9242, F1 Micro: 0.9242, F1 Macro: 0.9148\n",
      "Epoch 6/10, Train Loss: 0.099, Accuracy: 0.9242, F1 Micro: 0.9242, F1 Macro: 0.9162\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.074, Accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.9393\n",
      "Epoch 8/10, Train Loss: 0.0643, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9201\n",
      "Epoch 9/10, Train Loss: 0.0522, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9326\n",
      "Epoch 10/10, Train Loss: 0.0513, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9197\n",
      "\n",
      "Sentiment analysis accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.9393\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        85\n",
      "    positive       0.96      0.96      0.96       179\n",
      "\n",
      "    accuracy                           0.95       264\n",
      "   macro avg       0.94      0.94      0.94       264\n",
      "weighted avg       0.95      0.95      0.95       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.9084\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.91      0.88      0.89        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.96      0.99      0.97       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.95      0.94      0.94       152\n",
      "    positive       0.81      0.81      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.84      0.86      0.85       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 140.57369565963745 s\n",
      "Total runtime: 3082.048677444458 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[2], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d236e72",
   "metadata": {
    "papermill": {
     "duration": 0.144544,
     "end_time": "2025-03-02T17:42:51.202611",
     "exception": false,
     "start_time": "2025-03-02T17:42:51.058067",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d0b586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 4\n",
      "Random seed: 3\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6456, Accuracy: 0.7865, F1 Micro: 0.8804, F1 Macro: 0.8788\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5639, Accuracy: 0.7894, F1 Micro: 0.8822, F1 Macro: 0.8807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5346, Accuracy: 0.7894, F1 Micro: 0.8822, F1 Macro: 0.8807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5259, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4788, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Epoch 6/10, Train Loss: 0.477, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 7/10, Train Loss: 0.4707, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4588, Accuracy: 0.7909, F1 Micro: 0.883, F1 Macro: 0.8814\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.4215, Accuracy: 0.7932, F1 Micro: 0.8839, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3936, Accuracy: 0.7976, F1 Micro: 0.8857, F1 Macro: 0.884\n",
      "\n",
      "Aspect detection accuracy: 0.7976, F1 Micro: 0.8857, F1 Macro: 0.884\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.78      1.00      0.88       175\n",
      "      others       0.76      0.96      0.84       158\n",
      "        part       0.71      1.00      0.83       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.80      0.99      0.89      1061\n",
      "   macro avg       0.80      0.99      0.88      1061\n",
      "weighted avg       0.80      0.99      0.89      1061\n",
      " samples avg       0.80      0.99      0.88      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7056, Accuracy: 0.44, F1 Micro: 0.44, F1 Macro: 0.4318\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5997, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5241, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5185, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.494, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4806, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4617, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.422, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3873, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2944, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "\n",
      "Sentiment analysis accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         4\n",
      "    positive       0.84      1.00      0.91        21\n",
      "\n",
      "    accuracy                           0.84        25\n",
      "   macro avg       0.42      0.50      0.46        25\n",
      "weighted avg       0.71      0.84      0.77        25\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.7948, F1 Micro: 0.7948, F1 Macro: 0.3169\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.78      1.00      0.87       167\n",
      "    positive       1.00      0.03      0.06        33\n",
      "\n",
      "    accuracy                           0.78       216\n",
      "   macro avg       0.59      0.34      0.31       216\n",
      "weighted avg       0.75      0.78      0.68       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.76      0.95      0.84       152\n",
      "    positive       0.54      0.25      0.34        52\n",
      "\n",
      "    accuracy                           0.73       216\n",
      "   macro avg       0.43      0.40      0.40       216\n",
      "weighted avg       0.66      0.73      0.68       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        23\n",
      "     neutral       0.70      1.00      0.83       152\n",
      "    positive       0.00      0.00      0.00        41\n",
      "\n",
      "    accuracy                           0.70       216\n",
      "   macro avg       0.23      0.33      0.28       216\n",
      "weighted avg       0.50      0.70      0.58       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 60.269898653030396 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 81\n",
      "Sampling duration: 11.843570947647095 seconds\n",
      "New train size: 135\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5981, Accuracy: 0.7894, F1 Micro: 0.8822, F1 Macro: 0.8807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5158, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5117, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4848, Accuracy: 0.7969, F1 Micro: 0.8859, F1 Macro: 0.8844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4509, Accuracy: 0.8051, F1 Micro: 0.8894, F1 Macro: 0.8876\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4139, Accuracy: 0.8147, F1 Micro: 0.8935, F1 Macro: 0.8915\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3709, Accuracy: 0.84, F1 Micro: 0.9053, F1 Macro: 0.903\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3202, Accuracy: 0.8564, F1 Micro: 0.9151, F1 Macro: 0.9132\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2921, Accuracy: 0.8832, F1 Micro: 0.9292, F1 Macro: 0.9268\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2409, Accuracy: 0.9033, F1 Micro: 0.9407, F1 Macro: 0.9385\n",
      "\n",
      "Aspect detection accuracy: 0.9033, F1 Micro: 0.9407, F1 Macro: 0.9385\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.97      0.99      0.98       187\n",
      "     machine       0.89      0.98      0.93       175\n",
      "      others       0.88      0.94      0.91       158\n",
      "        part       0.88      0.91      0.90       158\n",
      "       price       0.95      0.99      0.97       192\n",
      "     service       0.90      1.00      0.95       191\n",
      "\n",
      "   micro avg       0.91      0.97      0.94      1061\n",
      "   macro avg       0.91      0.97      0.94      1061\n",
      "weighted avg       0.91      0.97      0.94      1061\n",
      " samples avg       0.92      0.97      0.94      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6026, Accuracy: 0.7136, F1 Micro: 0.7136, F1 Macro: 0.4164\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5883, Accuracy: 0.7136, F1 Micro: 0.7136, F1 Macro: 0.4164\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5417, Accuracy: 0.7282, F1 Micro: 0.7282, F1 Macro: 0.4948\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3579, Accuracy: 0.835, F1 Micro: 0.835, F1 Macro: 0.802\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2238, Accuracy: 0.8495, F1 Micro: 0.8495, F1 Macro: 0.8292\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1322, Accuracy: 0.8641, F1 Micro: 0.8641, F1 Macro: 0.8463\n",
      "Epoch 7/10, Train Loss: 0.0917, Accuracy: 0.8592, F1 Micro: 0.8592, F1 Macro: 0.8447\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.093, Accuracy: 0.8689, F1 Micro: 0.8689, F1 Macro: 0.8476\n",
      "Epoch 9/10, Train Loss: 0.1217, Accuracy: 0.8155, F1 Micro: 0.8155, F1 Macro: 0.803\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0739, Accuracy: 0.8738, F1 Micro: 0.8738, F1 Macro: 0.8603\n",
      "\n",
      "Sentiment analysis accuracy: 0.8738, F1 Micro: 0.8738, F1 Macro: 0.8603\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.98      0.82        59\n",
      "    positive       0.99      0.83      0.90       147\n",
      "\n",
      "    accuracy                           0.87       206\n",
      "   macro avg       0.85      0.91      0.86       206\n",
      "weighted avg       0.91      0.87      0.88       206\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 135: Accuracy: 0.892, F1 Micro: 0.892, F1 Macro: 0.7603\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.97      0.99      0.98       181\n",
      "    positive       0.95      0.79      0.86        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.90      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.50      0.67        16\n",
      "     neutral       0.88      0.98      0.93       167\n",
      "    positive       0.83      0.58      0.68        33\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.90      0.68      0.76       216\n",
      "weighted avg       0.88      0.88      0.87       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.38      0.67      0.48        12\n",
      "     neutral       0.88      0.93      0.90       152\n",
      "    positive       0.85      0.54      0.66        52\n",
      "\n",
      "    accuracy                           0.82       216\n",
      "   macro avg       0.70      0.71      0.68       216\n",
      "weighted avg       0.84      0.82      0.82       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.74      0.68        23\n",
      "     neutral       0.88      0.91      0.89       152\n",
      "    positive       0.81      0.63      0.71        41\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.77      0.76      0.76       216\n",
      "weighted avg       0.84      0.84      0.84       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.69      0.78        13\n",
      "     neutral       0.95      0.99      0.97       186\n",
      "    positive       0.82      0.53      0.64        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.74      0.80       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.43      0.60        14\n",
      "     neutral       0.90      1.00      0.95       185\n",
      "    positive       1.00      0.24      0.38        17\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.97      0.55      0.64       216\n",
      "weighted avg       0.91      0.90      0.88       216\n",
      "\n",
      "Total train time: 76.07384538650513 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 73\n",
      "Sampling duration: 16.081094980239868 seconds\n",
      "New train size: 208\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5867, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Epoch 2/10, Train Loss: 0.5156, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 3/10, Train Loss: 0.4686, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4517, Accuracy: 0.8155, F1 Micro: 0.8947, F1 Macro: 0.8934\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4099, Accuracy: 0.8311, F1 Micro: 0.9028, F1 Macro: 0.9016\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3525, Accuracy: 0.8802, F1 Micro: 0.928, F1 Macro: 0.9263\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3002, Accuracy: 0.9048, F1 Micro: 0.942, F1 Macro: 0.9405\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.245, Accuracy: 0.9167, F1 Micro: 0.9488, F1 Macro: 0.9469\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2086, Accuracy: 0.9338, F1 Micro: 0.9592, F1 Macro: 0.9571\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1671, Accuracy: 0.9405, F1 Micro: 0.9631, F1 Macro: 0.9614\n",
      "\n",
      "Aspect detection accuracy: 0.9405, F1 Micro: 0.9631, F1 Macro: 0.9614\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.97      1.00      0.98       187\n",
      "     machine       0.94      0.99      0.97       175\n",
      "      others       0.87      0.92      0.90       158\n",
      "        part       0.94      0.99      0.97       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.95      1.00      0.97       191\n",
      "\n",
      "   micro avg       0.94      0.98      0.96      1061\n",
      "   macro avg       0.94      0.98      0.96      1061\n",
      "weighted avg       0.94      0.98      0.96      1061\n",
      " samples avg       0.94      0.99      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6486, Accuracy: 0.6814, F1 Micro: 0.6814, F1 Macro: 0.4053\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5304, Accuracy: 0.6991, F1 Micro: 0.6991, F1 Macro: 0.4732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4413, Accuracy: 0.8894, F1 Micro: 0.8894, F1 Macro: 0.8712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2573, Accuracy: 0.9027, F1 Micro: 0.9027, F1 Macro: 0.8879\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1655, Accuracy: 0.9071, F1 Micro: 0.9071, F1 Macro: 0.8975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1735, Accuracy: 0.9159, F1 Micro: 0.9159, F1 Macro: 0.9049\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1431, Accuracy: 0.9159, F1 Micro: 0.9159, F1 Macro: 0.9073\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1047, Accuracy: 0.9159, F1 Micro: 0.9159, F1 Macro: 0.9073\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0692, Accuracy: 0.9159, F1 Micro: 0.9159, F1 Macro: 0.9067\n",
      "Epoch 10/10, Train Loss: 0.0632, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.9027\n",
      "\n",
      "Sentiment analysis accuracy: 0.9159, F1 Micro: 0.9159, F1 Macro: 0.9067\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.94      0.88        72\n",
      "    positive       0.97      0.90      0.94       154\n",
      "\n",
      "    accuracy                           0.92       226\n",
      "   macro avg       0.90      0.92      0.91       226\n",
      "weighted avg       0.92      0.92      0.92       226\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 208: Accuracy: 0.929, F1 Micro: 0.929, F1 Macro: 0.8492\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.97      1.00      0.99       181\n",
      "    positive       1.00      0.79      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.96      0.90      0.93       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.94      0.99      0.97       167\n",
      "    positive       0.92      0.70      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.81      0.85       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.42      0.67      0.52        12\n",
      "     neutral       0.88      0.92      0.90       152\n",
      "    positive       0.81      0.58      0.67        52\n",
      "\n",
      "    accuracy                           0.82       216\n",
      "   macro avg       0.70      0.72      0.70       216\n",
      "weighted avg       0.83      0.82      0.82       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.87      0.89        23\n",
      "     neutral       0.94      0.99      0.96       152\n",
      "    positive       0.94      0.76      0.84        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.87      0.90       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.84      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.64      0.78        14\n",
      "     neutral       0.94      1.00      0.97       185\n",
      "    positive       1.00      0.65      0.79        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.98      0.76      0.85       216\n",
      "weighted avg       0.95      0.95      0.94       216\n",
      "\n",
      "Total train time: 82.88583517074585 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 66\n",
      "Sampling duration: 15.22960877418518 seconds\n",
      "New train size: 274\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5769, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Epoch 2/10, Train Loss: 0.5068, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4727, Accuracy: 0.7961, F1 Micro: 0.885, F1 Macro: 0.8831\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4229, Accuracy: 0.8266, F1 Micro: 0.9003, F1 Macro: 0.8988\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3563, Accuracy: 0.8795, F1 Micro: 0.9273, F1 Macro: 0.9251\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2852, Accuracy: 0.904, F1 Micro: 0.941, F1 Macro: 0.9383\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2257, Accuracy: 0.9226, F1 Micro: 0.9517, F1 Macro: 0.9477\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.181, Accuracy: 0.9457, F1 Micro: 0.9664, F1 Macro: 0.9649\n",
      "Epoch 9/10, Train Loss: 0.1492, Accuracy: 0.9449, F1 Micro: 0.9658, F1 Macro: 0.9643\n",
      "Epoch 10/10, Train Loss: 0.1248, Accuracy: 0.9427, F1 Micro: 0.964, F1 Macro: 0.961\n",
      "\n",
      "Aspect detection accuracy: 0.9457, F1 Micro: 0.9664, F1 Macro: 0.9649\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.94      0.99      0.96       175\n",
      "      others       0.88      0.94      0.91       158\n",
      "        part       0.94      1.00      0.97       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       0.95      1.00      0.97       191\n",
      "\n",
      "   micro avg       0.95      0.99      0.97      1061\n",
      "   macro avg       0.94      0.99      0.96      1061\n",
      "weighted avg       0.95      0.99      0.97      1061\n",
      " samples avg       0.95      0.99      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.603, Accuracy: 0.6756, F1 Micro: 0.6756, F1 Macro: 0.4032\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4655, Accuracy: 0.8844, F1 Micro: 0.8844, F1 Macro: 0.8672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2822, Accuracy: 0.9111, F1 Micro: 0.9111, F1 Macro: 0.9013\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1873, Accuracy: 0.92, F1 Micro: 0.92, F1 Macro: 0.9088\n",
      "Epoch 5/10, Train Loss: 0.1717, Accuracy: 0.8889, F1 Micro: 0.8889, F1 Macro: 0.8804\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1146, Accuracy: 0.9378, F1 Micro: 0.9378, F1 Macro: 0.9309\n",
      "Epoch 7/10, Train Loss: 0.144, Accuracy: 0.88, F1 Micro: 0.88, F1 Macro: 0.8721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1419, Accuracy: 0.9556, F1 Micro: 0.9556, F1 Macro: 0.9497\n",
      "Epoch 9/10, Train Loss: 0.0838, Accuracy: 0.8533, F1 Micro: 0.8533, F1 Macro: 0.8463\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1427, Accuracy: 0.9556, F1 Micro: 0.9556, F1 Macro: 0.9497\n",
      "\n",
      "Sentiment analysis accuracy: 0.9556, F1 Micro: 0.9556, F1 Macro: 0.9497\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.95      0.93        73\n",
      "    positive       0.97      0.96      0.97       152\n",
      "\n",
      "    accuracy                           0.96       225\n",
      "   macro avg       0.95      0.95      0.95       225\n",
      "weighted avg       0.96      0.96      0.96       225\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 274: Accuracy: 0.9298, F1 Micro: 0.9298, F1 Macro: 0.8583\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.83      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.26      0.83      0.40        12\n",
      "     neutral       0.92      0.83      0.87       152\n",
      "    positive       0.83      0.65      0.73        52\n",
      "\n",
      "    accuracy                           0.79       216\n",
      "   macro avg       0.67      0.77      0.67       216\n",
      "weighted avg       0.86      0.79      0.81       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.87      0.91        23\n",
      "     neutral       0.95      1.00      0.97       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.95      0.89      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.85      0.81        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.71      0.83        14\n",
      "     neutral       0.95      1.00      0.97       185\n",
      "    positive       1.00      0.65      0.79        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.98      0.79      0.86       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Total train time: 81.98612689971924 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 59\n",
      "Sampling duration: 14.22540807723999 seconds\n",
      "New train size: 333\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5594, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Epoch 2/10, Train Loss: 0.5047, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4525, Accuracy: 0.8155, F1 Micro: 0.894, F1 Macro: 0.8918\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3738, Accuracy: 0.8772, F1 Micro: 0.9262, F1 Macro: 0.9247\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2892, Accuracy: 0.9129, F1 Micro: 0.9464, F1 Macro: 0.9435\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2309, Accuracy: 0.9368, F1 Micro: 0.9611, F1 Macro: 0.9596\n",
      "Epoch 7/10, Train Loss: 0.1866, Accuracy: 0.936, F1 Micro: 0.9602, F1 Macro: 0.9571\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1399, Accuracy: 0.9464, F1 Micro: 0.9664, F1 Macro: 0.964\n",
      "Epoch 9/10, Train Loss: 0.1214, Accuracy: 0.942, F1 Micro: 0.9634, F1 Macro: 0.96\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1008, Accuracy: 0.9472, F1 Micro: 0.9669, F1 Macro: 0.9643\n",
      "\n",
      "Aspect detection accuracy: 0.9472, F1 Micro: 0.9669, F1 Macro: 0.9643\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.94      0.99      0.96       175\n",
      "      others       0.93      0.87      0.90       158\n",
      "        part       0.92      1.00      0.96       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.97      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.95      0.98      0.96      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5796, Accuracy: 0.6892, F1 Micro: 0.6892, F1 Macro: 0.408\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4027, Accuracy: 0.9124, F1 Micro: 0.9124, F1 Macro: 0.8929\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2251, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9284\n",
      "Epoch 4/10, Train Loss: 0.1568, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.919\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.122, Accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9358\n",
      "Epoch 6/10, Train Loss: 0.151, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.92\n",
      "Epoch 7/10, Train Loss: 0.117, Accuracy: 0.9402, F1 Micro: 0.9402, F1 Macro: 0.9319\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1197, Accuracy: 0.9602, F1 Micro: 0.9602, F1 Macro: 0.9541\n",
      "Epoch 9/10, Train Loss: 0.0831, Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.946\n",
      "Epoch 10/10, Train Loss: 0.0994, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9246\n",
      "\n",
      "Sentiment analysis accuracy: 0.9602, F1 Micro: 0.9602, F1 Macro: 0.9541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        78\n",
      "    positive       0.98      0.96      0.97       173\n",
      "\n",
      "    accuracy                           0.96       251\n",
      "   macro avg       0.95      0.96      0.95       251\n",
      "weighted avg       0.96      0.96      0.96       251\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 333: Accuracy: 0.936, F1 Micro: 0.936, F1 Macro: 0.8782\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       1.00      0.88      0.93        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.84      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.59      0.83      0.69        12\n",
      "     neutral       0.94      0.87      0.90       152\n",
      "    positive       0.69      0.77      0.73        52\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.74      0.82      0.77       216\n",
      "weighted avg       0.86      0.84      0.85       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.87      0.83        23\n",
      "     neutral       0.92      1.00      0.96       152\n",
      "    positive       1.00      0.61      0.76        41\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.91      0.83      0.85       216\n",
      "weighted avg       0.92      0.91      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.97      1.00      0.98       185\n",
      "    positive       1.00      0.76      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.99      0.87      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 85.7019727230072 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 54\n",
      "Sampling duration: 13.512813806533813 seconds\n",
      "New train size: 387\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.549, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 2/10, Train Loss: 0.4821, Accuracy: 0.7879, F1 Micro: 0.8805, F1 Macro: 0.8783\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4178, Accuracy: 0.8445, F1 Micro: 0.9083, F1 Macro: 0.9064\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3371, Accuracy: 0.9077, F1 Micro: 0.9428, F1 Macro: 0.9401\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2423, Accuracy: 0.9368, F1 Micro: 0.9606, F1 Macro: 0.9584\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1774, Accuracy: 0.9487, F1 Micro: 0.9681, F1 Macro: 0.9666\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1438, Accuracy: 0.9509, F1 Micro: 0.9692, F1 Macro: 0.9669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1147, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9722\n",
      "Epoch 9/10, Train Loss: 0.0897, Accuracy: 0.9554, F1 Micro: 0.9721, F1 Macro: 0.9703\n",
      "Epoch 10/10, Train Loss: 0.0782, Accuracy: 0.9546, F1 Micro: 0.9715, F1 Macro: 0.9692\n",
      "\n",
      "Aspect detection accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9722\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.94      0.99      0.97       175\n",
      "      others       0.91      0.92      0.91       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5702, Accuracy: 0.7165, F1 Micro: 0.7165, F1 Macro: 0.5139\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3425, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9131\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1889, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9265\n",
      "Epoch 4/10, Train Loss: 0.1472, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9181\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.124, Accuracy: 0.9488, F1 Micro: 0.9488, F1 Macro: 0.942\n",
      "Epoch 6/10, Train Loss: 0.1625, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9366\n",
      "Epoch 7/10, Train Loss: 0.0833, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9297\n",
      "Epoch 8/10, Train Loss: 0.1039, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9327\n",
      "Epoch 9/10, Train Loss: 0.0831, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9237\n",
      "Epoch 10/10, Train Loss: 0.0647, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9331\n",
      "\n",
      "Sentiment analysis accuracy: 0.9488, F1 Micro: 0.9488, F1 Macro: 0.942\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.92        81\n",
      "    positive       0.98      0.95      0.96       173\n",
      "\n",
      "    accuracy                           0.95       254\n",
      "   macro avg       0.94      0.95      0.94       254\n",
      "weighted avg       0.95      0.95      0.95       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 387: Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.887\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.84      0.86       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.42      0.83      0.56        12\n",
      "     neutral       0.95      0.88      0.91       152\n",
      "    positive       0.81      0.81      0.81        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.72      0.84      0.76       216\n",
      "weighted avg       0.89      0.86      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.87      0.86      0.86       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.99      0.92      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 102.14319968223572 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 48\n",
      "Sampling duration: 11.62133526802063 seconds\n",
      "New train size: 435\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.557, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4751, Accuracy: 0.7954, F1 Micro: 0.8842, F1 Macro: 0.8821\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4162, Accuracy: 0.8594, F1 Micro: 0.9158, F1 Macro: 0.9122\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3158, Accuracy: 0.9219, F1 Micro: 0.952, F1 Macro: 0.9499\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2252, Accuracy: 0.9435, F1 Micro: 0.9647, F1 Macro: 0.9622\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1728, Accuracy: 0.9516, F1 Micro: 0.9697, F1 Macro: 0.9678\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1382, Accuracy: 0.9583, F1 Micro: 0.974, F1 Macro: 0.9729\n",
      "Epoch 8/10, Train Loss: 0.109, Accuracy: 0.9539, F1 Micro: 0.9709, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0876, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0756, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.974\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.974\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.94      0.91      0.92       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5524, Accuracy: 0.8409, F1 Micro: 0.8409, F1 Macro: 0.794\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2735, Accuracy: 0.9053, F1 Micro: 0.9053, F1 Macro: 0.885\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1627, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9245\n",
      "Epoch 4/10, Train Loss: 0.1336, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9168\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1011, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9285\n",
      "Epoch 6/10, Train Loss: 0.1015, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9241\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0743, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9285\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0586, Accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.9393\n",
      "Epoch 9/10, Train Loss: 0.0613, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9145\n",
      "Epoch 10/10, Train Loss: 0.043, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9204\n",
      "\n",
      "Sentiment analysis accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.9393\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.93      0.92        84\n",
      "    positive       0.97      0.96      0.96       180\n",
      "\n",
      "    accuracy                           0.95       264\n",
      "   macro avg       0.94      0.94      0.94       264\n",
      "weighted avg       0.95      0.95      0.95       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 435: Accuracy: 0.9491, F1 Micro: 0.9491, F1 Macro: 0.8948\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.62      0.77        16\n",
      "     neutral       0.94      0.99      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.94      0.80      0.85       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.67      0.73        12\n",
      "     neutral       0.95      0.91      0.93       152\n",
      "    positive       0.72      0.83      0.77        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.82      0.80      0.81       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.88      0.86      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 104.32910394668579 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 43\n",
      "Sampling duration: 11.03088927268982 seconds\n",
      "New train size: 478\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5511, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4691, Accuracy: 0.7946, F1 Micro: 0.883, F1 Macro: 0.8801\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4045, Accuracy: 0.8534, F1 Micro: 0.9122, F1 Macro: 0.9101\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.302, Accuracy: 0.9211, F1 Micro: 0.951, F1 Macro: 0.9486\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2203, Accuracy: 0.9487, F1 Micro: 0.9681, F1 Macro: 0.9669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1631, Accuracy: 0.9524, F1 Micro: 0.9703, F1 Macro: 0.969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1307, Accuracy: 0.9561, F1 Micro: 0.9726, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0968, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9762\n",
      "Epoch 9/10, Train Loss: 0.084, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.974\n",
      "Epoch 10/10, Train Loss: 0.0739, Accuracy: 0.9568, F1 Micro: 0.9728, F1 Macro: 0.971\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.91      0.96      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5556, Accuracy: 0.7733, F1 Micro: 0.7733, F1 Macro: 0.6637\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3026, Accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9389\n",
      "Epoch 3/10, Train Loss: 0.1824, Accuracy: 0.9393, F1 Micro: 0.9393, F1 Macro: 0.9279\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1416, Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.9449\n",
      "Epoch 5/10, Train Loss: 0.135, Accuracy: 0.9352, F1 Micro: 0.9352, F1 Macro: 0.929\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0754, Accuracy: 0.9595, F1 Micro: 0.9595, F1 Macro: 0.9544\n",
      "Epoch 7/10, Train Loss: 0.1151, Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.9456\n",
      "Epoch 8/10, Train Loss: 0.0642, Accuracy: 0.9352, F1 Micro: 0.9352, F1 Macro: 0.929\n",
      "Epoch 9/10, Train Loss: 0.0805, Accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9419\n",
      "Epoch 10/10, Train Loss: 0.0571, Accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9408\n",
      "\n",
      "Sentiment analysis accuracy: 0.9595, F1 Micro: 0.9595, F1 Macro: 0.9544\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.96      0.94        80\n",
      "    positive       0.98      0.96      0.97       167\n",
      "\n",
      "    accuracy                           0.96       247\n",
      "   macro avg       0.95      0.96      0.95       247\n",
      "weighted avg       0.96      0.96      0.96       247\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 478: Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.8836\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.85      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.36      0.75      0.49        12\n",
      "     neutral       0.93      0.90      0.92       152\n",
      "    positive       0.89      0.75      0.81        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.73      0.80      0.74       216\n",
      "weighted avg       0.89      0.86      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.80      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.69      0.72        13\n",
      "     neutral       0.98      0.99      0.98       186\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.85      0.82      0.83       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 102.82649970054626 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 39\n",
      "Sampling duration: 9.850057125091553 seconds\n",
      "New train size: 517\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5455, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4718, Accuracy: 0.8132, F1 Micro: 0.8924, F1 Macro: 0.8899\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3664, Accuracy: 0.904, F1 Micro: 0.9418, F1 Macro: 0.9396\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2561, Accuracy: 0.9442, F1 Micro: 0.9653, F1 Macro: 0.9636\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1846, Accuracy: 0.9501, F1 Micro: 0.9687, F1 Macro: 0.9665\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1405, Accuracy: 0.9546, F1 Micro: 0.9714, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1036, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9725\n",
      "Epoch 8/10, Train Loss: 0.0895, Accuracy: 0.9591, F1 Micro: 0.9741, F1 Macro: 0.9723\n",
      "Epoch 9/10, Train Loss: 0.0732, Accuracy: 0.9554, F1 Micro: 0.9719, F1 Macro: 0.9699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0603, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9728\n",
      "\n",
      "Aspect detection accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9728\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.89      0.91       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.97      0.97      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5576, Accuracy: 0.8246, F1 Micro: 0.8246, F1 Macro: 0.7601\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3133, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9315\n",
      "Epoch 3/10, Train Loss: 0.2248, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.9279\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.165, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9315\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1197, Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9483\n",
      "Epoch 6/10, Train Loss: 0.1024, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9331\n",
      "Epoch 7/10, Train Loss: 0.0955, Accuracy: 0.9478, F1 Micro: 0.9478, F1 Macro: 0.9389\n",
      "Epoch 8/10, Train Loss: 0.076, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9371\n",
      "Epoch 9/10, Train Loss: 0.0763, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9352\n",
      "Epoch 10/10, Train Loss: 0.0584, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.9256\n",
      "\n",
      "Sentiment analysis accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9483\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        85\n",
      "    positive       0.97      0.97      0.97       183\n",
      "\n",
      "    accuracy                           0.96       268\n",
      "   macro avg       0.95      0.95      0.95       268\n",
      "weighted avg       0.96      0.96      0.96       268\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 517: Accuracy: 0.9483, F1 Micro: 0.9483, F1 Macro: 0.8988\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.92      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.88      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.81      0.90        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.86      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.94      0.89      0.92       152\n",
      "    positive       0.72      0.83      0.77        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.85      0.85      0.85       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.87      0.85        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.90      0.85      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.90      0.90      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.69      0.78        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.90      0.84      0.86       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.96      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 107.12583875656128 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 23\n",
      "Sampling duration: 9.13655948638916 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5404, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4761, Accuracy: 0.8021, F1 Micro: 0.8879, F1 Macro: 0.8862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3773, Accuracy: 0.8988, F1 Micro: 0.9378, F1 Macro: 0.9354\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2717, Accuracy: 0.9412, F1 Micro: 0.9633, F1 Macro: 0.9615\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1961, Accuracy: 0.9472, F1 Micro: 0.9667, F1 Macro: 0.9641\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1501, Accuracy: 0.9554, F1 Micro: 0.9718, F1 Macro: 0.9696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1094, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0936, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.076, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0646, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.94      0.94      0.94       158\n",
      "        part       0.96      0.99      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.548, Accuracy: 0.8677, F1 Micro: 0.8677, F1 Macro: 0.8387\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2719, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9316\n",
      "Epoch 3/10, Train Loss: 0.1859, Accuracy: 0.8988, F1 Micro: 0.8988, F1 Macro: 0.8924\n",
      "Epoch 4/10, Train Loss: 0.1387, Accuracy: 0.8988, F1 Micro: 0.8988, F1 Macro: 0.8924\n",
      "Epoch 5/10, Train Loss: 0.1321, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9198\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1305, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9301\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0737, Accuracy: 0.9494, F1 Micro: 0.9494, F1 Macro: 0.944\n",
      "Epoch 8/10, Train Loss: 0.0871, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9316\n",
      "Epoch 9/10, Train Loss: 0.0618, Accuracy: 0.9222, F1 Micro: 0.9222, F1 Macro: 0.9131\n",
      "Epoch 10/10, Train Loss: 0.0608, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9319\n",
      "\n",
      "Sentiment analysis accuracy: 0.9494, F1 Micro: 0.9494, F1 Macro: 0.944\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.96      0.93        85\n",
      "    positive       0.98      0.94      0.96       172\n",
      "\n",
      "    accuracy                           0.95       257\n",
      "   macro avg       0.94      0.95      0.94       257\n",
      "weighted avg       0.95      0.95      0.95       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9138\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.94      0.91        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.96      0.76      0.85        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.89      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.92      0.81        12\n",
      "     neutral       0.95      0.94      0.94       152\n",
      "    positive       0.80      0.77      0.78        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.83      0.88      0.85       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.96      0.86        23\n",
      "     neutral       0.96      0.99      0.97       152\n",
      "    positive       0.97      0.76      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.90      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.93      0.89      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 112.45037603378296 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 33\n",
      "Sampling duration: 8.514427185058594 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5464, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4653, Accuracy: 0.8214, F1 Micro: 0.8966, F1 Macro: 0.8947\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3613, Accuracy: 0.9167, F1 Micro: 0.949, F1 Macro: 0.9471\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2425, Accuracy: 0.9375, F1 Micro: 0.9611, F1 Macro: 0.959\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1766, Accuracy: 0.9457, F1 Micro: 0.9657, F1 Macro: 0.962\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1398, Accuracy: 0.9501, F1 Micro: 0.9685, F1 Macro: 0.9661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1038, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0877, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9728\n",
      "Epoch 9/10, Train Loss: 0.0664, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9722\n",
      "Epoch 10/10, Train Loss: 0.0588, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9715\n",
      "\n",
      "Aspect detection accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9728\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.92      0.92      0.92       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5163, Accuracy: 0.8842, F1 Micro: 0.8842, F1 Macro: 0.8702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2333, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9394\n",
      "Epoch 3/10, Train Loss: 0.1714, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9349\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1709, Accuracy: 0.9575, F1 Micro: 0.9575, F1 Macro: 0.9508\n",
      "Epoch 5/10, Train Loss: 0.1423, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9193\n",
      "Epoch 6/10, Train Loss: 0.0868, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9234\n",
      "Epoch 7/10, Train Loss: 0.1235, Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9439\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0758, Accuracy: 0.9614, F1 Micro: 0.9614, F1 Macro: 0.9557\n",
      "Epoch 9/10, Train Loss: 0.0726, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9274\n",
      "Epoch 10/10, Train Loss: 0.0419, Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9465\n",
      "\n",
      "Sentiment analysis accuracy: 0.9614, F1 Micro: 0.9614, F1 Macro: 0.9557\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.95      0.94        82\n",
      "    positive       0.98      0.97      0.97       177\n",
      "\n",
      "    accuracy                           0.96       259\n",
      "   macro avg       0.95      0.96      0.96       259\n",
      "weighted avg       0.96      0.96      0.96       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.9007\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.85      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.92      0.85        12\n",
      "     neutral       0.94      0.90      0.92       152\n",
      "    positive       0.79      0.85      0.81        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.84      0.89      0.86       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.88      0.92        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.96      0.95      0.95       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.69      0.78        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.76      0.76      0.76        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.88      0.82      0.84       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 111.9375433921814 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 30\n",
      "Sampling duration: 7.7062668800354 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5417, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4592, Accuracy: 0.8356, F1 Micro: 0.9042, F1 Macro: 0.9022\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3326, Accuracy: 0.9226, F1 Micro: 0.9518, F1 Macro: 0.949\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2224, Accuracy: 0.9449, F1 Micro: 0.9656, F1 Macro: 0.9633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.175, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1298, Accuracy: 0.965, F1 Micro: 0.9782, F1 Macro: 0.9772\n",
      "Epoch 7/10, Train Loss: 0.106, Accuracy: 0.9583, F1 Micro: 0.9737, F1 Macro: 0.9713\n",
      "Epoch 8/10, Train Loss: 0.0807, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9769\n",
      "Epoch 9/10, Train Loss: 0.067, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9738\n",
      "Epoch 10/10, Train Loss: 0.0581, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9763\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.9782, F1 Macro: 0.9772\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.91      0.97      0.94       158\n",
      "        part       0.96      1.00      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.98      1061\n",
      "weighted avg       0.96      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5403, Accuracy: 0.8484, F1 Micro: 0.8484, F1 Macro: 0.8139\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3137, Accuracy: 0.918, F1 Micro: 0.918, F1 Macro: 0.9128\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.173, Accuracy: 0.9508, F1 Micro: 0.9508, F1 Macro: 0.9455\n",
      "Epoch 4/10, Train Loss: 0.0969, Accuracy: 0.9426, F1 Micro: 0.9426, F1 Macro: 0.9378\n",
      "Epoch 5/10, Train Loss: 0.1154, Accuracy: 0.9426, F1 Micro: 0.9426, F1 Macro: 0.9345\n",
      "Epoch 6/10, Train Loss: 0.1319, Accuracy: 0.9426, F1 Micro: 0.9426, F1 Macro: 0.9381\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1097, Accuracy: 0.9508, F1 Micro: 0.9508, F1 Macro: 0.9467\n",
      "Epoch 8/10, Train Loss: 0.0824, Accuracy: 0.9467, F1 Micro: 0.9467, F1 Macro: 0.9424\n",
      "Epoch 9/10, Train Loss: 0.0701, Accuracy: 0.9467, F1 Micro: 0.9467, F1 Macro: 0.9424\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0468, Accuracy: 0.9508, F1 Micro: 0.9508, F1 Macro: 0.9461\n",
      "\n",
      "Sentiment analysis accuracy: 0.9508, F1 Micro: 0.9508, F1 Macro: 0.9461\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.96      0.93        83\n",
      "    positive       0.98      0.94      0.96       161\n",
      "\n",
      "    accuracy                           0.95       244\n",
      "   macro avg       0.94      0.95      0.95       244\n",
      "weighted avg       0.95      0.95      0.95       244\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.8937\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.97      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.94      0.91        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.89      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.43      0.83      0.57        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.90      0.73      0.81        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.76      0.83      0.77       216\n",
      "weighted avg       0.90      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.96      0.86        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.88      0.87      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 120.88556957244873 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 27\n",
      "Sampling duration: 7.045317649841309 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5332, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4605, Accuracy: 0.8356, F1 Micro: 0.903, F1 Macro: 0.9008\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3392, Accuracy: 0.9263, F1 Micro: 0.9541, F1 Macro: 0.9515\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2225, Accuracy: 0.9509, F1 Micro: 0.9695, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1543, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1186, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9754\n",
      "Epoch 7/10, Train Loss: 0.0928, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0772, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9753\n",
      "Epoch 9/10, Train Loss: 0.0609, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9725\n",
      "Epoch 10/10, Train Loss: 0.0551, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9751\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9753\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.94      0.91      0.92       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5357, Accuracy: 0.794, F1 Micro: 0.794, F1 Macro: 0.7061\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2693, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9254\n",
      "Epoch 3/10, Train Loss: 0.1884, Accuracy: 0.9288, F1 Micro: 0.9288, F1 Macro: 0.9218\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1462, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9376\n",
      "Epoch 5/10, Train Loss: 0.1262, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9261\n",
      "Epoch 6/10, Train Loss: 0.0951, Accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.9109\n",
      "Epoch 7/10, Train Loss: 0.0817, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.925\n",
      "Epoch 8/10, Train Loss: 0.0603, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9265\n",
      "Epoch 9/10, Train Loss: 0.0815, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.925\n",
      "Epoch 10/10, Train Loss: 0.04, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9148\n",
      "\n",
      "Sentiment analysis accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9376\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.97      0.92        87\n",
      "    positive       0.98      0.93      0.96       180\n",
      "\n",
      "    accuracy                           0.94       267\n",
      "   macro avg       0.93      0.95      0.94       267\n",
      "weighted avg       0.95      0.94      0.94       267\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.946, F1 Micro: 0.946, F1 Macro: 0.8884\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.97      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.94      0.91        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.88      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.48      0.92      0.63        12\n",
      "     neutral       0.95      0.87      0.91       152\n",
      "    positive       0.76      0.79      0.77        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.73      0.86      0.77       216\n",
      "weighted avg       0.88      0.85      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.76      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.91      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      1.00      0.88        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.76      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.92      0.91       216\n",
      "weighted avg       0.99      0.98      0.98       216\n",
      "\n",
      "Total train time: 116.07552576065063 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 18\n",
      "Sampling duration: 6.4441680908203125 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5299, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4577, Accuracy: 0.8348, F1 Micro: 0.9037, F1 Macro: 0.902\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3156, Accuracy: 0.9345, F1 Micro: 0.9596, F1 Macro: 0.9581\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2078, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1539, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9738\n",
      "Epoch 6/10, Train Loss: 0.1138, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0908, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9762\n",
      "Epoch 8/10, Train Loss: 0.0744, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.974\n",
      "Epoch 9/10, Train Loss: 0.0614, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.974\n",
      "Epoch 10/10, Train Loss: 0.05, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.976\n",
      "\n",
      "Aspect detection accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.92      0.94      0.93       158\n",
      "        part       0.99      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4954, Accuracy: 0.8943, F1 Micro: 0.8943, F1 Macro: 0.8772\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.264, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9319\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1486, Accuracy: 0.9509, F1 Micro: 0.9509, F1 Macro: 0.9439\n",
      "Epoch 4/10, Train Loss: 0.1506, Accuracy: 0.883, F1 Micro: 0.883, F1 Macro: 0.8742\n",
      "Epoch 5/10, Train Loss: 0.1807, Accuracy: 0.9132, F1 Micro: 0.9132, F1 Macro: 0.9045\n",
      "Epoch 6/10, Train Loss: 0.1155, Accuracy: 0.9094, F1 Micro: 0.9094, F1 Macro: 0.9011\n",
      "Epoch 7/10, Train Loss: 0.1087, Accuracy: 0.9358, F1 Micro: 0.9358, F1 Macro: 0.9279\n",
      "Epoch 8/10, Train Loss: 0.103, Accuracy: 0.9245, F1 Micro: 0.9245, F1 Macro: 0.9159\n",
      "Epoch 9/10, Train Loss: 0.0763, Accuracy: 0.9245, F1 Micro: 0.9245, F1 Macro: 0.9163\n",
      "Epoch 10/10, Train Loss: 0.0634, Accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.936\n",
      "\n",
      "Sentiment analysis accuracy: 0.9509, F1 Micro: 0.9509, F1 Macro: 0.9439\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.92        83\n",
      "    positive       0.98      0.95      0.96       182\n",
      "\n",
      "    accuracy                           0.95       265\n",
      "   macro avg       0.94      0.95      0.94       265\n",
      "weighted avg       0.95      0.95      0.95       265\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9085\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.48      0.92      0.63        12\n",
      "     neutral       0.94      0.89      0.92       152\n",
      "    positive       0.80      0.75      0.77        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.74      0.85      0.77       216\n",
      "weighted avg       0.88      0.86      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.99      0.98      0.98       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.93      0.89      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 116.48571228981018 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 6.115655422210693 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5275, Accuracy: 0.7902, F1 Micro: 0.8826, F1 Macro: 0.8811\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4406, Accuracy: 0.8504, F1 Micro: 0.912, F1 Macro: 0.9102\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.297, Accuracy: 0.9338, F1 Micro: 0.9592, F1 Macro: 0.9576\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2058, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.974\n",
      "Epoch 5/10, Train Loss: 0.1478, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9717\n",
      "Epoch 6/10, Train Loss: 0.1078, Accuracy: 0.9591, F1 Micro: 0.9741, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0882, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0672, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9757\n",
      "Epoch 9/10, Train Loss: 0.0563, Accuracy: 0.9606, F1 Micro: 0.9749, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0479, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9761\n",
      "\n",
      "Aspect detection accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9761\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.93      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.98      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.528, Accuracy: 0.8881, F1 Micro: 0.8881, F1 Macro: 0.8682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2726, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9331\n",
      "Epoch 3/10, Train Loss: 0.1682, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.9291\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1149, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9323\n",
      "Epoch 5/10, Train Loss: 0.1504, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9229\n",
      "Epoch 6/10, Train Loss: 0.1133, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.9287\n",
      "Epoch 7/10, Train Loss: 0.0965, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.927\n",
      "Epoch 8/10, Train Loss: 0.0785, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9189\n",
      "Epoch 9/10, Train Loss: 0.0683, Accuracy: 0.9179, F1 Micro: 0.9179, F1 Macro: 0.9103\n",
      "Epoch 10/10, Train Loss: 0.059, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9212\n",
      "\n",
      "Sentiment analysis accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9323\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.93      0.91        86\n",
      "    positive       0.97      0.95      0.96       182\n",
      "\n",
      "    accuracy                           0.94       268\n",
      "   macro avg       0.93      0.94      0.93       268\n",
      "weighted avg       0.94      0.94      0.94       268\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9046\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.83      0.73      0.77        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.86      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.79      0.81      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.85      0.83      0.84       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.76      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.91      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.98      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.91      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 122.56330823898315 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.408713102340698 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5306, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4404, Accuracy: 0.8705, F1 Micro: 0.923, F1 Macro: 0.9214\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3121, Accuracy: 0.9375, F1 Micro: 0.9615, F1 Macro: 0.9599\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2175, Accuracy: 0.9546, F1 Micro: 0.9716, F1 Macro: 0.9701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1488, Accuracy: 0.9643, F1 Micro: 0.9777, F1 Macro: 0.9768\n",
      "Epoch 6/10, Train Loss: 0.1172, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9762\n",
      "Epoch 7/10, Train Loss: 0.0896, Accuracy: 0.9568, F1 Micro: 0.9727, F1 Macro: 0.9705\n",
      "Epoch 8/10, Train Loss: 0.074, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9756\n",
      "Epoch 9/10, Train Loss: 0.0581, Accuracy: 0.9583, F1 Micro: 0.9737, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0521, Accuracy: 0.965, F1 Micro: 0.9778, F1 Macro: 0.9761\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.9778, F1 Macro: 0.9761\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.95      0.90      0.93       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.97      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5049, Accuracy: 0.8949, F1 Micro: 0.8949, F1 Macro: 0.8833\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.266, Accuracy: 0.9312, F1 Micro: 0.9312, F1 Macro: 0.9223\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1509, Accuracy: 0.9457, F1 Micro: 0.9457, F1 Macro: 0.9383\n",
      "Epoch 4/10, Train Loss: 0.1591, Accuracy: 0.9275, F1 Micro: 0.9275, F1 Macro: 0.9197\n",
      "Epoch 5/10, Train Loss: 0.1232, Accuracy: 0.942, F1 Micro: 0.942, F1 Macro: 0.9329\n",
      "Epoch 6/10, Train Loss: 0.1024, Accuracy: 0.9203, F1 Micro: 0.9203, F1 Macro: 0.9126\n",
      "Epoch 7/10, Train Loss: 0.1013, Accuracy: 0.9312, F1 Micro: 0.9312, F1 Macro: 0.9205\n",
      "Epoch 8/10, Train Loss: 0.0942, Accuracy: 0.9312, F1 Micro: 0.9312, F1 Macro: 0.9223\n",
      "Epoch 9/10, Train Loss: 0.0724, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.9088\n",
      "Epoch 10/10, Train Loss: 0.0492, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.9088\n",
      "\n",
      "Sentiment analysis accuracy: 0.9457, F1 Micro: 0.9457, F1 Macro: 0.9383\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.95      0.92        87\n",
      "    positive       0.98      0.94      0.96       189\n",
      "\n",
      "    accuracy                           0.95       276\n",
      "   macro avg       0.93      0.95      0.94       276\n",
      "weighted avg       0.95      0.95      0.95       276\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.9035\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       1.00      0.88      0.93        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.86      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      1.00      0.80        12\n",
      "     neutral       0.96      0.89      0.93       152\n",
      "    positive       0.75      0.81      0.78        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.79      0.90      0.83       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      1.00      0.85        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.94      0.76      0.84        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.91      0.89       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 123.6581780910492 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.9932639598846436 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5214, Accuracy: 0.7909, F1 Micro: 0.883, F1 Macro: 0.8814\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4323, Accuracy: 0.8586, F1 Micro: 0.9154, F1 Macro: 0.9128\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2906, Accuracy: 0.9435, F1 Micro: 0.9649, F1 Macro: 0.9633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1948, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.14, Accuracy: 0.9621, F1 Micro: 0.9763, F1 Macro: 0.9753\n",
      "Epoch 6/10, Train Loss: 0.1051, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9721\n",
      "Epoch 7/10, Train Loss: 0.0821, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0673, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0564, Accuracy: 0.9702, F1 Micro: 0.9812, F1 Macro: 0.9799\n",
      "Epoch 10/10, Train Loss: 0.048, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.978\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9812, F1 Macro: 0.9799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.94      0.93      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4778, Accuracy: 0.9015, F1 Micro: 0.9015, F1 Macro: 0.8892\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2436, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9249\n",
      "Epoch 3/10, Train Loss: 0.1787, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9201\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1514, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9249\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1357, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9289\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.097, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9293\n",
      "Epoch 7/10, Train Loss: 0.0713, Accuracy: 0.9205, F1 Micro: 0.9205, F1 Macro: 0.9135\n",
      "Epoch 8/10, Train Loss: 0.0618, Accuracy: 0.9205, F1 Micro: 0.9205, F1 Macro: 0.9122\n",
      "Epoch 9/10, Train Loss: 0.0618, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9173\n",
      "Epoch 10/10, Train Loss: 0.0675, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.8986\n",
      "\n",
      "Sentiment analysis accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9293\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.97      0.91        87\n",
      "    positive       0.98      0.92      0.95       177\n",
      "\n",
      "    accuracy                           0.94       264\n",
      "   macro avg       0.92      0.94      0.93       264\n",
      "weighted avg       0.94      0.94      0.94       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.8813\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.82      0.82        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.75      0.69        16\n",
      "     neutral       0.97      0.98      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.82      0.83      0.82       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.95      0.92      0.93       152\n",
      "    positive       0.77      0.83      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.82      0.83      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.91      0.87        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.92      0.88      0.90        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.92      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.62      0.73        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.76      0.94      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.88      0.85      0.85       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 132.35389757156372 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: \n",
      "25Sampling duration: 4.349328279495239 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5273, Accuracy: 0.7902, F1 Micro: 0.8826, F1 Macro: 0.8811\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.422, Accuracy: 0.8854, F1 Micro: 0.9309, F1 Macro: 0.9288\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2771, Accuracy: 0.9487, F1 Micro: 0.968, F1 Macro: 0.9664\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1796, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1343, Accuracy: 0.9591, F1 Micro: 0.9741, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1025, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0791, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0681, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9798\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0613, Accuracy: 0.9725, F1 Micro: 0.9827, F1 Macro: 0.9817\n",
      "Epoch 10/10, Train Loss: 0.0457, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9791\n",
      "\n",
      "Aspect detection accuracy: 0.9725, F1 Micro: 0.9827, F1 Macro: 0.9817\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.96      0.95       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.98      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.98      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4698, Accuracy: 0.8817, F1 Micro: 0.8817, F1 Macro: 0.8729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2101, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.929\n",
      "Epoch 3/10, Train Loss: 0.1949, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.9018\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.141, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.9312\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1341, Accuracy: 0.9466, F1 Micro: 0.9466, F1 Macro: 0.9404\n",
      "Epoch 6/10, Train Loss: 0.1137, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9279\n",
      "Epoch 7/10, Train Loss: 0.0612, Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.9242\n",
      "Epoch 8/10, Train Loss: 0.0739, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9283\n",
      "Epoch 9/10, Train Loss: 0.0775, Accuracy: 0.9237, F1 Micro: 0.9237, F1 Macro: 0.917\n",
      "Epoch 10/10, Train Loss: 0.0533, Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.9242\n",
      "\n",
      "Sentiment analysis accuracy: 0.9466, F1 Micro: 0.9466, F1 Macro: 0.9404\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        87\n",
      "    positive       0.97      0.95      0.96       175\n",
      "\n",
      "    accuracy                           0.95       262\n",
      "   macro avg       0.94      0.95      0.94       262\n",
      "weighted avg       0.95      0.95      0.95       262\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9058\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.95      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.88      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.83      0.74        12\n",
      "     neutral       0.94      0.95      0.94       152\n",
      "    positive       0.85      0.79      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.82      0.86      0.84       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      1.00      0.85        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       1.00      0.80      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.91       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.92      0.83        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 136.48439955711365 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 8\n",
      "Sampling duration: 3.6248412132263184 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5185, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4299, Accuracy: 0.8981, F1 Micro: 0.9378, F1 Macro: 0.9354\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2746, Accuracy: 0.9509, F1 Micro: 0.9693, F1 Macro: 0.9676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1735, Accuracy: 0.9554, F1 Micro: 0.9719, F1 Macro: 0.9699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1353, Accuracy: 0.9613, F1 Micro: 0.9759, F1 Macro: 0.9748\n",
      "Epoch 6/10, Train Loss: 0.1065, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0841, Accuracy: 0.9628, F1 Micro: 0.9764, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0679, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9775\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0554, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9781\n",
      "Epoch 10/10, Train Loss: 0.0441, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9776\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.93      0.94      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.498, Accuracy: 0.9057, F1 Micro: 0.9057, F1 Macro: 0.8921\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2448, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9327\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1798, Accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.936\n",
      "Epoch 4/10, Train Loss: 0.1573, Accuracy: 0.9358, F1 Micro: 0.9358, F1 Macro: 0.9287\n",
      "Epoch 5/10, Train Loss: 0.1255, Accuracy: 0.9321, F1 Micro: 0.9321, F1 Macro: 0.9239\n",
      "Epoch 6/10, Train Loss: 0.086, Accuracy: 0.9358, F1 Micro: 0.9358, F1 Macro: 0.9257\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0857, Accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.936\n",
      "Epoch 8/10, Train Loss: 0.0616, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.9199\n",
      "Epoch 9/10, Train Loss: 0.0768, Accuracy: 0.9208, F1 Micro: 0.9208, F1 Macro: 0.9057\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0622, Accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.9405\n",
      "\n",
      "Sentiment analysis accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.9405\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        84\n",
      "    positive       0.98      0.94      0.96       181\n",
      "\n",
      "    accuracy                           0.95       265\n",
      "   macro avg       0.93      0.95      0.94       265\n",
      "weighted avg       0.95      0.95      0.95       265\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.9182\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.85      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.81      0.81      0.81        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.83      0.83      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.94      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      1.00      1.00       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.92      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 136.60111689567566 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.661203622817993 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5224, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4287, Accuracy: 0.8973, F1 Micro: 0.9383, F1 Macro: 0.9364\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2715, Accuracy: 0.9539, F1 Micro: 0.9713, F1 Macro: 0.9699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1806, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1272, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "Epoch 6/10, Train Loss: 0.0954, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0746, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9783\n",
      "Epoch 8/10, Train Loss: 0.0603, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9756\n",
      "Epoch 9/10, Train Loss: 0.0499, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9763\n",
      "Epoch 10/10, Train Loss: 0.0466, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9775\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9783\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.93      0.95      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4691, Accuracy: 0.9219, F1 Micro: 0.9219, F1 Macro: 0.9119\n",
      "Epoch 2/10, Train Loss: 0.225, Accuracy: 0.918, F1 Micro: 0.918, F1 Macro: 0.9115\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1589, Accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9442\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1445, Accuracy: 0.9531, F1 Micro: 0.9531, F1 Macro: 0.9468\n",
      "Epoch 5/10, Train Loss: 0.1206, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9341\n",
      "Epoch 6/10, Train Loss: 0.1089, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9384\n",
      "Epoch 7/10, Train Loss: 0.0833, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9281\n",
      "Epoch 8/10, Train Loss: 0.1003, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9352\n",
      "Epoch 9/10, Train Loss: 0.0707, Accuracy: 0.9102, F1 Micro: 0.9102, F1 Macro: 0.9035\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.074, Accuracy: 0.9648, F1 Micro: 0.9648, F1 Macro: 0.9603\n",
      "\n",
      "Sentiment analysis accuracy: 0.9648, F1 Micro: 0.9648, F1 Macro: 0.9603\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.94      0.95        85\n",
      "    positive       0.97      0.98      0.97       171\n",
      "\n",
      "    accuracy                           0.96       256\n",
      "   macro avg       0.96      0.96      0.96       256\n",
      "weighted avg       0.96      0.96      0.96       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.921\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.85      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.92      0.73        12\n",
      "     neutral       0.93      0.92      0.93       152\n",
      "    positive       0.85      0.79      0.82        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.80      0.88      0.83       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.96      0.94        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.95      0.90      0.92        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.95      0.95       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.99      1.00      1.00       186\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.93      0.90        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.93      0.94      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 141.0215082168579 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.912639856338501 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.521, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4194, Accuracy: 0.8943, F1 Micro: 0.9344, F1 Macro: 0.93\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2607, Accuracy: 0.9516, F1 Micro: 0.9699, F1 Macro: 0.9682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1687, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.125, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0941, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0744, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.978\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0635, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9799\n",
      "Epoch 9/10, Train Loss: 0.049, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9787\n",
      "Epoch 10/10, Train Loss: 0.046, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9773\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.97      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4653, Accuracy: 0.8846, F1 Micro: 0.8846, F1 Macro: 0.8781\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2349, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.9092\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1561, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9109\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1396, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9327\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1269, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9368\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.096, Accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.9452\n",
      "Epoch 7/10, Train Loss: 0.0879, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9313\n",
      "Epoch 8/10, Train Loss: 0.0662, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9207\n",
      "Epoch 9/10, Train Loss: 0.0521, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.925\n",
      "Epoch 10/10, Train Loss: 0.0554, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9272\n",
      "\n",
      "Sentiment analysis accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.9452\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.93        87\n",
      "    positive       0.99      0.94      0.96       173\n",
      "\n",
      "    accuracy                           0.95       260\n",
      "   macro avg       0.94      0.96      0.95       260\n",
      "weighted avg       0.95      0.95      0.95       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.8976\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.96      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.86      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.92      0.65        12\n",
      "     neutral       0.95      0.93      0.94       152\n",
      "    positive       0.87      0.75      0.80        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.77      0.86      0.80       216\n",
      "weighted avg       0.90      0.88      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.97      0.88      0.92        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.95      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.91      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.94      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 143.99378418922424 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.338932991027832 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.531, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4167, Accuracy: 0.8958, F1 Micro: 0.9363, F1 Macro: 0.9332\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.267, Accuracy: 0.9516, F1 Micro: 0.97, F1 Macro: 0.9686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1787, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1283, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9771\n",
      "Epoch 6/10, Train Loss: 0.0956, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9764\n",
      "Epoch 7/10, Train Loss: 0.077, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0603, Accuracy: 0.9658, F1 Micro: 0.9783, F1 Macro: 0.9766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0529, Accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9793\n",
      "Epoch 10/10, Train Loss: 0.0436, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9764\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.94      0.93      0.93       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4772, Accuracy: 0.9301, F1 Micro: 0.9301, F1 Macro: 0.919\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2044, Accuracy: 0.9301, F1 Micro: 0.9301, F1 Macro: 0.9179\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1644, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9379\n",
      "Epoch 4/10, Train Loss: 0.1485, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9266\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1148, Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9459\n",
      "Epoch 6/10, Train Loss: 0.1097, Accuracy: 0.9191, F1 Micro: 0.9191, F1 Macro: 0.911\n",
      "Epoch 7/10, Train Loss: 0.0857, Accuracy: 0.9265, F1 Micro: 0.9265, F1 Macro: 0.9187\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0755, Accuracy: 0.9559, F1 Micro: 0.9559, F1 Macro: 0.9493\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0767, Accuracy: 0.9596, F1 Micro: 0.9596, F1 Macro: 0.9531\n",
      "Epoch 10/10, Train Loss: 0.0683, Accuracy: 0.9338, F1 Micro: 0.9338, F1 Macro: 0.9261\n",
      "\n",
      "Sentiment analysis accuracy: 0.9596, F1 Micro: 0.9596, F1 Macro: 0.9531\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.94        86\n",
      "    positive       0.97      0.97      0.97       186\n",
      "\n",
      "    accuracy                           0.96       272\n",
      "   macro avg       0.95      0.95      0.95       272\n",
      "weighted avg       0.96      0.96      0.96       272\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9123\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.89      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.92      0.79        12\n",
      "     neutral       0.95      0.91      0.93       152\n",
      "    positive       0.79      0.81      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.81      0.88      0.84       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.92      0.80        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.88      0.89      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 142.76154446601868 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.761279582977295 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5202, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4065, Accuracy: 0.9196, F1 Micro: 0.9506, F1 Macro: 0.9481\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2473, Accuracy: 0.9568, F1 Micro: 0.9732, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1641, Accuracy: 0.9621, F1 Micro: 0.9763, F1 Macro: 0.9749\n",
      "Epoch 5/10, Train Loss: 0.1286, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9725\n",
      "Epoch 6/10, Train Loss: 0.0983, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0705, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9775\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0611, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9796\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0493, Accuracy: 0.9702, F1 Micro: 0.9812, F1 Macro: 0.9799\n",
      "Epoch 10/10, Train Loss: 0.0431, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9794\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9812, F1 Macro: 0.9799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.94      0.94      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4584, Accuracy: 0.9368, F1 Micro: 0.9368, F1 Macro: 0.9284\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2376, Accuracy: 0.9368, F1 Micro: 0.9368, F1 Macro: 0.9296\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1935, Accuracy: 0.948, F1 Micro: 0.948, F1 Macro: 0.9416\n",
      "Epoch 4/10, Train Loss: 0.1203, Accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9376\n",
      "Epoch 5/10, Train Loss: 0.1068, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9336\n",
      "Epoch 6/10, Train Loss: 0.087, Accuracy: 0.9368, F1 Micro: 0.9368, F1 Macro: 0.9292\n",
      "Epoch 7/10, Train Loss: 0.0862, Accuracy: 0.9257, F1 Micro: 0.9257, F1 Macro: 0.9129\n",
      "Epoch 8/10, Train Loss: 0.0644, Accuracy: 0.9219, F1 Micro: 0.9219, F1 Macro: 0.9139\n",
      "Epoch 9/10, Train Loss: 0.0617, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9324\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.049, Accuracy: 0.948, F1 Micro: 0.948, F1 Macro: 0.9412\n",
      "\n",
      "Sentiment analysis accuracy: 0.948, F1 Micro: 0.948, F1 Macro: 0.9412\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.95      0.92        86\n",
      "    positive       0.98      0.95      0.96       183\n",
      "\n",
      "    accuracy                           0.95       269\n",
      "   macro avg       0.93      0.95      0.94       269\n",
      "weighted avg       0.95      0.95      0.95       269\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9274\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.97      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.82      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.87      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.94      0.93      0.93       152\n",
      "    positive       0.81      0.81      0.81        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.82      0.86      0.84       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.94      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.95      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 142.60943627357483 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 8\n",
      "Sampling duration: 0.9869859218597412 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5143, Accuracy: 0.7917, F1 Micro: 0.8833, F1 Macro: 0.8818\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4086, Accuracy: 0.9115, F1 Micro: 0.9456, F1 Macro: 0.9431\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2639, Accuracy: 0.9442, F1 Micro: 0.9649, F1 Macro: 0.962\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1747, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1291, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0903, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9773\n",
      "Epoch 7/10, Train Loss: 0.0716, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0578, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9776\n",
      "Epoch 9/10, Train Loss: 0.0483, Accuracy: 0.9598, F1 Micro: 0.9745, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0438, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9795\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9795\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.94      0.94      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4918, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8941\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2279, Accuracy: 0.9211, F1 Micro: 0.9211, F1 Macro: 0.9142\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1716, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.926\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1489, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9321\n",
      "Epoch 5/10, Train Loss: 0.1145, Accuracy: 0.9248, F1 Micro: 0.9248, F1 Macro: 0.913\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1242, Accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9409\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0707, Accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9402\n",
      "Epoch 8/10, Train Loss: 0.0838, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9308\n",
      "Epoch 9/10, Train Loss: 0.0886, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9213\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0516, Accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9402\n",
      "\n",
      "Sentiment analysis accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9402\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.93      0.92        86\n",
      "    positive       0.97      0.96      0.96       180\n",
      "\n",
      "    accuracy                           0.95       266\n",
      "   macro avg       0.94      0.94      0.94       266\n",
      "weighted avg       0.95      0.95      0.95       266\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9248\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.85      0.85      0.85        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.86      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.94      0.94      0.94       152\n",
      "    positive       0.81      0.81      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.86      0.86      0.86       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 148.96067333221436 s\n",
      "Total runtime: 3224.0110955238342 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[3], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d149b65",
   "metadata": {
    "papermill": {
     "duration": 0.141766,
     "end_time": "2025-03-02T17:42:51.782998",
     "exception": false,
     "start_time": "2025-03-02T17:42:51.641232",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db065149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 5\n",
      "Random seed: 94\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6298, Accuracy: 0.7522, F1 Micro: 0.854, F1 Macro: 0.8362\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5654, Accuracy: 0.7887, F1 Micro: 0.8819, F1 Macro: 0.8803\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5262, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4783, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4582, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4326, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4132, Accuracy: 0.7924, F1 Micro: 0.8837, F1 Macro: 0.8822\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4395, Accuracy: 0.7939, F1 Micro: 0.8842, F1 Macro: 0.8826\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.4306, Accuracy: 0.7999, F1 Micro: 0.887, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3956, Accuracy: 0.8036, F1 Micro: 0.8888, F1 Macro: 0.8871\n",
      "\n",
      "Aspect detection accuracy: 0.8036, F1 Micro: 0.8888, F1 Macro: 0.8871\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.78      1.00      0.88       175\n",
      "      others       0.75      0.99      0.85       158\n",
      "        part       0.74      0.97      0.84       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.80      0.99      0.89      1061\n",
      "   macro avg       0.80      0.99      0.89      1061\n",
      "weighted avg       0.81      0.99      0.89      1061\n",
      " samples avg       0.81      0.99      0.89      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7142, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5719, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.6151, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5677, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.5123, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.5138, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4932, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3579, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3098, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2431, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "\n",
      "Sentiment analysis accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         6\n",
      "    positive       0.81      1.00      0.89        25\n",
      "\n",
      "    accuracy                           0.81        31\n",
      "   macro avg       0.40      0.50      0.45        31\n",
      "weighted avg       0.65      0.81      0.72        31\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.7994, F1 Micro: 0.7994, F1 Macro: 0.3298\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.77      1.00      0.87       167\n",
      "    positive       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.77       216\n",
      "   macro avg       0.26      0.33      0.29       216\n",
      "weighted avg       0.60      0.77      0.67       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.75      0.99      0.85       152\n",
      "    positive       0.67      0.19      0.30        52\n",
      "\n",
      "    accuracy                           0.74       216\n",
      "   macro avg       0.47      0.39      0.38       216\n",
      "weighted avg       0.69      0.74      0.67       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        23\n",
      "     neutral       0.74      0.97      0.84       152\n",
      "    positive       0.56      0.22      0.32        41\n",
      "\n",
      "    accuracy                           0.73       216\n",
      "   macro avg       0.43      0.40      0.39       216\n",
      "weighted avg       0.63      0.73      0.65       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 63.271135568618774 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 81\n",
      "Sampling duration: 14.845274209976196 seconds\n",
      "New train size: 135\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6104, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4983, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4891, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4497, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4308, Accuracy: 0.8043, F1 Micro: 0.8894, F1 Macro: 0.8879\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4009, Accuracy: 0.814, F1 Micro: 0.8942, F1 Macro: 0.8928\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.36, Accuracy: 0.8341, F1 Micro: 0.9039, F1 Macro: 0.9031\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3365, Accuracy: 0.8415, F1 Micro: 0.9071, F1 Macro: 0.9056\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2583, Accuracy: 0.8519, F1 Micro: 0.9125, F1 Macro: 0.9108\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.24, Accuracy: 0.8646, F1 Micro: 0.9195, F1 Macro: 0.918\n",
      "\n",
      "Aspect detection accuracy: 0.8646, F1 Micro: 0.9195, F1 Macro: 0.918\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.85      1.00      0.92       187\n",
      "     machine       0.81      1.00      0.90       175\n",
      "      others       0.85      0.89      0.87       158\n",
      "        part       0.89      0.97      0.93       158\n",
      "       price       0.88      1.00      0.93       192\n",
      "     service       0.92      1.00      0.96       191\n",
      "\n",
      "   micro avg       0.87      0.98      0.92      1061\n",
      "   macro avg       0.87      0.98      0.92      1061\n",
      "weighted avg       0.87      0.98      0.92      1061\n",
      " samples avg       0.87      0.98      0.92      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.67, Accuracy: 0.7445, F1 Micro: 0.7445, F1 Macro: 0.4268\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.6039, Accuracy: 0.7445, F1 Micro: 0.7445, F1 Macro: 0.4268\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4801, Accuracy: 0.8102, F1 Micro: 0.8102, F1 Macro: 0.648\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.417, Accuracy: 0.8905, F1 Micro: 0.8905, F1 Macro: 0.8487\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2942, Accuracy: 0.8905, F1 Micro: 0.8905, F1 Macro: 0.8547\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1387, Accuracy: 0.927, F1 Micro: 0.927, F1 Macro: 0.9104\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0694, Accuracy: 0.9416, F1 Micro: 0.9416, F1 Macro: 0.9246\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.067, Accuracy: 0.9416, F1 Micro: 0.9416, F1 Macro: 0.9246\n",
      "Epoch 9/10, Train Loss: 0.0205, Accuracy: 0.9197, F1 Micro: 0.9197, F1 Macro: 0.8935\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0665, Accuracy: 0.9416, F1 Micro: 0.9416, F1 Macro: 0.9246\n",
      "\n",
      "Sentiment analysis accuracy: 0.9416, F1 Micro: 0.9416, F1 Macro: 0.9246\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.91      0.89        35\n",
      "    positive       0.97      0.95      0.96       102\n",
      "\n",
      "    accuracy                           0.94       137\n",
      "   macro avg       0.92      0.93      0.92       137\n",
      "weighted avg       0.94      0.94      0.94       137\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 135: Accuracy: 0.858, F1 Micro: 0.858, F1 Macro: 0.6023\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.09      0.17        11\n",
      "     neutral       0.85      1.00      0.92       181\n",
      "    positive       1.00      0.12      0.22        24\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.95      0.41      0.44       216\n",
      "weighted avg       0.88      0.86      0.81       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.19      0.32        16\n",
      "     neutral       0.81      1.00      0.89       167\n",
      "    positive       1.00      0.18      0.31        33\n",
      "\n",
      "    accuracy                           0.81       216\n",
      "   macro avg       0.94      0.46      0.51       216\n",
      "weighted avg       0.85      0.81      0.76       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.67      0.70        12\n",
      "     neutral       0.85      0.89      0.87       152\n",
      "    positive       0.67      0.60      0.63        52\n",
      "\n",
      "    accuracy                           0.81       216\n",
      "   macro avg       0.75      0.72      0.73       216\n",
      "weighted avg       0.80      0.81      0.80       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.57      0.68        23\n",
      "     neutral       0.89      0.97      0.93       152\n",
      "    positive       0.82      0.68      0.75        41\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.86      0.74      0.79       216\n",
      "weighted avg       0.87      0.88      0.87       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.08      0.14        13\n",
      "     neutral       0.87      1.00      0.93       186\n",
      "    positive       1.00      0.12      0.21        17\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.96      0.40      0.43       216\n",
      "weighted avg       0.89      0.88      0.83       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.43      0.60        14\n",
      "     neutral       0.92      1.00      0.96       185\n",
      "    positive       0.89      0.47      0.62        17\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.94      0.63      0.72       216\n",
      "weighted avg       0.92      0.92      0.91       216\n",
      "\n",
      "Total train time: 72.11938333511353 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 73\n",
      "Sampling duration: 16.54474973678589 seconds\n",
      "New train size: 208\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.595, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5103, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4914, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4547, Accuracy: 0.8051, F1 Micro: 0.8898, F1 Macro: 0.8883\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4016, Accuracy: 0.8326, F1 Micro: 0.9037, F1 Macro: 0.9029\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3579, Accuracy: 0.875, F1 Micro: 0.9255, F1 Macro: 0.9245\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2769, Accuracy: 0.9077, F1 Micro: 0.9442, F1 Macro: 0.9428\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2324, Accuracy: 0.9159, F1 Micro: 0.9479, F1 Macro: 0.9455\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1888, Accuracy: 0.9286, F1 Micro: 0.9559, F1 Macro: 0.954\n",
      "Epoch 10/10, Train Loss: 0.1682, Accuracy: 0.9286, F1 Micro: 0.9554, F1 Macro: 0.953\n",
      "\n",
      "Aspect detection accuracy: 0.9286, F1 Micro: 0.9559, F1 Macro: 0.954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.97      1.00      0.99       187\n",
      "     machine       0.92      0.99      0.95       175\n",
      "      others       0.87      0.92      0.90       158\n",
      "        part       0.92      0.97      0.94       158\n",
      "       price       0.94      0.98      0.96       192\n",
      "     service       0.96      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.93      0.98      0.96      1061\n",
      "   macro avg       0.93      0.98      0.95      1061\n",
      "weighted avg       0.93      0.98      0.96      1061\n",
      " samples avg       0.94      0.98      0.95      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6453, Accuracy: 0.6727, F1 Micro: 0.6727, F1 Macro: 0.4022\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5693, Accuracy: 0.6727, F1 Micro: 0.6727, F1 Macro: 0.4022\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4591, Accuracy: 0.8818, F1 Micro: 0.8818, F1 Macro: 0.8581\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2478, Accuracy: 0.9227, F1 Micro: 0.9227, F1 Macro: 0.9158\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1853, Accuracy: 0.9364, F1 Micro: 0.9364, F1 Macro: 0.9287\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1651, Accuracy: 0.9364, F1 Micro: 0.9364, F1 Macro: 0.9305\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0726, Accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9367\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0803, Accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9401\n",
      "Epoch 9/10, Train Loss: 0.0975, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9257\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.067, Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9494\n",
      "\n",
      "Sentiment analysis accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9494\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.93        72\n",
      "    positive       0.99      0.95      0.97       148\n",
      "\n",
      "    accuracy                           0.95       220\n",
      "   macro avg       0.94      0.96      0.95       220\n",
      "weighted avg       0.96      0.95      0.95       220\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 208: Accuracy: 0.9182, F1 Micro: 0.9182, F1 Macro: 0.8378\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       1.00      0.88      0.93        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.93      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      0.81      0.76        16\n",
      "     neutral       0.92      0.98      0.95       167\n",
      "    positive       1.00      0.61      0.75        33\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.88      0.80      0.82       216\n",
      "weighted avg       0.92      0.91      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.53      0.67      0.59        12\n",
      "     neutral       0.88      0.91      0.89       152\n",
      "    positive       0.75      0.63      0.69        52\n",
      "\n",
      "    accuracy                           0.83       216\n",
      "   macro avg       0.72      0.74      0.72       216\n",
      "weighted avg       0.83      0.83      0.83       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.87      0.74        23\n",
      "     neutral       0.92      0.93      0.93       152\n",
      "    positive       0.90      0.68      0.78        41\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.82      0.83      0.82       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.77      0.74        13\n",
      "     neutral       0.97      0.98      0.97       186\n",
      "    positive       0.79      0.65      0.71        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.82      0.80      0.81       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.96      1.00      0.98       185\n",
      "    positive       1.00      0.71      0.83        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.99      0.85      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 79.52189588546753 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 66\n",
      "Sampling duration: 16.792799949645996 seconds\n",
      "New train size: 274\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5774, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5142, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4784, Accuracy: 0.8013, F1 Micro: 0.8882, F1 Macro: 0.8868\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4134, Accuracy: 0.8408, F1 Micro: 0.9078, F1 Macro: 0.9071\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3496, Accuracy: 0.9018, F1 Micro: 0.9411, F1 Macro: 0.9401\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2642, Accuracy: 0.9338, F1 Micro: 0.9592, F1 Macro: 0.9576\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.203, Accuracy: 0.9442, F1 Micro: 0.9655, F1 Macro: 0.9643\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1729, Accuracy: 0.9449, F1 Micro: 0.9658, F1 Macro: 0.9645\n",
      "Epoch 9/10, Train Loss: 0.1306, Accuracy: 0.9427, F1 Micro: 0.9643, F1 Macro: 0.963\n",
      "Epoch 10/10, Train Loss: 0.1176, Accuracy: 0.9435, F1 Micro: 0.9648, F1 Macro: 0.9638\n",
      "\n",
      "Aspect detection accuracy: 0.9449, F1 Micro: 0.9658, F1 Macro: 0.9645\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.94      0.99      0.96       175\n",
      "      others       0.89      0.95      0.92       158\n",
      "        part       0.94      0.99      0.96       158\n",
      "       price       0.97      0.98      0.98       192\n",
      "     service       0.96      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.95      0.99      0.97      1061\n",
      "   macro avg       0.95      0.98      0.96      1061\n",
      "weighted avg       0.95      0.99      0.97      1061\n",
      " samples avg       0.95      0.99      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6, Accuracy: 0.684, F1 Micro: 0.684, F1 Macro: 0.4062\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4019, Accuracy: 0.8658, F1 Micro: 0.8658, F1 Macro: 0.8418\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2463, Accuracy: 0.9437, F1 Micro: 0.9437, F1 Macro: 0.9373\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1174, Accuracy: 0.9567, F1 Micro: 0.9567, F1 Macro: 0.951\n",
      "Epoch 5/10, Train Loss: 0.1529, Accuracy: 0.9437, F1 Micro: 0.9437, F1 Macro: 0.9369\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0581, Accuracy: 0.961, F1 Micro: 0.961, F1 Macro: 0.9557\n",
      "Epoch 7/10, Train Loss: 0.0697, Accuracy: 0.9481, F1 Micro: 0.9481, F1 Macro: 0.9416\n",
      "Epoch 8/10, Train Loss: 0.0442, Accuracy: 0.9437, F1 Micro: 0.9437, F1 Macro: 0.9365\n",
      "Epoch 9/10, Train Loss: 0.0586, Accuracy: 0.9524, F1 Micro: 0.9524, F1 Macro: 0.9459\n",
      "Epoch 10/10, Train Loss: 0.0352, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9323\n",
      "\n",
      "Sentiment analysis accuracy: 0.961, F1 Micro: 0.961, F1 Macro: 0.9557\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94        73\n",
      "    positive       0.99      0.96      0.97       158\n",
      "\n",
      "    accuracy                           0.96       231\n",
      "   macro avg       0.95      0.96      0.96       231\n",
      "weighted avg       0.96      0.96      0.96       231\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 274: Accuracy: 0.9329, F1 Micro: 0.9329, F1 Macro: 0.8591\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.94      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.93      0.98      0.95       167\n",
      "    positive       0.96      0.73      0.83        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.84      0.86       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.67      0.70        12\n",
      "     neutral       0.89      0.95      0.92       152\n",
      "    positive       0.84      0.69      0.76        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.82      0.77      0.79       216\n",
      "weighted avg       0.87      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.66      1.00      0.79        23\n",
      "     neutral       0.97      0.96      0.96       152\n",
      "    positive       1.00      0.73      0.85        41\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.87      0.90      0.87       216\n",
      "weighted avg       0.94      0.92      0.92       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.69      0.69        13\n",
      "     neutral       0.97      0.97      0.97       186\n",
      "    positive       0.75      0.71      0.73        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.80      0.79      0.80       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.71      0.80        14\n",
      "     neutral       0.96      1.00      0.98       185\n",
      "    positive       1.00      0.71      0.83        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.96      0.81      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Total train time: 75.7036030292511 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 59\n",
      "Sampling duration: 14.750372171401978 seconds\n",
      "New train size: 333\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5611, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4914, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4449, Accuracy: 0.8266, F1 Micro: 0.9008, F1 Macro: 0.9\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3734, Accuracy: 0.8936, F1 Micro: 0.9365, F1 Macro: 0.936\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2936, Accuracy: 0.9323, F1 Micro: 0.9583, F1 Macro: 0.9574\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2087, Accuracy: 0.9479, F1 Micro: 0.9675, F1 Macro: 0.9661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1644, Accuracy: 0.9524, F1 Micro: 0.9705, F1 Macro: 0.9695\n",
      "Epoch 8/10, Train Loss: 0.1283, Accuracy: 0.9494, F1 Micro: 0.9684, F1 Macro: 0.9674\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1109, Accuracy: 0.9539, F1 Micro: 0.9711, F1 Macro: 0.9701\n",
      "Epoch 10/10, Train Loss: 0.0923, Accuracy: 0.9524, F1 Micro: 0.9702, F1 Macro: 0.9692\n",
      "\n",
      "Aspect detection accuracy: 0.9539, F1 Micro: 0.9711, F1 Macro: 0.9701\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.94      0.98      0.96       175\n",
      "      others       0.91      0.97      0.94       158\n",
      "        part       0.97      0.96      0.97       158\n",
      "       price       0.98      0.97      0.98       192\n",
      "     service       0.97      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5666, Accuracy: 0.6787, F1 Micro: 0.6787, F1 Macro: 0.4043\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3759, Accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.9048\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.166, Accuracy: 0.9317, F1 Micro: 0.9317, F1 Macro: 0.9215\n",
      "Epoch 4/10, Train Loss: 0.1494, Accuracy: 0.8876, F1 Micro: 0.8876, F1 Macro: 0.8793\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1071, Accuracy: 0.9317, F1 Micro: 0.9317, F1 Macro: 0.9198\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0695, Accuracy: 0.9598, F1 Micro: 0.9598, F1 Macro: 0.9543\n",
      "Epoch 7/10, Train Loss: 0.0766, Accuracy: 0.9076, F1 Micro: 0.9076, F1 Macro: 0.8997\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0547, Accuracy: 0.9598, F1 Micro: 0.9598, F1 Macro: 0.9543\n",
      "Epoch 9/10, Train Loss: 0.0382, Accuracy: 0.9357, F1 Micro: 0.9357, F1 Macro: 0.9286\n",
      "Epoch 10/10, Train Loss: 0.0376, Accuracy: 0.9558, F1 Micro: 0.9558, F1 Macro: 0.9498\n",
      "\n",
      "Sentiment analysis accuracy: 0.9598, F1 Micro: 0.9598, F1 Macro: 0.9543\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.95      0.94        80\n",
      "    positive       0.98      0.96      0.97       169\n",
      "\n",
      "    accuracy                           0.96       249\n",
      "   macro avg       0.95      0.96      0.95       249\n",
      "weighted avg       0.96      0.96      0.96       249\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 333: Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.8964\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.94      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.85      0.89       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.91      0.97      0.94       152\n",
      "    positive       0.91      0.79      0.85        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.91      0.84      0.87       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.96      0.83        23\n",
      "     neutral       0.97      0.95      0.96       152\n",
      "    positive       0.89      0.83      0.86        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.91      0.88       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.98      0.97      0.98       186\n",
      "    positive       0.67      0.82      0.74        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.85      0.86      0.85       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.97      1.00      0.98       185\n",
      "    positive       1.00      0.76      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.99      0.87      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 82.20098853111267 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 54\n",
      "Sampling duration: 13.686758995056152 seconds\n",
      "New train size: 387\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5502, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4702, Accuracy: 0.8036, F1 Micro: 0.8893, F1 Macro: 0.8878\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4076, Accuracy: 0.8557, F1 Micro: 0.9157, F1 Macro: 0.9148\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3228, Accuracy: 0.9249, F1 Micro: 0.9542, F1 Macro: 0.9529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2444, Accuracy: 0.9442, F1 Micro: 0.9656, F1 Macro: 0.9644\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1779, Accuracy: 0.9464, F1 Micro: 0.9665, F1 Macro: 0.965\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1405, Accuracy: 0.9509, F1 Micro: 0.9693, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1031, Accuracy: 0.9546, F1 Micro: 0.9716, F1 Macro: 0.9706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0887, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9733\n",
      "Epoch 10/10, Train Loss: 0.0746, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.972\n",
      "\n",
      "Aspect detection accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9733\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.91      0.97      0.94       158\n",
      "        part       0.97      0.97      0.97       158\n",
      "       price       0.98      0.98      0.98       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.577, Accuracy: 0.6825, F1 Micro: 0.6825, F1 Macro: 0.4057\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.343, Accuracy: 0.8968, F1 Micro: 0.8968, F1 Macro: 0.8871\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1376, Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9367\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1137, Accuracy: 0.9563, F1 Micro: 0.9563, F1 Macro: 0.9495\n",
      "Epoch 5/10, Train Loss: 0.1425, Accuracy: 0.9127, F1 Micro: 0.9127, F1 Macro: 0.9045\n",
      "Epoch 6/10, Train Loss: 0.0887, Accuracy: 0.9524, F1 Micro: 0.9524, F1 Macro: 0.9458\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0824, Accuracy: 0.9563, F1 Micro: 0.9563, F1 Macro: 0.9504\n",
      "Epoch 8/10, Train Loss: 0.0658, Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9379\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0534, Accuracy: 0.9563, F1 Micro: 0.9563, F1 Macro: 0.9507\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0362, Accuracy: 0.9603, F1 Micro: 0.9603, F1 Macro: 0.9539\n",
      "\n",
      "Sentiment analysis accuracy: 0.9603, F1 Micro: 0.9603, F1 Macro: 0.9539\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.93      0.94        80\n",
      "    positive       0.97      0.98      0.97       172\n",
      "\n",
      "    accuracy                           0.96       252\n",
      "   macro avg       0.96      0.95      0.95       252\n",
      "weighted avg       0.96      0.96      0.96       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 387: Accuracy: 0.9483, F1 Micro: 0.9483, F1 Macro: 0.8936\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.98      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.75      0.86        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.84      0.88       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.45      0.75      0.56        12\n",
      "     neutral       0.92      0.93      0.92       152\n",
      "    positive       0.91      0.75      0.82        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.76      0.81      0.77       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.99      0.97      0.98       152\n",
      "    positive       0.88      0.90      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.98      0.98      0.98       186\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.88      0.86      0.86       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.93      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 93.2670590877533 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 48\n",
      "Sampling duration: 12.837330341339111 seconds\n",
      "New train size: 435\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.555, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4784, Accuracy: 0.7999, F1 Micro: 0.8875, F1 Macro: 0.8861\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4106, Accuracy: 0.8728, F1 Micro: 0.925, F1 Macro: 0.9241\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3221, Accuracy: 0.9315, F1 Micro: 0.958, F1 Macro: 0.957\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.216, Accuracy: 0.9479, F1 Micro: 0.9675, F1 Macro: 0.9659\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1686, Accuracy: 0.9546, F1 Micro: 0.9717, F1 Macro: 0.9704\n",
      "Epoch 7/10, Train Loss: 0.133, Accuracy: 0.9524, F1 Micro: 0.9702, F1 Macro: 0.9689\n",
      "Epoch 8/10, Train Loss: 0.1038, Accuracy: 0.9531, F1 Micro: 0.9705, F1 Macro: 0.9688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0828, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0725, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9721\n",
      "\n",
      "Aspect detection accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9721\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.96      0.95       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.97      0.96      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6093, Accuracy: 0.6897, F1 Micro: 0.6897, F1 Macro: 0.4198\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3384, Accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.9067\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1705, Accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.9015\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1566, Accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.9397\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1344, Accuracy: 0.9579, F1 Micro: 0.9579, F1 Macro: 0.9506\n",
      "Epoch 6/10, Train Loss: 0.0988, Accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.9369\n",
      "Epoch 7/10, Train Loss: 0.1183, Accuracy: 0.9042, F1 Micro: 0.9042, F1 Macro: 0.8953\n",
      "Epoch 8/10, Train Loss: 0.056, Accuracy: 0.954, F1 Micro: 0.954, F1 Macro: 0.9467\n",
      "Epoch 9/10, Train Loss: 0.0783, Accuracy: 0.931, F1 Micro: 0.931, F1 Macro: 0.9158\n",
      "Epoch 10/10, Train Loss: 0.0568, Accuracy: 0.9387, F1 Micro: 0.9387, F1 Macro: 0.9314\n",
      "\n",
      "Sentiment analysis accuracy: 0.9579, F1 Micro: 0.9579, F1 Macro: 0.9506\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.91      0.93        82\n",
      "    positive       0.96      0.98      0.97       179\n",
      "\n",
      "    accuracy                           0.96       261\n",
      "   macro avg       0.96      0.95      0.95       261\n",
      "weighted avg       0.96      0.96      0.96       261\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 435: Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.8989\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.88      0.82        16\n",
      "     neutral       0.95      0.96      0.95       167\n",
      "    positive       0.83      0.73      0.77        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.85      0.85      0.85       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.92      0.96      0.94       152\n",
      "    positive       0.87      0.79      0.83        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.87      0.83      0.85       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       0.92      0.85      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.88      0.87      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 90.42585372924805 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 43\n",
      "Sampling duration: 11.615781784057617 seconds\n",
      "New train size: 478\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5473, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4938, Accuracy: 0.8051, F1 Micro: 0.8899, F1 Macro: 0.8887\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3874, Accuracy: 0.8832, F1 Micro: 0.9307, F1 Macro: 0.9299\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2883, Accuracy: 0.942, F1 Micro: 0.9641, F1 Macro: 0.9631\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2089, Accuracy: 0.9509, F1 Micro: 0.9694, F1 Macro: 0.9685\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.155, Accuracy: 0.9568, F1 Micro: 0.9731, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1219, Accuracy: 0.9613, F1 Micro: 0.9759, F1 Macro: 0.9748\n",
      "Epoch 8/10, Train Loss: 0.0949, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9747\n",
      "Epoch 9/10, Train Loss: 0.0866, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9739\n",
      "Epoch 10/10, Train Loss: 0.0715, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9726\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.9759, F1 Macro: 0.9748\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.91      0.97      0.94       158\n",
      "        part       0.97      0.97      0.97       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.97      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.97      1061\n",
      "weighted avg       0.96      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5412, Accuracy: 0.823, F1 Micro: 0.823, F1 Macro: 0.7634\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.249, Accuracy: 0.9465, F1 Micro: 0.9465, F1 Macro: 0.9388\n",
      "Epoch 3/10, Train Loss: 0.1421, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9189\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1564, Accuracy: 0.963, F1 Micro: 0.963, F1 Macro: 0.9587\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1495, Accuracy: 0.9671, F1 Micro: 0.9671, F1 Macro: 0.9627\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1127, Accuracy: 0.9671, F1 Micro: 0.9671, F1 Macro: 0.9632\n",
      "Epoch 7/10, Train Loss: 0.1037, Accuracy: 0.963, F1 Micro: 0.963, F1 Macro: 0.9577\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0944, Accuracy: 0.9671, F1 Micro: 0.9671, F1 Macro: 0.963\n",
      "Epoch 9/10, Train Loss: 0.0463, Accuracy: 0.963, F1 Micro: 0.963, F1 Macro: 0.9585\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0438, Accuracy: 0.9671, F1 Micro: 0.9671, F1 Macro: 0.9634\n",
      "\n",
      "Sentiment analysis accuracy: 0.9671, F1 Micro: 0.9671, F1 Macro: 0.9634\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.99      0.95        80\n",
      "    positive       0.99      0.96      0.97       163\n",
      "\n",
      "    accuracy                           0.97       243\n",
      "   macro avg       0.96      0.97      0.96       243\n",
      "weighted avg       0.97      0.97      0.97       243\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 478: Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9003\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.41      0.75      0.53        12\n",
      "     neutral       0.92      0.91      0.92       152\n",
      "    positive       0.91      0.75      0.82        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.75      0.80      0.76       216\n",
      "weighted avg       0.89      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.99      0.97      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.90      0.93      0.91       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 97.8409514427185 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 39\n",
      "Sampling duration: 10.308473825454712 seconds\n",
      "New train size: 517\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5468, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.469, Accuracy: 0.808, F1 Micro: 0.8916, F1 Macro: 0.8902\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3781, Accuracy: 0.9234, F1 Micro: 0.9533, F1 Macro: 0.9518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2531, Accuracy: 0.9524, F1 Micro: 0.9706, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1765, Accuracy: 0.9546, F1 Micro: 0.9716, F1 Macro: 0.9697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1281, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0987, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.078, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9769\n",
      "Epoch 9/10, Train Loss: 0.0692, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9766\n",
      "Epoch 10/10, Train Loss: 0.0611, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.976\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.97      0.96       175\n",
      "      others       0.93      0.96      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5267, Accuracy: 0.6783, F1 Micro: 0.6783, F1 Macro: 0.4042\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2606, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9351\n",
      "Epoch 3/10, Train Loss: 0.1631, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9265\n",
      "Epoch 4/10, Train Loss: 0.1751, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.9161\n",
      "Epoch 5/10, Train Loss: 0.0997, Accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.9155\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1015, Accuracy: 0.9457, F1 Micro: 0.9457, F1 Macro: 0.9396\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1259, Accuracy: 0.9457, F1 Micro: 0.9457, F1 Macro: 0.9396\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0631, Accuracy: 0.9496, F1 Micro: 0.9496, F1 Macro: 0.9438\n",
      "Epoch 9/10, Train Loss: 0.0834, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9323\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0511, Accuracy: 0.9574, F1 Micro: 0.9574, F1 Macro: 0.9524\n",
      "\n",
      "Sentiment analysis accuracy: 0.9574, F1 Micro: 0.9574, F1 Macro: 0.9524\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.99      0.94        83\n",
      "    positive       0.99      0.94      0.97       175\n",
      "\n",
      "    accuracy                           0.96       258\n",
      "   macro avg       0.94      0.97      0.95       258\n",
      "weighted avg       0.96      0.96      0.96       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 517: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.9187\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.94      0.88        16\n",
      "     neutral       0.95      0.97      0.96       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.88      0.88       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.94      0.95      0.94       152\n",
      "    positive       0.88      0.87      0.87        52\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.91      0.86      0.88       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      1.00      0.85        23\n",
      "     neutral       0.99      0.97      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.90      0.93      0.91       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.90      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 100.16364431381226 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Acquired samples: 23\n",
      "Sampling duration: 9.530159711837769 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5495, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4808, Accuracy: 0.8125, F1 Micro: 0.8938, F1 Macro: 0.8924\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3665, Accuracy: 0.9278, F1 Micro: 0.956, F1 Macro: 0.9547\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2535, Accuracy: 0.9442, F1 Micro: 0.9653, F1 Macro: 0.9635\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1849, Accuracy: 0.9524, F1 Micro: 0.9702, F1 Macro: 0.9687\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1347, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1071, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9767\n",
      "Epoch 8/10, Train Loss: 0.0819, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9753\n",
      "Epoch 9/10, Train Loss: 0.0714, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9738\n",
      "Epoch 10/10, Train Loss: 0.066, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.976\n",
      "\n",
      "Aspect detection accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.91      0.98      0.94       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5382, Accuracy: 0.8167, F1 Micro: 0.8167, F1 Macro: 0.7659\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2522, Accuracy: 0.9243, F1 Micro: 0.9243, F1 Macro: 0.9183\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.142, Accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9388\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1473, Accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9388\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1143, Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9472\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0965, Accuracy: 0.9602, F1 Micro: 0.9602, F1 Macro: 0.9558\n",
      "Epoch 7/10, Train Loss: 0.0786, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9266\n",
      "Epoch 8/10, Train Loss: 0.0944, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9307\n",
      "Epoch 9/10, Train Loss: 0.0842, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9307\n",
      "Epoch 10/10, Train Loss: 0.036, Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9466\n",
      "\n",
      "Sentiment analysis accuracy: 0.9602, F1 Micro: 0.9602, F1 Macro: 0.9558\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94        83\n",
      "    positive       0.99      0.95      0.97       168\n",
      "\n",
      "    accuracy                           0.96       251\n",
      "   macro avg       0.95      0.96      0.96       251\n",
      "weighted avg       0.96      0.96      0.96       251\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9051\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.97      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.95      0.97      0.96       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.86      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.75      0.69        12\n",
      "     neutral       0.91      0.97      0.94       152\n",
      "    positive       0.93      0.73      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.83      0.82      0.82       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.98      0.97      0.97       152\n",
      "    positive       0.90      0.88      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.93      0.89      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 98.08539628982544 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 33\n",
      "Sampling duration: 9.035237550735474 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5407, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4682, Accuracy: 0.8341, F1 Micro: 0.9044, F1 Macro: 0.9037\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3513, Accuracy: 0.9368, F1 Micro: 0.9611, F1 Macro: 0.96\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2429, Accuracy: 0.9501, F1 Micro: 0.969, F1 Macro: 0.9671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.168, Accuracy: 0.9606, F1 Micro: 0.9754, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1308, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.977\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0994, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.08, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.978\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0665, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9789\n",
      "Epoch 10/10, Train Loss: 0.0561, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9774\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.99      0.99      0.99       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4524, Accuracy: 0.8876, F1 Micro: 0.8876, F1 Macro: 0.8653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2388, Accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.9159\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1721, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.9236\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1475, Accuracy: 0.9535, F1 Micro: 0.9535, F1 Macro: 0.9477\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.129, Accuracy: 0.9535, F1 Micro: 0.9535, F1 Macro: 0.948\n",
      "Epoch 6/10, Train Loss: 0.1062, Accuracy: 0.9457, F1 Micro: 0.9457, F1 Macro: 0.939\n",
      "Epoch 7/10, Train Loss: 0.0754, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9358\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0652, Accuracy: 0.9535, F1 Micro: 0.9535, F1 Macro: 0.9467\n",
      "Epoch 9/10, Train Loss: 0.0492, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9302\n",
      "Epoch 10/10, Train Loss: 0.0625, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9277\n",
      "\n",
      "Sentiment analysis accuracy: 0.9535, F1 Micro: 0.9535, F1 Macro: 0.9467\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.92      0.93        84\n",
      "    positive       0.96      0.97      0.97       174\n",
      "\n",
      "    accuracy                           0.95       258\n",
      "   macro avg       0.95      0.94      0.95       258\n",
      "weighted avg       0.95      0.95      0.95       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9064\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.86      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.75      0.72        12\n",
      "     neutral       0.93      0.95      0.94       152\n",
      "    positive       0.87      0.79      0.83        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.83      0.83      0.83       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      1.00      0.85        23\n",
      "     neutral       0.99      0.98      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.90      0.93      0.91       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.90      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 105.26592683792114 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 30\n",
      "Sampling duration: 8.170117855072021 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5338, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4504, Accuracy: 0.8251, F1 Micro: 0.9002, F1 Macro: 0.8991\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.332, Accuracy: 0.936, F1 Micro: 0.9605, F1 Macro: 0.9591\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2255, Accuracy: 0.9524, F1 Micro: 0.9703, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1604, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1205, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0975, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9764\n",
      "Epoch 8/10, Train Loss: 0.0772, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0673, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9769\n",
      "Epoch 10/10, Train Loss: 0.0561, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.975\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.91      0.96      0.93       158\n",
      "        part       0.99      0.98      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5661, Accuracy: 0.7047, F1 Micro: 0.7047, F1 Macro: 0.498\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3013, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9343\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1765, Accuracy: 0.9488, F1 Micro: 0.9488, F1 Macro: 0.942\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1431, Accuracy: 0.9488, F1 Micro: 0.9488, F1 Macro: 0.943\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1157, Accuracy: 0.9488, F1 Micro: 0.9488, F1 Macro: 0.9413\n",
      "Epoch 6/10, Train Loss: 0.0856, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9366\n",
      "Epoch 7/10, Train Loss: 0.109, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9377\n",
      "Epoch 8/10, Train Loss: 0.08, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.9063\n",
      "Epoch 9/10, Train Loss: 0.0622, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9391\n",
      "Epoch 10/10, Train Loss: 0.0546, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9255\n",
      "\n",
      "Sentiment analysis accuracy: 0.9488, F1 Micro: 0.9488, F1 Macro: 0.9413\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.90      0.92        83\n",
      "    positive       0.95      0.97      0.96       171\n",
      "\n",
      "    accuracy                           0.95       254\n",
      "   macro avg       0.95      0.94      0.94       254\n",
      "weighted avg       0.95      0.95      0.95       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9483, F1 Micro: 0.9483, F1 Macro: 0.8837\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.84      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.45      0.75      0.56        12\n",
      "     neutral       0.93      0.91      0.92       152\n",
      "    positive       0.85      0.77      0.81        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.74      0.81      0.76       216\n",
      "weighted avg       0.89      0.87      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.96      0.86        23\n",
      "     neutral       0.99      0.97      0.98       152\n",
      "    positive       0.95      0.88      0.91        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.94      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.86      0.71      0.77        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.85      0.87       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.93      0.90        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.94      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 106.32574105262756 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 27\n",
      "Sampling duration: 7.4013121128082275 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5334, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4571, Accuracy: 0.8467, F1 Micro: 0.9109, F1 Macro: 0.9102\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3273, Accuracy: 0.9397, F1 Micro: 0.9628, F1 Macro: 0.9619\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2115, Accuracy: 0.9568, F1 Micro: 0.9732, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1512, Accuracy: 0.9583, F1 Micro: 0.9741, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1236, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9746\n",
      "Epoch 7/10, Train Loss: 0.0918, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0771, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9754\n",
      "Epoch 9/10, Train Loss: 0.0584, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9729\n",
      "Epoch 10/10, Train Loss: 0.0526, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9729\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9754\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.92      0.95      0.93       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5036, Accuracy: 0.8833, F1 Micro: 0.8833, F1 Macro: 0.8657\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2115, Accuracy: 0.9533, F1 Micro: 0.9533, F1 Macro: 0.9466\n",
      "Epoch 3/10, Train Loss: 0.1334, Accuracy: 0.9494, F1 Micro: 0.9494, F1 Macro: 0.943\n",
      "Epoch 4/10, Train Loss: 0.1296, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9271\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1403, Accuracy: 0.965, F1 Micro: 0.965, F1 Macro: 0.9606\n",
      "Epoch 6/10, Train Loss: 0.0893, Accuracy: 0.9416, F1 Micro: 0.9416, F1 Macro: 0.9354\n",
      "Epoch 7/10, Train Loss: 0.0727, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9312\n",
      "Epoch 8/10, Train Loss: 0.0739, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9231\n",
      "Epoch 9/10, Train Loss: 0.0612, Accuracy: 0.9533, F1 Micro: 0.9533, F1 Macro: 0.9469\n",
      "Epoch 10/10, Train Loss: 0.0557, Accuracy: 0.9572, F1 Micro: 0.9572, F1 Macro: 0.9515\n",
      "\n",
      "Sentiment analysis accuracy: 0.965, F1 Micro: 0.965, F1 Macro: 0.9606\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95        83\n",
      "    positive       0.99      0.96      0.97       174\n",
      "\n",
      "    accuracy                           0.96       257\n",
      "   macro avg       0.95      0.97      0.96       257\n",
      "weighted avg       0.97      0.96      0.97       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.9047\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.87      0.89       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.53      0.75      0.62        12\n",
      "     neutral       0.93      0.91      0.92       152\n",
      "    positive       0.84      0.81      0.82        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.77      0.82      0.79       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.91      0.84        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       0.92      0.83      0.87        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.91      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 104.41089868545532 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Acquired samples: 18\n",
      "Sampling duration: 6.610875129699707 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5389, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4488, Accuracy: 0.8601, F1 Micro: 0.9176, F1 Macro: 0.917\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.312, Accuracy: 0.9464, F1 Micro: 0.9669, F1 Macro: 0.966\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2055, Accuracy: 0.9591, F1 Micro: 0.9746, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1449, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1104, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9773\n",
      "Epoch 7/10, Train Loss: 0.0901, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9765\n",
      "Epoch 8/10, Train Loss: 0.0728, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9759\n",
      "Epoch 9/10, Train Loss: 0.0601, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9766\n",
      "Epoch 10/10, Train Loss: 0.0487, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9768\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.91      0.99      0.95       158\n",
      "        part       0.99      0.97      0.98       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5297, Accuracy: 0.884, F1 Micro: 0.884, F1 Macro: 0.8711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2345, Accuracy: 0.948, F1 Micro: 0.948, F1 Macro: 0.9416\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1605, Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9508\n",
      "Epoch 4/10, Train Loss: 0.1649, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.9004\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1218, Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9508\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0746, Accuracy: 0.964, F1 Micro: 0.964, F1 Macro: 0.9595\n",
      "Epoch 7/10, Train Loss: 0.0611, Accuracy: 0.96, F1 Micro: 0.96, F1 Macro: 0.9546\n",
      "Epoch 8/10, Train Loss: 0.0771, Accuracy: 0.96, F1 Micro: 0.96, F1 Macro: 0.9534\n",
      "Epoch 9/10, Train Loss: 0.0537, Accuracy: 0.96, F1 Micro: 0.96, F1 Macro: 0.9537\n",
      "Epoch 10/10, Train Loss: 0.0583, Accuracy: 0.96, F1 Micro: 0.96, F1 Macro: 0.9549\n",
      "\n",
      "Sentiment analysis accuracy: 0.964, F1 Micro: 0.964, F1 Macro: 0.9595\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95        81\n",
      "    positive       0.99      0.96      0.97       169\n",
      "\n",
      "    accuracy                           0.96       250\n",
      "   macro avg       0.95      0.97      0.96       250\n",
      "weighted avg       0.97      0.96      0.96       250\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9134\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.85      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.75      0.60        12\n",
      "     neutral       0.94      0.96      0.95       152\n",
      "    positive       0.95      0.77      0.85        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.80      0.83      0.80       216\n",
      "weighted avg       0.92      0.90      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.96      0.85        23\n",
      "     neutral       0.99      0.96      0.97       152\n",
      "    positive       0.92      0.88      0.90        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.93      0.91       216\n",
      "weighted avg       0.95      0.94      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 106.02036833763123 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 6.292301654815674 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5391, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4255, Accuracy: 0.8839, F1 Micro: 0.931, F1 Macro: 0.9305\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2846, Accuracy: 0.9501, F1 Micro: 0.9691, F1 Macro: 0.9682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1883, Accuracy: 0.9561, F1 Micro: 0.9727, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1374, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1079, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.079, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9795\n",
      "Epoch 8/10, Train Loss: 0.0652, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9783\n",
      "Epoch 9/10, Train Loss: 0.0584, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9784\n",
      "Epoch 10/10, Train Loss: 0.0483, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9779\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9795\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.95      0.96      0.95       158\n",
      "        part       0.99      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5312, Accuracy: 0.874, F1 Micro: 0.874, F1 Macro: 0.8614\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.236, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.9312\n",
      "Epoch 3/10, Train Loss: 0.1727, Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.9242\n",
      "Epoch 4/10, Train Loss: 0.1494, Accuracy: 0.9275, F1 Micro: 0.9275, F1 Macro: 0.9206\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1251, Accuracy: 0.9427, F1 Micro: 0.9427, F1 Macro: 0.936\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1302, Accuracy: 0.9466, F1 Micro: 0.9466, F1 Macro: 0.9404\n",
      "Epoch 7/10, Train Loss: 0.0877, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9286\n",
      "Epoch 8/10, Train Loss: 0.0855, Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.9246\n",
      "Epoch 9/10, Train Loss: 0.068, Accuracy: 0.9237, F1 Micro: 0.9237, F1 Macro: 0.9167\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0521, Accuracy: 0.9466, F1 Micro: 0.9466, F1 Macro: 0.9401\n",
      "\n",
      "Sentiment analysis accuracy: 0.9466, F1 Micro: 0.9466, F1 Macro: 0.9401\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.95      0.92        85\n",
      "    positive       0.98      0.94      0.96       177\n",
      "\n",
      "    accuracy                           0.95       262\n",
      "   macro avg       0.93      0.95      0.94       262\n",
      "weighted avg       0.95      0.95      0.95       262\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9133\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      0.81      0.76        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.88      0.70      0.78        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.85      0.83      0.84       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.92      0.85        12\n",
      "     neutral       0.95      0.95      0.95       152\n",
      "    positive       0.88      0.87      0.87        52\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.91      0.89       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.99      0.98      0.98       152\n",
      "    positive       0.95      0.88      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.95      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.85      0.79        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.86      0.87      0.86       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 111.95550751686096 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.707272291183472 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5345, Accuracy: 0.7961, F1 Micro: 0.8833, F1 Macro: 0.8804\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4476, Accuracy: 0.8646, F1 Micro: 0.9204, F1 Macro: 0.92\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3008, Accuracy: 0.9464, F1 Micro: 0.9668, F1 Macro: 0.9655\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1996, Accuracy: 0.9494, F1 Micro: 0.9682, F1 Macro: 0.966\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1497, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1126, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0875, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9789\n",
      "Epoch 8/10, Train Loss: 0.0714, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9782\n",
      "Epoch 9/10, Train Loss: 0.0572, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9771\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0504, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9792\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9792\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.95      0.94      0.95       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5114, Accuracy: 0.8906, F1 Micro: 0.8906, F1 Macro: 0.8732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2638, Accuracy: 0.9509, F1 Micro: 0.9509, F1 Macro: 0.9457\n",
      "Epoch 3/10, Train Loss: 0.1658, Accuracy: 0.9321, F1 Micro: 0.9321, F1 Macro: 0.9211\n",
      "Epoch 4/10, Train Loss: 0.1343, Accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.9371\n",
      "Epoch 5/10, Train Loss: 0.1247, Accuracy: 0.9358, F1 Micro: 0.9358, F1 Macro: 0.9266\n",
      "Epoch 6/10, Train Loss: 0.1075, Accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.9408\n",
      "Epoch 7/10, Train Loss: 0.0653, Accuracy: 0.9245, F1 Micro: 0.9245, F1 Macro: 0.9176\n",
      "Epoch 8/10, Train Loss: 0.087, Accuracy: 0.917, F1 Micro: 0.917, F1 Macro: 0.9102\n",
      "Epoch 9/10, Train Loss: 0.0629, Accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.9374\n",
      "Epoch 10/10, Train Loss: 0.0393, Accuracy: 0.9358, F1 Micro: 0.9358, F1 Macro: 0.9298\n",
      "\n",
      "Sentiment analysis accuracy: 0.9509, F1 Micro: 0.9509, F1 Macro: 0.9457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.97      0.93        88\n",
      "    positive       0.98      0.94      0.96       177\n",
      "\n",
      "    accuracy                           0.95       265\n",
      "   macro avg       0.94      0.95      0.95       265\n",
      "weighted avg       0.95      0.95      0.95       265\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.917\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.85      0.70      0.77        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.85      0.86       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.92      0.88        12\n",
      "     neutral       0.95      0.94      0.95       152\n",
      "    positive       0.81      0.83      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.87      0.89      0.88       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.92      0.65      0.76        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.86      0.87       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 109.90518617630005 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.106217622756958 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5251, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4296, Accuracy: 0.8884, F1 Micro: 0.9336, F1 Macro: 0.9329\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2838, Accuracy: 0.9516, F1 Micro: 0.9699, F1 Macro: 0.9686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.186, Accuracy: 0.9531, F1 Micro: 0.9706, F1 Macro: 0.9689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1331, Accuracy: 0.9576, F1 Micro: 0.9732, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1005, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9744\n",
      "Epoch 7/10, Train Loss: 0.083, Accuracy: 0.9613, F1 Micro: 0.9755, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0624, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9779\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0566, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9781\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0478, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9783\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9783\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.504, Accuracy: 0.8927, F1 Micro: 0.8927, F1 Macro: 0.8747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2277, Accuracy: 0.9387, F1 Micro: 0.9387, F1 Macro: 0.9322\n",
      "Epoch 3/10, Train Loss: 0.1669, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9165\n",
      "Epoch 4/10, Train Loss: 0.1289, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9273\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1111, Accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.9393\n",
      "Epoch 6/10, Train Loss: 0.0799, Accuracy: 0.9387, F1 Micro: 0.9387, F1 Macro: 0.9318\n",
      "Epoch 7/10, Train Loss: 0.0652, Accuracy: 0.9425, F1 Micro: 0.9425, F1 Macro: 0.9362\n",
      "Epoch 8/10, Train Loss: 0.0637, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9133\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.073, Accuracy: 0.9579, F1 Micro: 0.9579, F1 Macro: 0.9527\n",
      "Epoch 10/10, Train Loss: 0.0545, Accuracy: 0.9042, F1 Micro: 0.9042, F1 Macro: 0.8968\n",
      "\n",
      "Sentiment analysis accuracy: 0.9579, F1 Micro: 0.9579, F1 Macro: 0.9527\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        85\n",
      "    positive       0.98      0.95      0.97       176\n",
      "\n",
      "    accuracy                           0.96       261\n",
      "   macro avg       0.95      0.96      0.95       261\n",
      "weighted avg       0.96      0.96      0.96       261\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.8918\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.83      0.89        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.88      0.82        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.86      0.86      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.83      0.74        12\n",
      "     neutral       0.92      0.96      0.94       152\n",
      "    positive       0.86      0.71      0.78        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.82      0.84      0.82       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.94      0.78      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.92      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.85      0.81        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 117.92754673957825 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.432648658752441 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.524, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4257, Accuracy: 0.9018, F1 Micro: 0.9411, F1 Macro: 0.9399\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2728, Accuracy: 0.9501, F1 Micro: 0.969, F1 Macro: 0.9678\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1762, Accuracy: 0.9583, F1 Micro: 0.9741, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1207, Accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9786\n",
      "Epoch 6/10, Train Loss: 0.1025, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0767, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9795\n",
      "Epoch 8/10, Train Loss: 0.0627, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9753\n",
      "Epoch 9/10, Train Loss: 0.0558, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9777\n",
      "Epoch 10/10, Train Loss: 0.0468, Accuracy: 0.9606, F1 Micro: 0.975, F1 Macro: 0.973\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9795\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.97      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5464, Accuracy: 0.8854, F1 Micro: 0.8854, F1 Macro: 0.8651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.255, Accuracy: 0.9249, F1 Micro: 0.9249, F1 Macro: 0.9166\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1871, Accuracy: 0.9249, F1 Micro: 0.9249, F1 Macro: 0.9183\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1704, Accuracy: 0.9249, F1 Micro: 0.9249, F1 Macro: 0.9183\n",
      "Epoch 5/10, Train Loss: 0.1459, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.9029\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1075, Accuracy: 0.9289, F1 Micro: 0.9289, F1 Macro: 0.9231\n",
      "Epoch 7/10, Train Loss: 0.0935, Accuracy: 0.917, F1 Micro: 0.917, F1 Macro: 0.9109\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0852, Accuracy: 0.9289, F1 Micro: 0.9289, F1 Macro: 0.9231\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0443, Accuracy: 0.9486, F1 Micro: 0.9486, F1 Macro: 0.9426\n",
      "Epoch 10/10, Train Loss: 0.0556, Accuracy: 0.9368, F1 Micro: 0.9368, F1 Macro: 0.931\n",
      "\n",
      "Sentiment analysis accuracy: 0.9486, F1 Micro: 0.9486, F1 Macro: 0.9426\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.93      0.92        85\n",
      "    positive       0.96      0.96      0.96       168\n",
      "\n",
      "    accuracy                           0.95       253\n",
      "   macro avg       0.94      0.94      0.94       253\n",
      "weighted avg       0.95      0.95      0.95       253\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9475, F1 Micro: 0.9475, F1 Macro: 0.8928\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.88      0.82        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.86      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.35      0.92      0.51        12\n",
      "     neutral       0.95      0.88      0.91       152\n",
      "    positive       0.91      0.77      0.83        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.74      0.86      0.75       216\n",
      "weighted avg       0.91      0.86      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.91       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 121.19302773475647 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Acquired samples: 8\n",
      "Sampling duration: 4.133533000946045 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5282, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4281, Accuracy: 0.8966, F1 Micro: 0.9379, F1 Macro: 0.9368\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2734, Accuracy: 0.9479, F1 Micro: 0.9674, F1 Macro: 0.9651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.188, Accuracy: 0.9568, F1 Micro: 0.9731, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1319, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1018, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9774\n",
      "Epoch 7/10, Train Loss: 0.0791, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9766\n",
      "Epoch 8/10, Train Loss: 0.0678, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9768\n",
      "Epoch 9/10, Train Loss: 0.0562, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0462, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9791\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9791\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.94      0.94      0.94       158\n",
      "        part       0.99      0.99      0.99       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4611, Accuracy: 0.9182, F1 Micro: 0.9182, F1 Macro: 0.9096\n",
      "Epoch 2/10, Train Loss: 0.185, Accuracy: 0.9071, F1 Micro: 0.9071, F1 Macro: 0.899\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1771, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.926\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1161, Accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9357\n",
      "Epoch 5/10, Train Loss: 0.14, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9336\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1, Accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9369\n",
      "Epoch 7/10, Train Loss: 0.084, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9213\n",
      "Epoch 8/10, Train Loss: 0.0744, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9249\n",
      "Epoch 9/10, Train Loss: 0.0575, Accuracy: 0.9145, F1 Micro: 0.9145, F1 Macro: 0.9066\n",
      "Epoch 10/10, Train Loss: 0.0541, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9324\n",
      "\n",
      "Sentiment analysis accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9369\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.93      0.92        87\n",
      "    positive       0.97      0.95      0.96       182\n",
      "\n",
      "    accuracy                           0.94       269\n",
      "   macro avg       0.93      0.94      0.94       269\n",
      "weighted avg       0.94      0.94      0.94       269\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.9202\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.81      0.79      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.86      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.94      0.93      0.94       152\n",
      "    positive       0.80      0.83      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.88      0.86      0.87       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.99      0.99      0.99       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.93      0.92       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 118.69384169578552 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.904982089996338 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.532, Accuracy: 0.7954, F1 Micro: 0.8853, F1 Macro: 0.8838\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4254, Accuracy: 0.8876, F1 Micro: 0.9325, F1 Macro: 0.9311\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2601, Accuracy: 0.9479, F1 Micro: 0.9675, F1 Macro: 0.9659\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1726, Accuracy: 0.9546, F1 Micro: 0.9717, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1293, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0778, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "Epoch 8/10, Train Loss: 0.0625, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0537, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9781\n",
      "Epoch 10/10, Train Loss: 0.049, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9759\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.94      0.94      0.94       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4836, Accuracy: 0.9064, F1 Micro: 0.9064, F1 Macro: 0.8971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2106, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9148\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1687, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.929\n",
      "Epoch 4/10, Train Loss: 0.1223, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9148\n",
      "Epoch 5/10, Train Loss: 0.1159, Accuracy: 0.9251, F1 Micro: 0.9251, F1 Macro: 0.9179\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1227, Accuracy: 0.9476, F1 Micro: 0.9476, F1 Macro: 0.9413\n",
      "Epoch 7/10, Train Loss: 0.0778, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9297\n",
      "Epoch 8/10, Train Loss: 0.0853, Accuracy: 0.9401, F1 Micro: 0.9401, F1 Macro: 0.9337\n",
      "Epoch 9/10, Train Loss: 0.0732, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9373\n",
      "Epoch 10/10, Train Loss: 0.0589, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.93\n",
      "\n",
      "Sentiment analysis accuracy: 0.9476, F1 Micro: 0.9476, F1 Macro: 0.9413\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        88\n",
      "    positive       0.97      0.95      0.96       179\n",
      "\n",
      "    accuracy                           0.95       267\n",
      "   macro avg       0.94      0.95      0.94       267\n",
      "weighted avg       0.95      0.95      0.95       267\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9053\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.86      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.58      0.92      0.71        12\n",
      "     neutral       0.95      0.91      0.93       152\n",
      "    positive       0.81      0.81      0.81        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.78      0.88      0.82       216\n",
      "weighted avg       0.90      0.88      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.94      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.92      0.83        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 121.04154419898987 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.0824310779571533 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5253, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4072, Accuracy: 0.9249, F1 Micro: 0.9543, F1 Macro: 0.9532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2517, Accuracy: 0.9531, F1 Micro: 0.9709, F1 Macro: 0.9699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1661, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.111, Accuracy: 0.9643, F1 Micro: 0.9777, F1 Macro: 0.9767\n",
      "Epoch 6/10, Train Loss: 0.0899, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9761\n",
      "Epoch 7/10, Train Loss: 0.0711, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0586, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0513, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9781\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0446, Accuracy: 0.971, F1 Micro: 0.9817, F1 Macro: 0.9807\n",
      "\n",
      "Aspect detection accuracy: 0.971, F1 Micro: 0.9817, F1 Macro: 0.9807\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.94      0.96      0.95       158\n",
      "        part       0.99      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.98      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4837, Accuracy: 0.9205, F1 Micro: 0.9205, F1 Macro: 0.9113\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2152, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9224\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1914, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9293\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1296, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9318\n",
      "Epoch 5/10, Train Loss: 0.1138, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9201\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1204, Accuracy: 0.9432, F1 Micro: 0.9432, F1 Macro: 0.9363\n",
      "Epoch 7/10, Train Loss: 0.0765, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9273\n",
      "Epoch 8/10, Train Loss: 0.0631, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9326\n",
      "Epoch 9/10, Train Loss: 0.0718, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9318\n",
      "Epoch 10/10, Train Loss: 0.071, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9237\n",
      "\n",
      "Sentiment analysis accuracy: 0.9432, F1 Micro: 0.9432, F1 Macro: 0.9363\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.94      0.92        86\n",
      "    positive       0.97      0.94      0.96       178\n",
      "\n",
      "    accuracy                           0.94       264\n",
      "   macro avg       0.93      0.94      0.94       264\n",
      "weighted avg       0.94      0.94      0.94       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.917\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.82      0.85       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.95      0.95      0.95       152\n",
      "    positive       0.84      0.81      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.85      0.86      0.86       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.99      0.98      0.98       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 126.76283979415894 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.4123780727386475 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5186, Accuracy: 0.7939, F1 Micro: 0.8845, F1 Macro: 0.8831\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4159, Accuracy: 0.9174, F1 Micro: 0.9498, F1 Macro: 0.9485\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2571, Accuracy: 0.9516, F1 Micro: 0.9698, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1581, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1202, Accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9775\n",
      "Epoch 6/10, Train Loss: 0.0937, Accuracy: 0.9591, F1 Micro: 0.974, F1 Macro: 0.9719\n",
      "Epoch 7/10, Train Loss: 0.0716, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.063, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9795\n",
      "Epoch 9/10, Train Loss: 0.0546, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9773\n",
      "Epoch 10/10, Train Loss: 0.0444, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9758\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9795\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.94      0.97      0.96       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4666, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.8936\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2309, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9322\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.157, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9401\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1418, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9407\n",
      "Epoch 5/10, Train Loss: 0.1038, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9308\n",
      "Epoch 6/10, Train Loss: 0.0844, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9285\n",
      "Epoch 7/10, Train Loss: 0.0716, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9363\n",
      "Epoch 8/10, Train Loss: 0.0703, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9201\n",
      "Epoch 9/10, Train Loss: 0.0908, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9238\n",
      "Epoch 10/10, Train Loss: 0.0508, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9185\n",
      "\n",
      "Sentiment analysis accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9407\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.97      0.92        87\n",
      "    positive       0.98      0.94      0.96       172\n",
      "\n",
      "    accuracy                           0.95       259\n",
      "   macro avg       0.93      0.95      0.94       259\n",
      "weighted avg       0.95      0.95      0.95       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.8988\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.83      0.73      0.77        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.86      0.84      0.85       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.58      0.92      0.71        12\n",
      "     neutral       0.95      0.95      0.95       152\n",
      "    positive       0.89      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.81      0.88      0.83       216\n",
      "weighted avg       0.91      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.96      0.86        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.92      0.83      0.87        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.92      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 123.06894540786743 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.7756707668304443 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5214, Accuracy: 0.7954, F1 Micro: 0.8853, F1 Macro: 0.8838\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4026, Accuracy: 0.9271, F1 Micro: 0.9554, F1 Macro: 0.9539\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2516, Accuracy: 0.9539, F1 Micro: 0.9714, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1667, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1187, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0898, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9771\n",
      "Epoch 7/10, Train Loss: 0.0768, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9769\n",
      "Epoch 8/10, Train Loss: 0.0612, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.976\n",
      "Epoch 9/10, Train Loss: 0.0528, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0468, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9778\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4661, Accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.908\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2196, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9283\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1673, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9313\n",
      "Epoch 4/10, Train Loss: 0.1222, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9235\n",
      "Epoch 5/10, Train Loss: 0.1096, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9199\n",
      "Epoch 6/10, Train Loss: 0.0785, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.9079\n",
      "Epoch 7/10, Train Loss: 0.0741, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.906\n",
      "Epoch 8/10, Train Loss: 0.0871, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9115\n",
      "Epoch 9/10, Train Loss: 0.0668, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9264\n",
      "Epoch 10/10, Train Loss: 0.0443, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9223\n",
      "\n",
      "Sentiment analysis accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9313\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.94      0.91        85\n",
      "    positive       0.97      0.94      0.95       175\n",
      "\n",
      "    accuracy                           0.94       260\n",
      "   macro avg       0.92      0.94      0.93       260\n",
      "weighted avg       0.94      0.94      0.94       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9102\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.69      0.76        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.83      0.73      0.77        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.87      0.80      0.83       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.84      0.79      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.89      0.83      0.86       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.92      0.83      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.90      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 126.02750253677368 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Acquired samples: 8\n",
      "Sampling duration: 0.9909360408782959 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5222, Accuracy: 0.7969, F1 Micro: 0.886, F1 Macro: 0.8845\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4017, Accuracy: 0.933, F1 Micro: 0.959, F1 Macro: 0.958\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2484, Accuracy: 0.9501, F1 Micro: 0.9689, F1 Macro: 0.9674\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1696, Accuracy: 0.9643, F1 Micro: 0.9778, F1 Macro: 0.977\n",
      "Epoch 5/10, Train Loss: 0.1227, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0871, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.978\n",
      "Epoch 7/10, Train Loss: 0.0692, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9775\n",
      "Epoch 8/10, Train Loss: 0.0594, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0498, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.978\n",
      "Epoch 10/10, Train Loss: 0.0447, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9764\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.94      0.94      0.94       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4798, Accuracy: 0.9101, F1 Micro: 0.9101, F1 Macro: 0.9015\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2217, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9282\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.158, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.937\n",
      "Epoch 4/10, Train Loss: 0.1017, Accuracy: 0.9251, F1 Micro: 0.9251, F1 Macro: 0.9171\n",
      "Epoch 5/10, Train Loss: 0.122, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9046\n",
      "Epoch 6/10, Train Loss: 0.1008, Accuracy: 0.9101, F1 Micro: 0.9101, F1 Macro: 0.9015\n",
      "Epoch 7/10, Train Loss: 0.0664, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9286\n",
      "Epoch 8/10, Train Loss: 0.0763, Accuracy: 0.9101, F1 Micro: 0.9101, F1 Macro: 0.902\n",
      "Epoch 9/10, Train Loss: 0.0734, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9286\n",
      "Epoch 10/10, Train Loss: 0.0622, Accuracy: 0.9401, F1 Micro: 0.9401, F1 Macro: 0.933\n",
      "\n",
      "Sentiment analysis accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.937\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.96      0.92        85\n",
      "    positive       0.98      0.93      0.96       182\n",
      "\n",
      "    accuracy                           0.94       267\n",
      "   macro avg       0.93      0.95      0.94       267\n",
      "weighted avg       0.95      0.94      0.94       267\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9071\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.81      0.79        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.87      0.85      0.86       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.56      0.83      0.67        12\n",
      "     neutral       0.94      0.90      0.92       152\n",
      "    positive       0.81      0.83      0.82        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.77      0.85      0.80       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.92      0.83      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      1.00      0.90        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.94      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 123.51732182502747 s\n",
      "Total runtime: 3091.387883424759 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[4], 4)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6175447,
     "sourceId": 10843157,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2957.194393,
   "end_time": "2025-03-02T17:42:54.919569",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-02T16:53:37.725176",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "130c701262c249feafc63404ec79c96e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "13da7532e7ca42d5bf7ec8fa8cfbac0f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "15f1de6fd7714b75ab3cff72e84c6aa2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "28084c35f24b4781bee36cf4270912cb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_bdef3192487f43a38fe6be7487cf9eb8",
       "max": 2,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ed123a492fd741858c4b6af7ddd24c2b",
       "tabbable": null,
       "tooltip": null,
       "value": 2
      }
     },
     "30ed697fed004b92bbeeba263cedb67e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3c4d64dbda2c414a988701848605701b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_51155f901cc34435bbc0e56ee7bedb5b",
       "max": 1534,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_130c701262c249feafc63404ec79c96e",
       "tabbable": null,
       "tooltip": null,
       "value": 1534
      }
     },
     "4497660b777843b6a4604cb2776f7235": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f0a6ffa1dfa14214a2d31c508b79ccec",
        "IPY_MODEL_d41e5bfbf4334fae936875ea3b840d19",
        "IPY_MODEL_7253d943f1a247f48f830f457630a9b7"
       ],
       "layout": "IPY_MODEL_67cd385f316e4c638726611e2aa09227",
       "tabbable": null,
       "tooltip": null
      }
     },
     "4d09d59b8234451cbf3cfde2f3611fa9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "51155f901cc34435bbc0e56ee7bedb5b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "54874f85824c4e4da4527c9ee162cbfa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "59d32dc36a7a401a8f1cbd8862178694": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a827bc2eef824cfe9f67c7b2290db928",
        "IPY_MODEL_3c4d64dbda2c414a988701848605701b",
        "IPY_MODEL_bd8cc611086b45a583d6f7d17503f59d"
       ],
       "layout": "IPY_MODEL_e6395b9bce0b45848b2f6d581a4d5122",
       "tabbable": null,
       "tooltip": null
      }
     },
     "6178248894d24e3db1a61bf426f48736": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "640b7331c3e342f196114513dc3f7ec8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_8fa1f66c15624e6d977729fe384a7656",
        "IPY_MODEL_28084c35f24b4781bee36cf4270912cb",
        "IPY_MODEL_fb8111bf461d40e0b775827110d1d8b1"
       ],
       "layout": "IPY_MODEL_7d182284414741ecb47b7bcdb9eedcc6",
       "tabbable": null,
       "tooltip": null
      }
     },
     "67cd385f316e4c638726611e2aa09227": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "69594785e4084477816e4bd616ea2def": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d04cd004c02545468da68ce0d14962e8",
        "IPY_MODEL_e2953729feba4d349af95f7f1eeb4fb9",
        "IPY_MODEL_b663e24b59fd4b9e9d5f576f37be0f0e"
       ],
       "layout": "IPY_MODEL_d8718adef87149eeb1a68dbe64d36612",
       "tabbable": null,
       "tooltip": null
      }
     },
     "7253d943f1a247f48f830f457630a9b7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e797974a620f41759eb9da963b1d8ad4",
       "placeholder": "​",
       "style": "IPY_MODEL_793816f67c43430a8c8272d6344056ef",
       "tabbable": null,
       "tooltip": null,
       "value": " 112/112 [00:00&lt;00:00, 12.0kB/s]"
      }
     },
     "793816f67c43430a8c8272d6344056ef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7d182284414741ecb47b7bcdb9eedcc6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8bf0f407bb734fbe8b4a9071ee601ec2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8fa1f66c15624e6d977729fe384a7656": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_afc9b53af50a4c378881318c7b8ed671",
       "placeholder": "​",
       "style": "IPY_MODEL_6178248894d24e3db1a61bf426f48736",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json: 100%"
      }
     },
     "95af59c2066c4fe6b0505cd3ee40cec3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9d4ad49421fc4a0d86f3fefde6ffb853": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a13ccc0743264abb89af018536fb083e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a827bc2eef824cfe9f67c7b2290db928": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_13da7532e7ca42d5bf7ec8fa8cfbac0f",
       "placeholder": "​",
       "style": "IPY_MODEL_e08552576688496ab21894fca0ed801a",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: 100%"
      }
     },
     "ab9cd1fa7bdf415d88efe3534b7cdfdf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "aeae7c4b3fc0413ca41abd48ed98e98f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "afc9b53af50a4c378881318c7b8ed671": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b663e24b59fd4b9e9d5f576f37be0f0e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f9a48b6a4b8445ad888d3e81a3980eb5",
       "placeholder": "​",
       "style": "IPY_MODEL_ab9cd1fa7bdf415d88efe3534b7cdfdf",
       "tabbable": null,
       "tooltip": null,
       "value": " 229k/229k [00:00&lt;00:00, 5.13MB/s]"
      }
     },
     "bd8cc611086b45a583d6f7d17503f59d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d734714df0b84eaa9c2efe6a5d9a0db2",
       "placeholder": "​",
       "style": "IPY_MODEL_8bf0f407bb734fbe8b4a9071ee601ec2",
       "tabbable": null,
       "tooltip": null,
       "value": " 1.53k/1.53k [00:00&lt;00:00, 108kB/s]"
      }
     },
     "bdef3192487f43a38fe6be7487cf9eb8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c69508daf8f2418f8ec5afcf9d7f96d1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d04cd004c02545468da68ce0d14962e8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_15f1de6fd7714b75ab3cff72e84c6aa2",
       "placeholder": "​",
       "style": "IPY_MODEL_4d09d59b8234451cbf3cfde2f3611fa9",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.txt: 100%"
      }
     },
     "d41e5bfbf4334fae936875ea3b840d19": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ed83054c2b9c41b68259d9e3c67a4e37",
       "max": 112,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_aeae7c4b3fc0413ca41abd48ed98e98f",
       "tabbable": null,
       "tooltip": null,
       "value": 112
      }
     },
     "d734714df0b84eaa9c2efe6a5d9a0db2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d8718adef87149eeb1a68dbe64d36612": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e08552576688496ab21894fca0ed801a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e2953729feba4d349af95f7f1eeb4fb9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a13ccc0743264abb89af018536fb083e",
       "max": 229167,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_30ed697fed004b92bbeeba263cedb67e",
       "tabbable": null,
       "tooltip": null,
       "value": 229167
      }
     },
     "e6395b9bce0b45848b2f6d581a4d5122": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e797974a620f41759eb9da963b1d8ad4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ed123a492fd741858c4b6af7ddd24c2b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ed83054c2b9c41b68259d9e3c67a4e37": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f0a6ffa1dfa14214a2d31c508b79ccec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_95af59c2066c4fe6b0505cd3ee40cec3",
       "placeholder": "​",
       "style": "IPY_MODEL_9d4ad49421fc4a0d86f3fefde6ffb853",
       "tabbable": null,
       "tooltip": null,
       "value": "special_tokens_map.json: 100%"
      }
     },
     "f9a48b6a4b8445ad888d3e81a3980eb5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fb8111bf461d40e0b775827110d1d8b1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_c69508daf8f2418f8ec5afcf9d7f96d1",
       "placeholder": "​",
       "style": "IPY_MODEL_54874f85824c4e4da4527c9ee162cbfa",
       "tabbable": null,
       "tooltip": null,
       "value": " 2.00/2.00 [00:00&lt;00:00, 157B/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
