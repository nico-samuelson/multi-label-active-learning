{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bec2505",
   "metadata": {
    "papermill": {
     "duration": 0.012963,
     "end_time": "2025-03-23T08:37:05.511751",
     "exception": false,
     "start_time": "2025-03-23T08:37:05.498788",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a3acc41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T08:37:05.537517Z",
     "iopub.status.busy": "2025-03-23T08:37:05.537180Z",
     "iopub.status.idle": "2025-03-23T08:37:38.524271Z",
     "shell.execute_reply": "2025-03-23T08:37:38.523562Z"
    },
    "papermill": {
     "duration": 33.001948,
     "end_time": "2025-03-23T08:37:38.526021",
     "exception": false,
     "start_time": "2025-03-23T08:37:05.524073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score, classification_report\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "from torch.multiprocessing import Manager\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel, BertPreTrainedModel, BertConfig, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c651efbf",
   "metadata": {
    "papermill": {
     "duration": 0.011303,
     "end_time": "2025-03-23T08:37:38.548906",
     "exception": false,
     "start_time": "2025-03-23T08:37:38.537603",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c7276a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T08:37:38.572628Z",
     "iopub.status.busy": "2025-03-23T08:37:38.572043Z",
     "iopub.status.idle": "2025-03-23T08:37:38.575980Z",
     "shell.execute_reply": "2025-03-23T08:37:38.575062Z"
    },
    "papermill": {
     "duration": 0.01761,
     "end_time": "2025-03-23T08:37:38.577594",
     "exception": false,
     "start_time": "2025-03-23T08:37:38.559984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb133b1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T08:37:38.601633Z",
     "iopub.status.busy": "2025-03-23T08:37:38.601356Z",
     "iopub.status.idle": "2025-03-23T08:37:38.605141Z",
     "shell.execute_reply": "2025-03-23T08:37:38.604464Z"
    },
    "papermill": {
     "duration": 0.01725,
     "end_time": "2025-03-23T08:37:38.606498",
     "exception": false,
     "start_time": "2025-03-23T08:37:38.589248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists('/kaggle/working/results') == False:\n",
    "    os.mkdir('/kaggle/working/results')\n",
    "\n",
    "if os.path.exists('/kaggle/working/acquired_data') == False:\n",
    "    os.mkdir('/kaggle/working/acquired_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ebb1974",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T08:37:38.629845Z",
     "iopub.status.busy": "2025-03-23T08:37:38.629592Z",
     "iopub.status.idle": "2025-03-23T08:37:38.641916Z",
     "shell.execute_reply": "2025-03-23T08:37:38.641354Z"
    },
    "papermill": {
     "duration": 0.02511,
     "end_time": "2025-03-23T08:37:38.643086",
     "exception": false,
     "start_time": "2025-03-23T08:37:38.617976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "    torch.backends.cudnn.benchmark=False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aed7938",
   "metadata": {
    "papermill": {
     "duration": 0.010981,
     "end_time": "2025-03-23T08:37:38.665703",
     "exception": false,
     "start_time": "2025-03-23T08:37:38.654722",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# GLOBAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2512521f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T08:37:38.688786Z",
     "iopub.status.busy": "2025-03-23T08:37:38.688584Z",
     "iopub.status.idle": "2025-03-23T08:37:38.750445Z",
     "shell.execute_reply": "2025-03-23T08:37:38.749011Z"
    },
    "papermill": {
     "duration": 0.075068,
     "end_time": "2025-03-23T08:37:38.751930",
     "exception": false,
     "start_time": "2025-03-23T08:37:38.676862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "\n",
    "# Shared resources\n",
    "aspect_accuracies = manager.list()\n",
    "aspect_f1_micros = manager.list()\n",
    "aspect_f1_macros = manager.list()\n",
    "sentiment_accuracies = manager.list()\n",
    "sentiment_f1_micros = manager.list()\n",
    "sentiment_f1_macros = manager.list()\n",
    "accuracies = manager.list()\n",
    "f1_micros = manager.list()\n",
    "f1_macros = manager.list()\n",
    "\n",
    "# Non shared resources\n",
    "filename = 'casa-lc'\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "sequence_length = 48\n",
    "\n",
    "aspect_list = ['fuel', 'machine', 'others', 'part', 'price', 'service']\n",
    "aspect_mapping = {'fuel': 0, 'machine': 1, 'others': 2, 'part': 3, 'price': 4, 'service': 5 }\n",
    "label_mapping = {\"negative\": 0, \"neutral\": 1, 'positive': 2}\n",
    "ignored_keys = ['labels', 'ori_text', 'ori_label', 'ori_indices', 'aspect']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c460358",
   "metadata": {
    "papermill": {
     "duration": 0.011235,
     "end_time": "2025-03-23T08:37:38.774865",
     "exception": false,
     "start_time": "2025-03-23T08:37:38.763630",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LOAD AND PREPROCESS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0d27c2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T08:37:38.798390Z",
     "iopub.status.busy": "2025-03-23T08:37:38.798088Z",
     "iopub.status.idle": "2025-03-23T08:37:38.875729Z",
     "shell.execute_reply": "2025-03-23T08:37:38.875012Z"
    },
    "papermill": {
     "duration": 0.09101,
     "end_time": "2025-03-23T08:37:38.876985",
     "exception": false,
     "start_time": "2025-03-23T08:37:38.785975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>fuel</th>\n",
       "      <th>machine</th>\n",
       "      <th>others</th>\n",
       "      <th>part</th>\n",
       "      <th>price</th>\n",
       "      <th>service</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saya memakai Honda Jazz GK5 tahun 2014 ( perta...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Avanza kenapa jadi boros bensin begini dah ah....</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saran ku dan pengalaman ku , mending beli mobi...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dari segi harga juga pajero lebih mahal 30 jut...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kalo menurut gw enak pajero si</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence      fuel   machine  \\\n",
       "0  Saya memakai Honda Jazz GK5 tahun 2014 ( perta...   neutral   neutral   \n",
       "1  Avanza kenapa jadi boros bensin begini dah ah....  negative   neutral   \n",
       "2  saran ku dan pengalaman ku , mending beli mobi...  positive  positive   \n",
       "3  Dari segi harga juga pajero lebih mahal 30 jut...   neutral   neutral   \n",
       "4                     Kalo menurut gw enak pajero si   neutral   neutral   \n",
       "\n",
       "     others     part     price  service  \n",
       "0  positive  neutral   neutral  neutral  \n",
       "1   neutral  neutral   neutral  neutral  \n",
       "2   neutral  neutral   neutral  neutral  \n",
       "3   neutral  neutral  positive  neutral  \n",
       "4  positive  neutral   neutral  neutral  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('/kaggle/input/casa-dataset/train_preprocess.csv', encoding='latin-1')\n",
    "val_data = pd.read_csv('/kaggle/input/casa-dataset/valid_preprocess.csv', encoding='latin-1')\n",
    "test_data = pd.read_csv('/kaggle/input/casa-dataset/test_preprocess.csv', encoding='latin-1')\n",
    "\n",
    "data = pd.concat([train_data, val_data, test_data], ignore_index=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d175cf37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T08:37:38.901807Z",
     "iopub.status.busy": "2025-03-23T08:37:38.901601Z",
     "iopub.status.idle": "2025-03-23T08:37:38.910188Z",
     "shell.execute_reply": "2025-03-23T08:37:38.909388Z"
    },
    "papermill": {
     "duration": 0.021871,
     "end_time": "2025-03-23T08:37:38.911401",
     "exception": false,
     "start_time": "2025-03-23T08:37:38.889530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>fuel</th>\n",
       "      <th>machine</th>\n",
       "      <th>others</th>\n",
       "      <th>part</th>\n",
       "      <th>price</th>\n",
       "      <th>service</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saya memakai Honda Jazz GK5 tahun 2014 ( perta...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Avanza kenapa jadi boros bensin begini dah ah....</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saran ku dan pengalaman ku , mending beli mobi...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dari segi harga juga pajero lebih mahal 30 jut...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kalo menurut gw enak pajero si</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence      fuel   machine  \\\n",
       "0  Saya memakai Honda Jazz GK5 tahun 2014 ( perta...   neutral   neutral   \n",
       "1  Avanza kenapa jadi boros bensin begini dah ah....  negative   neutral   \n",
       "2  saran ku dan pengalaman ku , mending beli mobi...  positive  positive   \n",
       "3  Dari segi harga juga pajero lebih mahal 30 jut...   neutral   neutral   \n",
       "4                     Kalo menurut gw enak pajero si   neutral   neutral   \n",
       "\n",
       "     others     part     price  service  \n",
       "0  positive  neutral   neutral  neutral  \n",
       "1   neutral  neutral   neutral  neutral  \n",
       "2   neutral  neutral   neutral  neutral  \n",
       "3   neutral  neutral  positive  neutral  \n",
       "4  positive  neutral   neutral  neutral  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1872480e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T08:37:38.935128Z",
     "iopub.status.busy": "2025-03-23T08:37:38.934924Z",
     "iopub.status.idle": "2025-03-23T08:37:38.944161Z",
     "shell.execute_reply": "2025-03-23T08:37:38.943539Z"
    },
    "papermill": {
     "duration": 0.022523,
     "end_time": "2025-03-23T08:37:38.945438",
     "exception": false,
     "start_time": "2025-03-23T08:37:38.922915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d06fccb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T08:37:38.970256Z",
     "iopub.status.busy": "2025-03-23T08:37:38.970029Z",
     "iopub.status.idle": "2025-03-23T08:37:38.983225Z",
     "shell.execute_reply": "2025-03-23T08:37:38.982369Z"
    },
    "papermill": {
     "duration": 0.027647,
     "end_time": "2025-03-23T08:37:38.984747",
     "exception": false,
     "start_time": "2025-03-23T08:37:38.957100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(864,) (864, 6)\n",
      "(216,) (216, 6)\n"
     ]
    }
   ],
   "source": [
    "train_labels = train_data.columns[1:]\n",
    "val_labels = val_data.columns[1:]\n",
    "\n",
    "# Extract features and labels for training and validation\n",
    "X_train = train_data['sentence'].values\n",
    "y_train = train_data[train_labels].values\n",
    "X_val = val_data['sentence'].values\n",
    "y_val = val_data[val_labels].values\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143455d2",
   "metadata": {
    "papermill": {
     "duration": 0.011421,
     "end_time": "2025-03-23T08:37:39.009272",
     "exception": false,
     "start_time": "2025-03-23T08:37:38.997851",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BUILD DATASET & DATALOADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84118278",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T08:37:39.032982Z",
     "iopub.status.busy": "2025-03-23T08:37:39.032740Z",
     "iopub.status.idle": "2025-03-23T08:37:39.038601Z",
     "shell.execute_reply": "2025-03-23T08:37:39.038002Z"
    },
    "papermill": {
     "duration": 0.019141,
     "end_time": "2025-03-23T08:37:39.039877",
     "exception": false,
     "start_time": "2025-03-23T08:37:39.020736",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AspectDetectionDataset(Dataset):\n",
    "    def __init__(self, texts, labels, label_mapping, tokenizer, max_length=sequence_length, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.use_float = use_float\n",
    "        self.label_mapping = label_mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "        \n",
    "        original_labels = [self.label_mapping[label] for label in self.labels[idx]]\n",
    "        encoded_labels = [1 if label == 1 else 0 for label in original_labels]\n",
    "        \n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['ori_indices'] = idx\n",
    "        item['ori_text'] = self.texts[idx]\n",
    "        item['ori_label'] = torch.tensor(original_labels, dtype=torch.float)\n",
    "        item['labels'] = torch.tensor(encoded_labels, dtype=torch.float if self.use_float else torch.long)\n",
    "        \n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6331ad4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T08:37:39.063602Z",
     "iopub.status.busy": "2025-03-23T08:37:39.063375Z",
     "iopub.status.idle": "2025-03-23T08:37:39.070790Z",
     "shell.execute_reply": "2025-03-23T08:37:39.069772Z"
    },
    "papermill": {
     "duration": 0.020969,
     "end_time": "2025-03-23T08:37:39.072504",
     "exception": false,
     "start_time": "2025-03-23T08:37:39.051535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SentimentAnalysisDataset(Dataset):\n",
    "    def __init__(self, texts, labels, aspects, indices, label_mapping, tokenizer, max_length=96, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.aspects = aspects\n",
    "        self.indices = indices\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.use_float = use_float\n",
    "        self.label_mapping = label_mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = aspect_token + ' ' + self.aspects[idx] + ' ' + review_token + ' ' + self.texts[idx] \n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "\n",
    "        if isinstance(self.labels[idx], str):\n",
    "            self.labels[idx] = self.label_mapping[self.labels[idx]]\n",
    "        elif torch.is_tensor(self.labels[idx]):\n",
    "            self.labels[idx] = int(self.labels[idx].item())\n",
    "\n",
    "        encoded_label = 1 if self.labels[idx] == 2 else self.labels[idx]\n",
    "        one_hot_label = F.one_hot(torch.tensor(encoded_label, dtype=torch.long), num_classes=2).float()\n",
    "\n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['aspect'] = self.aspects[idx]\n",
    "        item['labels'] = one_hot_label\n",
    "        item['ori_indices'] = self.indices[idx]\n",
    "        item['ori_text'] = self.texts[idx]\n",
    "        item['ori_label'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ada3d552",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T08:37:39.099908Z",
     "iopub.status.busy": "2025-03-23T08:37:39.099382Z",
     "iopub.status.idle": "2025-03-23T08:37:39.858858Z",
     "shell.execute_reply": "2025-03-23T08:37:39.858021Z"
    },
    "papermill": {
     "duration": 0.775544,
     "end_time": "2025-03-23T08:37:39.860498",
     "exception": false,
     "start_time": "2025-03-23T08:37:39.084954",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e13aa41bee3a4b08869d0cccc6263b30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05fac24a37fd46eeb835d5417fbac870",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/229k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd88f48e36e54adc804463a4e6e32eb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "229563a6ff954f99ad7ff7d9bf684556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p1')\n",
    "review_token = '[REVIEW]'\n",
    "aspect_token = '[ASPECT]'\n",
    "special_tokens_dict = {'additional_special_tokens': [review_token, aspect_token]}\n",
    "num_added_tokens = tokenizer.add_special_tokens(special_tokens_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "309be474",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T08:37:39.888705Z",
     "iopub.status.busy": "2025-03-23T08:37:39.888236Z",
     "iopub.status.idle": "2025-03-23T08:37:39.894117Z",
     "shell.execute_reply": "2025-03-23T08:37:39.893387Z"
    },
    "papermill": {
     "duration": 0.021527,
     "end_time": "2025-03-23T08:37:39.895598",
     "exception": false,
     "start_time": "2025-03-23T08:37:39.874071",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_aspect_dataset(X_train, y_train, X_val, y_val, sequence_length, num_workers=4):\n",
    "    train_dataset = AspectDetectionDataset(X_train, y_train, label_mapping, tokenizer, max_length=sequence_length)\n",
    "    val_dataset = AspectDetectionDataset(X_val, y_val, label_mapping, tokenizer, max_length=sequence_length)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=num_workers,\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=num_workers, \n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5766e95c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T08:37:39.923743Z",
     "iopub.status.busy": "2025-03-23T08:37:39.923422Z",
     "iopub.status.idle": "2025-03-23T08:37:39.935245Z",
     "shell.execute_reply": "2025-03-23T08:37:39.934228Z"
    },
    "papermill": {
     "duration": 0.027717,
     "end_time": "2025-03-23T08:37:39.936813",
     "exception": false,
     "start_time": "2025-03-23T08:37:39.909096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_sentiment_dataset(device, train_dataset, val_dataset, aspect_detection_model, tokenizer, max_length=sequence_length):\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "\n",
    "    aspect_detection_model.to(device)\n",
    "    aspect_detection_model.eval()\n",
    "\n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "    train_aspects = []\n",
    "    train_indices = []\n",
    "\n",
    "    val_data = []\n",
    "    val_labels = []\n",
    "    val_aspects = []\n",
    "    val_indices = []\n",
    "\n",
    "    # Transform train set\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        for batch in train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = aspect_detection_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            for i in range(len(preds)):\n",
    "                for j in range(len(preds[i])):\n",
    "                    if int(preds[i][j]) != 1:\n",
    "                        train_aspects.append(aspect_list[j])\n",
    "                        train_data.append(batch['ori_text'][i])\n",
    "                        train_labels.append(batch['ori_label'][i][j])\n",
    "                        train_indices.append(batch['ori_indices'][i])\n",
    "            \n",
    "        # Transform validation set\n",
    "        for batch in val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = aspect_detection_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            for i in range(len(preds)):\n",
    "                for j in range(len(preds[i])):\n",
    "                    if int(preds[i][j]) != 1:\n",
    "                        val_aspects.append(aspect_list[j])\n",
    "                        val_data.append(batch['ori_text'][i])\n",
    "                        val_labels.append(batch['ori_label'][i][j])\n",
    "                        val_indices.append(batch['ori_indices'][i])\n",
    "\n",
    "    train_dataset = SentimentAnalysisDataset(train_data, train_labels, train_aspects, train_indices, label_mapping, tokenizer, max_length=max_length)\n",
    "    val_dataset = SentimentAnalysisDataset(val_data, val_labels, val_aspects, val_indices, label_mapping, tokenizer, max_length=max_length)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e07d3c3",
   "metadata": {
    "papermill": {
     "duration": 0.013306,
     "end_time": "2025-03-23T08:37:39.963627",
     "exception": false,
     "start_time": "2025-03-23T08:37:39.950321",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf0b895c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T08:37:39.991707Z",
     "iopub.status.busy": "2025-03-23T08:37:39.991084Z",
     "iopub.status.idle": "2025-03-23T08:37:39.996004Z",
     "shell.execute_reply": "2025-03-23T08:37:39.995322Z"
    },
    "papermill": {
     "duration": 0.020747,
     "end_time": "2025-03-23T08:37:39.997477",
     "exception": false,
     "start_time": "2025-03-23T08:37:39.976730",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_data = len(X_train) + len(X_val)\n",
    "initial_train_size = int(0.05 * total_data)\n",
    "checkpoints = [\n",
    "    int(0.5 * total_data), \n",
    "    int(0.6 * total_data), \n",
    "    int(0.7 * total_data),\n",
    "    len(X_train)\n",
    "]\n",
    "min_increment = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3b29ab2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T08:37:40.025280Z",
     "iopub.status.busy": "2025-03-23T08:37:40.024978Z",
     "iopub.status.idle": "2025-03-23T08:37:40.030244Z",
     "shell.execute_reply": "2025-03-23T08:37:40.029389Z"
    },
    "papermill": {
     "duration": 0.020788,
     "end_time": "2025-03-23T08:37:40.031699",
     "exception": false,
     "start_time": "2025-03-23T08:37:40.010911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p, label, classes):\n",
    "    preds = torch.tensor(p.predictions) # Sigmoid and threshold for multi-label\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Hamming accuracy: proportion of correctly predicted labels over total labels\n",
    "    hamming_accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Standard multi-label precision, recall, and F1 metrics\n",
    "    precision, recall, f1_micro, _ = precision_recall_fscore_support(labels, preds, average='micro', zero_division=0)\n",
    "    _, _, f1_macro, _ = precision_recall_fscore_support(labels, preds, average='macro', zero_division=0)\n",
    "\n",
    "    report = classification_report(\n",
    "        labels, \n",
    "        preds, \n",
    "        labels=label,\n",
    "        target_names=classes,\n",
    "        zero_division=0\n",
    "    ) \n",
    "\n",
    "    return {\n",
    "        'accuracy': hamming_accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'report': report\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39a93c17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T08:37:40.059715Z",
     "iopub.status.busy": "2025-03-23T08:37:40.059360Z",
     "iopub.status.idle": "2025-03-23T08:37:40.066461Z",
     "shell.execute_reply": "2025-03-23T08:37:40.065683Z"
    },
    "papermill": {
     "duration": 0.022663,
     "end_time": "2025-03-23T08:37:40.067832",
     "exception": false,
     "start_time": "2025-03-23T08:37:40.045169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics_overall(p, classes):\n",
    "    preds = torch.tensor(p.predictions)\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Ensure it's in the correct shape\n",
    "    if preds.shape != labels.shape:\n",
    "        raise ValueError(\"Shape mismatch: predictions and labels must have the same shape.\")\n",
    "\n",
    "    # Hamming accuracy: proportion of correctly predicted labels over total labels\n",
    "    hamming_accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Compute per-label (column-wise) precision, recall, F1\n",
    "    precision_list, recall_list, f1_micro_list, f1_macro_list = [], [], [], []\n",
    "    \n",
    "    for i in range(labels.shape[1]):  # Loop through each column (multi-output)\n",
    "        prec, rec, f1_micro, _ = precision_recall_fscore_support(\n",
    "            labels[:, i], preds[:, i], average='micro', zero_division=0\n",
    "        )\n",
    "        _, _, f1_macro, _ = precision_recall_fscore_support(\n",
    "            labels[:, i], preds[:, i], average='macro', zero_division=0\n",
    "        )\n",
    "\n",
    "        precision_list.append(prec)\n",
    "        recall_list.append(rec)\n",
    "        f1_micro_list.append(f1_micro)\n",
    "        f1_macro_list.append(f1_macro)\n",
    "\n",
    "    # Compute average metrics across all outputs\n",
    "    precision = sum(precision_list) / len(precision_list)\n",
    "    recall = sum(recall_list) / len(recall_list)\n",
    "    f1_micro = sum(f1_micro_list) / len(f1_micro_list)\n",
    "    f1_macro = sum(f1_macro_list) / len(f1_macro_list)\n",
    "\n",
    "    # Generate classification report per output\n",
    "    reports = [classification_report(labels[:, i], preds[:, i], target_names=classes, zero_division=0) for i in range(labels.shape[1])]\n",
    "\n",
    "    return {\n",
    "        'accuracy': hamming_accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'reports': reports  # Returns list of reports, one for each output label\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "191dc864",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T08:37:40.096583Z",
     "iopub.status.busy": "2025-03-23T08:37:40.096191Z",
     "iopub.status.idle": "2025-03-23T08:37:40.126577Z",
     "shell.execute_reply": "2025-03-23T08:37:40.125520Z"
    },
    "papermill": {
     "duration": 0.046973,
     "end_time": "2025-03-23T08:37:40.128540",
     "exception": false,
     "start_time": "2025-03-23T08:37:40.081567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(current_train_size, train_indices, aspect_metrics, sentiment_metrics, metrics, trials, seed):\n",
    "    accelerator = Accelerator(mixed_precision='fp16')  # Initialize the accelerator\n",
    "    device = accelerator.device\n",
    "\n",
    "    aspect_model = BertForSequenceClassification.from_pretrained(\n",
    "        'indobenchmark/indobert-base-p1',\n",
    "        num_labels=len(train_labels),\n",
    "        problem_type=\"multi_label_classification\"\n",
    "    )\n",
    "\n",
    "    # Freeze the first few layers of the encoder\n",
    "    for name, param in aspect_model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    # Define optimizer and loss function\n",
    "    aspect_optimizer = torch.optim.AdamW(aspect_model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Define DataLoaders\n",
    "    current_X_train = [X_train[i] for i in train_indices]\n",
    "    current_y_train = [y_train[i] for i in train_indices]\n",
    "    aspect_train_loader, aspect_val_loader, aspect_train_dataset, aspect_val_dataset = build_aspect_dataset(current_X_train, current_y_train, X_val, y_val, sequence_length)\n",
    "\n",
    "    # Prepare everything with Accelerator\n",
    "    aspect_model, aspect_optimizer, aspect_train_loader, aspect_val_loader = accelerator.prepare(\n",
    "        aspect_model, aspect_optimizer, aspect_train_loader, aspect_val_loader\n",
    "    )\n",
    "\n",
    "    aspect_result = None\n",
    "    start_time = time.time()\n",
    "\n",
    "    # ASPECT DETECTION\n",
    "    accelerator.print(\"ASPECT DETECTION\")\n",
    "    for epoch in range(epochs):\n",
    "        aspect_model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for batch in aspect_train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels']\n",
    "        \n",
    "            aspect_optimizer.zero_grad()\n",
    "            outputs = aspect_model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            aspect_optimizer.step()\n",
    "        \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "        aspect_model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in aspect_val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "                labels = batch['labels']\n",
    "                \n",
    "                outputs = aspect_model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                # Gather predictions and labels from all devices\n",
    "                all_preds.append(accelerator.gather(preds))\n",
    "                all_labels.append(accelerator.gather(labels))\n",
    "\n",
    "        all_preds = torch.cat(all_preds).cpu().numpy()\n",
    "        all_labels = torch.cat(all_labels).cpu().numpy()\n",
    "\n",
    "        result = compute_metrics(\n",
    "            type('EvalOutput', (object,), {'predictions': all_preds, 'label_ids': all_labels}),\n",
    "            None,\n",
    "            ['fuel', 'machine', 'others', 'part', 'price', 'service']\n",
    "        )\n",
    "\n",
    "        if aspect_result is None or result['f1_micro'] >= aspect_result['f1_micro']:\n",
    "            accelerator.print(\"Higher F1 achieved, saving model\")\n",
    "            \n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(aspect_model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                f'{filename}-aspect-{trials + 1}-model',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "            aspect_result = result\n",
    "\n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(aspect_train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "\n",
    "    accelerator.print(f\"\\nAspect detection accuracy: {round(aspect_result['accuracy'], 4)}, F1 Micro: {round(aspect_result['f1_micro'], 4)}, F1 Macro: {round(aspect_result['f1_macro'], 4)}\")\n",
    "    accelerator.print(aspect_result['report'])\n",
    "\n",
    "    best_aspect_model = BertForSequenceClassification.from_pretrained(f'{filename}-aspect-{trials + 1}-model')\n",
    "    best_aspect_model = accelerator.prepare(best_aspect_model)\n",
    "\n",
    "    # SENTIMENT ANALYSIS ON NON NEUTRAL ASPECTS\n",
    "    accelerator.print(\"--------------------------------------------------\")\n",
    "    accelerator.print(\"SENTIMENT ANALYSIS\")\n",
    "\n",
    "    sentiment_model = BertForSequenceClassification.from_pretrained(\n",
    "        'indobenchmark/indobert-base-p1',\n",
    "        num_labels=2,\n",
    "    )\n",
    "    sentiment_optimizer = torch.optim.AdamW(sentiment_model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "\n",
    "    for name, param in sentiment_model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    sentiment_train_loader, sentiment_val_loader, sentiment_train_dataset, sentiment_val_dataset = build_sentiment_dataset(\n",
    "        device, aspect_train_dataset, aspect_val_dataset, best_aspect_model, tokenizer, max_length=sequence_length\n",
    "    )\n",
    "    sentiment_model, sentiment_optimizer, sentiment_train_loader, sentiment_val_loader = accelerator.prepare(\n",
    "        sentiment_model, sentiment_optimizer, sentiment_train_loader, sentiment_val_loader\n",
    "    )\n",
    "    sentiment_result = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        sentiment_model.train()\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for batch in sentiment_train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels']\n",
    "        \n",
    "            sentiment_optimizer.zero_grad()\n",
    "            outputs = sentiment_model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            sentiment_optimizer.step()\n",
    "        \n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        sentiment_model.eval()\n",
    "        sentiment_val_outputs = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in sentiment_val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "                \n",
    "                outputs = sentiment_model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                for i in range(len(preds)):\n",
    "                    val_output = {\n",
    "                        'label': batch['labels'][i],\n",
    "                        'aspect': batch['aspect'][i],\n",
    "                        'ori_indices': batch['ori_indices'][i],\n",
    "                        'pred': np.argmax(preds[i].cpu().numpy()),\n",
    "                    }\n",
    "                    sentiment_val_outputs.append(val_output)\n",
    "\n",
    "        sentiment_val_outputs = accelerator.gather_for_metrics(sentiment_val_outputs)\n",
    "        unique_val_outputs = {(x['ori_indices'].item(), x['aspect']): x for x in sentiment_val_outputs}\n",
    "        sentiment_val_outputs = list(unique_val_outputs.values())\n",
    "\n",
    "        result = compute_metrics(\n",
    "            type('EvalOutput', (object,), {'predictions': [item['pred'] for item in sentiment_val_outputs], 'label_ids': [np.argmax(item['label'].cpu().numpy()) for item in sentiment_val_outputs]}),\n",
    "            [0, 1],\n",
    "            ['negative', 'positive']\n",
    "        )\n",
    "\n",
    "        if sentiment_result is None or result['f1_micro'] >= sentiment_result['f1_micro']:\n",
    "            accelerator.print(\"Higher F1 achieved, saving model\")\n",
    "            sentiment_result = result\n",
    "            \n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(sentiment_model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                 f'{filename}-sentiment-{trials + 1}-model',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "\n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(sentiment_train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "\n",
    "    accelerator.print(f\"\\nSentiment analysis accuracy: {round(sentiment_result['accuracy'], 4)}, F1 Micro: {round(sentiment_result['f1_micro'], 4)}, F1 Macro: {round(sentiment_result['f1_macro'], 4)}\")\n",
    "    accelerator.print(sentiment_result['report'])\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    best_sentiment_model = BertForSequenceClassification.from_pretrained( f'{filename}-sentiment-{trials + 1}-model')\n",
    "    best_sentiment_model = accelerator.prepare(best_sentiment_model)\n",
    "\n",
    "    # Compute overall metrics\n",
    "    aspect_labels = []\n",
    "    aspect_indices = []\n",
    "    aspect_preds = []\n",
    "\n",
    "    aspect_outputs = {}\n",
    "    sentiment_outputs = []\n",
    "    \n",
    "    best_aspect_model.eval()\n",
    "    best_sentiment_model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in aspect_val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            outputs = aspect_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            aspect_indices.append(accelerator.gather(batch['ori_indices']))\n",
    "            aspect_labels.append(accelerator.gather(batch['ori_label']))\n",
    "            aspect_preds.append(accelerator.gather(preds))\n",
    "\n",
    "        aspect_indices = torch.cat(aspect_indices).cpu().numpy()\n",
    "        aspect_labels = torch.cat(aspect_labels).cpu().numpy()\n",
    "        aspect_preds = torch.cat(aspect_preds).cpu().numpy()\n",
    "\n",
    "        accelerator.wait_for_everyone()\n",
    "        aspect_outputs = [\n",
    "            {'ori_indices': aspect_indices[i], \n",
    "             'ori_labels': aspect_labels[i], \n",
    "             'pred': aspect_preds[i]}\n",
    "            for i in range(len(aspect_preds))\n",
    "        ]\n",
    "        aspect_outputs = {x['ori_indices'].item(): x for x in aspect_outputs}\n",
    "    \n",
    "        for batch in sentiment_val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            outputs = sentiment_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "    \n",
    "            for i in range(len(preds)):\n",
    "                output = {\n",
    "                    'aspect': batch['aspect'][i],\n",
    "                    'ori_indices': batch['ori_indices'][i],\n",
    "                    'pred': np.argmax(preds[i].cpu().numpy()),\n",
    "                }\n",
    "                sentiment_outputs.append(output)\n",
    "\n",
    "        sentiment_outputs = accelerator.gather_for_metrics(sentiment_outputs)\n",
    "        sentiment_outputs = {(x['ori_indices'].item(), x['aspect']): x for x in sentiment_outputs}\n",
    "\n",
    "    # Replcae non neutral aspect to its predicted sentiment\n",
    "    accelerator.wait_for_everyone()\n",
    "    if accelerator.is_main_process:\n",
    "        i = -1\n",
    "        for (ori_index, aspect), value in sentiment_outputs.items():\n",
    "            aspect = aspect_mapping[aspect]\n",
    "            aspect_outputs[ori_index]['pred'][aspect] = 2 if value['pred'] == 1.0 else value['pred']\n",
    "\n",
    "        result = compute_metrics_overall(\n",
    "            type('EvalOutput', (object,), {'predictions': [output['pred'] for output in aspect_outputs.values()], 'label_ids': [output['ori_labels'] for output in aspect_outputs.values()]}),\n",
    "            ['negative', 'neutral', 'positive'],\n",
    "        )\n",
    "\n",
    "        accelerator.print(\"--------------------------------------------------\")\n",
    "        accelerator.print(f\"Iteration {current_train_size}: Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "        accelerator.print(\"--------------------------------------------------\")\n",
    "        for i in range(len(train_labels)):\n",
    "            accelerator.print(f\"Aspect {aspect_list[i]} report:\")\n",
    "            accelerator.print(result['reports'][i])\n",
    "       \n",
    "        \n",
    "        aspect_metrics[0].append(aspect_result['accuracy'])\n",
    "        aspect_metrics[1].append(aspect_result['f1_micro'])\n",
    "        aspect_metrics[2].append(aspect_result['f1_macro'])\n",
    "        sentiment_metrics[0].append(sentiment_result['accuracy'])\n",
    "        sentiment_metrics[1].append(sentiment_result['f1_micro'])\n",
    "        sentiment_metrics[2].append(sentiment_result['f1_macro'])\n",
    "        metrics[0].append(current_train_size)\n",
    "        metrics[1].append(result['accuracy'])\n",
    "        metrics[2].append(result['f1_micro'])\n",
    "        metrics[3].append(result['f1_macro'])\n",
    "        \n",
    "    accelerator.print(f\"Total train time: {duration} s\")\n",
    "    accelerator.end_training()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca0cf4e",
   "metadata": {
    "papermill": {
     "duration": 0.012753,
     "end_time": "2025-03-23T08:37:40.155404",
     "exception": false,
     "start_time": "2025-03-23T08:37:40.142651",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PLOT THE RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9bf04e6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T08:37:40.184345Z",
     "iopub.status.busy": "2025-03-23T08:37:40.183974Z",
     "iopub.status.idle": "2025-03-23T08:37:40.190558Z",
     "shell.execute_reply": "2025-03-23T08:37:40.189605Z"
    },
    "papermill": {
     "duration": 0.023103,
     "end_time": "2025-03-23T08:37:40.192165",
     "exception": false,
     "start_time": "2025-03-23T08:37:40.169062",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_result(data_used, accuracies, f1_micros, f1_macros):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(21, 5))\n",
    "    data_used = [round(data / total_data * 100, 1) for data in data_used]\n",
    "\n",
    "    # Plot for Accuracy\n",
    "    axs[0].plot(data_used, accuracies, label=\"Accuracy\", color=\"blue\")\n",
    "    axs[0].set_xlabel(\"Percentage of data used\")\n",
    "    axs[0].set_title(\"Accuracy\")\n",
    "    axs[0].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Micro\n",
    "    axs[1].plot(data_used, f1_micros, label=\"F1 Micro\", color=\"orange\")\n",
    "    axs[1].set_xlabel(\"Percentage of data used\")\n",
    "    axs[1].set_title(\"F1 Micro\")\n",
    "    axs[1].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Macro\n",
    "    axs[2].plot(data_used, f1_macros, label=\"F1 Macro\", color=\"green\")\n",
    "    axs[2].set_xlabel(\"Percentage of data used\")\n",
    "    axs[2].set_title(\"F1 Macro\")\n",
    "    axs[2].set_xticks(data_used)\n",
    "\n",
    "    # Adjust layout and show the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2aa7b8",
   "metadata": {
    "papermill": {
     "duration": 0.01316,
     "end_time": "2025-03-23T08:37:40.218788",
     "exception": false,
     "start_time": "2025-03-23T08:37:40.205628",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# QUERY STRATEGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9bdd3236",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T08:37:40.246960Z",
     "iopub.status.busy": "2025-03-23T08:37:40.246638Z",
     "iopub.status.idle": "2025-03-23T08:37:40.263547Z",
     "shell.execute_reply": "2025-03-23T08:37:40.262792Z"
    },
    "papermill": {
     "duration": 0.032639,
     "end_time": "2025-03-23T08:37:40.264994",
     "exception": false,
     "start_time": "2025-03-23T08:37:40.232355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def least_confidence_sampling(aspect_model, sentiment_model, X_pool, train_indices, remaining_indices, sampling_dur, new_samples, trials, n_samples=min_increment):\n",
    "    accelerator = Accelerator(mixed_precision=\"fp16\")\n",
    "    device = accelerator.device\n",
    "\n",
    "    aspect_model.to(device)\n",
    "    aspect_model.eval()\n",
    "    sentiment_model.to(device)\n",
    "    sentiment_model.eval()\n",
    "\n",
    "    current_train_size = len(train_indices)\n",
    "    aspect_dataset = AspectDetectionDataset(\n",
    "        X_pool, \n",
    "        [['neutral' for i in range(len(train_labels))] for x in range(len(X_pool))], \n",
    "        label_mapping, \n",
    "        tokenizer, \n",
    "        max_length=sequence_length\n",
    "    )\n",
    "    aspect_loader = DataLoader(\n",
    "        aspect_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    \n",
    "    aspect_outputs = {}\n",
    "    sentiment_outputs = {}\n",
    "\n",
    "    aspects = []\n",
    "    data = []\n",
    "    labels = []\n",
    "    indices = []\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Pass through aspect detction model\n",
    "    for batch in aspect_loader:\n",
    "        token_type_ids = batch['token_type_ids'].to(device, non_blocking=True)\n",
    "        input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "        attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = aspect_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids).logits\n",
    "\n",
    "        for i in range(len(outputs)):\n",
    "            aspect_outputs[batch['ori_indices'][i].item()] = np.max(torch.sigmoid(outputs[i]).cpu().numpy())\n",
    "            \n",
    "            for j in range(len(outputs[i])):\n",
    "                if int(outputs[i][j]) != 1:\n",
    "                    aspects.append(aspect_list[j])\n",
    "                    data.append(batch['ori_text'][i])\n",
    "                    labels.append(batch['ori_label'][i][j])\n",
    "                    indices.append(batch['ori_indices'][i])\n",
    "    \n",
    "    sentiment_dataset = SentimentAnalysisDataset(data, labels, aspects, indices, label_mapping, tokenizer, max_length=sequence_length)\n",
    "    sentiment_loader = torch.utils.data.DataLoader(\n",
    "        sentiment_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4,\n",
    "    )\n",
    "\n",
    "    # Pass through sentiment analysis model\n",
    "    for batch in sentiment_loader:\n",
    "        token_type_ids = batch['token_type_ids'].to(device, non_blocking=True)\n",
    "        input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "        attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = sentiment_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "        for i in range(len(preds)):\n",
    "            ori_index = batch['ori_indices'][i].item()\n",
    "            if ori_index in sentiment_outputs.keys():\n",
    "                max_pred = np.max(preds[i].cpu().numpy())\n",
    "                sentiment_outputs[ori_index] = max_pred if max_pred > sentiment_outputs[ori_index] else sentiment_outputs[ori_index]\n",
    "            else:\n",
    "                sentiment_outputs[ori_index] = np.max(preds[i].cpu().numpy())\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    if accelerator.is_main_process:\n",
    "        aspect_outputs = dict(sorted(aspect_outputs.items()))\n",
    "    \n",
    "        # accelerator.print(aspect_outputs)\n",
    "        for key, val in sentiment_outputs.items():\n",
    "            aspect_outputs[key] = 1 - ((val + aspect_outputs[key]) / 2)\n",
    "    \n",
    "        # accelerator.print(aspect_outputs)\n",
    "        uncertainties = np.array(list(aspect_outputs.values()))\n",
    "        sorted_unc = np.argsort(uncertainties)\n",
    "        sorted_unc = sorted_unc[::-1]\n",
    "\n",
    "        threshold = np.percentile(uncertainties, 90)\n",
    "        items_greater_than_average = uncertainties[uncertainties >= threshold]\n",
    "        num_of_candidates = len(items_greater_than_average)\n",
    "        \n",
    "        # Check nearest checkpoint\n",
    "        nearest_cp = 0\n",
    "        for cp in checkpoints:\n",
    "            if cp > current_train_size:\n",
    "                nearest_cp = cp\n",
    "                break\n",
    "        \n",
    "        if num_of_candidates <= n_samples and n_samples < nearest_cp - current_train_size:\n",
    "            least_confident_indices = sorted_unc[:n_samples]\n",
    "        elif num_of_candidates > n_samples and num_of_candidates < nearest_cp - current_train_size:\n",
    "            least_confident_indices = sorted_unc[:max(n_samples, min(math.ceil(0.1*len(sorted_unc)), num_of_candidates))]\n",
    "        else:\n",
    "            least_confident_indices = sorted_unc[:nearest_cp - current_train_size]\n",
    "    \n",
    "            temp = train_indices.copy()\n",
    "            temp.extend([remaining_indices[i] for i in least_confident_indices])\n",
    "            \n",
    "            # Save acquired data up to checkpoint\n",
    "            acquired_data = pd.DataFrame({\n",
    "                'processed_text': [X_train[i] for i in temp],\n",
    "                'fuel': [y_train[i][0] for i in temp],\n",
    "                'machine': [y_train[i][1] for i in temp],\n",
    "                'others': [y_train[i][2] for i in temp],\n",
    "                'part': [y_train[i][3] for i in temp],\n",
    "                'price': [y_train[i][4] for i in temp],\n",
    "                'service': [y_train[i][5] for i in temp],\n",
    "            })\n",
    "    \n",
    "            acquired_data.to_csv(f'acquired_data/{filename}-{trials+1}-data-{nearest_cp}.csv', index=False)\n",
    "    \n",
    "        end_time = time.time() \n",
    "        duration = end_time - start_time\n",
    "    \n",
    "        sampling_dur.append(duration)\n",
    "        for i in least_confident_indices:\n",
    "            new_samples.append(remaining_indices[i])\n",
    "            \n",
    "        print(\"Nearest checkpoint:\", nearest_cp)\n",
    "        print(\"Threshold:\", threshold)\n",
    "        print(\"Samples above threshold:\", num_of_candidates)\n",
    "        print(\"Acquired samples:\", len(least_confident_indices))\n",
    "        print(f\"Sampling duration: {duration} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e968dcb5",
   "metadata": {
    "papermill": {
     "duration": 0.013832,
     "end_time": "2025-03-23T08:37:40.292321",
     "exception": false,
     "start_time": "2025-03-23T08:37:40.278489",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MAIN LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2561071f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T08:37:40.318874Z",
     "iopub.status.busy": "2025-03-23T08:37:40.318556Z",
     "iopub.status.idle": "2025-03-23T08:37:40.328385Z",
     "shell.execute_reply": "2025-03-23T08:37:40.327548Z"
    },
    "papermill": {
     "duration": 0.024682,
     "end_time": "2025-03-23T08:37:40.329672",
     "exception": false,
     "start_time": "2025-03-23T08:37:40.304990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def active_learning(seed, i):\n",
    "    aspect_accuracies = manager.list()\n",
    "    aspect_f1_micros = manager.list()\n",
    "    aspect_f1_macros = manager.list()\n",
    "    sentiment_accuracies = manager.list()\n",
    "    sentiment_f1_micros = manager.list()\n",
    "    sentiment_f1_macros = manager.list()\n",
    "    accuracies = manager.list()\n",
    "    f1_micros = manager.list()\n",
    "    f1_macros = manager.list()\n",
    "    data_used = manager.list()\n",
    "    sampling_dur = manager.list()\n",
    "    new_samples = manager.list()\n",
    "\n",
    "    set_seed(seed)\n",
    "    \n",
    "    print(\"===============================================\")\n",
    "    print(\"TRIAL {}\".format(i+1))\n",
    "    print(\"Random seed:\", seed)\n",
    "    \n",
    "    train_indices = np.random.choice(range(len(X_train)), initial_train_size, replace=False).tolist()\n",
    "    remaining_indices = list(set(range(len(X_train))) - set(train_indices))\n",
    "    \n",
    "    current_train_size = initial_train_size\n",
    "    \n",
    "    start_time = time.time()\n",
    "    while current_train_size < checkpoints[len(checkpoints) - 1]:\n",
    "        # Train the model\n",
    "        args = (\n",
    "            current_train_size, \n",
    "            train_indices, \n",
    "            (aspect_accuracies, aspect_f1_micros, aspect_f1_macros), \n",
    "            (sentiment_accuracies, sentiment_f1_micros, sentiment_f1_macros),\n",
    "            (data_used, accuracies, f1_micros, f1_macros), \n",
    "            i,\n",
    "            seed\n",
    "        )\n",
    "        notebook_launcher(train_model, args, num_processes=2)\n",
    "\n",
    "        aspect_model = BertForSequenceClassification.from_pretrained(f'{filename}-aspect-{i+1}-model')\n",
    "        sentiment_model = BertForSequenceClassification.from_pretrained(f'{filename}-sentiment-{i+1}-model')\n",
    "    \n",
    "        # Perform query strategy to select new samples\n",
    "        new_samples = manager.list()\n",
    "        sampling_args = (\n",
    "            aspect_model, \n",
    "            sentiment_model, \n",
    "            [X_train[i] for i in remaining_indices], \n",
    "            train_indices, \n",
    "            remaining_indices, \n",
    "            sampling_dur, \n",
    "            new_samples, \n",
    "            i\n",
    "        )\n",
    "        notebook_launcher(least_confidence_sampling, sampling_args, num_processes=2)\n",
    "        new_samples = list(new_samples)\n",
    "        train_indices.extend(new_samples)\n",
    "        remaining_indices = list(set(remaining_indices) - set(new_samples))\n",
    "    \n",
    "        # Update current training size\n",
    "        current_train_size = len(train_indices)\n",
    "        print(\"New train size: {}\".format(current_train_size))\n",
    "    \n",
    "    # Train last epoch\n",
    "    args = (\n",
    "        current_train_size, \n",
    "        train_indices, \n",
    "        (aspect_accuracies, aspect_f1_micros, aspect_f1_macros), \n",
    "        (sentiment_accuracies, sentiment_f1_micros, sentiment_f1_macros),\n",
    "        (data_used, accuracies, f1_micros, f1_macros), \n",
    "        i,\n",
    "        seed\n",
    "    )\n",
    "    notebook_launcher(train_model, args, num_processes=2)\n",
    "    data_used, accuracies, f1_micros, f1_macros, sampling_dur = list(data_used), list(accuracies), list(f1_micros), list(f1_macros), list(sampling_dur)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    # print(f\"Total sampling time: {np.array(sampling_dur).sum().round(2)} seconds\")\n",
    "    print(f\"Total runtime: {duration} seconds\")\n",
    "    \n",
    "    plot_result(data_used, accuracies, f1_micros, f1_macros)\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        'Data Used': data_used,\n",
    "        'Aspect Accuracy': aspect_accuracies,\n",
    "        'Aspect F1 Micro': aspect_f1_micros,\n",
    "        'Aspect F1 Macro': aspect_f1_macros,\n",
    "        'Sentiment Accuracy': sentiment_accuracies,\n",
    "        'Sentiment F1 Micro': sentiment_f1_micros,\n",
    "        'Sentiment F1 Macro': sentiment_f1_macros,\n",
    "        'Accuracy': accuracies,\n",
    "        'F1 Micro': f1_micros,\n",
    "        'F1 Macro': f1_macros,\n",
    "    })\n",
    "    \n",
    "    sampling_dur.insert(0, 0)\n",
    "    results['Sampling Duration'] = sampling_dur\n",
    "    results.to_csv(f'results/{filename}-{i+1}-results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3fe0e950",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T08:37:40.354584Z",
     "iopub.status.busy": "2025-03-23T08:37:40.354334Z",
     "iopub.status.idle": "2025-03-23T08:37:40.357384Z",
     "shell.execute_reply": "2025-03-23T08:37:40.356752Z"
    },
    "papermill": {
     "duration": 0.016874,
     "end_time": "2025-03-23T08:37:40.358589",
     "exception": false,
     "start_time": "2025-03-23T08:37:40.341715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seeds = [50, 81, 14, 3, 94]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ab20e9",
   "metadata": {
    "papermill": {
     "duration": 0.0117,
     "end_time": "2025-03-23T08:37:40.382394",
     "exception": false,
     "start_time": "2025-03-23T08:37:40.370694",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ad342a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 1\n",
      "Random seed: 50\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6756, Accuracy: 0.7731, F1 Micro: 0.8711, F1 Macro: 0.8698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5958, Accuracy: 0.7887, F1 Micro: 0.8819, F1 Macro: 0.8804\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5785, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.513, Accuracy: 0.7939, F1 Micro: 0.8843, F1 Macro: 0.8828\n",
      "Epoch 5/10, Train Loss: 0.5006, Accuracy: 0.7924, F1 Micro: 0.8829, F1 Macro: 0.881\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4695, Accuracy: 0.7954, F1 Micro: 0.8846, F1 Macro: 0.8828\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4328, Accuracy: 0.7969, F1 Micro: 0.8857, F1 Macro: 0.8842\n",
      "Epoch 8/10, Train Loss: 0.4369, Accuracy: 0.7932, F1 Micro: 0.8832, F1 Macro: 0.8812\n",
      "Epoch 9/10, Train Loss: 0.415, Accuracy: 0.7917, F1 Micro: 0.8816, F1 Macro: 0.8789\n",
      "Epoch 10/10, Train Loss: 0.3884, Accuracy: 0.7894, F1 Micro: 0.88, F1 Macro: 0.8769\n",
      "\n",
      "Aspect detection accuracy: 0.7969, F1 Micro: 0.8857, F1 Macro: 0.8842\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.78      1.00      0.88       175\n",
      "      others       0.71      1.00      0.83       158\n",
      "        part       0.75      0.98      0.85       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.80      1.00      0.89      1061\n",
      "   macro avg       0.80      1.00      0.88      1061\n",
      "weighted avg       0.80      1.00      0.89      1061\n",
      " samples avg       0.80      1.00      0.88      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7162, Accuracy: 0.2857, F1 Micro: 0.2857, F1 Macro: 0.2222\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.6764, Accuracy: 0.5, F1 Micro: 0.5, F1 Macro: 0.4974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.6621, Accuracy: 0.7143, F1 Micro: 0.7143, F1 Macro: 0.65\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.6053, Accuracy: 0.7857, F1 Micro: 0.7857, F1 Macro: 0.7143\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.5803, Accuracy: 0.7857, F1 Micro: 0.7857, F1 Macro: 0.7143\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.5674, Accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.825\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4789, Accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.825\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4895, Accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.825\n",
      "Epoch 9/10, Train Loss: 0.4054, Accuracy: 0.7143, F1 Micro: 0.7143, F1 Macro: 0.6889\n",
      "Epoch 10/10, Train Loss: 0.3482, Accuracy: 0.5, F1 Micro: 0.5, F1 Macro: 0.4974\n",
      "\n",
      "Sentiment analysis accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.825\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75         4\n",
      "    positive       0.90      0.90      0.90        10\n",
      "\n",
      "    accuracy                           0.86        14\n",
      "   macro avg       0.82      0.82      0.82        14\n",
      "weighted avg       0.86      0.86      0.86        14\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.7793, F1 Micro: 0.7793, F1 Macro: 0.3103\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.77      1.00      0.87       167\n",
      "    positive       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.77       216\n",
      "   macro avg       0.26      0.33      0.29       216\n",
      "weighted avg       0.60      0.77      0.67       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.70      1.00      0.83       152\n",
      "    positive       0.00      0.00      0.00        52\n",
      "\n",
      "    accuracy                           0.70       216\n",
      "   macro avg       0.23      0.33      0.28       216\n",
      "weighted avg       0.50      0.70      0.58       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.16      0.26      0.20        23\n",
      "     neutral       0.75      0.86      0.80       152\n",
      "    positive       0.60      0.07      0.13        41\n",
      "\n",
      "    accuracy                           0.64       216\n",
      "   macro avg       0.50      0.40      0.38       216\n",
      "weighted avg       0.66      0.64      0.61       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 51.4710431098938 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.08030970096588134\n",
      "Samples above threshold: 81\n",
      "Acquired samples: 81\n",
      "Sampling duration: 8.503296852111816 seconds\n",
      "New train size: 135\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6251, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.524, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Epoch 3/10, Train Loss: 0.4791, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4478, Accuracy: 0.7961, F1 Micro: 0.8856, F1 Macro: 0.8842\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4014, Accuracy: 0.8073, F1 Micro: 0.8905, F1 Macro: 0.8888\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3607, Accuracy: 0.8326, F1 Micro: 0.9027, F1 Macro: 0.901\n",
      "Epoch 7/10, Train Loss: 0.3515, Accuracy: 0.8289, F1 Micro: 0.8976, F1 Macro: 0.8929\n",
      "Epoch 8/10, Train Loss: 0.3175, Accuracy: 0.8281, F1 Micro: 0.8973, F1 Macro: 0.8921\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2522, Accuracy: 0.8385, F1 Micro: 0.9033, F1 Macro: 0.8998\n",
      "Epoch 10/10, Train Loss: 0.2518, Accuracy: 0.8356, F1 Micro: 0.9013, F1 Macro: 0.8962\n",
      "\n",
      "Aspect detection accuracy: 0.8385, F1 Micro: 0.9033, F1 Macro: 0.8998\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.84      1.00      0.91       187\n",
      "     machine       0.78      1.00      0.88       175\n",
      "      others       0.84      0.80      0.82       158\n",
      "        part       0.88      0.90      0.89       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.96      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.86      0.96      0.90      1061\n",
      "   macro avg       0.86      0.95      0.90      1061\n",
      "weighted avg       0.86      0.96      0.90      1061\n",
      " samples avg       0.86      0.96      0.90      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7116, Accuracy: 0.7403, F1 Micro: 0.7403, F1 Macro: 0.4254\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.6006, Accuracy: 0.7468, F1 Micro: 0.7468, F1 Macro: 0.4514\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.492, Accuracy: 0.7792, F1 Micro: 0.7792, F1 Macro: 0.5941\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3645, Accuracy: 0.8247, F1 Micro: 0.8247, F1 Macro: 0.7306\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3079, Accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.7966\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2077, Accuracy: 0.8766, F1 Micro: 0.8766, F1 Macro: 0.8383\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1188, Accuracy: 0.8766, F1 Micro: 0.8766, F1 Macro: 0.8294\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1072, Accuracy: 0.8831, F1 Micro: 0.8831, F1 Macro: 0.8504\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.043, Accuracy: 0.8831, F1 Micro: 0.8831, F1 Macro: 0.8504\n",
      "Epoch 10/10, Train Loss: 0.026, Accuracy: 0.8701, F1 Micro: 0.8701, F1 Macro: 0.8311\n",
      "\n",
      "Sentiment analysis accuracy: 0.8831, F1 Micro: 0.8831, F1 Macro: 0.8504\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.80      0.78        40\n",
      "    positive       0.93      0.91      0.92       114\n",
      "\n",
      "    accuracy                           0.88       154\n",
      "   macro avg       0.85      0.86      0.85       154\n",
      "weighted avg       0.89      0.88      0.88       154\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 135: Accuracy: 0.8164, F1 Micro: 0.8164, F1 Macro: 0.5023\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.85      1.00      0.92       181\n",
      "    positive       1.00      0.04      0.08        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.62      0.35      0.33       216\n",
      "weighted avg       0.82      0.84      0.78       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.77      1.00      0.87       167\n",
      "    positive       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.77       216\n",
      "   macro avg       0.26      0.33      0.29       216\n",
      "weighted avg       0.60      0.77      0.67       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.18      0.42      0.25        12\n",
      "     neutral       0.85      0.72      0.78       152\n",
      "    positive       0.47      0.52      0.49        52\n",
      "\n",
      "    accuracy                           0.66       216\n",
      "   macro avg       0.50      0.55      0.51       216\n",
      "weighted avg       0.72      0.66      0.68       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.61      0.72        23\n",
      "     neutral       0.87      0.90      0.89       152\n",
      "    positive       0.56      0.59      0.57        41\n",
      "\n",
      "    accuracy                           0.81       216\n",
      "   macro avg       0.77      0.70      0.73       216\n",
      "weighted avg       0.81      0.81      0.81       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.96      1.00      0.98       185\n",
      "    positive       0.83      0.59      0.69        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.79      0.85       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Total train time: 64.67616987228394 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0380561113357544\n",
      "Samples above threshold: 73\n",
      "Acquired samples: 73\n",
      "Sampling duration: 10.651062726974487 seconds\n",
      "New train size: 208\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5957, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5127, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4684, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.434, Accuracy: 0.8207, F1 Micro: 0.8974, F1 Macro: 0.8962\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3866, Accuracy: 0.8385, F1 Micro: 0.9063, F1 Macro: 0.9053\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3348, Accuracy: 0.8542, F1 Micro: 0.9137, F1 Macro: 0.9128\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3094, Accuracy: 0.8847, F1 Micro: 0.9305, F1 Macro: 0.9291\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2611, Accuracy: 0.9062, F1 Micro: 0.9428, F1 Macro: 0.9408\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2285, Accuracy: 0.9219, F1 Micro: 0.9517, F1 Macro: 0.9492\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1794, Accuracy: 0.9241, F1 Micro: 0.9528, F1 Macro: 0.9502\n",
      "\n",
      "Aspect detection accuracy: 0.9241, F1 Micro: 0.9528, F1 Macro: 0.9502\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.88      0.96      0.92       175\n",
      "      others       0.90      0.89      0.90       158\n",
      "        part       0.90      0.96      0.93       158\n",
      "       price       0.95      1.00      0.97       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.94      0.97      0.95      1061\n",
      "   macro avg       0.93      0.97      0.95      1061\n",
      "weighted avg       0.94      0.97      0.95      1061\n",
      " samples avg       0.94      0.97      0.95      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6125, Accuracy: 0.7179, F1 Micro: 0.7179, F1 Macro: 0.4179\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4335, Accuracy: 0.8547, F1 Micro: 0.8547, F1 Macro: 0.8029\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.29, Accuracy: 0.8803, F1 Micro: 0.8803, F1 Macro: 0.8585\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1791, Accuracy: 0.906, F1 Micro: 0.906, F1 Macro: 0.8817\n",
      "Epoch 5/10, Train Loss: 0.0849, Accuracy: 0.8974, F1 Micro: 0.8974, F1 Macro: 0.8756\n",
      "Epoch 6/10, Train Loss: 0.0681, Accuracy: 0.8974, F1 Micro: 0.8974, F1 Macro: 0.8756\n",
      "Epoch 7/10, Train Loss: 0.0449, Accuracy: 0.9017, F1 Micro: 0.9017, F1 Macro: 0.8803\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0371, Accuracy: 0.906, F1 Micro: 0.906, F1 Macro: 0.885\n",
      "Epoch 9/10, Train Loss: 0.065, Accuracy: 0.9017, F1 Micro: 0.9017, F1 Macro: 0.8792\n",
      "Epoch 10/10, Train Loss: 0.0373, Accuracy: 0.8932, F1 Micro: 0.8932, F1 Macro: 0.8636\n",
      "\n",
      "Sentiment analysis accuracy: 0.906, F1 Micro: 0.906, F1 Macro: 0.885\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.85      0.84        66\n",
      "    positive       0.94      0.93      0.93       168\n",
      "\n",
      "    accuracy                           0.91       234\n",
      "   macro avg       0.88      0.89      0.88       234\n",
      "weighted avg       0.91      0.91      0.91       234\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 208: Accuracy: 0.9051, F1 Micro: 0.9051, F1 Macro: 0.7968\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.88      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.38      0.55        16\n",
      "     neutral       0.87      0.96      0.91       167\n",
      "    positive       0.70      0.58      0.63        33\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.86      0.64      0.70       216\n",
      "weighted avg       0.86      0.86      0.84       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.56      0.42      0.48        12\n",
      "     neutral       0.90      0.89      0.90       152\n",
      "    positive       0.64      0.69      0.67        52\n",
      "\n",
      "    accuracy                           0.82       216\n",
      "   macro avg       0.70      0.67      0.68       216\n",
      "weighted avg       0.82      0.82      0.82       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.52      0.62        23\n",
      "     neutral       0.90      0.95      0.93       152\n",
      "    positive       0.67      0.63      0.65        41\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.77      0.70      0.73       216\n",
      "weighted avg       0.84      0.85      0.84       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.54      0.70        13\n",
      "     neutral       0.95      1.00      0.97       186\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.96      0.75      0.82       216\n",
      "weighted avg       0.95      0.95      0.94       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 80.4954879283905 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.029782652854919434\n",
      "Samples above threshold: 66\n",
      "Acquired samples: 66\n",
      "Sampling duration: 12.565688610076904 seconds\n",
      "New train size: 274\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5982, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5272, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4751, Accuracy: 0.7946, F1 Micro: 0.8849, F1 Macro: 0.8834\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.422, Accuracy: 0.8326, F1 Micro: 0.9041, F1 Macro: 0.9032\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3614, Accuracy: 0.8884, F1 Micro: 0.9332, F1 Macro: 0.9318\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.297, Accuracy: 0.9062, F1 Micro: 0.9433, F1 Macro: 0.9419\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2384, Accuracy: 0.9196, F1 Micro: 0.9509, F1 Macro: 0.9495\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.202, Accuracy: 0.9241, F1 Micro: 0.9525, F1 Macro: 0.9485\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1619, Accuracy: 0.9368, F1 Micro: 0.9608, F1 Macro: 0.9591\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.138, Accuracy: 0.9442, F1 Micro: 0.9649, F1 Macro: 0.962\n",
      "\n",
      "Aspect detection accuracy: 0.9442, F1 Micro: 0.9649, F1 Macro: 0.962\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.93      0.99      0.96       175\n",
      "      others       0.92      0.86      0.89       158\n",
      "        part       0.94      0.97      0.95       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.97      0.96      1061\n",
      "   macro avg       0.96      0.97      0.96      1061\n",
      "weighted avg       0.96      0.97      0.96      1061\n",
      " samples avg       0.96      0.97      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5766, Accuracy: 0.7104, F1 Micro: 0.7104, F1 Macro: 0.4153\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3938, Accuracy: 0.8764, F1 Micro: 0.8764, F1 Macro: 0.8499\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2544, Accuracy: 0.9035, F1 Micro: 0.9035, F1 Macro: 0.8849\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1128, Accuracy: 0.9112, F1 Micro: 0.9112, F1 Macro: 0.8933\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0793, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9261\n",
      "Epoch 6/10, Train Loss: 0.0898, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.8915\n",
      "Epoch 7/10, Train Loss: 0.0837, Accuracy: 0.9035, F1 Micro: 0.9035, F1 Macro: 0.8841\n",
      "Epoch 8/10, Train Loss: 0.0591, Accuracy: 0.9112, F1 Micro: 0.9112, F1 Macro: 0.8956\n",
      "Epoch 9/10, Train Loss: 0.0454, Accuracy: 0.9035, F1 Micro: 0.9035, F1 Macro: 0.8803\n",
      "Epoch 10/10, Train Loss: 0.0449, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.8899\n",
      "\n",
      "Sentiment analysis accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9261\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.92      0.90        75\n",
      "    positive       0.97      0.95      0.96       184\n",
      "\n",
      "    accuracy                           0.94       259\n",
      "   macro avg       0.92      0.93      0.93       259\n",
      "weighted avg       0.94      0.94      0.94       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 274: Accuracy: 0.9275, F1 Micro: 0.9275, F1 Macro: 0.8532\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.96      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.89      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.62      0.71        16\n",
      "     neutral       0.93      0.99      0.96       167\n",
      "    positive       0.88      0.70      0.78        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.88      0.77      0.82       216\n",
      "weighted avg       0.91      0.92      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.46      0.50      0.48        12\n",
      "     neutral       0.92      0.86      0.89       152\n",
      "    positive       0.62      0.73      0.67        52\n",
      "\n",
      "    accuracy                           0.81       216\n",
      "   macro avg       0.67      0.70      0.68       216\n",
      "weighted avg       0.82      0.81      0.82       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.83      0.81        23\n",
      "     neutral       0.94      0.97      0.95       152\n",
      "    positive       0.83      0.71      0.76        41\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.85      0.83      0.84       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.97      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.84      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.96      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 88.92532873153687 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.02398720979690552\n",
      "Samples above threshold: 59\n",
      "Acquired samples: 59\n",
      "Sampling duration: 11.958125352859497 seconds\n",
      "New train size: 333\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5689, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4832, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4209, Accuracy: 0.8385, F1 Micro: 0.9065, F1 Macro: 0.905\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.362, Accuracy: 0.8876, F1 Micro: 0.9316, F1 Macro: 0.9299\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2641, Accuracy: 0.9219, F1 Micro: 0.9519, F1 Macro: 0.9506\n",
      "Epoch 6/10, Train Loss: 0.216, Accuracy: 0.9107, F1 Micro: 0.9445, F1 Macro: 0.9394\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1843, Accuracy: 0.936, F1 Micro: 0.96, F1 Macro: 0.9567\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1456, Accuracy: 0.9479, F1 Micro: 0.9676, F1 Macro: 0.9659\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.13, Accuracy: 0.9516, F1 Micro: 0.9699, F1 Macro: 0.9683\n",
      "Epoch 10/10, Train Loss: 0.1029, Accuracy: 0.9516, F1 Micro: 0.9699, F1 Macro: 0.968\n",
      "\n",
      "Aspect detection accuracy: 0.9516, F1 Micro: 0.9699, F1 Macro: 0.9683\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.93      0.99      0.96       175\n",
      "      others       0.90      0.95      0.93       158\n",
      "        part       0.94      0.97      0.96       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.95      0.99      0.97      1061\n",
      "   macro avg       0.95      0.99      0.97      1061\n",
      "weighted avg       0.95      0.99      0.97      1061\n",
      " samples avg       0.95      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5448, Accuracy: 0.6765, F1 Micro: 0.6765, F1 Macro: 0.4035\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3887, Accuracy: 0.8782, F1 Micro: 0.8782, F1 Macro: 0.8551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.223, Accuracy: 0.916, F1 Micro: 0.916, F1 Macro: 0.904\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.129, Accuracy: 0.916, F1 Micro: 0.916, F1 Macro: 0.907\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1265, Accuracy: 0.9202, F1 Micro: 0.9202, F1 Macro: 0.9114\n",
      "Epoch 6/10, Train Loss: 0.1024, Accuracy: 0.8866, F1 Micro: 0.8866, F1 Macro: 0.8616\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0622, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9207\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0308, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9187\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0509, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9202\n",
      "Epoch 10/10, Train Loss: 0.0466, Accuracy: 0.9202, F1 Micro: 0.9202, F1 Macro: 0.9091\n",
      "\n",
      "Sentiment analysis accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9202\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.94      0.89        77\n",
      "    positive       0.97      0.93      0.95       161\n",
      "\n",
      "    accuracy                           0.93       238\n",
      "   macro avg       0.91      0.93      0.92       238\n",
      "weighted avg       0.93      0.93      0.93       238\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 333: Accuracy: 0.9352, F1 Micro: 0.9352, F1 Macro: 0.8573\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.90      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.62      0.69        16\n",
      "     neutral       0.93      0.99      0.96       167\n",
      "    positive       0.92      0.70      0.79        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.87      0.77      0.82       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.38      0.50      0.43        12\n",
      "     neutral       0.92      0.92      0.92       152\n",
      "    positive       0.77      0.69      0.73        52\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.69      0.70      0.69       216\n",
      "weighted avg       0.85      0.84      0.84       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.91      0.87        23\n",
      "     neutral       0.94      0.97      0.95       152\n",
      "    positive       0.85      0.68      0.76        41\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.88      0.86      0.86       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.91      0.84      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.96      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 92.87218117713928 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.019872188568115234\n",
      "Samples above threshold: 54\n",
      "Acquired samples: 54\n",
      "Sampling duration: 11.154432535171509 seconds\n",
      "New train size: 387\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5617, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4961, Accuracy: 0.8028, F1 Micro: 0.889, F1 Macro: 0.8877\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4098, Accuracy: 0.8899, F1 Micro: 0.9341, F1 Macro: 0.9328\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.308, Accuracy: 0.9144, F1 Micro: 0.948, F1 Macro: 0.9474\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.229, Accuracy: 0.933, F1 Micro: 0.9583, F1 Macro: 0.9559\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1826, Accuracy: 0.9397, F1 Micro: 0.9624, F1 Macro: 0.9598\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1386, Accuracy: 0.9524, F1 Micro: 0.9702, F1 Macro: 0.9684\n",
      "Epoch 8/10, Train Loss: 0.1183, Accuracy: 0.9464, F1 Micro: 0.9664, F1 Macro: 0.9636\n",
      "Epoch 9/10, Train Loss: 0.1008, Accuracy: 0.9501, F1 Micro: 0.9688, F1 Macro: 0.9662\n",
      "Epoch 10/10, Train Loss: 0.0867, Accuracy: 0.9509, F1 Micro: 0.9693, F1 Macro: 0.9671\n",
      "\n",
      "Aspect detection accuracy: 0.9524, F1 Micro: 0.9702, F1 Macro: 0.9684\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.93      0.99      0.96       175\n",
      "      others       0.91      0.92      0.91       158\n",
      "        part       0.96      0.97      0.97       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5405, Accuracy: 0.7247, F1 Micro: 0.7247, F1 Macro: 0.5123\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3421, Accuracy: 0.8907, F1 Micro: 0.8907, F1 Macro: 0.8756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1687, Accuracy: 0.9271, F1 Micro: 0.9271, F1 Macro: 0.9151\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1296, Accuracy: 0.9352, F1 Micro: 0.9352, F1 Macro: 0.925\n",
      "Epoch 5/10, Train Loss: 0.0696, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9141\n",
      "Epoch 6/10, Train Loss: 0.0499, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9119\n",
      "Epoch 7/10, Train Loss: 0.0549, Accuracy: 0.8907, F1 Micro: 0.8907, F1 Macro: 0.866\n",
      "Epoch 8/10, Train Loss: 0.0406, Accuracy: 0.915, F1 Micro: 0.915, F1 Macro: 0.9026\n",
      "Epoch 9/10, Train Loss: 0.0565, Accuracy: 0.915, F1 Micro: 0.915, F1 Macro: 0.9006\n",
      "Epoch 10/10, Train Loss: 0.042, Accuracy: 0.9069, F1 Micro: 0.9069, F1 Macro: 0.8919\n",
      "\n",
      "Sentiment analysis accuracy: 0.9352, F1 Micro: 0.9352, F1 Macro: 0.925\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.92      0.90        76\n",
      "    positive       0.96      0.94      0.95       171\n",
      "\n",
      "    accuracy                           0.94       247\n",
      "   macro avg       0.92      0.93      0.93       247\n",
      "weighted avg       0.94      0.94      0.94       247\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 387: Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.8553\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.98      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.56      0.67        16\n",
      "     neutral       0.93      0.99      0.96       167\n",
      "    positive       0.88      0.70      0.78        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.88      0.75      0.80       216\n",
      "weighted avg       0.91      0.92      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.42      0.67      0.52        12\n",
      "     neutral       0.92      0.88      0.90       152\n",
      "    positive       0.73      0.73      0.73        52\n",
      "\n",
      "    accuracy                           0.83       216\n",
      "   macro avg       0.69      0.76      0.71       216\n",
      "weighted avg       0.84      0.83      0.83       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.83      0.79        23\n",
      "     neutral       0.95      0.97      0.96       152\n",
      "    positive       0.81      0.71      0.75        41\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.84      0.84      0.84       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.69      0.78        13\n",
      "     neutral       0.97      1.00      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.91      0.82      0.86       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.96      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 90.93331718444824 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.020315718650817872\n",
      "Samples above threshold: 48\n",
      "Acquired samples: 48\n",
      "Sampling duration: 9.912609815597534 seconds\n",
      "New train size: 435\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5756, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5043, Accuracy: 0.8036, F1 Micro: 0.8893, F1 Macro: 0.8879\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4035, Accuracy: 0.8973, F1 Micro: 0.9381, F1 Macro: 0.9371\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2968, Accuracy: 0.9189, F1 Micro: 0.9501, F1 Macro: 0.9481\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2421, Accuracy: 0.9308, F1 Micro: 0.9574, F1 Macro: 0.9559\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1819, Accuracy: 0.939, F1 Micro: 0.962, F1 Macro: 0.9599\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1491, Accuracy: 0.9472, F1 Micro: 0.9668, F1 Macro: 0.9644\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1183, Accuracy: 0.9494, F1 Micro: 0.9684, F1 Macro: 0.9665\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1034, Accuracy: 0.9524, F1 Micro: 0.9703, F1 Macro: 0.9686\n",
      "Epoch 10/10, Train Loss: 0.0821, Accuracy: 0.9524, F1 Micro: 0.9702, F1 Macro: 0.9682\n",
      "\n",
      "Aspect detection accuracy: 0.9524, F1 Micro: 0.9703, F1 Macro: 0.9686\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.93      0.99      0.96       175\n",
      "      others       0.91      0.93      0.92       158\n",
      "        part       0.94      0.98      0.96       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.97      1061\n",
      "   macro avg       0.95      0.98      0.97      1061\n",
      "weighted avg       0.96      0.99      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5358, Accuracy: 0.751, F1 Micro: 0.751, F1 Macro: 0.6035\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2469, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.8972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1612, Accuracy: 0.9295, F1 Micro: 0.9295, F1 Macro: 0.9162\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1285, Accuracy: 0.9378, F1 Micro: 0.9378, F1 Macro: 0.9296\n",
      "Epoch 5/10, Train Loss: 0.1043, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9237\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.088, Accuracy: 0.9461, F1 Micro: 0.9461, F1 Macro: 0.9386\n",
      "Epoch 7/10, Train Loss: 0.0928, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9349\n",
      "Epoch 8/10, Train Loss: 0.0522, Accuracy: 0.9046, F1 Micro: 0.9046, F1 Macro: 0.8847\n",
      "Epoch 9/10, Train Loss: 0.0392, Accuracy: 0.9378, F1 Micro: 0.9378, F1 Macro: 0.9296\n",
      "Epoch 10/10, Train Loss: 0.0332, Accuracy: 0.9004, F1 Micro: 0.9004, F1 Macro: 0.8792\n",
      "\n",
      "Sentiment analysis accuracy: 0.9461, F1 Micro: 0.9461, F1 Macro: 0.9386\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        75\n",
      "    positive       0.98      0.94      0.96       166\n",
      "\n",
      "    accuracy                           0.95       241\n",
      "   macro avg       0.93      0.95      0.94       241\n",
      "weighted avg       0.95      0.95      0.95       241\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 435: Accuracy: 0.9321, F1 Micro: 0.9321, F1 Macro: 0.8464\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.62      0.71        16\n",
      "     neutral       0.93      0.99      0.96       167\n",
      "    positive       0.88      0.70      0.78        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.88      0.77      0.82       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.45      0.42      0.43        12\n",
      "     neutral       0.91      0.91      0.91       152\n",
      "    positive       0.72      0.75      0.74        52\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.70      0.69      0.69       216\n",
      "weighted avg       0.84      0.84      0.84       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.65      0.71        23\n",
      "     neutral       0.94      0.97      0.95       152\n",
      "    positive       0.79      0.76      0.77        41\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.84      0.79      0.81       216\n",
      "weighted avg       0.89      0.90      0.90       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.69      0.78        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.84      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 103.85068535804749 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.013049173355102538\n",
      "Samples above threshold: 43\n",
      "Acquired samples: 43\n",
      "Sampling duration: 9.376959323883057 seconds\n",
      "New train size: 478\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5674, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4568, Accuracy: 0.8274, F1 Micro: 0.9013, F1 Macro: 0.9004\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3501, Accuracy: 0.91, F1 Micro: 0.9455, F1 Macro: 0.9448\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2692, Accuracy: 0.9353, F1 Micro: 0.9599, F1 Macro: 0.9582\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1874, Accuracy: 0.9457, F1 Micro: 0.9662, F1 Macro: 0.9642\n",
      "Epoch 6/10, Train Loss: 0.1507, Accuracy: 0.9457, F1 Micro: 0.9662, F1 Macro: 0.964\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1216, Accuracy: 0.9501, F1 Micro: 0.9687, F1 Macro: 0.9661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.109, Accuracy: 0.9621, F1 Micro: 0.9763, F1 Macro: 0.9752\n",
      "Epoch 9/10, Train Loss: 0.0884, Accuracy: 0.9516, F1 Micro: 0.9697, F1 Macro: 0.9672\n",
      "Epoch 10/10, Train Loss: 0.0787, Accuracy: 0.9501, F1 Micro: 0.9686, F1 Macro: 0.9656\n",
      "\n",
      "Aspect detection accuracy: 0.9621, F1 Micro: 0.9763, F1 Macro: 0.9752\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.94      0.99      0.96       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.97      0.98      0.97       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.98      1061\n",
      "weighted avg       0.96      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5151, Accuracy: 0.8066, F1 Micro: 0.8066, F1 Macro: 0.7385\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2833, Accuracy: 0.9218, F1 Micro: 0.9218, F1 Macro: 0.9143\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1865, Accuracy: 0.9259, F1 Micro: 0.9259, F1 Macro: 0.919\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1205, Accuracy: 0.9259, F1 Micro: 0.9259, F1 Macro: 0.919\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0833, Accuracy: 0.9424, F1 Micro: 0.9424, F1 Macro: 0.9363\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.08, Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.9441\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0958, Accuracy: 0.9547, F1 Micro: 0.9547, F1 Macro: 0.9489\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0548, Accuracy: 0.963, F1 Micro: 0.963, F1 Macro: 0.9579\n",
      "Epoch 9/10, Train Loss: 0.0501, Accuracy: 0.9095, F1 Micro: 0.9095, F1 Macro: 0.9025\n",
      "Epoch 10/10, Train Loss: 0.0402, Accuracy: 0.9465, F1 Micro: 0.9465, F1 Macro: 0.9407\n",
      "\n",
      "Sentiment analysis accuracy: 0.963, F1 Micro: 0.963, F1 Macro: 0.9579\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.95      0.94        79\n",
      "    positive       0.98      0.97      0.97       164\n",
      "\n",
      "    accuracy                           0.96       243\n",
      "   macro avg       0.96      0.96      0.96       243\n",
      "weighted avg       0.96      0.96      0.96       243\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 478: Accuracy: 0.9406, F1 Micro: 0.9406, F1 Macro: 0.8816\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.75      0.77        16\n",
      "     neutral       0.94      0.99      0.97       167\n",
      "    positive       0.96      0.70      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.81      0.85       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.26      0.75      0.39        12\n",
      "     neutral       0.94      0.85      0.89       152\n",
      "    positive       0.87      0.75      0.80        52\n",
      "\n",
      "    accuracy                           0.82       216\n",
      "   macro avg       0.69      0.78      0.70       216\n",
      "weighted avg       0.89      0.82      0.84       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.97      0.98      0.97       152\n",
      "    positive       0.94      0.78      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.92      0.91       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.97      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.84      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 106.69384121894836 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.013274729251861572\n",
      "Samples above threshold: 39\n",
      "Acquired samples: 39\n",
      "Sampling duration: 8.526045799255371 seconds\n",
      "New train size: 517\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.559, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4475, Accuracy: 0.8482, F1 Micro: 0.9119, F1 Macro: 0.911\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3398, Accuracy: 0.9189, F1 Micro: 0.9502, F1 Macro: 0.9486\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2409, Accuracy: 0.9412, F1 Micro: 0.9634, F1 Macro: 0.9611\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1791, Accuracy: 0.9516, F1 Micro: 0.9697, F1 Macro: 0.968\n",
      "Epoch 6/10, Train Loss: 0.1453, Accuracy: 0.9457, F1 Micro: 0.966, F1 Macro: 0.9633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1166, Accuracy: 0.9583, F1 Micro: 0.974, F1 Macro: 0.9725\n",
      "Epoch 8/10, Train Loss: 0.0915, Accuracy: 0.9561, F1 Micro: 0.9725, F1 Macro: 0.9705\n",
      "Epoch 9/10, Train Loss: 0.0781, Accuracy: 0.9516, F1 Micro: 0.9695, F1 Macro: 0.9667\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0693, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9735\n",
      "\n",
      "Aspect detection accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9735\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.94      0.99      0.96       175\n",
      "      others       0.92      0.94      0.93       158\n",
      "        part       0.97      0.98      0.97       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.97      1061\n",
      "   macro avg       0.96      0.99      0.97      1061\n",
      "weighted avg       0.96      0.99      0.97      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5313, Accuracy: 0.8153, F1 Micro: 0.8153, F1 Macro: 0.7415\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2501, Accuracy: 0.9357, F1 Micro: 0.9357, F1 Macro: 0.9277\n",
      "Epoch 3/10, Train Loss: 0.1174, Accuracy: 0.9237, F1 Micro: 0.9237, F1 Macro: 0.9097\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1446, Accuracy: 0.9357, F1 Micro: 0.9357, F1 Macro: 0.9237\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1317, Accuracy: 0.9518, F1 Micro: 0.9518, F1 Macro: 0.9455\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1252, Accuracy: 0.9558, F1 Micro: 0.9558, F1 Macro: 0.9498\n",
      "Epoch 7/10, Train Loss: 0.0771, Accuracy: 0.9357, F1 Micro: 0.9357, F1 Macro: 0.9289\n",
      "Epoch 8/10, Train Loss: 0.092, Accuracy: 0.9357, F1 Micro: 0.9357, F1 Macro: 0.9258\n",
      "Epoch 9/10, Train Loss: 0.0778, Accuracy: 0.9237, F1 Micro: 0.9237, F1 Macro: 0.9076\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.076, Accuracy: 0.9558, F1 Micro: 0.9558, F1 Macro: 0.9502\n",
      "\n",
      "Sentiment analysis accuracy: 0.9558, F1 Micro: 0.9558, F1 Macro: 0.9502\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.93        79\n",
      "    positive       0.99      0.95      0.97       170\n",
      "\n",
      "    accuracy                           0.96       249\n",
      "   macro avg       0.94      0.96      0.95       249\n",
      "weighted avg       0.96      0.96      0.96       249\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 517: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9076\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.93      0.99      0.96       167\n",
      "    positive       0.96      0.73      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.94      0.82      0.87       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.92      0.93      0.93       152\n",
      "    positive       0.80      0.77      0.78        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.82      0.82      0.82       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.98      0.97       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.97      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.84      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.96      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 108.82572650909424 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.008656907081604008\n",
      "Samples above threshold: 35\n",
      "Acquired samples: 23\n",
      "Sampling duration: 7.952547073364258 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5542, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4709, Accuracy: 0.8311, F1 Micro: 0.9032, F1 Macro: 0.9023\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3507, Accuracy: 0.9263, F1 Micro: 0.955, F1 Macro: 0.9538\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.258, Accuracy: 0.9449, F1 Micro: 0.966, F1 Macro: 0.9645\n",
      "Epoch 5/10, Train Loss: 0.1923, Accuracy: 0.9427, F1 Micro: 0.9645, F1 Macro: 0.9624\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1399, Accuracy: 0.9583, F1 Micro: 0.9741, F1 Macro: 0.9729\n",
      "Epoch 7/10, Train Loss: 0.1103, Accuracy: 0.9568, F1 Micro: 0.9731, F1 Macro: 0.9715\n",
      "Epoch 8/10, Train Loss: 0.0887, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9714\n",
      "Epoch 9/10, Train Loss: 0.0814, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9719\n",
      "Epoch 10/10, Train Loss: 0.0723, Accuracy: 0.9561, F1 Micro: 0.9724, F1 Macro: 0.9703\n",
      "\n",
      "Aspect detection accuracy: 0.9583, F1 Micro: 0.9741, F1 Macro: 0.9729\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.93      1.00      0.96       175\n",
      "      others       0.89      0.98      0.93       158\n",
      "        part       0.96      0.97      0.97       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.97      1061\n",
      "   macro avg       0.96      0.99      0.97      1061\n",
      "weighted avg       0.96      0.99      0.97      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.503, Accuracy: 0.8383, F1 Micro: 0.8383, F1 Macro: 0.7897\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2252, Accuracy: 0.9106, F1 Micro: 0.9106, F1 Macro: 0.904\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1497, Accuracy: 0.9489, F1 Micro: 0.9489, F1 Macro: 0.9431\n",
      "Epoch 4/10, Train Loss: 0.08, Accuracy: 0.9447, F1 Micro: 0.9447, F1 Macro: 0.9366\n",
      "Epoch 5/10, Train Loss: 0.1046, Accuracy: 0.9277, F1 Micro: 0.9277, F1 Macro: 0.9159\n",
      "Epoch 6/10, Train Loss: 0.0516, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9112\n",
      "Epoch 7/10, Train Loss: 0.0735, Accuracy: 0.9319, F1 Micro: 0.9319, F1 Macro: 0.9259\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0397, Accuracy: 0.9532, F1 Micro: 0.9532, F1 Macro: 0.9474\n",
      "Epoch 9/10, Train Loss: 0.0594, Accuracy: 0.9489, F1 Micro: 0.9489, F1 Macro: 0.9424\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0474, Accuracy: 0.9532, F1 Micro: 0.9532, F1 Macro: 0.9477\n",
      "\n",
      "Sentiment analysis accuracy: 0.9532, F1 Micro: 0.9532, F1 Macro: 0.9477\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.96      0.93        77\n",
      "    positive       0.98      0.95      0.96       158\n",
      "\n",
      "    accuracy                           0.95       235\n",
      "   macro avg       0.94      0.96      0.95       235\n",
      "weighted avg       0.95      0.95      0.95       235\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9429, F1 Micro: 0.9429, F1 Macro: 0.8806\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       1.00      0.96      0.98        24\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.99      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.69      0.69        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.96      0.70      0.81        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.86      0.79      0.82       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.33      0.83      0.48        12\n",
      "     neutral       0.94      0.90      0.92       152\n",
      "    positive       0.93      0.71      0.80        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.73      0.82      0.73       216\n",
      "weighted avg       0.90      0.85      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.97      0.96      0.96       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.92      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.97      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.84      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.93      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 103.83057141304016 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.016193974018096923\n",
      "Samples above threshold: 33\n",
      "Acquired samples: 33\n",
      "Sampling duration: 7.117747068405151 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5476, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4575, Accuracy: 0.8646, F1 Micro: 0.9206, F1 Macro: 0.9193\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3309, Accuracy: 0.936, F1 Micro: 0.9607, F1 Macro: 0.9597\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2313, Accuracy: 0.9487, F1 Micro: 0.9681, F1 Macro: 0.9665\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1781, Accuracy: 0.9531, F1 Micro: 0.9708, F1 Macro: 0.9695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1383, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9721\n",
      "Epoch 7/10, Train Loss: 0.1025, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0931, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9734\n",
      "Epoch 9/10, Train Loss: 0.0753, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9734\n",
      "Epoch 10/10, Train Loss: 0.0696, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.973\n",
      "\n",
      "Aspect detection accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9734\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.94      0.99      0.96       175\n",
      "      others       0.92      0.94      0.93       158\n",
      "        part       0.97      0.98      0.97       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.99      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5102, Accuracy: 0.892, F1 Micro: 0.892, F1 Macro: 0.8699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2538, Accuracy: 0.932, F1 Micro: 0.932, F1 Macro: 0.924\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1921, Accuracy: 0.936, F1 Micro: 0.936, F1 Macro: 0.9291\n",
      "Epoch 4/10, Train Loss: 0.1471, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9085\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0885, Accuracy: 0.964, F1 Micro: 0.964, F1 Macro: 0.9582\n",
      "Epoch 6/10, Train Loss: 0.1016, Accuracy: 0.952, F1 Micro: 0.952, F1 Macro: 0.9449\n",
      "Epoch 7/10, Train Loss: 0.0777, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9129\n",
      "Epoch 8/10, Train Loss: 0.0769, Accuracy: 0.936, F1 Micro: 0.936, F1 Macro: 0.9244\n",
      "Epoch 9/10, Train Loss: 0.0646, Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9505\n",
      "Epoch 10/10, Train Loss: 0.0504, Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9496\n",
      "\n",
      "Sentiment analysis accuracy: 0.964, F1 Micro: 0.964, F1 Macro: 0.9582\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.94      0.94        79\n",
      "    positive       0.97      0.98      0.97       171\n",
      "\n",
      "    accuracy                           0.96       250\n",
      "   macro avg       0.96      0.96      0.96       250\n",
      "weighted avg       0.96      0.96      0.96       250\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.8936\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.91      0.87        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.85      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.58      0.58      0.58        12\n",
      "     neutral       0.92      0.91      0.92       152\n",
      "    positive       0.79      0.81      0.80        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.77      0.77      0.77       216\n",
      "weighted avg       0.87      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.87      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.93      0.90        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.94      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 111.69474649429321 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.011166930198669434\n",
      "Samples above threshold: 30\n",
      "Acquired samples: 30\n",
      "Sampling duration: 6.86612343788147 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5449, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4581, Accuracy: 0.8564, F1 Micro: 0.9161, F1 Macro: 0.9153\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3188, Accuracy: 0.9375, F1 Micro: 0.9614, F1 Macro: 0.9598\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2218, Accuracy: 0.9509, F1 Micro: 0.9694, F1 Macro: 0.9677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1638, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1308, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1084, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9744\n",
      "Epoch 8/10, Train Loss: 0.0841, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9738\n",
      "Epoch 9/10, Train Loss: 0.0706, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0598, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9748\n",
      "\n",
      "Aspect detection accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9748\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.94      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.97      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4805, Accuracy: 0.8805, F1 Micro: 0.8805, F1 Macro: 0.865\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2574, Accuracy: 0.9044, F1 Micro: 0.9044, F1 Macro: 0.8811\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1529, Accuracy: 0.9243, F1 Micro: 0.9243, F1 Macro: 0.9157\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.143, Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9453\n",
      "Epoch 5/10, Train Loss: 0.1073, Accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9374\n",
      "Epoch 6/10, Train Loss: 0.1353, Accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9374\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1071, Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9457\n",
      "Epoch 8/10, Train Loss: 0.0911, Accuracy: 0.9402, F1 Micro: 0.9402, F1 Macro: 0.9331\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0766, Accuracy: 0.9602, F1 Micro: 0.9602, F1 Macro: 0.9547\n",
      "Epoch 10/10, Train Loss: 0.068, Accuracy: 0.9482, F1 Micro: 0.9482, F1 Macro: 0.9393\n",
      "\n",
      "Sentiment analysis accuracy: 0.9602, F1 Micro: 0.9602, F1 Macro: 0.9547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94        79\n",
      "    positive       0.99      0.95      0.97       172\n",
      "\n",
      "    accuracy                           0.96       251\n",
      "   macro avg       0.95      0.96      0.95       251\n",
      "weighted avg       0.96      0.96      0.96       251\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9025\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.69      0.79        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.82      0.86       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.58      0.74        12\n",
      "     neutral       0.92      0.94      0.93       152\n",
      "    positive       0.80      0.83      0.81        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.91      0.78      0.83       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.91      0.89        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.92      0.83      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.91      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.97      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.84      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 119.46022963523865 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.00834357738494873\n",
      "Samples above threshold: 27\n",
      "Acquired samples: 27\n",
      "Sampling duration: 6.338818073272705 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5485, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4414, Accuracy: 0.8996, F1 Micro: 0.9395, F1 Macro: 0.9388\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3008, Accuracy: 0.942, F1 Micro: 0.9643, F1 Macro: 0.9624\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2113, Accuracy: 0.9568, F1 Micro: 0.9731, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1522, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9739\n",
      "Epoch 6/10, Train Loss: 0.1213, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0989, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9794\n",
      "Epoch 8/10, Train Loss: 0.0822, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9725\n",
      "Epoch 9/10, Train Loss: 0.0619, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9759\n",
      "Epoch 10/10, Train Loss: 0.0579, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.975\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9794\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.99      0.98      0.98       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4795, Accuracy: 0.8906, F1 Micro: 0.8906, F1 Macro: 0.8669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2465, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9384\n",
      "Epoch 3/10, Train Loss: 0.1848, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.923\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1294, Accuracy: 0.9531, F1 Micro: 0.9531, F1 Macro: 0.9458\n",
      "Epoch 5/10, Train Loss: 0.1315, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9384\n",
      "Epoch 6/10, Train Loss: 0.0996, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9387\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0836, Accuracy: 0.9531, F1 Micro: 0.9531, F1 Macro: 0.9465\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0755, Accuracy: 0.9531, F1 Micro: 0.9531, F1 Macro: 0.9472\n",
      "Epoch 9/10, Train Loss: 0.0825, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9391\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0604, Accuracy: 0.957, F1 Micro: 0.957, F1 Macro: 0.9514\n",
      "\n",
      "Sentiment analysis accuracy: 0.957, F1 Micro: 0.957, F1 Macro: 0.9514\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.93        82\n",
      "    positive       0.98      0.95      0.97       174\n",
      "\n",
      "    accuracy                           0.96       256\n",
      "   macro avg       0.95      0.96      0.95       256\n",
      "weighted avg       0.96      0.96      0.96       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.917\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.88      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.75      0.69        12\n",
      "     neutral       0.93      0.94      0.93       152\n",
      "    positive       0.88      0.81      0.84        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.82      0.83      0.82       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.99      0.98      0.98       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.97      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.84      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 118.82222723960876 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.0112798810005188\n",
      "Samples above threshold: 24\n",
      "Acquired samples: 18\n",
      "Sampling duration: 5.681809186935425 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5515, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4315, Accuracy: 0.907, F1 Micro: 0.9432, F1 Macro: 0.9418\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2985, Accuracy: 0.939, F1 Micro: 0.9616, F1 Macro: 0.9595\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2111, Accuracy: 0.9583, F1 Micro: 0.9741, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1435, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9744\n",
      "Epoch 6/10, Train Loss: 0.1142, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9743\n",
      "Epoch 7/10, Train Loss: 0.0955, Accuracy: 0.9539, F1 Micro: 0.9709, F1 Macro: 0.9685\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0797, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9775\n",
      "Epoch 9/10, Train Loss: 0.0668, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9771\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0555, Accuracy: 0.968, F1 Micro: 0.98, F1 Macro: 0.9789\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.98, F1 Macro: 0.9789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.92      0.97      0.95       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5122, Accuracy: 0.873, F1 Micro: 0.873, F1 Macro: 0.8389\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2675, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9206\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1836, Accuracy: 0.9563, F1 Micro: 0.9563, F1 Macro: 0.9501\n",
      "Epoch 4/10, Train Loss: 0.1464, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.8887\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1465, Accuracy: 0.9563, F1 Micro: 0.9563, F1 Macro: 0.9507\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1318, Accuracy: 0.9603, F1 Micro: 0.9603, F1 Macro: 0.9556\n",
      "Epoch 7/10, Train Loss: 0.0984, Accuracy: 0.9246, F1 Micro: 0.9246, F1 Macro: 0.9115\n",
      "Epoch 8/10, Train Loss: 0.0891, Accuracy: 0.9365, F1 Micro: 0.9365, F1 Macro: 0.9281\n",
      "Epoch 9/10, Train Loss: 0.0641, Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9386\n",
      "Epoch 10/10, Train Loss: 0.0895, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9252\n",
      "\n",
      "Sentiment analysis accuracy: 0.9603, F1 Micro: 0.9603, F1 Macro: 0.9556\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94        82\n",
      "    positive       0.99      0.95      0.97       170\n",
      "\n",
      "    accuracy                           0.96       252\n",
      "   macro avg       0.95      0.96      0.96       252\n",
      "weighted avg       0.96      0.96      0.96       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9062\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.97      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.84      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.58      0.64        12\n",
      "     neutral       0.93      0.97      0.95       152\n",
      "    positive       0.87      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.83      0.78      0.80       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.87      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 123.68390917778015 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.006698787212371826\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.409958124160767 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5424, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4202, Accuracy: 0.9137, F1 Micro: 0.9477, F1 Macro: 0.9466\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2811, Accuracy: 0.9487, F1 Micro: 0.9682, F1 Macro: 0.9666\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.184, Accuracy: 0.9554, F1 Micro: 0.972, F1 Macro: 0.9703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1388, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1117, Accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9785\n",
      "Epoch 7/10, Train Loss: 0.0902, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9734\n",
      "Epoch 8/10, Train Loss: 0.0767, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9775\n",
      "Epoch 9/10, Train Loss: 0.0609, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.976\n",
      "Epoch 10/10, Train Loss: 0.0553, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9766\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9785\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      1.00      0.97       175\n",
      "      others       0.92      0.96      0.93       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4829, Accuracy: 0.9187, F1 Micro: 0.9187, F1 Macro: 0.9074\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2536, Accuracy: 0.939, F1 Micro: 0.939, F1 Macro: 0.9328\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1913, Accuracy: 0.9593, F1 Micro: 0.9593, F1 Macro: 0.9545\n",
      "Epoch 4/10, Train Loss: 0.1136, Accuracy: 0.9431, F1 Micro: 0.9431, F1 Macro: 0.9343\n",
      "Epoch 5/10, Train Loss: 0.119, Accuracy: 0.9512, F1 Micro: 0.9512, F1 Macro: 0.9458\n",
      "Epoch 6/10, Train Loss: 0.101, Accuracy: 0.9431, F1 Micro: 0.9431, F1 Macro: 0.9356\n",
      "Epoch 7/10, Train Loss: 0.067, Accuracy: 0.9268, F1 Micro: 0.9268, F1 Macro: 0.9161\n",
      "Epoch 8/10, Train Loss: 0.0792, Accuracy: 0.9553, F1 Micro: 0.9553, F1 Macro: 0.9498\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0709, Accuracy: 0.9634, F1 Micro: 0.9634, F1 Macro: 0.9592\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.054, Accuracy: 0.9634, F1 Micro: 0.9634, F1 Macro: 0.9592\n",
      "\n",
      "Sentiment analysis accuracy: 0.9634, F1 Micro: 0.9634, F1 Macro: 0.9592\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95        81\n",
      "    positive       0.99      0.96      0.97       165\n",
      "\n",
      "    accuracy                           0.96       246\n",
      "   macro avg       0.95      0.97      0.96       246\n",
      "weighted avg       0.96      0.96      0.96       246\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9014\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.97      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.88      0.78        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.96      0.76      0.85        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.87      0.87       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.83      0.62        12\n",
      "     neutral       0.93      0.92      0.93       152\n",
      "    positive       0.87      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.77      0.84      0.79       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       1.00      0.88      0.94        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.95      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 124.02502250671387 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.011576533317565918\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.76542854309082 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5486, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4445, Accuracy: 0.9077, F1 Micro: 0.944, F1 Macro: 0.9423\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2901, Accuracy: 0.9487, F1 Micro: 0.9681, F1 Macro: 0.9665\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1943, Accuracy: 0.9531, F1 Micro: 0.9706, F1 Macro: 0.9688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1435, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9727\n",
      "Epoch 6/10, Train Loss: 0.1157, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0914, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0722, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9762\n",
      "Epoch 9/10, Train Loss: 0.0625, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9738\n",
      "Epoch 10/10, Train Loss: 0.0554, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9727\n",
      "\n",
      "Aspect detection accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.92      0.93      0.93       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4777, Accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.9068\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2922, Accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9384\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.176, Accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.9434\n",
      "Epoch 4/10, Train Loss: 0.1565, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9313\n",
      "Epoch 5/10, Train Loss: 0.1407, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9191\n",
      "Epoch 6/10, Train Loss: 0.1131, Accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9392\n",
      "Epoch 7/10, Train Loss: 0.0931, Accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9381\n",
      "Epoch 8/10, Train Loss: 0.0947, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9213\n",
      "Epoch 9/10, Train Loss: 0.0681, Accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9372\n",
      "Epoch 10/10, Train Loss: 0.0613, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9204\n",
      "\n",
      "Sentiment analysis accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.9434\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.96      0.92        82\n",
      "    positive       0.98      0.94      0.96       178\n",
      "\n",
      "    accuracy                           0.95       260\n",
      "   macro avg       0.94      0.95      0.94       260\n",
      "weighted avg       0.95      0.95      0.95       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9475, F1 Micro: 0.9475, F1 Macro: 0.889\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.73      0.80        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.92      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.88      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.42      0.67      0.52        12\n",
      "     neutral       0.92      0.89      0.91       152\n",
      "    positive       0.80      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.72      0.78      0.74       216\n",
      "weighted avg       0.87      0.85      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.92      0.85      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.93      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.89      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 125.14044499397278 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.007556021213531494\n",
      "Samples above threshold: 17\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.3835976123809814 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.544, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4203, Accuracy: 0.9278, F1 Micro: 0.9556, F1 Macro: 0.954\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.264, Accuracy: 0.9479, F1 Micro: 0.9677, F1 Macro: 0.9661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1877, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1253, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.976\n",
      "Epoch 6/10, Train Loss: 0.1006, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.975\n",
      "Epoch 7/10, Train Loss: 0.0811, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9754\n",
      "Epoch 8/10, Train Loss: 0.0703, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9752\n",
      "Epoch 9/10, Train Loss: 0.057, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9739\n",
      "Epoch 10/10, Train Loss: 0.0506, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9734\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.94      0.93       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5203, Accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.9023\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2281, Accuracy: 0.9357, F1 Micro: 0.9357, F1 Macro: 0.9253\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1895, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9364\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.115, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9367\n",
      "Epoch 5/10, Train Loss: 0.1096, Accuracy: 0.9197, F1 Micro: 0.9197, F1 Macro: 0.9121\n",
      "Epoch 6/10, Train Loss: 0.0763, Accuracy: 0.9357, F1 Micro: 0.9357, F1 Macro: 0.9281\n",
      "Epoch 7/10, Train Loss: 0.1047, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9307\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0646, Accuracy: 0.9478, F1 Micro: 0.9478, F1 Macro: 0.9403\n",
      "Epoch 9/10, Train Loss: 0.0798, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9371\n",
      "Epoch 10/10, Train Loss: 0.061, Accuracy: 0.9197, F1 Micro: 0.9197, F1 Macro: 0.9121\n",
      "\n",
      "Sentiment analysis accuracy: 0.9478, F1 Micro: 0.9478, F1 Macro: 0.9403\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        79\n",
      "    positive       0.97      0.95      0.96       170\n",
      "\n",
      "    accuracy                           0.95       249\n",
      "   macro avg       0.94      0.94      0.94       249\n",
      "weighted avg       0.95      0.95      0.95       249\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.8722\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       1.00      0.88      0.93        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.96      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.88      0.80        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.96      0.70      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.85      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.41      0.75      0.53        12\n",
      "     neutral       0.93      0.89      0.91       152\n",
      "    positive       0.83      0.75      0.79        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.72      0.80      0.74       216\n",
      "weighted avg       0.87      0.85      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      1.00      0.82        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       1.00      0.78      0.88        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.92      0.89       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        13\n",
      "     neutral       0.97      1.00      0.99       186\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.91      0.83      0.86       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.93      0.90        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.94      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 125.6772346496582 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.01195383071899414\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.054647922515869 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5342, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4099, Accuracy: 0.9263, F1 Micro: 0.9548, F1 Macro: 0.9532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2601, Accuracy: 0.9509, F1 Micro: 0.9694, F1 Macro: 0.9676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1722, Accuracy: 0.9606, F1 Micro: 0.9754, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1344, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1092, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9768\n",
      "Epoch 7/10, Train Loss: 0.0855, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9748\n",
      "Epoch 8/10, Train Loss: 0.0672, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9766\n",
      "Epoch 9/10, Train Loss: 0.0581, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0474, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9781\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.94      0.94      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5047, Accuracy: 0.9015, F1 Micro: 0.9015, F1 Macro: 0.8916\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2326, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9206\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1496, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9306\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.17, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9306\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.112, Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9479\n",
      "Epoch 6/10, Train Loss: 0.1125, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9302\n",
      "Epoch 7/10, Train Loss: 0.0847, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9314\n",
      "Epoch 8/10, Train Loss: 0.0702, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9322\n",
      "Epoch 9/10, Train Loss: 0.0593, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9197\n",
      "Epoch 10/10, Train Loss: 0.0739, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9219\n",
      "\n",
      "Sentiment analysis accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9479\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.94      0.93        84\n",
      "    positive       0.97      0.96      0.97       180\n",
      "\n",
      "    accuracy                           0.95       264\n",
      "   macro avg       0.95      0.95      0.95       264\n",
      "weighted avg       0.95      0.95      0.95       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9065\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.82      0.86        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.92      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.85      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.94      0.94      0.94       152\n",
      "    positive       0.81      0.81      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.83      0.83      0.83       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.92      0.83      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.90      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 132.18025708198547 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.005193084478378296\n",
      "Samples above threshold: 12\n",
      "Acquired samples: 8\n",
      "Sampling duration: 3.5231270790100098 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5459, Accuracy: 0.7939, F1 Micro: 0.8845, F1 Macro: 0.8831\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.413, Accuracy: 0.9271, F1 Micro: 0.955, F1 Macro: 0.9532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2625, Accuracy: 0.9516, F1 Micro: 0.9699, F1 Macro: 0.9687\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1769, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1288, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1061, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0897, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.977\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.068, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9775\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0554, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9788\n",
      "Epoch 10/10, Train Loss: 0.0513, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.974\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9788\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.94      0.94      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4838, Accuracy: 0.8923, F1 Micro: 0.8923, F1 Macro: 0.8828\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2649, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9235\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1918, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9213\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1163, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9343\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1201, Accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9388\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1277, Accuracy: 0.9615, F1 Micro: 0.9615, F1 Macro: 0.9563\n",
      "Epoch 7/10, Train Loss: 0.097, Accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.911\n",
      "Epoch 8/10, Train Loss: 0.0773, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9146\n",
      "Epoch 9/10, Train Loss: 0.0719, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9272\n",
      "Epoch 10/10, Train Loss: 0.0636, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9309\n",
      "\n",
      "Sentiment analysis accuracy: 0.9615, F1 Micro: 0.9615, F1 Macro: 0.9563\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.96      0.94        83\n",
      "    positive       0.98      0.96      0.97       177\n",
      "\n",
      "    accuracy                           0.96       260\n",
      "   macro avg       0.95      0.96      0.96       260\n",
      "weighted avg       0.96      0.96      0.96       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.8987\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.87      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.48      0.83      0.61        12\n",
      "     neutral       0.95      0.90      0.93       152\n",
      "    positive       0.82      0.81      0.82        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.75      0.85      0.78       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.93      0.91       216\n",
      "weighted avg       0.95      0.94      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 137.9789936542511 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.006050980091094971\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.3504791259765625 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5315, Accuracy: 0.8021, F1 Micro: 0.8886, F1 Macro: 0.8873\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.407, Accuracy: 0.9308, F1 Micro: 0.9571, F1 Macro: 0.9548\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2564, Accuracy: 0.9487, F1 Micro: 0.9681, F1 Macro: 0.9662\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1739, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1317, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0983, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9771\n",
      "Epoch 7/10, Train Loss: 0.0823, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9755\n",
      "Epoch 8/10, Train Loss: 0.0673, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0552, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9776\n",
      "Epoch 10/10, Train Loss: 0.0473, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9769\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9776\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.94      0.94      0.94       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4446, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.9003\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2789, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9201\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1693, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9394\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1063, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9401\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1278, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9391\n",
      "Epoch 6/10, Train Loss: 0.1072, Accuracy: 0.8919, F1 Micro: 0.8919, F1 Macro: 0.8846\n",
      "Epoch 7/10, Train Loss: 0.1094, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9319\n",
      "Epoch 8/10, Train Loss: 0.0674, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9278\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.057, Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9436\n",
      "Epoch 10/10, Train Loss: 0.0448, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9277\n",
      "\n",
      "Sentiment analysis accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9436\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.94      0.92        85\n",
      "    positive       0.97      0.95      0.96       174\n",
      "\n",
      "    accuracy                           0.95       259\n",
      "   macro avg       0.94      0.95      0.94       259\n",
      "weighted avg       0.95      0.95      0.95       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.8938\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.73      0.76        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.88      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.69      0.73        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.81      0.76      0.78        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.85      0.81      0.83       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.94      0.93      0.93       152\n",
      "    positive       0.81      0.85      0.83        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.86      0.87      0.87       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.87      0.85        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       0.88      0.88      0.88        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.90      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 137.91810011863708 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0050700783729553224\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.848871946334839 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5297, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3934, Accuracy: 0.9278, F1 Micro: 0.9553, F1 Macro: 0.9532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2495, Accuracy: 0.9583, F1 Micro: 0.974, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.165, Accuracy: 0.9665, F1 Micro: 0.9791, F1 Macro: 0.9781\n",
      "Epoch 5/10, Train Loss: 0.125, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1019, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9781\n",
      "Epoch 7/10, Train Loss: 0.0812, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9756\n",
      "Epoch 8/10, Train Loss: 0.0697, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9779\n",
      "Epoch 9/10, Train Loss: 0.0548, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9779\n",
      "Epoch 10/10, Train Loss: 0.0493, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9778\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.95      0.93      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.461, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9275\n",
      "Epoch 2/10, Train Loss: 0.2737, Accuracy: 0.9237, F1 Micro: 0.9237, F1 Macro: 0.9106\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1564, Accuracy: 0.9427, F1 Micro: 0.9427, F1 Macro: 0.9353\n",
      "Epoch 4/10, Train Loss: 0.1417, Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.9242\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1216, Accuracy: 0.9542, F1 Micro: 0.9542, F1 Macro: 0.9481\n",
      "Epoch 6/10, Train Loss: 0.0975, Accuracy: 0.9427, F1 Micro: 0.9427, F1 Macro: 0.9353\n",
      "Epoch 7/10, Train Loss: 0.0976, Accuracy: 0.9466, F1 Micro: 0.9466, F1 Macro: 0.9383\n",
      "Epoch 8/10, Train Loss: 0.0648, Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.9242\n",
      "Epoch 9/10, Train Loss: 0.0553, Accuracy: 0.9427, F1 Micro: 0.9427, F1 Macro: 0.936\n",
      "Epoch 10/10, Train Loss: 0.0462, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.9323\n",
      "\n",
      "Sentiment analysis accuracy: 0.9542, F1 Micro: 0.9542, F1 Macro: 0.9481\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.94      0.93        85\n",
      "    positive       0.97      0.96      0.97       177\n",
      "\n",
      "    accuracy                           0.95       262\n",
      "   macro avg       0.95      0.95      0.95       262\n",
      "weighted avg       0.95      0.95      0.95       262\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.8971\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.88      0.82        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.86      0.86       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.53      0.83      0.65        12\n",
      "     neutral       0.95      0.89      0.92       152\n",
      "    positive       0.80      0.83      0.81        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.76      0.85      0.79       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.92      0.77        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.86      0.87      0.86       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 134.6866955757141 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.007657581567764283\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.403681516647339 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5364, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3951, Accuracy: 0.9241, F1 Micro: 0.9535, F1 Macro: 0.9519\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2477, Accuracy: 0.9501, F1 Micro: 0.969, F1 Macro: 0.9672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1728, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9781\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1178, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9788\n",
      "Epoch 6/10, Train Loss: 0.1038, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "Epoch 7/10, Train Loss: 0.0792, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0642, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9798\n",
      "Epoch 9/10, Train Loss: 0.0555, Accuracy: 0.965, F1 Micro: 0.9778, F1 Macro: 0.9761\n",
      "Epoch 10/10, Train Loss: 0.0495, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9776\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.94      0.96      0.95       158\n",
      "        part       0.96      1.00      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4795, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9136\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2066, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9272\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1483, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9364\n",
      "Epoch 4/10, Train Loss: 0.151, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.9039\n",
      "Epoch 5/10, Train Loss: 0.1568, Accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.9127\n",
      "Epoch 6/10, Train Loss: 0.1089, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9287\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1028, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.935\n",
      "Epoch 8/10, Train Loss: 0.0746, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9218\n",
      "Epoch 9/10, Train Loss: 0.0895, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9207\n",
      "Epoch 10/10, Train Loss: 0.0668, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9231\n",
      "\n",
      "Sentiment analysis accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.935\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.91      0.91        87\n",
      "    positive       0.95      0.96      0.96       173\n",
      "\n",
      "    accuracy                           0.94       260\n",
      "   macro avg       0.94      0.93      0.94       260\n",
      "weighted avg       0.94      0.94      0.94       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.9\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.75      0.71        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.83      0.73      0.77        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.82      0.82      0.82       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.83      0.62        12\n",
      "     neutral       0.95      0.91      0.93       152\n",
      "    positive       0.86      0.81      0.83        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.77      0.85      0.80       216\n",
      "weighted avg       0.90      0.88      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.96      0.85        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.76      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.90      0.89       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.89      0.94      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.95      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 138.5301477909088 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0046703100204467775\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.869417667388916 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5324, Accuracy: 0.7976, F1 Micro: 0.8864, F1 Macro: 0.885\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3829, Accuracy: 0.9301, F1 Micro: 0.9569, F1 Macro: 0.9551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.237, Accuracy: 0.9576, F1 Micro: 0.9737, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.157, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9759\n",
      "Epoch 5/10, Train Loss: 0.1208, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9753\n",
      "Epoch 6/10, Train Loss: 0.0974, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0727, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9769\n",
      "Epoch 8/10, Train Loss: 0.0614, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9739\n",
      "Epoch 9/10, Train Loss: 0.055, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.046, Accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9796\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9796\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.94      0.94      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4496, Accuracy: 0.9222, F1 Micro: 0.9222, F1 Macro: 0.9141\n",
      "Epoch 2/10, Train Loss: 0.2253, Accuracy: 0.9148, F1 Micro: 0.9148, F1 Macro: 0.9073\n",
      "Epoch 3/10, Train Loss: 0.169, Accuracy: 0.9185, F1 Micro: 0.9185, F1 Macro: 0.9111\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1466, Accuracy: 0.9222, F1 Micro: 0.9222, F1 Macro: 0.9145\n",
      "Epoch 5/10, Train Loss: 0.1127, Accuracy: 0.9185, F1 Micro: 0.9185, F1 Macro: 0.9107\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0937, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9241\n",
      "Epoch 7/10, Train Loss: 0.0818, Accuracy: 0.9185, F1 Micro: 0.9185, F1 Macro: 0.9102\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.069, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9294\n",
      "Epoch 9/10, Train Loss: 0.0736, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9254\n",
      "Epoch 10/10, Train Loss: 0.064, Accuracy: 0.9, F1 Micro: 0.9, F1 Macro: 0.8916\n",
      "\n",
      "Sentiment analysis accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9294\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.94      0.91        87\n",
      "    positive       0.97      0.93      0.95       183\n",
      "\n",
      "    accuracy                           0.94       270\n",
      "   macro avg       0.92      0.94      0.93       270\n",
      "weighted avg       0.94      0.94      0.94       270\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.8967\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.88      0.82        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.87      0.87      0.87       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.94      0.94      0.94       152\n",
      "    positive       0.80      0.77      0.78        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.82      0.85      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      1.00      0.84        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       1.00      0.76      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.91      0.89       216\n",
      "weighted avg       0.96      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.92      0.83        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.87      0.89      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 140.92695689201355 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0030053138732910154\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 8\n",
      "Sampling duration: 1.3163492679595947 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5217, Accuracy: 0.8043, F1 Micro: 0.8897, F1 Macro: 0.8885\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3961, Accuracy: 0.9368, F1 Micro: 0.961, F1 Macro: 0.9593\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2421, Accuracy: 0.9531, F1 Micro: 0.9709, F1 Macro: 0.9694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1609, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1212, Accuracy: 0.968, F1 Micro: 0.98, F1 Macro: 0.979\n",
      "Epoch 6/10, Train Loss: 0.0917, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9785\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0724, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9798\n",
      "Epoch 8/10, Train Loss: 0.0596, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9795\n",
      "Epoch 9/10, Train Loss: 0.0506, Accuracy: 0.9643, F1 Micro: 0.9773, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0458, Accuracy: 0.971, F1 Micro: 0.9817, F1 Macro: 0.9803\n",
      "\n",
      "Aspect detection accuracy: 0.971, F1 Micro: 0.9817, F1 Macro: 0.9803\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.94      0.92      0.93       158\n",
      "        part       0.98      1.00      0.99       158\n",
      "       price       0.99      1.00      1.00       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4399, Accuracy: 0.9037, F1 Micro: 0.9037, F1 Macro: 0.8954\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2177, Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.938\n",
      "Epoch 3/10, Train Loss: 0.1754, Accuracy: 0.9148, F1 Micro: 0.9148, F1 Macro: 0.9073\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1538, Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9377\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1292, Accuracy: 0.9519, F1 Micro: 0.9519, F1 Macro: 0.946\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1177, Accuracy: 0.9519, F1 Micro: 0.9519, F1 Macro: 0.946\n",
      "Epoch 7/10, Train Loss: 0.0815, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.933\n",
      "Epoch 8/10, Train Loss: 0.0883, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9277\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0676, Accuracy: 0.9593, F1 Micro: 0.9593, F1 Macro: 0.9538\n",
      "Epoch 10/10, Train Loss: 0.0541, Accuracy: 0.9556, F1 Micro: 0.9556, F1 Macro: 0.95\n",
      "\n",
      "Sentiment analysis accuracy: 0.9593, F1 Micro: 0.9593, F1 Macro: 0.9538\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.95      0.94        87\n",
      "    positive       0.98      0.96      0.97       183\n",
      "\n",
      "    accuracy                           0.96       270\n",
      "   macro avg       0.95      0.96      0.95       270\n",
      "weighted avg       0.96      0.96      0.96       270\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.963, F1 Micro: 0.963, F1 Macro: 0.9356\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.89      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.95      0.92      0.93       152\n",
      "    positive       0.77      0.85      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.88      0.87      0.87       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      1.00      0.99       152\n",
      "    positive       1.00      0.80      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      1.00       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.94      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 144.88352060317993 s\n",
      "Total runtime: 3031.958985567093 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[0], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36969746",
   "metadata": {
    "papermill": {
     "duration": 0.011669,
     "end_time": "2025-03-23T08:37:40.434263",
     "exception": false,
     "start_time": "2025-03-23T08:37:40.422594",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d69f8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 2\n",
      "Random seed: 81\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.647, Accuracy: 0.7054, F1 Micro: 0.8127, F1 Macro: 0.7262\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5731, Accuracy: 0.7374, F1 Micro: 0.8408, F1 Macro: 0.7949\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5493, Accuracy: 0.7917, F1 Micro: 0.8824, F1 Macro: 0.8802\n",
      "Epoch 4/10, Train Loss: 0.5049, Accuracy: 0.7894, F1 Micro: 0.8822, F1 Macro: 0.8807\n",
      "Epoch 5/10, Train Loss: 0.4781, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 6/10, Train Loss: 0.4364, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4061, Accuracy: 0.7902, F1 Micro: 0.8826, F1 Macro: 0.8811\n",
      "Epoch 8/10, Train Loss: 0.4421, Accuracy: 0.7902, F1 Micro: 0.8825, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.4208, Accuracy: 0.7939, F1 Micro: 0.8842, F1 Macro: 0.8826\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3864, Accuracy: 0.8036, F1 Micro: 0.8886, F1 Macro: 0.8869\n",
      "\n",
      "Aspect detection accuracy: 0.8036, F1 Micro: 0.8886, F1 Macro: 0.8869\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.79      1.00      0.88       175\n",
      "      others       0.78      0.95      0.86       158\n",
      "        part       0.71      1.00      0.83       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.80      0.99      0.89      1061\n",
      "   macro avg       0.80      0.99      0.89      1061\n",
      "weighted avg       0.81      0.99      0.89      1061\n",
      " samples avg       0.81      0.99      0.89      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6351, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5577, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5004, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4905, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4593, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4341, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4188, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2323, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2613, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2353, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "\n",
      "Sentiment analysis accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         3\n",
      "    positive       0.91      1.00      0.95        31\n",
      "\n",
      "    accuracy                           0.91        34\n",
      "   macro avg       0.46      0.50      0.48        34\n",
      "weighted avg       0.83      0.91      0.87        34\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.8009, F1 Micro: 0.8009, F1 Macro: 0.3313\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.78      1.00      0.88       167\n",
      "    positive       1.00      0.06      0.11        33\n",
      "\n",
      "    accuracy                           0.78       216\n",
      "   macro avg       0.59      0.35      0.33       216\n",
      "weighted avg       0.76      0.78      0.70       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.78      0.95      0.85       152\n",
      "    positive       0.65      0.38      0.48        52\n",
      "\n",
      "    accuracy                           0.76       216\n",
      "   macro avg       0.47      0.44      0.45       216\n",
      "weighted avg       0.70      0.76      0.72       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        23\n",
      "     neutral       0.71      1.00      0.83       152\n",
      "    positive       1.00      0.02      0.05        41\n",
      "\n",
      "    accuracy                           0.71       216\n",
      "   macro avg       0.57      0.34      0.29       216\n",
      "weighted avg       0.69      0.71      0.59       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 61.01998281478882 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.05877414345741273\n",
      "Samples above threshold: 81\n",
      "Acquired samples: 81\n",
      "Sampling duration: 12.091628789901733 seconds\n",
      "New train size: 135\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6029, Accuracy: 0.7879, F1 Micro: 0.8776, F1 Macro: 0.8726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5146, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4672, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4408, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3966, Accuracy: 0.8043, F1 Micro: 0.8894, F1 Macro: 0.8879\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.352, Accuracy: 0.8385, F1 Micro: 0.9069, F1 Macro: 0.9059\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3211, Accuracy: 0.8601, F1 Micro: 0.9177, F1 Macro: 0.9167\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2875, Accuracy: 0.878, F1 Micro: 0.9269, F1 Macro: 0.9248\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2344, Accuracy: 0.8906, F1 Micro: 0.9336, F1 Macro: 0.9312\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2035, Accuracy: 0.9115, F1 Micro: 0.9459, F1 Macro: 0.9439\n",
      "\n",
      "Aspect detection accuracy: 0.9115, F1 Micro: 0.9459, F1 Macro: 0.9439\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.90      1.00      0.95       187\n",
      "     machine       0.90      0.99      0.94       175\n",
      "      others       0.89      0.91      0.90       158\n",
      "        part       0.88      0.97      0.92       158\n",
      "       price       0.93      1.00      0.96       192\n",
      "     service       0.97      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.91      0.98      0.95      1061\n",
      "   macro avg       0.91      0.98      0.94      1061\n",
      "weighted avg       0.91      0.98      0.95      1061\n",
      " samples avg       0.92      0.98      0.94      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6244, Accuracy: 0.699, F1 Micro: 0.699, F1 Macro: 0.4114\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5385, Accuracy: 0.699, F1 Micro: 0.699, F1 Macro: 0.4114\n",
      "Epoch 3/10, Train Loss: 0.4988, Accuracy: 0.6939, F1 Micro: 0.6939, F1 Macro: 0.4096\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.408, Accuracy: 0.7959, F1 Micro: 0.7959, F1 Macro: 0.6916\n",
      "Epoch 5/10, Train Loss: 0.3849, Accuracy: 0.7857, F1 Micro: 0.7857, F1 Macro: 0.6639\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2682, Accuracy: 0.8265, F1 Micro: 0.8265, F1 Macro: 0.7827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1822, Accuracy: 0.8367, F1 Micro: 0.8367, F1 Macro: 0.788\n",
      "Epoch 8/10, Train Loss: 0.1358, Accuracy: 0.8214, F1 Micro: 0.8214, F1 Macro: 0.7666\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1305, Accuracy: 0.8673, F1 Micro: 0.8673, F1 Macro: 0.8492\n",
      "Epoch 10/10, Train Loss: 0.1622, Accuracy: 0.8622, F1 Micro: 0.8622, F1 Macro: 0.8401\n",
      "\n",
      "Sentiment analysis accuracy: 0.8673, F1 Micro: 0.8673, F1 Macro: 0.8492\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.86      0.80        59\n",
      "    positive       0.94      0.87      0.90       137\n",
      "\n",
      "    accuracy                           0.87       196\n",
      "   macro avg       0.84      0.87      0.85       196\n",
      "weighted avg       0.88      0.87      0.87       196\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 135: Accuracy: 0.8943, F1 Micro: 0.8943, F1 Macro: 0.7568\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.45      0.62        11\n",
      "     neutral       0.91      1.00      0.95       181\n",
      "    positive       0.91      0.42      0.57        24\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.94      0.62      0.72       216\n",
      "weighted avg       0.91      0.91      0.89       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.56      0.72        16\n",
      "     neutral       0.89      0.99      0.94       167\n",
      "    positive       0.86      0.55      0.67        33\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.92      0.70      0.78       216\n",
      "weighted avg       0.90      0.89      0.88       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.37      0.58      0.45        12\n",
      "     neutral       0.89      0.90      0.90       152\n",
      "    positive       0.79      0.65      0.72        52\n",
      "\n",
      "    accuracy                           0.82       216\n",
      "   macro avg       0.68      0.71      0.69       216\n",
      "weighted avg       0.84      0.82      0.83       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.39      0.51        23\n",
      "     neutral       0.87      0.97      0.92       152\n",
      "    positive       0.71      0.59      0.64        41\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.78      0.65      0.69       216\n",
      "weighted avg       0.83      0.84      0.82       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.54      0.67        13\n",
      "     neutral       0.93      1.00      0.96       186\n",
      "    positive       1.00      0.47      0.64        17\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.94      0.67      0.76       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.97      1.00      0.99       185\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.97      0.87      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 69.52164840698242 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.03680367469787598\n",
      "Samples above threshold: 73\n",
      "Acquired samples: 73\n",
      "Sampling duration: 13.117414474487305 seconds\n",
      "New train size: 208\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5953, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4935, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4678, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.429, Accuracy: 0.808, F1 Micro: 0.8915, F1 Macro: 0.8901\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3781, Accuracy: 0.8705, F1 Micro: 0.9231, F1 Macro: 0.9212\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3148, Accuracy: 0.8981, F1 Micro: 0.9372, F1 Macro: 0.9348\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.252, Accuracy: 0.9055, F1 Micro: 0.9418, F1 Macro: 0.9389\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2178, Accuracy: 0.9263, F1 Micro: 0.9541, F1 Macro: 0.9517\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1793, Accuracy: 0.9308, F1 Micro: 0.9569, F1 Macro: 0.9539\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1551, Accuracy: 0.9323, F1 Micro: 0.9578, F1 Macro: 0.9555\n",
      "\n",
      "Aspect detection accuracy: 0.9323, F1 Micro: 0.9578, F1 Macro: 0.9555\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      0.93      0.94       175\n",
      "      others       0.88      0.93      0.90       158\n",
      "        part       0.90      0.97      0.93       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.94      0.97      0.96      1061\n",
      "   macro avg       0.94      0.97      0.96      1061\n",
      "weighted avg       0.94      0.97      0.96      1061\n",
      " samples avg       0.94      0.97      0.95      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6338, Accuracy: 0.7012, F1 Micro: 0.7012, F1 Macro: 0.4122\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4634, Accuracy: 0.7842, F1 Micro: 0.7842, F1 Macro: 0.6719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3174, Accuracy: 0.888, F1 Micro: 0.888, F1 Macro: 0.8611\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1849, Accuracy: 0.8921, F1 Micro: 0.8921, F1 Macro: 0.8751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1489, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.8947\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0735, Accuracy: 0.9295, F1 Micro: 0.9295, F1 Macro: 0.9162\n",
      "Epoch 7/10, Train Loss: 0.1057, Accuracy: 0.9253, F1 Micro: 0.9253, F1 Macro: 0.9101\n",
      "Epoch 8/10, Train Loss: 0.1296, Accuracy: 0.9253, F1 Micro: 0.9253, F1 Macro: 0.907\n",
      "Epoch 9/10, Train Loss: 0.1262, Accuracy: 0.8838, F1 Micro: 0.8838, F1 Macro: 0.8721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0742, Accuracy: 0.9295, F1 Micro: 0.9295, F1 Macro: 0.9133\n",
      "\n",
      "Sentiment analysis accuracy: 0.9295, F1 Micro: 0.9295, F1 Macro: 0.9133\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.83      0.88        72\n",
      "    positive       0.93      0.97      0.95       169\n",
      "\n",
      "    accuracy                           0.93       241\n",
      "   macro avg       0.93      0.90      0.91       241\n",
      "weighted avg       0.93      0.93      0.93       241\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 208: Accuracy: 0.9221, F1 Micro: 0.9221, F1 Macro: 0.8488\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.94      0.93      0.93       167\n",
      "    positive       0.63      0.73      0.68        33\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.83      0.80      0.81       216\n",
      "weighted avg       0.89      0.88      0.89       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.50      0.60        12\n",
      "     neutral       0.88      0.93      0.90       152\n",
      "    positive       0.80      0.71      0.76        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.81      0.72      0.75       216\n",
      "weighted avg       0.85      0.86      0.85       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.48      0.61        23\n",
      "     neutral       0.89      0.97      0.93       152\n",
      "    positive       0.78      0.71      0.74        41\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.84      0.72      0.76       216\n",
      "weighted avg       0.87      0.87      0.86       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.95      0.84      0.89       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.71      0.83        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.87      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 81.61759662628174 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.02569437026977539\n",
      "Samples above threshold: 66\n",
      "Acquired samples: 66\n",
      "Sampling duration: 12.817080020904541 seconds\n",
      "New train size: 274\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5819, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5223, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4549, Accuracy: 0.8132, F1 Micro: 0.8942, F1 Macro: 0.8929\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3952, Accuracy: 0.8832, F1 Micro: 0.9303, F1 Macro: 0.929\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2954, Accuracy: 0.9159, F1 Micro: 0.9484, F1 Macro: 0.9464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2463, Accuracy: 0.9345, F1 Micro: 0.9594, F1 Macro: 0.9574\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2044, Accuracy: 0.9375, F1 Micro: 0.9615, F1 Macro: 0.9596\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1739, Accuracy: 0.9464, F1 Micro: 0.9664, F1 Macro: 0.9645\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1368, Accuracy: 0.9501, F1 Micro: 0.9689, F1 Macro: 0.967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1233, Accuracy: 0.9516, F1 Micro: 0.9698, F1 Macro: 0.9681\n",
      "\n",
      "Aspect detection accuracy: 0.9516, F1 Micro: 0.9698, F1 Macro: 0.9681\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.90      0.94      0.92       158\n",
      "        part       0.93      0.99      0.96       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.95      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5445, Accuracy: 0.6898, F1 Micro: 0.6898, F1 Macro: 0.4082\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.402, Accuracy: 0.7265, F1 Micro: 0.7265, F1 Macro: 0.5318\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.28, Accuracy: 0.902, F1 Micro: 0.902, F1 Macro: 0.8871\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.179, Accuracy: 0.9061, F1 Micro: 0.9061, F1 Macro: 0.8835\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1383, Accuracy: 0.9265, F1 Micro: 0.9265, F1 Macro: 0.9142\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0526, Accuracy: 0.9306, F1 Micro: 0.9306, F1 Macro: 0.9174\n",
      "Epoch 7/10, Train Loss: 0.0498, Accuracy: 0.9265, F1 Micro: 0.9265, F1 Macro: 0.9115\n",
      "Epoch 8/10, Train Loss: 0.0788, Accuracy: 0.9224, F1 Micro: 0.9224, F1 Macro: 0.9077\n",
      "Epoch 9/10, Train Loss: 0.0302, Accuracy: 0.9265, F1 Micro: 0.9265, F1 Macro: 0.9122\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0474, Accuracy: 0.9347, F1 Micro: 0.9347, F1 Macro: 0.9213\n",
      "\n",
      "Sentiment analysis accuracy: 0.9347, F1 Micro: 0.9347, F1 Macro: 0.9213\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.84      0.89        76\n",
      "    positive       0.93      0.98      0.95       169\n",
      "\n",
      "    accuracy                           0.93       245\n",
      "   macro avg       0.94      0.91      0.92       245\n",
      "weighted avg       0.93      0.93      0.93       245\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 274: Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.8801\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.69      0.79        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.81      0.76      0.78        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.81      0.84       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.91      0.94      0.92       152\n",
      "    positive       0.85      0.77      0.81        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.86      0.82      0.84       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.57      0.70        23\n",
      "     neutral       0.93      0.99      0.96       152\n",
      "    positive       0.82      0.80      0.81        41\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.89      0.79      0.82       216\n",
      "weighted avg       0.91      0.91      0.90       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.86      0.89       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.89      0.94      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 88.60852527618408 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.01873065829277039\n",
      "Samples above threshold: 59\n",
      "Acquired samples: 59\n",
      "Sampling duration: 11.886573791503906 seconds\n",
      "New train size: 333\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5699, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4952, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.429, Accuracy: 0.8713, F1 Micro: 0.924, F1 Macro: 0.9223\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3267, Accuracy: 0.9159, F1 Micro: 0.9481, F1 Macro: 0.9456\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2664, Accuracy: 0.9323, F1 Micro: 0.958, F1 Macro: 0.9555\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2141, Accuracy: 0.9464, F1 Micro: 0.9665, F1 Macro: 0.9645\n",
      "Epoch 7/10, Train Loss: 0.1612, Accuracy: 0.9427, F1 Micro: 0.9639, F1 Macro: 0.9606\n",
      "Epoch 8/10, Train Loss: 0.132, Accuracy: 0.9442, F1 Micro: 0.9648, F1 Macro: 0.9622\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1177, Accuracy: 0.9539, F1 Micro: 0.9711, F1 Macro: 0.9691\n",
      "Epoch 10/10, Train Loss: 0.0944, Accuracy: 0.9472, F1 Micro: 0.9669, F1 Macro: 0.9645\n",
      "\n",
      "Aspect detection accuracy: 0.9539, F1 Micro: 0.9711, F1 Macro: 0.9691\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.92      0.91      0.92       158\n",
      "        part       0.92      0.99      0.95       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5647, Accuracy: 0.68, F1 Micro: 0.68, F1 Macro: 0.4048\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4096, Accuracy: 0.868, F1 Micro: 0.868, F1 Macro: 0.841\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2283, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9105\n",
      "Epoch 4/10, Train Loss: 0.1151, Accuracy: 0.916, F1 Micro: 0.916, F1 Macro: 0.905\n",
      "Epoch 5/10, Train Loss: 0.0819, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.8917\n",
      "Epoch 6/10, Train Loss: 0.1166, Accuracy: 0.916, F1 Micro: 0.916, F1 Macro: 0.8988\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0763, Accuracy: 0.932, F1 Micro: 0.932, F1 Macro: 0.9205\n",
      "Epoch 8/10, Train Loss: 0.0617, Accuracy: 0.912, F1 Micro: 0.912, F1 Macro: 0.8989\n",
      "Epoch 9/10, Train Loss: 0.0549, Accuracy: 0.92, F1 Micro: 0.92, F1 Macro: 0.9075\n",
      "Epoch 10/10, Train Loss: 0.0329, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9155\n",
      "\n",
      "Sentiment analysis accuracy: 0.932, F1 Micro: 0.932, F1 Macro: 0.9205\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89        80\n",
      "    positive       0.94      0.96      0.95       170\n",
      "\n",
      "    accuracy                           0.93       250\n",
      "   macro avg       0.93      0.91      0.92       250\n",
      "weighted avg       0.93      0.93      0.93       250\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 333: Accuracy: 0.9383, F1 Micro: 0.9383, F1 Macro: 0.8767\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.83      0.86       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.75      0.60        12\n",
      "     neutral       0.93      0.88      0.91       152\n",
      "    positive       0.78      0.81      0.79        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.74      0.81      0.77       216\n",
      "weighted avg       0.87      0.86      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.65      0.75        23\n",
      "     neutral       0.92      0.99      0.95       152\n",
      "    positive       0.83      0.73      0.78        41\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.88      0.79      0.83       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.86      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.89      0.94      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 88.29591083526611 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0169907808303833\n",
      "Samples above threshold: 54\n",
      "Acquired samples: 54\n",
      "Sampling duration: 10.984915733337402 seconds\n",
      "New train size: 387\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5615, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4927, Accuracy: 0.808, F1 Micro: 0.8916, F1 Macro: 0.8902\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3987, Accuracy: 0.9062, F1 Micro: 0.9428, F1 Macro: 0.9407\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2874, Accuracy: 0.9271, F1 Micro: 0.955, F1 Macro: 0.9525\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.229, Accuracy: 0.9397, F1 Micro: 0.9621, F1 Macro: 0.9587\n",
      "Epoch 6/10, Train Loss: 0.1732, Accuracy: 0.939, F1 Micro: 0.9617, F1 Macro: 0.9584\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1336, Accuracy: 0.9464, F1 Micro: 0.9663, F1 Macro: 0.9635\n",
      "Epoch 8/10, Train Loss: 0.1156, Accuracy: 0.9457, F1 Micro: 0.9657, F1 Macro: 0.9627\n",
      "Epoch 9/10, Train Loss: 0.0998, Accuracy: 0.9457, F1 Micro: 0.9657, F1 Macro: 0.9623\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0868, Accuracy: 0.9472, F1 Micro: 0.9667, F1 Macro: 0.9638\n",
      "\n",
      "Aspect detection accuracy: 0.9472, F1 Micro: 0.9667, F1 Macro: 0.9638\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.92      0.85      0.89       158\n",
      "        part       0.92      0.99      0.96       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.97      0.97      1061\n",
      "   macro avg       0.96      0.97      0.96      1061\n",
      "weighted avg       0.96      0.97      0.97      1061\n",
      " samples avg       0.96      0.97      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5036, Accuracy: 0.7034, F1 Micro: 0.7034, F1 Macro: 0.4129\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3704, Accuracy: 0.8365, F1 Micro: 0.8365, F1 Macro: 0.7792\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2016, Accuracy: 0.8935, F1 Micro: 0.8935, F1 Macro: 0.8798\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1337, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.8966\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.124, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.8982\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.078, Accuracy: 0.9202, F1 Micro: 0.9202, F1 Macro: 0.9085\n",
      "Epoch 7/10, Train Loss: 0.0652, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.8842\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0595, Accuracy: 0.9278, F1 Micro: 0.9278, F1 Macro: 0.9172\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0444, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9333\n",
      "Epoch 10/10, Train Loss: 0.0266, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9249\n",
      "\n",
      "Sentiment analysis accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.95      0.91        78\n",
      "    positive       0.98      0.94      0.96       185\n",
      "\n",
      "    accuracy                           0.94       263\n",
      "   macro avg       0.92      0.94      0.93       263\n",
      "weighted avg       0.95      0.94      0.94       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 387: Accuracy: 0.9383, F1 Micro: 0.9383, F1 Macro: 0.889\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.82      0.82      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.87      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.56      0.83      0.67        12\n",
      "     neutral       0.92      0.86      0.89       152\n",
      "    positive       0.70      0.77      0.73        52\n",
      "\n",
      "    accuracy                           0.83       216\n",
      "   macro avg       0.73      0.82      0.76       216\n",
      "weighted avg       0.85      0.83      0.84       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.74      0.79        23\n",
      "     neutral       0.92      0.99      0.96       152\n",
      "    positive       0.94      0.73      0.82        41\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.90      0.82      0.86       216\n",
      "weighted avg       0.92      0.92      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.86      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.96      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 100.21061635017395 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.012343001365661622\n",
      "Samples above threshold: 48\n",
      "Acquired samples: 48\n",
      "Sampling duration: 10.352322340011597 seconds\n",
      "New train size: 435\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.561, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4676, Accuracy: 0.8214, F1 Micro: 0.8981, F1 Macro: 0.8966\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3691, Accuracy: 0.9107, F1 Micro: 0.9445, F1 Macro: 0.942\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2919, Accuracy: 0.9241, F1 Micro: 0.9524, F1 Macro: 0.9474\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2132, Accuracy: 0.9442, F1 Micro: 0.9652, F1 Macro: 0.9627\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1709, Accuracy: 0.9501, F1 Micro: 0.9687, F1 Macro: 0.9663\n",
      "Epoch 7/10, Train Loss: 0.1364, Accuracy: 0.9464, F1 Micro: 0.9662, F1 Macro: 0.9631\n",
      "Epoch 8/10, Train Loss: 0.1111, Accuracy: 0.9479, F1 Micro: 0.9672, F1 Macro: 0.9646\n",
      "Epoch 9/10, Train Loss: 0.0924, Accuracy: 0.9487, F1 Micro: 0.9676, F1 Macro: 0.9649\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0728, Accuracy: 0.9509, F1 Micro: 0.9691, F1 Macro: 0.9668\n",
      "\n",
      "Aspect detection accuracy: 0.9509, F1 Micro: 0.9691, F1 Macro: 0.9668\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.94      0.99      0.96       175\n",
      "      others       0.91      0.87      0.89       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.97      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.97      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5317, Accuracy: 0.6938, F1 Micro: 0.6938, F1 Macro: 0.4096\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3527, Accuracy: 0.9031, F1 Micro: 0.9031, F1 Macro: 0.883\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1667, Accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.9088\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1363, Accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.9074\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.113, Accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.9106\n",
      "Epoch 6/10, Train Loss: 0.1079, Accuracy: 0.9186, F1 Micro: 0.9186, F1 Macro: 0.907\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0764, Accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.9106\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.097, Accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.9164\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0716, Accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.913\n",
      "Epoch 10/10, Train Loss: 0.0669, Accuracy: 0.9186, F1 Micro: 0.9186, F1 Macro: 0.9052\n",
      "\n",
      "Sentiment analysis accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.913\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.87      0.88        79\n",
      "    positive       0.94      0.95      0.95       179\n",
      "\n",
      "    accuracy                           0.93       258\n",
      "   macro avg       0.91      0.91      0.91       258\n",
      "weighted avg       0.93      0.93      0.93       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 435: Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.8757\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.93      0.99      0.96       167\n",
      "    positive       0.88      0.64      0.74        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.89      0.79      0.83       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.75      0.67        12\n",
      "     neutral       0.92      0.88      0.90       152\n",
      "    positive       0.70      0.75      0.72        52\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.74      0.79      0.76       216\n",
      "weighted avg       0.85      0.84      0.84       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.74      0.79        23\n",
      "     neutral       0.96      0.99      0.97       152\n",
      "    positive       0.89      0.83      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.85      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.86      0.89       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.93      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 103.42497897148132 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.01147918701171875\n",
      "Samples above threshold: 43\n",
      "Acquired samples: 43\n",
      "Sampling duration: 9.477774143218994 seconds\n",
      "New train size: 478\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5607, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4656, Accuracy: 0.8356, F1 Micro: 0.9054, F1 Macro: 0.904\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3609, Accuracy: 0.9226, F1 Micro: 0.9525, F1 Macro: 0.9504\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2662, Accuracy: 0.942, F1 Micro: 0.9639, F1 Macro: 0.9621\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1988, Accuracy: 0.9487, F1 Micro: 0.9678, F1 Macro: 0.9658\n",
      "Epoch 6/10, Train Loss: 0.1522, Accuracy: 0.9435, F1 Micro: 0.9645, F1 Macro: 0.9617\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1268, Accuracy: 0.9539, F1 Micro: 0.971, F1 Macro: 0.9694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1054, Accuracy: 0.9554, F1 Micro: 0.9719, F1 Macro: 0.9701\n",
      "Epoch 9/10, Train Loss: 0.0908, Accuracy: 0.9487, F1 Micro: 0.9675, F1 Macro: 0.9645\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0742, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9717\n",
      "\n",
      "Aspect detection accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9717\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.91      0.92      0.92       158\n",
      "        part       0.97      0.97      0.97       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5476, Accuracy: 0.6897, F1 Micro: 0.6897, F1 Macro: 0.4082\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3859, Accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.9002\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2252, Accuracy: 0.9195, F1 Micro: 0.9195, F1 Macro: 0.9107\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1451, Accuracy: 0.9272, F1 Micro: 0.9272, F1 Macro: 0.9188\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1221, Accuracy: 0.9387, F1 Micro: 0.9387, F1 Macro: 0.9269\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1398, Accuracy: 0.954, F1 Micro: 0.954, F1 Macro: 0.9473\n",
      "Epoch 7/10, Train Loss: 0.1061, Accuracy: 0.9425, F1 Micro: 0.9425, F1 Macro: 0.9326\n",
      "Epoch 8/10, Train Loss: 0.093, Accuracy: 0.9425, F1 Micro: 0.9425, F1 Macro: 0.9335\n",
      "Epoch 9/10, Train Loss: 0.0706, Accuracy: 0.9119, F1 Micro: 0.9119, F1 Macro: 0.9032\n",
      "Epoch 10/10, Train Loss: 0.0446, Accuracy: 0.9502, F1 Micro: 0.9502, F1 Macro: 0.9416\n",
      "\n",
      "Sentiment analysis accuracy: 0.954, F1 Micro: 0.954, F1 Macro: 0.9473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.96      0.93        81\n",
      "    positive       0.98      0.95      0.97       180\n",
      "\n",
      "    accuracy                           0.95       261\n",
      "   macro avg       0.94      0.96      0.95       261\n",
      "weighted avg       0.96      0.95      0.95       261\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 478: Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.9058\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.96      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.89      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.82      0.82      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.85      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.92      0.93      0.92       152\n",
      "    positive       0.82      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.86      0.85      0.85       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.91      0.89        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       0.92      0.88      0.90        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.92      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.86      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.96      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 108.58668971061707 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.010503232479095459\n",
      "Samples above threshold: 39\n",
      "Acquired samples: 39\n",
      "Sampling duration: 8.577321767807007 seconds\n",
      "New train size: 517\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5463, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4423, Accuracy: 0.872, F1 Micro: 0.9245, F1 Macro: 0.9232\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3083, Accuracy: 0.9278, F1 Micro: 0.9556, F1 Macro: 0.9532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2265, Accuracy: 0.9457, F1 Micro: 0.9663, F1 Macro: 0.9644\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1589, Accuracy: 0.9554, F1 Micro: 0.9722, F1 Macro: 0.9707\n",
      "Epoch 6/10, Train Loss: 0.1314, Accuracy: 0.9464, F1 Micro: 0.9662, F1 Macro: 0.9631\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1032, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.973\n",
      "Epoch 8/10, Train Loss: 0.082, Accuracy: 0.9487, F1 Micro: 0.9674, F1 Macro: 0.9639\n",
      "Epoch 9/10, Train Loss: 0.0742, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.973\n",
      "Epoch 10/10, Train Loss: 0.0626, Accuracy: 0.9501, F1 Micro: 0.9685, F1 Macro: 0.966\n",
      "\n",
      "Aspect detection accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.973\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.89      0.94      0.92       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.99      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5155, Accuracy: 0.6867, F1 Micro: 0.6867, F1 Macro: 0.4071\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3579, Accuracy: 0.9598, F1 Micro: 0.9598, F1 Macro: 0.9536\n",
      "Epoch 3/10, Train Loss: 0.1658, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9287\n",
      "Epoch 4/10, Train Loss: 0.1516, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9367\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0883, Accuracy: 0.9598, F1 Micro: 0.9598, F1 Macro: 0.9536\n",
      "Epoch 6/10, Train Loss: 0.0939, Accuracy: 0.9518, F1 Micro: 0.9518, F1 Macro: 0.9447\n",
      "Epoch 7/10, Train Loss: 0.0527, Accuracy: 0.9518, F1 Micro: 0.9518, F1 Macro: 0.9451\n",
      "Epoch 8/10, Train Loss: 0.0843, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9328\n",
      "Epoch 9/10, Train Loss: 0.0631, Accuracy: 0.9518, F1 Micro: 0.9518, F1 Macro: 0.9436\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0329, Accuracy: 0.9639, F1 Micro: 0.9639, F1 Macro: 0.9587\n",
      "\n",
      "Sentiment analysis accuracy: 0.9639, F1 Micro: 0.9639, F1 Macro: 0.9587\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.97      0.94        78\n",
      "    positive       0.99      0.96      0.97       171\n",
      "\n",
      "    accuracy                           0.96       249\n",
      "   macro avg       0.95      0.97      0.96       249\n",
      "weighted avg       0.97      0.96      0.96       249\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 517: Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.8962\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.85      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.33      0.83      0.48        12\n",
      "     neutral       0.92      0.86      0.89       152\n",
      "    positive       0.84      0.73      0.78        52\n",
      "\n",
      "    accuracy                           0.82       216\n",
      "   macro avg       0.70      0.81      0.72       216\n",
      "weighted avg       0.87      0.82      0.84       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.86      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.99      0.99      0.99       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.97      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 104.17299699783325 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.012195897102355961\n",
      "Samples above threshold: 35\n",
      "Acquired samples: 23\n",
      "Sampling duration: 7.662287950515747 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5428, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4478, Accuracy: 0.8743, F1 Micro: 0.9258, F1 Macro: 0.9243\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3106, Accuracy: 0.9338, F1 Micro: 0.9591, F1 Macro: 0.9568\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2102, Accuracy: 0.9501, F1 Micro: 0.9692, F1 Macro: 0.9676\n",
      "Epoch 5/10, Train Loss: 0.1694, Accuracy: 0.9501, F1 Micro: 0.9687, F1 Macro: 0.9658\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1279, Accuracy: 0.9621, F1 Micro: 0.9763, F1 Macro: 0.9753\n",
      "Epoch 7/10, Train Loss: 0.1046, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9715\n",
      "Epoch 8/10, Train Loss: 0.0832, Accuracy: 0.9554, F1 Micro: 0.9719, F1 Macro: 0.97\n",
      "Epoch 9/10, Train Loss: 0.0727, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.972\n",
      "Epoch 10/10, Train Loss: 0.0604, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9714\n",
      "\n",
      "Aspect detection accuracy: 0.9621, F1 Micro: 0.9763, F1 Macro: 0.9753\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.89      0.99      0.94       158\n",
      "        part       0.97      0.97      0.97       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.98      1061\n",
      "weighted avg       0.96      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5071, Accuracy: 0.6901, F1 Micro: 0.6901, F1 Macro: 0.4327\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2596, Accuracy: 0.9463, F1 Micro: 0.9463, F1 Macro: 0.9387\n",
      "Epoch 3/10, Train Loss: 0.2104, Accuracy: 0.9174, F1 Micro: 0.9174, F1 Macro: 0.9027\n",
      "Epoch 4/10, Train Loss: 0.125, Accuracy: 0.9132, F1 Micro: 0.9132, F1 Macro: 0.8966\n",
      "Epoch 5/10, Train Loss: 0.096, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9342\n",
      "Epoch 6/10, Train Loss: 0.0686, Accuracy: 0.9256, F1 Micro: 0.9256, F1 Macro: 0.9124\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0868, Accuracy: 0.9587, F1 Micro: 0.9587, F1 Macro: 0.9527\n",
      "Epoch 8/10, Train Loss: 0.07, Accuracy: 0.9504, F1 Micro: 0.9504, F1 Macro: 0.9436\n",
      "Epoch 9/10, Train Loss: 0.0643, Accuracy: 0.9256, F1 Micro: 0.9256, F1 Macro: 0.9179\n",
      "Epoch 10/10, Train Loss: 0.0628, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9248\n",
      "\n",
      "Sentiment analysis accuracy: 0.9587, F1 Micro: 0.9587, F1 Macro: 0.9527\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.95      0.94        77\n",
      "    positive       0.98      0.96      0.97       165\n",
      "\n",
      "    accuracy                           0.96       242\n",
      "   macro avg       0.95      0.96      0.95       242\n",
      "weighted avg       0.96      0.96      0.96       242\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9437, F1 Micro: 0.9437, F1 Macro: 0.8861\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.97      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.75      0.77        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.82      0.85       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.32      0.83      0.47        12\n",
      "     neutral       0.92      0.89      0.91       152\n",
      "    positive       0.97      0.69      0.81        52\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.74      0.81      0.73       216\n",
      "weighted avg       0.90      0.84      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       0.88      0.88      0.88        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.86      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 101.04388618469238 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.015544432401657102\n",
      "Samples above threshold: 33\n",
      "Acquired samples: 33\n",
      "Sampling duration: 7.232901573181152 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.547, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4403, Accuracy: 0.8854, F1 Micro: 0.932, F1 Macro: 0.9304\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3103, Accuracy: 0.9382, F1 Micro: 0.9619, F1 Macro: 0.9603\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2158, Accuracy: 0.9479, F1 Micro: 0.9678, F1 Macro: 0.9662\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1659, Accuracy: 0.9554, F1 Micro: 0.9721, F1 Macro: 0.9707\n",
      "Epoch 6/10, Train Loss: 0.1324, Accuracy: 0.9524, F1 Micro: 0.97, F1 Macro: 0.968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1022, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9746\n",
      "Epoch 8/10, Train Loss: 0.0816, Accuracy: 0.9561, F1 Micro: 0.9723, F1 Macro: 0.9704\n",
      "Epoch 9/10, Train Loss: 0.0709, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9715\n",
      "Epoch 10/10, Train Loss: 0.0607, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9718\n",
      "\n",
      "Aspect detection accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9746\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.99      0.98       175\n",
      "      others       0.92      0.92      0.92       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5242, Accuracy: 0.692, F1 Micro: 0.692, F1 Macro: 0.409\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3544, Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.9422\n",
      "Epoch 3/10, Train Loss: 0.1974, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.9071\n",
      "Epoch 4/10, Train Loss: 0.1241, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9244\n",
      "Epoch 5/10, Train Loss: 0.1119, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9309\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0918, Accuracy: 0.9582, F1 Micro: 0.9582, F1 Macro: 0.9517\n",
      "Epoch 7/10, Train Loss: 0.0774, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9309\n",
      "Epoch 8/10, Train Loss: 0.0421, Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.9433\n",
      "Epoch 9/10, Train Loss: 0.0518, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9354\n",
      "Epoch 10/10, Train Loss: 0.0509, Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9392\n",
      "\n",
      "Sentiment analysis accuracy: 0.9582, F1 Micro: 0.9582, F1 Macro: 0.9517\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.93        81\n",
      "    positive       0.98      0.96      0.97       182\n",
      "\n",
      "    accuracy                           0.96       263\n",
      "   macro avg       0.95      0.96      0.95       263\n",
      "weighted avg       0.96      0.96      0.96       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.9048\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.97      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.86      0.87       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.83      0.71        12\n",
      "     neutral       0.93      0.91      0.92       152\n",
      "    positive       0.78      0.77      0.78        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.78      0.84      0.80       216\n",
      "weighted avg       0.88      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.91      0.87        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.88      0.92        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.86      0.89       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.96      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 111.09335732460022 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.011571764945983887\n",
      "Samples above threshold: 30\n",
      "Acquired samples: 30\n",
      "Sampling duration: 6.685807466506958 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5472, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4318, Accuracy: 0.9085, F1 Micro: 0.9448, F1 Macro: 0.9432\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2973, Accuracy: 0.9382, F1 Micro: 0.9618, F1 Macro: 0.96\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2123, Accuracy: 0.9412, F1 Micro: 0.9635, F1 Macro: 0.9611\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.153, Accuracy: 0.9501, F1 Micro: 0.9686, F1 Macro: 0.9656\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1152, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0988, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9732\n",
      "Epoch 8/10, Train Loss: 0.0805, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0728, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9745\n",
      "Epoch 10/10, Train Loss: 0.0603, Accuracy: 0.9531, F1 Micro: 0.9703, F1 Macro: 0.9676\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9745\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.90      0.94      0.92       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5117, Accuracy: 0.6929, F1 Micro: 0.6929, F1 Macro: 0.4214\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2915, Accuracy: 0.9488, F1 Micro: 0.9488, F1 Macro: 0.9409\n",
      "Epoch 3/10, Train Loss: 0.2061, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9361\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1541, Accuracy: 0.9488, F1 Micro: 0.9488, F1 Macro: 0.942\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1494, Accuracy: 0.9528, F1 Micro: 0.9528, F1 Macro: 0.946\n",
      "Epoch 6/10, Train Loss: 0.1337, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9289\n",
      "Epoch 7/10, Train Loss: 0.1096, Accuracy: 0.9488, F1 Micro: 0.9488, F1 Macro: 0.9417\n",
      "Epoch 8/10, Train Loss: 0.0894, Accuracy: 0.9488, F1 Micro: 0.9488, F1 Macro: 0.9417\n",
      "Epoch 9/10, Train Loss: 0.059, Accuracy: 0.9488, F1 Micro: 0.9488, F1 Macro: 0.9417\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0533, Accuracy: 0.9567, F1 Micro: 0.9567, F1 Macro: 0.9496\n",
      "\n",
      "Sentiment analysis accuracy: 0.9567, F1 Micro: 0.9567, F1 Macro: 0.9496\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.93        79\n",
      "    positive       0.97      0.97      0.97       175\n",
      "\n",
      "    accuracy                           0.96       254\n",
      "   macro avg       0.95      0.95      0.95       254\n",
      "weighted avg       0.96      0.96      0.96       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.8897\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.96      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.81      0.79        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.87      0.86      0.86       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.33      0.83      0.48        12\n",
      "     neutral       0.93      0.85      0.89       152\n",
      "    positive       0.85      0.79      0.82        52\n",
      "\n",
      "    accuracy                           0.83       216\n",
      "   macro avg       0.71      0.82      0.73       216\n",
      "weighted avg       0.88      0.83      0.85       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.91      0.87        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.88      0.92        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      0.99      0.98       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.93      0.89      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.96      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 118.87983298301697 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.007508397102355957\n",
      "Samples above threshold: 27\n",
      "Acquired samples: 27\n",
      "Sampling duration: 6.207782983779907 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5489, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4189, Accuracy: 0.9152, F1 Micro: 0.9485, F1 Macro: 0.947\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2689, Accuracy: 0.9464, F1 Micro: 0.9669, F1 Macro: 0.9654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1962, Accuracy: 0.9576, F1 Micro: 0.9737, F1 Macro: 0.9724\n",
      "Epoch 5/10, Train Loss: 0.1487, Accuracy: 0.9524, F1 Micro: 0.9703, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1169, Accuracy: 0.9613, F1 Micro: 0.9759, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0954, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9779\n",
      "Epoch 8/10, Train Loss: 0.0741, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9722\n",
      "Epoch 9/10, Train Loss: 0.0623, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9725\n",
      "Epoch 10/10, Train Loss: 0.0507, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9751\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9779\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.93      0.95      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5166, Accuracy: 0.7121, F1 Micro: 0.7121, F1 Macro: 0.4927\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.268, Accuracy: 0.9533, F1 Micro: 0.9533, F1 Macro: 0.9459\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1614, Accuracy: 0.9533, F1 Micro: 0.9533, F1 Macro: 0.9469\n",
      "Epoch 4/10, Train Loss: 0.1466, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9166\n",
      "Epoch 5/10, Train Loss: 0.1246, Accuracy: 0.9416, F1 Micro: 0.9416, F1 Macro: 0.9339\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0938, Accuracy: 0.9533, F1 Micro: 0.9533, F1 Macro: 0.9466\n",
      "Epoch 7/10, Train Loss: 0.0807, Accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.936\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0628, Accuracy: 0.9533, F1 Micro: 0.9533, F1 Macro: 0.9473\n",
      "Epoch 9/10, Train Loss: 0.0687, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9264\n",
      "Epoch 10/10, Train Loss: 0.0523, Accuracy: 0.9494, F1 Micro: 0.9494, F1 Macro: 0.9427\n",
      "\n",
      "Sentiment analysis accuracy: 0.9533, F1 Micro: 0.9533, F1 Macro: 0.9473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.93        81\n",
      "    positive       0.99      0.94      0.97       176\n",
      "\n",
      "    accuracy                           0.95       257\n",
      "   macro avg       0.94      0.96      0.95       257\n",
      "weighted avg       0.96      0.95      0.95       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9117\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.97      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.83      0.71        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.86      0.81      0.83        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.81      0.86      0.83       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.93      0.92       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.84      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 120.05643939971924 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.009418702125549317\n",
      "Samples above threshold: 24\n",
      "Acquired samples: 18\n",
      "Sampling duration: 5.699345827102661 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5415, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4133, Accuracy: 0.9092, F1 Micro: 0.9442, F1 Macro: 0.9427\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2658, Accuracy: 0.9412, F1 Micro: 0.9636, F1 Macro: 0.9615\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1997, Accuracy: 0.9583, F1 Micro: 0.974, F1 Macro: 0.973\n",
      "Epoch 5/10, Train Loss: 0.1506, Accuracy: 0.9583, F1 Micro: 0.974, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1138, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9751\n",
      "Epoch 7/10, Train Loss: 0.0866, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0725, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9758\n",
      "Epoch 9/10, Train Loss: 0.0583, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9754\n",
      "Epoch 10/10, Train Loss: 0.0525, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9736\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9758\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.99      0.98       175\n",
      "      others       0.90      0.94      0.92       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4809, Accuracy: 0.7333, F1 Micro: 0.7333, F1 Macro: 0.5491\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2858, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9083\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1534, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.934\n",
      "Epoch 4/10, Train Loss: 0.1355, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9215\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1109, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9382\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1203, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9382\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0876, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9382\n",
      "Epoch 8/10, Train Loss: 0.0659, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9328\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0569, Accuracy: 0.9569, F1 Micro: 0.9569, F1 Macro: 0.9497\n",
      "Epoch 10/10, Train Loss: 0.0533, Accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.9398\n",
      "\n",
      "Sentiment analysis accuracy: 0.9569, F1 Micro: 0.9569, F1 Macro: 0.9497\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.93        80\n",
      "    positive       0.97      0.97      0.97       175\n",
      "\n",
      "    accuracy                           0.96       255\n",
      "   macro avg       0.95      0.95      0.95       255\n",
      "weighted avg       0.96      0.96      0.96       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.8975\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.96      0.99      0.98       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.87      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.48      0.83      0.61        12\n",
      "     neutral       0.93      0.89      0.91       152\n",
      "    positive       0.83      0.77      0.80        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.74      0.83      0.77       216\n",
      "weighted avg       0.88      0.86      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.83      0.84        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.90      0.88      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.90      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.69      0.82        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.86      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 124.91021513938904 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.006911516189575195\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.932615518569946 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5345, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3967, Accuracy: 0.9256, F1 Micro: 0.9541, F1 Macro: 0.9524\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.255, Accuracy: 0.942, F1 Micro: 0.964, F1 Macro: 0.9621\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1775, Accuracy: 0.9606, F1 Micro: 0.9755, F1 Macro: 0.9747\n",
      "Epoch 5/10, Train Loss: 0.1329, Accuracy: 0.9546, F1 Micro: 0.9713, F1 Macro: 0.9686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1098, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9763\n",
      "Epoch 7/10, Train Loss: 0.0832, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.974\n",
      "Epoch 8/10, Train Loss: 0.0673, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9759\n",
      "Epoch 9/10, Train Loss: 0.0605, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9749\n",
      "Epoch 10/10, Train Loss: 0.0505, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.975\n",
      "\n",
      "Aspect detection accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9763\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.91      0.94      0.92       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      0.99      0.98       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5089, Accuracy: 0.875, F1 Micro: 0.875, F1 Macro: 0.8491\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2449, Accuracy: 0.9297, F1 Micro: 0.9297, F1 Macro: 0.917\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1765, Accuracy: 0.9531, F1 Micro: 0.9531, F1 Macro: 0.9451\n",
      "Epoch 4/10, Train Loss: 0.1432, Accuracy: 0.9297, F1 Micro: 0.9297, F1 Macro: 0.9216\n",
      "Epoch 5/10, Train Loss: 0.1036, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9345\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0965, Accuracy: 0.9609, F1 Micro: 0.9609, F1 Macro: 0.9549\n",
      "Epoch 7/10, Train Loss: 0.0767, Accuracy: 0.9531, F1 Micro: 0.9531, F1 Macro: 0.9465\n",
      "Epoch 8/10, Train Loss: 0.0908, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9345\n",
      "Epoch 9/10, Train Loss: 0.0757, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9345\n",
      "Epoch 10/10, Train Loss: 0.0536, Accuracy: 0.9531, F1 Micro: 0.9531, F1 Macro: 0.9458\n",
      "\n",
      "Sentiment analysis accuracy: 0.9609, F1 Micro: 0.9609, F1 Macro: 0.9549\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        81\n",
      "    positive       0.97      0.97      0.97       175\n",
      "\n",
      "    accuracy                           0.96       256\n",
      "   macro avg       0.95      0.95      0.95       256\n",
      "weighted avg       0.96      0.96      0.96       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9002\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.96      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      0.81      0.76        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.86      0.85      0.85       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.67      0.64        12\n",
      "     neutral       0.92      0.93      0.92       152\n",
      "    positive       0.84      0.81      0.82        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.79      0.80      0.80       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.91      0.87        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.92      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 118.89018630981445 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.009006977081298828\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.803186416625977 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5274, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4023, Accuracy: 0.9286, F1 Micro: 0.9559, F1 Macro: 0.9545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2503, Accuracy: 0.9472, F1 Micro: 0.9673, F1 Macro: 0.9656\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1769, Accuracy: 0.9591, F1 Micro: 0.9746, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1322, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9754\n",
      "Epoch 6/10, Train Loss: 0.1032, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0845, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.978\n",
      "Epoch 8/10, Train Loss: 0.0677, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9759\n",
      "Epoch 9/10, Train Loss: 0.061, Accuracy: 0.9591, F1 Micro: 0.9741, F1 Macro: 0.9717\n",
      "Epoch 10/10, Train Loss: 0.0531, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9738\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.90      0.96      0.93       158\n",
      "        part       0.98      1.00      0.99       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5295, Accuracy: 0.7028, F1 Micro: 0.7028, F1 Macro: 0.4982\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.281, Accuracy: 0.9518, F1 Micro: 0.9518, F1 Macro: 0.9451\n",
      "Epoch 3/10, Train Loss: 0.1877, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9385\n",
      "Epoch 4/10, Train Loss: 0.1274, Accuracy: 0.9317, F1 Micro: 0.9317, F1 Macro: 0.9255\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1198, Accuracy: 0.9558, F1 Micro: 0.9558, F1 Macro: 0.951\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0977, Accuracy: 0.9598, F1 Micro: 0.9598, F1 Macro: 0.9553\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0831, Accuracy: 0.9639, F1 Micro: 0.9639, F1 Macro: 0.9592\n",
      "Epoch 8/10, Train Loss: 0.0695, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9385\n",
      "Epoch 9/10, Train Loss: 0.0566, Accuracy: 0.9478, F1 Micro: 0.9478, F1 Macro: 0.9414\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0633, Accuracy: 0.9639, F1 Micro: 0.9639, F1 Macro: 0.9584\n",
      "\n",
      "Sentiment analysis accuracy: 0.9639, F1 Micro: 0.9639, F1 Macro: 0.9584\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.91      0.94        82\n",
      "    positive       0.96      0.99      0.97       167\n",
      "\n",
      "    accuracy                           0.96       249\n",
      "   macro avg       0.97      0.95      0.96       249\n",
      "weighted avg       0.96      0.96      0.96       249\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9006\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.82      0.86        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.92      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.96      0.99      0.98       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.86      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.43      0.83      0.57        12\n",
      "     neutral       0.93      0.91      0.92       152\n",
      "    positive       0.89      0.75      0.81        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.75      0.83      0.77       216\n",
      "weighted avg       0.89      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.91      0.93        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.93      0.95        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.97      0.94      0.96       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.93      0.89      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 126.77982139587402 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.0068822503089904785\n",
      "Samples above threshold: 17\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.484610080718994 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.528, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3885, Accuracy: 0.9219, F1 Micro: 0.9514, F1 Macro: 0.9495\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2546, Accuracy: 0.9516, F1 Micro: 0.97, F1 Macro: 0.9688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1757, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1356, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1043, Accuracy: 0.9665, F1 Micro: 0.9791, F1 Macro: 0.9781\n",
      "Epoch 7/10, Train Loss: 0.0837, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9746\n",
      "Epoch 8/10, Train Loss: 0.0656, Accuracy: 0.9524, F1 Micro: 0.9698, F1 Macro: 0.9662\n",
      "Epoch 9/10, Train Loss: 0.0615, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9765\n",
      "Epoch 10/10, Train Loss: 0.0503, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.975\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9791, F1 Macro: 0.9781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.90      0.98      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4846, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.8962\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2088, Accuracy: 0.9274, F1 Micro: 0.9274, F1 Macro: 0.9203\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1723, Accuracy: 0.9435, F1 Micro: 0.9435, F1 Macro: 0.9358\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1651, Accuracy: 0.9516, F1 Micro: 0.9516, F1 Macro: 0.9463\n",
      "Epoch 5/10, Train Loss: 0.15, Accuracy: 0.9435, F1 Micro: 0.9435, F1 Macro: 0.9377\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1093, Accuracy: 0.9556, F1 Micro: 0.9556, F1 Macro: 0.9506\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0824, Accuracy: 0.9556, F1 Micro: 0.9556, F1 Macro: 0.9506\n",
      "Epoch 8/10, Train Loss: 0.0854, Accuracy: 0.9516, F1 Micro: 0.9516, F1 Macro: 0.946\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0443, Accuracy: 0.9677, F1 Micro: 0.9677, F1 Macro: 0.9638\n",
      "Epoch 10/10, Train Loss: 0.0679, Accuracy: 0.9556, F1 Micro: 0.9556, F1 Macro: 0.9501\n",
      "\n",
      "Sentiment analysis accuracy: 0.9677, F1 Micro: 0.9677, F1 Macro: 0.9638\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.98      0.95        81\n",
      "    positive       0.99      0.96      0.98       167\n",
      "\n",
      "    accuracy                           0.97       248\n",
      "   macro avg       0.96      0.97      0.96       248\n",
      "weighted avg       0.97      0.97      0.97       248\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9056\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.96      0.99      0.98       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.35      0.92      0.51        12\n",
      "     neutral       0.94      0.89      0.92       152\n",
      "    positive       0.93      0.71      0.80        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.74      0.84      0.74       216\n",
      "weighted avg       0.90      0.85      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.91      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 130.51781582832336 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.007551431655883789\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.8774619102478027 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5401, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3925, Accuracy: 0.9308, F1 Micro: 0.9572, F1 Macro: 0.9554\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2491, Accuracy: 0.9509, F1 Micro: 0.9696, F1 Macro: 0.9683\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1712, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1317, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9762\n",
      "Epoch 6/10, Train Loss: 0.0939, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9742\n",
      "Epoch 7/10, Train Loss: 0.0729, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.062, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9771\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0552, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9772\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0485, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9795\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9795\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.94      0.95      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4923, Accuracy: 0.8835, F1 Micro: 0.8835, F1 Macro: 0.8702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.227, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9325\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1796, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9321\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1439, Accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9399\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1358, Accuracy: 0.9511, F1 Micro: 0.9511, F1 Macro: 0.9446\n",
      "Epoch 6/10, Train Loss: 0.0942, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9328\n",
      "Epoch 7/10, Train Loss: 0.1217, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9332\n",
      "Epoch 8/10, Train Loss: 0.0781, Accuracy: 0.9436, F1 Micro: 0.9436, F1 Macro: 0.9372\n",
      "Epoch 9/10, Train Loss: 0.072, Accuracy: 0.9248, F1 Micro: 0.9248, F1 Macro: 0.9173\n",
      "Epoch 10/10, Train Loss: 0.0595, Accuracy: 0.9361, F1 Micro: 0.9361, F1 Macro: 0.9288\n",
      "\n",
      "Sentiment analysis accuracy: 0.9511, F1 Micro: 0.9511, F1 Macro: 0.9446\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.93        85\n",
      "    positive       0.98      0.95      0.96       181\n",
      "\n",
      "    accuracy                           0.95       266\n",
      "   macro avg       0.94      0.95      0.94       266\n",
      "weighted avg       0.95      0.95      0.95       266\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9158\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.97      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.88      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.94      0.95      0.94       152\n",
      "    positive       0.86      0.83      0.84        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.86      0.87      0.86       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 136.28209781646729 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.004147589206695557\n",
      "Samples above threshold: 12\n",
      "Acquired samples: 8\n",
      "Sampling duration: 3.4668638706207275 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5279, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3788, Accuracy: 0.9182, F1 Micro: 0.9486, F1 Macro: 0.9449\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2452, Accuracy: 0.9501, F1 Micro: 0.9689, F1 Macro: 0.967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1723, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9745\n",
      "Epoch 5/10, Train Loss: 0.1295, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1042, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9769\n",
      "Epoch 7/10, Train Loss: 0.0807, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9763\n",
      "Epoch 8/10, Train Loss: 0.0591, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9763\n",
      "Epoch 9/10, Train Loss: 0.0531, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9758\n",
      "Epoch 10/10, Train Loss: 0.044, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9754\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.92      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5215, Accuracy: 0.9046, F1 Micro: 0.9046, F1 Macro: 0.8901\n",
      "Epoch 2/10, Train Loss: 0.2223, Accuracy: 0.8931, F1 Micro: 0.8931, F1 Macro: 0.8844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1901, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.9312\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.149, Accuracy: 0.9466, F1 Micro: 0.9466, F1 Macro: 0.9401\n",
      "Epoch 5/10, Train Loss: 0.1146, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9243\n",
      "Epoch 6/10, Train Loss: 0.113, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.9312\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0744, Accuracy: 0.9504, F1 Micro: 0.9504, F1 Macro: 0.9425\n",
      "Epoch 8/10, Train Loss: 0.0842, Accuracy: 0.9198, F1 Micro: 0.9198, F1 Macro: 0.9065\n",
      "Epoch 9/10, Train Loss: 0.0632, Accuracy: 0.9427, F1 Micro: 0.9427, F1 Macro: 0.9353\n",
      "Epoch 10/10, Train Loss: 0.0731, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9279\n",
      "\n",
      "Sentiment analysis accuracy: 0.9504, F1 Micro: 0.9504, F1 Macro: 0.9425\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.92      0.92        83\n",
      "    positive       0.96      0.97      0.96       179\n",
      "\n",
      "    accuracy                           0.95       262\n",
      "   macro avg       0.94      0.94      0.94       262\n",
      "weighted avg       0.95      0.95      0.95       262\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9072\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.97      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.88      0.82        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.86      0.86       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.83      0.71        12\n",
      "     neutral       0.93      0.91      0.92       152\n",
      "    positive       0.80      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.79      0.85      0.81       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 129.23509454727173 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.007244026660919189\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.258329153060913 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5313, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3793, Accuracy: 0.9271, F1 Micro: 0.9549, F1 Macro: 0.9524\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2403, Accuracy: 0.9494, F1 Micro: 0.9684, F1 Macro: 0.9665\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.167, Accuracy: 0.9621, F1 Micro: 0.9764, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1184, Accuracy: 0.9665, F1 Micro: 0.9791, F1 Macro: 0.9779\n",
      "Epoch 6/10, Train Loss: 0.0897, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9766\n",
      "Epoch 7/10, Train Loss: 0.0812, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9739\n",
      "Epoch 8/10, Train Loss: 0.0617, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9744\n",
      "Epoch 9/10, Train Loss: 0.0523, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9775\n",
      "Epoch 10/10, Train Loss: 0.049, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9774\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9791, F1 Macro: 0.9779\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.90      0.97      0.93       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5263, Accuracy: 0.8952, F1 Micro: 0.8952, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2532, Accuracy: 0.9637, F1 Micro: 0.9637, F1 Macro: 0.9596\n",
      "Epoch 3/10, Train Loss: 0.1701, Accuracy: 0.9516, F1 Micro: 0.9516, F1 Macro: 0.9466\n",
      "Epoch 4/10, Train Loss: 0.1193, Accuracy: 0.9395, F1 Micro: 0.9395, F1 Macro: 0.9338\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1131, Accuracy: 0.9637, F1 Micro: 0.9637, F1 Macro: 0.9596\n",
      "Epoch 6/10, Train Loss: 0.0883, Accuracy: 0.9476, F1 Micro: 0.9476, F1 Macro: 0.9417\n",
      "Epoch 7/10, Train Loss: 0.0613, Accuracy: 0.9435, F1 Micro: 0.9435, F1 Macro: 0.938\n",
      "Epoch 8/10, Train Loss: 0.0451, Accuracy: 0.9556, F1 Micro: 0.9556, F1 Macro: 0.9503\n",
      "Epoch 9/10, Train Loss: 0.0506, Accuracy: 0.9435, F1 Micro: 0.9435, F1 Macro: 0.938\n",
      "Epoch 10/10, Train Loss: 0.0419, Accuracy: 0.9315, F1 Micro: 0.9315, F1 Macro: 0.9202\n",
      "\n",
      "Sentiment analysis accuracy: 0.9637, F1 Micro: 0.9637, F1 Macro: 0.9596\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95        82\n",
      "    positive       0.99      0.96      0.97       166\n",
      "\n",
      "    accuracy                           0.96       248\n",
      "   macro avg       0.95      0.97      0.96       248\n",
      "weighted avg       0.97      0.96      0.96       248\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9483, F1 Micro: 0.9483, F1 Macro: 0.8814\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.96      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.89      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.75      0.77        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.87      0.84      0.85       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.92      0.65        12\n",
      "     neutral       0.95      0.93      0.94       152\n",
      "    positive       0.89      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.78      0.87      0.80       216\n",
      "weighted avg       0.91      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.68      0.83      0.75        23\n",
      "     neutral       0.98      0.97      0.97       152\n",
      "    positive       0.89      0.83      0.86        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.85      0.87      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.89      1.00      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 129.6525137424469 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.007798457145690918\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.8697011470794678 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5211, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3731, Accuracy: 0.9241, F1 Micro: 0.9527, F1 Macro: 0.9497\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2358, Accuracy: 0.9546, F1 Micro: 0.9719, F1 Macro: 0.9707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1651, Accuracy: 0.9628, F1 Micro: 0.9769, F1 Macro: 0.9759\n",
      "Epoch 5/10, Train Loss: 0.1183, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.093, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9755\n",
      "Epoch 7/10, Train Loss: 0.0707, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0597, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.978\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0529, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9783\n",
      "Epoch 10/10, Train Loss: 0.0444, Accuracy: 0.9628, F1 Micro: 0.9764, F1 Macro: 0.9742\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9783\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.92      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.48, Accuracy: 0.8993, F1 Micro: 0.8993, F1 Macro: 0.888\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2356, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9334\n",
      "Epoch 3/10, Train Loss: 0.1857, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9263\n",
      "Epoch 4/10, Train Loss: 0.1386, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9224\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1063, Accuracy: 0.9478, F1 Micro: 0.9478, F1 Macro: 0.9397\n",
      "Epoch 6/10, Train Loss: 0.0991, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9323\n",
      "Epoch 7/10, Train Loss: 0.1032, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9212\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0704, Accuracy: 0.959, F1 Micro: 0.959, F1 Macro: 0.9531\n",
      "Epoch 9/10, Train Loss: 0.0651, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9374\n",
      "Epoch 10/10, Train Loss: 0.0588, Accuracy: 0.9478, F1 Micro: 0.9478, F1 Macro: 0.9414\n",
      "\n",
      "Sentiment analysis accuracy: 0.959, F1 Micro: 0.959, F1 Macro: 0.9531\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.94        87\n",
      "    positive       0.97      0.97      0.97       181\n",
      "\n",
      "    accuracy                           0.96       268\n",
      "   macro avg       0.95      0.95      0.95       268\n",
      "weighted avg       0.96      0.96      0.96       268\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9104\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.97      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.87      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.55      0.92      0.69        12\n",
      "     neutral       0.96      0.88      0.92       152\n",
      "    positive       0.77      0.83      0.80        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.76      0.88      0.80       216\n",
      "weighted avg       0.89      0.87      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 138.76531600952148 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.004211711883544923\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.389948606491089 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5285, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3801, Accuracy: 0.9345, F1 Micro: 0.9594, F1 Macro: 0.9573\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2398, Accuracy: 0.9539, F1 Micro: 0.9713, F1 Macro: 0.9697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1632, Accuracy: 0.9658, F1 Micro: 0.9787, F1 Macro: 0.9777\n",
      "Epoch 5/10, Train Loss: 0.1195, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0923, Accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9801\n",
      "Epoch 7/10, Train Loss: 0.0726, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9782\n",
      "Epoch 8/10, Train Loss: 0.0616, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9796\n",
      "Epoch 9/10, Train Loss: 0.051, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9795\n",
      "Epoch 10/10, Train Loss: 0.043, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9796\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9801\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.93      0.95      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5224, Accuracy: 0.9004, F1 Micro: 0.9004, F1 Macro: 0.8892\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2525, Accuracy: 0.9387, F1 Micro: 0.9387, F1 Macro: 0.9298\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1847, Accuracy: 0.954, F1 Micro: 0.954, F1 Macro: 0.9483\n",
      "Epoch 4/10, Train Loss: 0.1269, Accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.9403\n",
      "Epoch 5/10, Train Loss: 0.1207, Accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.9403\n",
      "Epoch 6/10, Train Loss: 0.0988, Accuracy: 0.9425, F1 Micro: 0.9425, F1 Macro: 0.9362\n",
      "Epoch 7/10, Train Loss: 0.1077, Accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.9403\n",
      "Epoch 8/10, Train Loss: 0.0661, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9165\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0576, Accuracy: 0.954, F1 Micro: 0.954, F1 Macro: 0.9486\n",
      "Epoch 10/10, Train Loss: 0.0688, Accuracy: 0.9387, F1 Micro: 0.9387, F1 Macro: 0.9322\n",
      "\n",
      "Sentiment analysis accuracy: 0.954, F1 Micro: 0.954, F1 Macro: 0.9486\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.96      0.93        85\n",
      "    positive       0.98      0.95      0.97       176\n",
      "\n",
      "    accuracy                           0.95       261\n",
      "   macro avg       0.94      0.96      0.95       261\n",
      "weighted avg       0.96      0.95      0.95       261\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9119\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.88      0.82        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.86      0.86       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.56      0.75      0.64        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.84      0.79      0.81        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.78      0.82      0.80       216\n",
      "weighted avg       0.89      0.88      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.94      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 135.05292081832886 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.004514813423156738\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.8712263107299805 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5138, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3663, Accuracy: 0.9278, F1 Micro: 0.9549, F1 Macro: 0.9521\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2404, Accuracy: 0.9568, F1 Micro: 0.9731, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.161, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1144, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.093, Accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9802\n",
      "Epoch 7/10, Train Loss: 0.0721, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9759\n",
      "Epoch 8/10, Train Loss: 0.0599, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9757\n",
      "Epoch 9/10, Train Loss: 0.052, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9771\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0441, Accuracy: 0.971, F1 Micro: 0.9817, F1 Macro: 0.9806\n",
      "\n",
      "Aspect detection accuracy: 0.971, F1 Micro: 0.9817, F1 Macro: 0.9806\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5019, Accuracy: 0.9237, F1 Micro: 0.9237, F1 Macro: 0.914\n",
      "Epoch 2/10, Train Loss: 0.2413, Accuracy: 0.9046, F1 Micro: 0.9046, F1 Macro: 0.8975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1797, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.9312\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1266, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.9312\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0997, Accuracy: 0.9504, F1 Micro: 0.9504, F1 Macro: 0.9448\n",
      "Epoch 6/10, Train Loss: 0.0928, Accuracy: 0.9466, F1 Micro: 0.9466, F1 Macro: 0.9401\n",
      "Epoch 7/10, Train Loss: 0.0913, Accuracy: 0.9427, F1 Micro: 0.9427, F1 Macro: 0.9364\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0657, Accuracy: 0.9504, F1 Micro: 0.9504, F1 Macro: 0.9436\n",
      "Epoch 9/10, Train Loss: 0.0621, Accuracy: 0.9427, F1 Micro: 0.9427, F1 Macro: 0.937\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0519, Accuracy: 0.9504, F1 Micro: 0.9504, F1 Macro: 0.9451\n",
      "\n",
      "Sentiment analysis accuracy: 0.9504, F1 Micro: 0.9504, F1 Macro: 0.9451\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.98      0.93        86\n",
      "    positive       0.99      0.94      0.96       176\n",
      "\n",
      "    accuracy                           0.95       262\n",
      "   macro avg       0.94      0.96      0.95       262\n",
      "weighted avg       0.95      0.95      0.95       262\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9637, F1 Micro: 0.9637, F1 Macro: 0.9308\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.97      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.89      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.92      0.96      0.94       152\n",
      "    positive       0.89      0.81      0.85        52\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.91      0.87      0.89       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.94      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 145.06369018554688 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0034394383430480955\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 8\n",
      "Sampling duration: 1.3783857822418213 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5175, Accuracy: 0.7954, F1 Micro: 0.8853, F1 Macro: 0.8838\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3676, Accuracy: 0.9271, F1 Micro: 0.9545, F1 Macro: 0.9521\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2359, Accuracy: 0.9539, F1 Micro: 0.9712, F1 Macro: 0.9698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1612, Accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9776\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1249, Accuracy: 0.9673, F1 Micro: 0.9796, F1 Macro: 0.9786\n",
      "Epoch 6/10, Train Loss: 0.0965, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9766\n",
      "Epoch 7/10, Train Loss: 0.0738, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0589, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9796\n",
      "Epoch 9/10, Train Loss: 0.054, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9755\n",
      "Epoch 10/10, Train Loss: 0.0417, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9787\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9796\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.92      0.94      0.93       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5184, Accuracy: 0.9, F1 Micro: 0.9, F1 Macro: 0.8907\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2443, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.9092\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1987, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9371\n",
      "Epoch 4/10, Train Loss: 0.1584, Accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.9062\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1241, Accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9411\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1267, Accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9395\n",
      "Epoch 7/10, Train Loss: 0.1129, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9272\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0967, Accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.9443\n",
      "Epoch 9/10, Train Loss: 0.0726, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9364\n",
      "Epoch 10/10, Train Loss: 0.0631, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9368\n",
      "\n",
      "Sentiment analysis accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.9443\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.94      0.93        87\n",
      "    positive       0.97      0.95      0.96       173\n",
      "\n",
      "    accuracy                           0.95       260\n",
      "   macro avg       0.94      0.95      0.94       260\n",
      "weighted avg       0.95      0.95      0.95       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9124\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.88      0.82        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.87      0.87       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.83      0.74        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.80      0.75      0.77        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.80      0.84      0.81       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.98      0.99      0.99       152\n",
      "    positive       1.00      0.78      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.92      0.91       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 145.23403072357178 s\n",
      "Total runtime: 3015.558167219162 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86651d94",
   "metadata": {
    "papermill": {
     "duration": 0.048998,
     "end_time": "2025-03-23T08:37:40.523103",
     "exception": false,
     "start_time": "2025-03-23T08:37:40.474105",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "660887f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T08:37:40.548419Z",
     "iopub.status.busy": "2025-03-23T08:37:40.548091Z",
     "iopub.status.idle": "2025-03-23T09:25:21.650581Z",
     "shell.execute_reply": "2025-03-23T09:25:21.649795Z"
    },
    "papermill": {
     "duration": 2861.116774,
     "end_time": "2025-03-23T09:25:21.652046",
     "exception": false,
     "start_time": "2025-03-23T08:37:40.535272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 3\n",
      "Random seed: 14\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6791, Accuracy: 0.7746, F1 Micro: 0.8722, F1 Macro: 0.8703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5752, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.512, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4609, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4635, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4127, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3898, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4151, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.396, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3746, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "\n",
      "Aspect detection accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.78      1.00      0.88       175\n",
      "      others       0.71      1.00      0.83       158\n",
      "        part       0.71      1.00      0.83       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.79      1.00      0.88      1061\n",
      "   macro avg       0.79      1.00      0.88      1061\n",
      "weighted avg       0.80      1.00      0.89      1061\n",
      " samples avg       0.79      1.00      0.88      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.8159, Accuracy: 0.3333, F1 Micro: 0.3333, F1 Macro: 0.25\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.6264, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5442, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5154, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4038, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3617, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3192, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2942, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3391, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2952, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "\n",
      "Sentiment analysis accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         1\n",
      "    positive       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.67         3\n",
      "   macro avg       0.33      0.50      0.40         3\n",
      "weighted avg       0.44      0.67      0.53         3\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.7909, F1 Micro: 0.7909, F1 Macro: 0.298\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.77      1.00      0.87       167\n",
      "    positive       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.77       216\n",
      "   macro avg       0.26      0.33      0.29       216\n",
      "weighted avg       0.60      0.77      0.67       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.71      1.00      0.83       152\n",
      "    positive       0.67      0.04      0.07        52\n",
      "\n",
      "    accuracy                           0.71       216\n",
      "   macro avg       0.46      0.35      0.30       216\n",
      "weighted avg       0.66      0.71      0.60       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        23\n",
      "     neutral       0.70      1.00      0.83       152\n",
      "    positive       0.00      0.00      0.00        41\n",
      "\n",
      "    accuracy                           0.70       216\n",
      "   macro avg       0.23      0.33      0.28       216\n",
      "weighted avg       0.50      0.70      0.58       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 68.46478080749512 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0542205810546875\n",
      "Samples above threshold: 81\n",
      "Acquired samples: 81\n",
      "Sampling duration: 10.151098489761353 seconds\n",
      "New train size: 135\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6162, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4865, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4476, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4326, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3858, Accuracy: 0.7954, F1 Micro: 0.8853, F1 Macro: 0.8838\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3714, Accuracy: 0.814, F1 Micro: 0.8942, F1 Macro: 0.8926\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3335, Accuracy: 0.8296, F1 Micro: 0.9012, F1 Macro: 0.8993\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2779, Accuracy: 0.8475, F1 Micro: 0.9109, F1 Macro: 0.9093\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2537, Accuracy: 0.8698, F1 Micro: 0.9229, F1 Macro: 0.9214\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2069, Accuracy: 0.8906, F1 Micro: 0.9343, F1 Macro: 0.9325\n",
      "\n",
      "Aspect detection accuracy: 0.8906, F1 Micro: 0.9343, F1 Macro: 0.9325\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.92      1.00      0.96       187\n",
      "     machine       0.89      0.97      0.93       175\n",
      "      others       0.84      0.94      0.89       158\n",
      "        part       0.82      1.00      0.90       158\n",
      "       price       0.90      1.00      0.95       192\n",
      "     service       0.95      1.00      0.97       191\n",
      "\n",
      "   micro avg       0.89      0.99      0.93      1061\n",
      "   macro avg       0.89      0.98      0.93      1061\n",
      "weighted avg       0.89      0.99      0.93      1061\n",
      " samples avg       0.89      0.99      0.93      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6619, Accuracy: 0.6899, F1 Micro: 0.6899, F1 Macro: 0.4082\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5329, Accuracy: 0.6899, F1 Micro: 0.6899, F1 Macro: 0.4082\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4834, Accuracy: 0.7215, F1 Micro: 0.7215, F1 Macro: 0.5225\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.344, Accuracy: 0.7848, F1 Micro: 0.7848, F1 Macro: 0.6744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2693, Accuracy: 0.8418, F1 Micro: 0.8418, F1 Macro: 0.7925\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1667, Accuracy: 0.8608, F1 Micro: 0.8608, F1 Macro: 0.8159\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1172, Accuracy: 0.8608, F1 Micro: 0.8608, F1 Macro: 0.8188\n",
      "Epoch 8/10, Train Loss: 0.077, Accuracy: 0.8544, F1 Micro: 0.8544, F1 Macro: 0.8225\n",
      "Epoch 9/10, Train Loss: 0.0677, Accuracy: 0.8481, F1 Micro: 0.8481, F1 Macro: 0.811\n",
      "Epoch 10/10, Train Loss: 0.0252, Accuracy: 0.8038, F1 Micro: 0.8038, F1 Macro: 0.7184\n",
      "\n",
      "Sentiment analysis accuracy: 0.8608, F1 Micro: 0.8608, F1 Macro: 0.8188\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.61      0.73        49\n",
      "    positive       0.85      0.97      0.91       109\n",
      "\n",
      "    accuracy                           0.86       158\n",
      "   macro avg       0.88      0.79      0.82       158\n",
      "weighted avg       0.87      0.86      0.85       158\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 135: Accuracy: 0.8688, F1 Micro: 0.8688, F1 Macro: 0.6212\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.36      0.53        11\n",
      "     neutral       0.92      1.00      0.96       181\n",
      "    positive       0.80      0.50      0.62        24\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.91      0.62      0.70       216\n",
      "weighted avg       0.91      0.91      0.90       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.31      0.48        16\n",
      "     neutral       0.89      0.97      0.93       167\n",
      "    positive       0.68      0.58      0.62        33\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.85      0.62      0.67       216\n",
      "weighted avg       0.86      0.86      0.85       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.85      0.95      0.89       152\n",
      "    positive       0.66      0.56      0.60        52\n",
      "\n",
      "    accuracy                           0.80       216\n",
      "   macro avg       0.50      0.50      0.50       216\n",
      "weighted avg       0.75      0.80      0.77       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.13      0.23        23\n",
      "     neutral       0.81      1.00      0.90       152\n",
      "    positive       0.77      0.49      0.60        41\n",
      "\n",
      "    accuracy                           0.81       216\n",
      "   macro avg       0.86      0.54      0.57       216\n",
      "weighted avg       0.82      0.81      0.77       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.08      0.14        13\n",
      "     neutral       0.90      1.00      0.95       186\n",
      "    positive       0.56      0.29      0.38        17\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.82      0.46      0.49       216\n",
      "weighted avg       0.88      0.89      0.86       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.50      0.67        14\n",
      "     neutral       0.95      1.00      0.97       185\n",
      "    positive       0.79      0.65      0.71        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.72      0.78       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Total train time: 73.67271399497986 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.031340622901916505\n",
      "Samples above threshold: 73\n",
      "Acquired samples: 73\n",
      "Sampling duration: 11.132732629776001 seconds\n",
      "New train size: 208\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5717, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4656, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4363, Accuracy: 0.7984, F1 Micro: 0.8868, F1 Macro: 0.8854\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4143, Accuracy: 0.8065, F1 Micro: 0.8908, F1 Macro: 0.8898\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3751, Accuracy: 0.8237, F1 Micro: 0.8995, F1 Macro: 0.8985\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3001, Accuracy: 0.8564, F1 Micro: 0.9162, F1 Macro: 0.9148\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2786, Accuracy: 0.8929, F1 Micro: 0.9358, F1 Macro: 0.9339\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2025, Accuracy: 0.907, F1 Micro: 0.9436, F1 Macro: 0.9413\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1771, Accuracy: 0.9196, F1 Micro: 0.9509, F1 Macro: 0.9489\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1431, Accuracy: 0.9263, F1 Micro: 0.9549, F1 Macro: 0.9529\n",
      "\n",
      "Aspect detection accuracy: 0.9263, F1 Micro: 0.9549, F1 Macro: 0.9529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.95      1.00      0.98       187\n",
      "     machine       0.90      0.99      0.94       175\n",
      "      others       0.88      0.94      0.91       158\n",
      "        part       0.86      1.00      0.92       158\n",
      "       price       0.96      1.00      0.98       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.92      0.99      0.95      1061\n",
      "   macro avg       0.92      0.99      0.95      1061\n",
      "weighted avg       0.93      0.99      0.96      1061\n",
      " samples avg       0.93      0.99      0.95      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6528, Accuracy: 0.6734, F1 Micro: 0.6734, F1 Macro: 0.4024\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.506, Accuracy: 0.7839, F1 Micro: 0.7839, F1 Macro: 0.7069\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4324, Accuracy: 0.8291, F1 Micro: 0.8291, F1 Macro: 0.7787\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2244, Accuracy: 0.8794, F1 Micro: 0.8794, F1 Macro: 0.8568\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1563, Accuracy: 0.8945, F1 Micro: 0.8945, F1 Macro: 0.8753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0881, Accuracy: 0.8995, F1 Micro: 0.8995, F1 Macro: 0.8866\n",
      "Epoch 7/10, Train Loss: 0.0865, Accuracy: 0.8945, F1 Micro: 0.8945, F1 Macro: 0.8765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0688, Accuracy: 0.9045, F1 Micro: 0.9045, F1 Macro: 0.8957\n",
      "Epoch 9/10, Train Loss: 0.0166, Accuracy: 0.8744, F1 Micro: 0.8744, F1 Macro: 0.8578\n",
      "Epoch 10/10, Train Loss: 0.0464, Accuracy: 0.8593, F1 Micro: 0.8593, F1 Macro: 0.833\n",
      "\n",
      "Sentiment analysis accuracy: 0.9045, F1 Micro: 0.9045, F1 Macro: 0.8957\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.94      0.87        65\n",
      "    positive       0.97      0.89      0.93       134\n",
      "\n",
      "    accuracy                           0.90       199\n",
      "   macro avg       0.89      0.91      0.90       199\n",
      "weighted avg       0.91      0.90      0.91       199\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 208: Accuracy: 0.9074, F1 Micro: 0.9074, F1 Macro: 0.7822\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.45      0.62        11\n",
      "     neutral       0.96      1.00      0.98       181\n",
      "    positive       0.91      0.83      0.87        24\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.96      0.76      0.82       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.50      0.67        16\n",
      "     neutral       0.90      0.99      0.94       167\n",
      "    positive       0.79      0.58      0.67        33\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.90      0.69      0.76       216\n",
      "weighted avg       0.89      0.89      0.88       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.43      0.50      0.46        12\n",
      "     neutral       0.87      0.94      0.91       152\n",
      "    positive       0.76      0.56      0.64        52\n",
      "\n",
      "    accuracy                           0.82       216\n",
      "   macro avg       0.69      0.67      0.67       216\n",
      "weighted avg       0.82      0.82      0.82       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.35      0.50        23\n",
      "     neutral       0.85      1.00      0.92       152\n",
      "    positive       0.83      0.59      0.69        41\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.86      0.64      0.70       216\n",
      "weighted avg       0.85      0.85      0.83       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.69      0.82        13\n",
      "     neutral       0.96      1.00      0.98       186\n",
      "    positive       0.79      0.65      0.71        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.78      0.84       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.71      0.83        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.87      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 82.44645833969116 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.02188783884048462\n",
      "Samples above threshold: 66\n",
      "Acquired samples: 66\n",
      "Sampling duration: 11.133234739303589 seconds\n",
      "New train size: 274\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5757, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4815, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.426, Accuracy: 0.8036, F1 Micro: 0.8894, F1 Macro: 0.8882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3841, Accuracy: 0.8415, F1 Micro: 0.9087, F1 Macro: 0.9075\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3066, Accuracy: 0.8772, F1 Micro: 0.9277, F1 Macro: 0.9266\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2491, Accuracy: 0.9167, F1 Micro: 0.9492, F1 Macro: 0.9472\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2036, Accuracy: 0.936, F1 Micro: 0.9607, F1 Macro: 0.959\n",
      "Epoch 8/10, Train Loss: 0.1756, Accuracy: 0.9345, F1 Micro: 0.9595, F1 Macro: 0.9571\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1416, Accuracy: 0.942, F1 Micro: 0.9642, F1 Macro: 0.9626\n",
      "Epoch 10/10, Train Loss: 0.119, Accuracy: 0.9412, F1 Micro: 0.9636, F1 Macro: 0.9616\n",
      "\n",
      "Aspect detection accuracy: 0.942, F1 Micro: 0.9642, F1 Macro: 0.9626\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.96      0.99      0.98       187\n",
      "     machine       0.92      0.99      0.95       175\n",
      "      others       0.87      0.95      0.91       158\n",
      "        part       0.92      1.00      0.96       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.94      0.99      0.96      1061\n",
      "   macro avg       0.94      0.99      0.96      1061\n",
      "weighted avg       0.94      0.99      0.96      1061\n",
      " samples avg       0.94      0.99      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6322, Accuracy: 0.6743, F1 Micro: 0.6743, F1 Macro: 0.4027\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4591, Accuracy: 0.8716, F1 Micro: 0.8716, F1 Macro: 0.8373\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2634, Accuracy: 0.9083, F1 Micro: 0.9083, F1 Macro: 0.894\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1159, Accuracy: 0.9404, F1 Micro: 0.9404, F1 Macro: 0.9324\n",
      "Epoch 5/10, Train Loss: 0.0541, Accuracy: 0.9174, F1 Micro: 0.9174, F1 Macro: 0.9038\n",
      "Epoch 6/10, Train Loss: 0.0647, Accuracy: 0.9083, F1 Micro: 0.9083, F1 Macro: 0.8923\n",
      "Epoch 7/10, Train Loss: 0.0471, Accuracy: 0.9128, F1 Micro: 0.9128, F1 Macro: 0.9018\n",
      "Epoch 8/10, Train Loss: 0.0455, Accuracy: 0.8761, F1 Micro: 0.8761, F1 Macro: 0.8486\n",
      "Epoch 9/10, Train Loss: 0.0201, Accuracy: 0.9037, F1 Micro: 0.9037, F1 Macro: 0.8922\n",
      "Epoch 10/10, Train Loss: 0.0159, Accuracy: 0.8807, F1 Micro: 0.8807, F1 Macro: 0.8588\n",
      "\n",
      "Sentiment analysis accuracy: 0.9404, F1 Micro: 0.9404, F1 Macro: 0.9324\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.92      0.91        71\n",
      "    positive       0.96      0.95      0.96       147\n",
      "\n",
      "    accuracy                           0.94       218\n",
      "   macro avg       0.93      0.93      0.93       218\n",
      "weighted avg       0.94      0.94      0.94       218\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 274: Accuracy: 0.9236, F1 Micro: 0.9236, F1 Macro: 0.8238\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.55      0.67        11\n",
      "     neutral       0.97      0.99      0.98       181\n",
      "    positive       0.88      0.88      0.88        24\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.90      0.80      0.84       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.62      0.74        16\n",
      "     neutral       0.92      0.99      0.95       167\n",
      "    positive       0.81      0.64      0.71        33\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.88      0.75      0.80       216\n",
      "weighted avg       0.90      0.91      0.90       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.45      0.75      0.56        12\n",
      "     neutral       0.89      0.93      0.91       152\n",
      "    positive       0.84      0.62      0.71        52\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.73      0.76      0.73       216\n",
      "weighted avg       0.86      0.84      0.84       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.52      0.63        23\n",
      "     neutral       0.92      1.00      0.96       152\n",
      "    positive       0.80      0.68      0.74        41\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.84      0.73      0.77       216\n",
      "weighted avg       0.88      0.89      0.88       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.86      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.71      0.83        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.87      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 78.12012696266174 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.019488614797592164\n",
      "Samples above threshold: 59\n",
      "Acquired samples: 59\n",
      "Sampling duration: 10.511375665664673 seconds\n",
      "New train size: 333\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5762, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4884, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4353, Accuracy: 0.8348, F1 Micro: 0.905, F1 Macro: 0.9042\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3324, Accuracy: 0.8981, F1 Micro: 0.939, F1 Macro: 0.9382\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.25, Accuracy: 0.9271, F1 Micro: 0.9555, F1 Macro: 0.9542\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2098, Accuracy: 0.939, F1 Micro: 0.9624, F1 Macro: 0.9606\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1684, Accuracy: 0.9435, F1 Micro: 0.9652, F1 Macro: 0.9639\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1498, Accuracy: 0.9494, F1 Micro: 0.9687, F1 Macro: 0.9672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1126, Accuracy: 0.9501, F1 Micro: 0.9687, F1 Macro: 0.9664\n",
      "Epoch 10/10, Train Loss: 0.0992, Accuracy: 0.9435, F1 Micro: 0.9646, F1 Macro: 0.9619\n",
      "\n",
      "Aspect detection accuracy: 0.9501, F1 Micro: 0.9687, F1 Macro: 0.9664\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.98       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.93      0.87      0.90       158\n",
      "        part       0.93      1.00      0.97       158\n",
      "       price       0.97      1.00      0.98       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.97      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6064, Accuracy: 0.6838, F1 Micro: 0.6838, F1 Macro: 0.4061\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3957, Accuracy: 0.8775, F1 Micro: 0.8775, F1 Macro: 0.8588\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1976, Accuracy: 0.8814, F1 Micro: 0.8814, F1 Macro: 0.8719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2008, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9245\n",
      "Epoch 5/10, Train Loss: 0.1165, Accuracy: 0.9249, F1 Micro: 0.9249, F1 Macro: 0.9151\n",
      "Epoch 6/10, Train Loss: 0.0978, Accuracy: 0.9012, F1 Micro: 0.9012, F1 Macro: 0.8861\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0866, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9249\n",
      "Epoch 8/10, Train Loss: 0.0485, Accuracy: 0.913, F1 Micro: 0.913, F1 Macro: 0.9008\n",
      "Epoch 9/10, Train Loss: 0.0595, Accuracy: 0.917, F1 Micro: 0.917, F1 Macro: 0.9056\n",
      "Epoch 10/10, Train Loss: 0.056, Accuracy: 0.8972, F1 Micro: 0.8972, F1 Macro: 0.8842\n",
      "\n",
      "Sentiment analysis accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9249\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        80\n",
      "    positive       0.98      0.92      0.95       173\n",
      "\n",
      "    accuracy                           0.93       253\n",
      "   macro avg       0.91      0.94      0.92       253\n",
      "weighted avg       0.94      0.93      0.93       253\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 333: Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.8574\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.82      0.86        11\n",
      "     neutral       0.98      0.99      0.99       181\n",
      "    positive       0.88      0.88      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.89      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.88      0.67      0.76        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.86      0.80      0.82       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.42      0.67      0.52        12\n",
      "     neutral       0.94      0.86      0.90       152\n",
      "    positive       0.70      0.77      0.73        52\n",
      "\n",
      "    accuracy                           0.83       216\n",
      "   macro avg       0.69      0.77      0.72       216\n",
      "weighted avg       0.85      0.83      0.84       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.87      0.83        23\n",
      "     neutral       0.93      1.00      0.97       152\n",
      "    positive       0.93      0.63      0.75        41\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.89      0.83      0.85       216\n",
      "weighted avg       0.92      0.92      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.69      0.82        13\n",
      "     neutral       0.97      1.00      0.98       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.95      0.82      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.96      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 89.8768265247345 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.019055485725402832\n",
      "Samples above threshold: 54\n",
      "Acquired samples: 54\n",
      "Sampling duration: 10.105030298233032 seconds\n",
      "New train size: 387\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5613, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4823, Accuracy: 0.7999, F1 Micro: 0.8875, F1 Macro: 0.8861\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4035, Accuracy: 0.8624, F1 Micro: 0.9195, F1 Macro: 0.9184\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2976, Accuracy: 0.9241, F1 Micro: 0.9535, F1 Macro: 0.9516\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2378, Accuracy: 0.9353, F1 Micro: 0.9599, F1 Macro: 0.9573\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1727, Accuracy: 0.9405, F1 Micro: 0.9629, F1 Macro: 0.9601\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1402, Accuracy: 0.9435, F1 Micro: 0.9649, F1 Macro: 0.963\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1243, Accuracy: 0.9479, F1 Micro: 0.9676, F1 Macro: 0.9657\n",
      "Epoch 9/10, Train Loss: 0.1, Accuracy: 0.9472, F1 Micro: 0.967, F1 Macro: 0.9649\n",
      "Epoch 10/10, Train Loss: 0.0846, Accuracy: 0.9479, F1 Micro: 0.9675, F1 Macro: 0.9653\n",
      "\n",
      "Aspect detection accuracy: 0.9479, F1 Micro: 0.9676, F1 Macro: 0.9657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.97      0.99      0.98       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.90      0.92      0.91       158\n",
      "        part       0.92      1.00      0.96       158\n",
      "       price       0.97      1.00      0.98       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.95      0.98      0.97      1061\n",
      "   macro avg       0.95      0.98      0.97      1061\n",
      "weighted avg       0.95      0.98      0.97      1061\n",
      " samples avg       0.95      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5257, Accuracy: 0.6992, F1 Micro: 0.6992, F1 Macro: 0.4603\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2991, Accuracy: 0.911, F1 Micro: 0.911, F1 Macro: 0.8955\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1486, Accuracy: 0.9364, F1 Micro: 0.9364, F1 Macro: 0.9253\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1062, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9363\n",
      "Epoch 5/10, Train Loss: 0.082, Accuracy: 0.9364, F1 Micro: 0.9364, F1 Macro: 0.9253\n",
      "Epoch 6/10, Train Loss: 0.0853, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9334\n",
      "Epoch 7/10, Train Loss: 0.0448, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9311\n",
      "Epoch 8/10, Train Loss: 0.0607, Accuracy: 0.9322, F1 Micro: 0.9322, F1 Macro: 0.9239\n",
      "Epoch 9/10, Train Loss: 0.0516, Accuracy: 0.9322, F1 Micro: 0.9322, F1 Macro: 0.9218\n",
      "Epoch 10/10, Train Loss: 0.0461, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9178\n",
      "\n",
      "Sentiment analysis accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9363\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.91      0.91        75\n",
      "    positive       0.96      0.96      0.96       161\n",
      "\n",
      "    accuracy                           0.94       236\n",
      "   macro avg       0.94      0.93      0.94       236\n",
      "weighted avg       0.94      0.94      0.94       236\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 387: Accuracy: 0.936, F1 Micro: 0.936, F1 Macro: 0.8686\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.98      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.98      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.85      0.70      0.77        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.81      0.84       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.56      0.75      0.64        12\n",
      "     neutral       0.91      0.90      0.91       152\n",
      "    positive       0.76      0.73      0.75        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.75      0.79      0.77       216\n",
      "weighted avg       0.86      0.85      0.85       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.78      0.78        23\n",
      "     neutral       0.92      1.00      0.96       152\n",
      "    positive       0.93      0.63      0.75        41\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.88      0.81      0.83       216\n",
      "weighted avg       0.91      0.91      0.90       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.86      0.71      0.77        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.89      0.83      0.85       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.96      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 92.6911392211914 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.015164780616760257\n",
      "Samples above threshold: 48\n",
      "Acquired samples: 48\n",
      "Sampling duration: 9.497878789901733 seconds\n",
      "New train size: 435\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5632, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4921, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4055, Accuracy: 0.8757, F1 Micro: 0.9267, F1 Macro: 0.9253\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2939, Accuracy: 0.9271, F1 Micro: 0.9556, F1 Macro: 0.9542\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2191, Accuracy: 0.9479, F1 Micro: 0.9677, F1 Macro: 0.9663\n",
      "Epoch 6/10, Train Loss: 0.1714, Accuracy: 0.9479, F1 Micro: 0.9677, F1 Macro: 0.9659\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1519, Accuracy: 0.9494, F1 Micro: 0.9685, F1 Macro: 0.9664\n",
      "Epoch 8/10, Train Loss: 0.1153, Accuracy: 0.9487, F1 Micro: 0.968, F1 Macro: 0.9658\n",
      "Epoch 9/10, Train Loss: 0.0952, Accuracy: 0.9345, F1 Micro: 0.9588, F1 Macro: 0.9542\n",
      "Epoch 10/10, Train Loss: 0.0806, Accuracy: 0.9375, F1 Micro: 0.9607, F1 Macro: 0.9566\n",
      "\n",
      "Aspect detection accuracy: 0.9494, F1 Micro: 0.9685, F1 Macro: 0.9664\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.93      1.00      0.96       175\n",
      "      others       0.91      0.91      0.91       158\n",
      "        part       0.93      0.99      0.96       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.95      0.98      0.97      1061\n",
      "   macro avg       0.95      0.98      0.97      1061\n",
      "weighted avg       0.95      0.98      0.97      1061\n",
      " samples avg       0.95      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.523, Accuracy: 0.7125, F1 Micro: 0.7125, F1 Macro: 0.4663\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.289, Accuracy: 0.8875, F1 Micro: 0.8875, F1 Macro: 0.8753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2003, Accuracy: 0.9208, F1 Micro: 0.9208, F1 Macro: 0.9075\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1117, Accuracy: 0.9292, F1 Micro: 0.9292, F1 Macro: 0.9179\n",
      "Epoch 5/10, Train Loss: 0.1258, Accuracy: 0.925, F1 Micro: 0.925, F1 Macro: 0.914\n",
      "Epoch 6/10, Train Loss: 0.0921, Accuracy: 0.925, F1 Micro: 0.925, F1 Macro: 0.914\n",
      "Epoch 7/10, Train Loss: 0.039, Accuracy: 0.9083, F1 Micro: 0.9083, F1 Macro: 0.8909\n",
      "Epoch 8/10, Train Loss: 0.0662, Accuracy: 0.9208, F1 Micro: 0.9208, F1 Macro: 0.9061\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0614, Accuracy: 0.9292, F1 Micro: 0.9292, F1 Macro: 0.9201\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0383, Accuracy: 0.9292, F1 Micro: 0.9292, F1 Macro: 0.9185\n",
      "\n",
      "Sentiment analysis accuracy: 0.9292, F1 Micro: 0.9292, F1 Macro: 0.9185\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.93      0.89        73\n",
      "    positive       0.97      0.93      0.95       167\n",
      "\n",
      "    accuracy                           0.93       240\n",
      "   macro avg       0.91      0.93      0.92       240\n",
      "weighted avg       0.93      0.93      0.93       240\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 435: Accuracy: 0.9275, F1 Micro: 0.9275, F1 Macro: 0.8614\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.98      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.56      0.64        16\n",
      "     neutral       0.93      0.99      0.96       167\n",
      "    positive       0.88      0.70      0.78        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.86      0.75      0.79       216\n",
      "weighted avg       0.91      0.92      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.29      0.83      0.43        12\n",
      "     neutral       0.92      0.80      0.86       152\n",
      "    positive       0.74      0.71      0.73        52\n",
      "\n",
      "    accuracy                           0.78       216\n",
      "   macro avg       0.65      0.78      0.67       216\n",
      "weighted avg       0.84      0.78      0.80       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.83      0.84        23\n",
      "     neutral       0.93      0.99      0.96       152\n",
      "    positive       0.97      0.73      0.83        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.92      0.85      0.88       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.97      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.84      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.96      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 93.6566972732544 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.014304995536804197\n",
      "Samples above threshold: 43\n",
      "Acquired samples: 43\n",
      "Sampling duration: 8.690244197845459 seconds\n",
      "New train size: 478\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5538, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4766, Accuracy: 0.8103, F1 Micro: 0.8927, F1 Macro: 0.8915\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3792, Accuracy: 0.8966, F1 Micro: 0.9382, F1 Macro: 0.9371\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.259, Accuracy: 0.9397, F1 Micro: 0.963, F1 Macro: 0.9613\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.203, Accuracy: 0.9516, F1 Micro: 0.97, F1 Macro: 0.9684\n",
      "Epoch 6/10, Train Loss: 0.1463, Accuracy: 0.9472, F1 Micro: 0.967, F1 Macro: 0.9645\n",
      "Epoch 7/10, Train Loss: 0.1228, Accuracy: 0.9516, F1 Micro: 0.9698, F1 Macro: 0.9678\n",
      "Epoch 8/10, Train Loss: 0.0907, Accuracy: 0.9501, F1 Micro: 0.9688, F1 Macro: 0.9665\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0841, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9723\n",
      "Epoch 10/10, Train Loss: 0.0699, Accuracy: 0.9472, F1 Micro: 0.9669, F1 Macro: 0.9641\n",
      "\n",
      "Aspect detection accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9723\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.91      0.92      0.91       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5422, Accuracy: 0.8254, F1 Micro: 0.8254, F1 Macro: 0.7672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3569, Accuracy: 0.9206, F1 Micro: 0.9206, F1 Macro: 0.9117\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1834, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.926\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1127, Accuracy: 0.9524, F1 Micro: 0.9524, F1 Macro: 0.947\n",
      "Epoch 5/10, Train Loss: 0.1243, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9316\n",
      "Epoch 6/10, Train Loss: 0.0794, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9328\n",
      "Epoch 7/10, Train Loss: 0.0968, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8823\n",
      "Epoch 8/10, Train Loss: 0.0807, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.917\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0832, Accuracy: 0.9603, F1 Micro: 0.9603, F1 Macro: 0.9554\n",
      "Epoch 10/10, Train Loss: 0.054, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9164\n",
      "\n",
      "Sentiment analysis accuracy: 0.9603, F1 Micro: 0.9603, F1 Macro: 0.9554\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.96      0.94        82\n",
      "    positive       0.98      0.96      0.97       170\n",
      "\n",
      "    accuracy                           0.96       252\n",
      "   macro avg       0.95      0.96      0.96       252\n",
      "weighted avg       0.96      0.96      0.96       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 478: Accuracy: 0.9383, F1 Micro: 0.9383, F1 Macro: 0.8672\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.92      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.88      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.69      0.71        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.85      0.80      0.82       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.39      0.58      0.47        12\n",
      "     neutral       0.91      0.87      0.89       152\n",
      "    positive       0.72      0.73      0.72        52\n",
      "\n",
      "    accuracy                           0.82       216\n",
      "   macro avg       0.67      0.73      0.69       216\n",
      "weighted avg       0.83      0.82      0.83       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.90      0.85      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.92      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.69      0.82        13\n",
      "     neutral       0.97      1.00      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.84      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.96      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 96.50887155532837 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.011505305767059326\n",
      "Samples above threshold: 39\n",
      "Acquired samples: 39\n",
      "Sampling duration: 8.025382995605469 seconds\n",
      "New train size: 517\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5632, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4605, Accuracy: 0.8237, F1 Micro: 0.8993, F1 Macro: 0.898\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3307, Accuracy: 0.9263, F1 Micro: 0.9549, F1 Macro: 0.9532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2341, Accuracy: 0.9315, F1 Micro: 0.9576, F1 Macro: 0.9545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1701, Accuracy: 0.9412, F1 Micro: 0.9632, F1 Macro: 0.96\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1414, Accuracy: 0.9464, F1 Micro: 0.9665, F1 Macro: 0.9637\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1097, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0922, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.973\n",
      "Epoch 9/10, Train Loss: 0.0747, Accuracy: 0.9427, F1 Micro: 0.9638, F1 Macro: 0.9598\n",
      "Epoch 10/10, Train Loss: 0.0642, Accuracy: 0.9539, F1 Micro: 0.9711, F1 Macro: 0.969\n",
      "\n",
      "Aspect detection accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.973\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.90      0.94      0.92       158\n",
      "        part       0.95      1.00      0.97       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.97      1061\n",
      "   macro avg       0.96      0.99      0.97      1061\n",
      "weighted avg       0.96      0.99      0.97      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5143, Accuracy: 0.8848, F1 Micro: 0.8848, F1 Macro: 0.8595\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2628, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9183\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1766, Accuracy: 0.9424, F1 Micro: 0.9424, F1 Macro: 0.9339\n",
      "Epoch 4/10, Train Loss: 0.1233, Accuracy: 0.9383, F1 Micro: 0.9383, F1 Macro: 0.9299\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0946, Accuracy: 0.9465, F1 Micro: 0.9465, F1 Macro: 0.9404\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1154, Accuracy: 0.9465, F1 Micro: 0.9465, F1 Macro: 0.94\n",
      "Epoch 7/10, Train Loss: 0.0634, Accuracy: 0.9383, F1 Micro: 0.9383, F1 Macro: 0.9299\n",
      "Epoch 8/10, Train Loss: 0.0734, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9189\n",
      "Epoch 9/10, Train Loss: 0.0519, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.92\n",
      "Epoch 10/10, Train Loss: 0.0949, Accuracy: 0.9342, F1 Micro: 0.9342, F1 Macro: 0.9268\n",
      "\n",
      "Sentiment analysis accuracy: 0.9465, F1 Micro: 0.9465, F1 Macro: 0.94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        78\n",
      "    positive       0.98      0.94      0.96       165\n",
      "\n",
      "    accuracy                           0.95       243\n",
      "   macro avg       0.93      0.95      0.94       243\n",
      "weighted avg       0.95      0.95      0.95       243\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 517: Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.8795\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.91      0.88      0.89        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.81      0.79        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.87      0.86      0.86       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.45      0.83      0.59        12\n",
      "     neutral       0.92      0.90      0.91       152\n",
      "    positive       0.82      0.71      0.76        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.73      0.82      0.75       216\n",
      "weighted avg       0.87      0.85      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.96      0.86        23\n",
      "     neutral       0.95      0.99      0.97       152\n",
      "    positive       1.00      0.71      0.83        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.89      0.89       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.97      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.84      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 104.45865869522095 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.010558152198791507\n",
      "Samples above threshold: 35\n",
      "Acquired samples: 23\n",
      "Sampling duration: 7.967884540557861 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5578, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4541, Accuracy: 0.8229, F1 Micro: 0.8991, F1 Macro: 0.8979\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3335, Accuracy: 0.9241, F1 Micro: 0.9538, F1 Macro: 0.9527\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.233, Accuracy: 0.9516, F1 Micro: 0.9701, F1 Macro: 0.9689\n",
      "Epoch 5/10, Train Loss: 0.1699, Accuracy: 0.9494, F1 Micro: 0.9687, F1 Macro: 0.9671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1312, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9735\n",
      "Epoch 7/10, Train Loss: 0.1103, Accuracy: 0.9479, F1 Micro: 0.9674, F1 Macro: 0.9645\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0922, Accuracy: 0.9621, F1 Micro: 0.9763, F1 Macro: 0.9752\n",
      "Epoch 9/10, Train Loss: 0.0734, Accuracy: 0.9554, F1 Micro: 0.972, F1 Macro: 0.9701\n",
      "Epoch 10/10, Train Loss: 0.0688, Accuracy: 0.9561, F1 Micro: 0.9725, F1 Macro: 0.9708\n",
      "\n",
      "Aspect detection accuracy: 0.9621, F1 Micro: 0.9763, F1 Macro: 0.9752\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.90      0.96      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.98      1061\n",
      "weighted avg       0.96      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5063, Accuracy: 0.8776, F1 Micro: 0.8776, F1 Macro: 0.8473\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2962, Accuracy: 0.9469, F1 Micro: 0.9469, F1 Macro: 0.9387\n",
      "Epoch 3/10, Train Loss: 0.2068, Accuracy: 0.9224, F1 Micro: 0.9224, F1 Macro: 0.9097\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1268, Accuracy: 0.9469, F1 Micro: 0.9469, F1 Macro: 0.9406\n",
      "Epoch 5/10, Train Loss: 0.142, Accuracy: 0.9429, F1 Micro: 0.9429, F1 Macro: 0.9362\n",
      "Epoch 6/10, Train Loss: 0.0912, Accuracy: 0.9429, F1 Micro: 0.9429, F1 Macro: 0.9366\n",
      "Epoch 7/10, Train Loss: 0.0653, Accuracy: 0.9429, F1 Micro: 0.9429, F1 Macro: 0.9346\n",
      "Epoch 8/10, Train Loss: 0.0757, Accuracy: 0.9388, F1 Micro: 0.9388, F1 Macro: 0.9302\n",
      "Epoch 9/10, Train Loss: 0.0817, Accuracy: 0.9306, F1 Micro: 0.9306, F1 Macro: 0.9209\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.059, Accuracy: 0.951, F1 Micro: 0.951, F1 Macro: 0.9453\n",
      "\n",
      "Sentiment analysis accuracy: 0.951, F1 Micro: 0.951, F1 Macro: 0.9453\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.97      0.93        79\n",
      "    positive       0.99      0.94      0.96       166\n",
      "\n",
      "    accuracy                           0.95       245\n",
      "   macro avg       0.94      0.96      0.95       245\n",
      "weighted avg       0.95      0.95      0.95       245\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.8981\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.84      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.45      0.75      0.56        12\n",
      "     neutral       0.91      0.91      0.91       152\n",
      "    positive       0.86      0.71      0.78        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.74      0.79      0.75       216\n",
      "weighted avg       0.87      0.86      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.93      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.87      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.96      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 101.3487982749939 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.010596752166748047\n",
      "Samples above threshold: 33\n",
      "Acquired samples: 33\n",
      "Sampling duration: 7.131421089172363 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5503, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4667, Accuracy: 0.846, F1 Micro: 0.9107, F1 Macro: 0.9095\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3423, Accuracy: 0.9301, F1 Micro: 0.9572, F1 Macro: 0.9558\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2278, Accuracy: 0.9524, F1 Micro: 0.9705, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1762, Accuracy: 0.9568, F1 Micro: 0.9732, F1 Macro: 0.9718\n",
      "Epoch 6/10, Train Loss: 0.1301, Accuracy: 0.9509, F1 Micro: 0.9692, F1 Macro: 0.9666\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1064, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9748\n",
      "Epoch 8/10, Train Loss: 0.0854, Accuracy: 0.9509, F1 Micro: 0.9691, F1 Macro: 0.9665\n",
      "Epoch 9/10, Train Loss: 0.0715, Accuracy: 0.9516, F1 Micro: 0.9696, F1 Macro: 0.9672\n",
      "Epoch 10/10, Train Loss: 0.0607, Accuracy: 0.9554, F1 Micro: 0.972, F1 Macro: 0.9701\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9748\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      1.00      0.97       175\n",
      "      others       0.89      0.96      0.92       158\n",
      "        part       0.99      0.98      0.98       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.97      1061\n",
      "weighted avg       0.96      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.489, Accuracy: 0.7418, F1 Micro: 0.7418, F1 Macro: 0.5883\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2926, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9313\n",
      "Epoch 3/10, Train Loss: 0.1571, Accuracy: 0.9303, F1 Micro: 0.9303, F1 Macro: 0.9226\n",
      "Epoch 4/10, Train Loss: 0.1544, Accuracy: 0.9262, F1 Micro: 0.9262, F1 Macro: 0.9183\n",
      "Epoch 5/10, Train Loss: 0.1343, Accuracy: 0.9262, F1 Micro: 0.9262, F1 Macro: 0.9192\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1539, Accuracy: 0.9467, F1 Micro: 0.9467, F1 Macro: 0.9408\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1185, Accuracy: 0.959, F1 Micro: 0.959, F1 Macro: 0.9541\n",
      "Epoch 8/10, Train Loss: 0.1029, Accuracy: 0.9262, F1 Micro: 0.9262, F1 Macro: 0.9152\n",
      "Epoch 9/10, Train Loss: 0.0682, Accuracy: 0.9221, F1 Micro: 0.9221, F1 Macro: 0.9102\n",
      "Epoch 10/10, Train Loss: 0.0645, Accuracy: 0.9467, F1 Micro: 0.9467, F1 Macro: 0.9401\n",
      "\n",
      "Sentiment analysis accuracy: 0.959, F1 Micro: 0.959, F1 Macro: 0.9541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94        79\n",
      "    positive       0.99      0.95      0.97       165\n",
      "\n",
      "    accuracy                           0.96       244\n",
      "   macro avg       0.95      0.96      0.95       244\n",
      "weighted avg       0.96      0.96      0.96       244\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.8837\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.75      0.71        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.85      0.82      0.83       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.45      0.75      0.56        12\n",
      "     neutral       0.91      0.91      0.91       152\n",
      "    positive       0.86      0.71      0.78        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.74      0.79      0.75       216\n",
      "weighted avg       0.87      0.86      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.99      0.98      0.98       152\n",
      "    positive       0.95      0.88      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.95      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.97      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.84      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.93      0.90        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.94      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 104.96196031570435 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.011296331882476807\n",
      "Samples above threshold: 30\n",
      "Acquired samples: 30\n",
      "Sampling duration: 6.643237352371216 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.545, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4457, Accuracy: 0.8661, F1 Micro: 0.9214, F1 Macro: 0.9202\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3055, Accuracy: 0.9427, F1 Micro: 0.9648, F1 Macro: 0.9633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2149, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1558, Accuracy: 0.9613, F1 Micro: 0.976, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1292, Accuracy: 0.9673, F1 Micro: 0.9796, F1 Macro: 0.9787\n",
      "Epoch 7/10, Train Loss: 0.0957, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9722\n",
      "Epoch 8/10, Train Loss: 0.081, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9762\n",
      "Epoch 9/10, Train Loss: 0.0684, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9716\n",
      "Epoch 10/10, Train Loss: 0.0593, Accuracy: 0.9561, F1 Micro: 0.9723, F1 Macro: 0.9699\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9796, F1 Macro: 0.9787\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      1.00      0.97       175\n",
      "      others       0.90      0.98      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4719, Accuracy: 0.8765, F1 Micro: 0.8765, F1 Macro: 0.852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2351, Accuracy: 0.9383, F1 Micro: 0.9383, F1 Macro: 0.9294\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1645, Accuracy: 0.9588, F1 Micro: 0.9588, F1 Macro: 0.954\n",
      "Epoch 4/10, Train Loss: 0.1296, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9241\n",
      "Epoch 5/10, Train Loss: 0.1103, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9241\n",
      "Epoch 6/10, Train Loss: 0.1208, Accuracy: 0.9547, F1 Micro: 0.9547, F1 Macro: 0.9492\n",
      "Epoch 7/10, Train Loss: 0.0885, Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.9444\n",
      "Epoch 8/10, Train Loss: 0.0718, Accuracy: 0.9465, F1 Micro: 0.9465, F1 Macro: 0.9407\n",
      "Epoch 9/10, Train Loss: 0.0622, Accuracy: 0.9547, F1 Micro: 0.9547, F1 Macro: 0.9501\n",
      "Epoch 10/10, Train Loss: 0.0424, Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.9448\n",
      "\n",
      "Sentiment analysis accuracy: 0.9588, F1 Micro: 0.9588, F1 Macro: 0.954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.95      0.94        81\n",
      "    positive       0.97      0.96      0.97       162\n",
      "\n",
      "    accuracy                           0.96       243\n",
      "   macro avg       0.95      0.96      0.95       243\n",
      "weighted avg       0.96      0.96      0.96       243\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9452, F1 Micro: 0.9452, F1 Macro: 0.8905\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.75      0.73        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.86      0.82      0.84       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.31      0.92      0.46        12\n",
      "     neutral       0.94      0.86      0.90       152\n",
      "    positive       0.93      0.71      0.80        52\n",
      "\n",
      "    accuracy                           0.83       216\n",
      "   macro avg       0.72      0.83      0.72       216\n",
      "weighted avg       0.90      0.83      0.85       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.96      0.94        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.92      0.88      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.89      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 104.75637888908386 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.01183396577835083\n",
      "Samples above threshold: 27\n",
      "Acquired samples: 27\n",
      "Sampling duration: 6.058818101882935 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5497, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4376, Accuracy: 0.8906, F1 Micro: 0.935, F1 Macro: 0.934\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2998, Accuracy: 0.9397, F1 Micro: 0.9629, F1 Macro: 0.9614\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2119, Accuracy: 0.9516, F1 Micro: 0.9699, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1555, Accuracy: 0.965, F1 Micro: 0.9782, F1 Macro: 0.9772\n",
      "Epoch 6/10, Train Loss: 0.1205, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9742\n",
      "Epoch 7/10, Train Loss: 0.0981, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9711\n",
      "Epoch 8/10, Train Loss: 0.0791, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9737\n",
      "Epoch 9/10, Train Loss: 0.0645, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9719\n",
      "Epoch 10/10, Train Loss: 0.0513, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9733\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.9782, F1 Macro: 0.9772\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      1.00      0.97       175\n",
      "      others       0.89      0.97      0.93       158\n",
      "        part       0.96      1.00      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.96      1.00      0.98      1061\n",
      "   macro avg       0.96      0.99      0.98      1061\n",
      "weighted avg       0.96      1.00      0.98      1061\n",
      " samples avg       0.96      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5102, Accuracy: 0.7521, F1 Micro: 0.7521, F1 Macro: 0.6238\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.261, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9349\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1427, Accuracy: 0.9622, F1 Micro: 0.9622, F1 Macro: 0.9578\n",
      "Epoch 4/10, Train Loss: 0.1504, Accuracy: 0.9454, F1 Micro: 0.9454, F1 Macro: 0.94\n",
      "Epoch 5/10, Train Loss: 0.1043, Accuracy: 0.9496, F1 Micro: 0.9496, F1 Macro: 0.942\n",
      "Epoch 6/10, Train Loss: 0.0964, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9216\n",
      "Epoch 7/10, Train Loss: 0.104, Accuracy: 0.9538, F1 Micro: 0.9538, F1 Macro: 0.9484\n",
      "Epoch 8/10, Train Loss: 0.0907, Accuracy: 0.9538, F1 Micro: 0.9538, F1 Macro: 0.9477\n",
      "Epoch 9/10, Train Loss: 0.0662, Accuracy: 0.9496, F1 Micro: 0.9496, F1 Macro: 0.942\n",
      "Epoch 10/10, Train Loss: 0.0486, Accuracy: 0.9538, F1 Micro: 0.9538, F1 Macro: 0.949\n",
      "\n",
      "Sentiment analysis accuracy: 0.9622, F1 Micro: 0.9622, F1 Macro: 0.9578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.94        79\n",
      "    positive       0.98      0.96      0.97       159\n",
      "\n",
      "    accuracy                           0.96       238\n",
      "   macro avg       0.95      0.96      0.96       238\n",
      "weighted avg       0.96      0.96      0.96       238\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9034\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.81      0.79        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.96      0.73      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.84      0.86       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.47      0.75      0.58        12\n",
      "     neutral       0.90      0.93      0.92       152\n",
      "    positive       0.90      0.67      0.77        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.76      0.79      0.76       216\n",
      "weighted avg       0.87      0.86      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.83      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.93      0.92       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.89      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 105.94899773597717 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.013571321964263918\n",
      "Samples above threshold: 24\n",
      "Acquired samples: 18\n",
      "Sampling duration: 5.5598061084747314 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5442, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4366, Accuracy: 0.8914, F1 Micro: 0.9353, F1 Macro: 0.9338\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.279, Accuracy: 0.9487, F1 Micro: 0.9684, F1 Macro: 0.9674\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1866, Accuracy: 0.9576, F1 Micro: 0.9738, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1438, Accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9775\n",
      "Epoch 6/10, Train Loss: 0.113, Accuracy: 0.9546, F1 Micro: 0.9715, F1 Macro: 0.9691\n",
      "Epoch 7/10, Train Loss: 0.0958, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9768\n",
      "Epoch 8/10, Train Loss: 0.0696, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9736\n",
      "Epoch 9/10, Train Loss: 0.0604, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9765\n",
      "Epoch 10/10, Train Loss: 0.0503, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9735\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9775\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      1.00      0.97       175\n",
      "      others       0.91      0.96      0.93       158\n",
      "        part       0.97      1.00      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5012, Accuracy: 0.8934, F1 Micro: 0.8934, F1 Macro: 0.8758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2149, Accuracy: 0.9508, F1 Micro: 0.9508, F1 Macro: 0.9449\n",
      "Epoch 3/10, Train Loss: 0.1546, Accuracy: 0.9467, F1 Micro: 0.9467, F1 Macro: 0.9412\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1575, Accuracy: 0.9631, F1 Micro: 0.9631, F1 Macro: 0.958\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1277, Accuracy: 0.9672, F1 Micro: 0.9672, F1 Macro: 0.9628\n",
      "Epoch 6/10, Train Loss: 0.0981, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9325\n",
      "Epoch 7/10, Train Loss: 0.1016, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9317\n",
      "Epoch 8/10, Train Loss: 0.0831, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9325\n",
      "Epoch 9/10, Train Loss: 0.0683, Accuracy: 0.9549, F1 Micro: 0.9549, F1 Macro: 0.9496\n",
      "Epoch 10/10, Train Loss: 0.0309, Accuracy: 0.959, F1 Micro: 0.959, F1 Macro: 0.9538\n",
      "\n",
      "Sentiment analysis accuracy: 0.9672, F1 Micro: 0.9672, F1 Macro: 0.9628\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.95      0.95        80\n",
      "    positive       0.98      0.98      0.98       164\n",
      "\n",
      "    accuracy                           0.97       244\n",
      "   macro avg       0.96      0.96      0.96       244\n",
      "weighted avg       0.97      0.97      0.97       244\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.8988\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.93      0.79      0.85        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.84      0.87       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.43      0.75      0.55        12\n",
      "     neutral       0.93      0.92      0.93       152\n",
      "    positive       0.87      0.75      0.80        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.74      0.81      0.76       216\n",
      "weighted avg       0.89      0.87      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.91      0.87        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.85      0.92        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.92      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.87      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 107.17675161361694 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.011392802000045776\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.370569705963135 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5407, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4142, Accuracy: 0.8943, F1 Micro: 0.9369, F1 Macro: 0.9357\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2845, Accuracy: 0.9457, F1 Micro: 0.9663, F1 Macro: 0.9646\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1817, Accuracy: 0.9598, F1 Micro: 0.975, F1 Macro: 0.9739\n",
      "Epoch 5/10, Train Loss: 0.1422, Accuracy: 0.9598, F1 Micro: 0.975, F1 Macro: 0.9734\n",
      "Epoch 6/10, Train Loss: 0.1106, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0866, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9782\n",
      "Epoch 8/10, Train Loss: 0.0701, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9772\n",
      "Epoch 9/10, Train Loss: 0.0546, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9713\n",
      "Epoch 10/10, Train Loss: 0.0485, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9769\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9782\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.97      1.00      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4841, Accuracy: 0.8984, F1 Micro: 0.8984, F1 Macro: 0.888\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.209, Accuracy: 0.9297, F1 Micro: 0.9297, F1 Macro: 0.9221\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1667, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9387\n",
      "Epoch 4/10, Train Loss: 0.1621, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9262\n",
      "Epoch 5/10, Train Loss: 0.1803, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9349\n",
      "Epoch 6/10, Train Loss: 0.1263, Accuracy: 0.9219, F1 Micro: 0.9219, F1 Macro: 0.9103\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0889, Accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9429\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0729, Accuracy: 0.9609, F1 Micro: 0.9609, F1 Macro: 0.9549\n",
      "Epoch 9/10, Train Loss: 0.1024, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9311\n",
      "Epoch 10/10, Train Loss: 0.0544, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9384\n",
      "\n",
      "Sentiment analysis accuracy: 0.9609, F1 Micro: 0.9609, F1 Macro: 0.9549\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.92      0.94        83\n",
      "    positive       0.96      0.98      0.97       173\n",
      "\n",
      "    accuracy                           0.96       256\n",
      "   macro avg       0.96      0.95      0.95       256\n",
      "weighted avg       0.96      0.96      0.96       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9098\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.91      0.88      0.89        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.58      0.92      0.71        12\n",
      "     neutral       0.95      0.92      0.93       152\n",
      "    positive       0.86      0.81      0.83        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.79      0.88      0.82       216\n",
      "weighted avg       0.90      0.89      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.87      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 116.4825348854065 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.008405923843383789\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.935887098312378 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5435, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.429, Accuracy: 0.9062, F1 Micro: 0.9425, F1 Macro: 0.9403\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2731, Accuracy: 0.9539, F1 Micro: 0.9715, F1 Macro: 0.9701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.181, Accuracy: 0.9635, F1 Micro: 0.9773, F1 Macro: 0.9765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1356, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9775\n",
      "Epoch 6/10, Train Loss: 0.1001, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9748\n",
      "Epoch 7/10, Train Loss: 0.0867, Accuracy: 0.9539, F1 Micro: 0.9708, F1 Macro: 0.968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0725, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.978\n",
      "Epoch 9/10, Train Loss: 0.0579, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9776\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0521, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9793\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.95      0.93       158\n",
      "        part       0.99      0.99      0.99       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4978, Accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.8938\n",
      "Epoch 2/10, Train Loss: 0.2682, Accuracy: 0.9038, F1 Micro: 0.9038, F1 Macro: 0.8961\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.904\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1347, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.8998\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1149, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9239\n",
      "Epoch 6/10, Train Loss: 0.1016, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.902\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0947, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9239\n",
      "Epoch 8/10, Train Loss: 0.0883, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9199\n",
      "Epoch 9/10, Train Loss: 0.063, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9159\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0517, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9235\n",
      "\n",
      "Sentiment analysis accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9235\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.96      0.90        84\n",
      "    positive       0.98      0.91      0.95       176\n",
      "\n",
      "    accuracy                           0.93       260\n",
      "   macro avg       0.91      0.94      0.92       260\n",
      "weighted avg       0.94      0.93      0.93       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.9101\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.83      0.73      0.77        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.86      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.75      0.72        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.87      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.83      0.82      0.82       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.99      0.99      0.99       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.93      0.93       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 123.50066685676575 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.005027413368225098\n",
      "Samples above threshold: 17\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.60373592376709 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5406, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4276, Accuracy: 0.9092, F1 Micro: 0.9453, F1 Macro: 0.9437\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2625, Accuracy: 0.9546, F1 Micro: 0.9719, F1 Macro: 0.9708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1775, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1257, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.106, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.978\n",
      "Epoch 7/10, Train Loss: 0.0816, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9764\n",
      "Epoch 8/10, Train Loss: 0.0694, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9769\n",
      "Epoch 9/10, Train Loss: 0.0557, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.047, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9787\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9787\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.94      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4639, Accuracy: 0.9112, F1 Micro: 0.9112, F1 Macro: 0.9013\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2261, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9241\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1635, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9266\n",
      "Epoch 4/10, Train Loss: 0.1283, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9157\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1233, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9274\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0959, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9262\n",
      "Epoch 7/10, Train Loss: 0.0886, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.8998\n",
      "Epoch 8/10, Train Loss: 0.0793, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9217\n",
      "Epoch 9/10, Train Loss: 0.0505, Accuracy: 0.9189, F1 Micro: 0.9189, F1 Macro: 0.9113\n",
      "Epoch 10/10, Train Loss: 0.0546, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9193\n",
      "\n",
      "Sentiment analysis accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9262\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.92      0.90        85\n",
      "    positive       0.96      0.94      0.95       174\n",
      "\n",
      "    accuracy                           0.93       259\n",
      "   macro avg       0.92      0.93      0.93       259\n",
      "weighted avg       0.94      0.93      0.93       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9076\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.91      0.88      0.89        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.86      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.75      0.69        12\n",
      "     neutral       0.94      0.95      0.94       152\n",
      "    positive       0.83      0.77      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.80      0.82      0.81       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.83      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.89      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 124.10591292381287 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.003960013389587402\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 25\n",
      "Sampling duration: 6.246513843536377 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5392, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4267, Accuracy: 0.8914, F1 Micro: 0.9353, F1 Macro: 0.9337\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2765, Accuracy: 0.9524, F1 Micro: 0.9706, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1787, Accuracy: 0.9643, F1 Micro: 0.9777, F1 Macro: 0.9764\n",
      "Epoch 5/10, Train Loss: 0.1301, Accuracy: 0.9568, F1 Micro: 0.9728, F1 Macro: 0.9709\n",
      "Epoch 6/10, Train Loss: 0.0962, Accuracy: 0.9576, F1 Micro: 0.9732, F1 Macro: 0.9708\n",
      "Epoch 7/10, Train Loss: 0.082, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9751\n",
      "Epoch 8/10, Train Loss: 0.0652, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0573, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9768\n",
      "Epoch 10/10, Train Loss: 0.0493, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9736\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.92      0.92       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4893, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8869\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2311, Accuracy: 0.9361, F1 Micro: 0.9361, F1 Macro: 0.9284\n",
      "Epoch 3/10, Train Loss: 0.195, Accuracy: 0.9248, F1 Micro: 0.9248, F1 Macro: 0.9151\n",
      "Epoch 4/10, Train Loss: 0.1617, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.883\n",
      "Epoch 5/10, Train Loss: 0.1275, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9213\n",
      "Epoch 6/10, Train Loss: 0.1147, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9191\n",
      "Epoch 7/10, Train Loss: 0.1048, Accuracy: 0.9211, F1 Micro: 0.9211, F1 Macro: 0.9134\n",
      "Epoch 8/10, Train Loss: 0.0768, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9213\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0653, Accuracy: 0.9361, F1 Micro: 0.9361, F1 Macro: 0.9288\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0582, Accuracy: 0.9361, F1 Micro: 0.9361, F1 Macro: 0.9284\n",
      "\n",
      "Sentiment analysis accuracy: 0.9361, F1 Micro: 0.9361, F1 Macro: 0.9284\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.94      0.91        86\n",
      "    positive       0.97      0.93      0.95       180\n",
      "\n",
      "    accuracy                           0.94       266\n",
      "   macro avg       0.92      0.94      0.93       266\n",
      "weighted avg       0.94      0.94      0.94       266\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.9046\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.84      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.45      0.75      0.56        12\n",
      "     neutral       0.94      0.88      0.91       152\n",
      "    positive       0.77      0.79      0.78        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.72      0.81      0.75       216\n",
      "weighted avg       0.87      0.85      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect service report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "Total train time: 120.23211145401001 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.005053341388702393\n",
      "Samples above threshold: 12\n",
      "Acquired samples: 8\n",
      "Sampling duration: 3.6182947158813477 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.54, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.412, Accuracy: 0.9211, F1 Micro: 0.9518, F1 Macro: 0.9502\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2622, Accuracy: 0.9554, F1 Micro: 0.9723, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.182, Accuracy: 0.9591, F1 Micro: 0.9746, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.136, Accuracy: 0.968, F1 Micro: 0.98, F1 Macro: 0.979\n",
      "Epoch 6/10, Train Loss: 0.1048, Accuracy: 0.9546, F1 Micro: 0.9714, F1 Macro: 0.9689\n",
      "Epoch 7/10, Train Loss: 0.0848, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9766\n",
      "Epoch 8/10, Train Loss: 0.0692, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9732\n",
      "Epoch 9/10, Train Loss: 0.0567, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9781\n",
      "Epoch 10/10, Train Loss: 0.0494, Accuracy: 0.9613, F1 Micro: 0.9755, F1 Macro: 0.9735\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.98, F1 Macro: 0.979\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.92      0.97      0.94       158\n",
      "        part       0.99      0.98      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5172, Accuracy: 0.8889, F1 Micro: 0.8889, F1 Macro: 0.8681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2284, Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9382\n",
      "Epoch 3/10, Train Loss: 0.1632, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9264\n",
      "Epoch 4/10, Train Loss: 0.1585, Accuracy: 0.9365, F1 Micro: 0.9365, F1 Macro: 0.9298\n",
      "Epoch 5/10, Train Loss: 0.1304, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.934\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0906, Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9389\n",
      "Epoch 7/10, Train Loss: 0.096, Accuracy: 0.9365, F1 Micro: 0.9365, F1 Macro: 0.9305\n",
      "Epoch 8/10, Train Loss: 0.0759, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9243\n",
      "Epoch 9/10, Train Loss: 0.0619, Accuracy: 0.9206, F1 Micro: 0.9206, F1 Macro: 0.9112\n",
      "Epoch 10/10, Train Loss: 0.0502, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.9065\n",
      "\n",
      "Sentiment analysis accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9389\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        84\n",
      "    positive       0.98      0.93      0.96       168\n",
      "\n",
      "    accuracy                           0.94       252\n",
      "   macro avg       0.93      0.95      0.94       252\n",
      "weighted avg       0.95      0.94      0.95       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9437, F1 Micro: 0.9437, F1 Macro: 0.8765\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.85      0.82      0.83       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.35      0.75      0.47        12\n",
      "     neutral       0.94      0.89      0.92       152\n",
      "    positive       0.87      0.75      0.80        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.72      0.80      0.73       216\n",
      "weighted avg       0.89      0.85      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.83      0.79        23\n",
      "     neutral       0.99      0.97      0.98       152\n",
      "    positive       0.85      0.85      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.87      0.88      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 118.1815276145935 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.009875881671905517\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.2561354637145996 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5267, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3944, Accuracy: 0.9405, F1 Micro: 0.9634, F1 Macro: 0.962\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2338, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1652, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1218, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9778\n",
      "Epoch 6/10, Train Loss: 0.0912, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9731\n",
      "Epoch 7/10, Train Loss: 0.0792, Accuracy: 0.9568, F1 Micro: 0.9727, F1 Macro: 0.9702\n",
      "Epoch 8/10, Train Loss: 0.0629, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9769\n",
      "Epoch 9/10, Train Loss: 0.0533, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0437, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9778\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.94      0.92      0.93       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4697, Accuracy: 0.8881, F1 Micro: 0.8881, F1 Macro: 0.8794\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.231, Accuracy: 0.903, F1 Micro: 0.903, F1 Macro: 0.895\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1585, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9319\n",
      "Epoch 4/10, Train Loss: 0.1409, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9251\n",
      "Epoch 5/10, Train Loss: 0.1374, Accuracy: 0.9104, F1 Micro: 0.9104, F1 Macro: 0.9022\n",
      "Epoch 6/10, Train Loss: 0.0961, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9255\n",
      "Epoch 7/10, Train Loss: 0.0913, Accuracy: 0.9254, F1 Micro: 0.9254, F1 Macro: 0.9168\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0861, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9367\n",
      "Epoch 9/10, Train Loss: 0.0665, Accuracy: 0.9254, F1 Micro: 0.9254, F1 Macro: 0.9149\n",
      "Epoch 10/10, Train Loss: 0.0406, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.9287\n",
      "\n",
      "Sentiment analysis accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9367\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.94      0.92        86\n",
      "    positive       0.97      0.95      0.96       182\n",
      "\n",
      "    accuracy                           0.94       268\n",
      "   macro avg       0.93      0.94      0.94       268\n",
      "weighted avg       0.95      0.94      0.94       268\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9139\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.97      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.85      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.94      0.92      0.93       152\n",
      "    positive       0.76      0.79      0.77        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.82      0.85      0.83       216\n",
      "weighted avg       0.89      0.88      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.99      0.99       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 126.63682413101196 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.003639626502990723\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.946178674697876 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5347, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3962, Accuracy: 0.9241, F1 Micro: 0.9538, F1 Macro: 0.9521\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2564, Accuracy: 0.9524, F1 Micro: 0.9704, F1 Macro: 0.9686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1705, Accuracy: 0.9531, F1 Micro: 0.9708, F1 Macro: 0.9692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1231, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1001, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9769\n",
      "Epoch 7/10, Train Loss: 0.079, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0636, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9771\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0507, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9773\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0472, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.979\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.979\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.94      0.94      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5026, Accuracy: 0.9135, F1 Micro: 0.9135, F1 Macro: 0.9037\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2493, Accuracy: 0.9211, F1 Micro: 0.9211, F1 Macro: 0.9138\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1916, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9209\n",
      "Epoch 4/10, Train Loss: 0.1539, Accuracy: 0.9248, F1 Micro: 0.9248, F1 Macro: 0.9181\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0995, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9321\n",
      "Epoch 6/10, Train Loss: 0.1156, Accuracy: 0.9211, F1 Micro: 0.9211, F1 Macro: 0.9138\n",
      "Epoch 7/10, Train Loss: 0.0672, Accuracy: 0.9361, F1 Micro: 0.9361, F1 Macro: 0.9296\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0772, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9325\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0788, Accuracy: 0.9511, F1 Micro: 0.9511, F1 Macro: 0.945\n",
      "Epoch 10/10, Train Loss: 0.0635, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9328\n",
      "\n",
      "Sentiment analysis accuracy: 0.9511, F1 Micro: 0.9511, F1 Macro: 0.945\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.94      0.93        87\n",
      "    positive       0.97      0.96      0.96       179\n",
      "\n",
      "    accuracy                           0.95       266\n",
      "   macro avg       0.94      0.95      0.94       266\n",
      "weighted avg       0.95      0.95      0.95       266\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.917\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.91      0.88      0.89        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.85      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.94      0.94      0.94       152\n",
      "    positive       0.81      0.83      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.89      0.87      0.88       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 137.67695140838623 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0030585646629333503\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.4771828651428223 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.526, Accuracy: 0.7969, F1 Micro: 0.8859, F1 Macro: 0.8844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4041, Accuracy: 0.9159, F1 Micro: 0.9483, F1 Macro: 0.9462\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2491, Accuracy: 0.9524, F1 Micro: 0.9704, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1578, Accuracy: 0.9591, F1 Micro: 0.9746, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1214, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.979\n",
      "Epoch 6/10, Train Loss: 0.0912, Accuracy: 0.9665, F1 Micro: 0.9791, F1 Macro: 0.9781\n",
      "Epoch 7/10, Train Loss: 0.0767, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9742\n",
      "Epoch 8/10, Train Loss: 0.0613, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9774\n",
      "Epoch 9/10, Train Loss: 0.0515, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0459, Accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9803\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9803\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.92      0.97      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4973, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9366\n",
      "Epoch 2/10, Train Loss: 0.2112, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.9007\n",
      "Epoch 3/10, Train Loss: 0.1729, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9193\n",
      "Epoch 4/10, Train Loss: 0.1385, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9274\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1172, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9404\n",
      "Epoch 6/10, Train Loss: 0.117, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.9082\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1044, Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9442\n",
      "Epoch 8/10, Train Loss: 0.0853, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9157\n",
      "Epoch 9/10, Train Loss: 0.0656, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9274\n",
      "Epoch 10/10, Train Loss: 0.0457, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9241\n",
      "\n",
      "Sentiment analysis accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9442\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.93        86\n",
      "    positive       0.98      0.95      0.96       173\n",
      "\n",
      "    accuracy                           0.95       259\n",
      "   macro avg       0.94      0.95      0.94       259\n",
      "weighted avg       0.95      0.95      0.95       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9161\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.88      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.92      0.97      0.95       152\n",
      "    positive       0.89      0.75      0.81        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.86      0.85      0.85       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 126.66399598121643 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0023369073867797853\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.014470338821411 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5231, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.385, Accuracy: 0.9249, F1 Micro: 0.9542, F1 Macro: 0.9528\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2337, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1595, Accuracy: 0.9635, F1 Micro: 0.9773, F1 Macro: 0.9763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1189, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0881, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9788\n",
      "Epoch 7/10, Train Loss: 0.0755, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9777\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0585, Accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9802\n",
      "Epoch 9/10, Train Loss: 0.0539, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9794\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0415, Accuracy: 0.9717, F1 Micro: 0.9822, F1 Macro: 0.9812\n",
      "\n",
      "Aspect detection accuracy: 0.9717, F1 Micro: 0.9822, F1 Macro: 0.9812\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.97      0.97       175\n",
      "      others       0.93      0.97      0.95       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.98      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.98      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4529, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9288\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2182, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9295\n",
      "Epoch 3/10, Train Loss: 0.1605, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9176\n",
      "Epoch 4/10, Train Loss: 0.1607, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9248\n",
      "Epoch 5/10, Train Loss: 0.1297, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.902\n",
      "Epoch 6/10, Train Loss: 0.1041, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9223\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0898, Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9412\n",
      "Epoch 8/10, Train Loss: 0.0688, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9331\n",
      "Epoch 9/10, Train Loss: 0.0554, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9321\n",
      "Epoch 10/10, Train Loss: 0.0529, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9288\n",
      "\n",
      "Sentiment analysis accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9412\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.97      0.92        87\n",
      "    positive       0.98      0.94      0.96       176\n",
      "\n",
      "    accuracy                           0.95       263\n",
      "   macro avg       0.93      0.95      0.94       263\n",
      "weighted avg       0.95      0.95      0.95       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9198\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.91      0.88      0.89        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.97      0.97      0.97       167\n",
      "    positive       0.85      0.85      0.85        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.90      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.93      0.97      0.95       152\n",
      "    positive       0.87      0.77      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.88      0.86      0.87       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 134.70858907699585 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0018386244773864746\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 8\n",
      "Sampling duration: 1.5911865234375 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.53, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4001, Accuracy: 0.9241, F1 Micro: 0.953, F1 Macro: 0.9508\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2515, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1656, Accuracy: 0.9643, F1 Micro: 0.9777, F1 Macro: 0.9768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1272, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9775\n",
      "Epoch 6/10, Train Loss: 0.0932, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9766\n",
      "Epoch 7/10, Train Loss: 0.076, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9762\n",
      "Epoch 8/10, Train Loss: 0.0656, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9773\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.047, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9782\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0428, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9789\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.99      0.98       175\n",
      "      others       0.92      0.93      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4648, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9141\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2429, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9365\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1681, Accuracy: 0.9544, F1 Micro: 0.9544, F1 Macro: 0.9493\n",
      "Epoch 4/10, Train Loss: 0.1569, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9368\n",
      "Epoch 5/10, Train Loss: 0.1392, Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9402\n",
      "Epoch 6/10, Train Loss: 0.11, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.9085\n",
      "Epoch 7/10, Train Loss: 0.1078, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9236\n",
      "Epoch 8/10, Train Loss: 0.0933, Accuracy: 0.9278, F1 Micro: 0.9278, F1 Macro: 0.9208\n",
      "Epoch 9/10, Train Loss: 0.0734, Accuracy: 0.9202, F1 Micro: 0.9202, F1 Macro: 0.9129\n",
      "Epoch 10/10, Train Loss: 0.0533, Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.945\n",
      "\n",
      "Sentiment analysis accuracy: 0.9544, F1 Micro: 0.9544, F1 Macro: 0.9493\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.93        86\n",
      "    positive       0.99      0.94      0.97       177\n",
      "\n",
      "    accuracy                           0.95       263\n",
      "   macro avg       0.94      0.96      0.95       263\n",
      "weighted avg       0.96      0.95      0.95       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9253\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.99      0.98       167\n",
      "    positive       0.90      0.82      0.86        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.89      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.77      0.79      0.78        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.84      0.82      0.83       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.80      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 131.11109566688538 s\n",
      "Total runtime: 2859.945941925049 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[2], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f26c8c5",
   "metadata": {
    "papermill": {
     "duration": 0.151262,
     "end_time": "2025-03-23T09:25:21.957453",
     "exception": false,
     "start_time": "2025-03-23T09:25:21.806191",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "242a4e1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T09:25:22.257191Z",
     "iopub.status.busy": "2025-03-23T09:25:22.256861Z",
     "iopub.status.idle": "2025-03-23T10:14:17.885744Z",
     "shell.execute_reply": "2025-03-23T10:14:17.884814Z"
    },
    "papermill": {
     "duration": 2935.780246,
     "end_time": "2025-03-23T10:14:17.887128",
     "exception": false,
     "start_time": "2025-03-23T09:25:22.106882",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 4\n",
      "Random seed: 3\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6456, Accuracy: 0.7865, F1 Micro: 0.8804, F1 Macro: 0.8788\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5639, Accuracy: 0.7894, F1 Micro: 0.8822, F1 Macro: 0.8807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5346, Accuracy: 0.7894, F1 Micro: 0.8822, F1 Macro: 0.8807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5259, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4788, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Epoch 6/10, Train Loss: 0.477, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 7/10, Train Loss: 0.4707, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4588, Accuracy: 0.7909, F1 Micro: 0.883, F1 Macro: 0.8814\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.4215, Accuracy: 0.7932, F1 Micro: 0.8839, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3936, Accuracy: 0.7976, F1 Micro: 0.8857, F1 Macro: 0.884\n",
      "\n",
      "Aspect detection accuracy: 0.7976, F1 Micro: 0.8857, F1 Macro: 0.884\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.78      1.00      0.88       175\n",
      "      others       0.76      0.96      0.84       158\n",
      "        part       0.71      1.00      0.83       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.80      0.99      0.89      1061\n",
      "   macro avg       0.80      0.99      0.88      1061\n",
      "weighted avg       0.80      0.99      0.89      1061\n",
      " samples avg       0.80      0.99      0.88      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7056, Accuracy: 0.44, F1 Micro: 0.44, F1 Macro: 0.4318\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5997, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5241, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5185, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.494, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4806, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4617, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.422, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3873, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2944, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "\n",
      "Sentiment analysis accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         4\n",
      "    positive       0.84      1.00      0.91        21\n",
      "\n",
      "    accuracy                           0.84        25\n",
      "   macro avg       0.42      0.50      0.46        25\n",
      "weighted avg       0.71      0.84      0.77        25\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.7948, F1 Micro: 0.7948, F1 Macro: 0.3169\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.78      1.00      0.87       167\n",
      "    positive       1.00      0.03      0.06        33\n",
      "\n",
      "    accuracy                           0.78       216\n",
      "   macro avg       0.59      0.34      0.31       216\n",
      "weighted avg       0.75      0.78      0.68       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.76      0.95      0.84       152\n",
      "    positive       0.54      0.25      0.34        52\n",
      "\n",
      "    accuracy                           0.73       216\n",
      "   macro avg       0.43      0.40      0.40       216\n",
      "weighted avg       0.66      0.73      0.68       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        23\n",
      "     neutral       0.70      1.00      0.83       152\n",
      "    positive       0.00      0.00      0.00        41\n",
      "\n",
      "    accuracy                           0.70       216\n",
      "   macro avg       0.23      0.33      0.28       216\n",
      "weighted avg       0.50      0.70      0.58       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 62.32277584075928 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0730126976966858\n",
      "Samples above threshold: 81\n",
      "Acquired samples: 81\n",
      "Sampling duration: 9.756730079650879 seconds\n",
      "New train size: 135\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5837, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Epoch 2/10, Train Loss: 0.4805, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 3/10, Train Loss: 0.446, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 4/10, Train Loss: 0.4431, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4092, Accuracy: 0.7954, F1 Micro: 0.8852, F1 Macro: 0.8837\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3666, Accuracy: 0.8132, F1 Micro: 0.8938, F1 Macro: 0.8922\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.338, Accuracy: 0.8304, F1 Micro: 0.9023, F1 Macro: 0.901\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2854, Accuracy: 0.8579, F1 Micro: 0.9163, F1 Macro: 0.9147\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2459, Accuracy: 0.8743, F1 Micro: 0.9254, F1 Macro: 0.9242\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.211, Accuracy: 0.8839, F1 Micro: 0.93, F1 Macro: 0.9279\n",
      "\n",
      "Aspect detection accuracy: 0.8839, F1 Micro: 0.93, F1 Macro: 0.9279\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.93      0.99      0.96       187\n",
      "     machine       0.83      0.99      0.90       175\n",
      "      others       0.81      0.97      0.88       158\n",
      "        part       0.90      0.89      0.90       158\n",
      "       price       0.91      1.00      0.96       192\n",
      "     service       0.95      0.99      0.97       191\n",
      "\n",
      "   micro avg       0.89      0.98      0.93      1061\n",
      "   macro avg       0.89      0.97      0.93      1061\n",
      "weighted avg       0.89      0.98      0.93      1061\n",
      " samples avg       0.89      0.98      0.93      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6557, Accuracy: 0.7059, F1 Micro: 0.7059, F1 Macro: 0.4138\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5386, Accuracy: 0.7353, F1 Micro: 0.7353, F1 Macro: 0.5258\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5113, Accuracy: 0.8235, F1 Micro: 0.8235, F1 Macro: 0.77\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3823, Accuracy: 0.8588, F1 Micro: 0.8588, F1 Macro: 0.828\n",
      "Epoch 5/10, Train Loss: 0.2553, Accuracy: 0.8529, F1 Micro: 0.8529, F1 Macro: 0.8343\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1573, Accuracy: 0.8706, F1 Micro: 0.8706, F1 Macro: 0.8522\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0663, Accuracy: 0.8765, F1 Micro: 0.8765, F1 Macro: 0.8553\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0808, Accuracy: 0.8941, F1 Micro: 0.8941, F1 Macro: 0.8779\n",
      "Epoch 9/10, Train Loss: 0.0444, Accuracy: 0.8824, F1 Micro: 0.8824, F1 Macro: 0.8643\n",
      "Epoch 10/10, Train Loss: 0.0572, Accuracy: 0.8882, F1 Micro: 0.8882, F1 Macro: 0.8717\n",
      "\n",
      "Sentiment analysis accuracy: 0.8941, F1 Micro: 0.8941, F1 Macro: 0.8779\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.90      0.83        50\n",
      "    positive       0.96      0.89      0.92       120\n",
      "\n",
      "    accuracy                           0.89       170\n",
      "   macro avg       0.87      0.90      0.88       170\n",
      "weighted avg       0.90      0.89      0.90       170\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 135: Accuracy: 0.8765, F1 Micro: 0.8765, F1 Macro: 0.7014\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.64      0.74        11\n",
      "     neutral       0.93      0.99      0.96       181\n",
      "    positive       0.94      0.62      0.75        24\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.91      0.75      0.82       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.82      0.99      0.90       167\n",
      "    positive       0.86      0.36      0.51        33\n",
      "\n",
      "    accuracy                           0.82       216\n",
      "   macro avg       0.56      0.45      0.47       216\n",
      "weighted avg       0.77      0.82      0.77       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.33      0.47        12\n",
      "     neutral       0.81      0.97      0.88       152\n",
      "    positive       0.86      0.46      0.60        52\n",
      "\n",
      "    accuracy                           0.81       216\n",
      "   macro avg       0.82      0.59      0.65       216\n",
      "weighted avg       0.82      0.81      0.79       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.78      0.71        23\n",
      "     neutral       0.89      0.89      0.89       152\n",
      "    positive       0.69      0.61      0.65        41\n",
      "\n",
      "    accuracy                           0.83       216\n",
      "   macro avg       0.74      0.76      0.75       216\n",
      "weighted avg       0.83      0.83      0.83       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.46      0.60        13\n",
      "     neutral       0.92      1.00      0.96       186\n",
      "    positive       1.00      0.35      0.52        17\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.92      0.60      0.69       216\n",
      "weighted avg       0.92      0.92      0.90       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.71      0.80        14\n",
      "     neutral       0.95      0.99      0.97       185\n",
      "    positive       0.91      0.59      0.71        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.77      0.83       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Total train time: 67.31838607788086 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.035809922218322764\n",
      "Samples above threshold: 73\n",
      "Acquired samples: 73\n",
      "Sampling duration: 11.633409261703491 seconds\n",
      "New train size: 208\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5637, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Epoch 2/10, Train Loss: 0.4994, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 3/10, Train Loss: 0.4809, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4504, Accuracy: 0.7932, F1 Micro: 0.8836, F1 Macro: 0.8818\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4085, Accuracy: 0.8132, F1 Micro: 0.8937, F1 Macro: 0.892\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3456, Accuracy: 0.869, F1 Micro: 0.9224, F1 Macro: 0.921\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2831, Accuracy: 0.8891, F1 Micro: 0.933, F1 Macro: 0.9311\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2413, Accuracy: 0.901, F1 Micro: 0.9393, F1 Macro: 0.9368\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1944, Accuracy: 0.9129, F1 Micro: 0.9463, F1 Macro: 0.9434\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1656, Accuracy: 0.9152, F1 Micro: 0.9476, F1 Macro: 0.9455\n",
      "\n",
      "Aspect detection accuracy: 0.9152, F1 Micro: 0.9476, F1 Macro: 0.9455\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.85      1.00      0.92       175\n",
      "      others       0.87      0.94      0.90       158\n",
      "        part       0.91      0.91      0.91       158\n",
      "       price       0.97      0.97      0.97       192\n",
      "     service       0.96      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.93      0.97      0.95      1061\n",
      "   macro avg       0.93      0.97      0.95      1061\n",
      "weighted avg       0.93      0.97      0.95      1061\n",
      " samples avg       0.93      0.97      0.94      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6021, Accuracy: 0.7117, F1 Micro: 0.7117, F1 Macro: 0.4158\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4958, Accuracy: 0.7252, F1 Micro: 0.7252, F1 Macro: 0.5916\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3533, Accuracy: 0.8514, F1 Micro: 0.8514, F1 Macro: 0.8163\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2032, Accuracy: 0.8874, F1 Micro: 0.8874, F1 Macro: 0.8711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.169, Accuracy: 0.9099, F1 Micro: 0.9099, F1 Macro: 0.8972\n",
      "Epoch 6/10, Train Loss: 0.0652, Accuracy: 0.9054, F1 Micro: 0.9054, F1 Macro: 0.8863\n",
      "Epoch 7/10, Train Loss: 0.0921, Accuracy: 0.9009, F1 Micro: 0.9009, F1 Macro: 0.8852\n",
      "Epoch 8/10, Train Loss: 0.0497, Accuracy: 0.9054, F1 Micro: 0.9054, F1 Macro: 0.8917\n",
      "Epoch 9/10, Train Loss: 0.0581, Accuracy: 0.9054, F1 Micro: 0.9054, F1 Macro: 0.8892\n",
      "Epoch 10/10, Train Loss: 0.0395, Accuracy: 0.9009, F1 Micro: 0.9009, F1 Macro: 0.8861\n",
      "\n",
      "Sentiment analysis accuracy: 0.9099, F1 Micro: 0.9099, F1 Macro: 0.8972\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.97      0.86        64\n",
      "    positive       0.99      0.89      0.93       158\n",
      "\n",
      "    accuracy                           0.91       222\n",
      "   macro avg       0.88      0.93      0.90       222\n",
      "weighted avg       0.93      0.91      0.91       222\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 208: Accuracy: 0.9035, F1 Micro: 0.9035, F1 Macro: 0.7902\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.06      0.12        16\n",
      "     neutral       0.84      1.00      0.91       167\n",
      "    positive       0.94      0.45      0.61        33\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.93      0.51      0.55       216\n",
      "weighted avg       0.87      0.85      0.81       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.54      0.58      0.56        12\n",
      "     neutral       0.87      0.93      0.90       152\n",
      "    positive       0.75      0.58      0.65        52\n",
      "\n",
      "    accuracy                           0.83       216\n",
      "   macro avg       0.72      0.70      0.70       216\n",
      "weighted avg       0.82      0.83      0.82       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.83      0.76        23\n",
      "     neutral       0.91      0.91      0.91       152\n",
      "    positive       0.72      0.63      0.68        41\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.78      0.79      0.78       216\n",
      "weighted avg       0.85      0.85      0.85       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.77      0.74        13\n",
      "     neutral       0.97      0.97      0.97       186\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.83      0.84      0.83       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.96      1.00      0.98       185\n",
      "    positive       1.00      0.65      0.79        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.99      0.83      0.90       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Total train time: 75.34574294090271 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0249747633934021\n",
      "Samples above threshold: 66\n",
      "Acquired samples: 66\n",
      "Sampling duration: 11.882482290267944 seconds\n",
      "New train size: 274\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5574, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4872, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4564, Accuracy: 0.7909, F1 Micro: 0.8829, F1 Macro: 0.8814\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4048, Accuracy: 0.8192, F1 Micro: 0.8957, F1 Macro: 0.8941\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3665, Accuracy: 0.869, F1 Micro: 0.9225, F1 Macro: 0.9212\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2877, Accuracy: 0.8958, F1 Micro: 0.937, F1 Macro: 0.9355\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2252, Accuracy: 0.9055, F1 Micro: 0.9418, F1 Macro: 0.9394\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1911, Accuracy: 0.9196, F1 Micro: 0.9501, F1 Macro: 0.9472\n",
      "Epoch 9/10, Train Loss: 0.1496, Accuracy: 0.9159, F1 Micro: 0.9475, F1 Macro: 0.9435\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1332, Accuracy: 0.9308, F1 Micro: 0.9568, F1 Macro: 0.9542\n",
      "\n",
      "Aspect detection accuracy: 0.9308, F1 Micro: 0.9568, F1 Macro: 0.9542\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.98      0.99       187\n",
      "     machine       0.92      1.00      0.96       175\n",
      "      others       0.86      0.96      0.90       158\n",
      "        part       0.93      0.89      0.91       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.96      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.94      0.97      0.96      1061\n",
      "   macro avg       0.94      0.97      0.95      1061\n",
      "weighted avg       0.94      0.97      0.96      1061\n",
      " samples avg       0.94      0.97      0.95      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6211, Accuracy: 0.7012, F1 Micro: 0.7012, F1 Macro: 0.4122\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4794, Accuracy: 0.7303, F1 Micro: 0.7303, F1 Macro: 0.5597\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3283, Accuracy: 0.9004, F1 Micro: 0.9004, F1 Macro: 0.8821\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1798, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.8972\n",
      "Epoch 5/10, Train Loss: 0.0902, Accuracy: 0.9046, F1 Micro: 0.9046, F1 Macro: 0.8827\n",
      "Epoch 6/10, Train Loss: 0.0432, Accuracy: 0.9046, F1 Micro: 0.9046, F1 Macro: 0.8914\n",
      "Epoch 7/10, Train Loss: 0.0887, Accuracy: 0.9046, F1 Micro: 0.9046, F1 Macro: 0.8874\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0391, Accuracy: 0.917, F1 Micro: 0.917, F1 Macro: 0.901\n",
      "Epoch 9/10, Train Loss: 0.105, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.9008\n",
      "Epoch 10/10, Train Loss: 0.0816, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.8995\n",
      "\n",
      "Sentiment analysis accuracy: 0.917, F1 Micro: 0.917, F1 Macro: 0.901\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.86      0.86        72\n",
      "    positive       0.94      0.94      0.94       169\n",
      "\n",
      "    accuracy                           0.92       241\n",
      "   macro avg       0.90      0.90      0.90       241\n",
      "weighted avg       0.92      0.92      0.92       241\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 274: Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.8485\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.98      0.99       181\n",
      "    positive       0.88      0.96      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.98      0.97       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.62      0.74        16\n",
      "     neutral       0.91      1.00      0.95       167\n",
      "    positive       0.95      0.64      0.76        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.93      0.75      0.82       216\n",
      "weighted avg       0.92      0.92      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.58      0.64        12\n",
      "     neutral       0.86      0.96      0.91       152\n",
      "    positive       0.84      0.60      0.70        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.80      0.71      0.75       216\n",
      "weighted avg       0.85      0.85      0.84       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.68      0.74      0.71        23\n",
      "     neutral       0.93      0.89      0.91       152\n",
      "    positive       0.67      0.76      0.71        41\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.76      0.79      0.78       216\n",
      "weighted avg       0.86      0.85      0.85       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.77      0.77        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.88      0.86      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.96      1.00      0.98       185\n",
      "    positive       1.00      0.76      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.99      0.85      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 88.04901671409607 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.020069354772567754\n",
      "Samples above threshold: 59\n",
      "Acquired samples: 59\n",
      "Sampling duration: 11.145968675613403 seconds\n",
      "New train size: 333\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5618, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Epoch 2/10, Train Loss: 0.4933, Accuracy: 0.7902, F1 Micro: 0.8826, F1 Macro: 0.8811\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4476, Accuracy: 0.8051, F1 Micro: 0.8882, F1 Macro: 0.8857\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3962, Accuracy: 0.8616, F1 Micro: 0.9175, F1 Macro: 0.9146\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2894, Accuracy: 0.904, F1 Micro: 0.941, F1 Macro: 0.9383\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2361, Accuracy: 0.9129, F1 Micro: 0.946, F1 Macro: 0.9436\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1802, Accuracy: 0.9315, F1 Micro: 0.9574, F1 Macro: 0.9547\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1544, Accuracy: 0.939, F1 Micro: 0.9617, F1 Macro: 0.9592\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1251, Accuracy: 0.9405, F1 Micro: 0.9626, F1 Macro: 0.9604\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1056, Accuracy: 0.9435, F1 Micro: 0.9643, F1 Macro: 0.9623\n",
      "\n",
      "Aspect detection accuracy: 0.9435, F1 Micro: 0.9643, F1 Macro: 0.9623\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.98      0.98       187\n",
      "     machine       0.94      0.97      0.96       175\n",
      "      others       0.92      0.91      0.91       158\n",
      "        part       0.96      0.95      0.95       158\n",
      "       price       0.98      0.98      0.98       192\n",
      "     service       0.97      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.96      0.97      0.96      1061\n",
      "   macro avg       0.96      0.96      0.96      1061\n",
      "weighted avg       0.96      0.97      0.96      1061\n",
      " samples avg       0.96      0.96      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5547, Accuracy: 0.7222, F1 Micro: 0.7222, F1 Macro: 0.4194\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3962, Accuracy: 0.8926, F1 Micro: 0.8926, F1 Macro: 0.8656\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.235, Accuracy: 0.9185, F1 Micro: 0.9185, F1 Macro: 0.9016\n",
      "Epoch 4/10, Train Loss: 0.1765, Accuracy: 0.8963, F1 Micro: 0.8963, F1 Macro: 0.8718\n",
      "Epoch 5/10, Train Loss: 0.1003, Accuracy: 0.9148, F1 Micro: 0.9148, F1 Macro: 0.8996\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1481, Accuracy: 0.9222, F1 Micro: 0.9222, F1 Macro: 0.909\n",
      "Epoch 7/10, Train Loss: 0.1393, Accuracy: 0.9185, F1 Micro: 0.9185, F1 Macro: 0.9023\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0938, Accuracy: 0.9222, F1 Micro: 0.9222, F1 Macro: 0.901\n",
      "Epoch 9/10, Train Loss: 0.0485, Accuracy: 0.9185, F1 Micro: 0.9185, F1 Macro: 0.903\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0538, Accuracy: 0.9259, F1 Micro: 0.9259, F1 Macro: 0.9105\n",
      "\n",
      "Sentiment analysis accuracy: 0.9259, F1 Micro: 0.9259, F1 Macro: 0.9105\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.92      0.87        75\n",
      "    positive       0.97      0.93      0.95       195\n",
      "\n",
      "    accuracy                           0.93       270\n",
      "   macro avg       0.90      0.92      0.91       270\n",
      "weighted avg       0.93      0.93      0.93       270\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 333: Accuracy: 0.9329, F1 Micro: 0.9329, F1 Macro: 0.8669\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.98      0.99       181\n",
      "    positive       0.82      0.96      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.95      0.94       216\n",
      "weighted avg       0.98      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.62      0.74        16\n",
      "     neutral       0.94      0.97      0.96       167\n",
      "    positive       0.82      0.82      0.82        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.89      0.80      0.84       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.67      0.70        12\n",
      "     neutral       0.93      0.91      0.92       152\n",
      "    positive       0.75      0.81      0.78        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.80      0.79      0.80       216\n",
      "weighted avg       0.87      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.83      0.79        23\n",
      "     neutral       0.95      0.95      0.95       152\n",
      "    positive       0.82      0.80      0.81        41\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.85      0.86      0.85       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.77      0.74        13\n",
      "     neutral       0.98      0.98      0.98       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.84      0.86      0.85       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.97      1.00      0.98       185\n",
      "    positive       1.00      0.76      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.99      0.87      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 93.94467377662659 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.01668071746826172\n",
      "Samples above threshold: 54\n",
      "Acquired samples: 54\n",
      "Sampling duration: 10.660919427871704 seconds\n",
      "New train size: 387\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5708, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.492, Accuracy: 0.7932, F1 Micro: 0.8833, F1 Macro: 0.8813\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4277, Accuracy: 0.8452, F1 Micro: 0.9088, F1 Macro: 0.9067\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3315, Accuracy: 0.8981, F1 Micro: 0.9364, F1 Macro: 0.9318\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2553, Accuracy: 0.9182, F1 Micro: 0.9481, F1 Macro: 0.9441\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1787, Accuracy: 0.9375, F1 Micro: 0.9608, F1 Macro: 0.9586\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.157, Accuracy: 0.942, F1 Micro: 0.9634, F1 Macro: 0.961\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.125, Accuracy: 0.9427, F1 Micro: 0.964, F1 Macro: 0.962\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1051, Accuracy: 0.9509, F1 Micro: 0.9692, F1 Macro: 0.9676\n",
      "Epoch 10/10, Train Loss: 0.0827, Accuracy: 0.9457, F1 Micro: 0.9659, F1 Macro: 0.9639\n",
      "\n",
      "Aspect detection accuracy: 0.9509, F1 Micro: 0.9692, F1 Macro: 0.9676\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.93      0.99      0.96       175\n",
      "      others       0.91      0.91      0.91       158\n",
      "        part       0.97      0.98      0.97       158\n",
      "       price       0.98      0.98      0.98       192\n",
      "     service       0.97      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.517, Accuracy: 0.6969, F1 Micro: 0.6969, F1 Macro: 0.4107\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3109, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9088\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9039\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1173, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9179\n",
      "Epoch 5/10, Train Loss: 0.1103, Accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.8995\n",
      "Epoch 6/10, Train Loss: 0.0626, Accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.9025\n",
      "Epoch 7/10, Train Loss: 0.0695, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9116\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0899, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9216\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0387, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9222\n",
      "Epoch 10/10, Train Loss: 0.0508, Accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.8969\n",
      "\n",
      "Sentiment analysis accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.92      0.89        77\n",
      "    positive       0.97      0.94      0.95       177\n",
      "\n",
      "    accuracy                           0.93       254\n",
      "   macro avg       0.92      0.93      0.92       254\n",
      "weighted avg       0.94      0.93      0.93       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 387: Accuracy: 0.9321, F1 Micro: 0.9321, F1 Macro: 0.8477\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.96      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.89      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.50      0.67        16\n",
      "     neutral       0.93      0.99      0.96       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.92      0.75      0.81       216\n",
      "weighted avg       0.92      0.92      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.67      0.67        12\n",
      "     neutral       0.91      0.89      0.90       152\n",
      "    positive       0.75      0.79      0.77        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.77      0.78      0.78       216\n",
      "weighted avg       0.86      0.86      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.74      0.79        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       0.81      0.85      0.83        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.86      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.69      0.75        13\n",
      "     neutral       0.98      0.98      0.98       186\n",
      "    positive       0.75      0.88      0.81        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.85      0.85      0.85       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.71      0.83        14\n",
      "     neutral       0.97      1.00      0.98       185\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.95      0.83      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Total train time: 99.99326348304749 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.014836502075195317\n",
      "Samples above threshold: 48\n",
      "Acquired samples: 48\n",
      "Sampling duration: 9.664436101913452 seconds\n",
      "New train size: 435\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.562, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5017, Accuracy: 0.7991, F1 Micro: 0.8856, F1 Macro: 0.8832\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4118, Accuracy: 0.8728, F1 Micro: 0.924, F1 Macro: 0.9223\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3096, Accuracy: 0.9234, F1 Micro: 0.9527, F1 Macro: 0.9508\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2322, Accuracy: 0.939, F1 Micro: 0.9617, F1 Macro: 0.9594\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1724, Accuracy: 0.9464, F1 Micro: 0.9665, F1 Macro: 0.9651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.146, Accuracy: 0.9479, F1 Micro: 0.9674, F1 Macro: 0.9658\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1133, Accuracy: 0.9501, F1 Micro: 0.9686, F1 Macro: 0.9666\n",
      "Epoch 9/10, Train Loss: 0.0928, Accuracy: 0.9457, F1 Micro: 0.9659, F1 Macro: 0.9642\n",
      "Epoch 10/10, Train Loss: 0.0824, Accuracy: 0.9479, F1 Micro: 0.9673, F1 Macro: 0.9657\n",
      "\n",
      "Aspect detection accuracy: 0.9501, F1 Micro: 0.9686, F1 Macro: 0.9666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.93      0.99      0.96       175\n",
      "      others       0.93      0.89      0.91       158\n",
      "        part       0.97      0.97      0.97       158\n",
      "       price       0.98      0.98      0.98       192\n",
      "     service       0.97      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.96      0.97      0.97      1061\n",
      "   macro avg       0.96      0.97      0.97      1061\n",
      "weighted avg       0.96      0.97      0.97      1061\n",
      " samples avg       0.96      0.97      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5324, Accuracy: 0.705, F1 Micro: 0.705, F1 Macro: 0.4135\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3513, Accuracy: 0.9004, F1 Micro: 0.9004, F1 Macro: 0.8859\n",
      "Epoch 3/10, Train Loss: 0.2207, Accuracy: 0.8544, F1 Micro: 0.8544, F1 Macro: 0.8428\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1424, Accuracy: 0.9387, F1 Micro: 0.9387, F1 Macro: 0.9293\n",
      "Epoch 5/10, Train Loss: 0.1203, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9057\n",
      "Epoch 6/10, Train Loss: 0.0632, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9117\n",
      "Epoch 7/10, Train Loss: 0.0645, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9226\n",
      "Epoch 8/10, Train Loss: 0.0734, Accuracy: 0.9272, F1 Micro: 0.9272, F1 Macro: 0.9128\n",
      "Epoch 9/10, Train Loss: 0.0782, Accuracy: 0.931, F1 Micro: 0.931, F1 Macro: 0.9189\n",
      "Epoch 10/10, Train Loss: 0.0403, Accuracy: 0.931, F1 Micro: 0.931, F1 Macro: 0.9177\n",
      "\n",
      "Sentiment analysis accuracy: 0.9387, F1 Micro: 0.9387, F1 Macro: 0.9293\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.97      0.90        77\n",
      "    positive       0.99      0.92      0.96       184\n",
      "\n",
      "    accuracy                           0.94       261\n",
      "   macro avg       0.92      0.95      0.93       261\n",
      "weighted avg       0.95      0.94      0.94       261\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 435: Accuracy: 0.9352, F1 Micro: 0.9352, F1 Macro: 0.8636\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.50      0.55        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.80      0.74      0.77       216\n",
      "weighted avg       0.90      0.91      0.90       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.93      0.89      0.91       152\n",
      "    positive       0.73      0.83      0.77        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.80      0.82      0.81       216\n",
      "weighted avg       0.87      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.91      0.82        23\n",
      "     neutral       0.97      0.95      0.96       152\n",
      "    positive       0.87      0.80      0.84        41\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.86      0.89      0.87       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        13\n",
      "     neutral       0.98      0.98      0.98       186\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.87      0.88      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.79      0.85        14\n",
      "     neutral       0.97      1.00      0.99       185\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.85      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 96.29317784309387 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.013796198368072509\n",
      "Samples above threshold: 43\n",
      "Acquired samples: 43\n",
      "Sampling duration: 9.835289001464844 seconds\n",
      "New train size: 478\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.558, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4979, Accuracy: 0.7976, F1 Micro: 0.8838, F1 Macro: 0.8802\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3993, Accuracy: 0.881, F1 Micro: 0.9277, F1 Macro: 0.9248\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3013, Accuracy: 0.9182, F1 Micro: 0.9488, F1 Macro: 0.9457\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2142, Accuracy: 0.9412, F1 Micro: 0.9636, F1 Macro: 0.9621\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1675, Accuracy: 0.9464, F1 Micro: 0.9663, F1 Macro: 0.9644\n",
      "Epoch 7/10, Train Loss: 0.1287, Accuracy: 0.9435, F1 Micro: 0.9647, F1 Macro: 0.9633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1027, Accuracy: 0.9509, F1 Micro: 0.9693, F1 Macro: 0.9675\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0854, Accuracy: 0.9531, F1 Micro: 0.9707, F1 Macro: 0.969\n",
      "Epoch 10/10, Train Loss: 0.0698, Accuracy: 0.9487, F1 Micro: 0.9678, F1 Macro: 0.9664\n",
      "\n",
      "Aspect detection accuracy: 0.9531, F1 Micro: 0.9707, F1 Macro: 0.969\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.89      0.94      0.91       158\n",
      "        part       0.97      0.96      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5301, Accuracy: 0.6867, F1 Micro: 0.6867, F1 Macro: 0.4071\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3485, Accuracy: 0.8916, F1 Micro: 0.8916, F1 Macro: 0.8811\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2312, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9316\n",
      "Epoch 4/10, Train Loss: 0.1422, Accuracy: 0.9357, F1 Micro: 0.9357, F1 Macro: 0.9277\n",
      "Epoch 5/10, Train Loss: 0.1306, Accuracy: 0.9277, F1 Micro: 0.9277, F1 Macro: 0.9154\n",
      "Epoch 6/10, Train Loss: 0.11, Accuracy: 0.9317, F1 Micro: 0.9317, F1 Macro: 0.9239\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0784, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9367\n",
      "Epoch 8/10, Train Loss: 0.0778, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.932\n",
      "Epoch 9/10, Train Loss: 0.0852, Accuracy: 0.9237, F1 Micro: 0.9237, F1 Macro: 0.9116\n",
      "Epoch 10/10, Train Loss: 0.0435, Accuracy: 0.9277, F1 Micro: 0.9277, F1 Macro: 0.9166\n",
      "\n",
      "Sentiment analysis accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9367\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.97      0.92        78\n",
      "    positive       0.99      0.93      0.96       171\n",
      "\n",
      "    accuracy                           0.94       249\n",
      "   macro avg       0.93      0.95      0.94       249\n",
      "weighted avg       0.95      0.94      0.94       249\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 478: Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.8663\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.62      0.74        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.84      0.82      0.83        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.81      0.85       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.57      0.67      0.62        12\n",
      "     neutral       0.90      0.94      0.92       152\n",
      "    positive       0.81      0.67      0.74        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.76      0.76      0.76       216\n",
      "weighted avg       0.86      0.86      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.83      0.78        23\n",
      "     neutral       0.97      0.95      0.96       152\n",
      "    positive       0.80      0.80      0.80        41\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.84      0.86      0.85       216\n",
      "weighted avg       0.92      0.91      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.77      0.71        13\n",
      "     neutral       0.98      0.98      0.98       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.84      0.86      0.85       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.99      0.92      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 101.30435562133789 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.011731326580047607\n",
      "Samples above threshold: 39\n",
      "Acquired samples: 39\n",
      "Sampling duration: 8.559562921524048 seconds\n",
      "New train size: 517\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5587, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4708, Accuracy: 0.808, F1 Micro: 0.8903, F1 Macro: 0.8882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3695, Accuracy: 0.9122, F1 Micro: 0.9464, F1 Macro: 0.9445\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2404, Accuracy: 0.9509, F1 Micro: 0.9696, F1 Macro: 0.9685\n",
      "Epoch 5/10, Train Loss: 0.1775, Accuracy: 0.9457, F1 Micro: 0.9657, F1 Macro: 0.9634\n",
      "Epoch 6/10, Train Loss: 0.1324, Accuracy: 0.9457, F1 Micro: 0.966, F1 Macro: 0.9636\n",
      "Epoch 7/10, Train Loss: 0.1083, Accuracy: 0.9501, F1 Micro: 0.9688, F1 Macro: 0.9671\n",
      "Epoch 8/10, Train Loss: 0.0898, Accuracy: 0.9479, F1 Micro: 0.9671, F1 Macro: 0.9649\n",
      "Epoch 9/10, Train Loss: 0.0699, Accuracy: 0.9501, F1 Micro: 0.9685, F1 Macro: 0.9666\n",
      "Epoch 10/10, Train Loss: 0.0661, Accuracy: 0.9479, F1 Micro: 0.9671, F1 Macro: 0.9647\n",
      "\n",
      "Aspect detection accuracy: 0.9509, F1 Micro: 0.9696, F1 Macro: 0.9685\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.93      0.99      0.96       175\n",
      "      others       0.87      0.99      0.92       158\n",
      "        part       0.96      0.97      0.97       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.95      0.99      0.97      1061\n",
      "   macro avg       0.95      0.99      0.97      1061\n",
      "weighted avg       0.95      0.99      0.97      1061\n",
      " samples avg       0.95      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5261, Accuracy: 0.7911, F1 Micro: 0.7911, F1 Macro: 0.719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3381, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9262\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2263, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9262\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1419, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9247\n",
      "Epoch 5/10, Train Loss: 0.0942, Accuracy: 0.9067, F1 Micro: 0.9067, F1 Macro: 0.899\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0916, Accuracy: 0.9378, F1 Micro: 0.9378, F1 Macro: 0.93\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0753, Accuracy: 0.9378, F1 Micro: 0.9378, F1 Macro: 0.9309\n",
      "Epoch 8/10, Train Loss: 0.0964, Accuracy: 0.9244, F1 Micro: 0.9244, F1 Macro: 0.9168\n",
      "Epoch 9/10, Train Loss: 0.0508, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9231\n",
      "Epoch 10/10, Train Loss: 0.0453, Accuracy: 0.9289, F1 Micro: 0.9289, F1 Macro: 0.921\n",
      "\n",
      "Sentiment analysis accuracy: 0.9378, F1 Micro: 0.9378, F1 Macro: 0.9309\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.96      0.91        73\n",
      "    positive       0.98      0.93      0.95       152\n",
      "\n",
      "    accuracy                           0.94       225\n",
      "   macro avg       0.92      0.94      0.93       225\n",
      "weighted avg       0.94      0.94      0.94       225\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 517: Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.8404\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.91      0.87        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.57      0.81      0.67        16\n",
      "     neutral       0.96      0.97      0.97       167\n",
      "    positive       0.92      0.70      0.79        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.82      0.83      0.81       216\n",
      "weighted avg       0.93      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.24      0.67      0.35        12\n",
      "     neutral       0.90      0.88      0.89       152\n",
      "    positive       0.94      0.60      0.73        52\n",
      "\n",
      "    accuracy                           0.80       216\n",
      "   macro avg       0.69      0.71      0.66       216\n",
      "weighted avg       0.87      0.80      0.82       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.91      0.79        23\n",
      "     neutral       0.96      0.96      0.96       152\n",
      "    positive       0.91      0.76      0.83        41\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.86      0.88      0.86       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.92      0.75        13\n",
      "     neutral       0.99      0.97      0.98       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.83      0.90      0.86       216\n",
      "weighted avg       0.96      0.95      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.93      0.90        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 98.28718280792236 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.024469804763793956\n",
      "Samples above threshold: 35\n",
      "Acquired samples: 23\n",
      "Sampling duration: 6.907095670700073 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5514, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4748, Accuracy: 0.8051, F1 Micro: 0.8899, F1 Macro: 0.8884\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3698, Accuracy: 0.9152, F1 Micro: 0.9474, F1 Macro: 0.9445\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2529, Accuracy: 0.9338, F1 Micro: 0.9584, F1 Macro: 0.9547\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1857, Accuracy: 0.9487, F1 Micro: 0.968, F1 Macro: 0.9662\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1464, Accuracy: 0.9524, F1 Micro: 0.9702, F1 Macro: 0.9685\n",
      "Epoch 7/10, Train Loss: 0.1126, Accuracy: 0.9516, F1 Micro: 0.9696, F1 Macro: 0.9676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0956, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9761\n",
      "Epoch 9/10, Train Loss: 0.0762, Accuracy: 0.9561, F1 Micro: 0.9723, F1 Macro: 0.9702\n",
      "Epoch 10/10, Train Loss: 0.0638, Accuracy: 0.9554, F1 Micro: 0.9721, F1 Macro: 0.9705\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9761\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.89      0.97      0.93       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4717, Accuracy: 0.796, F1 Micro: 0.796, F1 Macro: 0.7155\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.252, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9207\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1561, Accuracy: 0.952, F1 Micro: 0.952, F1 Macro: 0.9456\n",
      "Epoch 4/10, Train Loss: 0.1016, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9167\n",
      "Epoch 5/10, Train Loss: 0.0984, Accuracy: 0.936, F1 Micro: 0.936, F1 Macro: 0.9274\n",
      "Epoch 6/10, Train Loss: 0.1133, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9165\n",
      "Epoch 7/10, Train Loss: 0.0767, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9207\n",
      "Epoch 8/10, Train Loss: 0.0863, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.9004\n",
      "Epoch 9/10, Train Loss: 0.0914, Accuracy: 0.932, F1 Micro: 0.932, F1 Macro: 0.9205\n",
      "Epoch 10/10, Train Loss: 0.0667, Accuracy: 0.904, F1 Micro: 0.904, F1 Macro: 0.8948\n",
      "\n",
      "Sentiment analysis accuracy: 0.952, F1 Micro: 0.952, F1 Macro: 0.9456\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.93        80\n",
      "    positive       0.98      0.95      0.96       170\n",
      "\n",
      "    accuracy                           0.95       250\n",
      "   macro avg       0.94      0.95      0.95       250\n",
      "weighted avg       0.95      0.95      0.95       250\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9429, F1 Micro: 0.9429, F1 Macro: 0.8786\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.85      0.87       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.38      0.67      0.48        12\n",
      "     neutral       0.89      0.93      0.91       152\n",
      "    positive       0.89      0.62      0.73        52\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.72      0.74      0.71       216\n",
      "weighted avg       0.86      0.84      0.84       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.96      0.83        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.91      0.78      0.84        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.90      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 105.15387272834778 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.010386914014816282\n",
      "Samples above threshold: 33\n",
      "Acquired samples: 33\n",
      "Sampling duration: 7.16263747215271 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5489, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4697, Accuracy: 0.8251, F1 Micro: 0.8989, F1 Macro: 0.8969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3514, Accuracy: 0.9144, F1 Micro: 0.9475, F1 Macro: 0.9452\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2377, Accuracy: 0.9464, F1 Micro: 0.9668, F1 Macro: 0.9654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1812, Accuracy: 0.9516, F1 Micro: 0.9697, F1 Macro: 0.9676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1392, Accuracy: 0.9524, F1 Micro: 0.9701, F1 Macro: 0.9682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1056, Accuracy: 0.9554, F1 Micro: 0.972, F1 Macro: 0.9701\n",
      "Epoch 8/10, Train Loss: 0.0906, Accuracy: 0.9539, F1 Micro: 0.9709, F1 Macro: 0.9691\n",
      "Epoch 9/10, Train Loss: 0.0737, Accuracy: 0.9554, F1 Micro: 0.9717, F1 Macro: 0.9692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0641, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9728\n",
      "\n",
      "Aspect detection accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9728\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.89      0.95      0.92       158\n",
      "        part       0.96      0.97      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.511, Accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.822\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2622, Accuracy: 0.9246, F1 Micro: 0.9246, F1 Macro: 0.9115\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1558, Accuracy: 0.9246, F1 Micro: 0.9246, F1 Macro: 0.9159\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1426, Accuracy: 0.9365, F1 Micro: 0.9365, F1 Macro: 0.929\n",
      "Epoch 5/10, Train Loss: 0.1274, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9239\n",
      "Epoch 6/10, Train Loss: 0.0901, Accuracy: 0.9246, F1 Micro: 0.9246, F1 Macro: 0.9159\n",
      "Epoch 7/10, Train Loss: 0.0735, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9243\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0673, Accuracy: 0.9365, F1 Micro: 0.9365, F1 Macro: 0.9286\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0541, Accuracy: 0.9365, F1 Micro: 0.9365, F1 Macro: 0.9281\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0481, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9336\n",
      "\n",
      "Sentiment analysis accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9336\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.97      0.91        80\n",
      "    positive       0.99      0.92      0.95       172\n",
      "\n",
      "    accuracy                           0.94       252\n",
      "   macro avg       0.92      0.95      0.93       252\n",
      "weighted avg       0.95      0.94      0.94       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9491, F1 Micro: 0.9491, F1 Macro: 0.9024\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.88      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.67      0.70        12\n",
      "     neutral       0.89      0.95      0.92       152\n",
      "    positive       0.84      0.69      0.76        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.82      0.77      0.79       216\n",
      "weighted avg       0.87      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.96      0.85        23\n",
      "     neutral       0.96      0.97      0.97       152\n",
      "    positive       0.91      0.73      0.81        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.89      0.87       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.86      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 115.95905828475952 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.007550358772277832\n",
      "Samples above threshold: 30\n",
      "Acquired samples: 30\n",
      "Sampling duration: 6.761124134063721 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5526, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4658, Accuracy: 0.8408, F1 Micro: 0.9068, F1 Macro: 0.9047\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3437, Accuracy: 0.9293, F1 Micro: 0.9566, F1 Macro: 0.955\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2243, Accuracy: 0.9345, F1 Micro: 0.9591, F1 Macro: 0.9562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1708, Accuracy: 0.9539, F1 Micro: 0.9713, F1 Macro: 0.9698\n",
      "Epoch 6/10, Train Loss: 0.1334, Accuracy: 0.9539, F1 Micro: 0.9711, F1 Macro: 0.9696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0986, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0806, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9749\n",
      "Epoch 9/10, Train Loss: 0.0683, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9711\n",
      "Epoch 10/10, Train Loss: 0.0575, Accuracy: 0.9583, F1 Micro: 0.9737, F1 Macro: 0.9719\n",
      "\n",
      "Aspect detection accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9749\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.91      0.95      0.93       158\n",
      "        part       0.97      0.98      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5351, Accuracy: 0.8893, F1 Micro: 0.8893, F1 Macro: 0.8683\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2276, Accuracy: 0.9368, F1 Micro: 0.9368, F1 Macro: 0.9287\n",
      "Epoch 3/10, Train Loss: 0.1689, Accuracy: 0.9209, F1 Micro: 0.9209, F1 Macro: 0.9133\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1461, Accuracy: 0.9368, F1 Micro: 0.9368, F1 Macro: 0.9299\n",
      "Epoch 5/10, Train Loss: 0.1236, Accuracy: 0.917, F1 Micro: 0.917, F1 Macro: 0.9097\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1104, Accuracy: 0.9447, F1 Micro: 0.9447, F1 Macro: 0.9368\n",
      "Epoch 7/10, Train Loss: 0.0876, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9245\n",
      "Epoch 8/10, Train Loss: 0.0668, Accuracy: 0.9051, F1 Micro: 0.9051, F1 Macro: 0.8975\n",
      "Epoch 9/10, Train Loss: 0.075, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9334\n",
      "Epoch 10/10, Train Loss: 0.066, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.924\n",
      "\n",
      "Sentiment analysis accuracy: 0.9447, F1 Micro: 0.9447, F1 Macro: 0.9368\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.93      0.91        81\n",
      "    positive       0.96      0.95      0.96       172\n",
      "\n",
      "    accuracy                           0.94       253\n",
      "   macro avg       0.93      0.94      0.94       253\n",
      "weighted avg       0.95      0.94      0.94       253\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.8851\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.85      0.86       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.53      0.75      0.62        12\n",
      "     neutral       0.91      0.92      0.92       152\n",
      "    positive       0.87      0.75      0.80        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.77      0.81      0.78       216\n",
      "weighted avg       0.88      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.96      0.85        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       0.92      0.80      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.91      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 111.92565703392029 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.009111225605010986\n",
      "Samples above threshold: 27\n",
      "Acquired samples: 27\n",
      "Sampling duration: 6.289766788482666 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5433, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4645, Accuracy: 0.8609, F1 Micro: 0.9175, F1 Macro: 0.9155\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3249, Accuracy: 0.936, F1 Micro: 0.9604, F1 Macro: 0.9584\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.228, Accuracy: 0.9501, F1 Micro: 0.969, F1 Macro: 0.9673\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1526, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1183, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9741\n",
      "Epoch 7/10, Train Loss: 0.0935, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9721\n",
      "Epoch 8/10, Train Loss: 0.0726, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0603, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9754\n",
      "Epoch 10/10, Train Loss: 0.0542, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.975\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9754\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.89      0.96      0.93       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5385, Accuracy: 0.6969, F1 Micro: 0.6969, F1 Macro: 0.456\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2869, Accuracy: 0.8976, F1 Micro: 0.8976, F1 Macro: 0.8897\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1955, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9297\n",
      "Epoch 4/10, Train Loss: 0.1706, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9251\n",
      "Epoch 5/10, Train Loss: 0.1466, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9135\n",
      "Epoch 6/10, Train Loss: 0.1218, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9131\n",
      "Epoch 7/10, Train Loss: 0.0807, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9131\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0673, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9335\n",
      "Epoch 9/10, Train Loss: 0.0686, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9293\n",
      "Epoch 10/10, Train Loss: 0.0518, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9293\n",
      "\n",
      "Sentiment analysis accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9335\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.95      0.91        81\n",
      "    positive       0.98      0.94      0.96       173\n",
      "\n",
      "    accuracy                           0.94       254\n",
      "   macro avg       0.93      0.94      0.93       254\n",
      "weighted avg       0.94      0.94      0.94       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.9491, F1 Micro: 0.9491, F1 Macro: 0.8911\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.86      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.45      0.75      0.56        12\n",
      "     neutral       0.91      0.93      0.92       152\n",
      "    positive       0.88      0.69      0.77        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.75      0.79      0.75       216\n",
      "weighted avg       0.88      0.86      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.92      0.83      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.91      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 114.35635471343994 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.006069093942642213\n",
      "Samples above threshold: 24\n",
      "Acquired samples: 18\n",
      "Sampling duration: 5.740978479385376 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5443, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.449, Accuracy: 0.8624, F1 Micro: 0.919, F1 Macro: 0.9173\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.31, Accuracy: 0.9368, F1 Micro: 0.9604, F1 Macro: 0.9577\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1993, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1401, Accuracy: 0.9598, F1 Micro: 0.975, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1101, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9755\n",
      "Epoch 7/10, Train Loss: 0.093, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9739\n",
      "Epoch 8/10, Train Loss: 0.0699, Accuracy: 0.9561, F1 Micro: 0.9723, F1 Macro: 0.9703\n",
      "Epoch 9/10, Train Loss: 0.0562, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9733\n",
      "Epoch 10/10, Train Loss: 0.0482, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9715\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9755\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.94      0.99      0.97       175\n",
      "      others       0.89      0.97      0.93       158\n",
      "        part       0.99      0.96      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5025, Accuracy: 0.7183, F1 Micro: 0.7183, F1 Macro: 0.5395\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3177, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9252\n",
      "Epoch 3/10, Train Loss: 0.1954, Accuracy: 0.9246, F1 Micro: 0.9246, F1 Macro: 0.9139\n",
      "Epoch 4/10, Train Loss: 0.109, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9206\n",
      "Epoch 5/10, Train Loss: 0.1277, Accuracy: 0.9127, F1 Micro: 0.9127, F1 Macro: 0.904\n",
      "Epoch 6/10, Train Loss: 0.1046, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.9086\n",
      "Epoch 7/10, Train Loss: 0.1062, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.9009\n",
      "Epoch 8/10, Train Loss: 0.0675, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9192\n",
      "Epoch 9/10, Train Loss: 0.0419, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9196\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0518, Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9363\n",
      "\n",
      "Sentiment analysis accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9363\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        81\n",
      "    positive       0.96      0.96      0.96       171\n",
      "\n",
      "    accuracy                           0.94       252\n",
      "   macro avg       0.94      0.94      0.94       252\n",
      "weighted avg       0.94      0.94      0.94       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9475, F1 Micro: 0.9475, F1 Macro: 0.8899\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.75      0.71        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.84      0.82      0.83       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.42      0.67      0.52        12\n",
      "     neutral       0.89      0.92      0.91       152\n",
      "    positive       0.90      0.69      0.78        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.74      0.76      0.73       216\n",
      "weighted avg       0.87      0.85      0.85       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.91      0.89        23\n",
      "     neutral       0.99      0.96      0.97       152\n",
      "    positive       0.86      0.93      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.84      0.94      0.89        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.95      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 114.04301071166992 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.008786231279373169\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.952846527099609 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5322, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4358, Accuracy: 0.881, F1 Micro: 0.9274, F1 Macro: 0.9244\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2998, Accuracy: 0.9375, F1 Micro: 0.9612, F1 Macro: 0.9594\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1938, Accuracy: 0.9524, F1 Micro: 0.9705, F1 Macro: 0.9695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1442, Accuracy: 0.9561, F1 Micro: 0.9724, F1 Macro: 0.9706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1163, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0836, Accuracy: 0.9583, F1 Micro: 0.9735, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.065, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0598, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0494, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.974\n",
      "\n",
      "Aspect detection accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.974\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.89      0.96      0.92       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.99      0.98      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5453, Accuracy: 0.8731, F1 Micro: 0.8731, F1 Macro: 0.8505\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2458, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.9075\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1837, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.935\n",
      "Epoch 4/10, Train Loss: 0.1495, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9313\n",
      "Epoch 5/10, Train Loss: 0.1216, Accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.8991\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0793, Accuracy: 0.9538, F1 Micro: 0.9538, F1 Macro: 0.9469\n",
      "Epoch 7/10, Train Loss: 0.0849, Accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9388\n",
      "Epoch 8/10, Train Loss: 0.0643, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9287\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0545, Accuracy: 0.9538, F1 Micro: 0.9538, F1 Macro: 0.9476\n",
      "Epoch 10/10, Train Loss: 0.0224, Accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9388\n",
      "\n",
      "Sentiment analysis accuracy: 0.9538, F1 Micro: 0.9538, F1 Macro: 0.9476\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.96      0.93        82\n",
      "    positive       0.98      0.95      0.97       178\n",
      "\n",
      "    accuracy                           0.95       260\n",
      "   macro avg       0.94      0.96      0.95       260\n",
      "weighted avg       0.96      0.95      0.95       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9078\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.86      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.67      0.76        12\n",
      "     neutral       0.90      0.95      0.92       152\n",
      "    positive       0.84      0.73      0.78        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.88      0.78      0.82       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.92      0.83      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.99      0.98      0.99       186\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.90      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.96      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 125.59245729446411 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.004679739475250244\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.903975009918213 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5314, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4457, Accuracy: 0.8653, F1 Micro: 0.9206, F1 Macro: 0.919\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3077, Accuracy: 0.9412, F1 Micro: 0.9636, F1 Macro: 0.9624\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2002, Accuracy: 0.9531, F1 Micro: 0.9705, F1 Macro: 0.9688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1459, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1151, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9747\n",
      "Epoch 7/10, Train Loss: 0.0889, Accuracy: 0.9554, F1 Micro: 0.9719, F1 Macro: 0.9701\n",
      "Epoch 8/10, Train Loss: 0.0687, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9744\n",
      "Epoch 9/10, Train Loss: 0.0578, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9731\n",
      "Epoch 10/10, Train Loss: 0.0516, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9737\n",
      "\n",
      "Aspect detection accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9747\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.91      0.93      0.92       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4979, Accuracy: 0.8958, F1 Micro: 0.8958, F1 Macro: 0.8799\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2131, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.9068\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1481, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9153\n",
      "Epoch 4/10, Train Loss: 0.1382, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.8998\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1315, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9262\n",
      "Epoch 6/10, Train Loss: 0.106, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9193\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1057, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9271\n",
      "Epoch 8/10, Train Loss: 0.0794, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9234\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0527, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.93\n",
      "Epoch 10/10, Train Loss: 0.03, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9266\n",
      "\n",
      "Sentiment analysis accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.93      0.91        83\n",
      "    positive       0.97      0.94      0.95       176\n",
      "\n",
      "    accuracy                           0.94       259\n",
      "   macro avg       0.93      0.94      0.93       259\n",
      "weighted avg       0.94      0.94      0.94       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9483, F1 Micro: 0.9483, F1 Macro: 0.8893\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.97      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.68      0.81      0.74        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.92      0.70      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.85      0.83      0.83       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.83      0.74        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.82      0.77      0.79        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.80      0.84      0.82       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.96      0.86        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.89      0.80      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.91      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.86      0.86        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 121.51896262168884 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.009813308715820312\n",
      "Samples above threshold: 17\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.454111099243164 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5329, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4384, Accuracy: 0.8772, F1 Micro: 0.9272, F1 Macro: 0.9256\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2731, Accuracy: 0.9524, F1 Micro: 0.9706, F1 Macro: 0.9696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1823, Accuracy: 0.9568, F1 Micro: 0.9731, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1402, Accuracy: 0.9583, F1 Micro: 0.9741, F1 Macro: 0.9732\n",
      "Epoch 6/10, Train Loss: 0.1042, Accuracy: 0.9568, F1 Micro: 0.9727, F1 Macro: 0.9705\n",
      "Epoch 7/10, Train Loss: 0.0845, Accuracy: 0.9554, F1 Micro: 0.9718, F1 Macro: 0.9697\n",
      "Epoch 8/10, Train Loss: 0.0677, Accuracy: 0.9568, F1 Micro: 0.9726, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0555, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.975\n",
      "Epoch 10/10, Train Loss: 0.049, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9744\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.90      0.94      0.92       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4825, Accuracy: 0.9, F1 Micro: 0.9, F1 Macro: 0.8826\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2038, Accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9402\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1482, Accuracy: 0.9538, F1 Micro: 0.9538, F1 Macro: 0.9482\n",
      "Epoch 4/10, Train Loss: 0.1409, Accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9402\n",
      "Epoch 5/10, Train Loss: 0.1098, Accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.9443\n",
      "Epoch 6/10, Train Loss: 0.1235, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9235\n",
      "Epoch 7/10, Train Loss: 0.0933, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.928\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0855, Accuracy: 0.9577, F1 Micro: 0.9577, F1 Macro: 0.9521\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0816, Accuracy: 0.9615, F1 Micro: 0.9615, F1 Macro: 0.9566\n",
      "Epoch 10/10, Train Loss: 0.0652, Accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.9437\n",
      "\n",
      "Sentiment analysis accuracy: 0.9615, F1 Micro: 0.9615, F1 Macro: 0.9566\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.96      0.94        84\n",
      "    positive       0.98      0.96      0.97       176\n",
      "\n",
      "    accuracy                           0.96       260\n",
      "   macro avg       0.95      0.96      0.96       260\n",
      "weighted avg       0.96      0.96      0.96       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.9027\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.97      0.98      0.98       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.87      0.86      0.87       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.56      0.75      0.64        12\n",
      "     neutral       0.90      0.91      0.91       152\n",
      "    positive       0.83      0.73      0.78        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.76      0.80      0.78       216\n",
      "weighted avg       0.87      0.86      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 123.28696870803833 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.005281567573547363\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.097723484039307 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5264, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4219, Accuracy: 0.904, F1 Micro: 0.9422, F1 Macro: 0.9405\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2702, Accuracy: 0.9516, F1 Micro: 0.9699, F1 Macro: 0.9684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1797, Accuracy: 0.9606, F1 Micro: 0.9754, F1 Macro: 0.9741\n",
      "Epoch 5/10, Train Loss: 0.1275, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0946, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0758, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9789\n",
      "Epoch 8/10, Train Loss: 0.0639, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9759\n",
      "Epoch 9/10, Train Loss: 0.0481, Accuracy: 0.9606, F1 Micro: 0.975, F1 Macro: 0.9729\n",
      "Epoch 10/10, Train Loss: 0.0469, Accuracy: 0.965, F1 Micro: 0.9778, F1 Macro: 0.976\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.98      0.98      0.98       175\n",
      "      others       0.89      0.98      0.93       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4936, Accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.9051\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2619, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9374\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1505, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9381\n",
      "Epoch 4/10, Train Loss: 0.1507, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.9063\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1332, Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.956\n",
      "Epoch 6/10, Train Loss: 0.1024, Accuracy: 0.9528, F1 Micro: 0.9528, F1 Macro: 0.9473\n",
      "Epoch 7/10, Train Loss: 0.1033, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9385\n",
      "Epoch 8/10, Train Loss: 0.0823, Accuracy: 0.9567, F1 Micro: 0.9567, F1 Macro: 0.9512\n",
      "Epoch 9/10, Train Loss: 0.061, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9259\n",
      "Epoch 10/10, Train Loss: 0.0481, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9309\n",
      "\n",
      "Sentiment analysis accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.956\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94        83\n",
      "    positive       0.99      0.95      0.97       171\n",
      "\n",
      "    accuracy                           0.96       254\n",
      "   macro avg       0.95      0.96      0.96       254\n",
      "weighted avg       0.96      0.96      0.96       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9491, F1 Micro: 0.9491, F1 Macro: 0.8888\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.96      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.69      0.79        16\n",
      "     neutral       0.98      0.98      0.98       167\n",
      "    positive       0.81      0.88      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.85      0.87       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.33      0.83      0.48        12\n",
      "     neutral       0.94      0.89      0.92       152\n",
      "    positive       0.90      0.71      0.80        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.72      0.81      0.73       216\n",
      "weighted avg       0.90      0.85      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.90      0.90      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.85      0.81        13\n",
      "     neutral       0.99      0.98      0.99       186\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.87      0.90      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 120.00159549713135 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.005702465772628784\n",
      "Samples above threshold: 12\n",
      "Acquired samples: 8\n",
      "Sampling duration: 3.7915050983428955 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5281, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4375, Accuracy: 0.8876, F1 Micro: 0.9327, F1 Macro: 0.931\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2748, Accuracy: 0.9524, F1 Micro: 0.9706, F1 Macro: 0.9694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1849, Accuracy: 0.9554, F1 Micro: 0.9721, F1 Macro: 0.9707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1289, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1011, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9768\n",
      "Epoch 7/10, Train Loss: 0.0771, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9751\n",
      "Epoch 8/10, Train Loss: 0.0621, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0517, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9768\n",
      "Epoch 10/10, Train Loss: 0.0475, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9739\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.99      0.98       175\n",
      "      others       0.92      0.92      0.92       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5243, Accuracy: 0.8769, F1 Micro: 0.8769, F1 Macro: 0.8479\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2476, Accuracy: 0.9254, F1 Micro: 0.9254, F1 Macro: 0.9164\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1861, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9315\n",
      "Epoch 4/10, Train Loss: 0.1457, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9247\n",
      "Epoch 5/10, Train Loss: 0.1217, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9194\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.076, Accuracy: 0.9478, F1 Micro: 0.9478, F1 Macro: 0.9389\n",
      "Epoch 7/10, Train Loss: 0.0829, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.9283\n",
      "Epoch 8/10, Train Loss: 0.0659, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9209\n",
      "Epoch 9/10, Train Loss: 0.0541, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.9265\n",
      "Epoch 10/10, Train Loss: 0.0562, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.936\n",
      "\n",
      "Sentiment analysis accuracy: 0.9478, F1 Micro: 0.9478, F1 Macro: 0.9389\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.90      0.92        84\n",
      "    positive       0.96      0.97      0.96       184\n",
      "\n",
      "    accuracy                           0.95       268\n",
      "   macro avg       0.94      0.94      0.94       268\n",
      "weighted avg       0.95      0.95      0.95       268\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9131\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.97      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.97      0.98      0.98       167\n",
      "    positive       0.90      0.85      0.88        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.90      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.93      0.92      0.93       152\n",
      "    positive       0.75      0.77      0.76        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.82      0.84      0.83       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.84      0.94      0.89        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.92      0.93      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 125.15332460403442 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.004337859153747558\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.4437036514282227 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5311, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4175, Accuracy: 0.9159, F1 Micro: 0.9488, F1 Macro: 0.9473\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2533, Accuracy: 0.9449, F1 Micro: 0.9655, F1 Macro: 0.9633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1728, Accuracy: 0.9554, F1 Micro: 0.972, F1 Macro: 0.97\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1276, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0943, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0758, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9758\n",
      "Epoch 8/10, Train Loss: 0.0625, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0533, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9763\n",
      "Epoch 10/10, Train Loss: 0.044, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.974\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9763\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.93      0.92      0.92       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5219, Accuracy: 0.8889, F1 Micro: 0.8889, F1 Macro: 0.8686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2736, Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9366\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1416, Accuracy: 0.9481, F1 Micro: 0.9481, F1 Macro: 0.9403\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1136, Accuracy: 0.9519, F1 Micro: 0.9519, F1 Macro: 0.9447\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.132, Accuracy: 0.9519, F1 Micro: 0.9519, F1 Macro: 0.9447\n",
      "Epoch 6/10, Train Loss: 0.1115, Accuracy: 0.9481, F1 Micro: 0.9481, F1 Macro: 0.9406\n",
      "Epoch 7/10, Train Loss: 0.1085, Accuracy: 0.9259, F1 Micro: 0.9259, F1 Macro: 0.9112\n",
      "Epoch 8/10, Train Loss: 0.0695, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9258\n",
      "Epoch 9/10, Train Loss: 0.0573, Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.935\n",
      "Epoch 10/10, Train Loss: 0.0499, Accuracy: 0.9481, F1 Micro: 0.9481, F1 Macro: 0.9391\n",
      "\n",
      "Sentiment analysis accuracy: 0.9519, F1 Micro: 0.9519, F1 Macro: 0.9447\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.92        84\n",
      "    positive       0.98      0.95      0.96       186\n",
      "\n",
      "    accuracy                           0.95       270\n",
      "   macro avg       0.94      0.95      0.94       270\n",
      "weighted avg       0.95      0.95      0.95       270\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9141\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.97      0.98      0.98       167\n",
      "    positive       0.82      0.82      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.85      0.86       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.93      0.91      0.92       152\n",
      "    positive       0.75      0.81      0.78        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.83      0.82      0.83       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.91      0.87        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.90      0.88      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.89      0.94      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.93      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.93      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 132.54818058013916 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.003533828258514404\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.0025010108947754 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.528, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4232, Accuracy: 0.9137, F1 Micro: 0.9476, F1 Macro: 0.9457\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2581, Accuracy: 0.9539, F1 Micro: 0.9713, F1 Macro: 0.9701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1742, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9769\n",
      "Epoch 5/10, Train Loss: 0.1204, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9747\n",
      "Epoch 6/10, Train Loss: 0.0952, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9748\n",
      "Epoch 7/10, Train Loss: 0.0726, Accuracy: 0.9635, F1 Micro: 0.9768, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0588, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9777\n",
      "Epoch 9/10, Train Loss: 0.0487, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9751\n",
      "Epoch 10/10, Train Loss: 0.0408, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9771\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9777\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.93      0.95      0.94       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5116, Accuracy: 0.8939, F1 Micro: 0.8939, F1 Macro: 0.8813\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2399, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9273\n",
      "Epoch 3/10, Train Loss: 0.1685, Accuracy: 0.9242, F1 Micro: 0.9242, F1 Macro: 0.9097\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1344, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.931\n",
      "Epoch 5/10, Train Loss: 0.1054, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9273\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0969, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9306\n",
      "Epoch 7/10, Train Loss: 0.0689, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9282\n",
      "Epoch 8/10, Train Loss: 0.0739, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9278\n",
      "Epoch 9/10, Train Loss: 0.068, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9197\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0843, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9322\n",
      "\n",
      "Sentiment analysis accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9322\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.96      0.91        84\n",
      "    positive       0.98      0.93      0.95       180\n",
      "\n",
      "    accuracy                           0.94       264\n",
      "   macro avg       0.92      0.95      0.93       264\n",
      "weighted avg       0.94      0.94      0.94       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9106\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.88      0.78        16\n",
      "     neutral       0.97      0.98      0.98       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.85      0.86      0.85       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.53      0.83      0.65        12\n",
      "     neutral       0.93      0.91      0.92       152\n",
      "    positive       0.83      0.77      0.80        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.76      0.84      0.79       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.92      0.83      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.89      0.94      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.95      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 127.67971730232239 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0038720488548278816\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.6049864292144775 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5234, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4134, Accuracy: 0.9092, F1 Micro: 0.9443, F1 Macro: 0.9423\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2562, Accuracy: 0.9524, F1 Micro: 0.9704, F1 Macro: 0.9691\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1564, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1213, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9771\n",
      "Epoch 6/10, Train Loss: 0.0949, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9736\n",
      "Epoch 7/10, Train Loss: 0.0737, Accuracy: 0.9621, F1 Micro: 0.9759, F1 Macro: 0.9739\n",
      "Epoch 8/10, Train Loss: 0.061, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.054, Accuracy: 0.9717, F1 Micro: 0.9822, F1 Macro: 0.9809\n",
      "Epoch 10/10, Train Loss: 0.0459, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9777\n",
      "\n",
      "Aspect detection accuracy: 0.9717, F1 Micro: 0.9822, F1 Macro: 0.9809\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.94      0.94      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      1.00      1.00       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.98      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4828, Accuracy: 0.9094, F1 Micro: 0.9094, F1 Macro: 0.9001\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2493, Accuracy: 0.9358, F1 Micro: 0.9358, F1 Macro: 0.9287\n",
      "Epoch 3/10, Train Loss: 0.1732, Accuracy: 0.917, F1 Micro: 0.917, F1 Macro: 0.9102\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1338, Accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.9344\n",
      "Epoch 5/10, Train Loss: 0.147, Accuracy: 0.9208, F1 Micro: 0.9208, F1 Macro: 0.9137\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1056, Accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.9408\n",
      "Epoch 7/10, Train Loss: 0.0932, Accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.9374\n",
      "Epoch 8/10, Train Loss: 0.078, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9334\n",
      "Epoch 9/10, Train Loss: 0.0778, Accuracy: 0.9208, F1 Micro: 0.9208, F1 Macro: 0.9132\n",
      "Epoch 10/10, Train Loss: 0.052, Accuracy: 0.9321, F1 Micro: 0.9321, F1 Macro: 0.9221\n",
      "\n",
      "Sentiment analysis accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.9408\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.95      0.92        86\n",
      "    positive       0.98      0.94      0.96       179\n",
      "\n",
      "    accuracy                           0.95       265\n",
      "   macro avg       0.93      0.95      0.94       265\n",
      "weighted avg       0.95      0.95      0.95       265\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9089\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.69      0.79        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.82      0.86       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.92      0.85        12\n",
      "     neutral       0.95      0.93      0.94       152\n",
      "    positive       0.83      0.83      0.83        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.85      0.89      0.87       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.96      0.85        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.92      0.90       216\n",
      "weighted avg       0.95      0.94      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.98      0.99       186\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.91      0.95      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.85      1.00      0.92        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.93      0.93       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 129.92372012138367 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.003076791763305664\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.9858040809631348 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5131, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3896, Accuracy: 0.9196, F1 Micro: 0.9509, F1 Macro: 0.9492\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2485, Accuracy: 0.9546, F1 Micro: 0.9718, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1623, Accuracy: 0.9628, F1 Micro: 0.9768, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1229, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9782\n",
      "Epoch 6/10, Train Loss: 0.0956, Accuracy: 0.9643, F1 Micro: 0.9773, F1 Macro: 0.9754\n",
      "Epoch 7/10, Train Loss: 0.0748, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9779\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.06, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9782\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0484, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9787\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0402, Accuracy: 0.9702, F1 Micro: 0.9812, F1 Macro: 0.9799\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9812, F1 Macro: 0.9799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.94      0.94      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4755, Accuracy: 0.9033, F1 Micro: 0.9033, F1 Macro: 0.8947\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2002, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9332\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.165, Accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9379\n",
      "Epoch 4/10, Train Loss: 0.1618, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.926\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1144, Accuracy: 0.9517, F1 Micro: 0.9517, F1 Macro: 0.9459\n",
      "Epoch 6/10, Train Loss: 0.0816, Accuracy: 0.948, F1 Micro: 0.948, F1 Macro: 0.9412\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0716, Accuracy: 0.9517, F1 Micro: 0.9517, F1 Macro: 0.9462\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0724, Accuracy: 0.9517, F1 Micro: 0.9517, F1 Macro: 0.9459\n",
      "Epoch 9/10, Train Loss: 0.0776, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9339\n",
      "Epoch 10/10, Train Loss: 0.0702, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.92\n",
      "\n",
      "Sentiment analysis accuracy: 0.9517, F1 Micro: 0.9517, F1 Macro: 0.9459\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.97      0.93        87\n",
      "    positive       0.98      0.95      0.96       182\n",
      "\n",
      "    accuracy                           0.95       269\n",
      "   macro avg       0.94      0.96      0.95       269\n",
      "weighted avg       0.95      0.95      0.95       269\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9096\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.82      0.86        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.92      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.81      0.79      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.84      0.86       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.94      0.93      0.94       152\n",
      "    positive       0.79      0.81      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.86      0.86      0.86       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 139.92999625205994 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.001438993215560913\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 8\n",
      "Sampling duration: 1.5421788692474365 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.519, Accuracy: 0.7924, F1 Micro: 0.8831, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.405, Accuracy: 0.9204, F1 Micro: 0.9512, F1 Macro: 0.9495\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2579, Accuracy: 0.9539, F1 Micro: 0.9713, F1 Macro: 0.9699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1651, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.125, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9779\n",
      "Epoch 6/10, Train Loss: 0.0966, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.072, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9783\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0569, Accuracy: 0.9702, F1 Micro: 0.9812, F1 Macro: 0.9798\n",
      "Epoch 9/10, Train Loss: 0.0497, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9776\n",
      "Epoch 10/10, Train Loss: 0.0412, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9783\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9812, F1 Macro: 0.9798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.94      0.94      0.94       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4468, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9298\n",
      "Epoch 2/10, Train Loss: 0.2159, Accuracy: 0.9304, F1 Micro: 0.9304, F1 Macro: 0.9231\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1528, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9298\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1342, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9373\n",
      "Epoch 5/10, Train Loss: 0.1121, Accuracy: 0.9267, F1 Micro: 0.9267, F1 Macro: 0.918\n",
      "Epoch 6/10, Train Loss: 0.0913, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9305\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0885, Accuracy: 0.9487, F1 Micro: 0.9487, F1 Macro: 0.9413\n",
      "Epoch 8/10, Train Loss: 0.0846, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9231\n",
      "Epoch 9/10, Train Loss: 0.0565, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9301\n",
      "Epoch 10/10, Train Loss: 0.0615, Accuracy: 0.9267, F1 Micro: 0.9267, F1 Macro: 0.9162\n",
      "\n",
      "Sentiment analysis accuracy: 0.9487, F1 Micro: 0.9487, F1 Macro: 0.9413\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.93      0.92        87\n",
      "    positive       0.97      0.96      0.96       186\n",
      "\n",
      "    accuracy                           0.95       273\n",
      "   macro avg       0.94      0.94      0.94       273\n",
      "weighted avg       0.95      0.95      0.95       273\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9058\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.98      0.98      0.98       167\n",
      "    positive       0.81      0.88      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.58      0.92      0.71        12\n",
      "     neutral       0.95      0.91      0.93       152\n",
      "    positive       0.80      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.78      0.87      0.81       216\n",
      "weighted avg       0.90      0.88      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.89      1.00      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 134.95682787895203 s\n",
      "Total runtime: 2934.77388715744 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[3], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61099592",
   "metadata": {
    "papermill": {
     "duration": 0.29419,
     "end_time": "2025-03-23T10:14:18.490968",
     "exception": false,
     "start_time": "2025-03-23T10:14:18.196778",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5fd6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 5\n",
      "Random seed: 94\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6298, Accuracy: 0.7522, F1 Micro: 0.854, F1 Macro: 0.8362\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5654, Accuracy: 0.7887, F1 Micro: 0.8819, F1 Macro: 0.8803\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5262, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4783, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4582, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4326, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4132, Accuracy: 0.7924, F1 Micro: 0.8837, F1 Macro: 0.8822\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4395, Accuracy: 0.7939, F1 Micro: 0.8842, F1 Macro: 0.8826\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.4306, Accuracy: 0.7999, F1 Micro: 0.887, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3956, Accuracy: 0.8036, F1 Micro: 0.8888, F1 Macro: 0.8871\n",
      "\n",
      "Aspect detection accuracy: 0.8036, F1 Micro: 0.8888, F1 Macro: 0.8871\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.78      1.00      0.88       175\n",
      "      others       0.75      0.99      0.85       158\n",
      "        part       0.74      0.97      0.84       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.80      0.99      0.89      1061\n",
      "   macro avg       0.80      0.99      0.89      1061\n",
      "weighted avg       0.81      0.99      0.89      1061\n",
      " samples avg       0.81      0.99      0.89      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7142, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5719, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.6151, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5677, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.5123, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.5138, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4932, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3579, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3098, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2431, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "\n",
      "Sentiment analysis accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         6\n",
      "    positive       0.81      1.00      0.89        25\n",
      "\n",
      "    accuracy                           0.81        31\n",
      "   macro avg       0.40      0.50      0.45        31\n",
      "weighted avg       0.65      0.81      0.72        31\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.7994, F1 Micro: 0.7994, F1 Macro: 0.3298\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.77      1.00      0.87       167\n",
      "    positive       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.77       216\n",
      "   macro avg       0.26      0.33      0.29       216\n",
      "weighted avg       0.60      0.77      0.67       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.75      0.99      0.85       152\n",
      "    positive       0.67      0.19      0.30        52\n",
      "\n",
      "    accuracy                           0.74       216\n",
      "   macro avg       0.47      0.39      0.38       216\n",
      "weighted avg       0.69      0.74      0.67       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        23\n",
      "     neutral       0.74      0.97      0.84       152\n",
      "    positive       0.56      0.22      0.32        41\n",
      "\n",
      "    accuracy                           0.73       216\n",
      "   macro avg       0.43      0.40      0.39       216\n",
      "weighted avg       0.63      0.73      0.65       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 68.61383652687073 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.06025115251541138\n",
      "Samples above threshold: 81\n",
      "Acquired samples: 81\n",
      "Sampling duration: 9.929436922073364 seconds\n",
      "New train size: 135\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6008, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4984, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4596, Accuracy: 0.7954, F1 Micro: 0.8851, F1 Macro: 0.8835\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4592, Accuracy: 0.8043, F1 Micro: 0.8891, F1 Macro: 0.8873\n",
      "Epoch 5/10, Train Loss: 0.428, Accuracy: 0.8065, F1 Micro: 0.8885, F1 Macro: 0.8857\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.387, Accuracy: 0.8192, F1 Micro: 0.8957, F1 Macro: 0.8938\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.391, Accuracy: 0.8259, F1 Micro: 0.8983, F1 Macro: 0.8961\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3192, Accuracy: 0.8318, F1 Micro: 0.9011, F1 Macro: 0.8988\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2818, Accuracy: 0.8408, F1 Micro: 0.9058, F1 Macro: 0.9032\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2687, Accuracy: 0.8542, F1 Micro: 0.9134, F1 Macro: 0.9119\n",
      "\n",
      "Aspect detection accuracy: 0.8542, F1 Micro: 0.9134, F1 Macro: 0.9119\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.85      1.00      0.92       187\n",
      "     machine       0.79      1.00      0.88       175\n",
      "      others       0.87      0.87      0.87       158\n",
      "        part       0.88      0.96      0.92       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.92      1.00      0.96       191\n",
      "\n",
      "   micro avg       0.86      0.97      0.91      1061\n",
      "   macro avg       0.86      0.97      0.91      1061\n",
      "weighted avg       0.86      0.97      0.91      1061\n",
      " samples avg       0.86      0.97      0.91      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5954, Accuracy: 0.7574, F1 Micro: 0.7574, F1 Macro: 0.431\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4046, Accuracy: 0.7574, F1 Micro: 0.7574, F1 Macro: 0.431\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3482, Accuracy: 0.7574, F1 Micro: 0.7574, F1 Macro: 0.431\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3802, Accuracy: 0.7721, F1 Micro: 0.7721, F1 Macro: 0.5549\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2328, Accuracy: 0.8235, F1 Micro: 0.8235, F1 Macro: 0.7227\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2009, Accuracy: 0.8529, F1 Micro: 0.8529, F1 Macro: 0.7809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1362, Accuracy: 0.8824, F1 Micro: 0.8824, F1 Macro: 0.84\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0642, Accuracy: 0.8824, F1 Micro: 0.8824, F1 Macro: 0.8247\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.065, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.8774\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0229, Accuracy: 0.9191, F1 Micro: 0.9191, F1 Macro: 0.8888\n",
      "\n",
      "Sentiment analysis accuracy: 0.9191, F1 Micro: 0.9191, F1 Macro: 0.8888\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.82      0.83        33\n",
      "    positive       0.94      0.95      0.95       103\n",
      "\n",
      "    accuracy                           0.92       136\n",
      "   macro avg       0.89      0.88      0.89       136\n",
      "weighted avg       0.92      0.92      0.92       136\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 135: Accuracy: 0.8465, F1 Micro: 0.8465, F1 Macro: 0.5379\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.85      1.00      0.92       181\n",
      "    positive       1.00      0.17      0.29        24\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.62      0.39      0.40       216\n",
      "weighted avg       0.83      0.86      0.80       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.78      1.00      0.88       167\n",
      "    positive       1.00      0.06      0.11        33\n",
      "\n",
      "    accuracy                           0.78       216\n",
      "   macro avg       0.59      0.35      0.33       216\n",
      "weighted avg       0.76      0.78      0.70       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.58      0.58      0.58        12\n",
      "     neutral       0.87      0.86      0.86       152\n",
      "    positive       0.64      0.65      0.65        52\n",
      "\n",
      "    accuracy                           0.80       216\n",
      "   macro avg       0.70      0.70      0.70       216\n",
      "weighted avg       0.80      0.80      0.80       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.57      0.72        23\n",
      "     neutral       0.88      0.96      0.92       152\n",
      "    positive       0.76      0.68      0.72        41\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.88      0.74      0.79       216\n",
      "weighted avg       0.87      0.87      0.86       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.50      0.67        14\n",
      "     neutral       0.92      1.00      0.96       185\n",
      "    positive       0.75      0.35      0.48        17\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.89      0.62      0.70       216\n",
      "weighted avg       0.91      0.92      0.90       216\n",
      "\n",
      "Total train time: 72.92659640312195 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.04385221004486085\n",
      "Samples above threshold: 73\n",
      "Acquired samples: 73\n",
      "Sampling duration: 11.055230379104614 seconds\n",
      "New train size: 208\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5951, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5328, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5072, Accuracy: 0.7954, F1 Micro: 0.8846, F1 Macro: 0.8828\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4701, Accuracy: 0.8132, F1 Micro: 0.8942, F1 Macro: 0.8929\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.406, Accuracy: 0.8199, F1 Micro: 0.8964, F1 Macro: 0.8946\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3773, Accuracy: 0.8549, F1 Micro: 0.9143, F1 Macro: 0.9126\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.315, Accuracy: 0.8839, F1 Micro: 0.9307, F1 Macro: 0.9294\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2534, Accuracy: 0.8943, F1 Micro: 0.9358, F1 Macro: 0.9333\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2101, Accuracy: 0.901, F1 Micro: 0.9393, F1 Macro: 0.9361\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.17, Accuracy: 0.9249, F1 Micro: 0.9536, F1 Macro: 0.9512\n",
      "\n",
      "Aspect detection accuracy: 0.9249, F1 Micro: 0.9536, F1 Macro: 0.9512\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.96      1.00      0.98       187\n",
      "     machine       0.89      0.99      0.94       175\n",
      "      others       0.88      0.91      0.89       158\n",
      "        part       0.89      0.97      0.93       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.97      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.93      0.98      0.95      1061\n",
      "   macro avg       0.93      0.98      0.95      1061\n",
      "weighted avg       0.93      0.98      0.95      1061\n",
      " samples avg       0.93      0.98      0.95      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5562, Accuracy: 0.7032, F1 Micro: 0.7032, F1 Macro: 0.4129\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.423, Accuracy: 0.7032, F1 Micro: 0.7032, F1 Macro: 0.4129\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3451, Accuracy: 0.8356, F1 Micro: 0.8356, F1 Macro: 0.7841\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2036, Accuracy: 0.8995, F1 Micro: 0.8995, F1 Macro: 0.8845\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0895, Accuracy: 0.9178, F1 Micro: 0.9178, F1 Macro: 0.8977\n",
      "Epoch 6/10, Train Loss: 0.1086, Accuracy: 0.895, F1 Micro: 0.895, F1 Macro: 0.8822\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0844, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.914\n",
      "Epoch 8/10, Train Loss: 0.0664, Accuracy: 0.8995, F1 Micro: 0.8995, F1 Macro: 0.8696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0301, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9133\n",
      "Epoch 10/10, Train Loss: 0.0139, Accuracy: 0.9178, F1 Micro: 0.9178, F1 Macro: 0.9032\n",
      "\n",
      "Sentiment analysis accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9133\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.89      0.88        65\n",
      "    positive       0.95      0.94      0.95       154\n",
      "\n",
      "    accuracy                           0.93       219\n",
      "   macro avg       0.91      0.92      0.91       219\n",
      "weighted avg       0.93      0.93      0.93       219\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 208: Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.8195\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.55      0.71        11\n",
      "     neutral       0.97      1.00      0.98       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.97      0.82      0.88       216\n",
      "weighted avg       0.97      0.97      0.96       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.56      0.67        16\n",
      "     neutral       0.89      0.99      0.93       167\n",
      "    positive       0.89      0.52      0.65        33\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.87      0.69      0.75       216\n",
      "weighted avg       0.88      0.88      0.87       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.75      0.67        12\n",
      "     neutral       0.88      0.90      0.89       152\n",
      "    positive       0.72      0.63      0.67        52\n",
      "\n",
      "    accuracy                           0.83       216\n",
      "   macro avg       0.73      0.76      0.74       216\n",
      "weighted avg       0.83      0.83      0.83       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.57      0.68        23\n",
      "     neutral       0.89      0.98      0.93       152\n",
      "    positive       0.85      0.68      0.76        41\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.87      0.74      0.79       216\n",
      "weighted avg       0.88      0.88      0.87       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.86      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.79      0.85        14\n",
      "     neutral       0.97      1.00      0.98       185\n",
      "    positive       0.85      0.65      0.73        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.91      0.81      0.85       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Total train time: 83.12248611450195 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.026847511529922485\n",
      "Samples above threshold: 66\n",
      "Acquired samples: 66\n",
      "Sampling duration: 12.72124981880188 seconds\n",
      "New train size: 274\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5859, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5244, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4789, Accuracy: 0.8065, F1 Micro: 0.8903, F1 Macro: 0.8886\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.418, Accuracy: 0.8341, F1 Micro: 0.9038, F1 Macro: 0.9022\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3571, Accuracy: 0.8765, F1 Micro: 0.9263, F1 Macro: 0.9247\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2758, Accuracy: 0.8943, F1 Micro: 0.936, F1 Macro: 0.9343\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2231, Accuracy: 0.9174, F1 Micro: 0.9495, F1 Macro: 0.9476\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1785, Accuracy: 0.9204, F1 Micro: 0.9509, F1 Macro: 0.9489\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1452, Accuracy: 0.9219, F1 Micro: 0.9513, F1 Macro: 0.9477\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1191, Accuracy: 0.9315, F1 Micro: 0.9572, F1 Macro: 0.9542\n",
      "\n",
      "Aspect detection accuracy: 0.9315, F1 Micro: 0.9572, F1 Macro: 0.9542\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.97      0.99      0.98       187\n",
      "     machine       0.93      0.99      0.96       175\n",
      "      others       0.91      0.85      0.88       158\n",
      "        part       0.91      0.99      0.95       158\n",
      "       price       0.97      0.97      0.97       192\n",
      "     service       0.97      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.95      0.97      0.96      1061\n",
      "   macro avg       0.94      0.97      0.95      1061\n",
      "weighted avg       0.95      0.97      0.96      1061\n",
      " samples avg       0.95      0.96      0.95      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5237, Accuracy: 0.724, F1 Micro: 0.724, F1 Macro: 0.42\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3352, Accuracy: 0.872, F1 Micro: 0.872, F1 Macro: 0.8246\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1947, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9092\n",
      "Epoch 4/10, Train Loss: 0.1304, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.8901\n",
      "Epoch 5/10, Train Loss: 0.0667, Accuracy: 0.912, F1 Micro: 0.912, F1 Macro: 0.8927\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0913, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9053\n",
      "Epoch 7/10, Train Loss: 0.0872, Accuracy: 0.892, F1 Micro: 0.892, F1 Macro: 0.8755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0609, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9099\n",
      "Epoch 9/10, Train Loss: 0.0364, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.8917\n",
      "Epoch 10/10, Train Loss: 0.0372, Accuracy: 0.912, F1 Micro: 0.912, F1 Macro: 0.8944\n",
      "\n",
      "Sentiment analysis accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9099\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87        69\n",
      "    positive       0.95      0.95      0.95       181\n",
      "\n",
      "    accuracy                           0.93       250\n",
      "   macro avg       0.91      0.91      0.91       250\n",
      "weighted avg       0.93      0.93      0.93       250\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 274: Accuracy: 0.9182, F1 Micro: 0.9182, F1 Macro: 0.8347\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.64      0.78        11\n",
      "     neutral       0.98      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.85      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.62      0.71        16\n",
      "     neutral       0.92      0.99      0.96       167\n",
      "    positive       0.92      0.67      0.77        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.89      0.76      0.81       216\n",
      "weighted avg       0.91      0.92      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.56      0.75      0.64        12\n",
      "     neutral       0.91      0.84      0.88       152\n",
      "    positive       0.63      0.73      0.68        52\n",
      "\n",
      "    accuracy                           0.81       216\n",
      "   macro avg       0.70      0.77      0.73       216\n",
      "weighted avg       0.83      0.81      0.82       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.61      0.68        23\n",
      "     neutral       0.91      0.99      0.95       152\n",
      "    positive       0.91      0.73      0.81        41\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.87      0.78      0.81       216\n",
      "weighted avg       0.90      0.90      0.89       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.77      0.77        13\n",
      "     neutral       0.97      0.97      0.97       186\n",
      "    positive       0.76      0.76      0.76        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.84      0.84      0.84       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.97      1.00      0.98       185\n",
      "    positive       1.00      0.71      0.83        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.99      0.88      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 89.14673209190369 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.018966501951217653\n",
      "Samples above threshold: 59\n",
      "Acquired samples: 59\n",
      "Sampling duration: 13.7549729347229 seconds\n",
      "New train size: 333\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5803, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5017, Accuracy: 0.7999, F1 Micro: 0.8873, F1 Macro: 0.8858\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4758, Accuracy: 0.8251, F1 Micro: 0.9001, F1 Macro: 0.8988\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3716, Accuracy: 0.8802, F1 Micro: 0.9282, F1 Macro: 0.9265\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2906, Accuracy: 0.9137, F1 Micro: 0.9471, F1 Macro: 0.9456\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2261, Accuracy: 0.9196, F1 Micro: 0.9507, F1 Macro: 0.9486\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1732, Accuracy: 0.9338, F1 Micro: 0.9589, F1 Macro: 0.9568\n",
      "Epoch 8/10, Train Loss: 0.1312, Accuracy: 0.9308, F1 Micro: 0.9565, F1 Macro: 0.9524\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1136, Accuracy: 0.939, F1 Micro: 0.962, F1 Macro: 0.9599\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0915, Accuracy: 0.942, F1 Micro: 0.9638, F1 Macro: 0.9614\n",
      "\n",
      "Aspect detection accuracy: 0.942, F1 Micro: 0.9638, F1 Macro: 0.9614\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.91      0.89      0.90       158\n",
      "        part       0.90      0.99      0.94       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.97      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.95      0.98      0.96      1061\n",
      "   macro avg       0.95      0.98      0.96      1061\n",
      "weighted avg       0.95      0.98      0.96      1061\n",
      " samples avg       0.95      0.97      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4727, Accuracy: 0.7037, F1 Micro: 0.7037, F1 Macro: 0.413\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.305, Accuracy: 0.8848, F1 Micro: 0.8848, F1 Macro: 0.8451\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2312, Accuracy: 0.9095, F1 Micro: 0.9095, F1 Macro: 0.8988\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1176, Accuracy: 0.9424, F1 Micro: 0.9424, F1 Macro: 0.9304\n",
      "Epoch 5/10, Train Loss: 0.1201, Accuracy: 0.9218, F1 Micro: 0.9218, F1 Macro: 0.9118\n",
      "Epoch 6/10, Train Loss: 0.0372, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9158\n",
      "Epoch 7/10, Train Loss: 0.0526, Accuracy: 0.9177, F1 Micro: 0.9177, F1 Macro: 0.9062\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0489, Accuracy: 0.9424, F1 Micro: 0.9424, F1 Macro: 0.932\n",
      "Epoch 9/10, Train Loss: 0.047, Accuracy: 0.9259, F1 Micro: 0.9259, F1 Macro: 0.9145\n",
      "Epoch 10/10, Train Loss: 0.0274, Accuracy: 0.9383, F1 Micro: 0.9383, F1 Macro: 0.9238\n",
      "\n",
      "Sentiment analysis accuracy: 0.9424, F1 Micro: 0.9424, F1 Macro: 0.932\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.93      0.91        72\n",
      "    positive       0.97      0.95      0.96       171\n",
      "\n",
      "    accuracy                           0.94       243\n",
      "   macro avg       0.93      0.94      0.93       243\n",
      "weighted avg       0.94      0.94      0.94       243\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 333: Accuracy: 0.9321, F1 Micro: 0.9321, F1 Macro: 0.8625\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.98      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.88      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.62      0.77        16\n",
      "     neutral       0.94      0.99      0.97       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.93      0.79      0.84       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.91      0.89      0.90       152\n",
      "    positive       0.73      0.79      0.76        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.82      0.81      0.82       216\n",
      "weighted avg       0.86      0.86      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.52      0.65        23\n",
      "     neutral       0.90      0.99      0.94       152\n",
      "    positive       0.86      0.76      0.81        41\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.87      0.75      0.80       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.86      0.89       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.97      1.00      0.99       185\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.97      0.87      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 88.21508073806763 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.014655888080596924\n",
      "Samples above threshold: 54\n",
      "Acquired samples: 54\n",
      "Sampling duration: 12.171477317810059 seconds\n",
      "New train size: 387\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5575, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4927, Accuracy: 0.8013, F1 Micro: 0.8882, F1 Macro: 0.8868\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4315, Accuracy: 0.8557, F1 Micro: 0.9157, F1 Macro: 0.9144\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3214, Accuracy: 0.9137, F1 Micro: 0.9477, F1 Macro: 0.9462\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2361, Accuracy: 0.9382, F1 Micro: 0.9616, F1 Macro: 0.9593\n",
      "Epoch 6/10, Train Loss: 0.1728, Accuracy: 0.9382, F1 Micro: 0.9615, F1 Macro: 0.9588\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1413, Accuracy: 0.9427, F1 Micro: 0.9641, F1 Macro: 0.9612\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1081, Accuracy: 0.9427, F1 Micro: 0.9643, F1 Macro: 0.9619\n",
      "Epoch 9/10, Train Loss: 0.0923, Accuracy: 0.942, F1 Micro: 0.9639, F1 Macro: 0.9614\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0797, Accuracy: 0.9516, F1 Micro: 0.9698, F1 Macro: 0.9679\n",
      "\n",
      "Aspect detection accuracy: 0.9516, F1 Micro: 0.9698, F1 Macro: 0.9679\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      0.99      0.97       175\n",
      "      others       0.91      0.92      0.91       158\n",
      "        part       0.93      0.99      0.96       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.95      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.503, Accuracy: 0.6967, F1 Micro: 0.6967, F1 Macro: 0.4106\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.338, Accuracy: 0.9057, F1 Micro: 0.9057, F1 Macro: 0.8862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1479, Accuracy: 0.9467, F1 Micro: 0.9467, F1 Macro: 0.9372\n",
      "Epoch 4/10, Train Loss: 0.1183, Accuracy: 0.9262, F1 Micro: 0.9262, F1 Macro: 0.912\n",
      "Epoch 5/10, Train Loss: 0.0462, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.8977\n",
      "Epoch 6/10, Train Loss: 0.092, Accuracy: 0.9303, F1 Micro: 0.9303, F1 Macro: 0.9207\n",
      "Epoch 7/10, Train Loss: 0.0815, Accuracy: 0.9262, F1 Micro: 0.9262, F1 Macro: 0.9099\n",
      "Epoch 8/10, Train Loss: 0.0526, Accuracy: 0.9262, F1 Micro: 0.9262, F1 Macro: 0.9106\n",
      "Epoch 9/10, Train Loss: 0.0462, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9286\n",
      "Epoch 10/10, Train Loss: 0.0465, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.927\n",
      "\n",
      "Sentiment analysis accuracy: 0.9467, F1 Micro: 0.9467, F1 Macro: 0.9372\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.92      0.91        74\n",
      "    positive       0.96      0.96      0.96       170\n",
      "\n",
      "    accuracy                           0.95       244\n",
      "   macro avg       0.94      0.94      0.94       244\n",
      "weighted avg       0.95      0.95      0.95       244\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 387: Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.8791\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.62      0.74        16\n",
      "     neutral       0.94      0.99      0.97       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.78      0.83       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.91      0.91      0.91       152\n",
      "    positive       0.75      0.77      0.76        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.83      0.81      0.82       216\n",
      "weighted avg       0.87      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.70      0.74        23\n",
      "     neutral       0.93      0.99      0.96       152\n",
      "    positive       0.91      0.76      0.83        41\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.88      0.81      0.84       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.97      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.97      0.86      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 88.07823777198792 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.011854958534240725\n",
      "Samples above threshold: 48\n",
      "Acquired samples: 48\n",
      "Sampling duration: 10.667458295822144 seconds\n",
      "New train size: 435\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5606, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4904, Accuracy: 0.8043, F1 Micro: 0.8888, F1 Macro: 0.887\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4085, Accuracy: 0.8713, F1 Micro: 0.9242, F1 Macro: 0.923\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2985, Accuracy: 0.9249, F1 Micro: 0.9534, F1 Macro: 0.9506\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2158, Accuracy: 0.939, F1 Micro: 0.9621, F1 Macro: 0.9601\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1627, Accuracy: 0.9442, F1 Micro: 0.9651, F1 Macro: 0.9626\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1275, Accuracy: 0.9479, F1 Micro: 0.9676, F1 Macro: 0.9659\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1051, Accuracy: 0.9576, F1 Micro: 0.9736, F1 Macro: 0.9724\n",
      "Epoch 9/10, Train Loss: 0.0836, Accuracy: 0.9472, F1 Micro: 0.967, F1 Macro: 0.9648\n",
      "Epoch 10/10, Train Loss: 0.0702, Accuracy: 0.9494, F1 Micro: 0.9685, F1 Macro: 0.9667\n",
      "\n",
      "Aspect detection accuracy: 0.9576, F1 Micro: 0.9736, F1 Macro: 0.9724\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      1.00      0.97       175\n",
      "      others       0.90      0.96      0.93       158\n",
      "        part       0.95      0.99      0.97       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.97      1061\n",
      "   macro avg       0.95      0.99      0.97      1061\n",
      "weighted avg       0.96      0.99      0.97      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4574, Accuracy: 0.678, F1 Micro: 0.678, F1 Macro: 0.404\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2736, Accuracy: 0.9322, F1 Micro: 0.9322, F1 Macro: 0.9244\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1669, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9367\n",
      "Epoch 4/10, Train Loss: 0.1107, Accuracy: 0.9364, F1 Micro: 0.9364, F1 Macro: 0.9293\n",
      "Epoch 5/10, Train Loss: 0.0959, Accuracy: 0.9322, F1 Micro: 0.9322, F1 Macro: 0.9239\n",
      "Epoch 6/10, Train Loss: 0.0988, Accuracy: 0.9322, F1 Micro: 0.9322, F1 Macro: 0.9244\n",
      "Epoch 7/10, Train Loss: 0.1262, Accuracy: 0.9322, F1 Micro: 0.9322, F1 Macro: 0.9188\n",
      "Epoch 8/10, Train Loss: 0.0925, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.93\n",
      "Epoch 9/10, Train Loss: 0.0606, Accuracy: 0.9237, F1 Micro: 0.9237, F1 Macro: 0.9159\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.05, Accuracy: 0.9534, F1 Micro: 0.9534, F1 Macro: 0.9475\n",
      "\n",
      "Sentiment analysis accuracy: 0.9534, F1 Micro: 0.9534, F1 Macro: 0.9475\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.96      0.93        76\n",
      "    positive       0.98      0.95      0.97       160\n",
      "\n",
      "    accuracy                           0.95       236\n",
      "   macro avg       0.94      0.96      0.95       236\n",
      "weighted avg       0.96      0.95      0.95       236\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 435: Accuracy: 0.9452, F1 Micro: 0.9452, F1 Macro: 0.8869\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        16\n",
      "     neutral       0.94      0.99      0.97       167\n",
      "    positive       0.96      0.67      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.80      0.83       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.75      0.69        12\n",
      "     neutral       0.90      0.93      0.92       152\n",
      "    positive       0.86      0.73      0.79        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.80      0.80      0.80       216\n",
      "weighted avg       0.88      0.88      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.83      0.84        23\n",
      "     neutral       0.96      0.99      0.97       152\n",
      "    positive       0.92      0.83      0.87        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.88      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.91      0.84      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 101.90914225578308 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.012977528572082519\n",
      "Samples above threshold: 43\n",
      "Acquired samples: 43\n",
      "Sampling duration: 9.5496084690094 seconds\n",
      "New train size: 478\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5465, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.476, Accuracy: 0.8222, F1 Micro: 0.8979, F1 Macro: 0.8964\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3646, Accuracy: 0.8981, F1 Micro: 0.9386, F1 Macro: 0.9374\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2594, Accuracy: 0.9286, F1 Micro: 0.9562, F1 Macro: 0.9546\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.194, Accuracy: 0.9435, F1 Micro: 0.965, F1 Macro: 0.9632\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1457, Accuracy: 0.9524, F1 Micro: 0.9704, F1 Macro: 0.9688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.122, Accuracy: 0.9576, F1 Micro: 0.9736, F1 Macro: 0.9726\n",
      "Epoch 8/10, Train Loss: 0.0949, Accuracy: 0.9524, F1 Micro: 0.9702, F1 Macro: 0.9685\n",
      "Epoch 9/10, Train Loss: 0.0799, Accuracy: 0.9539, F1 Micro: 0.9712, F1 Macro: 0.9697\n",
      "Epoch 10/10, Train Loss: 0.0674, Accuracy: 0.9472, F1 Micro: 0.9667, F1 Macro: 0.9642\n",
      "\n",
      "Aspect detection accuracy: 0.9576, F1 Micro: 0.9736, F1 Macro: 0.9726\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.90      0.98      0.94       158\n",
      "        part       0.95      0.99      0.97       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.97      1061\n",
      "   macro avg       0.96      0.99      0.97      1061\n",
      "weighted avg       0.96      0.99      0.97      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5515, Accuracy: 0.6933, F1 Micro: 0.6933, F1 Macro: 0.4345\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3052, Accuracy: 0.9202, F1 Micro: 0.9202, F1 Macro: 0.9097\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1845, Accuracy: 0.9244, F1 Micro: 0.9244, F1 Macro: 0.9111\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1405, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9216\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1158, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.919\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0765, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9333\n",
      "Epoch 7/10, Train Loss: 0.0637, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9197\n",
      "Epoch 8/10, Train Loss: 0.0705, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9227\n",
      "Epoch 9/10, Train Loss: 0.0987, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9187\n",
      "Epoch 10/10, Train Loss: 0.0596, Accuracy: 0.9244, F1 Micro: 0.9244, F1 Macro: 0.913\n",
      "\n",
      "Sentiment analysis accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.95      0.91        75\n",
      "    positive       0.97      0.94      0.96       163\n",
      "\n",
      "    accuracy                           0.94       238\n",
      "   macro avg       0.93      0.94      0.93       238\n",
      "weighted avg       0.94      0.94      0.94       238\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 478: Accuracy: 0.9321, F1 Micro: 0.9321, F1 Macro: 0.8539\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.82      0.86        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.88      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.90      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.62      0.65        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.83      0.79      0.80       216\n",
      "weighted avg       0.91      0.92      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.27      0.75      0.40        12\n",
      "     neutral       0.93      0.87      0.90       152\n",
      "    positive       0.93      0.73      0.82        52\n",
      "\n",
      "    accuracy                           0.83       216\n",
      "   macro avg       0.71      0.78      0.71       216\n",
      "weighted avg       0.89      0.83      0.85       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.78      0.82        23\n",
      "     neutral       0.95      0.99      0.97       152\n",
      "    positive       0.89      0.80      0.85        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.86      0.88       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.89      0.84      0.86       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 94.84774804115295 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.015533983707427979\n",
      "Samples above threshold: 39\n",
      "Acquired samples: 39\n",
      "Sampling duration: 8.505621194839478 seconds\n",
      "New train size: 517\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5511, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4635, Accuracy: 0.8326, F1 Micro: 0.9036, F1 Macro: 0.9022\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3397, Accuracy: 0.9308, F1 Micro: 0.9576, F1 Macro: 0.9564\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2294, Accuracy: 0.9479, F1 Micro: 0.9678, F1 Macro: 0.9665\n",
      "Epoch 5/10, Train Loss: 0.1661, Accuracy: 0.9435, F1 Micro: 0.9649, F1 Macro: 0.9627\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1269, Accuracy: 0.9561, F1 Micro: 0.9727, F1 Macro: 0.9718\n",
      "Epoch 7/10, Train Loss: 0.1041, Accuracy: 0.9494, F1 Micro: 0.9685, F1 Macro: 0.9668\n",
      "Epoch 8/10, Train Loss: 0.0875, Accuracy: 0.9561, F1 Micro: 0.9725, F1 Macro: 0.9711\n",
      "Epoch 9/10, Train Loss: 0.0664, Accuracy: 0.9561, F1 Micro: 0.9725, F1 Macro: 0.971\n",
      "Epoch 10/10, Train Loss: 0.0599, Accuracy: 0.9531, F1 Micro: 0.9705, F1 Macro: 0.9684\n",
      "\n",
      "Aspect detection accuracy: 0.9561, F1 Micro: 0.9727, F1 Macro: 0.9718\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.90      0.97      0.94       158\n",
      "        part       0.96      0.99      0.97       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.97      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.97      1061\n",
      "   macro avg       0.95      0.99      0.97      1061\n",
      "weighted avg       0.96      0.99      0.97      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5137, Accuracy: 0.6907, F1 Micro: 0.6907, F1 Macro: 0.4214\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2742, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9376\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1684, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9367\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1353, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9376\n",
      "Epoch 5/10, Train Loss: 0.1006, Accuracy: 0.9322, F1 Micro: 0.9322, F1 Macro: 0.9239\n",
      "Epoch 6/10, Train Loss: 0.0872, Accuracy: 0.9364, F1 Micro: 0.9364, F1 Macro: 0.9275\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0742, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9348\n",
      "Epoch 8/10, Train Loss: 0.1094, Accuracy: 0.9195, F1 Micro: 0.9195, F1 Macro: 0.9068\n",
      "Epoch 9/10, Train Loss: 0.0424, Accuracy: 0.9322, F1 Micro: 0.9322, F1 Macro: 0.9239\n",
      "Epoch 10/10, Train Loss: 0.064, Accuracy: 0.9364, F1 Micro: 0.9364, F1 Macro: 0.9284\n",
      "\n",
      "Sentiment analysis accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9348\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.88      0.91        74\n",
      "    positive       0.95      0.98      0.96       162\n",
      "\n",
      "    accuracy                           0.94       236\n",
      "   macro avg       0.94      0.93      0.93       236\n",
      "weighted avg       0.94      0.94      0.94       236\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 517: Accuracy: 0.9367, F1 Micro: 0.9367, F1 Macro: 0.8575\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.91      0.88      0.89        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.96      0.73      0.83        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.88      0.82      0.85       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.31      0.75      0.44        12\n",
      "     neutral       0.92      0.88      0.90       152\n",
      "    positive       0.90      0.73      0.81        52\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.71      0.79      0.72       216\n",
      "weighted avg       0.89      0.84      0.85       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.87      0.83        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.90      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.77      0.74        13\n",
      "     neutral       0.98      0.99      0.98       186\n",
      "    positive       0.86      0.71      0.77        17\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.85      0.82      0.83       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.93      0.90        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.76      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.90      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 97.29066610336304 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.014106082916259767\n",
      "Samples above threshold: 35\n",
      "Acquired samples: 23\n",
      "Sampling duration: 7.895242214202881 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5435, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4664, Accuracy: 0.8304, F1 Micro: 0.9021, F1 Macro: 0.9008\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3468, Accuracy: 0.9159, F1 Micro: 0.9489, F1 Macro: 0.9476\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2284, Accuracy: 0.9509, F1 Micro: 0.9695, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1745, Accuracy: 0.9531, F1 Micro: 0.9708, F1 Macro: 0.9696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.133, Accuracy: 0.9539, F1 Micro: 0.9712, F1 Macro: 0.9698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1151, Accuracy: 0.9546, F1 Micro: 0.9717, F1 Macro: 0.9703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.089, Accuracy: 0.9583, F1 Micro: 0.974, F1 Macro: 0.9727\n",
      "Epoch 9/10, Train Loss: 0.073, Accuracy: 0.9524, F1 Micro: 0.97, F1 Macro: 0.9676\n",
      "Epoch 10/10, Train Loss: 0.0653, Accuracy: 0.9487, F1 Micro: 0.9677, F1 Macro: 0.9653\n",
      "\n",
      "Aspect detection accuracy: 0.9583, F1 Micro: 0.974, F1 Macro: 0.9727\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.92      0.96      0.93       158\n",
      "        part       0.94      0.99      0.97       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.97      1061\n",
      "   macro avg       0.96      0.99      0.97      1061\n",
      "weighted avg       0.96      0.99      0.97      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4557, Accuracy: 0.75, F1 Micro: 0.75, F1 Macro: 0.5734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2313, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9296\n",
      "Epoch 3/10, Train Loss: 0.1391, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9241\n",
      "Epoch 4/10, Train Loss: 0.1347, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9224\n",
      "Epoch 5/10, Train Loss: 0.1154, Accuracy: 0.9262, F1 Micro: 0.9262, F1 Macro: 0.9163\n",
      "Epoch 6/10, Train Loss: 0.1367, Accuracy: 0.9057, F1 Micro: 0.9057, F1 Macro: 0.8953\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0628, Accuracy: 0.9508, F1 Micro: 0.9508, F1 Macro: 0.9431\n",
      "Epoch 8/10, Train Loss: 0.1034, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9258\n",
      "Epoch 9/10, Train Loss: 0.0717, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9264\n",
      "Epoch 10/10, Train Loss: 0.0696, Accuracy: 0.9467, F1 Micro: 0.9467, F1 Macro: 0.9372\n",
      "\n",
      "Sentiment analysis accuracy: 0.9508, F1 Micro: 0.9508, F1 Macro: 0.9431\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.96      0.92        74\n",
      "    positive       0.98      0.95      0.96       170\n",
      "\n",
      "    accuracy                           0.95       244\n",
      "   macro avg       0.93      0.95      0.94       244\n",
      "weighted avg       0.95      0.95      0.95       244\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.8758\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.56      0.67        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.81      0.79      0.80        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.86      0.78      0.81       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.38      0.75      0.50        12\n",
      "     neutral       0.92      0.88      0.90       152\n",
      "    positive       0.85      0.77      0.81        52\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.71      0.80      0.73       216\n",
      "weighted avg       0.87      0.84      0.85       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.70      0.76        23\n",
      "     neutral       0.94      0.99      0.96       152\n",
      "    positive       0.95      0.88      0.91        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.85      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 102.17781567573547 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.010334932804107666\n",
      "Samples above threshold: 33\n",
      "Acquired samples: 33\n",
      "Sampling duration: 7.435745000839233 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5414, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4543, Accuracy: 0.8363, F1 Micro: 0.9053, F1 Macro: 0.904\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3408, Accuracy: 0.933, F1 Micro: 0.9589, F1 Macro: 0.9573\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2214, Accuracy: 0.942, F1 Micro: 0.9642, F1 Macro: 0.9624\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1701, Accuracy: 0.9568, F1 Micro: 0.9732, F1 Macro: 0.9722\n",
      "Epoch 6/10, Train Loss: 0.1291, Accuracy: 0.9509, F1 Micro: 0.9691, F1 Macro: 0.9666\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0994, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9756\n",
      "Epoch 8/10, Train Loss: 0.0843, Accuracy: 0.9554, F1 Micro: 0.972, F1 Macro: 0.9702\n",
      "Epoch 9/10, Train Loss: 0.0651, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9728\n",
      "Epoch 10/10, Train Loss: 0.0596, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9736\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9756\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.91      0.95      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.98       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4683, Accuracy: 0.8392, F1 Micro: 0.8392, F1 Macro: 0.7873\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2403, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9076\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1444, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9294\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1308, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9319\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1146, Accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.9418\n",
      "Epoch 6/10, Train Loss: 0.1259, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9286\n",
      "Epoch 7/10, Train Loss: 0.1021, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9206\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0853, Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9464\n",
      "Epoch 9/10, Train Loss: 0.0752, Accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.9421\n",
      "Epoch 10/10, Train Loss: 0.0527, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.8901\n",
      "\n",
      "Sentiment analysis accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9464\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93        81\n",
      "    positive       0.98      0.95      0.97       174\n",
      "\n",
      "    accuracy                           0.95       255\n",
      "   macro avg       0.94      0.95      0.95       255\n",
      "weighted avg       0.95      0.95      0.95       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.8526\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.64      0.78        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.81      0.92      0.86        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.93      0.85      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.56      0.67        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.79      0.82      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.86      0.79      0.81       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.33      0.58      0.42        12\n",
      "     neutral       0.94      0.89      0.92       152\n",
      "    positive       0.80      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.69      0.76      0.71       216\n",
      "weighted avg       0.88      0.85      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.78      0.86        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.88      0.93      0.90        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.94      0.90      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.69      0.78        13\n",
      "     neutral       0.98      0.99      0.98       186\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.89      0.84      0.86       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 103.88475894927979 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.010903716087341309\n",
      "Samples above threshold: 30\n",
      "Acquired samples: 30\n",
      "Sampling duration: 6.811455249786377 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5445, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4518, Accuracy: 0.8497, F1 Micro: 0.9126, F1 Macro: 0.9115\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3125, Accuracy: 0.9382, F1 Micro: 0.9616, F1 Macro: 0.9596\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2076, Accuracy: 0.9472, F1 Micro: 0.9671, F1 Macro: 0.9653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1571, Accuracy: 0.9554, F1 Micro: 0.9722, F1 Macro: 0.9712\n",
      "Epoch 6/10, Train Loss: 0.1187, Accuracy: 0.9546, F1 Micro: 0.9716, F1 Macro: 0.9696\n",
      "Epoch 7/10, Train Loss: 0.0962, Accuracy: 0.9539, F1 Micro: 0.9711, F1 Macro: 0.9694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0805, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0658, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9749\n",
      "Epoch 10/10, Train Loss: 0.0557, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.974\n",
      "\n",
      "Aspect detection accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9749\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.93      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4805, Accuracy: 0.8108, F1 Micro: 0.8108, F1 Macro: 0.7227\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2294, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9217\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1724, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9367\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1437, Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9418\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0901, Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9465\n",
      "Epoch 6/10, Train Loss: 0.082, Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9429\n",
      "Epoch 7/10, Train Loss: 0.0867, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9341\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0829, Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9465\n",
      "Epoch 9/10, Train Loss: 0.0862, Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.941\n",
      "Epoch 10/10, Train Loss: 0.0614, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9383\n",
      "\n",
      "Sentiment analysis accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9465\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.93        80\n",
      "    positive       0.98      0.96      0.97       179\n",
      "\n",
      "    accuracy                           0.95       259\n",
      "   macro avg       0.94      0.95      0.95       259\n",
      "weighted avg       0.95      0.95      0.95       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.903\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.87      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.79      0.81      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.85      0.83      0.84       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.93      0.92       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.85      0.79        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.86      0.87      0.86       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 111.02045798301697 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.007924020290374756\n",
      "Samples above threshold: 27\n",
      "Acquired samples: 27\n",
      "Sampling duration: 6.712282657623291 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5478, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4531, Accuracy: 0.8646, F1 Micro: 0.9205, F1 Macro: 0.9195\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3081, Accuracy: 0.9412, F1 Micro: 0.9636, F1 Macro: 0.9621\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1931, Accuracy: 0.9524, F1 Micro: 0.9703, F1 Macro: 0.9686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1469, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9721\n",
      "Epoch 6/10, Train Loss: 0.1102, Accuracy: 0.9561, F1 Micro: 0.9726, F1 Macro: 0.9713\n",
      "Epoch 7/10, Train Loss: 0.0907, Accuracy: 0.9539, F1 Micro: 0.9711, F1 Macro: 0.9694\n",
      "Epoch 8/10, Train Loss: 0.074, Accuracy: 0.9554, F1 Micro: 0.9719, F1 Macro: 0.9702\n",
      "Epoch 9/10, Train Loss: 0.0594, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0505, Accuracy: 0.9583, F1 Micro: 0.9737, F1 Macro: 0.9718\n",
      "\n",
      "Aspect detection accuracy: 0.9583, F1 Micro: 0.9737, F1 Macro: 0.9718\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.89      0.91       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.97      0.97      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5307, Accuracy: 0.7556, F1 Micro: 0.7556, F1 Macro: 0.5835\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2754, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9227\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1944, Accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.9355\n",
      "Epoch 4/10, Train Loss: 0.132, Accuracy: 0.9361, F1 Micro: 0.9361, F1 Macro: 0.9214\n",
      "Epoch 5/10, Train Loss: 0.1207, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9186\n",
      "Epoch 6/10, Train Loss: 0.1054, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9245\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1101, Accuracy: 0.9474, F1 Micro: 0.9474, F1 Macro: 0.937\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.108, Accuracy: 0.9511, F1 Micro: 0.9511, F1 Macro: 0.9421\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.089, Accuracy: 0.9511, F1 Micro: 0.9511, F1 Macro: 0.9425\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0872, Accuracy: 0.9549, F1 Micro: 0.9549, F1 Macro: 0.9467\n",
      "\n",
      "Sentiment analysis accuracy: 0.9549, F1 Micro: 0.9549, F1 Macro: 0.9467\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.94      0.93        80\n",
      "    positive       0.97      0.96      0.97       186\n",
      "\n",
      "    accuracy                           0.95       266\n",
      "   macro avg       0.94      0.95      0.95       266\n",
      "weighted avg       0.96      0.95      0.96       266\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.9498, F1 Micro: 0.9498, F1 Macro: 0.9064\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.87      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.67      0.76        12\n",
      "     neutral       0.93      0.89      0.91       152\n",
      "    positive       0.71      0.85      0.77        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.84      0.80      0.81       216\n",
      "weighted avg       0.88      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.87      0.89        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.92      0.88      0.90        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.91      0.84      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 113.2550847530365 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.006357890367507934\n",
      "Samples above threshold: 24\n",
      "Acquired samples: 18\n",
      "Sampling duration: 6.096864938735962 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5371, Accuracy: 0.8021, F1 Micro: 0.8877, F1 Macro: 0.886\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4449, Accuracy: 0.872, F1 Micro: 0.9245, F1 Macro: 0.9234\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3043, Accuracy: 0.9435, F1 Micro: 0.965, F1 Macro: 0.9635\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1916, Accuracy: 0.9554, F1 Micro: 0.9722, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1425, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1196, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9735\n",
      "Epoch 7/10, Train Loss: 0.0934, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9712\n",
      "Epoch 8/10, Train Loss: 0.0714, Accuracy: 0.9509, F1 Micro: 0.969, F1 Macro: 0.9667\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0598, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9741\n",
      "Epoch 10/10, Train Loss: 0.0519, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9728\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9741\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.92      0.92       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4932, Accuracy: 0.874, F1 Micro: 0.874, F1 Macro: 0.8369\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2376, Accuracy: 0.9466, F1 Micro: 0.9466, F1 Macro: 0.9379\n",
      "Epoch 3/10, Train Loss: 0.1527, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.899\n",
      "Epoch 4/10, Train Loss: 0.1286, Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.9226\n",
      "Epoch 5/10, Train Loss: 0.0946, Accuracy: 0.9427, F1 Micro: 0.9427, F1 Macro: 0.9357\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.109, Accuracy: 0.9504, F1 Micro: 0.9504, F1 Macro: 0.9436\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.098, Accuracy: 0.9656, F1 Micro: 0.9656, F1 Macro: 0.9602\n",
      "Epoch 8/10, Train Loss: 0.0811, Accuracy: 0.9618, F1 Micro: 0.9618, F1 Macro: 0.9562\n",
      "Epoch 9/10, Train Loss: 0.0539, Accuracy: 0.9618, F1 Micro: 0.9618, F1 Macro: 0.9547\n",
      "Epoch 10/10, Train Loss: 0.0603, Accuracy: 0.9542, F1 Micro: 0.9542, F1 Macro: 0.9478\n",
      "\n",
      "Sentiment analysis accuracy: 0.9656, F1 Micro: 0.9656, F1 Macro: 0.9602\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.95      0.95        82\n",
      "    positive       0.98      0.97      0.97       180\n",
      "\n",
      "    accuracy                           0.97       262\n",
      "   macro avg       0.96      0.96      0.96       262\n",
      "weighted avg       0.97      0.97      0.97       262\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.9005\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.87      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.75      0.69        12\n",
      "     neutral       0.92      0.90      0.91       152\n",
      "    positive       0.77      0.79      0.78        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.78      0.81      0.79       216\n",
      "weighted avg       0.87      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.96      0.94        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.95      0.90      0.92        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.95      0.95       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.85      0.79        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.89      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.93      0.90        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.94      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 112.89584374427795 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.006626129150390625\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 25\n",
      "Sampling duration: 6.010189771652222 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5446, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.435, Accuracy: 0.8876, F1 Micro: 0.933, F1 Macro: 0.9322\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2764, Accuracy: 0.9487, F1 Micro: 0.968, F1 Macro: 0.966\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1704, Accuracy: 0.9546, F1 Micro: 0.9716, F1 Macro: 0.9699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1255, Accuracy: 0.9546, F1 Micro: 0.9718, F1 Macro: 0.9705\n",
      "Epoch 6/10, Train Loss: 0.1024, Accuracy: 0.9464, F1 Micro: 0.966, F1 Macro: 0.9619\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0833, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0686, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9749\n",
      "Epoch 9/10, Train Loss: 0.0587, Accuracy: 0.9591, F1 Micro: 0.9741, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0486, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9756\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9756\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.92      0.92       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5096, Accuracy: 0.8981, F1 Micro: 0.8981, F1 Macro: 0.8778\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2172, Accuracy: 0.9208, F1 Micro: 0.9208, F1 Macro: 0.9124\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.169, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9323\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1422, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9319\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1385, Accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.936\n",
      "Epoch 6/10, Train Loss: 0.1017, Accuracy: 0.9321, F1 Micro: 0.9321, F1 Macro: 0.9243\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0808, Accuracy: 0.9585, F1 Micro: 0.9585, F1 Macro: 0.9528\n",
      "Epoch 8/10, Train Loss: 0.0943, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.9203\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0845, Accuracy: 0.9585, F1 Micro: 0.9585, F1 Macro: 0.9519\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0525, Accuracy: 0.9623, F1 Micro: 0.9623, F1 Macro: 0.9561\n",
      "\n",
      "Sentiment analysis accuracy: 0.9623, F1 Micro: 0.9623, F1 Macro: 0.9561\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        83\n",
      "    positive       0.97      0.97      0.97       182\n",
      "\n",
      "    accuracy                           0.96       265\n",
      "   macro avg       0.96      0.96      0.96       265\n",
      "weighted avg       0.96      0.96      0.96       265\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.9223\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.81      0.79      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.84      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.83      0.91        12\n",
      "     neutral       0.93      0.92      0.92       152\n",
      "    positive       0.78      0.83      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.90      0.86      0.88       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.96      0.94        23\n",
      "     neutral       0.98      0.99      0.99       152\n",
      "    positive       0.97      0.90      0.94        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.96      0.95      0.95       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.96      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 126.17343544960022 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.005137920379638672\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 25\n",
      "Sampling duration: 5.0899927616119385 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5457, Accuracy: 0.7984, F1 Micro: 0.8868, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4444, Accuracy: 0.881, F1 Micro: 0.9294, F1 Macro: 0.9288\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2856, Accuracy: 0.9464, F1 Micro: 0.9667, F1 Macro: 0.9651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1853, Accuracy: 0.9576, F1 Micro: 0.9737, F1 Macro: 0.9727\n",
      "Epoch 5/10, Train Loss: 0.1427, Accuracy: 0.9487, F1 Micro: 0.9677, F1 Macro: 0.965\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1072, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9766\n",
      "Epoch 7/10, Train Loss: 0.0845, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9755\n",
      "Epoch 8/10, Train Loss: 0.065, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9727\n",
      "Epoch 9/10, Train Loss: 0.0607, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9751\n",
      "Epoch 10/10, Train Loss: 0.0495, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9745\n",
      "\n",
      "Aspect detection accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9766\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.91      0.96      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4912, Accuracy: 0.8849, F1 Micro: 0.8849, F1 Macro: 0.856\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2565, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9324\n",
      "Epoch 3/10, Train Loss: 0.1717, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.909\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1282, Accuracy: 0.9524, F1 Micro: 0.9524, F1 Macro: 0.9454\n",
      "Epoch 5/10, Train Loss: 0.1401, Accuracy: 0.9365, F1 Micro: 0.9365, F1 Macro: 0.9286\n",
      "Epoch 6/10, Train Loss: 0.0947, Accuracy: 0.9246, F1 Micro: 0.9246, F1 Macro: 0.9164\n",
      "Epoch 7/10, Train Loss: 0.0972, Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9355\n",
      "Epoch 8/10, Train Loss: 0.0994, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9208\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0612, Accuracy: 0.9524, F1 Micro: 0.9524, F1 Macro: 0.9461\n",
      "Epoch 10/10, Train Loss: 0.0539, Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9375\n",
      "\n",
      "Sentiment analysis accuracy: 0.9524, F1 Micro: 0.9524, F1 Macro: 0.9461\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93        81\n",
      "    positive       0.98      0.95      0.96       171\n",
      "\n",
      "    accuracy                           0.95       252\n",
      "   macro avg       0.94      0.95      0.95       252\n",
      "weighted avg       0.95      0.95      0.95       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9514, F1 Micro: 0.9514, F1 Macro: 0.895\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.45      0.83      0.59        12\n",
      "     neutral       0.93      0.91      0.92       152\n",
      "    positive       0.87      0.75      0.80        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.75      0.83      0.77       216\n",
      "weighted avg       0.89      0.87      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.93      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.85      0.79        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.88      0.87      0.87       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 121.10518503189087 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.009107410907745361\n",
      "Samples above threshold: 17\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.469604730606079 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5371, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4255, Accuracy: 0.8914, F1 Micro: 0.9346, F1 Macro: 0.9326\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2801, Accuracy: 0.9531, F1 Micro: 0.971, F1 Macro: 0.9697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1801, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9738\n",
      "Epoch 5/10, Train Loss: 0.1326, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0996, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0753, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9751\n",
      "Epoch 8/10, Train Loss: 0.062, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0561, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0457, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9758\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9758\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.93      0.93      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4961, Accuracy: 0.8851, F1 Micro: 0.8851, F1 Macro: 0.8536\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2203, Accuracy: 0.9502, F1 Micro: 0.9502, F1 Macro: 0.9416\n",
      "Epoch 3/10, Train Loss: 0.1567, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9269\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.134, Accuracy: 0.9579, F1 Micro: 0.9579, F1 Macro: 0.9519\n",
      "Epoch 5/10, Train Loss: 0.1124, Accuracy: 0.954, F1 Micro: 0.954, F1 Macro: 0.9477\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1073, Accuracy: 0.9579, F1 Micro: 0.9579, F1 Macro: 0.9519\n",
      "Epoch 7/10, Train Loss: 0.0807, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9269\n",
      "Epoch 8/10, Train Loss: 0.0669, Accuracy: 0.9502, F1 Micro: 0.9502, F1 Macro: 0.9435\n",
      "Epoch 9/10, Train Loss: 0.0629, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9265\n",
      "Epoch 10/10, Train Loss: 0.0746, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9261\n",
      "\n",
      "Sentiment analysis accuracy: 0.9579, F1 Micro: 0.9579, F1 Macro: 0.9519\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.93        81\n",
      "    positive       0.99      0.95      0.97       180\n",
      "\n",
      "    accuracy                           0.96       261\n",
      "   macro avg       0.94      0.96      0.95       261\n",
      "weighted avg       0.96      0.96      0.96       261\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.8988\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.84      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.81      0.81      0.81        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.83      0.83      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.95      0.88      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.77      0.74        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.87      0.82      0.84       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 121.53603625297546 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.0044820308685302734\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 25\n",
      "Sampling duration: 6.200449228286743 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5393, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4276, Accuracy: 0.881, F1 Micro: 0.9293, F1 Macro: 0.9279\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2658, Accuracy: 0.9546, F1 Micro: 0.9718, F1 Macro: 0.9706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1647, Accuracy: 0.9628, F1 Micro: 0.9768, F1 Macro: 0.9757\n",
      "Epoch 5/10, Train Loss: 0.1273, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9733\n",
      "Epoch 6/10, Train Loss: 0.0955, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9758\n",
      "Epoch 7/10, Train Loss: 0.0798, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9732\n",
      "Epoch 8/10, Train Loss: 0.06, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0585, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9762\n",
      "Epoch 10/10, Train Loss: 0.0464, Accuracy: 0.9583, F1 Micro: 0.9736, F1 Macro: 0.9714\n",
      "\n",
      "Aspect detection accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.91      0.94      0.92       158\n",
      "        part       0.99      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4684, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.9175\n",
      "Epoch 2/10, Train Loss: 0.242, Accuracy: 0.9208, F1 Micro: 0.9208, F1 Macro: 0.9119\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1403, Accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.936\n",
      "Epoch 4/10, Train Loss: 0.1085, Accuracy: 0.9358, F1 Micro: 0.9358, F1 Macro: 0.9283\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1213, Accuracy: 0.9509, F1 Micro: 0.9509, F1 Macro: 0.9439\n",
      "Epoch 6/10, Train Loss: 0.0989, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9323\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0925, Accuracy: 0.9547, F1 Micro: 0.9547, F1 Macro: 0.9477\n",
      "Epoch 8/10, Train Loss: 0.0967, Accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.9405\n",
      "Epoch 9/10, Train Loss: 0.0646, Accuracy: 0.9358, F1 Micro: 0.9358, F1 Macro: 0.9283\n",
      "Epoch 10/10, Train Loss: 0.0499, Accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.9364\n",
      "\n",
      "Sentiment analysis accuracy: 0.9547, F1 Micro: 0.9547, F1 Macro: 0.9477\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.94      0.93        83\n",
      "    positive       0.97      0.96      0.97       182\n",
      "\n",
      "    accuracy                           0.95       265\n",
      "   macro avg       0.94      0.95      0.95       265\n",
      "weighted avg       0.96      0.95      0.95       265\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9483, F1 Micro: 0.9483, F1 Macro: 0.8992\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.87      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.41      0.92      0.56        12\n",
      "     neutral       0.95      0.88      0.91       152\n",
      "    positive       0.80      0.75      0.77        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.72      0.85      0.75       216\n",
      "weighted avg       0.88      0.85      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.99      0.98      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.94      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.85      0.81        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.88      0.89      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 116.89495515823364 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.004773557186126709\n",
      "Samples above threshold: 12\n",
      "Acquired samples: 8\n",
      "Sampling duration: 3.619945526123047 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5282, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4054, Accuracy: 0.9167, F1 Micro: 0.9494, F1 Macro: 0.9478\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.254, Accuracy: 0.9539, F1 Micro: 0.9715, F1 Macro: 0.9704\n",
      "Epoch 4/10, Train Loss: 0.168, Accuracy: 0.9539, F1 Micro: 0.9712, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.131, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.975\n",
      "Epoch 6/10, Train Loss: 0.0917, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0748, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9766\n",
      "Epoch 8/10, Train Loss: 0.0664, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.973\n",
      "Epoch 9/10, Train Loss: 0.0502, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0442, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5028, Accuracy: 0.9122, F1 Micro: 0.9122, F1 Macro: 0.8996\n",
      "Epoch 2/10, Train Loss: 0.2086, Accuracy: 0.9046, F1 Micro: 0.9046, F1 Macro: 0.8956\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1475, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.9316\n",
      "Epoch 4/10, Train Loss: 0.1557, Accuracy: 0.9198, F1 Micro: 0.9198, F1 Macro: 0.9118\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1345, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.9308\n",
      "Epoch 6/10, Train Loss: 0.1268, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9271\n",
      "Epoch 7/10, Train Loss: 0.0842, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.8995\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0739, Accuracy: 0.9466, F1 Micro: 0.9466, F1 Macro: 0.9394\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0551, Accuracy: 0.9504, F1 Micro: 0.9504, F1 Macro: 0.9432\n",
      "Epoch 10/10, Train Loss: 0.0872, Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.9234\n",
      "\n",
      "Sentiment analysis accuracy: 0.9504, F1 Micro: 0.9504, F1 Macro: 0.9432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.94      0.92        83\n",
      "    positive       0.97      0.96      0.96       179\n",
      "\n",
      "    accuracy                           0.95       262\n",
      "   macro avg       0.94      0.95      0.94       262\n",
      "weighted avg       0.95      0.95      0.95       262\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9045\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.88      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.80      0.77      0.78        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.83      0.85      0.84       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.91      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.85      0.79        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.88      0.85      0.86       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 120.48814082145691 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.004007869958877563\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.4448184967041016 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5269, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4333, Accuracy: 0.9182, F1 Micro: 0.9504, F1 Macro: 0.9488\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2604, Accuracy: 0.9539, F1 Micro: 0.9712, F1 Macro: 0.9701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1731, Accuracy: 0.9576, F1 Micro: 0.9736, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1208, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1024, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.978\n",
      "Epoch 7/10, Train Loss: 0.0782, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9734\n",
      "Epoch 8/10, Train Loss: 0.064, Accuracy: 0.9613, F1 Micro: 0.9755, F1 Macro: 0.9734\n",
      "Epoch 9/10, Train Loss: 0.0514, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9729\n",
      "Epoch 10/10, Train Loss: 0.0452, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9753\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.93      0.95      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.97      1.00      0.98       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4879, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8966\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2417, Accuracy: 0.917, F1 Micro: 0.917, F1 Macro: 0.9101\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1883, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9257\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.15, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9257\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.105, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9341\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1077, Accuracy: 0.9486, F1 Micro: 0.9486, F1 Macro: 0.9419\n",
      "Epoch 7/10, Train Loss: 0.0769, Accuracy: 0.9289, F1 Micro: 0.9289, F1 Macro: 0.922\n",
      "Epoch 8/10, Train Loss: 0.0517, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9253\n",
      "Epoch 9/10, Train Loss: 0.0658, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9253\n",
      "Epoch 10/10, Train Loss: 0.0604, Accuracy: 0.9249, F1 Micro: 0.9249, F1 Macro: 0.9183\n",
      "\n",
      "Sentiment analysis accuracy: 0.9486, F1 Micro: 0.9486, F1 Macro: 0.9419\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.93      0.92        83\n",
      "    positive       0.96      0.96      0.96       170\n",
      "\n",
      "    accuracy                           0.95       253\n",
      "   macro avg       0.94      0.94      0.94       253\n",
      "weighted avg       0.95      0.95      0.95       253\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.8802\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       1.00      0.88      0.93        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.88      0.80        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.92      0.67      0.77        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.84      0.85       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.38      0.83      0.53        12\n",
      "     neutral       0.96      0.89      0.93       152\n",
      "    positive       0.85      0.79      0.82        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.73      0.84      0.76       216\n",
      "weighted avg       0.90      0.87      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.91       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.92      0.80        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.87      0.87      0.86       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 121.30630326271057 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.006961357593536376\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.9434688091278076 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.526, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3971, Accuracy: 0.9129, F1 Micro: 0.9473, F1 Macro: 0.9461\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2484, Accuracy: 0.9539, F1 Micro: 0.9714, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1609, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1123, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.091, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0713, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0598, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9775\n",
      "Epoch 9/10, Train Loss: 0.0503, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0445, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9787\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9787\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.465, Accuracy: 0.9198, F1 Micro: 0.9198, F1 Macro: 0.9127\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2143, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9286\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1405, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9286\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1253, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.9303\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1326, Accuracy: 0.9427, F1 Micro: 0.9427, F1 Macro: 0.936\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.067, Accuracy: 0.9466, F1 Micro: 0.9466, F1 Macro: 0.939\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0694, Accuracy: 0.9504, F1 Micro: 0.9504, F1 Macro: 0.9439\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0603, Accuracy: 0.9542, F1 Micro: 0.9542, F1 Macro: 0.9481\n",
      "Epoch 9/10, Train Loss: 0.0624, Accuracy: 0.916, F1 Micro: 0.916, F1 Macro: 0.9079\n",
      "Epoch 10/10, Train Loss: 0.0401, Accuracy: 0.9275, F1 Micro: 0.9275, F1 Macro: 0.9202\n",
      "\n",
      "Sentiment analysis accuracy: 0.9542, F1 Micro: 0.9542, F1 Macro: 0.9481\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.94      0.93        85\n",
      "    positive       0.97      0.96      0.97       177\n",
      "\n",
      "    accuracy                           0.95       262\n",
      "   macro avg       0.95      0.95      0.95       262\n",
      "weighted avg       0.95      0.95      0.95       262\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.911\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.87      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.85      0.77      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.87      0.85      0.86       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.94      0.78      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.92      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.85      0.81        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 132.28567051887512 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.003193342685699463\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.657485008239746 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5404, Accuracy: 0.7976, F1 Micro: 0.8864, F1 Macro: 0.8849\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3993, Accuracy: 0.9353, F1 Micro: 0.9603, F1 Macro: 0.9592\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2434, Accuracy: 0.9524, F1 Micro: 0.9704, F1 Macro: 0.9688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1604, Accuracy: 0.9628, F1 Micro: 0.9768, F1 Macro: 0.9758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1249, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9768\n",
      "Epoch 6/10, Train Loss: 0.0931, Accuracy: 0.9583, F1 Micro: 0.9736, F1 Macro: 0.9714\n",
      "Epoch 7/10, Train Loss: 0.0743, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9768\n",
      "Epoch 8/10, Train Loss: 0.0635, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0534, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.978\n",
      "Epoch 10/10, Train Loss: 0.0447, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.92      0.97      0.94       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4729, Accuracy: 0.8672, F1 Micro: 0.8672, F1 Macro: 0.8583\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.225, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9311\n",
      "Epoch 3/10, Train Loss: 0.1419, Accuracy: 0.9297, F1 Micro: 0.9297, F1 Macro: 0.9233\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1412, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9387\n",
      "Epoch 5/10, Train Loss: 0.0992, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9345\n",
      "Epoch 6/10, Train Loss: 0.1, Accuracy: 0.9258, F1 Micro: 0.9258, F1 Macro: 0.9192\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0573, Accuracy: 0.957, F1 Micro: 0.957, F1 Macro: 0.9523\n",
      "Epoch 8/10, Train Loss: 0.0559, Accuracy: 0.9219, F1 Micro: 0.9219, F1 Macro: 0.9152\n",
      "Epoch 9/10, Train Loss: 0.0692, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.927\n",
      "Epoch 10/10, Train Loss: 0.0596, Accuracy: 0.9258, F1 Micro: 0.9258, F1 Macro: 0.915\n",
      "\n",
      "Sentiment analysis accuracy: 0.957, F1 Micro: 0.957, F1 Macro: 0.9523\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94        84\n",
      "    positive       0.99      0.95      0.97       172\n",
      "\n",
      "    accuracy                           0.96       256\n",
      "   macro avg       0.94      0.96      0.95       256\n",
      "weighted avg       0.96      0.96      0.96       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.889\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.92      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.88      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.69      0.73        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.83      0.73      0.77        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.85      0.80      0.82       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.75      0.69        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.91      0.79      0.85        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.83      0.83      0.83       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.90      0.85      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.89      1.00      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 121.15445566177368 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.003930377960205078\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.2581229209899902 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5136, Accuracy: 0.7961, F1 Micro: 0.8856, F1 Macro: 0.8842\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3976, Accuracy: 0.907, F1 Micro: 0.9434, F1 Macro: 0.942\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2405, Accuracy: 0.9583, F1 Micro: 0.9742, F1 Macro: 0.9733\n",
      "Epoch 4/10, Train Loss: 0.172, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1169, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9768\n",
      "Epoch 6/10, Train Loss: 0.0931, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9734\n",
      "Epoch 7/10, Train Loss: 0.0722, Accuracy: 0.9613, F1 Micro: 0.9755, F1 Macro: 0.9736\n",
      "Epoch 8/10, Train Loss: 0.0628, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0503, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9772\n",
      "Epoch 10/10, Train Loss: 0.0423, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9757\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9772\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4662, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.9199\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2227, Accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.9367\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1508, Accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.9352\n",
      "Epoch 4/10, Train Loss: 0.1267, Accuracy: 0.9208, F1 Micro: 0.9208, F1 Macro: 0.9128\n",
      "Epoch 5/10, Train Loss: 0.1018, Accuracy: 0.9208, F1 Micro: 0.9208, F1 Macro: 0.9124\n",
      "Epoch 6/10, Train Loss: 0.0605, Accuracy: 0.9094, F1 Micro: 0.9094, F1 Macro: 0.9006\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0768, Accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.9352\n",
      "Epoch 8/10, Train Loss: 0.0612, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9316\n",
      "Epoch 9/10, Train Loss: 0.0716, Accuracy: 0.9132, F1 Micro: 0.9132, F1 Macro: 0.9045\n",
      "Epoch 10/10, Train Loss: 0.0712, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9316\n",
      "\n",
      "Sentiment analysis accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.9352\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.92      0.91        85\n",
      "    positive       0.96      0.96      0.96       180\n",
      "\n",
      "    accuracy                           0.94       265\n",
      "   macro avg       0.93      0.94      0.94       265\n",
      "weighted avg       0.94      0.94      0.94       265\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9034\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.75      0.67        12\n",
      "     neutral       0.94      0.91      0.92       152\n",
      "    positive       0.80      0.83      0.81        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.78      0.83      0.80       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.94      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.89      1.00      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 124.91790437698364 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.0019046664237976074\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 8\n",
      "Sampling duration: 1.423888921737671 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5273, Accuracy: 0.7976, F1 Micro: 0.8864, F1 Macro: 0.885\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4079, Accuracy: 0.9137, F1 Micro: 0.9473, F1 Macro: 0.9457\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2602, Accuracy: 0.9524, F1 Micro: 0.9701, F1 Macro: 0.9683\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1664, Accuracy: 0.9643, F1 Micro: 0.9777, F1 Macro: 0.9766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1235, Accuracy: 0.9673, F1 Micro: 0.9796, F1 Macro: 0.9788\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0921, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9789\n",
      "Epoch 7/10, Train Loss: 0.073, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9771\n",
      "Epoch 8/10, Train Loss: 0.0627, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9755\n",
      "Epoch 9/10, Train Loss: 0.0494, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9766\n",
      "Epoch 10/10, Train Loss: 0.0449, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9781\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.93      0.96      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4987, Accuracy: 0.9038, F1 Micro: 0.9038, F1 Macro: 0.8956\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2413, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9199\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1492, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9199\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1459, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9235\n",
      "Epoch 5/10, Train Loss: 0.1182, Accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.9119\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0757, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9347\n",
      "Epoch 7/10, Train Loss: 0.0871, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9191\n",
      "Epoch 8/10, Train Loss: 0.0431, Accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.9115\n",
      "Epoch 9/10, Train Loss: 0.0855, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9317\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.064, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9358\n",
      "\n",
      "Sentiment analysis accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9358\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.95      0.92        85\n",
      "    positive       0.98      0.94      0.96       175\n",
      "\n",
      "    accuracy                           0.94       260\n",
      "   macro avg       0.93      0.95      0.94       260\n",
      "weighted avg       0.94      0.94      0.94       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.9131\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.82      0.86        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.88      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.90      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.94      0.81        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.87      0.88      0.86       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      1.00      0.83        12\n",
      "     neutral       0.94      0.93      0.94       152\n",
      "    positive       0.85      0.79      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.83      0.91      0.86       216\n",
      "weighted avg       0.91      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.88      0.92        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.95      0.95       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 129.35415053367615 s\n",
      "Total runtime: 2913.962673664093 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[4], 4)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6159439,
     "sourceId": 10801903,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5840.408017,
   "end_time": "2025-03-23T10:14:22.262190",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-23T08:37:01.854173",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "05eaea6779644934b86856400d183435": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3857f36ca9e1457eb9d7de159a93be4b",
       "placeholder": "​",
       "style": "IPY_MODEL_e0ec8dbd5e0e4ebb8050b99de9811d43",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: 100%"
      }
     },
     "05fac24a37fd46eeb835d5417fbac870": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_dc5ac87eee784adf9d82369c0cc524ed",
        "IPY_MODEL_e9eeee92e0b34bf6b4a27fde0ab2ceff",
        "IPY_MODEL_ef2751c08260401ebd6da06bd5a2b99f"
       ],
       "layout": "IPY_MODEL_dad233b947724de8b1f4f576162b1d4d",
       "tabbable": null,
       "tooltip": null
      }
     },
     "12a980a5f28a417ca22601cb802419e8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "19c67d74ea61450aaaf89ba9df3fee85": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e716f9555e5d4f36935929d605afced6",
       "placeholder": "​",
       "style": "IPY_MODEL_488149125ff941af92d96625293aeb73",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json: 100%"
      }
     },
     "1dc5ab0b2b6b4333a2abbcb579dfa55d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1e5447d5424047e783aa608ac645e4c9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "228fac8b7d0e4f55b2e99c74714d6726": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "229563a6ff954f99ad7ff7d9bf684556": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_05eaea6779644934b86856400d183435",
        "IPY_MODEL_9eec184694c044e7992b1566d4d522fa",
        "IPY_MODEL_b676b51a572b4a5d9180bd58aee69567"
       ],
       "layout": "IPY_MODEL_8772b3119a42447aba1bcd00053e823d",
       "tabbable": null,
       "tooltip": null
      }
     },
     "25b91b79f41c4d6ba76851d3a604a689": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3857f36ca9e1457eb9d7de159a93be4b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "38590ff9a6bc4361a7166100815038f8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "43a2fb48a3da45e384d1f8313e143472": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "44ab710bcace42388efbd9e2023b7ecd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "47550a507f9442cca3bfdf881c44edce": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "488149125ff941af92d96625293aeb73": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "4a7ce42ef6764c7b92e5894ab7153b2c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4ef89ee9f1304adba8f146b97eb524c9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d2ea825b3232490996190f144c04a4ca",
       "placeholder": "​",
       "style": "IPY_MODEL_6846e502015e4b08a833032d21e7848b",
       "tabbable": null,
       "tooltip": null,
       "value": " 2.00/2.00 [00:00&lt;00:00, 159B/s]"
      }
     },
     "6425c61295e942c7b6b6e21e45845273": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6846e502015e4b08a833032d21e7848b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7c097f68ca294e6eb0b47fb214154df8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7d1f257a65cd4dec816c080a683eb622": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7df4bbb685d047b3b285ea0197affaea": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "83ce13cd9ced425f9b5af6e887ed6cd0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a95abfe71d41472fb7ac4c55d5f10c8f",
       "placeholder": "​",
       "style": "IPY_MODEL_25b91b79f41c4d6ba76851d3a604a689",
       "tabbable": null,
       "tooltip": null,
       "value": " 112/112 [00:00&lt;00:00, 8.80kB/s]"
      }
     },
     "8772b3119a42447aba1bcd00053e823d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9205f3086f8e40f0bb38e17509c569ff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7d1f257a65cd4dec816c080a683eb622",
       "placeholder": "​",
       "style": "IPY_MODEL_a6abfecc77dc4728a3c0efeef5d22416",
       "tabbable": null,
       "tooltip": null,
       "value": "special_tokens_map.json: 100%"
      }
     },
     "93a7d599869e485784526a45f6a7d2b6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9eec184694c044e7992b1566d4d522fa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_47550a507f9442cca3bfdf881c44edce",
       "max": 1534,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_38590ff9a6bc4361a7166100815038f8",
       "tabbable": null,
       "tooltip": null,
       "value": 1534
      }
     },
     "a6abfecc77dc4728a3c0efeef5d22416": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a6d221f9ecde43f99ad83045baf13239": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_228fac8b7d0e4f55b2e99c74714d6726",
       "max": 2,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e969d19c68f146beb1f7ab261782433f",
       "tabbable": null,
       "tooltip": null,
       "value": 2
      }
     },
     "a95abfe71d41472fb7ac4c55d5f10c8f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a9bbc41fba364bbfb4325328be5fb889": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_93a7d599869e485784526a45f6a7d2b6",
       "max": 112,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_7c097f68ca294e6eb0b47fb214154df8",
       "tabbable": null,
       "tooltip": null,
       "value": 112
      }
     },
     "b676b51a572b4a5d9180bd58aee69567": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ebb1b55919b54c86ba1b1ea9d6bcea47",
       "placeholder": "​",
       "style": "IPY_MODEL_7df4bbb685d047b3b285ea0197affaea",
       "tabbable": null,
       "tooltip": null,
       "value": " 1.53k/1.53k [00:00&lt;00:00, 127kB/s]"
      }
     },
     "d2ea825b3232490996190f144c04a4ca": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dad233b947724de8b1f4f576162b1d4d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dc5ac87eee784adf9d82369c0cc524ed": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1e5447d5424047e783aa608ac645e4c9",
       "placeholder": "​",
       "style": "IPY_MODEL_43a2fb48a3da45e384d1f8313e143472",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.txt: 100%"
      }
     },
     "dd88f48e36e54adc804463a4e6e32eb5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_9205f3086f8e40f0bb38e17509c569ff",
        "IPY_MODEL_a9bbc41fba364bbfb4325328be5fb889",
        "IPY_MODEL_83ce13cd9ced425f9b5af6e887ed6cd0"
       ],
       "layout": "IPY_MODEL_6425c61295e942c7b6b6e21e45845273",
       "tabbable": null,
       "tooltip": null
      }
     },
     "e0ec8dbd5e0e4ebb8050b99de9811d43": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e13aa41bee3a4b08869d0cccc6263b30": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_19c67d74ea61450aaaf89ba9df3fee85",
        "IPY_MODEL_a6d221f9ecde43f99ad83045baf13239",
        "IPY_MODEL_4ef89ee9f1304adba8f146b97eb524c9"
       ],
       "layout": "IPY_MODEL_4a7ce42ef6764c7b92e5894ab7153b2c",
       "tabbable": null,
       "tooltip": null
      }
     },
     "e3a4442549cd4c9bbd45be195e4a357c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "e716f9555e5d4f36935929d605afced6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e969d19c68f146beb1f7ab261782433f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "e9eeee92e0b34bf6b4a27fde0ab2ceff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1dc5ab0b2b6b4333a2abbcb579dfa55d",
       "max": 229167,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e3a4442549cd4c9bbd45be195e4a357c",
       "tabbable": null,
       "tooltip": null,
       "value": 229167
      }
     },
     "ebb1b55919b54c86ba1b1ea9d6bcea47": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ef2751c08260401ebd6da06bd5a2b99f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_44ab710bcace42388efbd9e2023b7ecd",
       "placeholder": "​",
       "style": "IPY_MODEL_12a980a5f28a417ca22601cb802419e8",
       "tabbable": null,
       "tooltip": null,
       "value": " 229k/229k [00:00&lt;00:00, 5.94MB/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
