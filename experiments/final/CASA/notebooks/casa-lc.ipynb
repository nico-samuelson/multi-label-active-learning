{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "963c8eab",
   "metadata": {
    "papermill": {
     "duration": 0.014318,
     "end_time": "2025-03-24T15:19:48.111392",
     "exception": false,
     "start_time": "2025-03-24T15:19:48.097074",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b3c68f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T15:19:48.139821Z",
     "iopub.status.busy": "2025-03-24T15:19:48.139318Z",
     "iopub.status.idle": "2025-03-24T15:20:22.996547Z",
     "shell.execute_reply": "2025-03-24T15:20:22.995121Z"
    },
    "papermill": {
     "duration": 34.873979,
     "end_time": "2025-03-24T15:20:22.998840",
     "exception": false,
     "start_time": "2025-03-24T15:19:48.124861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score, classification_report\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "from torch.multiprocessing import Manager\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel, BertPreTrainedModel, BertConfig, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d628fd5f",
   "metadata": {
    "papermill": {
     "duration": 0.024131,
     "end_time": "2025-03-24T15:20:23.045054",
     "exception": false,
     "start_time": "2025-03-24T15:20:23.020923",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "368f1a3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T15:20:23.073991Z",
     "iopub.status.busy": "2025-03-24T15:20:23.073311Z",
     "iopub.status.idle": "2025-03-24T15:20:23.077955Z",
     "shell.execute_reply": "2025-03-24T15:20:23.076972Z"
    },
    "papermill": {
     "duration": 0.020599,
     "end_time": "2025-03-24T15:20:23.079611",
     "exception": false,
     "start_time": "2025-03-24T15:20:23.059012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad347827",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T15:20:23.107507Z",
     "iopub.status.busy": "2025-03-24T15:20:23.107151Z",
     "iopub.status.idle": "2025-03-24T15:20:23.111669Z",
     "shell.execute_reply": "2025-03-24T15:20:23.110837Z"
    },
    "papermill": {
     "duration": 0.019999,
     "end_time": "2025-03-24T15:20:23.113044",
     "exception": false,
     "start_time": "2025-03-24T15:20:23.093045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists('/kaggle/working/results') == False:\n",
    "    os.mkdir('/kaggle/working/results')\n",
    "\n",
    "if os.path.exists('/kaggle/working/acquired_data') == False:\n",
    "    os.mkdir('/kaggle/working/acquired_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3334aa7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T15:20:23.141301Z",
     "iopub.status.busy": "2025-03-24T15:20:23.140985Z",
     "iopub.status.idle": "2025-03-24T15:20:23.154709Z",
     "shell.execute_reply": "2025-03-24T15:20:23.153910Z"
    },
    "papermill": {
     "duration": 0.029595,
     "end_time": "2025-03-24T15:20:23.156305",
     "exception": false,
     "start_time": "2025-03-24T15:20:23.126710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "    torch.backends.cudnn.benchmark=False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cb1b78",
   "metadata": {
    "papermill": {
     "duration": 0.013088,
     "end_time": "2025-03-24T15:20:23.183066",
     "exception": false,
     "start_time": "2025-03-24T15:20:23.169978",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# GLOBAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b09221d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T15:20:23.210772Z",
     "iopub.status.busy": "2025-03-24T15:20:23.210408Z",
     "iopub.status.idle": "2025-03-24T15:20:23.283316Z",
     "shell.execute_reply": "2025-03-24T15:20:23.281658Z"
    },
    "papermill": {
     "duration": 0.089178,
     "end_time": "2025-03-24T15:20:23.285459",
     "exception": false,
     "start_time": "2025-03-24T15:20:23.196281",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "\n",
    "# Shared resources\n",
    "aspect_accuracies = manager.list()\n",
    "aspect_f1_micros = manager.list()\n",
    "aspect_f1_macros = manager.list()\n",
    "sentiment_accuracies = manager.list()\n",
    "sentiment_f1_micros = manager.list()\n",
    "sentiment_f1_macros = manager.list()\n",
    "accuracies = manager.list()\n",
    "f1_micros = manager.list()\n",
    "f1_macros = manager.list()\n",
    "\n",
    "# Non shared resources\n",
    "filename = 'casa-lc'\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "sequence_length = 48\n",
    "\n",
    "aspect_list = ['fuel', 'machine', 'others', 'part', 'price', 'service']\n",
    "aspect_mapping = {'fuel': 0, 'machine': 1, 'others': 2, 'part': 3, 'price': 4, 'service': 5 }\n",
    "label_mapping = {\"negative\": 0, \"neutral\": 1, 'positive': 2}\n",
    "ignored_keys = ['labels', 'ori_text', 'ori_label', 'ori_indices', 'aspect']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2713a8fe",
   "metadata": {
    "papermill": {
     "duration": 0.013318,
     "end_time": "2025-03-24T15:20:23.312384",
     "exception": false,
     "start_time": "2025-03-24T15:20:23.299066",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LOAD AND PREPROCESS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed05f5de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T15:20:23.341063Z",
     "iopub.status.busy": "2025-03-24T15:20:23.340682Z",
     "iopub.status.idle": "2025-03-24T15:20:23.435131Z",
     "shell.execute_reply": "2025-03-24T15:20:23.434098Z"
    },
    "papermill": {
     "duration": 0.110834,
     "end_time": "2025-03-24T15:20:23.436806",
     "exception": false,
     "start_time": "2025-03-24T15:20:23.325972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>fuel</th>\n",
       "      <th>machine</th>\n",
       "      <th>others</th>\n",
       "      <th>part</th>\n",
       "      <th>price</th>\n",
       "      <th>service</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saya memakai Honda Jazz GK5 tahun 2014 ( perta...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Avanza kenapa jadi boros bensin begini dah ah....</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saran ku dan pengalaman ku , mending beli mobi...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dari segi harga juga pajero lebih mahal 30 jut...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kalo menurut gw enak pajero si</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence      fuel   machine  \\\n",
       "0  Saya memakai Honda Jazz GK5 tahun 2014 ( perta...   neutral   neutral   \n",
       "1  Avanza kenapa jadi boros bensin begini dah ah....  negative   neutral   \n",
       "2  saran ku dan pengalaman ku , mending beli mobi...  positive  positive   \n",
       "3  Dari segi harga juga pajero lebih mahal 30 jut...   neutral   neutral   \n",
       "4                     Kalo menurut gw enak pajero si   neutral   neutral   \n",
       "\n",
       "     others     part     price  service  \n",
       "0  positive  neutral   neutral  neutral  \n",
       "1   neutral  neutral   neutral  neutral  \n",
       "2   neutral  neutral   neutral  neutral  \n",
       "3   neutral  neutral  positive  neutral  \n",
       "4  positive  neutral   neutral  neutral  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('/kaggle/input/casa-dataset/train_preprocess.csv', encoding='latin-1')\n",
    "val_data = pd.read_csv('/kaggle/input/casa-dataset/valid_preprocess.csv', encoding='latin-1')\n",
    "test_data = pd.read_csv('/kaggle/input/casa-dataset/test_preprocess.csv', encoding='latin-1')\n",
    "\n",
    "data = pd.concat([train_data, val_data, test_data], ignore_index=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2aa19306",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T15:20:23.465149Z",
     "iopub.status.busy": "2025-03-24T15:20:23.464831Z",
     "iopub.status.idle": "2025-03-24T15:20:23.476726Z",
     "shell.execute_reply": "2025-03-24T15:20:23.475873Z"
    },
    "papermill": {
     "duration": 0.027962,
     "end_time": "2025-03-24T15:20:23.478224",
     "exception": false,
     "start_time": "2025-03-24T15:20:23.450262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>fuel</th>\n",
       "      <th>machine</th>\n",
       "      <th>others</th>\n",
       "      <th>part</th>\n",
       "      <th>price</th>\n",
       "      <th>service</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saya memakai Honda Jazz GK5 tahun 2014 ( perta...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Avanza kenapa jadi boros bensin begini dah ah....</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saran ku dan pengalaman ku , mending beli mobi...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dari segi harga juga pajero lebih mahal 30 jut...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kalo menurut gw enak pajero si</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence      fuel   machine  \\\n",
       "0  Saya memakai Honda Jazz GK5 tahun 2014 ( perta...   neutral   neutral   \n",
       "1  Avanza kenapa jadi boros bensin begini dah ah....  negative   neutral   \n",
       "2  saran ku dan pengalaman ku , mending beli mobi...  positive  positive   \n",
       "3  Dari segi harga juga pajero lebih mahal 30 jut...   neutral   neutral   \n",
       "4                     Kalo menurut gw enak pajero si   neutral   neutral   \n",
       "\n",
       "     others     part     price  service  \n",
       "0  positive  neutral   neutral  neutral  \n",
       "1   neutral  neutral   neutral  neutral  \n",
       "2   neutral  neutral   neutral  neutral  \n",
       "3   neutral  neutral  positive  neutral  \n",
       "4  positive  neutral   neutral  neutral  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eca5881",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T15:20:23.506292Z",
     "iopub.status.busy": "2025-03-24T15:20:23.505978Z",
     "iopub.status.idle": "2025-03-24T15:20:23.516776Z",
     "shell.execute_reply": "2025-03-24T15:20:23.515968Z"
    },
    "papermill": {
     "duration": 0.026442,
     "end_time": "2025-03-24T15:20:23.518284",
     "exception": false,
     "start_time": "2025-03-24T15:20:23.491842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e6287f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T15:20:23.546456Z",
     "iopub.status.busy": "2025-03-24T15:20:23.546162Z",
     "iopub.status.idle": "2025-03-24T15:20:23.561639Z",
     "shell.execute_reply": "2025-03-24T15:20:23.560734Z"
    },
    "papermill": {
     "duration": 0.031418,
     "end_time": "2025-03-24T15:20:23.563456",
     "exception": false,
     "start_time": "2025-03-24T15:20:23.532038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(864,) (864, 6)\n",
      "(216,) (216, 6)\n"
     ]
    }
   ],
   "source": [
    "train_labels = train_data.columns[1:]\n",
    "val_labels = val_data.columns[1:]\n",
    "\n",
    "# Extract features and labels for training and validation\n",
    "X_train = train_data['sentence'].values\n",
    "y_train = train_data[train_labels].values\n",
    "X_val = val_data['sentence'].values\n",
    "y_val = val_data[val_labels].values\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4d1eeb",
   "metadata": {
    "papermill": {
     "duration": 0.013325,
     "end_time": "2025-03-24T15:20:23.590779",
     "exception": false,
     "start_time": "2025-03-24T15:20:23.577454",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BUILD DATASET & DATALOADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c514aa36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T15:20:23.620133Z",
     "iopub.status.busy": "2025-03-24T15:20:23.619811Z",
     "iopub.status.idle": "2025-03-24T15:20:23.627227Z",
     "shell.execute_reply": "2025-03-24T15:20:23.626319Z"
    },
    "papermill": {
     "duration": 0.024076,
     "end_time": "2025-03-24T15:20:23.628841",
     "exception": false,
     "start_time": "2025-03-24T15:20:23.604765",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AspectDetectionDataset(Dataset):\n",
    "    def __init__(self, texts, labels, label_mapping, tokenizer, max_length=sequence_length, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.use_float = use_float\n",
    "        self.label_mapping = label_mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "        \n",
    "        original_labels = [self.label_mapping[label] for label in self.labels[idx]]\n",
    "        encoded_labels = [1 if label == 1 else 0 for label in original_labels]\n",
    "        \n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['ori_indices'] = idx\n",
    "        item['ori_text'] = self.texts[idx]\n",
    "        item['ori_label'] = torch.tensor(original_labels, dtype=torch.float)\n",
    "        item['labels'] = torch.tensor(encoded_labels, dtype=torch.float if self.use_float else torch.long)\n",
    "        \n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6dcb1ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T15:20:23.658387Z",
     "iopub.status.busy": "2025-03-24T15:20:23.658078Z",
     "iopub.status.idle": "2025-03-24T15:20:23.666104Z",
     "shell.execute_reply": "2025-03-24T15:20:23.665318Z"
    },
    "papermill": {
     "duration": 0.024518,
     "end_time": "2025-03-24T15:20:23.667573",
     "exception": false,
     "start_time": "2025-03-24T15:20:23.643055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SentimentAnalysisDataset(Dataset):\n",
    "    def __init__(self, texts, labels, aspects, indices, label_mapping, tokenizer, max_length=96, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.aspects = aspects\n",
    "        self.indices = indices\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.use_float = use_float\n",
    "        self.label_mapping = label_mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = aspect_token + ' ' + self.aspects[idx] + ' ' + review_token + ' ' + self.texts[idx] \n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "\n",
    "        if isinstance(self.labels[idx], str):\n",
    "            self.labels[idx] = self.label_mapping[self.labels[idx]]\n",
    "        elif torch.is_tensor(self.labels[idx]):\n",
    "            self.labels[idx] = int(self.labels[idx].item())\n",
    "\n",
    "        encoded_label = 1 if self.labels[idx] == 2 else self.labels[idx]\n",
    "        one_hot_label = F.one_hot(torch.tensor(encoded_label, dtype=torch.long), num_classes=2).float()\n",
    "\n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['aspect'] = self.aspects[idx]\n",
    "        item['labels'] = one_hot_label\n",
    "        item['ori_indices'] = self.indices[idx]\n",
    "        item['ori_text'] = self.texts[idx]\n",
    "        item['ori_label'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c351bced",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T15:20:23.695920Z",
     "iopub.status.busy": "2025-03-24T15:20:23.695587Z",
     "iopub.status.idle": "2025-03-24T15:20:26.604165Z",
     "shell.execute_reply": "2025-03-24T15:20:26.603301Z"
    },
    "papermill": {
     "duration": 2.924985,
     "end_time": "2025-03-24T15:20:26.606002",
     "exception": false,
     "start_time": "2025-03-24T15:20:23.681017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2eb663f8ed24c0386c5bf5dadd2e9c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e488b098f7a04d39819e4c49f2ef25a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/229k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fb88473eff742a98c9439f74bd09ed7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99b1d44a7613479bb598571084bff0d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p1')\n",
    "review_token = '[REVIEW]'\n",
    "aspect_token = '[ASPECT]'\n",
    "special_tokens_dict = {'additional_special_tokens': [review_token, aspect_token]}\n",
    "num_added_tokens = tokenizer.add_special_tokens(special_tokens_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b424c8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T15:20:26.637065Z",
     "iopub.status.busy": "2025-03-24T15:20:26.636714Z",
     "iopub.status.idle": "2025-03-24T15:20:26.642093Z",
     "shell.execute_reply": "2025-03-24T15:20:26.641231Z"
    },
    "papermill": {
     "duration": 0.022587,
     "end_time": "2025-03-24T15:20:26.643619",
     "exception": false,
     "start_time": "2025-03-24T15:20:26.621032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_aspect_dataset(X_train, y_train, X_val, y_val, sequence_length, num_workers=4):\n",
    "    train_dataset = AspectDetectionDataset(X_train, y_train, label_mapping, tokenizer, max_length=sequence_length)\n",
    "    val_dataset = AspectDetectionDataset(X_val, y_val, label_mapping, tokenizer, max_length=sequence_length)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=num_workers,\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=num_workers, \n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4cac8e38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T15:20:26.674556Z",
     "iopub.status.busy": "2025-03-24T15:20:26.674186Z",
     "iopub.status.idle": "2025-03-24T15:20:26.687404Z",
     "shell.execute_reply": "2025-03-24T15:20:26.686570Z"
    },
    "papermill": {
     "duration": 0.030303,
     "end_time": "2025-03-24T15:20:26.688888",
     "exception": false,
     "start_time": "2025-03-24T15:20:26.658585",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_sentiment_dataset(device, train_dataset, val_dataset, aspect_detection_model, tokenizer, max_length=sequence_length):\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "\n",
    "    aspect_detection_model.to(device)\n",
    "    aspect_detection_model.eval()\n",
    "\n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "    train_aspects = []\n",
    "    train_indices = []\n",
    "\n",
    "    val_data = []\n",
    "    val_labels = []\n",
    "    val_aspects = []\n",
    "    val_indices = []\n",
    "\n",
    "    # Transform train set\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        for batch in train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = aspect_detection_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            for i in range(len(preds)):\n",
    "                for j in range(len(preds[i])):\n",
    "                    if int(preds[i][j]) != 1:\n",
    "                        train_aspects.append(aspect_list[j])\n",
    "                        train_data.append(batch['ori_text'][i])\n",
    "                        train_labels.append(batch['ori_label'][i][j])\n",
    "                        train_indices.append(batch['ori_indices'][i])\n",
    "            \n",
    "        # Transform validation set\n",
    "        for batch in val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = aspect_detection_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            for i in range(len(preds)):\n",
    "                for j in range(len(preds[i])):\n",
    "                    if int(preds[i][j]) != 1:\n",
    "                        val_aspects.append(aspect_list[j])\n",
    "                        val_data.append(batch['ori_text'][i])\n",
    "                        val_labels.append(batch['ori_label'][i][j])\n",
    "                        val_indices.append(batch['ori_indices'][i])\n",
    "\n",
    "    train_dataset = SentimentAnalysisDataset(train_data, train_labels, train_aspects, train_indices, label_mapping, tokenizer, max_length=max_length)\n",
    "    val_dataset = SentimentAnalysisDataset(val_data, val_labels, val_aspects, val_indices, label_mapping, tokenizer, max_length=max_length)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb25ba9a",
   "metadata": {
    "papermill": {
     "duration": 0.013915,
     "end_time": "2025-03-24T15:20:26.717298",
     "exception": false,
     "start_time": "2025-03-24T15:20:26.703383",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53fbbd85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T15:20:26.748889Z",
     "iopub.status.busy": "2025-03-24T15:20:26.748562Z",
     "iopub.status.idle": "2025-03-24T15:20:26.753150Z",
     "shell.execute_reply": "2025-03-24T15:20:26.752332Z"
    },
    "papermill": {
     "duration": 0.022767,
     "end_time": "2025-03-24T15:20:26.754465",
     "exception": false,
     "start_time": "2025-03-24T15:20:26.731698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_data = len(X_train) + len(X_val)\n",
    "initial_train_size = int(0.05 * total_data)\n",
    "checkpoints = [\n",
    "    int(0.5 * total_data), \n",
    "    int(0.6 * total_data), \n",
    "    int(0.7 * total_data),\n",
    "    len(X_train)\n",
    "]\n",
    "min_increment = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "510ba2d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T15:20:26.784268Z",
     "iopub.status.busy": "2025-03-24T15:20:26.783948Z",
     "iopub.status.idle": "2025-03-24T15:20:26.789464Z",
     "shell.execute_reply": "2025-03-24T15:20:26.788691Z"
    },
    "papermill": {
     "duration": 0.02222,
     "end_time": "2025-03-24T15:20:26.791060",
     "exception": false,
     "start_time": "2025-03-24T15:20:26.768840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p, label, classes):\n",
    "    preds = torch.tensor(p.predictions) # Sigmoid and threshold for multi-label\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Hamming accuracy: proportion of correctly predicted labels over total labels\n",
    "    hamming_accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Standard multi-label precision, recall, and F1 metrics\n",
    "    precision, recall, f1_micro, _ = precision_recall_fscore_support(labels, preds, average='micro', zero_division=0)\n",
    "    _, _, f1_macro, _ = precision_recall_fscore_support(labels, preds, average='macro', zero_division=0)\n",
    "\n",
    "    report = classification_report(\n",
    "        labels, \n",
    "        preds, \n",
    "        labels=label,\n",
    "        target_names=classes,\n",
    "        zero_division=0\n",
    "    ) \n",
    "\n",
    "    return {\n",
    "        'accuracy': hamming_accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'report': report\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a99c405",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T15:20:26.820861Z",
     "iopub.status.busy": "2025-03-24T15:20:26.820533Z",
     "iopub.status.idle": "2025-03-24T15:20:26.828019Z",
     "shell.execute_reply": "2025-03-24T15:20:26.827219Z"
    },
    "papermill": {
     "duration": 0.023708,
     "end_time": "2025-03-24T15:20:26.829424",
     "exception": false,
     "start_time": "2025-03-24T15:20:26.805716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics_overall(p, classes):\n",
    "    preds = torch.tensor(p.predictions)\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Ensure it's in the correct shape\n",
    "    if preds.shape != labels.shape:\n",
    "        raise ValueError(\"Shape mismatch: predictions and labels must have the same shape.\")\n",
    "\n",
    "    # Hamming accuracy: proportion of correctly predicted labels over total labels\n",
    "    hamming_accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Compute per-label (column-wise) precision, recall, F1\n",
    "    precision_list, recall_list, f1_micro_list, f1_macro_list = [], [], [], []\n",
    "    \n",
    "    for i in range(labels.shape[1]):  # Loop through each column (multi-output)\n",
    "        prec, rec, f1_micro, _ = precision_recall_fscore_support(\n",
    "            labels[:, i], preds[:, i], average='micro', zero_division=0\n",
    "        )\n",
    "        _, _, f1_macro, _ = precision_recall_fscore_support(\n",
    "            labels[:, i], preds[:, i], average='macro', zero_division=0\n",
    "        )\n",
    "\n",
    "        precision_list.append(prec)\n",
    "        recall_list.append(rec)\n",
    "        f1_micro_list.append(f1_micro)\n",
    "        f1_macro_list.append(f1_macro)\n",
    "\n",
    "    # Compute average metrics across all outputs\n",
    "    precision = sum(precision_list) / len(precision_list)\n",
    "    recall = sum(recall_list) / len(recall_list)\n",
    "    f1_micro = sum(f1_micro_list) / len(f1_micro_list)\n",
    "    f1_macro = sum(f1_macro_list) / len(f1_macro_list)\n",
    "\n",
    "    # Generate classification report per output\n",
    "    reports = [classification_report(labels[:, i], preds[:, i], target_names=classes, zero_division=0) for i in range(labels.shape[1])]\n",
    "\n",
    "    return {\n",
    "        'accuracy': hamming_accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'reports': reports  # Returns list of reports, one for each output label\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfaf0971",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T15:20:26.859631Z",
     "iopub.status.busy": "2025-03-24T15:20:26.859273Z",
     "iopub.status.idle": "2025-03-24T15:20:26.890044Z",
     "shell.execute_reply": "2025-03-24T15:20:26.889213Z"
    },
    "papermill": {
     "duration": 0.047501,
     "end_time": "2025-03-24T15:20:26.891727",
     "exception": false,
     "start_time": "2025-03-24T15:20:26.844226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(current_train_size, train_indices, aspect_metrics, sentiment_metrics, metrics, trials, seed):\n",
    "    accelerator = Accelerator(mixed_precision='fp16')  # Initialize the accelerator\n",
    "    device = accelerator.device\n",
    "\n",
    "    aspect_model = BertForSequenceClassification.from_pretrained(\n",
    "        'indobenchmark/indobert-base-p1',\n",
    "        num_labels=len(train_labels),\n",
    "        problem_type=\"multi_label_classification\"\n",
    "    )\n",
    "\n",
    "    # Freeze the first few layers of the encoder\n",
    "    for name, param in aspect_model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    # Define optimizer and loss function\n",
    "    aspect_optimizer = torch.optim.AdamW(aspect_model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Define DataLoaders\n",
    "    current_X_train = [X_train[i] for i in train_indices]\n",
    "    current_y_train = [y_train[i] for i in train_indices]\n",
    "    aspect_train_loader, aspect_val_loader, aspect_train_dataset, aspect_val_dataset = build_aspect_dataset(current_X_train, current_y_train, X_val, y_val, sequence_length)\n",
    "\n",
    "    # Prepare everything with Accelerator\n",
    "    aspect_model, aspect_optimizer, aspect_train_loader, aspect_val_loader = accelerator.prepare(\n",
    "        aspect_model, aspect_optimizer, aspect_train_loader, aspect_val_loader\n",
    "    )\n",
    "\n",
    "    aspect_result = None\n",
    "    start_time = time.time()\n",
    "\n",
    "    # ASPECT DETECTION\n",
    "    accelerator.print(\"ASPECT DETECTION\")\n",
    "    for epoch in range(epochs):\n",
    "        aspect_model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for batch in aspect_train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels']\n",
    "        \n",
    "            aspect_optimizer.zero_grad()\n",
    "            outputs = aspect_model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            aspect_optimizer.step()\n",
    "        \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "        aspect_model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in aspect_val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "                labels = batch['labels']\n",
    "                \n",
    "                outputs = aspect_model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                # Gather predictions and labels from all devices\n",
    "                all_preds.append(accelerator.gather(preds))\n",
    "                all_labels.append(accelerator.gather(labels))\n",
    "\n",
    "        all_preds = torch.cat(all_preds).cpu().numpy()\n",
    "        all_labels = torch.cat(all_labels).cpu().numpy()\n",
    "\n",
    "        result = compute_metrics(\n",
    "            type('EvalOutput', (object,), {'predictions': all_preds, 'label_ids': all_labels}),\n",
    "            None,\n",
    "            ['fuel', 'machine', 'others', 'part', 'price', 'service']\n",
    "        )\n",
    "\n",
    "        if aspect_result is None or result['f1_micro'] >= aspect_result['f1_micro']:\n",
    "            accelerator.print(\"Higher F1 achieved, saving model\")\n",
    "            \n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(aspect_model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                f'{filename}-aspect-{trials + 1}-model',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "            aspect_result = result\n",
    "\n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(aspect_train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "\n",
    "    accelerator.print(f\"\\nAspect detection accuracy: {round(aspect_result['accuracy'], 4)}, F1 Micro: {round(aspect_result['f1_micro'], 4)}, F1 Macro: {round(aspect_result['f1_macro'], 4)}\")\n",
    "    accelerator.print(aspect_result['report'])\n",
    "\n",
    "    best_aspect_model = BertForSequenceClassification.from_pretrained(f'{filename}-aspect-{trials + 1}-model')\n",
    "    best_aspect_model = accelerator.prepare(best_aspect_model)\n",
    "\n",
    "    # SENTIMENT ANALYSIS ON NON NEUTRAL ASPECTS\n",
    "    accelerator.print(\"--------------------------------------------------\")\n",
    "    accelerator.print(\"SENTIMENT ANALYSIS\")\n",
    "\n",
    "    sentiment_model = BertForSequenceClassification.from_pretrained(\n",
    "        'indobenchmark/indobert-base-p1',\n",
    "        num_labels=2,\n",
    "    )\n",
    "    sentiment_optimizer = torch.optim.AdamW(sentiment_model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "\n",
    "    for name, param in sentiment_model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    sentiment_train_loader, sentiment_val_loader, sentiment_train_dataset, sentiment_val_dataset = build_sentiment_dataset(\n",
    "        device, aspect_train_dataset, aspect_val_dataset, best_aspect_model, tokenizer, max_length=sequence_length\n",
    "    )\n",
    "    sentiment_model, sentiment_optimizer, sentiment_train_loader, sentiment_val_loader = accelerator.prepare(\n",
    "        sentiment_model, sentiment_optimizer, sentiment_train_loader, sentiment_val_loader\n",
    "    )\n",
    "    sentiment_result = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        sentiment_model.train()\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for batch in sentiment_train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels']\n",
    "        \n",
    "            sentiment_optimizer.zero_grad()\n",
    "            outputs = sentiment_model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            sentiment_optimizer.step()\n",
    "        \n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        sentiment_model.eval()\n",
    "        sentiment_val_outputs = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in sentiment_val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "                \n",
    "                outputs = sentiment_model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                for i in range(len(preds)):\n",
    "                    val_output = {\n",
    "                        'label': batch['labels'][i],\n",
    "                        'aspect': batch['aspect'][i],\n",
    "                        'ori_indices': batch['ori_indices'][i],\n",
    "                        'pred': np.argmax(preds[i].cpu().numpy()),\n",
    "                    }\n",
    "                    sentiment_val_outputs.append(val_output)\n",
    "\n",
    "        sentiment_val_outputs = accelerator.gather_for_metrics(sentiment_val_outputs)\n",
    "        unique_val_outputs = {(x['ori_indices'].item(), x['aspect']): x for x in sentiment_val_outputs}\n",
    "        sentiment_val_outputs = list(unique_val_outputs.values())\n",
    "\n",
    "        result = compute_metrics(\n",
    "            type('EvalOutput', (object,), {'predictions': [item['pred'] for item in sentiment_val_outputs], 'label_ids': [np.argmax(item['label'].cpu().numpy()) for item in sentiment_val_outputs]}),\n",
    "            [0, 1],\n",
    "            ['negative', 'positive']\n",
    "        )\n",
    "\n",
    "        if sentiment_result is None or result['f1_micro'] >= sentiment_result['f1_micro']:\n",
    "            accelerator.print(\"Higher F1 achieved, saving model\")\n",
    "            sentiment_result = result\n",
    "            \n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(sentiment_model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                 f'{filename}-sentiment-{trials + 1}-model',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "\n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(sentiment_train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "\n",
    "    accelerator.print(f\"\\nSentiment analysis accuracy: {round(sentiment_result['accuracy'], 4)}, F1 Micro: {round(sentiment_result['f1_micro'], 4)}, F1 Macro: {round(sentiment_result['f1_macro'], 4)}\")\n",
    "    accelerator.print(sentiment_result['report'])\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    best_sentiment_model = BertForSequenceClassification.from_pretrained( f'{filename}-sentiment-{trials + 1}-model')\n",
    "    best_sentiment_model = accelerator.prepare(best_sentiment_model)\n",
    "\n",
    "    # Compute overall metrics\n",
    "    aspect_labels = []\n",
    "    aspect_indices = []\n",
    "    aspect_preds = []\n",
    "\n",
    "    aspect_outputs = {}\n",
    "    sentiment_outputs = []\n",
    "    \n",
    "    best_aspect_model.eval()\n",
    "    best_sentiment_model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in aspect_val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            outputs = best_aspect_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            aspect_indices.append(accelerator.gather(batch['ori_indices']))\n",
    "            aspect_labels.append(accelerator.gather(batch['ori_label']))\n",
    "            aspect_preds.append(accelerator.gather(preds))\n",
    "\n",
    "        aspect_indices = torch.cat(aspect_indices).cpu().numpy()\n",
    "        aspect_labels = torch.cat(aspect_labels).cpu().numpy()\n",
    "        aspect_preds = torch.cat(aspect_preds).cpu().numpy()\n",
    "\n",
    "        accelerator.wait_for_everyone()\n",
    "        aspect_outputs = [\n",
    "            {'ori_indices': aspect_indices[i], \n",
    "             'ori_labels': aspect_labels[i], \n",
    "             'pred': aspect_preds[i]}\n",
    "            for i in range(len(aspect_preds))\n",
    "        ]\n",
    "        aspect_outputs = {x['ori_indices'].item(): x for x in aspect_outputs}\n",
    "    \n",
    "        for batch in sentiment_val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            outputs = best_sentiment_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "    \n",
    "            for i in range(len(preds)):\n",
    "                output = {\n",
    "                    'aspect': batch['aspect'][i],\n",
    "                    'ori_indices': batch['ori_indices'][i],\n",
    "                    'pred': np.argmax(preds[i].cpu().numpy()),\n",
    "                }\n",
    "                sentiment_outputs.append(output)\n",
    "\n",
    "        sentiment_outputs = accelerator.gather_for_metrics(sentiment_outputs)\n",
    "        sentiment_outputs = {(x['ori_indices'].item(), x['aspect']): x for x in sentiment_outputs}\n",
    "\n",
    "    # Replcae non neutral aspect to its predicted sentiment\n",
    "    accelerator.wait_for_everyone()\n",
    "    if accelerator.is_main_process:\n",
    "        i = -1\n",
    "        for (ori_index, aspect), value in sentiment_outputs.items():\n",
    "            aspect = aspect_mapping[aspect]\n",
    "            aspect_outputs[ori_index]['pred'][aspect] = 2 if value['pred'] == 1.0 else value['pred']\n",
    "\n",
    "        result = compute_metrics_overall(\n",
    "            type('EvalOutput', (object,), {'predictions': [output['pred'] for output in aspect_outputs.values()], 'label_ids': [output['ori_labels'] for output in aspect_outputs.values()]}),\n",
    "            ['negative', 'neutral', 'positive'],\n",
    "        )\n",
    "\n",
    "        accelerator.print(\"--------------------------------------------------\")\n",
    "        accelerator.print(f\"Iteration {current_train_size}: Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "        accelerator.print(\"--------------------------------------------------\")\n",
    "        for i in range(len(train_labels)):\n",
    "            accelerator.print(f\"Aspect {aspect_list[i]} report:\")\n",
    "            accelerator.print(result['reports'][i])\n",
    "       \n",
    "        \n",
    "        aspect_metrics[0].append(aspect_result['accuracy'])\n",
    "        aspect_metrics[1].append(aspect_result['f1_micro'])\n",
    "        aspect_metrics[2].append(aspect_result['f1_macro'])\n",
    "        sentiment_metrics[0].append(sentiment_result['accuracy'])\n",
    "        sentiment_metrics[1].append(sentiment_result['f1_micro'])\n",
    "        sentiment_metrics[2].append(sentiment_result['f1_macro'])\n",
    "        metrics[0].append(current_train_size)\n",
    "        metrics[1].append(result['accuracy'])\n",
    "        metrics[2].append(result['f1_micro'])\n",
    "        metrics[3].append(result['f1_macro'])\n",
    "        \n",
    "    accelerator.print(f\"Total train time: {duration} s\")\n",
    "    accelerator.end_training()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff34f396",
   "metadata": {
    "papermill": {
     "duration": 0.01389,
     "end_time": "2025-03-24T15:20:26.920194",
     "exception": false,
     "start_time": "2025-03-24T15:20:26.906304",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PLOT THE RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bae1112f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T15:20:26.949602Z",
     "iopub.status.busy": "2025-03-24T15:20:26.949248Z",
     "iopub.status.idle": "2025-03-24T15:20:26.955421Z",
     "shell.execute_reply": "2025-03-24T15:20:26.954698Z"
    },
    "papermill": {
     "duration": 0.022534,
     "end_time": "2025-03-24T15:20:26.956877",
     "exception": false,
     "start_time": "2025-03-24T15:20:26.934343",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_result(data_used, accuracies, f1_micros, f1_macros):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(21, 5))\n",
    "    data_used = [round(data / total_data * 100, 1) for data in data_used]\n",
    "\n",
    "    # Plot for Accuracy\n",
    "    axs[0].plot(data_used, accuracies, label=\"Accuracy\", color=\"blue\")\n",
    "    axs[0].set_xlabel(\"Percentage of data used\")\n",
    "    axs[0].set_title(\"Accuracy\")\n",
    "    axs[0].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Micro\n",
    "    axs[1].plot(data_used, f1_micros, label=\"F1 Micro\", color=\"orange\")\n",
    "    axs[1].set_xlabel(\"Percentage of data used\")\n",
    "    axs[1].set_title(\"F1 Micro\")\n",
    "    axs[1].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Macro\n",
    "    axs[2].plot(data_used, f1_macros, label=\"F1 Macro\", color=\"green\")\n",
    "    axs[2].set_xlabel(\"Percentage of data used\")\n",
    "    axs[2].set_title(\"F1 Macro\")\n",
    "    axs[2].set_xticks(data_used)\n",
    "\n",
    "    # Adjust layout and show the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841f1d61",
   "metadata": {
    "papermill": {
     "duration": 0.013594,
     "end_time": "2025-03-24T15:20:26.984314",
     "exception": false,
     "start_time": "2025-03-24T15:20:26.970720",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# QUERY STRATEGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37931c5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T15:20:27.013659Z",
     "iopub.status.busy": "2025-03-24T15:20:27.013287Z",
     "iopub.status.idle": "2025-03-24T15:20:27.030907Z",
     "shell.execute_reply": "2025-03-24T15:20:27.030040Z"
    },
    "papermill": {
     "duration": 0.034321,
     "end_time": "2025-03-24T15:20:27.032394",
     "exception": false,
     "start_time": "2025-03-24T15:20:26.998073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def least_confidence_sampling(aspect_model, sentiment_model, X_pool, train_indices, remaining_indices, sampling_dur, new_samples, trials, n_samples=min_increment):\n",
    "    accelerator = Accelerator(mixed_precision=\"fp16\")\n",
    "    device = accelerator.device\n",
    "\n",
    "    aspect_model.to(device)\n",
    "    aspect_model.eval()\n",
    "    sentiment_model.to(device)\n",
    "    sentiment_model.eval()\n",
    "\n",
    "    current_train_size = len(train_indices)\n",
    "    aspect_dataset = AspectDetectionDataset(\n",
    "        X_pool, \n",
    "        [['neutral' for i in range(len(train_labels))] for x in range(len(X_pool))], \n",
    "        label_mapping, \n",
    "        tokenizer, \n",
    "        max_length=sequence_length\n",
    "    )\n",
    "    aspect_loader = DataLoader(\n",
    "        aspect_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    \n",
    "    aspect_outputs = {}\n",
    "    sentiment_outputs = {}\n",
    "\n",
    "    aspects = []\n",
    "    data = []\n",
    "    labels = []\n",
    "    indices = []\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Pass through aspect detction model\n",
    "    for batch in aspect_loader:\n",
    "        token_type_ids = batch['token_type_ids'].to(device, non_blocking=True)\n",
    "        input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "        attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = aspect_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "            preds = torch.sigmoid(outputs.logits)\n",
    "\n",
    "        for i in range(len(preds)):\n",
    "            aspect_outputs[batch['ori_indices'][i].item()] = np.max(preds[i].cpu().numpy())\n",
    "            \n",
    "            for j in range(len(preds[i])):\n",
    "                if int(preds[i][j].round()) != 1:\n",
    "                    aspects.append(aspect_list[j])\n",
    "                    data.append(batch['ori_text'][i])\n",
    "                    labels.append(batch['ori_label'][i][j])\n",
    "                    indices.append(batch['ori_indices'][i])\n",
    "    \n",
    "    sentiment_dataset = SentimentAnalysisDataset(data, labels, aspects, indices, label_mapping, tokenizer, max_length=sequence_length)\n",
    "    sentiment_loader = torch.utils.data.DataLoader(\n",
    "        sentiment_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4,\n",
    "    )\n",
    "\n",
    "    # Pass through sentiment analysis model\n",
    "    for batch in sentiment_loader:\n",
    "        token_type_ids = batch['token_type_ids'].to(device, non_blocking=True)\n",
    "        input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "        attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = sentiment_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "            preds = torch.sigmoid(outputs.logits)\n",
    "\n",
    "        for i in range(len(preds)):\n",
    "            ori_index = batch['ori_indices'][i].item()\n",
    "            if ori_index in sentiment_outputs.keys():\n",
    "                max_pred = np.max(preds[i].cpu().numpy())\n",
    "                sentiment_outputs[ori_index] = max_pred if max_pred > sentiment_outputs[ori_index] else sentiment_outputs[ori_index]\n",
    "            else:\n",
    "                sentiment_outputs[ori_index] = np.max(preds[i].cpu().numpy())\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    if accelerator.is_main_process:\n",
    "        aspect_outputs = dict(sorted(aspect_outputs.items()))\n",
    "    \n",
    "        # accelerator.print(aspect_outputs)\n",
    "        for key, val in sentiment_outputs.items():\n",
    "            aspect_outputs[key] = 1 - ((val + aspect_outputs[key]) / 2)\n",
    "    \n",
    "        # accelerator.print(aspect_outputs)\n",
    "        uncertainties = np.array(list(aspect_outputs.values()))\n",
    "        sorted_unc = np.argsort(uncertainties)\n",
    "        sorted_unc = sorted_unc[::-1]\n",
    "\n",
    "        threshold = np.percentile(uncertainties, 90)\n",
    "        items_greater_than_average = uncertainties[uncertainties >= threshold]\n",
    "        num_of_candidates = len(items_greater_than_average)\n",
    "        \n",
    "        # Check nearest checkpoint\n",
    "        nearest_cp = 0\n",
    "        for cp in checkpoints:\n",
    "            if cp > current_train_size:\n",
    "                nearest_cp = cp\n",
    "                break\n",
    "        \n",
    "        if num_of_candidates <= n_samples and n_samples < nearest_cp - current_train_size:\n",
    "            least_confident_indices = sorted_unc[:n_samples]\n",
    "        elif num_of_candidates > n_samples and num_of_candidates < nearest_cp - current_train_size:\n",
    "            least_confident_indices = sorted_unc[:max(n_samples, min(math.ceil(0.1*len(sorted_unc)), num_of_candidates))]\n",
    "        else:\n",
    "            least_confident_indices = sorted_unc[:nearest_cp - current_train_size]\n",
    "    \n",
    "            temp = train_indices.copy()\n",
    "            temp.extend([remaining_indices[i] for i in least_confident_indices])\n",
    "            \n",
    "            # Save acquired data up to checkpoint\n",
    "            acquired_data = pd.DataFrame({\n",
    "                'processed_text': [X_train[i] for i in temp],\n",
    "                'fuel': [y_train[i][0] for i in temp],\n",
    "                'machine': [y_train[i][1] for i in temp],\n",
    "                'others': [y_train[i][2] for i in temp],\n",
    "                'part': [y_train[i][3] for i in temp],\n",
    "                'price': [y_train[i][4] for i in temp],\n",
    "                'service': [y_train[i][5] for i in temp],\n",
    "            })\n",
    "    \n",
    "            acquired_data.to_csv(f'acquired_data/{filename}-{trials+1}-data-{nearest_cp}.csv', index=False)\n",
    "    \n",
    "        end_time = time.time() \n",
    "        duration = end_time - start_time\n",
    "    \n",
    "        sampling_dur.append(duration)\n",
    "        for i in least_confident_indices:\n",
    "            new_samples.append(remaining_indices[i])\n",
    "            \n",
    "        print(\"Nearest checkpoint:\", nearest_cp)\n",
    "        print(\"Threshold:\", threshold)\n",
    "        print(\"Samples above threshold:\", num_of_candidates)\n",
    "        print(\"Acquired samples:\", len(least_confident_indices))\n",
    "        print(f\"Sampling duration: {duration} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7170cf1a",
   "metadata": {
    "papermill": {
     "duration": 0.01387,
     "end_time": "2025-03-24T15:20:27.060491",
     "exception": false,
     "start_time": "2025-03-24T15:20:27.046621",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MAIN LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c2d2fb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T15:20:27.091135Z",
     "iopub.status.busy": "2025-03-24T15:20:27.090795Z",
     "iopub.status.idle": "2025-03-24T15:20:27.102301Z",
     "shell.execute_reply": "2025-03-24T15:20:27.101178Z"
    },
    "papermill": {
     "duration": 0.02884,
     "end_time": "2025-03-24T15:20:27.104016",
     "exception": false,
     "start_time": "2025-03-24T15:20:27.075176",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def active_learning(seed, i):\n",
    "    aspect_accuracies = manager.list()\n",
    "    aspect_f1_micros = manager.list()\n",
    "    aspect_f1_macros = manager.list()\n",
    "    sentiment_accuracies = manager.list()\n",
    "    sentiment_f1_micros = manager.list()\n",
    "    sentiment_f1_macros = manager.list()\n",
    "    accuracies = manager.list()\n",
    "    f1_micros = manager.list()\n",
    "    f1_macros = manager.list()\n",
    "    data_used = manager.list()\n",
    "    sampling_dur = manager.list()\n",
    "    new_samples = manager.list()\n",
    "\n",
    "    set_seed(seed)\n",
    "    \n",
    "    print(\"===============================================\")\n",
    "    print(\"TRIAL {}\".format(i+1))\n",
    "    print(\"Random seed:\", seed)\n",
    "    \n",
    "    train_indices = np.random.choice(range(len(X_train)), initial_train_size, replace=False).tolist()\n",
    "    remaining_indices = list(set(range(len(X_train))) - set(train_indices))\n",
    "    \n",
    "    current_train_size = initial_train_size\n",
    "    \n",
    "    start_time = time.time()\n",
    "    while current_train_size < checkpoints[len(checkpoints) - 1]:\n",
    "        # Train the model\n",
    "        args = (\n",
    "            current_train_size, \n",
    "            train_indices, \n",
    "            (aspect_accuracies, aspect_f1_micros, aspect_f1_macros), \n",
    "            (sentiment_accuracies, sentiment_f1_micros, sentiment_f1_macros),\n",
    "            (data_used, accuracies, f1_micros, f1_macros), \n",
    "            i,\n",
    "            seed\n",
    "        )\n",
    "        notebook_launcher(train_model, args, num_processes=2)\n",
    "\n",
    "        aspect_model = BertForSequenceClassification.from_pretrained(f'{filename}-aspect-{i+1}-model')\n",
    "        sentiment_model = BertForSequenceClassification.from_pretrained(f'{filename}-sentiment-{i+1}-model')\n",
    "    \n",
    "        # Perform query strategy to select new samples\n",
    "        new_samples = manager.list()\n",
    "        sampling_args = (\n",
    "            aspect_model, \n",
    "            sentiment_model, \n",
    "            [X_train[i] for i in remaining_indices], \n",
    "            train_indices, \n",
    "            remaining_indices, \n",
    "            sampling_dur, \n",
    "            new_samples, \n",
    "            i\n",
    "        )\n",
    "        notebook_launcher(least_confidence_sampling, sampling_args, num_processes=2)\n",
    "        new_samples = list(new_samples)\n",
    "        train_indices.extend(new_samples)\n",
    "        remaining_indices = list(set(remaining_indices) - set(new_samples))\n",
    "    \n",
    "        # Update current training size\n",
    "        current_train_size = len(train_indices)\n",
    "        print(\"New train size: {}\".format(current_train_size))\n",
    "    \n",
    "    # Train last epoch\n",
    "    args = (\n",
    "        current_train_size, \n",
    "        train_indices, \n",
    "        (aspect_accuracies, aspect_f1_micros, aspect_f1_macros), \n",
    "        (sentiment_accuracies, sentiment_f1_micros, sentiment_f1_macros),\n",
    "        (data_used, accuracies, f1_micros, f1_macros), \n",
    "        i,\n",
    "        seed\n",
    "    )\n",
    "    notebook_launcher(train_model, args, num_processes=2)\n",
    "    data_used, accuracies, f1_micros, f1_macros, sampling_dur = list(data_used), list(accuracies), list(f1_micros), list(f1_macros), list(sampling_dur)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    # print(f\"Total sampling time: {np.array(sampling_dur).sum().round(2)} seconds\")\n",
    "    print(f\"Total runtime: {duration} seconds\")\n",
    "    \n",
    "    plot_result(data_used, accuracies, f1_micros, f1_macros)\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        'Data Used': data_used,\n",
    "        'Aspect Accuracy': aspect_accuracies,\n",
    "        'Aspect F1 Micro': aspect_f1_micros,\n",
    "        'Aspect F1 Macro': aspect_f1_macros,\n",
    "        'Sentiment Accuracy': sentiment_accuracies,\n",
    "        'Sentiment F1 Micro': sentiment_f1_micros,\n",
    "        'Sentiment F1 Macro': sentiment_f1_macros,\n",
    "        'Accuracy': accuracies,\n",
    "        'F1 Micro': f1_micros,\n",
    "        'F1 Macro': f1_macros,\n",
    "    })\n",
    "    \n",
    "    sampling_dur.insert(0, 0)\n",
    "    results['Sampling Duration'] = sampling_dur\n",
    "    results.to_csv(f'results/{filename}-{i+1}-results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4d83f20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T15:20:27.133895Z",
     "iopub.status.busy": "2025-03-24T15:20:27.133575Z",
     "iopub.status.idle": "2025-03-24T15:20:27.137570Z",
     "shell.execute_reply": "2025-03-24T15:20:27.136635Z"
    },
    "papermill": {
     "duration": 0.020516,
     "end_time": "2025-03-24T15:20:27.138969",
     "exception": false,
     "start_time": "2025-03-24T15:20:27.118453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seeds = [50, 81, 14, 3, 94]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042a3ef9",
   "metadata": {
    "papermill": {
     "duration": 0.014092,
     "end_time": "2025-03-24T15:20:27.167516",
     "exception": false,
     "start_time": "2025-03-24T15:20:27.153424",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17e8e234",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T15:20:27.197246Z",
     "iopub.status.busy": "2025-03-24T15:20:27.196895Z",
     "iopub.status.idle": "2025-03-24T16:09:10.818600Z",
     "shell.execute_reply": "2025-03-24T16:09:10.817589Z"
    },
    "papermill": {
     "duration": 2923.638644,
     "end_time": "2025-03-24T16:09:10.820612",
     "exception": false,
     "start_time": "2025-03-24T15:20:27.181968",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 1\n",
      "Random seed: 50\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6756, Accuracy: 0.7731, F1 Micro: 0.8711, F1 Macro: 0.8698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5958, Accuracy: 0.7887, F1 Micro: 0.8819, F1 Macro: 0.8804\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5785, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.513, Accuracy: 0.7939, F1 Micro: 0.8843, F1 Macro: 0.8828\n",
      "Epoch 5/10, Train Loss: 0.5006, Accuracy: 0.7924, F1 Micro: 0.8829, F1 Macro: 0.881\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4695, Accuracy: 0.7954, F1 Micro: 0.8846, F1 Macro: 0.8828\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4328, Accuracy: 0.7969, F1 Micro: 0.8857, F1 Macro: 0.8842\n",
      "Epoch 8/10, Train Loss: 0.4369, Accuracy: 0.7932, F1 Micro: 0.8832, F1 Macro: 0.8812\n",
      "Epoch 9/10, Train Loss: 0.415, Accuracy: 0.7917, F1 Micro: 0.8816, F1 Macro: 0.8789\n",
      "Epoch 10/10, Train Loss: 0.3884, Accuracy: 0.7894, F1 Micro: 0.88, F1 Macro: 0.8769\n",
      "\n",
      "Aspect detection accuracy: 0.7969, F1 Micro: 0.8857, F1 Macro: 0.8842\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.78      1.00      0.88       175\n",
      "      others       0.71      1.00      0.83       158\n",
      "        part       0.75      0.98      0.85       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.80      1.00      0.89      1061\n",
      "   macro avg       0.80      1.00      0.88      1061\n",
      "weighted avg       0.80      1.00      0.89      1061\n",
      " samples avg       0.80      1.00      0.88      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7162, Accuracy: 0.2857, F1 Micro: 0.2857, F1 Macro: 0.2222\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.6764, Accuracy: 0.5, F1 Micro: 0.5, F1 Macro: 0.4974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.6621, Accuracy: 0.7143, F1 Micro: 0.7143, F1 Macro: 0.65\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.6053, Accuracy: 0.7857, F1 Micro: 0.7857, F1 Macro: 0.7143\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.5803, Accuracy: 0.7857, F1 Micro: 0.7857, F1 Macro: 0.7143\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.5674, Accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.825\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4789, Accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.825\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4895, Accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.825\n",
      "Epoch 9/10, Train Loss: 0.4054, Accuracy: 0.7143, F1 Micro: 0.7143, F1 Macro: 0.6889\n",
      "Epoch 10/10, Train Loss: 0.3482, Accuracy: 0.5, F1 Micro: 0.5, F1 Macro: 0.4974\n",
      "\n",
      "Sentiment analysis accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.825\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75         4\n",
      "    positive       0.90      0.90      0.90        10\n",
      "\n",
      "    accuracy                           0.86        14\n",
      "   macro avg       0.82      0.82      0.82        14\n",
      "weighted avg       0.86      0.86      0.86        14\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.794, F1 Micro: 0.794, F1 Macro: 0.3199\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.77      1.00      0.87       167\n",
      "    positive       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.77       216\n",
      "   macro avg       0.26      0.33      0.29       216\n",
      "weighted avg       0.60      0.77      0.67       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.70      1.00      0.83       152\n",
      "    positive       0.00      0.00      0.00        52\n",
      "\n",
      "    accuracy                           0.70       216\n",
      "   macro avg       0.23      0.33      0.28       216\n",
      "weighted avg       0.50      0.70      0.58       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.13      0.22        23\n",
      "     neutral       0.74      0.98      0.84       152\n",
      "    positive       0.60      0.15      0.24        41\n",
      "\n",
      "    accuracy                           0.73       216\n",
      "   macro avg       0.70      0.42      0.43       216\n",
      "weighted avg       0.71      0.73      0.66       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 58.803948402404785 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.8998008251190186\n",
      "Samples above threshold: 81\n",
      "Acquired samples: 81\n",
      "Sampling duration: 3.926985502243042 seconds\n",
      "New train size: 135\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6141, Accuracy: 0.7887, F1 Micro: 0.8819, F1 Macro: 0.8804\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5112, Accuracy: 0.7917, F1 Micro: 0.8833, F1 Macro: 0.8819\n",
      "Epoch 3/10, Train Loss: 0.4731, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.452, Accuracy: 0.7939, F1 Micro: 0.8844, F1 Macro: 0.883\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4247, Accuracy: 0.7999, F1 Micro: 0.8873, F1 Macro: 0.8859\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3861, Accuracy: 0.808, F1 Micro: 0.8912, F1 Macro: 0.8898\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3652, Accuracy: 0.8378, F1 Micro: 0.9061, F1 Macro: 0.905\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3331, Accuracy: 0.8534, F1 Micro: 0.9147, F1 Macro: 0.9139\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2809, Accuracy: 0.8795, F1 Micro: 0.9283, F1 Macro: 0.9278\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2598, Accuracy: 0.8943, F1 Micro: 0.9361, F1 Macro: 0.9348\n",
      "\n",
      "Aspect detection accuracy: 0.8943, F1 Micro: 0.9361, F1 Macro: 0.9348\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.89      1.00      0.94       187\n",
      "     machine       0.94      0.97      0.95       175\n",
      "      others       0.86      0.93      0.90       158\n",
      "        part       0.85      0.99      0.92       158\n",
      "       price       0.94      0.98      0.96       192\n",
      "     service       0.89      1.00      0.94       191\n",
      "\n",
      "   micro avg       0.90      0.98      0.94      1061\n",
      "   macro avg       0.90      0.98      0.93      1061\n",
      "weighted avg       0.90      0.98      0.94      1061\n",
      " samples avg       0.90      0.98      0.93      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6486, Accuracy: 0.6954, F1 Micro: 0.6954, F1 Macro: 0.4102\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.6037, Accuracy: 0.6954, F1 Micro: 0.6954, F1 Macro: 0.4102\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5149, Accuracy: 0.7529, F1 Micro: 0.7529, F1 Macro: 0.5833\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4421, Accuracy: 0.7644, F1 Micro: 0.7644, F1 Macro: 0.6294\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3884, Accuracy: 0.8161, F1 Micro: 0.8161, F1 Macro: 0.7602\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2866, Accuracy: 0.8851, F1 Micro: 0.8851, F1 Macro: 0.8695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2605, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1299, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8876\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1537, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.8937\n",
      "Epoch 10/10, Train Loss: 0.1795, Accuracy: 0.8966, F1 Micro: 0.8966, F1 Macro: 0.8815\n",
      "\n",
      "Sentiment analysis accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.8937\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.89      0.85        53\n",
      "    positive       0.95      0.92      0.93       121\n",
      "\n",
      "    accuracy                           0.91       174\n",
      "   macro avg       0.89      0.90      0.89       174\n",
      "weighted avg       0.91      0.91      0.91       174\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 135: Accuracy: 0.8835, F1 Micro: 0.8835, F1 Macro: 0.707\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.36      0.50        11\n",
      "     neutral       0.89      1.00      0.94       181\n",
      "    positive       0.86      0.25      0.39        24\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.85      0.54      0.61       216\n",
      "weighted avg       0.88      0.88      0.86       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.94      0.97      0.95       167\n",
      "    positive       0.80      0.73      0.76        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.89      0.82      0.85       216\n",
      "weighted avg       0.91      0.92      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.75      0.67        12\n",
      "     neutral       0.87      0.93      0.90       152\n",
      "    positive       0.82      0.60      0.69        52\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.76      0.76      0.75       216\n",
      "weighted avg       0.84      0.84      0.83       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.52      0.65        23\n",
      "     neutral       0.84      0.99      0.91       152\n",
      "    positive       0.91      0.51      0.66        41\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.87      0.68      0.74       216\n",
      "weighted avg       0.86      0.85      0.84       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.46      0.63        13\n",
      "     neutral       0.94      0.98      0.96       186\n",
      "    positive       0.67      0.59      0.62        17\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.87      0.68      0.74       216\n",
      "weighted avg       0.92      0.92      0.91       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.29      0.44        14\n",
      "     neutral       0.89      1.00      0.94       185\n",
      "    positive       0.75      0.18      0.29        17\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.88      0.49      0.56       216\n",
      "weighted avg       0.89      0.89      0.86       216\n",
      "\n",
      "Total train time: 80.60155010223389 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.9461406111717224\n",
      "Samples above threshold: 73\n",
      "Acquired samples: 73\n",
      "Sampling duration: 5.1227867603302 seconds\n",
      "New train size: 208\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5963, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5157, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Epoch 3/10, Train Loss: 0.4929, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4647, Accuracy: 0.808, F1 Micro: 0.8913, F1 Macro: 0.8902\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4149, Accuracy: 0.8333, F1 Micro: 0.9039, F1 Macro: 0.9033\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3715, Accuracy: 0.8676, F1 Micro: 0.9223, F1 Macro: 0.9213\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3137, Accuracy: 0.9129, F1 Micro: 0.9472, F1 Macro: 0.946\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2591, Accuracy: 0.9353, F1 Micro: 0.9602, F1 Macro: 0.9589\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2191, Accuracy: 0.939, F1 Micro: 0.9624, F1 Macro: 0.9607\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1794, Accuracy: 0.9449, F1 Micro: 0.9659, F1 Macro: 0.9646\n",
      "\n",
      "Aspect detection accuracy: 0.9449, F1 Micro: 0.9659, F1 Macro: 0.9646\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.97      1.00      0.99       187\n",
      "     machine       0.94      0.98      0.96       175\n",
      "      others       0.86      0.97      0.91       158\n",
      "        part       0.93      0.99      0.96       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.97      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.94      0.99      0.97      1061\n",
      "   macro avg       0.94      0.99      0.96      1061\n",
      "weighted avg       0.95      0.99      0.97      1061\n",
      " samples avg       0.94      0.99      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6643, Accuracy: 0.68, F1 Micro: 0.68, F1 Macro: 0.4048\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5287, Accuracy: 0.8044, F1 Micro: 0.8044, F1 Macro: 0.7841\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3814, Accuracy: 0.8578, F1 Micro: 0.8578, F1 Macro: 0.84\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2394, Accuracy: 0.88, F1 Micro: 0.88, F1 Macro: 0.8701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2056, Accuracy: 0.9111, F1 Micro: 0.9111, F1 Macro: 0.8979\n",
      "Epoch 6/10, Train Loss: 0.148, Accuracy: 0.8889, F1 Micro: 0.8889, F1 Macro: 0.8791\n",
      "Epoch 7/10, Train Loss: 0.0904, Accuracy: 0.9067, F1 Micro: 0.9067, F1 Macro: 0.8967\n",
      "Epoch 8/10, Train Loss: 0.1646, Accuracy: 0.8533, F1 Micro: 0.8533, F1 Macro: 0.8457\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1493, Accuracy: 0.92, F1 Micro: 0.92, F1 Macro: 0.9094\n",
      "Epoch 10/10, Train Loss: 0.1201, Accuracy: 0.8933, F1 Micro: 0.8933, F1 Macro: 0.8823\n",
      "\n",
      "Sentiment analysis accuracy: 0.92, F1 Micro: 0.92, F1 Macro: 0.9094\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.90      0.88        72\n",
      "    positive       0.95      0.93      0.94       153\n",
      "\n",
      "    accuracy                           0.92       225\n",
      "   macro avg       0.90      0.92      0.91       225\n",
      "weighted avg       0.92      0.92      0.92       225\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 208: Accuracy: 0.9329, F1 Micro: 0.9329, F1 Macro: 0.8559\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.98      0.90      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.62      0.71        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.87      0.79      0.82       216\n",
      "weighted avg       0.91      0.92      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.57      0.67      0.62        12\n",
      "     neutral       0.86      0.97      0.91       152\n",
      "    positive       0.88      0.54      0.67        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.77      0.72      0.73       216\n",
      "weighted avg       0.85      0.85      0.84       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.78      0.82        23\n",
      "     neutral       0.93      0.99      0.96       152\n",
      "    positive       0.94      0.78      0.85        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.91      0.85      0.88       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.62      0.76        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.81      0.86       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.97      1.00      0.99       185\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.97      0.87      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 83.57678031921387 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.21146264672279358\n",
      "Samples above threshold: 66\n",
      "Acquired samples: 66\n",
      "Sampling duration: 5.4467620849609375 seconds\n",
      "New train size: 274\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5885, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.492, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4754, Accuracy: 0.7939, F1 Micro: 0.8845, F1 Macro: 0.8831\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4292, Accuracy: 0.8021, F1 Micro: 0.8885, F1 Macro: 0.8872\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3869, Accuracy: 0.8579, F1 Micro: 0.9167, F1 Macro: 0.916\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3358, Accuracy: 0.9115, F1 Micro: 0.9464, F1 Macro: 0.9454\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2766, Accuracy: 0.942, F1 Micro: 0.9641, F1 Macro: 0.9625\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2134, Accuracy: 0.9494, F1 Micro: 0.9688, F1 Macro: 0.9674\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1742, Accuracy: 0.9501, F1 Micro: 0.9691, F1 Macro: 0.9677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1443, Accuracy: 0.9524, F1 Micro: 0.9703, F1 Macro: 0.9687\n",
      "\n",
      "Aspect detection accuracy: 0.9524, F1 Micro: 0.9703, F1 Macro: 0.9687\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.89      0.94      0.92       158\n",
      "        part       0.94      0.99      0.96       158\n",
      "       price       0.98      0.99      0.98       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.95      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6837, Accuracy: 0.6749, F1 Micro: 0.6749, F1 Macro: 0.4148\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5532, Accuracy: 0.8807, F1 Micro: 0.8807, F1 Macro: 0.8712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3308, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9215\n",
      "Epoch 4/10, Train Loss: 0.2304, Accuracy: 0.8848, F1 Micro: 0.8848, F1 Macro: 0.8776\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1934, Accuracy: 0.9383, F1 Micro: 0.9383, F1 Macro: 0.9303\n",
      "Epoch 6/10, Train Loss: 0.1048, Accuracy: 0.9259, F1 Micro: 0.9259, F1 Macro: 0.9198\n",
      "Epoch 7/10, Train Loss: 0.1229, Accuracy: 0.9218, F1 Micro: 0.9218, F1 Macro: 0.9152\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1044, Accuracy: 0.9383, F1 Micro: 0.9383, F1 Macro: 0.9323\n",
      "Epoch 9/10, Train Loss: 0.0754, Accuracy: 0.9342, F1 Micro: 0.9342, F1 Macro: 0.9272\n",
      "Epoch 10/10, Train Loss: 0.0728, Accuracy: 0.9218, F1 Micro: 0.9218, F1 Macro: 0.9152\n",
      "\n",
      "Sentiment analysis accuracy: 0.9383, F1 Micro: 0.9383, F1 Macro: 0.9323\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.97      0.91        80\n",
      "    positive       0.99      0.92      0.95       163\n",
      "\n",
      "    accuracy                           0.94       243\n",
      "   macro avg       0.92      0.95      0.93       243\n",
      "weighted avg       0.94      0.94      0.94       243\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 274: Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.8932\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.94      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.92      0.70      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.85      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.75      0.72        12\n",
      "     neutral       0.89      0.94      0.92       152\n",
      "    positive       0.81      0.67      0.74        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.80      0.79      0.79       216\n",
      "weighted avg       0.86      0.87      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.91      0.89        23\n",
      "     neutral       0.94      0.99      0.96       152\n",
      "    positive       0.97      0.76      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.89      0.90       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        13\n",
      "     neutral       0.98      0.99      0.98       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.90      0.86      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 87.78244543075562 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.07539478540420536\n",
      "Samples above threshold: 59\n",
      "Acquired samples: 59\n",
      "Sampling duration: 5.404713869094849 seconds\n",
      "New train size: 333\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5718, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Epoch 2/10, Train Loss: 0.4805, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4463, Accuracy: 0.811, F1 Micro: 0.8929, F1 Macro: 0.892\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3948, Accuracy: 0.8824, F1 Micro: 0.9304, F1 Macro: 0.9297\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3121, Accuracy: 0.9323, F1 Micro: 0.9583, F1 Macro: 0.9565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2439, Accuracy: 0.9412, F1 Micro: 0.9635, F1 Macro: 0.9618\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2012, Accuracy: 0.9561, F1 Micro: 0.9727, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.148, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1249, Accuracy: 0.9583, F1 Micro: 0.974, F1 Macro: 0.9727\n",
      "Epoch 10/10, Train Loss: 0.0957, Accuracy: 0.9554, F1 Micro: 0.972, F1 Macro: 0.9705\n",
      "\n",
      "Aspect detection accuracy: 0.9583, F1 Micro: 0.974, F1 Macro: 0.9727\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.90      0.96      0.93       158\n",
      "        part       0.96      0.97      0.97       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.97      1061\n",
      "   macro avg       0.96      0.99      0.97      1061\n",
      "weighted avg       0.96      0.99      0.97      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.67, Accuracy: 0.7976, F1 Micro: 0.7976, F1 Macro: 0.7835\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5034, Accuracy: 0.8907, F1 Micro: 0.8907, F1 Macro: 0.8838\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2859, Accuracy: 0.9028, F1 Micro: 0.9028, F1 Macro: 0.8961\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1739, Accuracy: 0.9069, F1 Micro: 0.9069, F1 Macro: 0.8953\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1423, Accuracy: 0.919, F1 Micro: 0.919, F1 Macro: 0.9093\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1382, Accuracy: 0.919, F1 Micro: 0.919, F1 Macro: 0.9122\n",
      "Epoch 7/10, Train Loss: 0.1268, Accuracy: 0.915, F1 Micro: 0.915, F1 Macro: 0.908\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1088, Accuracy: 0.919, F1 Micro: 0.919, F1 Macro: 0.9122\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0868, Accuracy: 0.919, F1 Micro: 0.919, F1 Macro: 0.9117\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0629, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9135\n",
      "\n",
      "Sentiment analysis accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9135\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.88      0.88        83\n",
      "    positive       0.94      0.95      0.94       164\n",
      "\n",
      "    accuracy                           0.92       247\n",
      "   macro avg       0.91      0.91      0.91       247\n",
      "weighted avg       0.92      0.92      0.92       247\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 333: Accuracy: 0.9452, F1 Micro: 0.9452, F1 Macro: 0.8845\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.69      0.79        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.81      0.85       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.91      0.96      0.93       152\n",
      "    positive       0.84      0.69      0.76        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.83      0.80      0.81       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.96      0.97      0.97       152\n",
      "    positive       0.89      0.78      0.83        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.90      0.90       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.91      0.84      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 96.73909068107605 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.041591525077819824\n",
      "Samples above threshold: 54\n",
      "Acquired samples: 54\n",
      "Sampling duration: 5.187345266342163 seconds\n",
      "New train size: 387\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.572, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4869, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4509, Accuracy: 0.8326, F1 Micro: 0.9035, F1 Macro: 0.9032\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3502, Accuracy: 0.9226, F1 Micro: 0.9524, F1 Macro: 0.9503\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2743, Accuracy: 0.9412, F1 Micro: 0.9635, F1 Macro: 0.9619\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.207, Accuracy: 0.9501, F1 Micro: 0.9691, F1 Macro: 0.9676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1502, Accuracy: 0.9554, F1 Micro: 0.9722, F1 Macro: 0.9707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.131, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1014, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0877, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9739\n",
      "\n",
      "Aspect detection accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9739\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.91      0.94      0.92       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.98      0.99      0.98       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6298, Accuracy: 0.8261, F1 Micro: 0.8261, F1 Macro: 0.8015\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4541, Accuracy: 0.8972, F1 Micro: 0.8972, F1 Macro: 0.89\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2557, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9345\n",
      "Epoch 4/10, Train Loss: 0.173, Accuracy: 0.9289, F1 Micro: 0.9289, F1 Macro: 0.9231\n",
      "Epoch 5/10, Train Loss: 0.1615, Accuracy: 0.9289, F1 Micro: 0.9289, F1 Macro: 0.9224\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1414, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9348\n",
      "Epoch 7/10, Train Loss: 0.1279, Accuracy: 0.917, F1 Micro: 0.917, F1 Macro: 0.9067\n",
      "Epoch 8/10, Train Loss: 0.0831, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9261\n",
      "Epoch 9/10, Train Loss: 0.1019, Accuracy: 0.917, F1 Micro: 0.917, F1 Macro: 0.9067\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0962, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9345\n",
      "\n",
      "Sentiment analysis accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9345\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.95      0.91        84\n",
      "    positive       0.98      0.93      0.95       169\n",
      "\n",
      "    accuracy                           0.94       253\n",
      "   macro avg       0.93      0.94      0.93       253\n",
      "weighted avg       0.94      0.94      0.94       253\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 387: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9051\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.92      0.94      0.93       152\n",
      "    positive       0.79      0.73      0.76        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.82      0.81      0.81       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.96      0.99      0.98       152\n",
      "    positive       1.00      0.80      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.98       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.94      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 100.69421672821045 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.02973313331604004\n",
      "Samples above threshold: 48\n",
      "Acquired samples: 48\n",
      "Sampling duration: 4.935128927230835 seconds\n",
      "New train size: 435\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5737, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5017, Accuracy: 0.7969, F1 Micro: 0.886, F1 Macro: 0.8846\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4211, Accuracy: 0.8891, F1 Micro: 0.9342, F1 Macro: 0.9335\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.323, Accuracy: 0.9375, F1 Micro: 0.9613, F1 Macro: 0.9596\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2525, Accuracy: 0.9531, F1 Micro: 0.9708, F1 Macro: 0.9694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1876, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9739\n",
      "Epoch 7/10, Train Loss: 0.1451, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9713\n",
      "Epoch 8/10, Train Loss: 0.1128, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0955, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0778, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.975\n",
      "\n",
      "Aspect detection accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.98      0.99      0.98       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.621, Accuracy: 0.8157, F1 Micro: 0.8157, F1 Macro: 0.807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3781, Accuracy: 0.9255, F1 Micro: 0.9255, F1 Macro: 0.919\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2335, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9228\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.212, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9281\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1896, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9393\n",
      "Epoch 6/10, Train Loss: 0.1396, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9336\n",
      "Epoch 7/10, Train Loss: 0.1322, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9348\n",
      "Epoch 8/10, Train Loss: 0.1159, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9234\n",
      "Epoch 9/10, Train Loss: 0.1114, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9227\n",
      "Epoch 10/10, Train Loss: 0.0623, Accuracy: 0.9255, F1 Micro: 0.9255, F1 Macro: 0.9186\n",
      "\n",
      "Sentiment analysis accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9393\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        84\n",
      "    positive       0.98      0.94      0.96       171\n",
      "\n",
      "    accuracy                           0.95       255\n",
      "   macro avg       0.93      0.95      0.94       255\n",
      "weighted avg       0.95      0.95      0.95       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 435: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9135\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.85      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.75      0.72        12\n",
      "     neutral       0.93      0.95      0.94       152\n",
      "    positive       0.81      0.75      0.78        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.81      0.82      0.81       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.96      0.99      0.98       152\n",
      "    positive       1.00      0.78      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.94      0.92      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.98       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 101.09602618217468 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.059939146041870096\n",
      "Samples above threshold: 43\n",
      "Acquired samples: 43\n",
      "Sampling duration: 4.700274467468262 seconds\n",
      "New train size: 478\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5621, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4792, Accuracy: 0.8095, F1 Micro: 0.8922, F1 Macro: 0.8911\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3983, Accuracy: 0.9048, F1 Micro: 0.9428, F1 Macro: 0.9418\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2951, Accuracy: 0.9449, F1 Micro: 0.966, F1 Macro: 0.9647\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2195, Accuracy: 0.9583, F1 Micro: 0.9741, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1691, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9729\n",
      "Epoch 7/10, Train Loss: 0.1329, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9719\n",
      "Epoch 8/10, Train Loss: 0.1046, Accuracy: 0.9561, F1 Micro: 0.9725, F1 Macro: 0.9712\n",
      "Epoch 9/10, Train Loss: 0.0886, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0769, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9755\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9755\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.90      0.96      0.93       158\n",
      "        part       0.96      0.99      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6002, Accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.8444\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4146, Accuracy: 0.9206, F1 Micro: 0.9206, F1 Macro: 0.9136\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3159, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9196\n",
      "Epoch 4/10, Train Loss: 0.2208, Accuracy: 0.9246, F1 Micro: 0.9246, F1 Macro: 0.9154\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1851, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9347\n",
      "Epoch 6/10, Train Loss: 0.1678, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9264\n",
      "Epoch 7/10, Train Loss: 0.1427, Accuracy: 0.9246, F1 Micro: 0.9246, F1 Macro: 0.9181\n",
      "Epoch 8/10, Train Loss: 0.1234, Accuracy: 0.9246, F1 Micro: 0.9246, F1 Macro: 0.9181\n",
      "Epoch 9/10, Train Loss: 0.0971, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.9099\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1043, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9332\n",
      "\n",
      "Sentiment analysis accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9332\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.91      0.91        85\n",
      "    positive       0.95      0.96      0.96       167\n",
      "\n",
      "    accuracy                           0.94       252\n",
      "   macro avg       0.93      0.93      0.93       252\n",
      "weighted avg       0.94      0.94      0.94       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 478: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9064\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.92      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.88      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.85      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.67      0.76        12\n",
      "     neutral       0.91      0.97      0.94       152\n",
      "    positive       0.87      0.75      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.89      0.79      0.83       216\n",
      "weighted avg       0.90      0.90      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.96      0.99      0.97       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 102.16743993759155 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.02167251706123352\n",
      "Samples above threshold: 39\n",
      "Acquired samples: 39\n",
      "Sampling duration: 4.377509117126465 seconds\n",
      "New train size: 517\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5551, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.472, Accuracy: 0.8118, F1 Micro: 0.8933, F1 Macro: 0.8922\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3669, Accuracy: 0.9263, F1 Micro: 0.9551, F1 Macro: 0.9537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2603, Accuracy: 0.9554, F1 Micro: 0.9724, F1 Macro: 0.971\n",
      "Epoch 5/10, Train Loss: 0.1896, Accuracy: 0.9554, F1 Micro: 0.9721, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1369, Accuracy: 0.9561, F1 Micro: 0.9724, F1 Macro: 0.9707\n",
      "Epoch 7/10, Train Loss: 0.114, Accuracy: 0.9539, F1 Micro: 0.9709, F1 Macro: 0.9685\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0905, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9739\n",
      "Epoch 9/10, Train Loss: 0.0762, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0643, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9743\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9743\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.91      0.94      0.92       158\n",
      "        part       0.96      0.99      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6103, Accuracy: 0.8672, F1 Micro: 0.8672, F1 Macro: 0.8465\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3482, Accuracy: 0.9102, F1 Micro: 0.9102, F1 Macro: 0.9031\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2445, Accuracy: 0.9102, F1 Micro: 0.9102, F1 Macro: 0.9031\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2468, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9262\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.202, Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.9352\n",
      "Epoch 6/10, Train Loss: 0.1549, Accuracy: 0.9297, F1 Micro: 0.9297, F1 Macro: 0.9203\n",
      "Epoch 7/10, Train Loss: 0.1237, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.93\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0774, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9394\n",
      "Epoch 9/10, Train Loss: 0.1098, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9307\n",
      "Epoch 10/10, Train Loss: 0.0906, Accuracy: 0.9297, F1 Micro: 0.9297, F1 Macro: 0.9229\n",
      "\n",
      "Sentiment analysis accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9394\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        84\n",
      "    positive       0.98      0.94      0.96       172\n",
      "\n",
      "    accuracy                           0.95       256\n",
      "   macro avg       0.93      0.95      0.94       256\n",
      "weighted avg       0.95      0.95      0.95       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 517: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9156\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.92      0.94      0.93       152\n",
      "    positive       0.79      0.73      0.76        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.82      0.81      0.81       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.96      0.99      0.97       152\n",
      "    positive       0.97      0.76      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.91      0.91       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 108.35492444038391 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.018940520286560063\n",
      "Samples above threshold: 35\n",
      "Acquired samples: 23\n",
      "Sampling duration: 4.076385021209717 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5535, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4728, Accuracy: 0.8177, F1 Micro: 0.8963, F1 Macro: 0.8959\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3638, Accuracy: 0.9204, F1 Micro: 0.9517, F1 Macro: 0.9504\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2758, Accuracy: 0.9464, F1 Micro: 0.967, F1 Macro: 0.9658\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2017, Accuracy: 0.9561, F1 Micro: 0.9727, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1502, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9738\n",
      "Epoch 7/10, Train Loss: 0.1142, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9736\n",
      "Epoch 8/10, Train Loss: 0.0934, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9724\n",
      "Epoch 9/10, Train Loss: 0.0796, Accuracy: 0.9591, F1 Micro: 0.9741, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0646, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9757\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9757\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.91      0.94      0.93       158\n",
      "        part       0.97      0.98      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5567, Accuracy: 0.8654, F1 Micro: 0.8654, F1 Macro: 0.8558\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3783, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9182\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2316, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9361\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2001, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9364\n",
      "Epoch 5/10, Train Loss: 0.1512, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9309\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1382, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9354\n",
      "Epoch 7/10, Train Loss: 0.1034, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.928\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0873, Accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9399\n",
      "Epoch 9/10, Train Loss: 0.0855, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.9079\n",
      "Epoch 10/10, Train Loss: 0.0736, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9213\n",
      "\n",
      "Sentiment analysis accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9399\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        86\n",
      "    positive       0.97      0.95      0.96       174\n",
      "\n",
      "    accuracy                           0.95       260\n",
      "   macro avg       0.94      0.95      0.94       260\n",
      "weighted avg       0.95      0.95      0.95       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9183\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.92      0.94      0.93       152\n",
      "    positive       0.80      0.75      0.77        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.84      0.81      0.83       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.98      0.97       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.93      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 110.94932174682617 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.019050681591033933\n",
      "Samples above threshold: 33\n",
      "Acquired samples: 33\n",
      "Sampling duration: 3.8928322792053223 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5472, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4756, Accuracy: 0.8192, F1 Micro: 0.8973, F1 Macro: 0.8962\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3576, Accuracy: 0.9286, F1 Micro: 0.9564, F1 Macro: 0.9552\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2625, Accuracy: 0.9531, F1 Micro: 0.9708, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.177, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1397, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1111, Accuracy: 0.9628, F1 Micro: 0.9768, F1 Macro: 0.9754\n",
      "Epoch 8/10, Train Loss: 0.0911, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9751\n",
      "Epoch 9/10, Train Loss: 0.0742, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9712\n",
      "Epoch 10/10, Train Loss: 0.0664, Accuracy: 0.9591, F1 Micro: 0.9741, F1 Macro: 0.9721\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9768, F1 Macro: 0.9754\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.95      0.93       158\n",
      "        part       0.95      0.99      0.97       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.98      1061\n",
      "weighted avg       0.96      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6028, Accuracy: 0.8852, F1 Micro: 0.8852, F1 Macro: 0.8743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3217, Accuracy: 0.8975, F1 Micro: 0.8975, F1 Macro: 0.8818\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2298, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9256\n",
      "Epoch 4/10, Train Loss: 0.195, Accuracy: 0.9303, F1 Micro: 0.9303, F1 Macro: 0.9222\n",
      "Epoch 5/10, Train Loss: 0.1829, Accuracy: 0.9262, F1 Micro: 0.9262, F1 Macro: 0.9178\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1737, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9328\n",
      "Epoch 7/10, Train Loss: 0.1152, Accuracy: 0.9303, F1 Micro: 0.9303, F1 Macro: 0.9243\n",
      "Epoch 8/10, Train Loss: 0.1355, Accuracy: 0.9303, F1 Micro: 0.9303, F1 Macro: 0.9239\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0985, Accuracy: 0.9508, F1 Micro: 0.9508, F1 Macro: 0.9452\n",
      "Epoch 10/10, Train Loss: 0.0774, Accuracy: 0.9221, F1 Micro: 0.9221, F1 Macro: 0.9154\n",
      "\n",
      "Sentiment analysis accuracy: 0.9508, F1 Micro: 0.9508, F1 Macro: 0.9452\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        83\n",
      "    positive       0.96      0.96      0.96       161\n",
      "\n",
      "    accuracy                           0.95       244\n",
      "   macro avg       0.95      0.95      0.95       244\n",
      "weighted avg       0.95      0.95      0.95       244\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.912\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.83      0.87       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.83      0.77      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.86      0.82      0.84       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.94      0.99      0.97       152\n",
      "    positive       1.00      0.76      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.94      0.90      0.92       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.89      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 111.86962413787842 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.022965669631958008\n",
      "Samples above threshold: 30\n",
      "Acquired samples: 30\n",
      "Sampling duration: 3.634577512741089 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5487, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4502, Accuracy: 0.8452, F1 Micro: 0.9106, F1 Macro: 0.9101\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3242, Accuracy: 0.9323, F1 Micro: 0.9587, F1 Macro: 0.9569\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2299, Accuracy: 0.9561, F1 Micro: 0.9726, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1748, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9733\n",
      "Epoch 6/10, Train Loss: 0.1232, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.098, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0874, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9754\n",
      "Epoch 9/10, Train Loss: 0.071, Accuracy: 0.9561, F1 Micro: 0.9722, F1 Macro: 0.9696\n",
      "Epoch 10/10, Train Loss: 0.0624, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9735\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9754\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.94      0.92      0.93       158\n",
      "        part       0.96      0.99      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5575, Accuracy: 0.8859, F1 Micro: 0.8859, F1 Macro: 0.8726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.28, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.916\n",
      "Epoch 3/10, Train Loss: 0.2571, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.9012\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1884, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9365\n",
      "Epoch 5/10, Train Loss: 0.1848, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9244\n",
      "Epoch 6/10, Train Loss: 0.1454, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.8922\n",
      "Epoch 7/10, Train Loss: 0.1142, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.928\n",
      "Epoch 8/10, Train Loss: 0.0971, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9223\n",
      "Epoch 9/10, Train Loss: 0.0744, Accuracy: 0.9278, F1 Micro: 0.9278, F1 Macro: 0.9191\n",
      "Epoch 10/10, Train Loss: 0.0761, Accuracy: 0.9278, F1 Micro: 0.9278, F1 Macro: 0.9182\n",
      "\n",
      "Sentiment analysis accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9365\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.96      0.92        85\n",
      "    positive       0.98      0.93      0.96       178\n",
      "\n",
      "    accuracy                           0.94       263\n",
      "   macro avg       0.93      0.95      0.94       263\n",
      "weighted avg       0.95      0.94      0.94       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9198\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.94      0.92      0.93       152\n",
      "    positive       0.77      0.79      0.78        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.81      0.85      0.83       216\n",
      "weighted avg       0.89      0.88      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.96      0.99      0.97       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.92      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 110.37322068214417 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.03231930732727051\n",
      "Samples above threshold: 27\n",
      "Acquired samples: 27\n",
      "Sampling duration: 3.4449548721313477 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5416, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.437, Accuracy: 0.8757, F1 Micro: 0.9265, F1 Macro: 0.9257\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3192, Accuracy: 0.9382, F1 Micro: 0.9619, F1 Macro: 0.9602\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2174, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9721\n",
      "Epoch 5/10, Train Loss: 0.1703, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9719\n",
      "Epoch 6/10, Train Loss: 0.1228, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.098, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9742\n",
      "Epoch 8/10, Train Loss: 0.0772, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9716\n",
      "Epoch 9/10, Train Loss: 0.0664, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0622, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9749\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.93      0.91      0.92       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5452, Accuracy: 0.8902, F1 Micro: 0.8902, F1 Macro: 0.8805\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3053, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9269\n",
      "Epoch 3/10, Train Loss: 0.2467, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9188\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2103, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9282\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2192, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9285\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1615, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9326\n",
      "Epoch 7/10, Train Loss: 0.1459, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9229\n",
      "Epoch 8/10, Train Loss: 0.107, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9289\n",
      "Epoch 9/10, Train Loss: 0.0865, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9289\n",
      "Epoch 10/10, Train Loss: 0.074, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9245\n",
      "\n",
      "Sentiment analysis accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9326\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.94      0.91        87\n",
      "    positive       0.97      0.94      0.95       177\n",
      "\n",
      "    accuracy                           0.94       264\n",
      "   macro avg       0.93      0.94      0.93       264\n",
      "weighted avg       0.94      0.94      0.94       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9146\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.93      0.91      0.92       152\n",
      "    positive       0.75      0.77      0.76        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.80      0.84      0.82       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.96      0.99      0.98       152\n",
      "    positive       1.00      0.80      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 114.43863558769226 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.019313085079193115\n",
      "Samples above threshold: 24\n",
      "Acquired samples: 18\n",
      "Sampling duration: 3.2936697006225586 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5377, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4244, Accuracy: 0.904, F1 Micro: 0.9422, F1 Macro: 0.9412\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3069, Accuracy: 0.9442, F1 Micro: 0.9651, F1 Macro: 0.9628\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2071, Accuracy: 0.9554, F1 Micro: 0.9721, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.156, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1159, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9766\n",
      "Epoch 7/10, Train Loss: 0.0919, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9752\n",
      "Epoch 8/10, Train Loss: 0.0763, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0602, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.978\n",
      "Epoch 10/10, Train Loss: 0.0534, Accuracy: 0.9606, F1 Micro: 0.975, F1 Macro: 0.9729\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.93      0.93      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5403, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8983\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2661, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9289\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1684, Accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.9413\n",
      "Epoch 4/10, Train Loss: 0.2096, Accuracy: 0.9242, F1 Micro: 0.9242, F1 Macro: 0.9127\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.152, Accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.9403\n",
      "Epoch 6/10, Train Loss: 0.1095, Accuracy: 0.8977, F1 Micro: 0.8977, F1 Macro: 0.8911\n",
      "Epoch 7/10, Train Loss: 0.1572, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9289\n",
      "Epoch 8/10, Train Loss: 0.0918, Accuracy: 0.9432, F1 Micro: 0.9432, F1 Macro: 0.9359\n",
      "Epoch 9/10, Train Loss: 0.0803, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9206\n",
      "Epoch 10/10, Train Loss: 0.0724, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.9013\n",
      "\n",
      "Sentiment analysis accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.9403\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.93      0.92        87\n",
      "    positive       0.97      0.95      0.96       177\n",
      "\n",
      "    accuracy                           0.95       264\n",
      "   macro avg       0.94      0.94      0.94       264\n",
      "weighted avg       0.95      0.95      0.95       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9227\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.96      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.78      0.77      0.78        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.83      0.85      0.84       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.88      0.94        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 117.42209601402283 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.018147766590118408\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.0950677394866943 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5439, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4183, Accuracy: 0.9137, F1 Micro: 0.9475, F1 Macro: 0.9462\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2869, Accuracy: 0.9509, F1 Micro: 0.9696, F1 Macro: 0.9682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1958, Accuracy: 0.9554, F1 Micro: 0.9721, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1408, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1105, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0898, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9755\n",
      "Epoch 8/10, Train Loss: 0.0687, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9739\n",
      "Epoch 9/10, Train Loss: 0.0593, Accuracy: 0.9568, F1 Micro: 0.9727, F1 Macro: 0.9701\n",
      "Epoch 10/10, Train Loss: 0.0526, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9751\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9755\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.93      0.92       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5031, Accuracy: 0.9011, F1 Micro: 0.9011, F1 Macro: 0.8902\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2831, Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9406\n",
      "Epoch 3/10, Train Loss: 0.1913, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9313\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1923, Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9399\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1345, Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9406\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.132, Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9402\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0888, Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9406\n",
      "Epoch 8/10, Train Loss: 0.0914, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9358\n",
      "Epoch 9/10, Train Loss: 0.0628, Accuracy: 0.9125, F1 Micro: 0.9125, F1 Macro: 0.9046\n",
      "Epoch 10/10, Train Loss: 0.0955, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9321\n",
      "\n",
      "Sentiment analysis accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9406\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        85\n",
      "    positive       0.98      0.94      0.96       178\n",
      "\n",
      "    accuracy                           0.95       263\n",
      "   macro avg       0.93      0.95      0.94       263\n",
      "weighted avg       0.95      0.95      0.95       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9189\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.84      0.86       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.92      0.93      0.93       152\n",
      "    positive       0.78      0.77      0.78        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.84      0.82      0.83       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 124.54839491844177 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.01845639944076538\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.238961696624756 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5378, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4388, Accuracy: 0.8966, F1 Micro: 0.9378, F1 Macro: 0.9367\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2903, Accuracy: 0.9479, F1 Micro: 0.9677, F1 Macro: 0.9662\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1959, Accuracy: 0.9576, F1 Micro: 0.9737, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1458, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1054, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9749\n",
      "Epoch 7/10, Train Loss: 0.0882, Accuracy: 0.9583, F1 Micro: 0.9737, F1 Macro: 0.9718\n",
      "Epoch 8/10, Train Loss: 0.073, Accuracy: 0.9591, F1 Micro: 0.9741, F1 Macro: 0.9719\n",
      "Epoch 9/10, Train Loss: 0.0588, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9731\n",
      "Epoch 10/10, Train Loss: 0.0555, Accuracy: 0.9591, F1 Micro: 0.974, F1 Macro: 0.9715\n",
      "\n",
      "Aspect detection accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9749\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.93      0.93       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5734, Accuracy: 0.9027, F1 Micro: 0.9027, F1 Macro: 0.8934\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2719, Accuracy: 0.9183, F1 Micro: 0.9183, F1 Macro: 0.9074\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2133, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9275\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1714, Accuracy: 0.9416, F1 Micro: 0.9416, F1 Macro: 0.9347\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.106, Accuracy: 0.9533, F1 Micro: 0.9533, F1 Macro: 0.9479\n",
      "Epoch 6/10, Train Loss: 0.0776, Accuracy: 0.9494, F1 Micro: 0.9494, F1 Macro: 0.9437\n",
      "Epoch 7/10, Train Loss: 0.1057, Accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9385\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0802, Accuracy: 0.9533, F1 Micro: 0.9533, F1 Macro: 0.9476\n",
      "Epoch 9/10, Train Loss: 0.0652, Accuracy: 0.9222, F1 Micro: 0.9222, F1 Macro: 0.9099\n",
      "Epoch 10/10, Train Loss: 0.061, Accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9385\n",
      "\n",
      "Sentiment analysis accuracy: 0.9533, F1 Micro: 0.9533, F1 Macro: 0.9476\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93        84\n",
      "    positive       0.98      0.95      0.96       173\n",
      "\n",
      "    accuracy                           0.95       257\n",
      "   macro avg       0.94      0.95      0.95       257\n",
      "weighted avg       0.95      0.95      0.95       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9154\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.94      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.85      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.78      0.75      0.76        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.83      0.84      0.83       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.95      0.88      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.95      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 124.94541358947754 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.02011394500732422\n",
      "Samples above threshold: 17\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.7941901683807373 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5389, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4168, Accuracy: 0.9241, F1 Micro: 0.9539, F1 Macro: 0.9527\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2776, Accuracy: 0.9464, F1 Micro: 0.9667, F1 Macro: 0.9651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1822, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1323, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1004, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0834, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0635, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "Epoch 9/10, Train Loss: 0.0587, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9756\n",
      "Epoch 10/10, Train Loss: 0.0525, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9747\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.92      0.95      0.93       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5346, Accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.9028\n",
      "Epoch 2/10, Train Loss: 0.2475, Accuracy: 0.9119, F1 Micro: 0.9119, F1 Macro: 0.9042\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1778, Accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.9081\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1549, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9152\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1328, Accuracy: 0.9272, F1 Micro: 0.9272, F1 Macro: 0.9192\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0983, Accuracy: 0.9272, F1 Micro: 0.9272, F1 Macro: 0.9179\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0946, Accuracy: 0.931, F1 Micro: 0.931, F1 Macro: 0.9237\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0708, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9273\n",
      "Epoch 9/10, Train Loss: 0.0639, Accuracy: 0.9042, F1 Micro: 0.9042, F1 Macro: 0.8958\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0531, Accuracy: 0.9425, F1 Micro: 0.9425, F1 Macro: 0.9359\n",
      "\n",
      "Sentiment analysis accuracy: 0.9425, F1 Micro: 0.9425, F1 Macro: 0.9359\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.96      0.92        84\n",
      "    positive       0.98      0.93      0.96       177\n",
      "\n",
      "    accuracy                           0.94       261\n",
      "   macro avg       0.93      0.95      0.94       261\n",
      "weighted avg       0.95      0.94      0.94       261\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9171\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.93      0.79      0.85        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.86      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.82      0.77      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.85      0.82      0.84       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.91      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 134.88002038002014 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.012233495712280273\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.638913154602051 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5307, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4195, Accuracy: 0.9196, F1 Micro: 0.9508, F1 Macro: 0.949\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.272, Accuracy: 0.9524, F1 Micro: 0.9704, F1 Macro: 0.9687\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1801, Accuracy: 0.9531, F1 Micro: 0.9708, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1308, Accuracy: 0.9643, F1 Micro: 0.9777, F1 Macro: 0.9767\n",
      "Epoch 6/10, Train Loss: 0.1029, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9756\n",
      "Epoch 7/10, Train Loss: 0.0815, Accuracy: 0.9613, F1 Micro: 0.9755, F1 Macro: 0.9735\n",
      "Epoch 8/10, Train Loss: 0.069, Accuracy: 0.9606, F1 Micro: 0.975, F1 Macro: 0.9731\n",
      "Epoch 9/10, Train Loss: 0.0569, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9758\n",
      "Epoch 10/10, Train Loss: 0.0466, Accuracy: 0.9621, F1 Micro: 0.9759, F1 Macro: 0.974\n",
      "\n",
      "Aspect detection accuracy: 0.9643, F1 Micro: 0.9777, F1 Macro: 0.9767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.91      0.97      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      0.99      0.98       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5587, Accuracy: 0.8996, F1 Micro: 0.8996, F1 Macro: 0.891\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2656, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9339\n",
      "Epoch 3/10, Train Loss: 0.2, Accuracy: 0.9317, F1 Micro: 0.9317, F1 Macro: 0.9255\n",
      "Epoch 4/10, Train Loss: 0.1367, Accuracy: 0.9357, F1 Micro: 0.9357, F1 Macro: 0.9277\n",
      "Epoch 5/10, Train Loss: 0.1122, Accuracy: 0.9317, F1 Micro: 0.9317, F1 Macro: 0.9251\n",
      "Epoch 6/10, Train Loss: 0.1066, Accuracy: 0.9197, F1 Micro: 0.9197, F1 Macro: 0.9126\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0894, Accuracy: 0.9398, F1 Micro: 0.9398, F1 Macro: 0.9336\n",
      "Epoch 8/10, Train Loss: 0.0669, Accuracy: 0.9277, F1 Micro: 0.9277, F1 Macro: 0.9209\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0871, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9382\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0666, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9375\n",
      "\n",
      "Sentiment analysis accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        83\n",
      "    positive       0.97      0.95      0.96       166\n",
      "\n",
      "    accuracy                           0.94       249\n",
      "   macro avg       0.93      0.94      0.94       249\n",
      "weighted avg       0.94      0.94      0.94       249\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9094\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.98      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.94      0.99      0.97       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.82      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.91      0.97      0.94       152\n",
      "    positive       0.86      0.71      0.78        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.84      0.81      0.82       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.98       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 122.3206148147583 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.018509119749069214\n",
      "Samples above threshold: 12\n",
      "Acquired samples: 8\n",
      "Sampling duration: 2.469735860824585 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5389, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4149, Accuracy: 0.9122, F1 Micro: 0.9469, F1 Macro: 0.9454\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.264, Accuracy: 0.9539, F1 Micro: 0.9714, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1852, Accuracy: 0.9561, F1 Micro: 0.9725, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1283, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9736\n",
      "Epoch 6/10, Train Loss: 0.0992, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0847, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9755\n",
      "Epoch 8/10, Train Loss: 0.0649, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9741\n",
      "Epoch 9/10, Train Loss: 0.0567, Accuracy: 0.9591, F1 Micro: 0.9741, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0464, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9771\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5189, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.9007\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2786, Accuracy: 0.9425, F1 Micro: 0.9425, F1 Macro: 0.9366\n",
      "Epoch 3/10, Train Loss: 0.2019, Accuracy: 0.9272, F1 Micro: 0.9272, F1 Macro: 0.9208\n",
      "Epoch 4/10, Train Loss: 0.169, Accuracy: 0.9272, F1 Micro: 0.9272, F1 Macro: 0.9208\n",
      "Epoch 5/10, Train Loss: 0.1551, Accuracy: 0.9272, F1 Micro: 0.9272, F1 Macro: 0.9179\n",
      "Epoch 6/10, Train Loss: 0.1089, Accuracy: 0.9195, F1 Micro: 0.9195, F1 Macro: 0.9125\n",
      "Epoch 7/10, Train Loss: 0.0844, Accuracy: 0.9272, F1 Micro: 0.9272, F1 Macro: 0.9201\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0793, Accuracy: 0.9425, F1 Micro: 0.9425, F1 Macro: 0.9344\n",
      "Epoch 9/10, Train Loss: 0.0585, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9281\n",
      "Epoch 10/10, Train Loss: 0.06, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9261\n",
      "\n",
      "Sentiment analysis accuracy: 0.9425, F1 Micro: 0.9425, F1 Macro: 0.9344\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.90      0.91        86\n",
      "    positive       0.95      0.97      0.96       175\n",
      "\n",
      "    accuracy                           0.94       261\n",
      "   macro avg       0.94      0.93      0.93       261\n",
      "weighted avg       0.94      0.94      0.94       261\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.914\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.92      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.88      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.87      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.79      0.81      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.88      0.86      0.87       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.96      0.99      0.97       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.94      0.91      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 125.95010924339294 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.010201752185821533\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.3393540382385254 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5374, Accuracy: 0.7939, F1 Micro: 0.8845, F1 Macro: 0.8831\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4156, Accuracy: 0.9234, F1 Micro: 0.9532, F1 Macro: 0.9517\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2568, Accuracy: 0.9554, F1 Micro: 0.9723, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.18, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9714\n",
      "Epoch 5/10, Train Loss: 0.1292, Accuracy: 0.9568, F1 Micro: 0.9728, F1 Macro: 0.9708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0967, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0807, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9801\n",
      "Epoch 8/10, Train Loss: 0.0651, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9769\n",
      "Epoch 9/10, Train Loss: 0.0572, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9748\n",
      "Epoch 10/10, Train Loss: 0.0484, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9763\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9801\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.98      0.95       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5302, Accuracy: 0.8876, F1 Micro: 0.8876, F1 Macro: 0.8805\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2515, Accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.9155\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.183, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9306\n",
      "Epoch 4/10, Train Loss: 0.1521, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.9228\n",
      "Epoch 5/10, Train Loss: 0.1353, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.9228\n",
      "Epoch 6/10, Train Loss: 0.1272, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.9232\n",
      "Epoch 7/10, Train Loss: 0.1115, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9273\n",
      "Epoch 8/10, Train Loss: 0.0636, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9273\n",
      "Epoch 9/10, Train Loss: 0.0805, Accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.9169\n",
      "Epoch 10/10, Train Loss: 0.063, Accuracy: 0.9109, F1 Micro: 0.9109, F1 Macro: 0.9016\n",
      "\n",
      "Sentiment analysis accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9306\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.94      0.91        84\n",
      "    positive       0.97      0.94      0.95       174\n",
      "\n",
      "    accuracy                           0.94       258\n",
      "   macro avg       0.92      0.94      0.93       258\n",
      "weighted avg       0.94      0.94      0.94       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.917\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.90      0.82      0.86        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.87      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.93      0.98      0.96       152\n",
      "    positive       0.91      0.77      0.83        52\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.86      0.83      0.85       216\n",
      "weighted avg       0.92      0.92      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.92      0.83      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.90      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 125.46161794662476 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.025575315952301024\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.1714303493499756 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5262, Accuracy: 0.7999, F1 Micro: 0.8875, F1 Macro: 0.8861\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3917, Accuracy: 0.9315, F1 Micro: 0.9579, F1 Macro: 0.9563\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2484, Accuracy: 0.9568, F1 Micro: 0.9732, F1 Macro: 0.9722\n",
      "Epoch 4/10, Train Loss: 0.1679, Accuracy: 0.9546, F1 Micro: 0.9714, F1 Macro: 0.9692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1235, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0949, Accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9778\n",
      "Epoch 7/10, Train Loss: 0.0751, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9725\n",
      "Epoch 8/10, Train Loss: 0.061, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0491, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.979\n",
      "Epoch 10/10, Train Loss: 0.047, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9785\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.979\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.93      0.94      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4528, Accuracy: 0.9219, F1 Micro: 0.9219, F1 Macro: 0.9116\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2439, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9244\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1776, Accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9379\n",
      "Epoch 4/10, Train Loss: 0.1419, Accuracy: 0.9257, F1 Micro: 0.9257, F1 Macro: 0.9151\n",
      "Epoch 5/10, Train Loss: 0.1448, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9257\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1232, Accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9372\n",
      "Epoch 7/10, Train Loss: 0.0951, Accuracy: 0.9219, F1 Micro: 0.9219, F1 Macro: 0.9121\n",
      "Epoch 8/10, Train Loss: 0.0585, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.92\n",
      "Epoch 9/10, Train Loss: 0.0689, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9257\n",
      "Epoch 10/10, Train Loss: 0.0706, Accuracy: 0.9257, F1 Micro: 0.9257, F1 Macro: 0.9182\n",
      "\n",
      "Sentiment analysis accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9372\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.94      0.92        87\n",
      "    positive       0.97      0.95      0.96       182\n",
      "\n",
      "    accuracy                           0.94       269\n",
      "   macro avg       0.93      0.94      0.94       269\n",
      "weighted avg       0.95      0.94      0.94       269\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9252\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.96      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.90      0.82      0.86        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.93      0.94      0.94       152\n",
      "    positive       0.82      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.84      0.85      0.85       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 131.2738835811615 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.011265236139297486\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.9573485851287842 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5331, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4048, Accuracy: 0.9129, F1 Micro: 0.9473, F1 Macro: 0.946\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2534, Accuracy: 0.9561, F1 Micro: 0.9727, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1781, Accuracy: 0.9576, F1 Micro: 0.9736, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1254, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0988, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9786\n",
      "Epoch 7/10, Train Loss: 0.0766, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9781\n",
      "Epoch 8/10, Train Loss: 0.0635, Accuracy: 0.9628, F1 Micro: 0.9764, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0534, Accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9793\n",
      "Epoch 10/10, Train Loss: 0.0469, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9774\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9807, F1 Macro: 0.9793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.99      0.98       175\n",
      "      others       0.94      0.93      0.93       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.484, Accuracy: 0.9259, F1 Micro: 0.9259, F1 Macro: 0.9167\n",
      "Epoch 2/10, Train Loss: 0.2543, Accuracy: 0.9222, F1 Micro: 0.9222, F1 Macro: 0.9145\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1692, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.925\n",
      "Epoch 4/10, Train Loss: 0.1395, Accuracy: 0.9185, F1 Micro: 0.9185, F1 Macro: 0.9098\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1347, Accuracy: 0.9481, F1 Micro: 0.9481, F1 Macro: 0.9413\n",
      "Epoch 6/10, Train Loss: 0.1122, Accuracy: 0.9296, F1 Micro: 0.9296, F1 Macro: 0.9219\n",
      "Epoch 7/10, Train Loss: 0.1027, Accuracy: 0.9185, F1 Micro: 0.9185, F1 Macro: 0.9098\n",
      "Epoch 8/10, Train Loss: 0.0843, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.929\n",
      "Epoch 9/10, Train Loss: 0.064, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9258\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.085, Accuracy: 0.9519, F1 Micro: 0.9519, F1 Macro: 0.945\n",
      "\n",
      "Sentiment analysis accuracy: 0.9519, F1 Micro: 0.9519, F1 Macro: 0.945\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.94      0.93        86\n",
      "    positive       0.97      0.96      0.96       184\n",
      "\n",
      "    accuracy                           0.95       270\n",
      "   macro avg       0.94      0.95      0.95       270\n",
      "weighted avg       0.95      0.95      0.95       270\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9614, F1 Micro: 0.9614, F1 Macro: 0.9283\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.99      0.98       167\n",
      "    positive       0.90      0.82      0.86        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.89      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.94      0.93      0.93       152\n",
      "    positive       0.78      0.83      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.88      0.86      0.87       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.92      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 133.9060673713684 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.007991218566894531\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.7623324394226074 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5228, Accuracy: 0.808, F1 Micro: 0.8914, F1 Macro: 0.8903\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3877, Accuracy: 0.9286, F1 Micro: 0.9557, F1 Macro: 0.9536\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2398, Accuracy: 0.9561, F1 Micro: 0.9726, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1727, Accuracy: 0.9621, F1 Micro: 0.9764, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.121, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0944, Accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9787\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0797, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9784\n",
      "Epoch 8/10, Train Loss: 0.0643, Accuracy: 0.9628, F1 Micro: 0.9764, F1 Macro: 0.9744\n",
      "Epoch 9/10, Train Loss: 0.0538, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9779\n",
      "Epoch 10/10, Train Loss: 0.0483, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9757\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9784\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       1.00      0.99      1.00       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4835, Accuracy: 0.9139, F1 Micro: 0.9139, F1 Macro: 0.9058\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2544, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9282\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.151, Accuracy: 0.9401, F1 Micro: 0.9401, F1 Macro: 0.9322\n",
      "Epoch 4/10, Train Loss: 0.128, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.914\n",
      "Epoch 5/10, Train Loss: 0.1295, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9258\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1196, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9373\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0797, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9373\n",
      "Epoch 8/10, Train Loss: 0.0734, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9264\n",
      "Epoch 9/10, Train Loss: 0.0774, Accuracy: 0.9288, F1 Micro: 0.9288, F1 Macro: 0.9197\n",
      "Epoch 10/10, Train Loss: 0.0637, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.925\n",
      "\n",
      "Sentiment analysis accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9373\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.97      0.92        86\n",
      "    positive       0.98      0.93      0.96       181\n",
      "\n",
      "    accuracy                           0.94       267\n",
      "   macro avg       0.93      0.95      0.94       267\n",
      "weighted avg       0.95      0.94      0.94       267\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.9201\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       1.00      0.99      1.00       181\n",
      "    positive       0.96      1.00      0.98        24\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.99      1.00      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.88      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.93      0.94      0.93       152\n",
      "    positive       0.80      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.85      0.83      0.84       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.92      0.86        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 137.15407848358154 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.007982844114303589\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 8\n",
      "Sampling duration: 1.4748635292053223 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5175, Accuracy: 0.8013, F1 Micro: 0.8882, F1 Macro: 0.8869\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3823, Accuracy: 0.9219, F1 Micro: 0.9516, F1 Macro: 0.9489\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2489, Accuracy: 0.9568, F1 Micro: 0.9732, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1656, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1275, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0949, Accuracy: 0.965, F1 Micro: 0.9778, F1 Macro: 0.9762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0737, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9782\n",
      "Epoch 8/10, Train Loss: 0.0605, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0513, Accuracy: 0.9725, F1 Micro: 0.9827, F1 Macro: 0.9818\n",
      "Epoch 10/10, Train Loss: 0.0478, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9789\n",
      "\n",
      "Aspect detection accuracy: 0.9725, F1 Micro: 0.9827, F1 Macro: 0.9818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.93      0.97      0.95       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.98      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.98      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4675, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.921\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2165, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9289\n",
      "Epoch 3/10, Train Loss: 0.1544, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.91\n",
      "Epoch 4/10, Train Loss: 0.1198, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9233\n",
      "Epoch 5/10, Train Loss: 0.1005, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9201\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0882, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9285\n",
      "Epoch 7/10, Train Loss: 0.0764, Accuracy: 0.9242, F1 Micro: 0.9242, F1 Macro: 0.9174\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0591, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9282\n",
      "Epoch 9/10, Train Loss: 0.0568, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9253\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0353, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9322\n",
      "\n",
      "Sentiment analysis accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9322\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.93      0.91        87\n",
      "    positive       0.97      0.94      0.95       177\n",
      "\n",
      "    accuracy                           0.94       264\n",
      "   macro avg       0.93      0.94      0.93       264\n",
      "weighted avg       0.94      0.94      0.94       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9622, F1 Micro: 0.9622, F1 Macro: 0.9252\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.79      0.82      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.85      0.87       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.94      0.97      0.95       152\n",
      "    positive       0.88      0.81      0.84        52\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.91      0.87      0.89       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.99      0.99       152\n",
      "    positive       1.00      0.80      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.93      0.92       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.91      0.93      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 140.54081416130066 s\n",
      "Total runtime: 2922.262064218521 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[0], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc16bee",
   "metadata": {
    "papermill": {
     "duration": 0.209957,
     "end_time": "2025-03-24T16:09:11.213929",
     "exception": false,
     "start_time": "2025-03-24T16:09:11.003972",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e18364b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-24T16:09:11.645057Z",
     "iopub.status.busy": "2025-03-24T16:09:11.644695Z",
     "iopub.status.idle": "2025-03-24T16:58:54.557547Z",
     "shell.execute_reply": "2025-03-24T16:58:54.556239Z"
    },
    "papermill": {
     "duration": 2983.097758,
     "end_time": "2025-03-24T16:58:54.559434",
     "exception": false,
     "start_time": "2025-03-24T16:09:11.461676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 2\n",
      "Random seed: 81\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.647, Accuracy: 0.7054, F1 Micro: 0.8127, F1 Macro: 0.7262\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5731, Accuracy: 0.7374, F1 Micro: 0.8408, F1 Macro: 0.7949\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5493, Accuracy: 0.7917, F1 Micro: 0.8824, F1 Macro: 0.8802\n",
      "Epoch 4/10, Train Loss: 0.5049, Accuracy: 0.7894, F1 Micro: 0.8822, F1 Macro: 0.8807\n",
      "Epoch 5/10, Train Loss: 0.4781, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 6/10, Train Loss: 0.4364, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4061, Accuracy: 0.7902, F1 Micro: 0.8826, F1 Macro: 0.8811\n",
      "Epoch 8/10, Train Loss: 0.4421, Accuracy: 0.7902, F1 Micro: 0.8825, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.4208, Accuracy: 0.7939, F1 Micro: 0.8842, F1 Macro: 0.8826\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3864, Accuracy: 0.8036, F1 Micro: 0.8886, F1 Macro: 0.8869\n",
      "\n",
      "Aspect detection accuracy: 0.8036, F1 Micro: 0.8886, F1 Macro: 0.8869\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.79      1.00      0.88       175\n",
      "      others       0.78      0.95      0.86       158\n",
      "        part       0.71      1.00      0.83       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.80      0.99      0.89      1061\n",
      "   macro avg       0.80      0.99      0.89      1061\n",
      "weighted avg       0.81      0.99      0.89      1061\n",
      " samples avg       0.81      0.99      0.89      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6351, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5577, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5004, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4905, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4593, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4341, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4188, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2323, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2613, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2353, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "\n",
      "Sentiment analysis accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.4769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         3\n",
      "    positive       0.91      1.00      0.95        31\n",
      "\n",
      "    accuracy                           0.91        34\n",
      "   macro avg       0.46      0.50      0.48        34\n",
      "weighted avg       0.83      0.91      0.87        34\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.8009, F1 Micro: 0.8009, F1 Macro: 0.3313\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.78      1.00      0.88       167\n",
      "    positive       1.00      0.06      0.11        33\n",
      "\n",
      "    accuracy                           0.78       216\n",
      "   macro avg       0.59      0.35      0.33       216\n",
      "weighted avg       0.76      0.78      0.70       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.78      0.95      0.85       152\n",
      "    positive       0.65      0.38      0.48        52\n",
      "\n",
      "    accuracy                           0.76       216\n",
      "   macro avg       0.47      0.44      0.45       216\n",
      "weighted avg       0.70      0.76      0.72       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        23\n",
      "     neutral       0.71      1.00      0.83       152\n",
      "    positive       1.00      0.02      0.05        41\n",
      "\n",
      "    accuracy                           0.71       216\n",
      "   macro avg       0.57      0.34      0.29       216\n",
      "weighted avg       0.69      0.71      0.59       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 66.52702116966248 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.9374258995056153\n",
      "Samples above threshold: 81\n",
      "Acquired samples: 81\n",
      "Sampling duration: 4.3185875415802 seconds\n",
      "New train size: 135\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.603, Accuracy: 0.7403, F1 Micro: 0.8433, F1 Macro: 0.8018\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4979, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4668, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4383, Accuracy: 0.8006, F1 Micro: 0.8876, F1 Macro: 0.8861\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3929, Accuracy: 0.8051, F1 Micro: 0.8892, F1 Macro: 0.8877\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3576, Accuracy: 0.8281, F1 Micro: 0.9007, F1 Macro: 0.899\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3356, Accuracy: 0.869, F1 Micro: 0.9222, F1 Macro: 0.9208\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2741, Accuracy: 0.8869, F1 Micro: 0.9312, F1 Macro: 0.929\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2465, Accuracy: 0.8966, F1 Micro: 0.9365, F1 Macro: 0.9344\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2031, Accuracy: 0.9033, F1 Micro: 0.9407, F1 Macro: 0.9392\n",
      "\n",
      "Aspect detection accuracy: 0.9033, F1 Micro: 0.9407, F1 Macro: 0.9392\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.94      1.00      0.97       187\n",
      "     machine       0.94      0.99      0.97       175\n",
      "      others       0.90      0.87      0.88       158\n",
      "        part       0.89      0.97      0.93       158\n",
      "       price       0.95      0.97      0.96       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.91      0.97      0.94      1061\n",
      "   macro avg       0.91      0.97      0.94      1061\n",
      "weighted avg       0.91      0.97      0.94      1061\n",
      " samples avg       0.92      0.97      0.94      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5659, Accuracy: 0.715, F1 Micro: 0.715, F1 Macro: 0.4328\n",
      "Epoch 2/10, Train Loss: 0.5337, Accuracy: 0.7101, F1 Micro: 0.7101, F1 Macro: 0.4153\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.468, Accuracy: 0.744, F1 Micro: 0.744, F1 Macro: 0.6432\n",
      "Epoch 4/10, Train Loss: 0.3475, Accuracy: 0.7391, F1 Micro: 0.7391, F1 Macro: 0.6832\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.235, Accuracy: 0.7681, F1 Micro: 0.7681, F1 Macro: 0.7476\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1642, Accuracy: 0.8213, F1 Micro: 0.8213, F1 Macro: 0.7967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1433, Accuracy: 0.8261, F1 Micro: 0.8261, F1 Macro: 0.8014\n",
      "Epoch 8/10, Train Loss: 0.1269, Accuracy: 0.8019, F1 Micro: 0.8019, F1 Macro: 0.7824\n",
      "Epoch 9/10, Train Loss: 0.1273, Accuracy: 0.8213, F1 Micro: 0.8213, F1 Macro: 0.7934\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0852, Accuracy: 0.8261, F1 Micro: 0.8261, F1 Macro: 0.7821\n",
      "\n",
      "Sentiment analysis accuracy: 0.8261, F1 Micro: 0.8261, F1 Macro: 0.7821\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      0.65      0.68        60\n",
      "    positive       0.86      0.90      0.88       147\n",
      "\n",
      "    accuracy                           0.83       207\n",
      "   macro avg       0.79      0.77      0.78       207\n",
      "weighted avg       0.82      0.83      0.82       207\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 135: Accuracy: 0.8812, F1 Micro: 0.8812, F1 Macro: 0.6692\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.64      0.74        11\n",
      "     neutral       0.94      1.00      0.97       181\n",
      "    positive       0.88      0.58      0.70        24\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.74      0.80       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.62      0.71        16\n",
      "     neutral       0.94      0.99      0.97       167\n",
      "    positive       0.81      0.67      0.73        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.86      0.76      0.80       216\n",
      "weighted avg       0.91      0.92      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.33      0.42      0.37        12\n",
      "     neutral       0.90      0.88      0.89       152\n",
      "    positive       0.64      0.65      0.65        52\n",
      "\n",
      "    accuracy                           0.80       216\n",
      "   macro avg       0.62      0.65      0.63       216\n",
      "weighted avg       0.81      0.80      0.80       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.52      0.65        23\n",
      "     neutral       0.89      0.97      0.93       152\n",
      "    positive       0.80      0.68      0.74        41\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.85      0.73      0.77       216\n",
      "weighted avg       0.87      0.87      0.86       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.38      0.56        13\n",
      "     neutral       0.96      0.97      0.97       186\n",
      "    positive       0.50      0.65      0.56        17\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.82      0.67      0.69       216\n",
      "weighted avg       0.92      0.91      0.91       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 79.19859075546265 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.9436831831932068\n",
      "Samples above threshold: 73\n",
      "Acquired samples: 73\n",
      "Sampling duration: 6.1596996784210205 seconds\n",
      "New train size: 208\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5904, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4903, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4862, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4577, Accuracy: 0.7902, F1 Micro: 0.8826, F1 Macro: 0.8811\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4023, Accuracy: 0.8326, F1 Micro: 0.9038, F1 Macro: 0.9024\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3388, Accuracy: 0.8891, F1 Micro: 0.9332, F1 Macro: 0.9313\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2835, Accuracy: 0.9182, F1 Micro: 0.9497, F1 Macro: 0.9474\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2241, Accuracy: 0.9263, F1 Micro: 0.9544, F1 Macro: 0.9522\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2027, Accuracy: 0.9308, F1 Micro: 0.957, F1 Macro: 0.9551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1669, Accuracy: 0.939, F1 Micro: 0.9621, F1 Macro: 0.9603\n",
      "\n",
      "Aspect detection accuracy: 0.939, F1 Micro: 0.9621, F1 Macro: 0.9603\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.97      1.00      0.99       187\n",
      "     machine       0.93      0.98      0.96       175\n",
      "      others       0.88      0.92      0.90       158\n",
      "        part       0.93      0.98      0.96       158\n",
      "       price       0.96      1.00      0.98       192\n",
      "     service       0.96      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.94      0.98      0.96      1061\n",
      "   macro avg       0.94      0.98      0.96      1061\n",
      "weighted avg       0.94      0.98      0.96      1061\n",
      " samples avg       0.94      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6228, Accuracy: 0.671, F1 Micro: 0.671, F1 Macro: 0.4139\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5747, Accuracy: 0.7186, F1 Micro: 0.7186, F1 Macro: 0.5693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4497, Accuracy: 0.8485, F1 Micro: 0.8485, F1 Macro: 0.8312\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2688, Accuracy: 0.8961, F1 Micro: 0.8961, F1 Macro: 0.8846\n",
      "Epoch 5/10, Train Loss: 0.1804, Accuracy: 0.8874, F1 Micro: 0.8874, F1 Macro: 0.8801\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1473, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8952\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1088, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8999\n",
      "Epoch 8/10, Train Loss: 0.0767, Accuracy: 0.9004, F1 Micro: 0.9004, F1 Macro: 0.8927\n",
      "Epoch 9/10, Train Loss: 0.0821, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.896\n",
      "Epoch 10/10, Train Loss: 0.0965, Accuracy: 0.9004, F1 Micro: 0.9004, F1 Macro: 0.8869\n",
      "\n",
      "Sentiment analysis accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8999\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.91      0.87        77\n",
      "    positive       0.95      0.91      0.93       154\n",
      "\n",
      "    accuracy                           0.91       231\n",
      "   macro avg       0.89      0.91      0.90       231\n",
      "weighted avg       0.91      0.91      0.91       231\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 208: Accuracy: 0.9275, F1 Micro: 0.9275, F1 Macro: 0.8516\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       1.00      0.83      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.75      0.77        16\n",
      "     neutral       0.93      0.98      0.96       167\n",
      "    positive       0.88      0.67      0.76        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.87      0.80      0.83       216\n",
      "weighted avg       0.91      0.92      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.75      0.67        12\n",
      "     neutral       0.89      0.92      0.90       152\n",
      "    positive       0.74      0.62      0.67        52\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.74      0.76      0.75       216\n",
      "weighted avg       0.84      0.84      0.83       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        23\n",
      "     neutral       0.93      0.98      0.96       152\n",
      "    positive       0.91      0.73      0.81        41\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.89      0.85      0.86       216\n",
      "weighted avg       0.92      0.92      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.96      1.00      0.98       186\n",
      "    positive       0.92      0.65      0.76        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.96      0.81      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.71      0.83        14\n",
      "     neutral       0.96      1.00      0.98       185\n",
      "    positive       0.86      0.71      0.77        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.81      0.86       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Total train time: 84.68453311920166 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.16653379797935486\n",
      "Samples above threshold: 66\n",
      "Acquired samples: 66\n",
      "Sampling duration: 6.094289779663086 seconds\n",
      "New train size: 274\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5698, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5056, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 3/10, Train Loss: 0.4603, Accuracy: 0.7887, F1 Micro: 0.8819, F1 Macro: 0.8803\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4356, Accuracy: 0.8304, F1 Micro: 0.9026, F1 Macro: 0.9012\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3507, Accuracy: 0.9115, F1 Micro: 0.9458, F1 Macro: 0.9437\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2871, Accuracy: 0.9204, F1 Micro: 0.9505, F1 Macro: 0.9485\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2449, Accuracy: 0.939, F1 Micro: 0.962, F1 Macro: 0.96\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1823, Accuracy: 0.9412, F1 Micro: 0.9632, F1 Macro: 0.9613\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1484, Accuracy: 0.9487, F1 Micro: 0.9678, F1 Macro: 0.9662\n",
      "Epoch 10/10, Train Loss: 0.1229, Accuracy: 0.9479, F1 Micro: 0.9674, F1 Macro: 0.9654\n",
      "\n",
      "Aspect detection accuracy: 0.9487, F1 Micro: 0.9678, F1 Macro: 0.9662\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.97      0.96       175\n",
      "      others       0.90      0.92      0.91       158\n",
      "        part       0.94      0.99      0.97       158\n",
      "       price       0.98      0.98      0.98       192\n",
      "     service       0.98      0.99      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6009, Accuracy: 0.6733, F1 Micro: 0.6733, F1 Macro: 0.4024\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4601, Accuracy: 0.8406, F1 Micro: 0.8406, F1 Macro: 0.8211\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3081, Accuracy: 0.8924, F1 Micro: 0.8924, F1 Macro: 0.8822\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2038, Accuracy: 0.9004, F1 Micro: 0.9004, F1 Macro: 0.8915\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1162, Accuracy: 0.9044, F1 Micro: 0.9044, F1 Macro: 0.8926\n",
      "Epoch 6/10, Train Loss: 0.0741, Accuracy: 0.8964, F1 Micro: 0.8964, F1 Macro: 0.8807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1533, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.898\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.084, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.9079\n",
      "Epoch 9/10, Train Loss: 0.0381, Accuracy: 0.9124, F1 Micro: 0.9124, F1 Macro: 0.8997\n",
      "Epoch 10/10, Train Loss: 0.0523, Accuracy: 0.9124, F1 Micro: 0.9124, F1 Macro: 0.9052\n",
      "\n",
      "Sentiment analysis accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.9079\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.94      0.88        82\n",
      "    positive       0.97      0.91      0.94       169\n",
      "\n",
      "    accuracy                           0.92       251\n",
      "   macro avg       0.90      0.92      0.91       251\n",
      "weighted avg       0.92      0.92      0.92       251\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 274: Accuracy: 0.9383, F1 Micro: 0.9383, F1 Macro: 0.8767\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.88      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        16\n",
      "     neutral       0.95      0.97      0.96       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.87      0.85      0.86       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.56      0.75      0.64        12\n",
      "     neutral       0.90      0.92      0.91       152\n",
      "    positive       0.78      0.67      0.72        52\n",
      "\n",
      "    accuracy                           0.85       216\n",
      "   macro avg       0.75      0.78      0.76       216\n",
      "weighted avg       0.85      0.85      0.85       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.94      0.99      0.96       152\n",
      "    positive       1.00      0.71      0.83        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.89      0.90       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.98      0.98      0.98       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.98      0.99      0.99       185\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.90      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 88.81381154060364 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.09580594301223755\n",
      "Samples above threshold: 59\n",
      "Acquired samples: 59\n",
      "Sampling duration: 6.116454124450684 seconds\n",
      "New train size: 333\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5551, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4763, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4467, Accuracy: 0.811, F1 Micro: 0.893, F1 Macro: 0.8916\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3654, Accuracy: 0.9092, F1 Micro: 0.9445, F1 Macro: 0.9422\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3003, Accuracy: 0.9323, F1 Micro: 0.958, F1 Macro: 0.9563\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2234, Accuracy: 0.9449, F1 Micro: 0.9655, F1 Macro: 0.9637\n",
      "Epoch 7/10, Train Loss: 0.1814, Accuracy: 0.9412, F1 Micro: 0.963, F1 Macro: 0.96\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1431, Accuracy: 0.9524, F1 Micro: 0.9701, F1 Macro: 0.9682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1117, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9716\n",
      "Epoch 10/10, Train Loss: 0.098, Accuracy: 0.9554, F1 Micro: 0.972, F1 Macro: 0.9705\n",
      "\n",
      "Aspect detection accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9716\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.90      0.94      0.92       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.98      0.98      0.98       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6131, Accuracy: 0.7052, F1 Micro: 0.7052, F1 Macro: 0.5448\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4505, Accuracy: 0.8924, F1 Micro: 0.8924, F1 Macro: 0.8789\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3009, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9237\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1838, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9237\n",
      "Epoch 5/10, Train Loss: 0.137, Accuracy: 0.9243, F1 Micro: 0.9243, F1 Macro: 0.9171\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1096, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9269\n",
      "Epoch 7/10, Train Loss: 0.1179, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.9109\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1002, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9269\n",
      "Epoch 9/10, Train Loss: 0.0703, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.9208\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0828, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9233\n",
      "\n",
      "Sentiment analysis accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9233\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.86      0.90        86\n",
      "    positive       0.93      0.97      0.95       165\n",
      "\n",
      "    accuracy                           0.93       251\n",
      "   macro avg       0.93      0.92      0.92       251\n",
      "weighted avg       0.93      0.93      0.93       251\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 333: Accuracy: 0.9452, F1 Micro: 0.9452, F1 Macro: 0.8885\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.88      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.85      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.67      0.80        12\n",
      "     neutral       0.90      0.94      0.92       152\n",
      "    positive       0.78      0.73      0.75        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.89      0.78      0.82       216\n",
      "weighted avg       0.88      0.88      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.96      0.99      0.97       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.94      0.91      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.98      0.98       186\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.88      0.88      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.89      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 95.52547264099121 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.06994962692260742\n",
      "Samples above threshold: 54\n",
      "Acquired samples: 54\n",
      "Sampling duration: 5.493349313735962 seconds\n",
      "New train size: 387\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5488, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4817, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4074, Accuracy: 0.8906, F1 Micro: 0.9345, F1 Macro: 0.9328\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3113, Accuracy: 0.9323, F1 Micro: 0.9583, F1 Macro: 0.9563\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2411, Accuracy: 0.9472, F1 Micro: 0.967, F1 Macro: 0.9654\n",
      "Epoch 6/10, Train Loss: 0.1836, Accuracy: 0.9449, F1 Micro: 0.9653, F1 Macro: 0.9627\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1432, Accuracy: 0.9494, F1 Micro: 0.9682, F1 Macro: 0.9658\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1193, Accuracy: 0.9516, F1 Micro: 0.9694, F1 Macro: 0.9669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0975, Accuracy: 0.9568, F1 Micro: 0.9728, F1 Macro: 0.9707\n",
      "Epoch 10/10, Train Loss: 0.0808, Accuracy: 0.9561, F1 Micro: 0.9724, F1 Macro: 0.9705\n",
      "\n",
      "Aspect detection accuracy: 0.9568, F1 Micro: 0.9728, F1 Macro: 0.9707\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.93      0.89      0.91       158\n",
      "        part       0.96      0.99      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6172, Accuracy: 0.7917, F1 Micro: 0.7917, F1 Macro: 0.7607\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4709, Accuracy: 0.8939, F1 Micro: 0.8939, F1 Macro: 0.8844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2571, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.9073\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2277, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9193\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1973, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9269\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1278, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9322\n",
      "Epoch 7/10, Train Loss: 0.1031, Accuracy: 0.9205, F1 Micro: 0.9205, F1 Macro: 0.9139\n",
      "Epoch 8/10, Train Loss: 0.0539, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9249\n",
      "Epoch 9/10, Train Loss: 0.0623, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9178\n",
      "Epoch 10/10, Train Loss: 0.0735, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.921\n",
      "\n",
      "Sentiment analysis accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9322\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.93      0.91        87\n",
      "    positive       0.97      0.94      0.95       177\n",
      "\n",
      "    accuracy                           0.94       264\n",
      "   macro avg       0.93      0.94      0.93       264\n",
      "weighted avg       0.94      0.94      0.94       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 387: Accuracy: 0.9483, F1 Micro: 0.9483, F1 Macro: 0.9055\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.86      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.93      0.89      0.91       152\n",
      "    positive       0.72      0.83      0.77        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.85      0.85      0.85       216\n",
      "weighted avg       0.88      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.96      0.99      0.97       152\n",
      "    positive       0.94      0.78      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.91      0.91       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.93      0.90        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 100.1314263343811 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.04017419815063477\n",
      "Samples above threshold: 48\n",
      "Acquired samples: 48\n",
      "Sampling duration: 5.195486545562744 seconds\n",
      "New train size: 435\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5551, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4773, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4015, Accuracy: 0.8943, F1 Micro: 0.9361, F1 Macro: 0.9349\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3095, Accuracy: 0.933, F1 Micro: 0.9584, F1 Macro: 0.9563\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2346, Accuracy: 0.9464, F1 Micro: 0.9667, F1 Macro: 0.9653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1799, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9736\n",
      "Epoch 7/10, Train Loss: 0.1399, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9717\n",
      "Epoch 8/10, Train Loss: 0.1139, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9709\n",
      "Epoch 9/10, Train Loss: 0.091, Accuracy: 0.9524, F1 Micro: 0.97, F1 Macro: 0.9676\n",
      "Epoch 10/10, Train Loss: 0.08, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9718\n",
      "\n",
      "Aspect detection accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9736\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.89      0.96      0.92       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.97      1061\n",
      "   macro avg       0.96      0.99      0.97      1061\n",
      "weighted avg       0.96      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6573, Accuracy: 0.7805, F1 Micro: 0.7805, F1 Macro: 0.7745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4707, Accuracy: 0.9106, F1 Micro: 0.9106, F1 Macro: 0.9041\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2879, Accuracy: 0.9512, F1 Micro: 0.9512, F1 Macro: 0.9458\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.254, Accuracy: 0.9553, F1 Micro: 0.9553, F1 Macro: 0.9512\n",
      "Epoch 5/10, Train Loss: 0.1947, Accuracy: 0.9512, F1 Micro: 0.9512, F1 Macro: 0.9466\n",
      "Epoch 6/10, Train Loss: 0.1323, Accuracy: 0.939, F1 Micro: 0.939, F1 Macro: 0.9341\n",
      "Epoch 7/10, Train Loss: 0.1167, Accuracy: 0.9431, F1 Micro: 0.9431, F1 Macro: 0.9364\n",
      "Epoch 8/10, Train Loss: 0.0922, Accuracy: 0.9512, F1 Micro: 0.9512, F1 Macro: 0.9469\n",
      "Epoch 9/10, Train Loss: 0.0853, Accuracy: 0.939, F1 Micro: 0.939, F1 Macro: 0.9341\n",
      "Epoch 10/10, Train Loss: 0.069, Accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.9424\n",
      "\n",
      "Sentiment analysis accuracy: 0.9553, F1 Micro: 0.9553, F1 Macro: 0.9512\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94        84\n",
      "    positive       0.99      0.94      0.97       162\n",
      "\n",
      "    accuracy                           0.96       246\n",
      "   macro avg       0.94      0.96      0.95       246\n",
      "weighted avg       0.96      0.96      0.96       246\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 435: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9187\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.94      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.87      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.89      0.96      0.92       152\n",
      "    positive       0.86      0.69      0.77        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.88      0.80      0.84       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.96      0.99      0.98       152\n",
      "    positive       1.00      0.76      0.86        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 93.89472699165344 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0654220700263977\n",
      "Samples above threshold: 43\n",
      "Acquired samples: 43\n",
      "Sampling duration: 4.742575407028198 seconds\n",
      "New train size: 478\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5448, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4565, Accuracy: 0.8006, F1 Micro: 0.8879, F1 Macro: 0.8864\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.385, Accuracy: 0.9048, F1 Micro: 0.942, F1 Macro: 0.9406\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2813, Accuracy: 0.9382, F1 Micro: 0.962, F1 Macro: 0.9607\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2031, Accuracy: 0.9516, F1 Micro: 0.9699, F1 Macro: 0.9685\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1748, Accuracy: 0.9561, F1 Micro: 0.9725, F1 Macro: 0.9708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1277, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9744\n",
      "Epoch 8/10, Train Loss: 0.0996, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9709\n",
      "Epoch 9/10, Train Loss: 0.0925, Accuracy: 0.9591, F1 Micro: 0.9741, F1 Macro: 0.9719\n",
      "Epoch 10/10, Train Loss: 0.0712, Accuracy: 0.9554, F1 Micro: 0.9719, F1 Macro: 0.9702\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9744\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.94      0.99      0.97       175\n",
      "      others       0.90      0.96      0.93       158\n",
      "        part       0.95      0.99      0.97       158\n",
      "       price       0.99      0.98      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.97      1061\n",
      "weighted avg       0.96      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6537, Accuracy: 0.7952, F1 Micro: 0.7952, F1 Macro: 0.7834\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4146, Accuracy: 0.9076, F1 Micro: 0.9076, F1 Macro: 0.9007\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2276, Accuracy: 0.9478, F1 Micro: 0.9478, F1 Macro: 0.943\n",
      "Epoch 4/10, Train Loss: 0.1837, Accuracy: 0.9317, F1 Micro: 0.9317, F1 Macro: 0.9251\n",
      "Epoch 5/10, Train Loss: 0.1584, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9388\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1202, Accuracy: 0.9518, F1 Micro: 0.9518, F1 Macro: 0.9458\n",
      "Epoch 7/10, Train Loss: 0.0832, Accuracy: 0.9197, F1 Micro: 0.9197, F1 Macro: 0.9134\n",
      "Epoch 8/10, Train Loss: 0.0885, Accuracy: 0.9277, F1 Micro: 0.9277, F1 Macro: 0.9221\n",
      "Epoch 9/10, Train Loss: 0.0899, Accuracy: 0.9277, F1 Micro: 0.9277, F1 Macro: 0.9217\n",
      "Epoch 10/10, Train Loss: 0.0528, Accuracy: 0.9478, F1 Micro: 0.9478, F1 Macro: 0.9411\n",
      "\n",
      "Sentiment analysis accuracy: 0.9518, F1 Micro: 0.9518, F1 Macro: 0.9458\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.91      0.93        85\n",
      "    positive       0.95      0.98      0.96       164\n",
      "\n",
      "    accuracy                           0.95       249\n",
      "   macro avg       0.95      0.94      0.95       249\n",
      "weighted avg       0.95      0.95      0.95       249\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 478: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9155\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.94      0.99      0.97       167\n",
      "    positive       0.88      0.70      0.78        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.92      0.81      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.75      0.86        12\n",
      "     neutral       0.91      0.95      0.93       152\n",
      "    positive       0.83      0.75      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.91      0.82      0.86       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        23\n",
      "     neutral       0.95      0.99      0.97       152\n",
      "    positive       0.91      0.78      0.84        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.89      0.91       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.98      0.99       186\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.93      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 100.49181985855103 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.03274598717689514\n",
      "Samples above threshold: 39\n",
      "Acquired samples: 39\n",
      "Sampling duration: 4.36341667175293 seconds\n",
      "New train size: 517\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.534, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4652, Accuracy: 0.8185, F1 Micro: 0.8968, F1 Macro: 0.8954\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3484, Accuracy: 0.9211, F1 Micro: 0.9513, F1 Macro: 0.9493\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2484, Accuracy: 0.9464, F1 Micro: 0.9666, F1 Macro: 0.9651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1883, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1484, Accuracy: 0.9606, F1 Micro: 0.9754, F1 Macro: 0.9745\n",
      "Epoch 7/10, Train Loss: 0.1129, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9726\n",
      "Epoch 8/10, Train Loss: 0.0913, Accuracy: 0.9576, F1 Micro: 0.9732, F1 Macro: 0.9711\n",
      "Epoch 9/10, Train Loss: 0.0771, Accuracy: 0.9576, F1 Micro: 0.9732, F1 Macro: 0.9706\n",
      "Epoch 10/10, Train Loss: 0.0637, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9728\n",
      "\n",
      "Aspect detection accuracy: 0.9606, F1 Micro: 0.9754, F1 Macro: 0.9745\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.88      0.99      0.93       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.98      0.98      0.98       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.97      1061\n",
      "weighted avg       0.96      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6274, Accuracy: 0.8156, F1 Micro: 0.8156, F1 Macro: 0.8071\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3745, Accuracy: 0.9303, F1 Micro: 0.9303, F1 Macro: 0.9222\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2423, Accuracy: 0.9508, F1 Micro: 0.9508, F1 Macro: 0.9455\n",
      "Epoch 4/10, Train Loss: 0.1561, Accuracy: 0.9426, F1 Micro: 0.9426, F1 Macro: 0.9381\n",
      "Epoch 5/10, Train Loss: 0.1714, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9328\n",
      "Epoch 6/10, Train Loss: 0.1256, Accuracy: 0.9467, F1 Micro: 0.9467, F1 Macro: 0.9412\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1048, Accuracy: 0.9549, F1 Micro: 0.9549, F1 Macro: 0.9507\n",
      "Epoch 8/10, Train Loss: 0.0964, Accuracy: 0.9467, F1 Micro: 0.9467, F1 Macro: 0.9421\n",
      "Epoch 9/10, Train Loss: 0.0987, Accuracy: 0.9426, F1 Micro: 0.9426, F1 Macro: 0.9378\n",
      "Epoch 10/10, Train Loss: 0.0616, Accuracy: 0.9426, F1 Micro: 0.9426, F1 Macro: 0.9372\n",
      "\n",
      "Sentiment analysis accuracy: 0.9549, F1 Micro: 0.9549, F1 Macro: 0.9507\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94        83\n",
      "    positive       0.99      0.94      0.97       161\n",
      "\n",
      "    accuracy                           0.95       244\n",
      "   macro avg       0.94      0.96      0.95       244\n",
      "weighted avg       0.96      0.95      0.96       244\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 517: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9159\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.84      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.67      0.76        12\n",
      "     neutral       0.88      0.99      0.93       152\n",
      "    positive       0.94      0.65      0.77        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.90      0.77      0.82       216\n",
      "weighted avg       0.89      0.89      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.98      0.98      0.98       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 103.12063789367676 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0305534839630127\n",
      "Samples above threshold: 35\n",
      "Acquired samples: 23\n",
      "Sampling duration: 4.179579734802246 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5323, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4484, Accuracy: 0.849, F1 Micro: 0.9122, F1 Macro: 0.9113\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3363, Accuracy: 0.9241, F1 Micro: 0.9533, F1 Macro: 0.9514\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.245, Accuracy: 0.9501, F1 Micro: 0.9687, F1 Macro: 0.9672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1883, Accuracy: 0.9568, F1 Micro: 0.9731, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1366, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9748\n",
      "Epoch 7/10, Train Loss: 0.1138, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9725\n",
      "Epoch 8/10, Train Loss: 0.0889, Accuracy: 0.9561, F1 Micro: 0.9724, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0724, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9769\n",
      "Epoch 10/10, Train Loss: 0.0679, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9746\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.93      0.93      0.93       158\n",
      "        part       0.96      0.98      0.97       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6496, Accuracy: 0.7248, F1 Micro: 0.7248, F1 Macro: 0.6252\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4094, Accuracy: 0.9186, F1 Micro: 0.9186, F1 Macro: 0.9115\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2219, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.9324\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2157, Accuracy: 0.9535, F1 Micro: 0.9535, F1 Macro: 0.9483\n",
      "Epoch 5/10, Train Loss: 0.1273, Accuracy: 0.9031, F1 Micro: 0.9031, F1 Macro: 0.8961\n",
      "Epoch 6/10, Train Loss: 0.1529, Accuracy: 0.9147, F1 Micro: 0.9147, F1 Macro: 0.8982\n",
      "Epoch 7/10, Train Loss: 0.1119, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9351\n",
      "Epoch 8/10, Train Loss: 0.0865, Accuracy: 0.9457, F1 Micro: 0.9457, F1 Macro: 0.9396\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0858, Accuracy: 0.9535, F1 Micro: 0.9535, F1 Macro: 0.948\n",
      "Epoch 10/10, Train Loss: 0.0628, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9355\n",
      "\n",
      "Sentiment analysis accuracy: 0.9535, F1 Micro: 0.9535, F1 Macro: 0.948\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.94      0.93        86\n",
      "    positive       0.97      0.96      0.96       172\n",
      "\n",
      "    accuracy                           0.95       258\n",
      "   macro avg       0.95      0.95      0.95       258\n",
      "weighted avg       0.95      0.95      0.95       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9255\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.84      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.79      0.81      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.85      0.83      0.84       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.96      0.98      0.97       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.93      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 111.89398193359375 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.016970676183700562\n",
      "Samples above threshold: 33\n",
      "Acquired samples: 33\n",
      "Sampling duration: 4.034593343734741 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5483, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4522, Accuracy: 0.8467, F1 Micro: 0.9114, F1 Macro: 0.9107\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3282, Accuracy: 0.9345, F1 Micro: 0.9596, F1 Macro: 0.9581\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2278, Accuracy: 0.9516, F1 Micro: 0.97, F1 Macro: 0.9686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1736, Accuracy: 0.9568, F1 Micro: 0.9731, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1321, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9735\n",
      "Epoch 7/10, Train Loss: 0.1025, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9727\n",
      "Epoch 8/10, Train Loss: 0.08, Accuracy: 0.9576, F1 Micro: 0.9732, F1 Macro: 0.9709\n",
      "Epoch 9/10, Train Loss: 0.0722, Accuracy: 0.9568, F1 Micro: 0.9727, F1 Macro: 0.9701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0607, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9744\n",
      "\n",
      "Aspect detection accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9744\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.91      0.91       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.98      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6043, Accuracy: 0.7744, F1 Micro: 0.7744, F1 Macro: 0.7702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.357, Accuracy: 0.9248, F1 Micro: 0.9248, F1 Macro: 0.9151\n",
      "Epoch 3/10, Train Loss: 0.2236, Accuracy: 0.9211, F1 Micro: 0.9211, F1 Macro: 0.9071\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1575, Accuracy: 0.9361, F1 Micro: 0.9361, F1 Macro: 0.9296\n",
      "Epoch 5/10, Train Loss: 0.1889, Accuracy: 0.8872, F1 Micro: 0.8872, F1 Macro: 0.8798\n",
      "Epoch 6/10, Train Loss: 0.1672, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9204\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1088, Accuracy: 0.9361, F1 Micro: 0.9361, F1 Macro: 0.9292\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0827, Accuracy: 0.9361, F1 Micro: 0.9361, F1 Macro: 0.9292\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0715, Accuracy: 0.9436, F1 Micro: 0.9436, F1 Macro: 0.9354\n",
      "Epoch 10/10, Train Loss: 0.0638, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9236\n",
      "\n",
      "Sentiment analysis accuracy: 0.9436, F1 Micro: 0.9436, F1 Macro: 0.9354\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.91      0.91        86\n",
      "    positive       0.96      0.96      0.96       180\n",
      "\n",
      "    accuracy                           0.94       266\n",
      "   macro avg       0.94      0.93      0.94       266\n",
      "weighted avg       0.94      0.94      0.94       266\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9117\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.93      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.83      0.73      0.77        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.82      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.75      0.86        12\n",
      "     neutral       0.92      0.91      0.91       152\n",
      "    positive       0.74      0.81      0.77        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.89      0.82      0.85       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.93      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.98      0.99       186\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.93      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 118.54184818267822 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.015492081642150879\n",
      "Samples above threshold: 30\n",
      "Acquired samples: 30\n",
      "Sampling duration: 3.7966601848602295 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.54, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4452, Accuracy: 0.8683, F1 Micro: 0.9227, F1 Macro: 0.9217\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.311, Accuracy: 0.9338, F1 Micro: 0.9587, F1 Macro: 0.9563\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2193, Accuracy: 0.9539, F1 Micro: 0.9712, F1 Macro: 0.9697\n",
      "Epoch 5/10, Train Loss: 0.1562, Accuracy: 0.9539, F1 Micro: 0.9709, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1262, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9746\n",
      "Epoch 7/10, Train Loss: 0.0977, Accuracy: 0.9576, F1 Micro: 0.9732, F1 Macro: 0.9708\n",
      "Epoch 8/10, Train Loss: 0.0771, Accuracy: 0.9583, F1 Micro: 0.9737, F1 Macro: 0.9714\n",
      "Epoch 9/10, Train Loss: 0.0654, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0603, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9748\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9748\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.92      0.92      0.92       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5989, Accuracy: 0.8662, F1 Micro: 0.8662, F1 Macro: 0.8549\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.336, Accuracy: 0.9182, F1 Micro: 0.9182, F1 Macro: 0.9091\n",
      "Epoch 3/10, Train Loss: 0.2478, Accuracy: 0.9145, F1 Micro: 0.9145, F1 Macro: 0.9066\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1726, Accuracy: 0.9368, F1 Micro: 0.9368, F1 Macro: 0.9296\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1581, Accuracy: 0.9368, F1 Micro: 0.9368, F1 Macro: 0.9296\n",
      "Epoch 6/10, Train Loss: 0.1238, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9249\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.094, Accuracy: 0.9368, F1 Micro: 0.9368, F1 Macro: 0.9262\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0864, Accuracy: 0.9517, F1 Micro: 0.9517, F1 Macro: 0.9453\n",
      "Epoch 9/10, Train Loss: 0.0807, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9332\n",
      "Epoch 10/10, Train Loss: 0.0716, Accuracy: 0.9368, F1 Micro: 0.9368, F1 Macro: 0.9288\n",
      "\n",
      "Sentiment analysis accuracy: 0.9517, F1 Micro: 0.9517, F1 Macro: 0.9453\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.96      0.93        85\n",
      "    positive       0.98      0.95      0.96       184\n",
      "\n",
      "    accuracy                           0.95       269\n",
      "   macro avg       0.94      0.96      0.95       269\n",
      "weighted avg       0.95      0.95      0.95       269\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9161\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.97      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.88      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.67      0.73        12\n",
      "     neutral       0.92      0.91      0.92       152\n",
      "    positive       0.75      0.79      0.77        52\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.82      0.79      0.80       216\n",
      "weighted avg       0.87      0.87      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 117.46496820449829 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.014702200889587402\n",
      "Samples above threshold: 27\n",
      "Acquired samples: 27\n",
      "Sampling duration: 3.507965564727783 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5423, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4289, Accuracy: 0.8914, F1 Micro: 0.9351, F1 Macro: 0.9338\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3148, Accuracy: 0.9375, F1 Micro: 0.9615, F1 Macro: 0.9602\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2162, Accuracy: 0.9539, F1 Micro: 0.9713, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1602, Accuracy: 0.9621, F1 Micro: 0.9763, F1 Macro: 0.9754\n",
      "Epoch 6/10, Train Loss: 0.1202, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0972, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9774\n",
      "Epoch 8/10, Train Loss: 0.0705, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9744\n",
      "Epoch 9/10, Train Loss: 0.0673, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9756\n",
      "Epoch 10/10, Train Loss: 0.0572, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9746\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9774\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.93      0.96      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.98      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.57, Accuracy: 0.8726, F1 Micro: 0.8726, F1 Macro: 0.856\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2644, Accuracy: 0.9035, F1 Micro: 0.9035, F1 Macro: 0.8968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1998, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9176\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.173, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.9193\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1224, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9271\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1292, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9353\n",
      "Epoch 7/10, Train Loss: 0.1119, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9315\n",
      "Epoch 8/10, Train Loss: 0.0885, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9262\n",
      "Epoch 9/10, Train Loss: 0.0715, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9238\n",
      "Epoch 10/10, Train Loss: 0.0668, Accuracy: 0.9189, F1 Micro: 0.9189, F1 Macro: 0.9047\n",
      "\n",
      "Sentiment analysis accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9353\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.93      0.91        86\n",
      "    positive       0.96      0.95      0.96       173\n",
      "\n",
      "    accuracy                           0.94       259\n",
      "   macro avg       0.93      0.94      0.94       259\n",
      "weighted avg       0.94      0.94      0.94       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9155\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.93      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.73      0.79        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.86      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.93      0.95      0.94       152\n",
      "    positive       0.85      0.79      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.84      0.83      0.84       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.98      0.99       186\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.93      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 120.92977571487427 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.0196561336517334\n",
      "Samples above threshold: 24\n",
      "Acquired samples: 18\n",
      "Sampling duration: 3.2866621017456055 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5274, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.413, Accuracy: 0.904, F1 Micro: 0.9417, F1 Macro: 0.9399\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2851, Accuracy: 0.9487, F1 Micro: 0.9682, F1 Macro: 0.9668\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2004, Accuracy: 0.9531, F1 Micro: 0.9708, F1 Macro: 0.9697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1451, Accuracy: 0.9568, F1 Micro: 0.9728, F1 Macro: 0.9706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1118, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9771\n",
      "Epoch 7/10, Train Loss: 0.0905, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9738\n",
      "Epoch 8/10, Train Loss: 0.0743, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9742\n",
      "Epoch 9/10, Train Loss: 0.0597, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9744\n",
      "Epoch 10/10, Train Loss: 0.0521, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9746\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.90      0.97      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.98      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5436, Accuracy: 0.872, F1 Micro: 0.872, F1 Macro: 0.8611\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2769, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9219\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2085, Accuracy: 0.94, F1 Micro: 0.94, F1 Macro: 0.9347\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1224, Accuracy: 0.952, F1 Micro: 0.952, F1 Macro: 0.9462\n",
      "Epoch 5/10, Train Loss: 0.133, Accuracy: 0.936, F1 Micro: 0.936, F1 Macro: 0.9302\n",
      "Epoch 6/10, Train Loss: 0.0866, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9383\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0799, Accuracy: 0.952, F1 Micro: 0.952, F1 Macro: 0.9468\n",
      "Epoch 8/10, Train Loss: 0.0652, Accuracy: 0.94, F1 Micro: 0.94, F1 Macro: 0.933\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0697, Accuracy: 0.952, F1 Micro: 0.952, F1 Macro: 0.9474\n",
      "Epoch 10/10, Train Loss: 0.0509, Accuracy: 0.936, F1 Micro: 0.936, F1 Macro: 0.9302\n",
      "\n",
      "Sentiment analysis accuracy: 0.952, F1 Micro: 0.952, F1 Macro: 0.9474\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.93        84\n",
      "    positive       0.99      0.94      0.96       166\n",
      "\n",
      "    accuracy                           0.95       250\n",
      "   macro avg       0.94      0.96      0.95       250\n",
      "weighted avg       0.96      0.95      0.95       250\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.9168\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.88      0.93        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.96      0.99      0.97       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.86      0.87       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.67      0.76        12\n",
      "     neutral       0.90      0.97      0.94       152\n",
      "    positive       0.91      0.75      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.90      0.80      0.84       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.98      0.99       186\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.93      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.96      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 120.01939535140991 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.01993626356124878\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.2392759323120117 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.54, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.401, Accuracy: 0.9144, F1 Micro: 0.9478, F1 Macro: 0.9466\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.271, Accuracy: 0.9501, F1 Micro: 0.969, F1 Macro: 0.9677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1919, Accuracy: 0.9554, F1 Micro: 0.9721, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1424, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9759\n",
      "Epoch 6/10, Train Loss: 0.1026, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0867, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0678, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9771\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0559, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9777\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0511, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9794\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9794\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.91      0.97      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.98      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5576, Accuracy: 0.8745, F1 Micro: 0.8745, F1 Macro: 0.8588\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2998, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9344\n",
      "Epoch 3/10, Train Loss: 0.2208, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9306\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1479, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9351\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1327, Accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.9431\n",
      "Epoch 6/10, Train Loss: 0.139, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.934\n",
      "Epoch 7/10, Train Loss: 0.0909, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9306\n",
      "Epoch 8/10, Train Loss: 0.0813, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9344\n",
      "Epoch 9/10, Train Loss: 0.0751, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9268\n",
      "Epoch 10/10, Train Loss: 0.0567, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9306\n",
      "\n",
      "Sentiment analysis accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.9431\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.94      0.92        85\n",
      "    positive       0.97      0.95      0.96       170\n",
      "\n",
      "    accuracy                           0.95       255\n",
      "   macro avg       0.94      0.95      0.94       255\n",
      "weighted avg       0.95      0.95      0.95       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.9614, F1 Micro: 0.9614, F1 Macro: 0.9223\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.93      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.90      0.82      0.86        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.67      0.73        12\n",
      "     neutral       0.91      0.97      0.94       152\n",
      "    positive       0.88      0.73      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.86      0.79      0.82       216\n",
      "weighted avg       0.90      0.90      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.83      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.95      0.94      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.98      0.99       186\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.93      0.92       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 124.50763654708862 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.01566159725189209\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.9689536094665527 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5317, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4087, Accuracy: 0.8973, F1 Micro: 0.936, F1 Macro: 0.9333\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.268, Accuracy: 0.9472, F1 Micro: 0.9674, F1 Macro: 0.9664\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1925, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1431, Accuracy: 0.965, F1 Micro: 0.9782, F1 Macro: 0.9773\n",
      "Epoch 6/10, Train Loss: 0.1013, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0877, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9773\n",
      "Epoch 8/10, Train Loss: 0.0701, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0588, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9792\n",
      "Epoch 10/10, Train Loss: 0.0514, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9759\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9792\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.93      0.95      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5704, Accuracy: 0.8919, F1 Micro: 0.8919, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3063, Accuracy: 0.9266, F1 Micro: 0.9266, F1 Macro: 0.918\n",
      "Epoch 3/10, Train Loss: 0.201, Accuracy: 0.8996, F1 Micro: 0.8996, F1 Macro: 0.8929\n",
      "Epoch 4/10, Train Loss: 0.1853, Accuracy: 0.9189, F1 Micro: 0.9189, F1 Macro: 0.9117\n",
      "Epoch 5/10, Train Loss: 0.1462, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.9086\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.151, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9312\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1044, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9356\n",
      "Epoch 8/10, Train Loss: 0.0726, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9161\n",
      "Epoch 9/10, Train Loss: 0.0763, Accuracy: 0.9189, F1 Micro: 0.9189, F1 Macro: 0.9117\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0391, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9398\n",
      "\n",
      "Sentiment analysis accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9398\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        86\n",
      "    positive       0.97      0.95      0.96       173\n",
      "\n",
      "    accuracy                           0.95       259\n",
      "   macro avg       0.94      0.94      0.94       259\n",
      "weighted avg       0.95      0.95      0.95       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9225\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       1.00      0.96      0.98        24\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.99      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.83      0.91        12\n",
      "     neutral       0.93      0.95      0.94       152\n",
      "    positive       0.82      0.81      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.92      0.86      0.89       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.80      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.96      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 125.86178994178772 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.011480391025543213\n",
      "Samples above threshold: 17\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.8747141361236572 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5211, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3891, Accuracy: 0.9129, F1 Micro: 0.9463, F1 Macro: 0.9438\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2672, Accuracy: 0.9501, F1 Micro: 0.969, F1 Macro: 0.9679\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1805, Accuracy: 0.9531, F1 Micro: 0.9706, F1 Macro: 0.9688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1321, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1063, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0835, Accuracy: 0.9695, F1 Micro: 0.9809, F1 Macro: 0.9802\n",
      "Epoch 8/10, Train Loss: 0.0647, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9721\n",
      "Epoch 9/10, Train Loss: 0.0593, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9768\n",
      "Epoch 10/10, Train Loss: 0.0485, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9775\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9809, F1 Macro: 0.9802\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.91      0.99      0.95       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5519, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.899\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2586, Accuracy: 0.9476, F1 Micro: 0.9476, F1 Macro: 0.9426\n",
      "Epoch 3/10, Train Loss: 0.1821, Accuracy: 0.9435, F1 Micro: 0.9435, F1 Macro: 0.938\n",
      "Epoch 4/10, Train Loss: 0.132, Accuracy: 0.9274, F1 Micro: 0.9274, F1 Macro: 0.9219\n",
      "Epoch 5/10, Train Loss: 0.1132, Accuracy: 0.9435, F1 Micro: 0.9435, F1 Macro: 0.9387\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0793, Accuracy: 0.9476, F1 Micro: 0.9476, F1 Macro: 0.9426\n",
      "Epoch 7/10, Train Loss: 0.109, Accuracy: 0.9435, F1 Micro: 0.9435, F1 Macro: 0.9387\n",
      "Epoch 8/10, Train Loss: 0.0711, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9174\n",
      "Epoch 9/10, Train Loss: 0.0792, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9121\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0591, Accuracy: 0.9476, F1 Micro: 0.9476, F1 Macro: 0.9423\n",
      "\n",
      "Sentiment analysis accuracy: 0.9476, F1 Micro: 0.9476, F1 Macro: 0.9423\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.94      0.92        85\n",
      "    positive       0.97      0.95      0.96       163\n",
      "\n",
      "    accuracy                           0.95       248\n",
      "   macro avg       0.94      0.95      0.94       248\n",
      "weighted avg       0.95      0.95      0.95       248\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9614, F1 Micro: 0.9614, F1 Macro: 0.9189\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.90      0.82      0.86        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.91      0.99      0.95       152\n",
      "    positive       0.95      0.71      0.81        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.89      0.82      0.85       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.83      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.95      0.94      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.87      0.90       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 122.74493670463562 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.017687857151031494\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.601487159729004 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5246, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3824, Accuracy: 0.9249, F1 Micro: 0.9533, F1 Macro: 0.9513\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2594, Accuracy: 0.9554, F1 Micro: 0.9724, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1732, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1277, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1044, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0809, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0654, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9765\n",
      "Epoch 9/10, Train Loss: 0.0556, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0462, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9782\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9782\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.97      0.97      0.97       175\n",
      "      others       0.93      0.95      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.98      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5178, Accuracy: 0.9064, F1 Micro: 0.9064, F1 Macro: 0.8976\n",
      "Epoch 2/10, Train Loss: 0.252, Accuracy: 0.8876, F1 Micro: 0.8876, F1 Macro: 0.8801\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1727, Accuracy: 0.9288, F1 Micro: 0.9288, F1 Macro: 0.9214\n",
      "Epoch 4/10, Train Loss: 0.1561, Accuracy: 0.9251, F1 Micro: 0.9251, F1 Macro: 0.9175\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1305, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.925\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0876, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9246\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.091, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9254\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0876, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9218\n",
      "Epoch 9/10, Train Loss: 0.0806, Accuracy: 0.8989, F1 Micro: 0.8989, F1 Macro: 0.8909\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0748, Accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9258\n",
      "\n",
      "Sentiment analysis accuracy: 0.9326, F1 Micro: 0.9326, F1 Macro: 0.9258\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.97      0.90        87\n",
      "    positive       0.98      0.92      0.95       180\n",
      "\n",
      "    accuracy                           0.93       267\n",
      "   macro avg       0.92      0.94      0.93       267\n",
      "weighted avg       0.94      0.93      0.93       267\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9159\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.97      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.97      0.97       167\n",
      "    positive       0.84      0.82      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.93      0.95      0.94       152\n",
      "    positive       0.82      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.89      0.86      0.87       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.92      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.92      0.83        13\n",
      "     neutral       0.99      0.98      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.87      0.89      0.88       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 137.2014183998108 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.00911027193069458\n",
      "Samples above threshold: 12\n",
      "Acquired samples: 8\n",
      "Sampling duration: 2.521451711654663 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5236, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3885, Accuracy: 0.9219, F1 Micro: 0.9514, F1 Macro: 0.9488\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2456, Accuracy: 0.9546, F1 Micro: 0.9718, F1 Macro: 0.9708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1747, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1297, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.099, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.08, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9763\n",
      "Epoch 8/10, Train Loss: 0.0638, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0556, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9768\n",
      "Epoch 10/10, Train Loss: 0.0462, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9769\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.91      0.92       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.551, Accuracy: 0.8918, F1 Micro: 0.8918, F1 Macro: 0.8755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2353, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9179\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1698, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9364\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1465, Accuracy: 0.9478, F1 Micro: 0.9478, F1 Macro: 0.9401\n",
      "Epoch 5/10, Train Loss: 0.1534, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.9256\n",
      "Epoch 6/10, Train Loss: 0.1217, Accuracy: 0.9179, F1 Micro: 0.9179, F1 Macro: 0.9107\n",
      "Epoch 7/10, Train Loss: 0.0978, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9327\n",
      "Epoch 8/10, Train Loss: 0.0689, Accuracy: 0.9254, F1 Micro: 0.9254, F1 Macro: 0.9181\n",
      "Epoch 9/10, Train Loss: 0.064, Accuracy: 0.9254, F1 Micro: 0.9254, F1 Macro: 0.9181\n",
      "Epoch 10/10, Train Loss: 0.0647, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.9287\n",
      "\n",
      "Sentiment analysis accuracy: 0.9478, F1 Micro: 0.9478, F1 Macro: 0.9401\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.91      0.92        87\n",
      "    positive       0.96      0.97      0.96       181\n",
      "\n",
      "    accuracy                           0.95       268\n",
      "   macro avg       0.94      0.94      0.94       268\n",
      "weighted avg       0.95      0.95      0.95       268\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.9197\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.93      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.87      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.93      0.91      0.92       152\n",
      "    positive       0.75      0.79      0.77        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.84      0.85      0.84       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.96      0.94        23\n",
      "     neutral       0.98      0.99      0.99       152\n",
      "    positive       0.97      0.90      0.94        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.96      0.95      0.95       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.93      0.91      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 132.03929662704468 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.018247365951538086\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.3897433280944824 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5314, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3839, Accuracy: 0.9085, F1 Micro: 0.9423, F1 Macro: 0.9388\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.247, Accuracy: 0.9546, F1 Micro: 0.9719, F1 Macro: 0.9707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1752, Accuracy: 0.9576, F1 Micro: 0.9736, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1263, Accuracy: 0.9606, F1 Micro: 0.975, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0976, Accuracy: 0.9628, F1 Micro: 0.9768, F1 Macro: 0.9758\n",
      "Epoch 7/10, Train Loss: 0.0756, Accuracy: 0.9606, F1 Micro: 0.975, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0632, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9771\n",
      "Epoch 9/10, Train Loss: 0.056, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9743\n",
      "Epoch 10/10, Train Loss: 0.0463, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.92      0.94      0.93       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5156, Accuracy: 0.8783, F1 Micro: 0.8783, F1 Macro: 0.8508\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2796, Accuracy: 0.9278, F1 Micro: 0.9278, F1 Macro: 0.9182\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1759, Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9406\n",
      "Epoch 4/10, Train Loss: 0.1173, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9295\n",
      "Epoch 5/10, Train Loss: 0.128, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9164\n",
      "Epoch 6/10, Train Loss: 0.1028, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.924\n",
      "Epoch 7/10, Train Loss: 0.0939, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9164\n",
      "Epoch 8/10, Train Loss: 0.0963, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9354\n",
      "Epoch 9/10, Train Loss: 0.0646, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9368\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0707, Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9402\n",
      "\n",
      "Sentiment analysis accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9402\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        86\n",
      "    positive       0.97      0.95      0.96       177\n",
      "\n",
      "    accuracy                           0.95       263\n",
      "   macro avg       0.94      0.95      0.94       263\n",
      "weighted avg       0.95      0.95      0.95       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9194\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.87      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.75      0.86        12\n",
      "     neutral       0.92      0.94      0.93       152\n",
      "    positive       0.81      0.81      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.91      0.83      0.87       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      1.00      0.87        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.93      0.90       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 133.14678716659546 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.010328638553619384\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.28499698638916 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5156, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3729, Accuracy: 0.9278, F1 Micro: 0.9551, F1 Macro: 0.9522\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2399, Accuracy: 0.9546, F1 Micro: 0.9717, F1 Macro: 0.9703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.172, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.122, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9769\n",
      "Epoch 6/10, Train Loss: 0.096, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0727, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9776\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0602, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9785\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0521, Accuracy: 0.9725, F1 Micro: 0.9826, F1 Macro: 0.9813\n",
      "Epoch 10/10, Train Loss: 0.0416, Accuracy: 0.965, F1 Micro: 0.9778, F1 Macro: 0.9762\n",
      "\n",
      "Aspect detection accuracy: 0.9725, F1 Micro: 0.9826, F1 Macro: 0.9813\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.95      0.92      0.94       158\n",
      "        part       0.98      0.99      0.99       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5268, Accuracy: 0.886, F1 Micro: 0.886, F1 Macro: 0.8702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2644, Accuracy: 0.9301, F1 Micro: 0.9301, F1 Macro: 0.9226\n",
      "Epoch 3/10, Train Loss: 0.1515, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9153\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1492, Accuracy: 0.9301, F1 Micro: 0.9301, F1 Macro: 0.9222\n",
      "Epoch 5/10, Train Loss: 0.122, Accuracy: 0.9228, F1 Micro: 0.9228, F1 Macro: 0.9153\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1288, Accuracy: 0.9338, F1 Micro: 0.9338, F1 Macro: 0.9265\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0973, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9343\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0854, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9348\n",
      "Epoch 9/10, Train Loss: 0.0807, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.9039\n",
      "Epoch 10/10, Train Loss: 0.0521, Accuracy: 0.9338, F1 Micro: 0.9338, F1 Macro: 0.9265\n",
      "\n",
      "Sentiment analysis accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9348\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.85      0.91        88\n",
      "    positive       0.93      0.99      0.96       184\n",
      "\n",
      "    accuracy                           0.94       272\n",
      "   macro avg       0.95      0.92      0.93       272\n",
      "weighted avg       0.95      0.94      0.94       272\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9622, F1 Micro: 0.9622, F1 Macro: 0.9225\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       0.88      0.96      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.90      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.75      0.86        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.82      0.85      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.86      0.89       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        12\n",
      "     neutral       0.96      0.92      0.94       152\n",
      "    positive       0.78      0.88      0.83        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.92      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        23\n",
      "     neutral       0.98      0.99      0.99       152\n",
      "    positive       0.95      0.90      0.92        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.94      0.94       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.93      0.88      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 141.3596591949463 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.009494292736053466\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.0174732208251953 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5244, Accuracy: 0.7976, F1 Micro: 0.8864, F1 Macro: 0.885\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3671, Accuracy: 0.9293, F1 Micro: 0.9562, F1 Macro: 0.9538\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2311, Accuracy: 0.9576, F1 Micro: 0.9737, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1601, Accuracy: 0.9606, F1 Micro: 0.9754, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1301, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0943, Accuracy: 0.968, F1 Micro: 0.98, F1 Macro: 0.9789\n",
      "Epoch 7/10, Train Loss: 0.0773, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9776\n",
      "Epoch 8/10, Train Loss: 0.0635, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9785\n",
      "Epoch 9/10, Train Loss: 0.0521, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9778\n",
      "Epoch 10/10, Train Loss: 0.0427, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9768\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.98, F1 Macro: 0.9789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.90      0.97      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4876, Accuracy: 0.881, F1 Micro: 0.881, F1 Macro: 0.8733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2538, Accuracy: 0.9206, F1 Micro: 0.9206, F1 Macro: 0.9144\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2018, Accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9437\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.142, Accuracy: 0.9524, F1 Micro: 0.9524, F1 Macro: 0.947\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1011, Accuracy: 0.9524, F1 Micro: 0.9524, F1 Macro: 0.9476\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0864, Accuracy: 0.9563, F1 Micro: 0.9563, F1 Macro: 0.9521\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0902, Accuracy: 0.9603, F1 Micro: 0.9603, F1 Macro: 0.9563\n",
      "Epoch 8/10, Train Loss: 0.0717, Accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9437\n",
      "Epoch 9/10, Train Loss: 0.079, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9353\n",
      "Epoch 10/10, Train Loss: 0.0589, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9353\n",
      "\n",
      "Sentiment analysis accuracy: 0.9603, F1 Micro: 0.9603, F1 Macro: 0.9563\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94        85\n",
      "    positive       0.99      0.95      0.97       167\n",
      "\n",
      "    accuracy                           0.96       252\n",
      "   macro avg       0.95      0.96      0.96       252\n",
      "weighted avg       0.96      0.96      0.96       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9614, F1 Micro: 0.9614, F1 Macro: 0.9285\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.97      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.90      0.97      0.93       152\n",
      "    positive       0.88      0.73      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.90      0.82      0.85       216\n",
      "weighted avg       0.90      0.90      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.83      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 138.20854020118713 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.013039946556091309\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.7742161750793457 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5251, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3603, Accuracy: 0.9263, F1 Micro: 0.9538, F1 Macro: 0.9512\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2333, Accuracy: 0.9546, F1 Micro: 0.9718, F1 Macro: 0.9708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1678, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1187, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9779\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0909, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9783\n",
      "Epoch 7/10, Train Loss: 0.0775, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9755\n",
      "Epoch 8/10, Train Loss: 0.0653, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0532, Accuracy: 0.9702, F1 Micro: 0.9812, F1 Macro: 0.9798\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0452, Accuracy: 0.974, F1 Micro: 0.9836, F1 Macro: 0.9826\n",
      "\n",
      "Aspect detection accuracy: 0.974, F1 Micro: 0.9836, F1 Macro: 0.9826\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.99      0.98       175\n",
      "      others       0.93      0.96      0.95       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.98      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.98      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4818, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.9065\n",
      "Epoch 2/10, Train Loss: 0.2294, Accuracy: 0.8769, F1 Micro: 0.8769, F1 Macro: 0.8705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1947, Accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.9123\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1408, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9361\n",
      "Epoch 5/10, Train Loss: 0.1571, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9204\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0979, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9354\n",
      "Epoch 7/10, Train Loss: 0.1079, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9243\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.085, Accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.9446\n",
      "Epoch 9/10, Train Loss: 0.0762, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9324\n",
      "Epoch 10/10, Train Loss: 0.0725, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9368\n",
      "\n",
      "Sentiment analysis accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.9446\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.97      0.93        86\n",
      "    positive       0.98      0.94      0.96       174\n",
      "\n",
      "    accuracy                           0.95       260\n",
      "   macro avg       0.94      0.95      0.94       260\n",
      "weighted avg       0.95      0.95      0.95       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9653, F1 Micro: 0.9653, F1 Macro: 0.9317\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.99      0.98       167\n",
      "    positive       0.90      0.82      0.86        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.89      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.94      0.96      0.95       152\n",
      "    positive       0.87      0.79      0.83        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.86      0.86      0.86       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.80      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 143.1749565601349 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.006323903799057007\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 8\n",
      "Sampling duration: 1.563746690750122 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5122, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3625, Accuracy: 0.9308, F1 Micro: 0.9572, F1 Macro: 0.9551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2296, Accuracy: 0.9546, F1 Micro: 0.9718, F1 Macro: 0.9707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1639, Accuracy: 0.965, F1 Micro: 0.9782, F1 Macro: 0.9771\n",
      "Epoch 5/10, Train Loss: 0.1212, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9764\n",
      "Epoch 6/10, Train Loss: 0.091, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9763\n",
      "Epoch 7/10, Train Loss: 0.074, Accuracy: 0.9628, F1 Micro: 0.9764, F1 Macro: 0.9741\n",
      "Epoch 8/10, Train Loss: 0.0592, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0464, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9783\n",
      "Epoch 10/10, Train Loss: 0.0432, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9765\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9783\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.97      0.97      0.97       175\n",
      "      others       0.94      0.93      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4889, Accuracy: 0.8955, F1 Micro: 0.8955, F1 Macro: 0.8869\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2283, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9093\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1465, Accuracy: 0.9366, F1 Micro: 0.9366, F1 Macro: 0.9295\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1204, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9371\n",
      "Epoch 5/10, Train Loss: 0.1177, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9251\n",
      "Epoch 6/10, Train Loss: 0.0766, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9133\n",
      "Epoch 7/10, Train Loss: 0.0869, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9162\n",
      "Epoch 8/10, Train Loss: 0.0729, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9315\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0616, Accuracy: 0.9515, F1 Micro: 0.9515, F1 Macro: 0.9455\n",
      "Epoch 10/10, Train Loss: 0.054, Accuracy: 0.9403, F1 Micro: 0.9403, F1 Macro: 0.9311\n",
      "\n",
      "Sentiment analysis accuracy: 0.9515, F1 Micro: 0.9515, F1 Macro: 0.9455\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.93        87\n",
      "    positive       0.98      0.95      0.96       181\n",
      "\n",
      "    accuracy                           0.95       268\n",
      "   macro avg       0.94      0.95      0.95       268\n",
      "weighted avg       0.95      0.95      0.95       268\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9267\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        16\n",
      "     neutral       0.96      0.97      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.88      0.88      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.94      0.93      0.93       152\n",
      "    positive       0.78      0.83      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.88      0.86      0.87       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.83      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.95      0.94      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 139.32061958312988 s\n",
      "Total runtime: 2981.9931766986847 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d6c659",
   "metadata": {
    "papermill": {
     "duration": 0.349434,
     "end_time": "2025-03-24T16:58:55.254049",
     "exception": false,
     "start_time": "2025-03-24T16:58:54.904615",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575a2578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 3\n",
      "Random seed: 14\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6791, Accuracy: 0.7746, F1 Micro: 0.8722, F1 Macro: 0.8703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5752, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.512, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4609, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4635, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4127, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3898, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4151, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.396, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3746, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "\n",
      "Aspect detection accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.78      1.00      0.88       175\n",
      "      others       0.71      1.00      0.83       158\n",
      "        part       0.71      1.00      0.83       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.79      1.00      0.88      1061\n",
      "   macro avg       0.79      1.00      0.88      1061\n",
      "weighted avg       0.80      1.00      0.89      1061\n",
      " samples avg       0.79      1.00      0.88      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.8159, Accuracy: 0.3333, F1 Micro: 0.3333, F1 Macro: 0.25\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.6264, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5442, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5154, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4038, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3617, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3192, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2942, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3391, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2952, Accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "\n",
      "Sentiment analysis accuracy: 0.6667, F1 Micro: 0.6667, F1 Macro: 0.4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         1\n",
      "    positive       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.67         3\n",
      "   macro avg       0.33      0.50      0.40         3\n",
      "weighted avg       0.44      0.67      0.53         3\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.7909, F1 Micro: 0.7909, F1 Macro: 0.298\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.77      1.00      0.87       167\n",
      "    positive       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.77       216\n",
      "   macro avg       0.26      0.33      0.29       216\n",
      "weighted avg       0.60      0.77      0.67       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.71      1.00      0.83       152\n",
      "    positive       0.67      0.04      0.07        52\n",
      "\n",
      "    accuracy                           0.71       216\n",
      "   macro avg       0.46      0.35      0.30       216\n",
      "weighted avg       0.66      0.71      0.60       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        23\n",
      "     neutral       0.70      1.00      0.83       152\n",
      "    positive       0.00      0.00      0.00        41\n",
      "\n",
      "    accuracy                           0.70       216\n",
      "   macro avg       0.23      0.33      0.28       216\n",
      "weighted avg       0.50      0.70      0.58       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 63.1262583732605 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.9325591504573822\n",
      "Samples above threshold: 81\n",
      "Acquired samples: 81\n",
      "Sampling duration: 3.6062114238739014 seconds\n",
      "New train size: 135\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6192, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4908, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4511, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4285, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4123, Accuracy: 0.8006, F1 Micro: 0.8879, F1 Macro: 0.8864\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3981, Accuracy: 0.8244, F1 Micro: 0.8991, F1 Macro: 0.8977\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.341, Accuracy: 0.8281, F1 Micro: 0.9006, F1 Macro: 0.8989\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.294, Accuracy: 0.8579, F1 Micro: 0.9159, F1 Macro: 0.9148\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.265, Accuracy: 0.8728, F1 Micro: 0.9239, F1 Macro: 0.9221\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2299, Accuracy: 0.8951, F1 Micro: 0.9368, F1 Macro: 0.936\n",
      "\n",
      "Aspect detection accuracy: 0.8951, F1 Micro: 0.9368, F1 Macro: 0.936\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.93      0.99      0.96       187\n",
      "     machine       0.91      0.98      0.95       175\n",
      "      others       0.83      0.95      0.88       158\n",
      "        part       0.91      0.97      0.94       158\n",
      "       price       0.86      1.00      0.93       192\n",
      "     service       0.91      1.00      0.95       191\n",
      "\n",
      "   micro avg       0.89      0.98      0.94      1061\n",
      "   macro avg       0.89      0.98      0.94      1061\n",
      "weighted avg       0.89      0.98      0.94      1061\n",
      " samples avg       0.90      0.99      0.93      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7227, Accuracy: 0.6845, F1 Micro: 0.6845, F1 Macro: 0.4064\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.6022, Accuracy: 0.6845, F1 Micro: 0.6845, F1 Macro: 0.4064\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5799, Accuracy: 0.6964, F1 Micro: 0.6964, F1 Macro: 0.4456\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4987, Accuracy: 0.7321, F1 Micro: 0.7321, F1 Macro: 0.5805\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3989, Accuracy: 0.8452, F1 Micro: 0.8452, F1 Macro: 0.7968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3188, Accuracy: 0.9226, F1 Micro: 0.9226, F1 Macro: 0.908\n",
      "Epoch 7/10, Train Loss: 0.1785, Accuracy: 0.881, F1 Micro: 0.881, F1 Macro: 0.8523\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1737, Accuracy: 0.9345, F1 Micro: 0.9345, F1 Macro: 0.923\n",
      "Epoch 9/10, Train Loss: 0.1395, Accuracy: 0.8929, F1 Micro: 0.8929, F1 Macro: 0.8688\n",
      "Epoch 10/10, Train Loss: 0.1195, Accuracy: 0.9107, F1 Micro: 0.9107, F1 Macro: 0.8926\n",
      "\n",
      "Sentiment analysis accuracy: 0.9345, F1 Micro: 0.9345, F1 Macro: 0.923\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.87      0.89        53\n",
      "    positive       0.94      0.97      0.95       115\n",
      "\n",
      "    accuracy                           0.93       168\n",
      "   macro avg       0.93      0.92      0.92       168\n",
      "weighted avg       0.93      0.93      0.93       168\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 135: Accuracy: 0.8897, F1 Micro: 0.8897, F1 Macro: 0.6999\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.94      0.99      0.97       181\n",
      "    positive       0.81      0.54      0.65        24\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.92      0.75      0.82       216\n",
      "weighted avg       0.93      0.93      0.92       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.44      0.61        16\n",
      "     neutral       0.91      0.98      0.95       167\n",
      "    positive       0.83      0.73      0.77        33\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.91      0.72      0.78       216\n",
      "weighted avg       0.90      0.90      0.89       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.75      0.72        12\n",
      "     neutral       0.83      0.95      0.89       152\n",
      "    positive       0.86      0.48      0.62        52\n",
      "\n",
      "    accuracy                           0.83       216\n",
      "   macro avg       0.80      0.73      0.74       216\n",
      "weighted avg       0.83      0.83      0.81       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.74      0.85        23\n",
      "     neutral       0.91      0.97      0.94       152\n",
      "    positive       0.83      0.73      0.78        41\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.91      0.81      0.86       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.87      1.00      0.93       186\n",
      "    positive       1.00      0.06      0.11        17\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.62      0.35      0.35       216\n",
      "weighted avg       0.82      0.87      0.81       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.36      0.53        14\n",
      "     neutral       0.91      1.00      0.95       185\n",
      "    positive       0.86      0.35      0.50        17\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.92      0.57      0.66       216\n",
      "weighted avg       0.91      0.91      0.89       216\n",
      "\n",
      "Total train time: 71.23225116729736 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.9526485204696655\n",
      "Samples above threshold: 73\n",
      "Acquired samples: 73\n",
      "Sampling duration: 4.522303104400635 seconds\n",
      "New train size: 208\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5877, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.501, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4877, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4527, Accuracy: 0.7984, F1 Micro: 0.8863, F1 Macro: 0.8846\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4162, Accuracy: 0.8192, F1 Micro: 0.8959, F1 Macro: 0.8939\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3563, Accuracy: 0.8512, F1 Micro: 0.912, F1 Macro: 0.9099\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3112, Accuracy: 0.8862, F1 Micro: 0.9309, F1 Macro: 0.9285\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2548, Accuracy: 0.9167, F1 Micro: 0.9493, F1 Macro: 0.9475\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2272, Accuracy: 0.9323, F1 Micro: 0.958, F1 Macro: 0.9562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1759, Accuracy: 0.9368, F1 Micro: 0.9609, F1 Macro: 0.9592\n",
      "\n",
      "Aspect detection accuracy: 0.9368, F1 Micro: 0.9609, F1 Macro: 0.9592\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.97      1.00      0.98       187\n",
      "     machine       0.92      0.99      0.95       175\n",
      "      others       0.86      0.94      0.90       158\n",
      "        part       0.93      0.97      0.95       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.95      1.00      0.97       191\n",
      "\n",
      "   micro avg       0.94      0.98      0.96      1061\n",
      "   macro avg       0.94      0.98      0.96      1061\n",
      "weighted avg       0.94      0.98      0.96      1061\n",
      " samples avg       0.94      0.99      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6131, Accuracy: 0.6652, F1 Micro: 0.6652, F1 Macro: 0.3995\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4915, Accuracy: 0.7376, F1 Micro: 0.7376, F1 Macro: 0.6252\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.299, Accuracy: 0.8959, F1 Micro: 0.8959, F1 Macro: 0.8836\n",
      "Epoch 4/10, Train Loss: 0.213, Accuracy: 0.8507, F1 Micro: 0.8507, F1 Macro: 0.824\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1754, Accuracy: 0.9186, F1 Micro: 0.9186, F1 Macro: 0.9108\n",
      "Epoch 6/10, Train Loss: 0.1326, Accuracy: 0.8824, F1 Micro: 0.8824, F1 Macro: 0.8651\n",
      "Epoch 7/10, Train Loss: 0.1317, Accuracy: 0.9095, F1 Micro: 0.9095, F1 Macro: 0.8997\n",
      "Epoch 8/10, Train Loss: 0.0712, Accuracy: 0.905, F1 Micro: 0.905, F1 Macro: 0.8944\n",
      "Epoch 9/10, Train Loss: 0.0884, Accuracy: 0.9005, F1 Micro: 0.9005, F1 Macro: 0.889\n",
      "Epoch 10/10, Train Loss: 0.0994, Accuracy: 0.8869, F1 Micro: 0.8869, F1 Macro: 0.8717\n",
      "\n",
      "Sentiment analysis accuracy: 0.9186, F1 Micro: 0.9186, F1 Macro: 0.9108\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.93      0.88        74\n",
      "    positive       0.96      0.91      0.94       147\n",
      "\n",
      "    accuracy                           0.92       221\n",
      "   macro avg       0.90      0.92      0.91       221\n",
      "weighted avg       0.92      0.92      0.92       221\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 208: Accuracy: 0.9267, F1 Micro: 0.9267, F1 Macro: 0.8492\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.97      1.00      0.99       181\n",
      "    positive       1.00      0.83      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.99      0.91      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.69      0.76        16\n",
      "     neutral       0.92      0.99      0.95       167\n",
      "    positive       0.91      0.64      0.75        33\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.89      0.77      0.82       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.56      0.75      0.64        12\n",
      "     neutral       0.86      0.94      0.90       152\n",
      "    positive       0.85      0.56      0.67        52\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.76      0.75      0.74       216\n",
      "weighted avg       0.84      0.84      0.83       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.87      0.85        23\n",
      "     neutral       0.93      0.97      0.95       152\n",
      "    positive       0.91      0.73      0.81        41\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.89      0.86      0.87       216\n",
      "weighted avg       0.92      0.92      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.57      0.70        14\n",
      "     neutral       0.95      1.00      0.97       185\n",
      "    positive       0.83      0.59      0.69        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.72      0.79       216\n",
      "weighted avg       0.94      0.94      0.93       216\n",
      "\n",
      "Total train time: 72.92255353927612 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.9533956944942474\n",
      "Samples above threshold: 66\n",
      "Acquired samples: 66\n",
      "Sampling duration: 4.846534490585327 seconds\n",
      "New train size: 274\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5722, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.499, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4657, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.44, Accuracy: 0.8118, F1 Micro: 0.8922, F1 Macro: 0.8906\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3755, Accuracy: 0.8504, F1 Micro: 0.9109, F1 Macro: 0.9087\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3332, Accuracy: 0.9025, F1 Micro: 0.9406, F1 Macro: 0.9386\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2709, Accuracy: 0.9375, F1 Micro: 0.9613, F1 Macro: 0.9599\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2162, Accuracy: 0.9412, F1 Micro: 0.9634, F1 Macro: 0.9618\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1711, Accuracy: 0.9501, F1 Micro: 0.969, F1 Macro: 0.9674\n",
      "Epoch 10/10, Train Loss: 0.1413, Accuracy: 0.9479, F1 Micro: 0.9674, F1 Macro: 0.9655\n",
      "\n",
      "Aspect detection accuracy: 0.9501, F1 Micro: 0.969, F1 Macro: 0.9674\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.94      0.99      0.96       175\n",
      "      others       0.88      0.96      0.92       158\n",
      "        part       0.93      0.97      0.95       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.95      0.99      0.97      1061\n",
      "   macro avg       0.95      0.99      0.97      1061\n",
      "weighted avg       0.95      0.99      0.97      1061\n",
      " samples avg       0.95      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6753, Accuracy: 0.6567, F1 Micro: 0.6567, F1 Macro: 0.3964\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4893, Accuracy: 0.7725, F1 Micro: 0.7725, F1 Macro: 0.7073\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3324, Accuracy: 0.897, F1 Micro: 0.897, F1 Macro: 0.8904\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2174, Accuracy: 0.9227, F1 Micro: 0.9227, F1 Macro: 0.9167\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1376, Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.9239\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1419, Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.9234\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0996, Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.9239\n",
      "Epoch 8/10, Train Loss: 0.0828, Accuracy: 0.9227, F1 Micro: 0.9227, F1 Macro: 0.9127\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0985, Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.9239\n",
      "Epoch 10/10, Train Loss: 0.0693, Accuracy: 0.9185, F1 Micro: 0.9185, F1 Macro: 0.9082\n",
      "\n",
      "Sentiment analysis accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.9239\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.91      0.90        79\n",
      "    positive       0.95      0.94      0.95       154\n",
      "\n",
      "    accuracy                           0.93       233\n",
      "   macro avg       0.92      0.93      0.92       233\n",
      "weighted avg       0.93      0.93      0.93       233\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 274: Accuracy: 0.9406, F1 Micro: 0.9406, F1 Macro: 0.8775\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.88      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.93      0.99      0.96       167\n",
      "    positive       0.88      0.70      0.78        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.91      0.81      0.86       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.89      0.97      0.92       152\n",
      "    positive       0.89      0.65      0.76        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.84      0.79      0.81       216\n",
      "weighted avg       0.88      0.88      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.87      0.85        23\n",
      "     neutral       0.93      0.97      0.95       152\n",
      "    positive       0.91      0.73      0.81        41\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.89      0.86      0.87       216\n",
      "weighted avg       0.92      0.92      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.88      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.88      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 84.15654015541077 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.10158747434616096\n",
      "Samples above threshold: 59\n",
      "Acquired samples: 59\n",
      "Sampling duration: 4.865896463394165 seconds\n",
      "New train size: 333\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5685, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4831, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.466, Accuracy: 0.8006, F1 Micro: 0.8875, F1 Macro: 0.8859\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3988, Accuracy: 0.8423, F1 Micro: 0.9078, F1 Macro: 0.9059\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3346, Accuracy: 0.9025, F1 Micro: 0.9404, F1 Macro: 0.9384\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2713, Accuracy: 0.9345, F1 Micro: 0.9593, F1 Macro: 0.9576\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2275, Accuracy: 0.9449, F1 Micro: 0.9655, F1 Macro: 0.9641\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1691, Accuracy: 0.9479, F1 Micro: 0.9674, F1 Macro: 0.9658\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1389, Accuracy: 0.9516, F1 Micro: 0.9698, F1 Macro: 0.9681\n",
      "Epoch 10/10, Train Loss: 0.1216, Accuracy: 0.9509, F1 Micro: 0.9691, F1 Macro: 0.967\n",
      "\n",
      "Aspect detection accuracy: 0.9516, F1 Micro: 0.9698, F1 Macro: 0.9681\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.93      0.99      0.96       175\n",
      "      others       0.89      0.95      0.92       158\n",
      "        part       0.94      0.97      0.96       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.95      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.95      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6339, Accuracy: 0.7231, F1 Micro: 0.7231, F1 Macro: 0.5746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4926, Accuracy: 0.905, F1 Micro: 0.905, F1 Macro: 0.8971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3119, Accuracy: 0.9256, F1 Micro: 0.9256, F1 Macro: 0.9175\n",
      "Epoch 4/10, Train Loss: 0.2609, Accuracy: 0.9215, F1 Micro: 0.9215, F1 Macro: 0.9092\n",
      "Epoch 5/10, Train Loss: 0.2169, Accuracy: 0.9174, F1 Micro: 0.9174, F1 Macro: 0.9048\n",
      "Epoch 6/10, Train Loss: 0.1385, Accuracy: 0.9215, F1 Micro: 0.9215, F1 Macro: 0.915\n",
      "Epoch 7/10, Train Loss: 0.1468, Accuracy: 0.9215, F1 Micro: 0.9215, F1 Macro: 0.9098\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1202, Accuracy: 0.9298, F1 Micro: 0.9298, F1 Macro: 0.9231\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1532, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9362\n",
      "Epoch 10/10, Train Loss: 0.0709, Accuracy: 0.938, F1 Micro: 0.938, F1 Macro: 0.931\n",
      "\n",
      "Sentiment analysis accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9362\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        80\n",
      "    positive       0.98      0.93      0.96       162\n",
      "\n",
      "    accuracy                           0.94       242\n",
      "   macro avg       0.93      0.95      0.94       242\n",
      "weighted avg       0.95      0.94      0.94       242\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 333: Accuracy: 0.9429, F1 Micro: 0.9429, F1 Macro: 0.8899\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.94      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.69      0.79        16\n",
      "     neutral       0.93      0.99      0.96       167\n",
      "    positive       0.88      0.70      0.78        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.91      0.79      0.84       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.89      0.95      0.92       152\n",
      "    positive       0.84      0.69      0.76        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.85      0.80      0.82       216\n",
      "weighted avg       0.87      0.88      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.94      0.97      0.95       152\n",
      "    positive       0.91      0.73      0.81        41\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.89      0.89      0.88       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.93      0.90        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.90      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 85.04770827293396 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0700751543045044\n",
      "Samples above threshold: 54\n",
      "Acquired samples: 54\n",
      "Sampling duration: 4.695023536682129 seconds\n",
      "New train size: 387\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5571, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4732, Accuracy: 0.7932, F1 Micro: 0.8842, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4404, Accuracy: 0.8237, F1 Micro: 0.8994, F1 Macro: 0.8981\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3632, Accuracy: 0.9018, F1 Micro: 0.9398, F1 Macro: 0.9369\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2699, Accuracy: 0.9435, F1 Micro: 0.9648, F1 Macro: 0.9634\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.215, Accuracy: 0.9524, F1 Micro: 0.9704, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1643, Accuracy: 0.9546, F1 Micro: 0.9717, F1 Macro: 0.9703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1231, Accuracy: 0.9554, F1 Micro: 0.972, F1 Macro: 0.9706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1079, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0891, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9729\n",
      "\n",
      "Aspect detection accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9729\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.97      0.97       175\n",
      "      others       0.89      0.96      0.92       158\n",
      "        part       0.96      0.98      0.97       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6302, Accuracy: 0.8182, F1 Micro: 0.8182, F1 Macro: 0.7963\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4889, Accuracy: 0.8933, F1 Micro: 0.8933, F1 Macro: 0.886\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3057, Accuracy: 0.9209, F1 Micro: 0.9209, F1 Macro: 0.9142\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2385, Accuracy: 0.9565, F1 Micro: 0.9565, F1 Macro: 0.9514\n",
      "Epoch 5/10, Train Loss: 0.2234, Accuracy: 0.9526, F1 Micro: 0.9526, F1 Macro: 0.9474\n",
      "Epoch 6/10, Train Loss: 0.1835, Accuracy: 0.9368, F1 Micro: 0.9368, F1 Macro: 0.9307\n",
      "Epoch 7/10, Train Loss: 0.1633, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9317\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1361, Accuracy: 0.9605, F1 Micro: 0.9605, F1 Macro: 0.9554\n",
      "Epoch 9/10, Train Loss: 0.1033, Accuracy: 0.9486, F1 Micro: 0.9486, F1 Macro: 0.9408\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0807, Accuracy: 0.9605, F1 Micro: 0.9605, F1 Macro: 0.9557\n",
      "\n",
      "Sentiment analysis accuracy: 0.9605, F1 Micro: 0.9605, F1 Macro: 0.9557\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.96      0.94        83\n",
      "    positive       0.98      0.96      0.97       170\n",
      "\n",
      "    accuracy                           0.96       253\n",
      "   macro avg       0.95      0.96      0.96       253\n",
      "weighted avg       0.96      0.96      0.96       253\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 387: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9179\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.97      0.97       167\n",
      "    positive       0.84      0.82      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.90      0.95      0.92       152\n",
      "    positive       0.84      0.71      0.77        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.88      0.81      0.84       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.96      0.98      0.97       152\n",
      "    positive       0.94      0.78      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.92      0.91       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.97      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.97      0.86      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 94.03202366828918 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.03343925476074221\n",
      "Samples above threshold: 48\n",
      "Acquired samples: 48\n",
      "Sampling duration: 4.327348947525024 seconds\n",
      "New train size: 435\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5528, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4961, Accuracy: 0.7984, F1 Micro: 0.8866, F1 Macro: 0.8851\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4177, Accuracy: 0.8504, F1 Micro: 0.9113, F1 Macro: 0.9095\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3359, Accuracy: 0.9115, F1 Micro: 0.9454, F1 Macro: 0.9432\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2467, Accuracy: 0.9472, F1 Micro: 0.967, F1 Macro: 0.9653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1929, Accuracy: 0.9568, F1 Micro: 0.9731, F1 Macro: 0.9721\n",
      "Epoch 7/10, Train Loss: 0.1536, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9717\n",
      "Epoch 8/10, Train Loss: 0.1221, Accuracy: 0.9561, F1 Micro: 0.9724, F1 Macro: 0.971\n",
      "Epoch 9/10, Train Loss: 0.1036, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.086, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9727\n",
      "\n",
      "Aspect detection accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9727\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.91      0.93      0.92       158\n",
      "        part       0.96      0.98      0.97       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6389, Accuracy: 0.7765, F1 Micro: 0.7765, F1 Macro: 0.7129\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4012, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9348\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3121, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9393\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1837, Accuracy: 0.9608, F1 Micro: 0.9608, F1 Macro: 0.9564\n",
      "Epoch 5/10, Train Loss: 0.1793, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.915\n",
      "Epoch 6/10, Train Loss: 0.1378, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9332\n",
      "Epoch 7/10, Train Loss: 0.1398, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9313\n",
      "Epoch 8/10, Train Loss: 0.0934, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9396\n",
      "Epoch 9/10, Train Loss: 0.095, Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9474\n",
      "Epoch 10/10, Train Loss: 0.108, Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9467\n",
      "\n",
      "Sentiment analysis accuracy: 0.9608, F1 Micro: 0.9608, F1 Macro: 0.9564\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94        84\n",
      "    positive       0.99      0.95      0.97       171\n",
      "\n",
      "    accuracy                           0.96       255\n",
      "   macro avg       0.95      0.96      0.96       255\n",
      "weighted avg       0.96      0.96      0.96       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 435: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9185\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.88      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.91      0.93      0.92       152\n",
      "    positive       0.81      0.75      0.78        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.85      0.84      0.85       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.96      0.98      0.97       152\n",
      "    positive       0.94      0.78      0.85        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.92      0.91       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.97      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.84      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 89.2213294506073 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.04879755973815918\n",
      "Samples above threshold: 43\n",
      "Acquired samples: 43\n",
      "Sampling duration: 4.049647331237793 seconds\n",
      "New train size: 478\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5541, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4802, Accuracy: 0.8021, F1 Micro: 0.8883, F1 Macro: 0.8869\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4027, Accuracy: 0.8661, F1 Micro: 0.9201, F1 Macro: 0.918\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3088, Accuracy: 0.9338, F1 Micro: 0.959, F1 Macro: 0.9575\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2276, Accuracy: 0.9561, F1 Micro: 0.9728, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1679, Accuracy: 0.9568, F1 Micro: 0.9731, F1 Macro: 0.9721\n",
      "Epoch 7/10, Train Loss: 0.136, Accuracy: 0.9561, F1 Micro: 0.9726, F1 Macro: 0.9712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1053, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0871, Accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9773\n",
      "Epoch 10/10, Train Loss: 0.0757, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9761\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.90      0.96      0.93       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6421, Accuracy: 0.8088, F1 Micro: 0.8088, F1 Macro: 0.77\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4162, Accuracy: 0.9482, F1 Micro: 0.9482, F1 Macro: 0.9427\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2837, Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9472\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2012, Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9478\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1291, Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9475\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1295, Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9472\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0921, Accuracy: 0.9602, F1 Micro: 0.9602, F1 Macro: 0.9558\n",
      "Epoch 8/10, Train Loss: 0.0908, Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.946\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0958, Accuracy: 0.9641, F1 Micro: 0.9641, F1 Macro: 0.9601\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0885, Accuracy: 0.9641, F1 Micro: 0.9641, F1 Macro: 0.9603\n",
      "\n",
      "Sentiment analysis accuracy: 0.9641, F1 Micro: 0.9641, F1 Macro: 0.9603\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        85\n",
      "    positive       0.98      0.96      0.97       166\n",
      "\n",
      "    accuracy                           0.96       251\n",
      "   macro avg       0.96      0.96      0.96       251\n",
      "weighted avg       0.96      0.96      0.96       251\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 478: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9281\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.89      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.75      0.86        12\n",
      "     neutral       0.90      0.96      0.93       152\n",
      "    positive       0.87      0.75      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.92      0.82      0.86       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.96      0.99      0.98       152\n",
      "    positive       1.00      0.78      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.94      0.92      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 104.66165781021118 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.022867143154144287\n",
      "Samples above threshold: 39\n",
      "Acquired samples: 39\n",
      "Sampling duration: 3.827589750289917 seconds\n",
      "New train size: 517\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5431, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4754, Accuracy: 0.808, F1 Micro: 0.8909, F1 Macro: 0.8895\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3824, Accuracy: 0.9129, F1 Micro: 0.9473, F1 Macro: 0.9462\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2723, Accuracy: 0.9531, F1 Micro: 0.971, F1 Macro: 0.9701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1955, Accuracy: 0.9554, F1 Micro: 0.9722, F1 Macro: 0.9707\n",
      "Epoch 6/10, Train Loss: 0.148, Accuracy: 0.9546, F1 Micro: 0.9716, F1 Macro: 0.9699\n",
      "Epoch 7/10, Train Loss: 0.1109, Accuracy: 0.9554, F1 Micro: 0.972, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0944, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0779, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9749\n",
      "Epoch 10/10, Train Loss: 0.0639, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9744\n",
      "\n",
      "Aspect detection accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9749\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.90      0.96      0.93       158\n",
      "        part       0.97      0.98      0.97       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.97      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5884, Accuracy: 0.876, F1 Micro: 0.876, F1 Macro: 0.8622\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3449, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.9022\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3046, Accuracy: 0.948, F1 Micro: 0.948, F1 Macro: 0.9426\n",
      "Epoch 4/10, Train Loss: 0.2037, Accuracy: 0.932, F1 Micro: 0.932, F1 Macro: 0.9221\n",
      "Epoch 5/10, Train Loss: 0.2218, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9372\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.166, Accuracy: 0.96, F1 Micro: 0.96, F1 Macro: 0.9562\n",
      "Epoch 7/10, Train Loss: 0.1332, Accuracy: 0.94, F1 Micro: 0.94, F1 Macro: 0.9351\n",
      "Epoch 8/10, Train Loss: 0.1149, Accuracy: 0.952, F1 Micro: 0.952, F1 Macro: 0.9474\n",
      "Epoch 9/10, Train Loss: 0.0985, Accuracy: 0.952, F1 Micro: 0.952, F1 Macro: 0.9468\n",
      "Epoch 10/10, Train Loss: 0.1095, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9185\n",
      "\n",
      "Sentiment analysis accuracy: 0.96, F1 Micro: 0.96, F1 Macro: 0.9562\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94        85\n",
      "    positive       0.99      0.95      0.97       165\n",
      "\n",
      "    accuracy                           0.96       250\n",
      "   macro avg       0.95      0.96      0.96       250\n",
      "weighted avg       0.96      0.96      0.96       250\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 517: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9197\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.88      0.70      0.78        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.85      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.91      0.95      0.93       152\n",
      "    positive       0.84      0.73      0.78        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.86      0.81      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.98      0.97       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.93      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.90      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 96.09170198440552 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.025971746444702157\n",
      "Samples above threshold: 35\n",
      "Acquired samples: 23\n",
      "Sampling duration: 3.591322898864746 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5558, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4607, Accuracy: 0.7984, F1 Micro: 0.8868, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3714, Accuracy: 0.9077, F1 Micro: 0.944, F1 Macro: 0.9429\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2726, Accuracy: 0.9546, F1 Micro: 0.9719, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1977, Accuracy: 0.9583, F1 Micro: 0.9741, F1 Macro: 0.9728\n",
      "Epoch 6/10, Train Loss: 0.15, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1116, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0951, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9749\n",
      "Epoch 9/10, Train Loss: 0.0784, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0659, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9759\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9759\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      0.99      0.97       175\n",
      "      others       0.90      0.95      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6104, Accuracy: 0.852, F1 Micro: 0.852, F1 Macro: 0.8282\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.347, Accuracy: 0.932, F1 Micro: 0.932, F1 Macro: 0.9253\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2721, Accuracy: 0.952, F1 Micro: 0.952, F1 Macro: 0.9468\n",
      "Epoch 4/10, Train Loss: 0.2009, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.938\n",
      "Epoch 5/10, Train Loss: 0.1514, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9215\n",
      "Epoch 6/10, Train Loss: 0.1558, Accuracy: 0.948, F1 Micro: 0.948, F1 Macro: 0.9416\n",
      "Epoch 7/10, Train Loss: 0.1114, Accuracy: 0.936, F1 Micro: 0.936, F1 Macro: 0.9302\n",
      "Epoch 8/10, Train Loss: 0.0744, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9207\n",
      "Epoch 9/10, Train Loss: 0.0885, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9173\n",
      "Epoch 10/10, Train Loss: 0.0732, Accuracy: 0.932, F1 Micro: 0.932, F1 Macro: 0.9257\n",
      "\n",
      "Sentiment analysis accuracy: 0.952, F1 Micro: 0.952, F1 Macro: 0.9468\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.94      0.93        85\n",
      "    positive       0.97      0.96      0.96       165\n",
      "\n",
      "    accuracy                           0.95       250\n",
      "   macro avg       0.94      0.95      0.95       250\n",
      "weighted avg       0.95      0.95      0.95       250\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9177\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.94      0.99      0.97       167\n",
      "    positive       0.92      0.70      0.79        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.83      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.91      0.95      0.93       152\n",
      "    positive       0.81      0.73      0.77        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.87      0.81      0.84       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.92      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 98.15249633789062 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.03917145133018494\n",
      "Samples above threshold: 33\n",
      "Acquired samples: 33\n",
      "Sampling duration: 3.4539425373077393 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5406, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4663, Accuracy: 0.8058, F1 Micro: 0.8893, F1 Macro: 0.8874\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3714, Accuracy: 0.9092, F1 Micro: 0.945, F1 Macro: 0.9436\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.26, Accuracy: 0.9561, F1 Micro: 0.9728, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1886, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1417, Accuracy: 0.9606, F1 Micro: 0.9754, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1035, Accuracy: 0.9621, F1 Micro: 0.9763, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0902, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9753\n",
      "Epoch 9/10, Train Loss: 0.0689, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9746\n",
      "Epoch 10/10, Train Loss: 0.0619, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9734\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9753\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.90      0.95      0.93       158\n",
      "        part       0.96      0.99      0.97       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6002, Accuracy: 0.8775, F1 Micro: 0.8775, F1 Macro: 0.8578\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3022, Accuracy: 0.9407, F1 Micro: 0.9407, F1 Macro: 0.9352\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2608, Accuracy: 0.9565, F1 Micro: 0.9565, F1 Macro: 0.952\n",
      "Epoch 4/10, Train Loss: 0.2044, Accuracy: 0.9447, F1 Micro: 0.9447, F1 Macro: 0.9396\n",
      "Epoch 5/10, Train Loss: 0.1617, Accuracy: 0.9486, F1 Micro: 0.9486, F1 Macro: 0.9438\n",
      "Epoch 6/10, Train Loss: 0.1155, Accuracy: 0.9486, F1 Micro: 0.9486, F1 Macro: 0.9415\n",
      "Epoch 7/10, Train Loss: 0.0843, Accuracy: 0.9526, F1 Micro: 0.9526, F1 Macro: 0.9477\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.092, Accuracy: 0.9565, F1 Micro: 0.9565, F1 Macro: 0.9525\n",
      "Epoch 9/10, Train Loss: 0.0779, Accuracy: 0.9526, F1 Micro: 0.9526, F1 Macro: 0.9468\n",
      "Epoch 10/10, Train Loss: 0.0502, Accuracy: 0.9447, F1 Micro: 0.9447, F1 Macro: 0.9376\n",
      "\n",
      "Sentiment analysis accuracy: 0.9565, F1 Micro: 0.9565, F1 Macro: 0.9525\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.99      0.94        85\n",
      "    positive       0.99      0.94      0.97       168\n",
      "\n",
      "    accuracy                           0.96       253\n",
      "   macro avg       0.94      0.96      0.95       253\n",
      "weighted avg       0.96      0.96      0.96       253\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9186\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.94      0.88        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.88      0.70      0.78        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.87      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.91      0.95      0.93       152\n",
      "    positive       0.83      0.75      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.88      0.82      0.84       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.96      0.99      0.97       152\n",
      "    positive       0.97      0.78      0.86        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.92      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.90      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 103.05384707450867 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.020868301391601562\n",
      "Samples above threshold: 30\n",
      "Acquired samples: 30\n",
      "Sampling duration: 3.1969118118286133 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5419, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4602, Accuracy: 0.8348, F1 Micro: 0.9044, F1 Macro: 0.9029\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3431, Accuracy: 0.9323, F1 Micro: 0.9586, F1 Macro: 0.9571\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2425, Accuracy: 0.9628, F1 Micro: 0.9769, F1 Macro: 0.9759\n",
      "Epoch 5/10, Train Loss: 0.1772, Accuracy: 0.9606, F1 Micro: 0.9754, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1328, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9759\n",
      "Epoch 7/10, Train Loss: 0.1077, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9749\n",
      "Epoch 8/10, Train Loss: 0.0899, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9736\n",
      "Epoch 9/10, Train Loss: 0.0719, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9737\n",
      "Epoch 10/10, Train Loss: 0.0614, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9755\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9759\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.90      0.96      0.93       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5455, Accuracy: 0.8937, F1 Micro: 0.8937, F1 Macro: 0.8803\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2852, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9173\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1978, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9301\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1641, Accuracy: 0.9528, F1 Micro: 0.9528, F1 Macro: 0.9466\n",
      "Epoch 5/10, Train Loss: 0.129, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9255\n",
      "Epoch 6/10, Train Loss: 0.0979, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9366\n",
      "Epoch 7/10, Train Loss: 0.1179, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9222\n",
      "Epoch 8/10, Train Loss: 0.0687, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9209\n",
      "Epoch 9/10, Train Loss: 0.0667, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.937\n",
      "Epoch 10/10, Train Loss: 0.075, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9251\n",
      "\n",
      "Sentiment analysis accuracy: 0.9528, F1 Micro: 0.9528, F1 Macro: 0.9466\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93        82\n",
      "    positive       0.98      0.95      0.96       172\n",
      "\n",
      "    accuracy                           0.95       254\n",
      "   macro avg       0.94      0.95      0.95       254\n",
      "weighted avg       0.95      0.95      0.95       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9168\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.98      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.91      0.95      0.93       152\n",
      "    positive       0.85      0.75      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.88      0.82      0.85       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.96      0.88        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.92      0.85      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 100.76774597167969 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.027663826942443848\n",
      "Samples above threshold: 27\n",
      "Acquired samples: 27\n",
      "Sampling duration: 2.963588237762451 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.541, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4399, Accuracy: 0.8609, F1 Micro: 0.9176, F1 Macro: 0.9157\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3283, Accuracy: 0.9457, F1 Micro: 0.9663, F1 Macro: 0.9648\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2262, Accuracy: 0.9531, F1 Micro: 0.9707, F1 Macro: 0.969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1671, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9742\n",
      "Epoch 6/10, Train Loss: 0.1227, Accuracy: 0.9606, F1 Micro: 0.9754, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0976, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0787, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9762\n",
      "Epoch 9/10, Train Loss: 0.0649, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9744\n",
      "Epoch 10/10, Train Loss: 0.0579, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9733\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      0.99      0.96       175\n",
      "      others       0.90      0.97      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.98      1061\n",
      "weighted avg       0.96      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5734, Accuracy: 0.9016, F1 Micro: 0.9016, F1 Macro: 0.8953\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3, Accuracy: 0.9426, F1 Micro: 0.9426, F1 Macro: 0.9375\n",
      "Epoch 3/10, Train Loss: 0.1827, Accuracy: 0.9221, F1 Micro: 0.9221, F1 Macro: 0.9114\n",
      "Epoch 4/10, Train Loss: 0.1781, Accuracy: 0.9139, F1 Micro: 0.9139, F1 Macro: 0.909\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1626, Accuracy: 0.9426, F1 Micro: 0.9426, F1 Macro: 0.9378\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1033, Accuracy: 0.9426, F1 Micro: 0.9426, F1 Macro: 0.9378\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1041, Accuracy: 0.9631, F1 Micro: 0.9631, F1 Macro: 0.9593\n",
      "Epoch 8/10, Train Loss: 0.0925, Accuracy: 0.9467, F1 Micro: 0.9467, F1 Macro: 0.9421\n",
      "Epoch 9/10, Train Loss: 0.0645, Accuracy: 0.9467, F1 Micro: 0.9467, F1 Macro: 0.9408\n",
      "Epoch 10/10, Train Loss: 0.071, Accuracy: 0.959, F1 Micro: 0.959, F1 Macro: 0.9546\n",
      "\n",
      "Sentiment analysis accuracy: 0.9631, F1 Micro: 0.9631, F1 Macro: 0.9593\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.95      0.95        84\n",
      "    positive       0.97      0.97      0.97       160\n",
      "\n",
      "    accuracy                           0.96       244\n",
      "   macro avg       0.96      0.96      0.96       244\n",
      "weighted avg       0.96      0.96      0.96       244\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.9224\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.88      0.70      0.78        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.92      0.83      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.90      0.97      0.94       152\n",
      "    positive       0.88      0.71      0.79        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.89      0.81      0.85       216\n",
      "weighted avg       0.90      0.90      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.89      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 109.28295588493347 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.015311688184738166\n",
      "Samples above threshold: 24\n",
      "Acquired samples: 18\n",
      "Sampling duration: 2.8112587928771973 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5274, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4371, Accuracy: 0.869, F1 Micro: 0.9214, F1 Macro: 0.9196\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3135, Accuracy: 0.9412, F1 Micro: 0.9634, F1 Macro: 0.9609\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2173, Accuracy: 0.9598, F1 Micro: 0.975, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1572, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.974\n",
      "Epoch 6/10, Train Loss: 0.1171, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0919, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9764\n",
      "Epoch 8/10, Train Loss: 0.0776, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0644, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0553, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9779\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9779\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.90      0.97      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5707, Accuracy: 0.874, F1 Micro: 0.874, F1 Macro: 0.8594\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2922, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9158\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1908, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9343\n",
      "Epoch 4/10, Train Loss: 0.1483, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9218\n",
      "Epoch 5/10, Train Loss: 0.1337, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9255\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1033, Accuracy: 0.9488, F1 Micro: 0.9488, F1 Macro: 0.9433\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0863, Accuracy: 0.9488, F1 Micro: 0.9488, F1 Macro: 0.9436\n",
      "Epoch 8/10, Train Loss: 0.0973, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9315\n",
      "Epoch 9/10, Train Loss: 0.0745, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9388\n",
      "Epoch 10/10, Train Loss: 0.0534, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9181\n",
      "\n",
      "Sentiment analysis accuracy: 0.9488, F1 Micro: 0.9488, F1 Macro: 0.9436\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.93        86\n",
      "    positive       0.98      0.95      0.96       168\n",
      "\n",
      "    accuracy                           0.95       254\n",
      "   macro avg       0.94      0.95      0.94       254\n",
      "weighted avg       0.95      0.95      0.95       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.9222\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.91      0.88      0.89        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.88      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.90      0.97      0.93       152\n",
      "    positive       0.88      0.71      0.79        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.90      0.84      0.86       216\n",
      "weighted avg       0.90      0.90      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.80      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 112.65809917449951 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.012413978576660156\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.743696689605713 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5339, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4339, Accuracy: 0.8973, F1 Micro: 0.9383, F1 Macro: 0.9367\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3023, Accuracy: 0.9479, F1 Micro: 0.9676, F1 Macro: 0.9665\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2044, Accuracy: 0.9621, F1 Micro: 0.9764, F1 Macro: 0.9755\n",
      "Epoch 5/10, Train Loss: 0.1467, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1075, Accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9784\n",
      "Epoch 7/10, Train Loss: 0.0858, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9729\n",
      "Epoch 8/10, Train Loss: 0.0712, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9756\n",
      "Epoch 9/10, Train Loss: 0.0583, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "Epoch 10/10, Train Loss: 0.0533, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9747\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9784\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.99      0.98       175\n",
      "      others       0.90      0.97      0.94       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5439, Accuracy: 0.902, F1 Micro: 0.902, F1 Macro: 0.8935\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3102, Accuracy: 0.9255, F1 Micro: 0.9255, F1 Macro: 0.9159\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2098, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9348\n",
      "Epoch 4/10, Train Loss: 0.1172, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9306\n",
      "Epoch 5/10, Train Loss: 0.1263, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.931\n",
      "Epoch 6/10, Train Loss: 0.0857, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9228\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0945, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9379\n",
      "Epoch 8/10, Train Loss: 0.0749, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9344\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0611, Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9471\n",
      "Epoch 10/10, Train Loss: 0.0536, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9191\n",
      "\n",
      "Sentiment analysis accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9471\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93        83\n",
      "    positive       0.98      0.95      0.96       172\n",
      "\n",
      "    accuracy                           0.95       255\n",
      "   macro avg       0.94      0.95      0.95       255\n",
      "weighted avg       0.95      0.95      0.95       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.9614, F1 Micro: 0.9614, F1 Macro: 0.9251\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.96      0.99      0.98       167\n",
      "    positive       0.90      0.85      0.88        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.88      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.90      0.97      0.94       152\n",
      "    positive       0.90      0.73      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.90      0.82      0.85       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.97      0.88      0.92        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.95      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 110.75138473510742 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.01938498020172119\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.5899548530578613 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5401, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4381, Accuracy: 0.8705, F1 Micro: 0.9231, F1 Macro: 0.9215\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.309, Accuracy: 0.9501, F1 Micro: 0.9692, F1 Macro: 0.968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2002, Accuracy: 0.9635, F1 Micro: 0.9773, F1 Macro: 0.9761\n",
      "Epoch 5/10, Train Loss: 0.1471, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9728\n",
      "Epoch 6/10, Train Loss: 0.1133, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.973\n",
      "Epoch 7/10, Train Loss: 0.0946, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9729\n",
      "Epoch 8/10, Train Loss: 0.0788, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9749\n",
      "Epoch 9/10, Train Loss: 0.0597, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0547, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9769\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.92      0.94      0.93       158\n",
      "        part       0.96      0.99      0.97       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5133, Accuracy: 0.9038, F1 Micro: 0.9038, F1 Macro: 0.8911\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2754, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.9092\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.238, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9324\n",
      "Epoch 4/10, Train Loss: 0.1839, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.921\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1712, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9364\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.131, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9358\n",
      "Epoch 7/10, Train Loss: 0.1069, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9327\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0717, Accuracy: 0.9538, F1 Micro: 0.9538, F1 Macro: 0.9482\n",
      "Epoch 9/10, Train Loss: 0.0698, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9276\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0671, Accuracy: 0.9538, F1 Micro: 0.9538, F1 Macro: 0.9485\n",
      "\n",
      "Sentiment analysis accuracy: 0.9538, F1 Micro: 0.9538, F1 Macro: 0.9485\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.94      0.93        87\n",
      "    positive       0.97      0.96      0.97       173\n",
      "\n",
      "    accuracy                           0.95       260\n",
      "   macro avg       0.95      0.95      0.95       260\n",
      "weighted avg       0.95      0.95      0.95       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.9244\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.89      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.92      0.94      0.93       152\n",
      "    positive       0.80      0.75      0.77        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.85      0.84      0.85       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.96      0.99      0.97       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 115.81811547279358 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.010279238224029541\n",
      "Samples above threshold: 17\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.4065628051757812 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.536, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4245, Accuracy: 0.8929, F1 Micro: 0.9358, F1 Macro: 0.9344\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2783, Accuracy: 0.9516, F1 Micro: 0.97, F1 Macro: 0.9685\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1956, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9752\n",
      "Epoch 5/10, Train Loss: 0.139, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.972\n",
      "Epoch 6/10, Train Loss: 0.1096, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9711\n",
      "Epoch 7/10, Train Loss: 0.0866, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9748\n",
      "Epoch 8/10, Train Loss: 0.0692, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.972\n",
      "Epoch 9/10, Train Loss: 0.0581, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9723\n",
      "Epoch 10/10, Train Loss: 0.0491, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9752\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.94      1.00      0.97       175\n",
      "      others       0.91      0.92      0.92       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5409, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8932\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2839, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.927\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1644, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9235\n",
      "Epoch 4/10, Train Loss: 0.1512, Accuracy: 0.9297, F1 Micro: 0.9297, F1 Macro: 0.9187\n",
      "Epoch 5/10, Train Loss: 0.0923, Accuracy: 0.9219, F1 Micro: 0.9219, F1 Macro: 0.9143\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1205, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.927\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0653, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9249\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0959, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9295\n",
      "Epoch 9/10, Train Loss: 0.0904, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9254\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0642, Accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9422\n",
      "\n",
      "Sentiment analysis accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9422\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.93      0.92        83\n",
      "    positive       0.97      0.96      0.96       173\n",
      "\n",
      "    accuracy                           0.95       256\n",
      "   macro avg       0.94      0.94      0.94       256\n",
      "weighted avg       0.95      0.95      0.95       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9144\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.69      0.79        16\n",
      "     neutral       0.94      1.00      0.97       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.80      0.86       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.92      0.93      0.92       152\n",
      "    positive       0.77      0.77      0.77        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.86      0.82      0.84       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.95      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 115.75862455368042 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.026294052600860596\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.2887916564941406 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5333, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4206, Accuracy: 0.9033, F1 Micro: 0.9408, F1 Macro: 0.9383\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2687, Accuracy: 0.9561, F1 Micro: 0.9728, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1826, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1315, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1018, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9762\n",
      "Epoch 7/10, Train Loss: 0.085, Accuracy: 0.9606, F1 Micro: 0.9749, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0703, Accuracy: 0.968, F1 Micro: 0.98, F1 Macro: 0.9789\n",
      "Epoch 9/10, Train Loss: 0.0604, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9747\n",
      "Epoch 10/10, Train Loss: 0.0506, Accuracy: 0.9658, F1 Micro: 0.9783, F1 Macro: 0.9765\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.98, F1 Macro: 0.9789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.90      0.99      0.94       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5679, Accuracy: 0.9206, F1 Micro: 0.9206, F1 Macro: 0.9117\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.277, Accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9425\n",
      "Epoch 3/10, Train Loss: 0.2069, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.935\n",
      "Epoch 4/10, Train Loss: 0.1459, Accuracy: 0.9325, F1 Micro: 0.9325, F1 Macro: 0.9264\n",
      "Epoch 5/10, Train Loss: 0.1243, Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9386\n",
      "Epoch 6/10, Train Loss: 0.133, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.9226\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1066, Accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9434\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1021, Accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9434\n",
      "Epoch 9/10, Train Loss: 0.0705, Accuracy: 0.9365, F1 Micro: 0.9365, F1 Macro: 0.9305\n",
      "Epoch 10/10, Train Loss: 0.076, Accuracy: 0.9444, F1 Micro: 0.9444, F1 Macro: 0.9382\n",
      "\n",
      "Sentiment analysis accuracy: 0.9484, F1 Micro: 0.9484, F1 Macro: 0.9434\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.98      0.93        84\n",
      "    positive       0.99      0.93      0.96       168\n",
      "\n",
      "    accuracy                           0.95       252\n",
      "   macro avg       0.93      0.96      0.94       252\n",
      "weighted avg       0.95      0.95      0.95       252\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9189\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      1.00      0.96        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.96      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.88      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.67      0.73        12\n",
      "     neutral       0.90      0.99      0.94       152\n",
      "    positive       0.95      0.71      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.88      0.79      0.83       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.94      0.80      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.92      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 116.55488085746765 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.011599302291870117\n",
      "Samples above threshold: 12\n",
      "Acquired samples: 8\n",
      "Sampling duration: 2.1032116413116455 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5323, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.416, Accuracy: 0.9144, F1 Micro: 0.9481, F1 Macro: 0.9464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2712, Accuracy: 0.9501, F1 Micro: 0.969, F1 Macro: 0.9673\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1789, Accuracy: 0.9606, F1 Micro: 0.9754, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1319, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9771\n",
      "Epoch 6/10, Train Loss: 0.1024, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9747\n",
      "Epoch 7/10, Train Loss: 0.0781, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9752\n",
      "Epoch 8/10, Train Loss: 0.0681, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9748\n",
      "Epoch 9/10, Train Loss: 0.0544, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0455, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9773\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.94      0.92      0.93       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.98      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5048, Accuracy: 0.9182, F1 Micro: 0.9182, F1 Macro: 0.9105\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2687, Accuracy: 0.9182, F1 Micro: 0.9182, F1 Macro: 0.9101\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1819, Accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9376\n",
      "Epoch 4/10, Train Loss: 0.1504, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9209\n",
      "Epoch 5/10, Train Loss: 0.1442, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9209\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1065, Accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9369\n",
      "Epoch 7/10, Train Loss: 0.1066, Accuracy: 0.9257, F1 Micro: 0.9257, F1 Macro: 0.9178\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0667, Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9534\n",
      "Epoch 9/10, Train Loss: 0.0831, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.932\n",
      "Epoch 10/10, Train Loss: 0.082, Accuracy: 0.9517, F1 Micro: 0.9517, F1 Macro: 0.945\n",
      "\n",
      "Sentiment analysis accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9534\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.95      0.94        86\n",
      "    positive       0.98      0.96      0.97       183\n",
      "\n",
      "    accuracy                           0.96       269\n",
      "   macro avg       0.95      0.96      0.95       269\n",
      "weighted avg       0.96      0.96      0.96       269\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.93\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.88      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.95      0.92      0.93       152\n",
      "    positive       0.77      0.83      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.85      0.86      0.85       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 120.46594262123108 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.010243189334869384\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.0591628551483154 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5276, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4104, Accuracy: 0.9234, F1 Micro: 0.9533, F1 Macro: 0.9518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.262, Accuracy: 0.9546, F1 Micro: 0.9718, F1 Macro: 0.9706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1775, Accuracy: 0.9591, F1 Micro: 0.9745, F1 Macro: 0.9737\n",
      "Epoch 5/10, Train Loss: 0.1327, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0991, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0829, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9783\n",
      "Epoch 8/10, Train Loss: 0.0654, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9761\n",
      "Epoch 9/10, Train Loss: 0.0519, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.044, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9788\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9788\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.90      0.96      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.524, Accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.9111\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2247, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9233\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2156, Accuracy: 0.9528, F1 Micro: 0.9528, F1 Macro: 0.9478\n",
      "Epoch 4/10, Train Loss: 0.1391, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9237\n",
      "Epoch 5/10, Train Loss: 0.1362, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9346\n",
      "Epoch 6/10, Train Loss: 0.0955, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9388\n",
      "Epoch 7/10, Train Loss: 0.0923, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.9067\n",
      "Epoch 8/10, Train Loss: 0.0712, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.9148\n",
      "Epoch 9/10, Train Loss: 0.0618, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9226\n",
      "Epoch 10/10, Train Loss: 0.0412, Accuracy: 0.9488, F1 Micro: 0.9488, F1 Macro: 0.9433\n",
      "\n",
      "Sentiment analysis accuracy: 0.9528, F1 Micro: 0.9528, F1 Macro: 0.9478\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93        86\n",
      "    positive       0.98      0.95      0.96       168\n",
      "\n",
      "    accuracy                           0.95       254\n",
      "   macro avg       0.94      0.95      0.95       254\n",
      "weighted avg       0.95      0.95      0.95       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.927\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.87      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.91      0.96      0.93       152\n",
      "    positive       0.86      0.71      0.78        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.87      0.84      0.85       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.95      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.89      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 117.64851403236389 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.011508369445800781\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.8520002365112305 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5261, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4098, Accuracy: 0.9234, F1 Micro: 0.9532, F1 Macro: 0.9515\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.252, Accuracy: 0.9546, F1 Micro: 0.9719, F1 Macro: 0.9708\n",
      "Epoch 4/10, Train Loss: 0.1647, Accuracy: 0.9554, F1 Micro: 0.9718, F1 Macro: 0.9698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1229, Accuracy: 0.9673, F1 Micro: 0.9796, F1 Macro: 0.9787\n",
      "Epoch 6/10, Train Loss: 0.0949, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9739\n",
      "Epoch 7/10, Train Loss: 0.0713, Accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9773\n",
      "Epoch 8/10, Train Loss: 0.0645, Accuracy: 0.9606, F1 Micro: 0.975, F1 Macro: 0.9727\n",
      "Epoch 9/10, Train Loss: 0.0526, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9747\n",
      "Epoch 10/10, Train Loss: 0.0485, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9777\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9796, F1 Macro: 0.9787\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.90      0.98      0.94       158\n",
      "        part       0.98      1.00      0.99       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4981, Accuracy: 0.9306, F1 Micro: 0.9306, F1 Macro: 0.9232\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2293, Accuracy: 0.9592, F1 Micro: 0.9592, F1 Macro: 0.9552\n",
      "Epoch 3/10, Train Loss: 0.1567, Accuracy: 0.9429, F1 Micro: 0.9429, F1 Macro: 0.9379\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1139, Accuracy: 0.9592, F1 Micro: 0.9592, F1 Macro: 0.9552\n",
      "Epoch 5/10, Train Loss: 0.0768, Accuracy: 0.9469, F1 Micro: 0.9469, F1 Macro: 0.9419\n",
      "Epoch 6/10, Train Loss: 0.0845, Accuracy: 0.9429, F1 Micro: 0.9429, F1 Macro: 0.9379\n",
      "Epoch 7/10, Train Loss: 0.0836, Accuracy: 0.9388, F1 Micro: 0.9388, F1 Macro: 0.9319\n",
      "Epoch 8/10, Train Loss: 0.057, Accuracy: 0.9429, F1 Micro: 0.9429, F1 Macro: 0.935\n",
      "Epoch 9/10, Train Loss: 0.0639, Accuracy: 0.9347, F1 Micro: 0.9347, F1 Macro: 0.9283\n",
      "Epoch 10/10, Train Loss: 0.0513, Accuracy: 0.9388, F1 Micro: 0.9388, F1 Macro: 0.9333\n",
      "\n",
      "Sentiment analysis accuracy: 0.9592, F1 Micro: 0.9592, F1 Macro: 0.9552\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.96      0.94        84\n",
      "    positive       0.98      0.96      0.97       161\n",
      "\n",
      "    accuracy                           0.96       245\n",
      "   macro avg       0.95      0.96      0.96       245\n",
      "weighted avg       0.96      0.96      0.96       245\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9253\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.85      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.90      0.98      0.94       152\n",
      "    positive       0.90      0.69      0.78        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.90      0.81      0.85       216\n",
      "weighted avg       0.90      0.90      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.97      1.00      0.99       152\n",
      "    positive       1.00      0.83      0.91        41\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.94      0.94       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 112.36199736595154 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.016652333736419677\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.7259445190429688 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5257, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3947, Accuracy: 0.9196, F1 Micro: 0.9503, F1 Macro: 0.9482\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2512, Accuracy: 0.9501, F1 Micro: 0.9689, F1 Macro: 0.9675\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1672, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9743\n",
      "Epoch 5/10, Train Loss: 0.1271, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0969, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9756\n",
      "Epoch 7/10, Train Loss: 0.0758, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0655, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9774\n",
      "Epoch 9/10, Train Loss: 0.0493, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0466, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9777\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9777\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.90      0.97      0.93       158\n",
      "        part       0.98      0.97      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4902, Accuracy: 0.9109, F1 Micro: 0.9109, F1 Macro: 0.9035\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2074, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9269\n",
      "Epoch 3/10, Train Loss: 0.1595, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.924\n",
      "Epoch 4/10, Train Loss: 0.1321, Accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.9199\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1188, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9362\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0862, Accuracy: 0.9457, F1 Micro: 0.9457, F1 Macro: 0.94\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.079, Accuracy: 0.9535, F1 Micro: 0.9535, F1 Macro: 0.9485\n",
      "Epoch 8/10, Train Loss: 0.0577, Accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.9148\n",
      "Epoch 9/10, Train Loss: 0.1033, Accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.9133\n",
      "Epoch 10/10, Train Loss: 0.0691, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9261\n",
      "\n",
      "Sentiment analysis accuracy: 0.9535, F1 Micro: 0.9535, F1 Macro: 0.9485\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.93        85\n",
      "    positive       0.99      0.94      0.96       173\n",
      "\n",
      "    accuracy                           0.95       258\n",
      "   macro avg       0.94      0.96      0.95       258\n",
      "weighted avg       0.96      0.95      0.95       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9297\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.99      0.97       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.88      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.90      0.97      0.93       152\n",
      "    positive       0.88      0.71      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.87      0.81      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      1.00      0.88        23\n",
      "     neutral       0.98      0.97      0.97       152\n",
      "    positive       0.92      0.83      0.87        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.93      0.91       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.95      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 124.43038296699524 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.008621621131896972\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.4721388816833496 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5293, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3907, Accuracy: 0.9286, F1 Micro: 0.956, F1 Macro: 0.9544\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2367, Accuracy: 0.9501, F1 Micro: 0.969, F1 Macro: 0.9678\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1625, Accuracy: 0.965, F1 Micro: 0.9782, F1 Macro: 0.9774\n",
      "Epoch 5/10, Train Loss: 0.1195, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9744\n",
      "Epoch 6/10, Train Loss: 0.0927, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0746, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9787\n",
      "Epoch 8/10, Train Loss: 0.0644, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9784\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0522, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9792\n",
      "Epoch 10/10, Train Loss: 0.0445, Accuracy: 0.9613, F1 Micro: 0.9755, F1 Macro: 0.9734\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9792\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.96      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4717, Accuracy: 0.8774, F1 Micro: 0.8774, F1 Macro: 0.8698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2173, Accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.9086\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1658, Accuracy: 0.9502, F1 Micro: 0.9502, F1 Macro: 0.9441\n",
      "Epoch 4/10, Train Loss: 0.1573, Accuracy: 0.931, F1 Micro: 0.931, F1 Macro: 0.9241\n",
      "Epoch 5/10, Train Loss: 0.1449, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9148\n",
      "Epoch 6/10, Train Loss: 0.0935, Accuracy: 0.931, F1 Micro: 0.931, F1 Macro: 0.9224\n",
      "Epoch 7/10, Train Loss: 0.072, Accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.9393\n",
      "Epoch 8/10, Train Loss: 0.0809, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9281\n",
      "Epoch 9/10, Train Loss: 0.0759, Accuracy: 0.9042, F1 Micro: 0.9042, F1 Macro: 0.8913\n",
      "Epoch 10/10, Train Loss: 0.0525, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9161\n",
      "\n",
      "Sentiment analysis accuracy: 0.9502, F1 Micro: 0.9502, F1 Macro: 0.9441\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.93        85\n",
      "    positive       0.98      0.95      0.96       176\n",
      "\n",
      "    accuracy                           0.95       261\n",
      "   macro avg       0.94      0.95      0.94       261\n",
      "weighted avg       0.95      0.95      0.95       261\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9253\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.93      0.95      0.94       152\n",
      "    positive       0.85      0.79      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.87      0.86      0.86       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.92      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 122.7902181148529 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.007939273118972778\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 8\n",
      "Sampling duration: 1.3044745922088623 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5244, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.403, Accuracy: 0.9204, F1 Micro: 0.9513, F1 Macro: 0.9494\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2515, Accuracy: 0.9554, F1 Micro: 0.9723, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1711, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1286, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9776\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1056, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9797\n",
      "Epoch 7/10, Train Loss: 0.0821, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9774\n",
      "Epoch 8/10, Train Loss: 0.0603, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9785\n",
      "Epoch 9/10, Train Loss: 0.0525, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9776\n",
      "Epoch 10/10, Train Loss: 0.0452, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9789\n",
      "\n",
      "Aspect detection accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9797\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.92      0.96      0.93       158\n",
      "        part       0.98      1.00      0.99       158\n",
      "       price       0.99      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.475, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9355\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2515, Accuracy: 0.9457, F1 Micro: 0.9457, F1 Macro: 0.939\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.143, Accuracy: 0.9535, F1 Micro: 0.9535, F1 Macro: 0.9488\n",
      "Epoch 4/10, Train Loss: 0.1179, Accuracy: 0.9457, F1 Micro: 0.9457, F1 Macro: 0.9403\n",
      "Epoch 5/10, Train Loss: 0.1376, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9287\n",
      "Epoch 6/10, Train Loss: 0.1102, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9348\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0847, Accuracy: 0.9535, F1 Micro: 0.9535, F1 Macro: 0.9488\n",
      "Epoch 8/10, Train Loss: 0.0584, Accuracy: 0.9457, F1 Micro: 0.9457, F1 Macro: 0.94\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0671, Accuracy: 0.9729, F1 Micro: 0.9729, F1 Macro: 0.9692\n",
      "Epoch 10/10, Train Loss: 0.0363, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9362\n",
      "\n",
      "Sentiment analysis accuracy: 0.9729, F1 Micro: 0.9729, F1 Macro: 0.9692\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.98      0.94      0.96        86\n",
      "    positive       0.97      0.99      0.98       172\n",
      "\n",
      "    accuracy                           0.97       258\n",
      "   macro avg       0.97      0.97      0.97       258\n",
      "weighted avg       0.97      0.97      0.97       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9645, F1 Micro: 0.9645, F1 Macro: 0.9371\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.82      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.89      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.75      0.86        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.84      0.79      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.92      0.83      0.87       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      1.00      0.98        23\n",
      "     neutral       0.97      1.00      0.99       152\n",
      "    positive       1.00      0.88      0.94        41\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.98      0.96      0.97       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        13\n",
      "     neutral       0.99      1.00      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 124.8967695236206 s\n",
      "Total runtime: 2676.2202174663544 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[2], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28e5ee3",
   "metadata": {
    "papermill": {
     "duration": 0.33493,
     "end_time": "2025-03-24T16:58:56.729611",
     "exception": false,
     "start_time": "2025-03-24T16:58:56.394681",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f0ccfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 4\n",
      "Random seed: 3\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6456, Accuracy: 0.7865, F1 Micro: 0.8804, F1 Macro: 0.8788\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5639, Accuracy: 0.7894, F1 Micro: 0.8822, F1 Macro: 0.8807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5346, Accuracy: 0.7894, F1 Micro: 0.8822, F1 Macro: 0.8807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5259, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4788, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Epoch 6/10, Train Loss: 0.477, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Epoch 7/10, Train Loss: 0.4707, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4588, Accuracy: 0.7909, F1 Micro: 0.883, F1 Macro: 0.8814\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.4215, Accuracy: 0.7932, F1 Micro: 0.8839, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3936, Accuracy: 0.7976, F1 Micro: 0.8857, F1 Macro: 0.884\n",
      "\n",
      "Aspect detection accuracy: 0.7976, F1 Micro: 0.8857, F1 Macro: 0.884\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.78      1.00      0.88       175\n",
      "      others       0.76      0.96      0.84       158\n",
      "        part       0.71      1.00      0.83       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.80      0.99      0.89      1061\n",
      "   macro avg       0.80      0.99      0.88      1061\n",
      "weighted avg       0.80      0.99      0.89      1061\n",
      " samples avg       0.80      0.99      0.88      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7056, Accuracy: 0.44, F1 Micro: 0.44, F1 Macro: 0.4318\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5997, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5241, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5185, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.494, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4806, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4617, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.422, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3873, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2944, Accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "\n",
      "Sentiment analysis accuracy: 0.84, F1 Micro: 0.84, F1 Macro: 0.4565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         4\n",
      "    positive       0.84      1.00      0.91        21\n",
      "\n",
      "    accuracy                           0.84        25\n",
      "   macro avg       0.42      0.50      0.46        25\n",
      "weighted avg       0.71      0.84      0.77        25\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.7948, F1 Micro: 0.7948, F1 Macro: 0.3169\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.78      1.00      0.87       167\n",
      "    positive       1.00      0.03      0.06        33\n",
      "\n",
      "    accuracy                           0.78       216\n",
      "   macro avg       0.59      0.34      0.31       216\n",
      "weighted avg       0.75      0.78      0.68       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.76      0.95      0.84       152\n",
      "    positive       0.54      0.25      0.34        52\n",
      "\n",
      "    accuracy                           0.73       216\n",
      "   macro avg       0.43      0.40      0.40       216\n",
      "weighted avg       0.66      0.73      0.68       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        23\n",
      "     neutral       0.70      1.00      0.83       152\n",
      "    positive       0.00      0.00      0.00        41\n",
      "\n",
      "    accuracy                           0.70       216\n",
      "   macro avg       0.23      0.33      0.28       216\n",
      "weighted avg       0.50      0.70      0.58       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 58.48277401924133 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.9322364866733551\n",
      "Samples above threshold: 81\n",
      "Acquired samples: 81\n",
      "Sampling duration: 4.0041344165802 seconds\n",
      "New train size: 135\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6192, Accuracy: 0.782, F1 Micro: 0.8763, F1 Macro: 0.873\n",
      "Epoch 2/10, Train Loss: 0.535, Accuracy: 0.7775, F1 Micro: 0.8743, F1 Macro: 0.8713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5001, Accuracy: 0.7879, F1 Micro: 0.8813, F1 Macro: 0.8797\n",
      "Epoch 4/10, Train Loss: 0.5051, Accuracy: 0.7842, F1 Micro: 0.8776, F1 Macro: 0.8746\n",
      "Epoch 5/10, Train Loss: 0.4748, Accuracy: 0.7924, F1 Micro: 0.8809, F1 Macro: 0.8774\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4241, Accuracy: 0.8051, F1 Micro: 0.8871, F1 Macro: 0.8833\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.383, Accuracy: 0.8304, F1 Micro: 0.9, F1 Macro: 0.8965\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3486, Accuracy: 0.8445, F1 Micro: 0.9069, F1 Macro: 0.9027\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2947, Accuracy: 0.8631, F1 Micro: 0.9172, F1 Macro: 0.9135\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2407, Accuracy: 0.8802, F1 Micro: 0.9263, F1 Macro: 0.9222\n",
      "\n",
      "Aspect detection accuracy: 0.8802, F1 Micro: 0.9263, F1 Macro: 0.9222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.97      1.00      0.98       187\n",
      "     machine       0.90      0.98      0.94       175\n",
      "      others       0.88      0.77      0.82       158\n",
      "        part       0.82      0.99      0.90       158\n",
      "       price       0.98      0.96      0.97       192\n",
      "     service       0.86      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.90      0.95      0.93      1061\n",
      "   macro avg       0.90      0.95      0.92      1061\n",
      "weighted avg       0.90      0.95      0.93      1061\n",
      " samples avg       0.90      0.95      0.92      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5225, Accuracy: 0.7653, F1 Micro: 0.7653, F1 Macro: 0.4335\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.573, Accuracy: 0.7653, F1 Micro: 0.7653, F1 Macro: 0.4335\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3291, Accuracy: 0.7653, F1 Micro: 0.7653, F1 Macro: 0.4335\n",
      "Epoch 4/10, Train Loss: 0.3867, Accuracy: 0.7606, F1 Micro: 0.7606, F1 Macro: 0.432\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2958, Accuracy: 0.7746, F1 Micro: 0.7746, F1 Macro: 0.58\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2304, Accuracy: 0.8357, F1 Micro: 0.8357, F1 Macro: 0.7664\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1722, Accuracy: 0.8451, F1 Micro: 0.8451, F1 Macro: 0.7829\n",
      "Epoch 8/10, Train Loss: 0.1446, Accuracy: 0.8263, F1 Micro: 0.8263, F1 Macro: 0.753\n",
      "Epoch 9/10, Train Loss: 0.1144, Accuracy: 0.8404, F1 Micro: 0.8404, F1 Macro: 0.8028\n",
      "Epoch 10/10, Train Loss: 0.1203, Accuracy: 0.831, F1 Micro: 0.831, F1 Macro: 0.7794\n",
      "\n",
      "Sentiment analysis accuracy: 0.8451, F1 Micro: 0.8451, F1 Macro: 0.7829\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.66      0.67        50\n",
      "    positive       0.90      0.90      0.90       163\n",
      "\n",
      "    accuracy                           0.85       213\n",
      "   macro avg       0.78      0.78      0.78       213\n",
      "weighted avg       0.84      0.85      0.84       213\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 135: Accuracy: 0.8627, F1 Micro: 0.8627, F1 Macro: 0.6514\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.97      1.00      0.99       181\n",
      "    positive       0.95      0.79      0.86        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.97      0.90      0.93       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.31      0.43        16\n",
      "     neutral       0.89      0.98      0.93       167\n",
      "    positive       0.80      0.61      0.69        33\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.80      0.63      0.69       216\n",
      "weighted avg       0.86      0.88      0.86       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.35      0.50      0.41        12\n",
      "     neutral       0.88      0.78      0.83       152\n",
      "    positive       0.53      0.65      0.59        52\n",
      "\n",
      "    accuracy                           0.74       216\n",
      "   macro avg       0.59      0.65      0.61       216\n",
      "weighted avg       0.77      0.74      0.75       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.22      0.34        23\n",
      "     neutral       0.82      0.99      0.90       152\n",
      "    positive       0.75      0.51      0.61        41\n",
      "\n",
      "    accuracy                           0.81       216\n",
      "   macro avg       0.80      0.57      0.62       216\n",
      "weighted avg       0.81      0.81      0.78       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.54      0.64        13\n",
      "     neutral       0.98      0.96      0.97       186\n",
      "    positive       0.54      0.82      0.65        17\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.77      0.77      0.75       216\n",
      "weighted avg       0.94      0.92      0.92       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.79       216\n",
      "\n",
      "Total train time: 65.4097011089325 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.9422729969024658\n",
      "Samples above threshold: 73\n",
      "Acquired samples: 73\n",
      "Sampling duration: 5.560940265655518 seconds\n",
      "New train size: 208\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5842, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Epoch 2/10, Train Loss: 0.4961, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4881, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4542, Accuracy: 0.7969, F1 Micro: 0.8855, F1 Macro: 0.8838\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.434, Accuracy: 0.8155, F1 Micro: 0.8931, F1 Macro: 0.8908\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3795, Accuracy: 0.8452, F1 Micro: 0.9085, F1 Macro: 0.9059\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.325, Accuracy: 0.8876, F1 Micro: 0.9316, F1 Macro: 0.9299\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2659, Accuracy: 0.904, F1 Micro: 0.9409, F1 Macro: 0.9389\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.221, Accuracy: 0.9159, F1 Micro: 0.9477, F1 Macro: 0.9456\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1843, Accuracy: 0.9174, F1 Micro: 0.9489, F1 Macro: 0.9471\n",
      "\n",
      "Aspect detection accuracy: 0.9174, F1 Micro: 0.9489, F1 Macro: 0.9471\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.97      1.00      0.98       187\n",
      "     machine       0.93      0.99      0.96       175\n",
      "      others       0.87      0.89      0.88       158\n",
      "        part       0.96      0.93      0.95       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.88      1.00      0.93       191\n",
      "\n",
      "   micro avg       0.93      0.97      0.95      1061\n",
      "   macro avg       0.93      0.97      0.95      1061\n",
      "weighted avg       0.93      0.97      0.95      1061\n",
      " samples avg       0.93      0.97      0.95      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5684, Accuracy: 0.6991, F1 Micro: 0.6991, F1 Macro: 0.4115\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.506, Accuracy: 0.6991, F1 Micro: 0.6991, F1 Macro: 0.4115\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4286, Accuracy: 0.8186, F1 Micro: 0.8186, F1 Macro: 0.7552\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3007, Accuracy: 0.8761, F1 Micro: 0.8761, F1 Macro: 0.854\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2196, Accuracy: 0.8761, F1 Micro: 0.8761, F1 Macro: 0.8594\n",
      "Epoch 6/10, Train Loss: 0.208, Accuracy: 0.8717, F1 Micro: 0.8717, F1 Macro: 0.8441\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.136, Accuracy: 0.8982, F1 Micro: 0.8982, F1 Macro: 0.8856\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1489, Accuracy: 0.9071, F1 Micro: 0.9071, F1 Macro: 0.8949\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1129, Accuracy: 0.9159, F1 Micro: 0.9159, F1 Macro: 0.9028\n",
      "Epoch 10/10, Train Loss: 0.073, Accuracy: 0.8805, F1 Micro: 0.8805, F1 Macro: 0.8507\n",
      "\n",
      "Sentiment analysis accuracy: 0.9159, F1 Micro: 0.9159, F1 Macro: 0.9028\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.91      0.87        68\n",
      "    positive       0.96      0.92      0.94       158\n",
      "\n",
      "    accuracy                           0.92       226\n",
      "   macro avg       0.89      0.91      0.90       226\n",
      "weighted avg       0.92      0.92      0.92       226\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 208: Accuracy: 0.9082, F1 Micro: 0.9082, F1 Macro: 0.7813\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.82      0.86        11\n",
      "     neutral       0.97      1.00      0.99       181\n",
      "    positive       0.95      0.79      0.86        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.87      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.69      0.79        16\n",
      "     neutral       0.92      0.99      0.96       167\n",
      "    positive       0.92      0.67      0.77        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.92      0.78      0.84       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.87      0.89      0.88       152\n",
      "    positive       0.67      0.63      0.65        52\n",
      "\n",
      "    accuracy                           0.82       216\n",
      "   macro avg       0.81      0.76      0.78       216\n",
      "weighted avg       0.82      0.82      0.82       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.96      0.81        23\n",
      "     neutral       0.96      0.93      0.94       152\n",
      "    positive       0.84      0.78      0.81        41\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.84      0.89      0.86       216\n",
      "weighted avg       0.91      0.90      0.90       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.86      0.89       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.07      0.13        14\n",
      "     neutral       0.88      1.00      0.93       185\n",
      "    positive       0.50      0.12      0.19        17\n",
      "\n",
      "    accuracy                           0.87       216\n",
      "   macro avg       0.79      0.40      0.42       216\n",
      "weighted avg       0.86      0.87      0.82       216\n",
      "\n",
      "Total train time: 78.80563855171204 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.9610178470611572\n",
      "Samples above threshold: 66\n",
      "Acquired samples: 66\n",
      "Sampling duration: 5.33479118347168 seconds\n",
      "New train size: 274\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5665, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Epoch 2/10, Train Loss: 0.4913, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4847, Accuracy: 0.7924, F1 Micro: 0.8836, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4436, Accuracy: 0.8185, F1 Micro: 0.8953, F1 Macro: 0.8932\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3826, Accuracy: 0.8423, F1 Micro: 0.9082, F1 Macro: 0.9066\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3189, Accuracy: 0.8966, F1 Micro: 0.9364, F1 Macro: 0.9334\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2727, Accuracy: 0.9263, F1 Micro: 0.9541, F1 Macro: 0.9511\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2102, Accuracy: 0.9375, F1 Micro: 0.9611, F1 Macro: 0.9589\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1716, Accuracy: 0.9382, F1 Micro: 0.9613, F1 Macro: 0.958\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1526, Accuracy: 0.9472, F1 Micro: 0.9671, F1 Macro: 0.9654\n",
      "\n",
      "Aspect detection accuracy: 0.9472, F1 Micro: 0.9671, F1 Macro: 0.9654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.96      1.00      0.98       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.91      0.93      0.92       158\n",
      "        part       0.94      0.97      0.96       158\n",
      "       price       0.96      0.99      0.98       192\n",
      "     service       0.97      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.95      0.98      0.97      1061\n",
      "   macro avg       0.95      0.98      0.97      1061\n",
      "weighted avg       0.95      0.98      0.97      1061\n",
      " samples avg       0.95      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5952, Accuracy: 0.6778, F1 Micro: 0.6778, F1 Macro: 0.404\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5325, Accuracy: 0.8243, F1 Micro: 0.8243, F1 Macro: 0.7689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3311, Accuracy: 0.8954, F1 Micro: 0.8954, F1 Macro: 0.8829\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2426, Accuracy: 0.8996, F1 Micro: 0.8996, F1 Macro: 0.8866\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1578, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.9066\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1776, Accuracy: 0.9205, F1 Micro: 0.9205, F1 Macro: 0.9067\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1051, Accuracy: 0.9205, F1 Micro: 0.9205, F1 Macro: 0.9087\n",
      "Epoch 8/10, Train Loss: 0.0805, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.9077\n",
      "Epoch 9/10, Train Loss: 0.0746, Accuracy: 0.9079, F1 Micro: 0.9079, F1 Macro: 0.8915\n",
      "Epoch 10/10, Train Loss: 0.0835, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.9072\n",
      "\n",
      "Sentiment analysis accuracy: 0.9205, F1 Micro: 0.9205, F1 Macro: 0.9087\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.87      0.88        77\n",
      "    positive       0.94      0.94      0.94       162\n",
      "\n",
      "    accuracy                           0.92       239\n",
      "   macro avg       0.91      0.91      0.91       239\n",
      "weighted avg       0.92      0.92      0.92       239\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 274: Accuracy: 0.936, F1 Micro: 0.936, F1 Macro: 0.8615\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.64      0.74        11\n",
      "     neutral       0.97      1.00      0.98       181\n",
      "    positive       0.90      0.79      0.84        24\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.81      0.85       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.69      0.76        16\n",
      "     neutral       0.94      0.99      0.97       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.81      0.85       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.91      0.93      0.92       152\n",
      "    positive       0.79      0.71      0.75        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.82      0.83      0.82       216\n",
      "weighted avg       0.87      0.88      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87        23\n",
      "     neutral       0.94      0.97      0.95       152\n",
      "    positive       0.86      0.78      0.82        41\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.89      0.87      0.88       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.62      0.76        13\n",
      "     neutral       0.96      0.99      0.98       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.95      0.81      0.86       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.79      0.88        14\n",
      "     neutral       0.97      1.00      0.99       185\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.95      0.85      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 80.91575312614441 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.1520117342472077\n",
      "Samples above threshold: 59\n",
      "Acquired samples: 59\n",
      "Sampling duration: 5.274967670440674 seconds\n",
      "New train size: 333\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5559, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Epoch 2/10, Train Loss: 0.5018, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4587, Accuracy: 0.7976, F1 Micro: 0.8862, F1 Macro: 0.8846\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3977, Accuracy: 0.8542, F1 Micro: 0.914, F1 Macro: 0.9123\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.326, Accuracy: 0.9085, F1 Micro: 0.9439, F1 Macro: 0.9416\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2623, Accuracy: 0.936, F1 Micro: 0.9601, F1 Macro: 0.9575\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2086, Accuracy: 0.9487, F1 Micro: 0.968, F1 Macro: 0.9664\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1552, Accuracy: 0.9509, F1 Micro: 0.9693, F1 Macro: 0.9673\n",
      "Epoch 9/10, Train Loss: 0.1376, Accuracy: 0.9449, F1 Micro: 0.9651, F1 Macro: 0.9617\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1123, Accuracy: 0.9531, F1 Micro: 0.9706, F1 Macro: 0.9686\n",
      "\n",
      "Aspect detection accuracy: 0.9531, F1 Micro: 0.9706, F1 Macro: 0.9686\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.94      0.90      0.92       158\n",
      "        part       0.95      0.97      0.96       158\n",
      "       price       0.97      1.00      0.99       192\n",
      "     service       0.97      1.00      0.98       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6446, Accuracy: 0.7333, F1 Micro: 0.7333, F1 Macro: 0.5893\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5261, Accuracy: 0.8745, F1 Micro: 0.8745, F1 Macro: 0.8596\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3208, Accuracy: 0.9137, F1 Micro: 0.9137, F1 Macro: 0.9046\n",
      "Epoch 4/10, Train Loss: 0.2601, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.9005\n",
      "Epoch 5/10, Train Loss: 0.1291, Accuracy: 0.9059, F1 Micro: 0.9059, F1 Macro: 0.8867\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1763, Accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.9065\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1137, Accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.9076\n",
      "Epoch 8/10, Train Loss: 0.0882, Accuracy: 0.9137, F1 Micro: 0.9137, F1 Macro: 0.9051\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0992, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9163\n",
      "Epoch 10/10, Train Loss: 0.1029, Accuracy: 0.9137, F1 Micro: 0.9137, F1 Macro: 0.9046\n",
      "\n",
      "Sentiment analysis accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9163\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.84      0.88        81\n",
      "    positive       0.93      0.97      0.95       174\n",
      "\n",
      "    accuracy                           0.93       255\n",
      "   macro avg       0.93      0.91      0.92       255\n",
      "weighted avg       0.93      0.93      0.93       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 333: Accuracy: 0.9414, F1 Micro: 0.9414, F1 Macro: 0.882\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.98      0.93      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.62      0.74        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.81      0.76      0.78        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.79      0.83       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.94      0.90      0.92       152\n",
      "    positive       0.73      0.83      0.77        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.84      0.85      0.84       216\n",
      "weighted avg       0.89      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.78      0.84        23\n",
      "     neutral       0.95      0.97      0.96       152\n",
      "    positive       0.85      0.83      0.84        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.86      0.88       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.77      0.87        13\n",
      "     neutral       0.97      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.97      0.86      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.71      0.83        14\n",
      "     neutral       0.97      1.00      0.98       185\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.95      0.83      0.88       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Total train time: 83.40453433990479 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.05681091547012329\n",
      "Samples above threshold: 54\n",
      "Acquired samples: 54\n",
      "Sampling duration: 4.940140247344971 seconds\n",
      "New train size: 387\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5511, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4806, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4323, Accuracy: 0.8155, F1 Micro: 0.8939, F1 Macro: 0.892\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3685, Accuracy: 0.8899, F1 Micro: 0.9339, F1 Macro: 0.932\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2813, Accuracy: 0.9397, F1 Micro: 0.9629, F1 Macro: 0.9611\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.206, Accuracy: 0.9472, F1 Micro: 0.9672, F1 Macro: 0.9655\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1561, Accuracy: 0.9501, F1 Micro: 0.9689, F1 Macro: 0.9671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1227, Accuracy: 0.9524, F1 Micro: 0.9702, F1 Macro: 0.9681\n",
      "Epoch 9/10, Train Loss: 0.1082, Accuracy: 0.9472, F1 Micro: 0.9668, F1 Macro: 0.9639\n",
      "Epoch 10/10, Train Loss: 0.086, Accuracy: 0.9516, F1 Micro: 0.9696, F1 Macro: 0.9669\n",
      "\n",
      "Aspect detection accuracy: 0.9524, F1 Micro: 0.9702, F1 Macro: 0.9681\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.94      0.91      0.92       158\n",
      "        part       0.91      0.99      0.95       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6365, Accuracy: 0.7742, F1 Micro: 0.7742, F1 Macro: 0.7304\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5181, Accuracy: 0.879, F1 Micro: 0.879, F1 Macro: 0.8507\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3634, Accuracy: 0.9395, F1 Micro: 0.9395, F1 Macro: 0.9331\n",
      "Epoch 4/10, Train Loss: 0.2614, Accuracy: 0.9194, F1 Micro: 0.9194, F1 Macro: 0.9124\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.201, Accuracy: 0.9395, F1 Micro: 0.9395, F1 Macro: 0.9323\n",
      "Epoch 6/10, Train Loss: 0.149, Accuracy: 0.9355, F1 Micro: 0.9355, F1 Macro: 0.9284\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1194, Accuracy: 0.9476, F1 Micro: 0.9476, F1 Macro: 0.9406\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1209, Accuracy: 0.9556, F1 Micro: 0.9556, F1 Macro: 0.9501\n",
      "Epoch 9/10, Train Loss: 0.0928, Accuracy: 0.9395, F1 Micro: 0.9395, F1 Macro: 0.9334\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0424, Accuracy: 0.9556, F1 Micro: 0.9556, F1 Macro: 0.9503\n",
      "\n",
      "Sentiment analysis accuracy: 0.9556, F1 Micro: 0.9556, F1 Macro: 0.9503\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.95      0.93        82\n",
      "    positive       0.98      0.96      0.97       166\n",
      "\n",
      "    accuracy                           0.96       248\n",
      "   macro avg       0.95      0.95      0.95       248\n",
      "weighted avg       0.96      0.96      0.96       248\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 387: Accuracy: 0.946, F1 Micro: 0.946, F1 Macro: 0.9045\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       1.00      0.88      0.93        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.96      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.92      0.88        12\n",
      "     neutral       0.95      0.91      0.93       152\n",
      "    positive       0.74      0.81      0.77        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.84      0.88      0.86       216\n",
      "weighted avg       0.89      0.88      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87        23\n",
      "     neutral       0.91      0.99      0.95       152\n",
      "    positive       1.00      0.68      0.81        41\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.93      0.85      0.88       216\n",
      "weighted avg       0.92      0.92      0.91       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.89      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.87      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Total train time: 92.36825895309448 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.03777046203613284\n",
      "Samples above threshold: 48\n",
      "Acquired samples: 48\n",
      "Sampling duration: 4.639435052871704 seconds\n",
      "New train size: 435\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.532, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4734, Accuracy: 0.7939, F1 Micro: 0.8845, F1 Macro: 0.8831\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.43, Accuracy: 0.8356, F1 Micro: 0.9045, F1 Macro: 0.9026\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3431, Accuracy: 0.9159, F1 Micro: 0.9478, F1 Macro: 0.9447\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2581, Accuracy: 0.942, F1 Micro: 0.9635, F1 Macro: 0.9609\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2045, Accuracy: 0.9554, F1 Micro: 0.9722, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1489, Accuracy: 0.9561, F1 Micro: 0.9727, F1 Macro: 0.9713\n",
      "Epoch 8/10, Train Loss: 0.1258, Accuracy: 0.9531, F1 Micro: 0.9706, F1 Macro: 0.9687\n",
      "Epoch 9/10, Train Loss: 0.0999, Accuracy: 0.9561, F1 Micro: 0.9724, F1 Macro: 0.9706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0807, Accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9714\n",
      "\n",
      "Aspect detection accuracy: 0.9576, F1 Micro: 0.9733, F1 Macro: 0.9714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.93      0.91      0.92       158\n",
      "        part       0.96      0.97      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.97      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6417, Accuracy: 0.7833, F1 Micro: 0.7833, F1 Macro: 0.7705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.458, Accuracy: 0.8859, F1 Micro: 0.8859, F1 Macro: 0.8775\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2937, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9284\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2444, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9313\n",
      "Epoch 5/10, Train Loss: 0.2177, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9223\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1576, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9317\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1215, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9361\n",
      "Epoch 8/10, Train Loss: 0.124, Accuracy: 0.9278, F1 Micro: 0.9278, F1 Macro: 0.9195\n",
      "Epoch 9/10, Train Loss: 0.0845, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9276\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1011, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9346\n",
      "\n",
      "Sentiment analysis accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9346\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.90      0.91        86\n",
      "    positive       0.95      0.97      0.96       177\n",
      "\n",
      "    accuracy                           0.94       263\n",
      "   macro avg       0.94      0.93      0.93       263\n",
      "weighted avg       0.94      0.94      0.94       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 435: Accuracy: 0.9491, F1 Micro: 0.9491, F1 Macro: 0.9091\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.75      0.86        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.93      0.83      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        12\n",
      "     neutral       0.93      0.91      0.92       152\n",
      "    positive       0.75      0.81      0.78        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.89      0.88      0.89       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.87      0.83        23\n",
      "     neutral       0.96      0.97      0.96       152\n",
      "    positive       0.89      0.83      0.86        41\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.89      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 98.49066114425659 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.027119517326354977\n",
      "Samples above threshold: 43\n",
      "Acquired samples: 43\n",
      "Sampling duration: 4.381713151931763 seconds\n",
      "New train size: 478\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5371, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4918, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4225, Accuracy: 0.8631, F1 Micro: 0.9174, F1 Macro: 0.9142\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3264, Accuracy: 0.9375, F1 Micro: 0.961, F1 Macro: 0.9585\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2292, Accuracy: 0.9546, F1 Micro: 0.9717, F1 Macro: 0.9704\n",
      "Epoch 6/10, Train Loss: 0.1766, Accuracy: 0.9546, F1 Micro: 0.9715, F1 Macro: 0.9697\n",
      "Epoch 7/10, Train Loss: 0.1381, Accuracy: 0.9546, F1 Micro: 0.9715, F1 Macro: 0.9694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1021, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0896, Accuracy: 0.9591, F1 Micro: 0.9741, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0752, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9747\n",
      "\n",
      "Aspect detection accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9747\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.95      0.98      0.97       175\n",
      "      others       0.91      0.95      0.93       158\n",
      "        part       0.96      0.97      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6278, Accuracy: 0.8249, F1 Micro: 0.8249, F1 Macro: 0.7856\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4165, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.9069\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2649, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9198\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2099, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9288\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1651, Accuracy: 0.9416, F1 Micro: 0.9416, F1 Macro: 0.935\n",
      "Epoch 6/10, Train Loss: 0.1549, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.9077\n",
      "Epoch 7/10, Train Loss: 0.1484, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9194\n",
      "Epoch 8/10, Train Loss: 0.1115, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9309\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.113, Accuracy: 0.9416, F1 Micro: 0.9416, F1 Macro: 0.935\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0988, Accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9381\n",
      "\n",
      "Sentiment analysis accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.9381\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.91      0.92        85\n",
      "    positive       0.95      0.97      0.96       172\n",
      "\n",
      "    accuracy                           0.95       257\n",
      "   macro avg       0.94      0.94      0.94       257\n",
      "weighted avg       0.95      0.95      0.95       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 478: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9116\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.83      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.92      0.96        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.85      0.77      0.81        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.92      0.88      0.90       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.91      0.89        23\n",
      "     neutral       0.96      0.97      0.97       152\n",
      "    positive       0.89      0.83      0.86        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.89      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.89      0.94      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.93      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 100.39610958099365 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0262281596660614\n",
      "Samples above threshold: 39\n",
      "Acquired samples: 39\n",
      "Sampling duration: 3.8456411361694336 seconds\n",
      "New train size: 517\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5465, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4971, Accuracy: 0.8043, F1 Micro: 0.8894, F1 Macro: 0.8879\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3939, Accuracy: 0.9107, F1 Micro: 0.9454, F1 Macro: 0.9431\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2904, Accuracy: 0.9494, F1 Micro: 0.9686, F1 Macro: 0.9675\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2032, Accuracy: 0.9583, F1 Micro: 0.974, F1 Macro: 0.9726\n",
      "Epoch 6/10, Train Loss: 0.1452, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1176, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0936, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9778\n",
      "Epoch 9/10, Train Loss: 0.077, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0654, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9787\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9787\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.94      0.95      0.94       158\n",
      "        part       0.97      0.98      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5887, Accuracy: 0.8224, F1 Micro: 0.8224, F1 Macro: 0.7905\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3703, Accuracy: 0.9421, F1 Micro: 0.9421, F1 Macro: 0.9366\n",
      "Epoch 3/10, Train Loss: 0.2108, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9326\n",
      "Epoch 4/10, Train Loss: 0.1966, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9289\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1219, Accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9401\n",
      "Epoch 6/10, Train Loss: 0.1296, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.93\n",
      "Epoch 7/10, Train Loss: 0.1049, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9319\n",
      "Epoch 8/10, Train Loss: 0.0888, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9282\n",
      "Epoch 9/10, Train Loss: 0.0715, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9278\n",
      "Epoch 10/10, Train Loss: 0.1, Accuracy: 0.9382, F1 Micro: 0.9382, F1 Macro: 0.9319\n",
      "\n",
      "Sentiment analysis accuracy: 0.9459, F1 Micro: 0.9459, F1 Macro: 0.9401\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.93      0.92        88\n",
      "    positive       0.96      0.95      0.96       171\n",
      "\n",
      "    accuracy                           0.95       259\n",
      "   macro avg       0.94      0.94      0.94       259\n",
      "weighted avg       0.95      0.95      0.95       259\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 517: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9217\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.93      0.76      0.83        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.94      0.88      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.92      0.88        12\n",
      "     neutral       0.94      0.95      0.95       152\n",
      "    positive       0.84      0.79      0.81        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.87      0.89      0.88       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.97      0.98      0.97       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.89      0.94      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.93      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 101.37011194229126 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.035633397102355975\n",
      "Samples above threshold: 35\n",
      "Acquired samples: 23\n",
      "Sampling duration: 3.7865025997161865 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5484, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4901, Accuracy: 0.7984, F1 Micro: 0.8866, F1 Macro: 0.8851\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4013, Accuracy: 0.9018, F1 Micro: 0.94, F1 Macro: 0.9376\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2949, Accuracy: 0.9457, F1 Micro: 0.9661, F1 Macro: 0.9641\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1963, Accuracy: 0.9531, F1 Micro: 0.9707, F1 Macro: 0.9689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1489, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9735\n",
      "Epoch 7/10, Train Loss: 0.1154, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0973, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9731\n",
      "Epoch 9/10, Train Loss: 0.0804, Accuracy: 0.9576, F1 Micro: 0.9732, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0605, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9747\n",
      "\n",
      "Aspect detection accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9747\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.94      0.99      0.96       175\n",
      "      others       0.92      0.94      0.93       158\n",
      "        part       0.97      0.97      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5771, Accuracy: 0.845, F1 Micro: 0.845, F1 Macro: 0.8149\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3752, Accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.9142\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2546, Accuracy: 0.9457, F1 Micro: 0.9457, F1 Macro: 0.9393\n",
      "Epoch 4/10, Train Loss: 0.2062, Accuracy: 0.9225, F1 Micro: 0.9225, F1 Macro: 0.9163\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1373, Accuracy: 0.9457, F1 Micro: 0.9457, F1 Macro: 0.94\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1179, Accuracy: 0.9457, F1 Micro: 0.9457, F1 Macro: 0.9386\n",
      "Epoch 7/10, Train Loss: 0.0997, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9261\n",
      "Epoch 8/10, Train Loss: 0.1082, Accuracy: 0.9341, F1 Micro: 0.9341, F1 Macro: 0.9273\n",
      "Epoch 9/10, Train Loss: 0.078, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.9228\n",
      "Epoch 10/10, Train Loss: 0.0713, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9344\n",
      "\n",
      "Sentiment analysis accuracy: 0.9457, F1 Micro: 0.9457, F1 Macro: 0.9386\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        85\n",
      "    positive       0.96      0.96      0.96       173\n",
      "\n",
      "    accuracy                           0.95       258\n",
      "   macro avg       0.94      0.94      0.94       258\n",
      "weighted avg       0.95      0.95      0.95       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9089\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.93      0.99      0.96       167\n",
      "    positive       0.92      0.67      0.77        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.93      0.82      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.92      0.94      0.93       152\n",
      "    positive       0.80      0.77      0.78        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.85      0.82      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       0.92      0.83      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.93      0.93       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.89      1.00      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.96      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 104.67447185516357 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.02072939872741699\n",
      "Samples above threshold: 33\n",
      "Acquired samples: 33\n",
      "Sampling duration: 3.6264476776123047 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5379, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4688, Accuracy: 0.8021, F1 Micro: 0.8875, F1 Macro: 0.8855\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3833, Accuracy: 0.9182, F1 Micro: 0.9494, F1 Macro: 0.947\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2681, Accuracy: 0.9539, F1 Micro: 0.9715, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1849, Accuracy: 0.9621, F1 Micro: 0.9763, F1 Macro: 0.9752\n",
      "Epoch 6/10, Train Loss: 0.1389, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1071, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9758\n",
      "Epoch 8/10, Train Loss: 0.0933, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0702, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0642, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9772\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9772\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.89      0.96      0.93       158\n",
      "        part       0.99      0.97      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6175, Accuracy: 0.7638, F1 Micro: 0.7638, F1 Macro: 0.6867\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3837, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9274\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2428, Accuracy: 0.9528, F1 Micro: 0.9528, F1 Macro: 0.9476\n",
      "Epoch 4/10, Train Loss: 0.1861, Accuracy: 0.9488, F1 Micro: 0.9488, F1 Macro: 0.9439\n",
      "Epoch 5/10, Train Loss: 0.1711, Accuracy: 0.9488, F1 Micro: 0.9488, F1 Macro: 0.9439\n",
      "Epoch 6/10, Train Loss: 0.127, Accuracy: 0.9488, F1 Micro: 0.9488, F1 Macro: 0.9427\n",
      "Epoch 7/10, Train Loss: 0.14, Accuracy: 0.9449, F1 Micro: 0.9449, F1 Macro: 0.9381\n",
      "Epoch 8/10, Train Loss: 0.0906, Accuracy: 0.9488, F1 Micro: 0.9488, F1 Macro: 0.9439\n",
      "Epoch 9/10, Train Loss: 0.092, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9356\n",
      "Epoch 10/10, Train Loss: 0.0798, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.935\n",
      "\n",
      "Sentiment analysis accuracy: 0.9528, F1 Micro: 0.9528, F1 Macro: 0.9476\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93        85\n",
      "    positive       0.98      0.95      0.96       169\n",
      "\n",
      "    accuracy                           0.95       254\n",
      "   macro avg       0.94      0.95      0.95       254\n",
      "weighted avg       0.95      0.95      0.95       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.925\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       1.00      0.96      0.98        24\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.99      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.87      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.90      0.97      0.93       152\n",
      "    positive       0.90      0.69      0.78        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.88      0.83      0.85       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.99      0.97      0.98       152\n",
      "    positive       0.88      0.88      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.90      0.93      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.89      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 102.25598168373108 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.06263315677642822\n",
      "Samples above threshold: 30\n",
      "Acquired samples: 30\n",
      "Sampling duration: 3.331920623779297 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5428, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4662, Accuracy: 0.811, F1 Micro: 0.8911, F1 Macro: 0.8892\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3559, Accuracy: 0.9256, F1 Micro: 0.9544, F1 Macro: 0.9525\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2495, Accuracy: 0.9464, F1 Micro: 0.967, F1 Macro: 0.966\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1766, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1292, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1033, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9757\n",
      "Epoch 8/10, Train Loss: 0.0869, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9739\n",
      "Epoch 9/10, Train Loss: 0.0683, Accuracy: 0.9583, F1 Micro: 0.9737, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0565, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9772\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9772\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.95      0.94       158\n",
      "        part       0.97      0.98      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6031, Accuracy: 0.8659, F1 Micro: 0.8659, F1 Macro: 0.8449\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3701, Accuracy: 0.931, F1 Micro: 0.931, F1 Macro: 0.9245\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2214, Accuracy: 0.9425, F1 Micro: 0.9425, F1 Macro: 0.9372\n",
      "Epoch 4/10, Train Loss: 0.1991, Accuracy: 0.9272, F1 Micro: 0.9272, F1 Macro: 0.9208\n",
      "Epoch 5/10, Train Loss: 0.146, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9261\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1406, Accuracy: 0.9425, F1 Micro: 0.9425, F1 Macro: 0.9366\n",
      "Epoch 7/10, Train Loss: 0.1328, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9165\n",
      "Epoch 8/10, Train Loss: 0.1204, Accuracy: 0.9387, F1 Micro: 0.9387, F1 Macro: 0.9306\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0972, Accuracy: 0.9425, F1 Micro: 0.9425, F1 Macro: 0.9355\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0814, Accuracy: 0.9502, F1 Micro: 0.9502, F1 Macro: 0.9444\n",
      "\n",
      "Sentiment analysis accuracy: 0.9502, F1 Micro: 0.9502, F1 Macro: 0.9444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.94      0.93        87\n",
      "    positive       0.97      0.95      0.96       174\n",
      "\n",
      "    accuracy                           0.95       261\n",
      "   macro avg       0.94      0.95      0.94       261\n",
      "weighted avg       0.95      0.95      0.95       261\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.9243\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.85      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.93      0.95      0.94       152\n",
      "    positive       0.82      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.89      0.86      0.87       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.97      0.98      0.97       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 111.78475856781006 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.015025854110717773\n",
      "Samples above threshold: 27\n",
      "Acquired samples: 27\n",
      "Sampling duration: 3.2077555656433105 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5358, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4576, Accuracy: 0.8214, F1 Micro: 0.8963, F1 Macro: 0.8942\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3396, Accuracy: 0.933, F1 Micro: 0.9582, F1 Macro: 0.9556\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2341, Accuracy: 0.9546, F1 Micro: 0.9718, F1 Macro: 0.9706\n",
      "Epoch 5/10, Train Loss: 0.1627, Accuracy: 0.9546, F1 Micro: 0.9716, F1 Macro: 0.9701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.12, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0937, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9759\n",
      "Epoch 8/10, Train Loss: 0.0765, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9729\n",
      "Epoch 9/10, Train Loss: 0.0652, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0546, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9791\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9791\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.95      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6063, Accuracy: 0.8717, F1 Micro: 0.8717, F1 Macro: 0.8518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3346, Accuracy: 0.9321, F1 Micro: 0.9321, F1 Macro: 0.9239\n",
      "Epoch 3/10, Train Loss: 0.2541, Accuracy: 0.9208, F1 Micro: 0.9208, F1 Macro: 0.9137\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1849, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9331\n",
      "Epoch 5/10, Train Loss: 0.1419, Accuracy: 0.9019, F1 Micro: 0.9019, F1 Macro: 0.8943\n",
      "Epoch 6/10, Train Loss: 0.1639, Accuracy: 0.9245, F1 Micro: 0.9245, F1 Macro: 0.9172\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0975, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9327\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0832, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9311\n",
      "Epoch 9/10, Train Loss: 0.0811, Accuracy: 0.9321, F1 Micro: 0.9321, F1 Macro: 0.9251\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.081, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9323\n",
      "\n",
      "Sentiment analysis accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9323\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.94      0.91        86\n",
      "    positive       0.97      0.94      0.95       179\n",
      "\n",
      "    accuracy                           0.94       265\n",
      "   macro avg       0.93      0.94      0.93       265\n",
      "weighted avg       0.94      0.94      0.94       265\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.9182\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.81      0.79      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.86      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.93      0.95      0.94       152\n",
      "    positive       0.83      0.77      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.84      0.85      0.85       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 111.28617143630981 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.014003252983093262\n",
      "Samples above threshold: 24\n",
      "Acquired samples: 18\n",
      "Sampling duration: 3.0779404640197754 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5295, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4551, Accuracy: 0.8512, F1 Micro: 0.9117, F1 Macro: 0.9094\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3151, Accuracy: 0.939, F1 Micro: 0.9621, F1 Macro: 0.9605\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2158, Accuracy: 0.9546, F1 Micro: 0.9717, F1 Macro: 0.9707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1601, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1175, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.976\n",
      "Epoch 7/10, Train Loss: 0.0931, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9754\n",
      "Epoch 8/10, Train Loss: 0.0737, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9742\n",
      "Epoch 9/10, Train Loss: 0.0586, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.976\n",
      "Epoch 10/10, Train Loss: 0.0527, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9731\n",
      "\n",
      "Aspect detection accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.93      0.93       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.514, Accuracy: 0.8931, F1 Micro: 0.8931, F1 Macro: 0.8815\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2618, Accuracy: 0.9275, F1 Micro: 0.9275, F1 Macro: 0.9198\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1975, Accuracy: 0.9427, F1 Micro: 0.9427, F1 Macro: 0.9353\n",
      "Epoch 4/10, Train Loss: 0.1585, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.9323\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1383, Accuracy: 0.9466, F1 Micro: 0.9466, F1 Macro: 0.939\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1483, Accuracy: 0.9466, F1 Micro: 0.9466, F1 Macro: 0.9398\n",
      "Epoch 7/10, Train Loss: 0.1098, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.9323\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1079, Accuracy: 0.9504, F1 Micro: 0.9504, F1 Macro: 0.9442\n",
      "Epoch 9/10, Train Loss: 0.0706, Accuracy: 0.9427, F1 Micro: 0.9427, F1 Macro: 0.9337\n",
      "Epoch 10/10, Train Loss: 0.0789, Accuracy: 0.9427, F1 Micro: 0.9427, F1 Macro: 0.9357\n",
      "\n",
      "Sentiment analysis accuracy: 0.9504, F1 Micro: 0.9504, F1 Macro: 0.9442\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.96      0.93        84\n",
      "    positive       0.98      0.94      0.96       178\n",
      "\n",
      "    accuracy                           0.95       262\n",
      "   macro avg       0.94      0.95      0.94       262\n",
      "weighted avg       0.95      0.95      0.95       262\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9164\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.97      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.82      0.77      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.82      0.85      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.92      0.88      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.95      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.89      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.96      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 112.083420753479 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.02257704734802246\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.065587282180786 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5346, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4529, Accuracy: 0.8467, F1 Micro: 0.9088, F1 Macro: 0.906\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3156, Accuracy: 0.9435, F1 Micro: 0.9649, F1 Macro: 0.9633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.206, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1402, Accuracy: 0.9606, F1 Micro: 0.9754, F1 Macro: 0.9743\n",
      "Epoch 6/10, Train Loss: 0.108, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0875, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9761\n",
      "Epoch 8/10, Train Loss: 0.0723, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9732\n",
      "Epoch 9/10, Train Loss: 0.057, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9744\n",
      "Epoch 10/10, Train Loss: 0.0484, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.976\n",
      "\n",
      "Aspect detection accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9761\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.94      0.93      0.93       158\n",
      "        part       0.96      0.99      0.97       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       0.99      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5345, Accuracy: 0.8927, F1 Micro: 0.8927, F1 Macro: 0.8747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2803, Accuracy: 0.9042, F1 Micro: 0.9042, F1 Macro: 0.8968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.199, Accuracy: 0.9425, F1 Micro: 0.9425, F1 Macro: 0.9362\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.158, Accuracy: 0.9425, F1 Micro: 0.9425, F1 Macro: 0.9348\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.158, Accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.94\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1302, Accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.94\n",
      "Epoch 7/10, Train Loss: 0.1174, Accuracy: 0.931, F1 Micro: 0.931, F1 Macro: 0.9241\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1036, Accuracy: 0.9502, F1 Micro: 0.9502, F1 Macro: 0.9428\n",
      "Epoch 9/10, Train Loss: 0.092, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9277\n",
      "Epoch 10/10, Train Loss: 0.0852, Accuracy: 0.9119, F1 Micro: 0.9119, F1 Macro: 0.9042\n",
      "\n",
      "Sentiment analysis accuracy: 0.9502, F1 Micro: 0.9502, F1 Macro: 0.9428\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.91      0.92        85\n",
      "    positive       0.96      0.97      0.96       176\n",
      "\n",
      "    accuracy                           0.95       261\n",
      "   macro avg       0.95      0.94      0.94       261\n",
      "weighted avg       0.95      0.95      0.95       261\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9133\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.85      0.96      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.89      0.91       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.94      0.93      0.93       152\n",
      "    positive       0.78      0.83      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.88      0.86      0.87       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.96      0.94        23\n",
      "     neutral       0.96      0.99      0.97       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      0.99       185\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 116.27570343017578 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.016882896423339844\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.7134342193603516 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5387, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4489, Accuracy: 0.8594, F1 Micro: 0.9168, F1 Macro: 0.9145\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.303, Accuracy: 0.9427, F1 Micro: 0.9644, F1 Macro: 0.9631\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.197, Accuracy: 0.9554, F1 Micro: 0.9721, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1455, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1099, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0818, Accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9782\n",
      "Epoch 8/10, Train Loss: 0.0676, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9742\n",
      "Epoch 9/10, Train Loss: 0.0576, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9739\n",
      "Epoch 10/10, Train Loss: 0.048, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9762\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9782\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.91      0.95      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5986, Accuracy: 0.8031, F1 Micro: 0.8031, F1 Macro: 0.7389\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3411, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9136\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1988, Accuracy: 0.9488, F1 Micro: 0.9488, F1 Macro: 0.9433\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1705, Accuracy: 0.9528, F1 Micro: 0.9528, F1 Macro: 0.9473\n",
      "Epoch 5/10, Train Loss: 0.1319, Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.9308\n",
      "Epoch 6/10, Train Loss: 0.1224, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.935\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1019, Accuracy: 0.9567, F1 Micro: 0.9567, F1 Macro: 0.9518\n",
      "Epoch 8/10, Train Loss: 0.0893, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9263\n",
      "Epoch 9/10, Train Loss: 0.0572, Accuracy: 0.9252, F1 Micro: 0.9252, F1 Macro: 0.9153\n",
      "Epoch 10/10, Train Loss: 0.0892, Accuracy: 0.9291, F1 Micro: 0.9291, F1 Macro: 0.9173\n",
      "\n",
      "Sentiment analysis accuracy: 0.9567, F1 Micro: 0.9567, F1 Macro: 0.9518\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.95      0.94        85\n",
      "    positive       0.98      0.96      0.97       169\n",
      "\n",
      "    accuracy                           0.96       254\n",
      "   macro avg       0.95      0.96      0.95       254\n",
      "weighted avg       0.96      0.96      0.96       254\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9273\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.92      0.95      0.94       152\n",
      "    positive       0.83      0.75      0.79        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.89      0.85      0.86       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.83      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.89      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 116.59143781661987 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.014672040939331055\n",
      "Samples above threshold: 17\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.5880393981933594 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5258, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4368, Accuracy: 0.8571, F1 Micro: 0.9163, F1 Macro: 0.9147\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3023, Accuracy: 0.9442, F1 Micro: 0.9652, F1 Macro: 0.9635\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1918, Accuracy: 0.9561, F1 Micro: 0.9727, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1356, Accuracy: 0.9635, F1 Micro: 0.9773, F1 Macro: 0.9763\n",
      "Epoch 6/10, Train Loss: 0.1113, Accuracy: 0.9524, F1 Micro: 0.9698, F1 Macro: 0.9663\n",
      "Epoch 7/10, Train Loss: 0.0939, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0698, Accuracy: 0.965, F1 Micro: 0.9782, F1 Macro: 0.977\n",
      "Epoch 9/10, Train Loss: 0.0571, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9757\n",
      "Epoch 10/10, Train Loss: 0.0493, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9763\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.9782, F1 Macro: 0.977\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      1.00      0.99       187\n",
      "     machine       0.94      0.99      0.97       175\n",
      "      others       0.90      0.97      0.93       158\n",
      "        part       0.96      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5565, Accuracy: 0.8975, F1 Micro: 0.8975, F1 Macro: 0.8826\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2535, Accuracy: 0.9303, F1 Micro: 0.9303, F1 Macro: 0.9243\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1794, Accuracy: 0.9467, F1 Micro: 0.9467, F1 Macro: 0.9415\n",
      "Epoch 4/10, Train Loss: 0.1641, Accuracy: 0.9426, F1 Micro: 0.9426, F1 Macro: 0.9353\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1354, Accuracy: 0.959, F1 Micro: 0.959, F1 Macro: 0.9546\n",
      "Epoch 6/10, Train Loss: 0.1112, Accuracy: 0.9549, F1 Micro: 0.9549, F1 Macro: 0.9499\n",
      "Epoch 7/10, Train Loss: 0.0713, Accuracy: 0.9262, F1 Micro: 0.9262, F1 Macro: 0.914\n",
      "Epoch 8/10, Train Loss: 0.0741, Accuracy: 0.9467, F1 Micro: 0.9467, F1 Macro: 0.9405\n",
      "Epoch 9/10, Train Loss: 0.0803, Accuracy: 0.9426, F1 Micro: 0.9426, F1 Macro: 0.9368\n",
      "Epoch 10/10, Train Loss: 0.1019, Accuracy: 0.9344, F1 Micro: 0.9344, F1 Macro: 0.9265\n",
      "\n",
      "Sentiment analysis accuracy: 0.959, F1 Micro: 0.959, F1 Macro: 0.9546\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94        81\n",
      "    positive       0.99      0.95      0.97       163\n",
      "\n",
      "    accuracy                           0.96       244\n",
      "   macro avg       0.95      0.96      0.95       244\n",
      "weighted avg       0.96      0.96      0.96       244\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9216\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      1.00       181\n",
      "    positive       1.00      0.96      0.98        24\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.99      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.94      0.99      0.97       167\n",
      "    positive       0.92      0.70      0.79        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.83      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.67      0.76        12\n",
      "     neutral       0.90      0.97      0.93       152\n",
      "    positive       0.89      0.75      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.89      0.79      0.84       216\n",
      "weighted avg       0.90      0.90      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.96      0.99      0.98       152\n",
      "    positive       1.00      0.80      0.89        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.94      0.92      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 113.97144746780396 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.016425907611846924\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.4117565155029297 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5349, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4249, Accuracy: 0.9025, F1 Micro: 0.9405, F1 Macro: 0.9384\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2727, Accuracy: 0.9539, F1 Micro: 0.9712, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1817, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1269, Accuracy: 0.9665, F1 Micro: 0.9791, F1 Macro: 0.978\n",
      "Epoch 6/10, Train Loss: 0.1027, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9778\n",
      "Epoch 7/10, Train Loss: 0.0773, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9774\n",
      "Epoch 8/10, Train Loss: 0.0618, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9779\n",
      "Epoch 9/10, Train Loss: 0.0542, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9771\n",
      "Epoch 10/10, Train Loss: 0.0466, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9777\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9791, F1 Macro: 0.978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.90      0.97      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5429, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9137\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2848, Accuracy: 0.9476, F1 Micro: 0.9476, F1 Macro: 0.941\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2132, Accuracy: 0.9516, F1 Micro: 0.9516, F1 Macro: 0.9463\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1307, Accuracy: 0.9637, F1 Micro: 0.9637, F1 Macro: 0.9596\n",
      "Epoch 5/10, Train Loss: 0.1289, Accuracy: 0.9597, F1 Micro: 0.9597, F1 Macro: 0.9553\n",
      "Epoch 6/10, Train Loss: 0.0844, Accuracy: 0.9597, F1 Micro: 0.9597, F1 Macro: 0.955\n",
      "Epoch 7/10, Train Loss: 0.0731, Accuracy: 0.9516, F1 Micro: 0.9516, F1 Macro: 0.9466\n",
      "Epoch 8/10, Train Loss: 0.0688, Accuracy: 0.9476, F1 Micro: 0.9476, F1 Macro: 0.942\n",
      "Epoch 9/10, Train Loss: 0.0591, Accuracy: 0.9315, F1 Micro: 0.9315, F1 Macro: 0.9208\n",
      "Epoch 10/10, Train Loss: 0.0712, Accuracy: 0.9435, F1 Micro: 0.9435, F1 Macro: 0.9362\n",
      "\n",
      "Sentiment analysis accuracy: 0.9637, F1 Micro: 0.9637, F1 Macro: 0.9596\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95        82\n",
      "    positive       0.99      0.96      0.97       166\n",
      "\n",
      "    accuracy                           0.96       248\n",
      "   macro avg       0.95      0.97      0.96       248\n",
      "weighted avg       0.97      0.96      0.96       248\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9267\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.86      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.90      0.97      0.94       152\n",
      "    positive       0.90      0.71      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.87      0.81      0.84       216\n",
      "weighted avg       0.90      0.90      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.89      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 112.44499683380127 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.01952582597732544\n",
      "Samples above threshold: 12\n",
      "Acquired samples: 8\n",
      "Sampling duration: 2.207890510559082 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5303, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4281, Accuracy: 0.8824, F1 Micro: 0.9298, F1 Macro: 0.9279\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2822, Accuracy: 0.9464, F1 Micro: 0.9665, F1 Macro: 0.9648\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1789, Accuracy: 0.9554, F1 Micro: 0.9721, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1282, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9764\n",
      "Epoch 6/10, Train Loss: 0.0972, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9718\n",
      "Epoch 7/10, Train Loss: 0.0812, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9741\n",
      "Epoch 8/10, Train Loss: 0.0683, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0555, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9789\n",
      "Epoch 10/10, Train Loss: 0.0452, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9785\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.99      0.97       175\n",
      "      others       0.94      0.92      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.98      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4969, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.9087\n",
      "Epoch 2/10, Train Loss: 0.2834, Accuracy: 0.8977, F1 Micro: 0.8977, F1 Macro: 0.8902\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1799, Accuracy: 0.9242, F1 Micro: 0.9242, F1 Macro: 0.9174\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.15, Accuracy: 0.9432, F1 Micro: 0.9432, F1 Macro: 0.9369\n",
      "Epoch 5/10, Train Loss: 0.1216, Accuracy: 0.9356, F1 Micro: 0.9356, F1 Macro: 0.9282\n",
      "Epoch 6/10, Train Loss: 0.114, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.921\n",
      "Epoch 7/10, Train Loss: 0.0822, Accuracy: 0.9318, F1 Micro: 0.9318, F1 Macro: 0.9249\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1201, Accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.941\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.079, Accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.9396\n",
      "Epoch 10/10, Train Loss: 0.0615, Accuracy: 0.9432, F1 Micro: 0.9432, F1 Macro: 0.9351\n",
      "\n",
      "Sentiment analysis accuracy: 0.947, F1 Micro: 0.947, F1 Macro: 0.9396\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        86\n",
      "    positive       0.96      0.96      0.96       178\n",
      "\n",
      "    accuracy                           0.95       264\n",
      "   macro avg       0.94      0.94      0.94       264\n",
      "weighted avg       0.95      0.95      0.95       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9236\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.96      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.69      0.79        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.82      0.86       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.92      0.88        12\n",
      "     neutral       0.94      0.93      0.93       152\n",
      "    positive       0.77      0.79      0.78        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.85      0.88      0.86       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.95      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 118.72372937202454 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.010578113794326782\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.158123016357422 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5221, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.422, Accuracy: 0.8981, F1 Micro: 0.9376, F1 Macro: 0.9351\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2625, Accuracy: 0.9524, F1 Micro: 0.9704, F1 Macro: 0.969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1751, Accuracy: 0.9613, F1 Micro: 0.9759, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1259, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.978\n",
      "Epoch 6/10, Train Loss: 0.0981, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9755\n",
      "Epoch 7/10, Train Loss: 0.0766, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9778\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0607, Accuracy: 0.9695, F1 Micro: 0.9809, F1 Macro: 0.98\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0488, Accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9804\n",
      "Epoch 10/10, Train Loss: 0.0441, Accuracy: 0.965, F1 Micro: 0.9778, F1 Macro: 0.976\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.9804\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.98      0.98      0.98       175\n",
      "      others       0.91      0.97      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5031, Accuracy: 0.8755, F1 Micro: 0.8755, F1 Macro: 0.8675\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2362, Accuracy: 0.9183, F1 Micro: 0.9183, F1 Macro: 0.9113\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2055, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9194\n",
      "Epoch 4/10, Train Loss: 0.1646, Accuracy: 0.9261, F1 Micro: 0.9261, F1 Macro: 0.9194\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1266, Accuracy: 0.9416, F1 Micro: 0.9416, F1 Macro: 0.9357\n",
      "Epoch 6/10, Train Loss: 0.101, Accuracy: 0.9105, F1 Micro: 0.9105, F1 Macro: 0.9033\n",
      "Epoch 7/10, Train Loss: 0.0935, Accuracy: 0.9339, F1 Micro: 0.9339, F1 Macro: 0.9226\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0911, Accuracy: 0.9533, F1 Micro: 0.9533, F1 Macro: 0.9479\n",
      "Epoch 9/10, Train Loss: 0.0673, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9316\n",
      "Epoch 10/10, Train Loss: 0.0392, Accuracy: 0.9377, F1 Micro: 0.9377, F1 Macro: 0.9316\n",
      "\n",
      "Sentiment analysis accuracy: 0.9533, F1 Micro: 0.9533, F1 Macro: 0.9479\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.96      0.93        84\n",
      "    positive       0.98      0.95      0.96       173\n",
      "\n",
      "    accuracy                           0.95       257\n",
      "   macro avg       0.94      0.96      0.95       257\n",
      "weighted avg       0.96      0.95      0.95       257\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9637, F1 Micro: 0.9637, F1 Macro: 0.93\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       1.00      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.98      0.98      0.98       167\n",
      "    positive       0.88      0.88      0.88        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.91      0.97      0.94       152\n",
      "    positive       0.90      0.73      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.88      0.82      0.84       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.83      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.89      0.94      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 122.58986377716064 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.010434579849243163\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.919633388519287 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5258, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4104, Accuracy: 0.9085, F1 Micro: 0.9436, F1 Macro: 0.9403\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2487, Accuracy: 0.9449, F1 Micro: 0.9655, F1 Macro: 0.963\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1716, Accuracy: 0.9539, F1 Micro: 0.971, F1 Macro: 0.9683\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1219, Accuracy: 0.9635, F1 Micro: 0.977, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0921, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.9778\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0709, Accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9783\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0615, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9789\n",
      "Epoch 9/10, Train Loss: 0.0533, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.977\n",
      "Epoch 10/10, Train Loss: 0.0489, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9786\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.97      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.536, Accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.8967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.232, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9245\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1937, Accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9429\n",
      "Epoch 4/10, Train Loss: 0.1382, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9273\n",
      "Epoch 5/10, Train Loss: 0.1398, Accuracy: 0.9141, F1 Micro: 0.9141, F1 Macro: 0.9067\n",
      "Epoch 6/10, Train Loss: 0.1092, Accuracy: 0.9375, F1 Micro: 0.9375, F1 Macro: 0.9304\n",
      "Epoch 7/10, Train Loss: 0.0867, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9387\n",
      "Epoch 8/10, Train Loss: 0.0695, Accuracy: 0.9258, F1 Micro: 0.9258, F1 Macro: 0.9184\n",
      "Epoch 9/10, Train Loss: 0.0582, Accuracy: 0.9453, F1 Micro: 0.9453, F1 Macro: 0.9376\n",
      "Epoch 10/10, Train Loss: 0.0575, Accuracy: 0.9258, F1 Micro: 0.9258, F1 Macro: 0.9171\n",
      "\n",
      "Sentiment analysis accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.9429\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.94      0.92        84\n",
      "    positive       0.97      0.95      0.96       172\n",
      "\n",
      "    accuracy                           0.95       256\n",
      "   macro avg       0.94      0.95      0.94       256\n",
      "weighted avg       0.95      0.95      0.95       256\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.9234\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.96      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.85      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.92      0.97      0.94       152\n",
      "    positive       0.89      0.75      0.81        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.85      0.82      0.83       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.92      0.88      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 123.50099587440491 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.01345815658569336\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.7669508457183838 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5339, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4085, Accuracy: 0.9018, F1 Micro: 0.9388, F1 Macro: 0.9345\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2562, Accuracy: 0.9561, F1 Micro: 0.9726, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1741, Accuracy: 0.9621, F1 Micro: 0.9763, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1277, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0947, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9769\n",
      "Epoch 7/10, Train Loss: 0.078, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0616, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.977\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0493, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.9768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.045, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9779\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9779\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.92      0.93      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4544, Accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.9057\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1964, Accuracy: 0.9251, F1 Micro: 0.9251, F1 Macro: 0.9162\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1636, Accuracy: 0.9288, F1 Micro: 0.9288, F1 Macro: 0.921\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1379, Accuracy: 0.9401, F1 Micro: 0.9401, F1 Macro: 0.9326\n",
      "Epoch 5/10, Train Loss: 0.1084, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9286\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0755, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9363\n",
      "Epoch 7/10, Train Loss: 0.0704, Accuracy: 0.9401, F1 Micro: 0.9401, F1 Macro: 0.9322\n",
      "Epoch 8/10, Train Loss: 0.0683, Accuracy: 0.8989, F1 Micro: 0.8989, F1 Macro: 0.8905\n",
      "Epoch 9/10, Train Loss: 0.084, Accuracy: 0.9401, F1 Micro: 0.9401, F1 Macro: 0.931\n",
      "Epoch 10/10, Train Loss: 0.064, Accuracy: 0.9251, F1 Micro: 0.9251, F1 Macro: 0.9157\n",
      "\n",
      "Sentiment analysis accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9363\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.94      0.91        85\n",
      "    positive       0.97      0.95      0.96       182\n",
      "\n",
      "    accuracy                           0.94       267\n",
      "   macro avg       0.93      0.94      0.94       267\n",
      "weighted avg       0.95      0.94      0.94       267\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.9207\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.87      0.82      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.75      0.72        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.78      0.77      0.78        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.80      0.82      0.81       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.95      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.95      0.95       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 131.87982654571533 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.007253575325012207\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.7447621822357178 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5196, Accuracy: 0.7954, F1 Micro: 0.8853, F1 Macro: 0.8838\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4004, Accuracy: 0.9159, F1 Micro: 0.9483, F1 Macro: 0.9459\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2465, Accuracy: 0.9561, F1 Micro: 0.9727, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1583, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1211, Accuracy: 0.9688, F1 Micro: 0.9804, F1 Macro: 0.9796\n",
      "Epoch 6/10, Train Loss: 0.0873, Accuracy: 0.9665, F1 Micro: 0.979, F1 Macro: 0.978\n",
      "Epoch 7/10, Train Loss: 0.0758, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9791\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0573, Accuracy: 0.9695, F1 Micro: 0.9808, F1 Macro: 0.9795\n",
      "Epoch 9/10, Train Loss: 0.0498, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.978\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0405, Accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.98\n",
      "\n",
      "Aspect detection accuracy: 0.9702, F1 Micro: 0.9813, F1 Macro: 0.98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.93      0.95      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      1.00      1.00       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.98      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4892, Accuracy: 0.9278, F1 Micro: 0.9278, F1 Macro: 0.9191\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2537, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9288\n",
      "Epoch 3/10, Train Loss: 0.1761, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9172\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1338, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9317\n",
      "Epoch 5/10, Train Loss: 0.1208, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9251\n",
      "Epoch 6/10, Train Loss: 0.0766, Accuracy: 0.9354, F1 Micro: 0.9354, F1 Macro: 0.9259\n",
      "Epoch 7/10, Train Loss: 0.1115, Accuracy: 0.9316, F1 Micro: 0.9316, F1 Macro: 0.9251\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0703, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9372\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0506, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9361\n",
      "Epoch 10/10, Train Loss: 0.057, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9172\n",
      "\n",
      "Sentiment analysis accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9361\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.93      0.92        87\n",
      "    positive       0.97      0.95      0.96       176\n",
      "\n",
      "    accuracy                           0.94       263\n",
      "   macro avg       0.93      0.94      0.94       263\n",
      "weighted avg       0.94      0.94      0.94       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9221\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.82      0.83        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.87      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.94      0.95      0.94       152\n",
      "    positive       0.82      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.86      0.86      0.86       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.93      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        13\n",
      "     neutral       0.99      1.00      1.00       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.95      0.94      0.94       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 130.04041004180908 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.005109953880310059\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 8\n",
      "Sampling duration: 1.3536906242370605 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5194, Accuracy: 0.7924, F1 Micro: 0.882, F1 Macro: 0.8794\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4067, Accuracy: 0.9196, F1 Micro: 0.951, F1 Macro: 0.9494\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2587, Accuracy: 0.9531, F1 Micro: 0.9708, F1 Macro: 0.9694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1678, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1216, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0948, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.9784\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0737, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9786\n",
      "Epoch 8/10, Train Loss: 0.0616, Accuracy: 0.9665, F1 Micro: 0.9788, F1 Macro: 0.9772\n",
      "Epoch 9/10, Train Loss: 0.0478, Accuracy: 0.9643, F1 Micro: 0.9774, F1 Macro: 0.9757\n",
      "Epoch 10/10, Train Loss: 0.0443, Accuracy: 0.9673, F1 Micro: 0.9794, F1 Macro: 0.978\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.9786\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.99      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.95      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4731, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9103\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2337, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9283\n",
      "Epoch 3/10, Train Loss: 0.1692, Accuracy: 0.9269, F1 Micro: 0.9269, F1 Macro: 0.9162\n",
      "Epoch 4/10, Train Loss: 0.1374, Accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.9119\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1211, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.935\n",
      "Epoch 6/10, Train Loss: 0.085, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9239\n",
      "Epoch 7/10, Train Loss: 0.0856, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.925\n",
      "Epoch 8/10, Train Loss: 0.085, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9317\n",
      "Epoch 9/10, Train Loss: 0.0656, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9259\n",
      "Epoch 10/10, Train Loss: 0.0372, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9218\n",
      "\n",
      "Sentiment analysis accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.935\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.93      0.91        85\n",
      "    positive       0.97      0.95      0.96       175\n",
      "\n",
      "    accuracy                           0.94       260\n",
      "   macro avg       0.93      0.94      0.94       260\n",
      "weighted avg       0.94      0.94      0.94       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.9176\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.96      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.92      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.84      0.79      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.86      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.75      0.72        12\n",
      "     neutral       0.93      0.95      0.94       152\n",
      "    positive       0.83      0.77      0.80        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.82      0.82      0.82       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.97      0.80      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.93      0.93       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 125.35903072357178 s\n",
      "Total runtime: 2729.801841020584 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[3], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd04b785",
   "metadata": {
    "papermill": {
     "duration": 0.346928,
     "end_time": "2025-03-24T16:58:58.174032",
     "exception": false,
     "start_time": "2025-03-24T16:58:57.827104",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea5cc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 5\n",
      "Random seed: 94\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6298, Accuracy: 0.7522, F1 Micro: 0.854, F1 Macro: 0.8362\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5654, Accuracy: 0.7887, F1 Micro: 0.8819, F1 Macro: 0.8803\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5262, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4783, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4582, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4326, Accuracy: 0.7902, F1 Micro: 0.8827, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4132, Accuracy: 0.7924, F1 Micro: 0.8837, F1 Macro: 0.8822\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4395, Accuracy: 0.7939, F1 Micro: 0.8842, F1 Macro: 0.8826\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.4306, Accuracy: 0.7999, F1 Micro: 0.887, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3956, Accuracy: 0.8036, F1 Micro: 0.8888, F1 Macro: 0.8871\n",
      "\n",
      "Aspect detection accuracy: 0.8036, F1 Micro: 0.8888, F1 Macro: 0.8871\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.83      1.00      0.91       187\n",
      "     machine       0.78      1.00      0.88       175\n",
      "      others       0.75      0.99      0.85       158\n",
      "        part       0.74      0.97      0.84       158\n",
      "       price       0.86      1.00      0.92       192\n",
      "     service       0.85      1.00      0.92       191\n",
      "\n",
      "   micro avg       0.80      0.99      0.89      1061\n",
      "   macro avg       0.80      0.99      0.89      1061\n",
      "weighted avg       0.81      0.99      0.89      1061\n",
      " samples avg       0.81      0.99      0.89      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7142, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5719, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.6151, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5677, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.5123, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.5138, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4932, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3579, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3098, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2431, Accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "\n",
      "Sentiment analysis accuracy: 0.8065, F1 Micro: 0.8065, F1 Macro: 0.4464\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         6\n",
      "    positive       0.81      1.00      0.89        25\n",
      "\n",
      "    accuracy                           0.81        31\n",
      "   macro avg       0.40      0.50      0.45        31\n",
      "weighted avg       0.65      0.81      0.72        31\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54: Accuracy: 0.7994, F1 Micro: 0.7994, F1 Macro: 0.3298\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        11\n",
      "     neutral       0.84      1.00      0.91       181\n",
      "    positive       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.84       216\n",
      "   macro avg       0.28      0.33      0.30       216\n",
      "weighted avg       0.70      0.84      0.76       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        16\n",
      "     neutral       0.77      1.00      0.87       167\n",
      "    positive       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.77       216\n",
      "   macro avg       0.26      0.33      0.29       216\n",
      "weighted avg       0.60      0.77      0.67       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        12\n",
      "     neutral       0.75      0.99      0.85       152\n",
      "    positive       0.67      0.19      0.30        52\n",
      "\n",
      "    accuracy                           0.74       216\n",
      "   macro avg       0.47      0.39      0.38       216\n",
      "weighted avg       0.69      0.74      0.67       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        23\n",
      "     neutral       0.74      0.97      0.84       152\n",
      "    positive       0.56      0.22      0.32        41\n",
      "\n",
      "    accuracy                           0.73       216\n",
      "   macro avg       0.43      0.40      0.39       216\n",
      "weighted avg       0.63      0.73      0.65       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        13\n",
      "     neutral       0.86      1.00      0.93       186\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.74      0.86      0.80       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        14\n",
      "     neutral       0.86      1.00      0.92       185\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.29      0.33      0.31       216\n",
      "weighted avg       0.73      0.86      0.79       216\n",
      "\n",
      "Total train time: 65.48553943634033 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.9247112333774566\n",
      "Samples above threshold: 81\n",
      "Acquired samples: 81\n",
      "Sampling duration: 4.189006328582764 seconds\n",
      "New train size: 135\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6127, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5046, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4848, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4985, Accuracy: 0.7946, F1 Micro: 0.8849, F1 Macro: 0.8834\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4552, Accuracy: 0.808, F1 Micro: 0.8912, F1 Macro: 0.89\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4116, Accuracy: 0.8192, F1 Micro: 0.8967, F1 Macro: 0.8957\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3835, Accuracy: 0.8408, F1 Micro: 0.9073, F1 Macro: 0.9064\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3501, Accuracy: 0.875, F1 Micro: 0.9259, F1 Macro: 0.9249\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2705, Accuracy: 0.8906, F1 Micro: 0.9343, F1 Macro: 0.9329\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2389, Accuracy: 0.9092, F1 Micro: 0.9449, F1 Macro: 0.9432\n",
      "\n",
      "Aspect detection accuracy: 0.9092, F1 Micro: 0.9449, F1 Macro: 0.9432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.94      1.00      0.97       187\n",
      "     machine       0.88      1.00      0.94       175\n",
      "      others       0.83      0.94      0.88       158\n",
      "        part       0.91      0.96      0.94       158\n",
      "       price       0.92      1.00      0.96       192\n",
      "     service       0.95      1.00      0.97       191\n",
      "\n",
      "   micro avg       0.91      0.99      0.94      1061\n",
      "   macro avg       0.91      0.98      0.94      1061\n",
      "weighted avg       0.91      0.99      0.95      1061\n",
      " samples avg       0.91      0.99      0.94      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7022, Accuracy: 0.6648, F1 Micro: 0.6648, F1 Macro: 0.3993\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.6131, Accuracy: 0.6813, F1 Micro: 0.6813, F1 Macro: 0.4633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.589, Accuracy: 0.8297, F1 Micro: 0.8297, F1 Macro: 0.7925\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4854, Accuracy: 0.8352, F1 Micro: 0.8352, F1 Macro: 0.7878\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4023, Accuracy: 0.9011, F1 Micro: 0.9011, F1 Macro: 0.8815\n",
      "Epoch 6/10, Train Loss: 0.2812, Accuracy: 0.8956, F1 Micro: 0.8956, F1 Macro: 0.8714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2469, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9137\n",
      "Epoch 8/10, Train Loss: 0.166, Accuracy: 0.9121, F1 Micro: 0.9121, F1 Macro: 0.8935\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1392, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9384\n",
      "Epoch 10/10, Train Loss: 0.1409, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9122\n",
      "\n",
      "Sentiment analysis accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9384\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        61\n",
      "    positive       0.96      0.96      0.96       121\n",
      "\n",
      "    accuracy                           0.95       182\n",
      "   macro avg       0.94      0.94      0.94       182\n",
      "weighted avg       0.95      0.95      0.95       182\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 135: Accuracy: 0.902, F1 Micro: 0.902, F1 Macro: 0.7821\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.95      1.00      0.97       181\n",
      "    positive       1.00      0.67      0.80        24\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.98      0.83      0.89       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.62      0.74        16\n",
      "     neutral       0.87      1.00      0.93       167\n",
      "    positive       0.93      0.39      0.55        33\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.90      0.67      0.74       216\n",
      "weighted avg       0.89      0.88      0.86       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.42      0.59        12\n",
      "     neutral       0.83      0.95      0.89       152\n",
      "    positive       0.74      0.54      0.62        52\n",
      "\n",
      "    accuracy                           0.82       216\n",
      "   macro avg       0.86      0.63      0.70       216\n",
      "weighted avg       0.82      0.82      0.81       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.70      0.78        23\n",
      "     neutral       0.91      0.97      0.94       152\n",
      "    positive       0.83      0.73      0.78        41\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.88      0.80      0.83       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.46      0.60        13\n",
      "     neutral       0.93      1.00      0.96       186\n",
      "    positive       0.88      0.41      0.56        17\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.89      0.62      0.71       216\n",
      "weighted avg       0.92      0.92      0.91       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.71      0.80        14\n",
      "     neutral       0.94      1.00      0.97       185\n",
      "    positive       1.00      0.53      0.69        17\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.95      0.75      0.82       216\n",
      "weighted avg       0.95      0.94      0.94       216\n",
      "\n",
      "Total train time: 72.97022747993469 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.9313085675239563\n",
      "Samples above threshold: 73\n",
      "Acquired samples: 73\n",
      "Sampling duration: 5.625662088394165 seconds\n",
      "New train size: 208\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5938, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.522, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5117, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4894, Accuracy: 0.7946, F1 Micro: 0.8849, F1 Macro: 0.8834\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4555, Accuracy: 0.8125, F1 Micro: 0.8938, F1 Macro: 0.8925\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4071, Accuracy: 0.8534, F1 Micro: 0.9146, F1 Macro: 0.9135\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3292, Accuracy: 0.9062, F1 Micro: 0.9433, F1 Macro: 0.9414\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2775, Accuracy: 0.9301, F1 Micro: 0.9569, F1 Macro: 0.9551\n",
      "Epoch 9/10, Train Loss: 0.2254, Accuracy: 0.9286, F1 Micro: 0.9554, F1 Macro: 0.9527\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.174, Accuracy: 0.933, F1 Micro: 0.9583, F1 Macro: 0.9553\n",
      "\n",
      "Aspect detection accuracy: 0.933, F1 Micro: 0.9583, F1 Macro: 0.9553\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.92      0.99      0.95       175\n",
      "      others       0.87      0.87      0.87       158\n",
      "        part       0.92      0.97      0.94       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.97      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.94      0.97      0.96      1061\n",
      "   macro avg       0.94      0.97      0.96      1061\n",
      "weighted avg       0.94      0.97      0.96      1061\n",
      " samples avg       0.94      0.97      0.95      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6939, Accuracy: 0.6751, F1 Micro: 0.6751, F1 Macro: 0.403\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5961, Accuracy: 0.865, F1 Micro: 0.865, F1 Macro: 0.844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4281, Accuracy: 0.9198, F1 Micro: 0.9198, F1 Macro: 0.9117\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3297, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.9174\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2171, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.934\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2271, Accuracy: 0.9409, F1 Micro: 0.9409, F1 Macro: 0.9344\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1962, Accuracy: 0.9494, F1 Micro: 0.9494, F1 Macro: 0.943\n",
      "Epoch 8/10, Train Loss: 0.1819, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9385\n",
      "Epoch 9/10, Train Loss: 0.1453, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9381\n",
      "Epoch 10/10, Train Loss: 0.1367, Accuracy: 0.9367, F1 Micro: 0.9367, F1 Macro: 0.9299\n",
      "\n",
      "Sentiment analysis accuracy: 0.9494, F1 Micro: 0.9494, F1 Macro: 0.943\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.92        77\n",
      "    positive       0.97      0.95      0.96       160\n",
      "\n",
      "    accuracy                           0.95       237\n",
      "   macro avg       0.94      0.95      0.94       237\n",
      "weighted avg       0.95      0.95      0.95       237\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 208: Accuracy: 0.9267, F1 Micro: 0.9267, F1 Macro: 0.8689\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.98      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.91      0.99      0.95       167\n",
      "    positive       0.95      0.58      0.72        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.93      0.79      0.84       216\n",
      "weighted avg       0.92      0.92      0.91       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.88      0.88      0.88       152\n",
      "    positive       0.67      0.67      0.67        52\n",
      "\n",
      "    accuracy                           0.82       216\n",
      "   macro avg       0.77      0.77      0.77       216\n",
      "weighted avg       0.82      0.82      0.82       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.83      0.84        23\n",
      "     neutral       0.91      0.97      0.94       152\n",
      "    positive       0.88      0.68      0.77        41\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.88      0.83      0.85       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.90      0.84      0.87       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.97      1.00      0.99       185\n",
      "    positive       1.00      0.76      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.99      0.90      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Total train time: 82.23322582244873 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.22141918540000916\n",
      "Samples above threshold: 66\n",
      "Acquired samples: 66\n",
      "Sampling duration: 5.739040851593018 seconds\n",
      "New train size: 274\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5669, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5084, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4886, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4556, Accuracy: 0.8036, F1 Micro: 0.8894, F1 Macro: 0.888\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4078, Accuracy: 0.8408, F1 Micro: 0.9078, F1 Macro: 0.9069\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3468, Accuracy: 0.8996, F1 Micro: 0.9392, F1 Macro: 0.9372\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2867, Accuracy: 0.9323, F1 Micro: 0.958, F1 Macro: 0.9559\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2157, Accuracy: 0.9397, F1 Micro: 0.9624, F1 Macro: 0.9605\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1605, Accuracy: 0.9412, F1 Micro: 0.9629, F1 Macro: 0.9597\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1398, Accuracy: 0.9457, F1 Micro: 0.9661, F1 Macro: 0.9639\n",
      "\n",
      "Aspect detection accuracy: 0.9457, F1 Micro: 0.9661, F1 Macro: 0.9639\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.97      1.00      0.99       187\n",
      "     machine       0.93      0.98      0.96       175\n",
      "      others       0.90      0.91      0.90       158\n",
      "        part       0.93      0.99      0.96       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.98      1.00      0.99       191\n",
      "\n",
      "   micro avg       0.95      0.98      0.97      1061\n",
      "   macro avg       0.95      0.98      0.96      1061\n",
      "weighted avg       0.95      0.98      0.97      1061\n",
      " samples avg       0.95      0.98      0.96      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6706, Accuracy: 0.6914, F1 Micro: 0.6914, F1 Macro: 0.4653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5996, Accuracy: 0.8765, F1 Micro: 0.8765, F1 Macro: 0.8602\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4085, Accuracy: 0.8765, F1 Micro: 0.8765, F1 Macro: 0.8694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3203, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9211\n",
      "Epoch 5/10, Train Loss: 0.2009, Accuracy: 0.9218, F1 Micro: 0.9218, F1 Macro: 0.9094\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1991, Accuracy: 0.9465, F1 Micro: 0.9465, F1 Macro: 0.9404\n",
      "Epoch 7/10, Train Loss: 0.1925, Accuracy: 0.8765, F1 Micro: 0.8765, F1 Macro: 0.8694\n",
      "Epoch 8/10, Train Loss: 0.1714, Accuracy: 0.9424, F1 Micro: 0.9424, F1 Macro: 0.9352\n",
      "Epoch 9/10, Train Loss: 0.1195, Accuracy: 0.9342, F1 Micro: 0.9342, F1 Macro: 0.928\n",
      "Epoch 10/10, Train Loss: 0.1102, Accuracy: 0.93, F1 Micro: 0.93, F1 Macro: 0.9215\n",
      "\n",
      "Sentiment analysis accuracy: 0.9465, F1 Micro: 0.9465, F1 Macro: 0.9404\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        79\n",
      "    positive       0.98      0.94      0.96       164\n",
      "\n",
      "    accuracy                           0.95       243\n",
      "   macro avg       0.93      0.95      0.94       243\n",
      "weighted avg       0.95      0.95      0.95       243\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 274: Accuracy: 0.9383, F1 Micro: 0.9383, F1 Macro: 0.8859\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.82      0.86        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       0.95      0.83      0.89        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.88      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.93      0.98      0.96       167\n",
      "    positive       0.88      0.70      0.78        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.92      0.83      0.87       216\n",
      "weighted avg       0.92      0.93      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.90      0.91      0.90       152\n",
      "    positive       0.76      0.71      0.73        52\n",
      "\n",
      "    accuracy                           0.86       216\n",
      "   macro avg       0.79      0.82      0.80       216\n",
      "weighted avg       0.86      0.86      0.86       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87        23\n",
      "     neutral       0.93      0.99      0.96       152\n",
      "    positive       0.94      0.71      0.81        41\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.91      0.85      0.88       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.98      1.00      0.99       185\n",
      "    positive       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.94      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 84.23564076423645 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.0862779200077058\n",
      "Samples above threshold: 59\n",
      "Acquired samples: 59\n",
      "Sampling duration: 5.554490566253662 seconds\n",
      "New train size: 333\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5633, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4981, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4724, Accuracy: 0.7984, F1 Micro: 0.8868, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4251, Accuracy: 0.8415, F1 Micro: 0.9079, F1 Macro: 0.9073\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3498, Accuracy: 0.8988, F1 Micro: 0.939, F1 Macro: 0.9374\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2816, Accuracy: 0.9301, F1 Micro: 0.9565, F1 Macro: 0.9546\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2095, Accuracy: 0.939, F1 Micro: 0.962, F1 Macro: 0.9602\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1693, Accuracy: 0.9457, F1 Micro: 0.9661, F1 Macro: 0.964\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1283, Accuracy: 0.9568, F1 Micro: 0.9731, F1 Macro: 0.9718\n",
      "Epoch 10/10, Train Loss: 0.1013, Accuracy: 0.9546, F1 Micro: 0.9716, F1 Macro: 0.9701\n",
      "\n",
      "Aspect detection accuracy: 0.9568, F1 Micro: 0.9731, F1 Macro: 0.9718\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.88      0.97      0.92       158\n",
      "        part       0.96      0.98      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.97      1061\n",
      "   macro avg       0.96      0.99      0.97      1061\n",
      "weighted avg       0.96      0.99      0.97      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6692, Accuracy: 0.7137, F1 Micro: 0.7137, F1 Macro: 0.591\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5728, Accuracy: 0.8963, F1 Micro: 0.8963, F1 Macro: 0.8855\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3367, Accuracy: 0.9212, F1 Micro: 0.9212, F1 Macro: 0.909\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2505, Accuracy: 0.9378, F1 Micro: 0.9378, F1 Macro: 0.9324\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1886, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9337\n",
      "Epoch 6/10, Train Loss: 0.2052, Accuracy: 0.917, F1 Micro: 0.917, F1 Macro: 0.9109\n",
      "Epoch 7/10, Train Loss: 0.1151, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9256\n",
      "Epoch 8/10, Train Loss: 0.1032, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.9067\n",
      "Epoch 9/10, Train Loss: 0.1297, Accuracy: 0.917, F1 Micro: 0.917, F1 Macro: 0.9109\n",
      "Epoch 10/10, Train Loss: 0.0581, Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.9269\n",
      "\n",
      "Sentiment analysis accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9337\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.88      0.91        81\n",
      "    positive       0.94      0.97      0.96       160\n",
      "\n",
      "    accuracy                           0.94       241\n",
      "   macro avg       0.94      0.93      0.93       241\n",
      "weighted avg       0.94      0.94      0.94       241\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 333: Accuracy: 0.9475, F1 Micro: 0.9475, F1 Macro: 0.8969\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.73      0.84        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.88      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.69      0.79        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.78      0.76      0.77        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.88      0.81      0.84       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.75      0.86        12\n",
      "     neutral       0.88      0.97      0.93       152\n",
      "    positive       0.90      0.67      0.77        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.93      0.80      0.85       216\n",
      "weighted avg       0.89      0.89      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.87      0.89        23\n",
      "     neutral       0.96      0.98      0.97       152\n",
      "    positive       0.87      0.80      0.84        41\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.88      0.90       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.89      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 89.53502154350281 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.07417160272598267\n",
      "Samples above threshold: 54\n",
      "Acquired samples: 54\n",
      "Sampling duration: 5.100371599197388 seconds\n",
      "New train size: 387\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5356, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4625, Accuracy: 0.7961, F1 Micro: 0.8856, F1 Macro: 0.8842\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4362, Accuracy: 0.8289, F1 Micro: 0.902, F1 Macro: 0.9011\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3648, Accuracy: 0.881, F1 Micro: 0.929, F1 Macro: 0.9285\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2681, Accuracy: 0.9308, F1 Micro: 0.9571, F1 Macro: 0.9553\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2108, Accuracy: 0.9442, F1 Micro: 0.9651, F1 Macro: 0.9635\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1487, Accuracy: 0.9539, F1 Micro: 0.9714, F1 Macro: 0.9701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.119, Accuracy: 0.9554, F1 Micro: 0.9723, F1 Macro: 0.9709\n",
      "Epoch 9/10, Train Loss: 0.1017, Accuracy: 0.9554, F1 Micro: 0.9722, F1 Macro: 0.9707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0822, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9723\n",
      "\n",
      "Aspect detection accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9723\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.94      0.99      0.96       175\n",
      "      others       0.91      0.94      0.92       158\n",
      "        part       0.97      0.97      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      1061\n",
      "   macro avg       0.96      0.98      0.97      1061\n",
      "weighted avg       0.96      0.98      0.97      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6707, Accuracy: 0.7431, F1 Micro: 0.7431, F1 Macro: 0.7384\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4787, Accuracy: 0.8063, F1 Micro: 0.8063, F1 Macro: 0.7997\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3347, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9249\n",
      "Epoch 4/10, Train Loss: 0.2689, Accuracy: 0.917, F1 Micro: 0.917, F1 Macro: 0.9088\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1714, Accuracy: 0.9447, F1 Micro: 0.9447, F1 Macro: 0.938\n",
      "Epoch 6/10, Train Loss: 0.1609, Accuracy: 0.9209, F1 Micro: 0.9209, F1 Macro: 0.9133\n",
      "Epoch 7/10, Train Loss: 0.1023, Accuracy: 0.917, F1 Micro: 0.917, F1 Macro: 0.9088\n",
      "Epoch 8/10, Train Loss: 0.0845, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9249\n",
      "Epoch 9/10, Train Loss: 0.0997, Accuracy: 0.9289, F1 Micro: 0.9289, F1 Macro: 0.9207\n",
      "Epoch 10/10, Train Loss: 0.0645, Accuracy: 0.9328, F1 Micro: 0.9328, F1 Macro: 0.9245\n",
      "\n",
      "Sentiment analysis accuracy: 0.9447, F1 Micro: 0.9447, F1 Macro: 0.938\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.97      0.92        80\n",
      "    positive       0.99      0.93      0.96       173\n",
      "\n",
      "    accuracy                           0.94       253\n",
      "   macro avg       0.93      0.95      0.94       253\n",
      "weighted avg       0.95      0.94      0.95       253\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 387: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.91\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.99      0.94      0.97       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.93      0.99      0.96       167\n",
      "    positive       0.92      0.70      0.79        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.93      0.81      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.75      0.72        12\n",
      "     neutral       0.91      0.93      0.92       152\n",
      "    positive       0.83      0.75      0.79        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.81      0.81      0.81       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.97      0.97      0.97       152\n",
      "    positive       0.97      0.88      0.92        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.92      0.95      0.93       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 93.01556754112244 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.03524131774902344\n",
      "Samples above threshold: 48\n",
      "Acquired samples: 48\n",
      "Sampling duration: 4.868350505828857 seconds\n",
      "New train size: 435\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5481, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4734, Accuracy: 0.7961, F1 Micro: 0.8856, F1 Macro: 0.8842\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4256, Accuracy: 0.8393, F1 Micro: 0.9072, F1 Macro: 0.9064\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3497, Accuracy: 0.9211, F1 Micro: 0.9517, F1 Macro: 0.9497\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2496, Accuracy: 0.939, F1 Micro: 0.9619, F1 Macro: 0.9596\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1798, Accuracy: 0.9494, F1 Micro: 0.9685, F1 Macro: 0.9669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1406, Accuracy: 0.9554, F1 Micro: 0.9721, F1 Macro: 0.9708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1158, Accuracy: 0.9561, F1 Micro: 0.9725, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0888, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.079, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9746\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9746\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.89      0.96      0.92       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.96      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.97      1061\n",
      "weighted avg       0.96      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6663, Accuracy: 0.7733, F1 Micro: 0.7733, F1 Macro: 0.7692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4927, Accuracy: 0.919, F1 Micro: 0.919, F1 Macro: 0.9093\n",
      "Epoch 3/10, Train Loss: 0.3018, Accuracy: 0.9028, F1 Micro: 0.9028, F1 Macro: 0.897\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2764, Accuracy: 0.9433, F1 Micro: 0.9433, F1 Macro: 0.9382\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2035, Accuracy: 0.9555, F1 Micro: 0.9555, F1 Macro: 0.9508\n",
      "Epoch 6/10, Train Loss: 0.1366, Accuracy: 0.9312, F1 Micro: 0.9312, F1 Macro: 0.9212\n",
      "Epoch 7/10, Train Loss: 0.1032, Accuracy: 0.9352, F1 Micro: 0.9352, F1 Macro: 0.9256\n",
      "Epoch 8/10, Train Loss: 0.1019, Accuracy: 0.9433, F1 Micro: 0.9433, F1 Macro: 0.9372\n",
      "Epoch 9/10, Train Loss: 0.0995, Accuracy: 0.9433, F1 Micro: 0.9433, F1 Macro: 0.9376\n",
      "Epoch 10/10, Train Loss: 0.0728, Accuracy: 0.9393, F1 Micro: 0.9393, F1 Macro: 0.934\n",
      "\n",
      "Sentiment analysis accuracy: 0.9555, F1 Micro: 0.9555, F1 Macro: 0.9508\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        83\n",
      "    positive       0.98      0.95      0.97       164\n",
      "\n",
      "    accuracy                           0.96       247\n",
      "   macro avg       0.95      0.96      0.95       247\n",
      "weighted avg       0.96      0.96      0.96       247\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 435: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9149\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.94      0.99      0.97       167\n",
      "    positive       0.92      0.70      0.79        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.86      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.89      0.96      0.92       152\n",
      "    positive       0.85      0.67      0.75        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.85      0.79      0.82       216\n",
      "weighted avg       0.88      0.88      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 103.13871502876282 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.03621525764465332\n",
      "Samples above threshold: 43\n",
      "Acquired samples: 43\n",
      "Sampling duration: 4.388256311416626 seconds\n",
      "New train size: 478\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5505, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4846, Accuracy: 0.8021, F1 Micro: 0.8885, F1 Macro: 0.887\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4024, Accuracy: 0.8534, F1 Micro: 0.9149, F1 Macro: 0.914\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.317, Accuracy: 0.9368, F1 Micro: 0.9609, F1 Macro: 0.9591\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2297, Accuracy: 0.942, F1 Micro: 0.9636, F1 Macro: 0.961\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1699, Accuracy: 0.9479, F1 Micro: 0.9676, F1 Macro: 0.9661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1219, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0986, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9739\n",
      "Epoch 9/10, Train Loss: 0.0782, Accuracy: 0.9583, F1 Micro: 0.9737, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.074, Accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9748\n",
      "\n",
      "Aspect detection accuracy: 0.9621, F1 Micro: 0.9761, F1 Macro: 0.9748\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.93      0.92       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6374, Accuracy: 0.8615, F1 Micro: 0.8615, F1 Macro: 0.8478\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4065, Accuracy: 0.9346, F1 Micro: 0.9346, F1 Macro: 0.9276\n",
      "Epoch 3/10, Train Loss: 0.264, Accuracy: 0.9308, F1 Micro: 0.9308, F1 Macro: 0.9204\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2072, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9347\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1636, Accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9395\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1524, Accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.944\n",
      "Epoch 7/10, Train Loss: 0.0993, Accuracy: 0.9423, F1 Micro: 0.9423, F1 Macro: 0.9347\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1208, Accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.944\n",
      "Epoch 9/10, Train Loss: 0.081, Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.9309\n",
      "Epoch 10/10, Train Loss: 0.076, Accuracy: 0.9462, F1 Micro: 0.9462, F1 Macro: 0.9384\n",
      "\n",
      "Sentiment analysis accuracy: 0.95, F1 Micro: 0.95, F1 Macro: 0.944\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.96      0.93        84\n",
      "    positive       0.98      0.94      0.96       176\n",
      "\n",
      "    accuracy                           0.95       260\n",
      "   macro avg       0.94      0.95      0.94       260\n",
      "weighted avg       0.95      0.95      0.95       260\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 478: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9157\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.94      0.99      0.97       167\n",
      "    positive       0.92      0.70      0.79        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.86      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.92      0.93      0.92       152\n",
      "    positive       0.78      0.77      0.78        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.82      0.82      0.82       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.89      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 107.22045755386353 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.021922707557678223\n",
      "Samples above threshold: 39\n",
      "Acquired samples: 39\n",
      "Sampling duration: 4.141707181930542 seconds\n",
      "New train size: 517\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5495, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4827, Accuracy: 0.814, F1 Micro: 0.8945, F1 Macro: 0.8932\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3983, Accuracy: 0.8921, F1 Micro: 0.9355, F1 Macro: 0.9343\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2657, Accuracy: 0.9479, F1 Micro: 0.9676, F1 Macro: 0.9661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1883, Accuracy: 0.9501, F1 Micro: 0.9689, F1 Macro: 0.9674\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1367, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9724\n",
      "Epoch 7/10, Train Loss: 0.1092, Accuracy: 0.9576, F1 Micro: 0.9735, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0857, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0717, Accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9765\n",
      "Epoch 10/10, Train Loss: 0.0643, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9748\n",
      "\n",
      "Aspect detection accuracy: 0.9643, F1 Micro: 0.9776, F1 Macro: 0.9765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      0.99      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6468, Accuracy: 0.7968, F1 Micro: 0.7968, F1 Macro: 0.7254\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4075, Accuracy: 0.9283, F1 Micro: 0.9283, F1 Macro: 0.922\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2181, Accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9381\n",
      "Epoch 4/10, Train Loss: 0.2213, Accuracy: 0.9323, F1 Micro: 0.9323, F1 Macro: 0.9262\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1267, Accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9381\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1253, Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9466\n",
      "Epoch 7/10, Train Loss: 0.1043, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9292\n",
      "Epoch 8/10, Train Loss: 0.0958, Accuracy: 0.9363, F1 Micro: 0.9363, F1 Macro: 0.9296\n",
      "Epoch 9/10, Train Loss: 0.0875, Accuracy: 0.9402, F1 Micro: 0.9402, F1 Macro: 0.9339\n",
      "Epoch 10/10, Train Loss: 0.0742, Accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.937\n",
      "\n",
      "Sentiment analysis accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.9466\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93        83\n",
      "    positive       0.98      0.95      0.96       168\n",
      "\n",
      "    accuracy                           0.95       251\n",
      "   macro avg       0.94      0.95      0.95       251\n",
      "weighted avg       0.95      0.95      0.95       251\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 517: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9159\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.94      0.99      0.97       167\n",
      "    positive       0.92      0.70      0.79        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.83      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.92      0.96      0.94       152\n",
      "    positive       0.85      0.75      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.86      0.82      0.84       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 108.48020315170288 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 540\n",
      "Threshold: 0.018632209300994875\n",
      "Samples above threshold: 35\n",
      "Acquired samples: 23\n",
      "Sampling duration: 3.8248894214630127 seconds\n",
      "New train size: 540\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.537, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4674, Accuracy: 0.811, F1 Micro: 0.893, F1 Macro: 0.8916\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3937, Accuracy: 0.9122, F1 Micro: 0.9468, F1 Macro: 0.9455\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2733, Accuracy: 0.9479, F1 Micro: 0.9675, F1 Macro: 0.9656\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1917, Accuracy: 0.9576, F1 Micro: 0.9736, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1455, Accuracy: 0.9613, F1 Micro: 0.9759, F1 Macro: 0.9746\n",
      "Epoch 7/10, Train Loss: 0.1104, Accuracy: 0.9591, F1 Micro: 0.9744, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0853, Accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9777\n",
      "Epoch 9/10, Train Loss: 0.0753, Accuracy: 0.9583, F1 Micro: 0.9738, F1 Macro: 0.9718\n",
      "Epoch 10/10, Train Loss: 0.0617, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9786, F1 Macro: 0.9777\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.91      0.97      0.94       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.618, Accuracy: 0.8514, F1 Micro: 0.8514, F1 Macro: 0.8242\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3579, Accuracy: 0.8916, F1 Micro: 0.8916, F1 Macro: 0.8844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3177, Accuracy: 0.9357, F1 Micro: 0.9357, F1 Macro: 0.9289\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2016, Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9371\n",
      "Epoch 5/10, Train Loss: 0.164, Accuracy: 0.9357, F1 Micro: 0.9357, F1 Macro: 0.9263\n",
      "Epoch 6/10, Train Loss: 0.169, Accuracy: 0.9317, F1 Micro: 0.9317, F1 Macro: 0.9239\n",
      "Epoch 7/10, Train Loss: 0.1388, Accuracy: 0.9357, F1 Micro: 0.9357, F1 Macro: 0.9286\n",
      "Epoch 8/10, Train Loss: 0.1043, Accuracy: 0.9357, F1 Micro: 0.9357, F1 Macro: 0.9293\n",
      "Epoch 9/10, Train Loss: 0.1096, Accuracy: 0.9237, F1 Micro: 0.9237, F1 Macro: 0.9163\n",
      "Epoch 10/10, Train Loss: 0.0589, Accuracy: 0.9277, F1 Micro: 0.9277, F1 Macro: 0.9196\n",
      "\n",
      "Sentiment analysis accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.9371\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        82\n",
      "    positive       0.97      0.95      0.96       167\n",
      "\n",
      "    accuracy                           0.94       249\n",
      "   macro avg       0.93      0.94      0.94       249\n",
      "weighted avg       0.94      0.94      0.94       249\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 540: Accuracy: 0.9568, F1 Micro: 0.9568, F1 Macro: 0.9117\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.94      0.99      0.97       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.84      0.88       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.91      0.97      0.94       152\n",
      "    positive       0.86      0.71      0.78        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.84      0.81      0.82       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.95      0.88      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.86      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 106.59740257263184 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.03544610738754272\n",
      "Samples above threshold: 33\n",
      "Acquired samples: 33\n",
      "Sampling duration: 3.667421340942383 seconds\n",
      "New train size: 573\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.541, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4775, Accuracy: 0.811, F1 Micro: 0.8931, F1 Macro: 0.8917\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3785, Accuracy: 0.9144, F1 Micro: 0.9479, F1 Macro: 0.9466\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2574, Accuracy: 0.9509, F1 Micro: 0.9696, F1 Macro: 0.9684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.175, Accuracy: 0.9524, F1 Micro: 0.9705, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1457, Accuracy: 0.9576, F1 Micro: 0.9736, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1058, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0891, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9758\n",
      "Epoch 9/10, Train Loss: 0.0696, Accuracy: 0.9598, F1 Micro: 0.9749, F1 Macro: 0.9734\n",
      "Epoch 10/10, Train Loss: 0.0608, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9746\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.9758\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.93      0.93       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6282, Accuracy: 0.8784, F1 Micro: 0.8784, F1 Macro: 0.8593\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3347, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9227\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2165, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9386\n",
      "Epoch 4/10, Train Loss: 0.2111, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9348\n",
      "Epoch 5/10, Train Loss: 0.157, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9324\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1075, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9386\n",
      "Epoch 7/10, Train Loss: 0.0923, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9306\n",
      "Epoch 8/10, Train Loss: 0.094, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9336\n",
      "Epoch 9/10, Train Loss: 0.0859, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9302\n",
      "Epoch 10/10, Train Loss: 0.0665, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9344\n",
      "\n",
      "Sentiment analysis accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9386\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.95      0.92        83\n",
      "    positive       0.98      0.94      0.96       172\n",
      "\n",
      "    accuracy                           0.95       255\n",
      "   macro avg       0.93      0.95      0.94       255\n",
      "weighted avg       0.95      0.95      0.95       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 573: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9123\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.87      0.90       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.93      0.93      0.93       152\n",
      "    positive       0.78      0.77      0.78        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.82      0.82      0.82       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.80      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.86      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 109.87421870231628 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.0207061767578125\n",
      "Samples above threshold: 30\n",
      "Acquired samples: 30\n",
      "Sampling duration: 3.4595887660980225 seconds\n",
      "New train size: 603\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5376, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4678, Accuracy: 0.8289, F1 Micro: 0.902, F1 Macro: 0.9008\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3497, Accuracy: 0.9323, F1 Micro: 0.9587, F1 Macro: 0.957\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.236, Accuracy: 0.9539, F1 Micro: 0.9715, F1 Macro: 0.9703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1611, Accuracy: 0.9568, F1 Micro: 0.9731, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1217, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0955, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0833, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0658, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9763\n",
      "Epoch 10/10, Train Loss: 0.0594, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9722\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9763\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.89      0.99      0.94       158\n",
      "        part       0.99      0.97      0.98       158\n",
      "       price       0.98      0.99      0.98       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6292, Accuracy: 0.864, F1 Micro: 0.864, F1 Macro: 0.8551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3218, Accuracy: 0.912, F1 Micro: 0.912, F1 Macro: 0.905\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2115, Accuracy: 0.944, F1 Micro: 0.944, F1 Macro: 0.9383\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1778, Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9502\n",
      "Epoch 5/10, Train Loss: 0.1653, Accuracy: 0.948, F1 Micro: 0.948, F1 Macro: 0.9412\n",
      "Epoch 6/10, Train Loss: 0.1258, Accuracy: 0.932, F1 Micro: 0.932, F1 Macro: 0.9253\n",
      "Epoch 7/10, Train Loss: 0.0998, Accuracy: 0.896, F1 Micro: 0.896, F1 Macro: 0.8887\n",
      "Epoch 8/10, Train Loss: 0.0823, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9141\n",
      "Epoch 9/10, Train Loss: 0.0671, Accuracy: 0.94, F1 Micro: 0.94, F1 Macro: 0.9337\n",
      "Epoch 10/10, Train Loss: 0.0346, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.9169\n",
      "\n",
      "Sentiment analysis accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.9502\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.93        82\n",
      "    positive       0.97      0.96      0.97       168\n",
      "\n",
      "    accuracy                           0.96       250\n",
      "   macro avg       0.95      0.95      0.95       250\n",
      "weighted avg       0.96      0.96      0.96       250\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 603: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.9178\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.89      0.85      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.89      0.99      0.94       152\n",
      "    positive       0.95      0.69      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.91      0.81      0.85       216\n",
      "weighted avg       0.91      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.96      0.94        23\n",
      "     neutral       0.99      0.97      0.98       152\n",
      "    positive       0.90      0.93      0.92        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.95      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83        13\n",
      "     neutral       0.98      0.99      0.98       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.88      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.86      0.92        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.95      0.96       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Total train time: 116.57002019882202 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.02245807647705078\n",
      "Samples above threshold: 27\n",
      "Acquired samples: 27\n",
      "Sampling duration: 3.3046884536743164 seconds\n",
      "New train size: 630\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5377, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4573, Accuracy: 0.8318, F1 Micro: 0.9037, F1 Macro: 0.9025\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3407, Accuracy: 0.9382, F1 Micro: 0.9618, F1 Macro: 0.96\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2154, Accuracy: 0.9479, F1 Micro: 0.9675, F1 Macro: 0.9653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1567, Accuracy: 0.9568, F1 Micro: 0.973, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1185, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9757\n",
      "Epoch 7/10, Train Loss: 0.0935, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9734\n",
      "Epoch 8/10, Train Loss: 0.0768, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0641, Accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9784\n",
      "Epoch 10/10, Train Loss: 0.0533, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.9673, F1 Micro: 0.9795, F1 Macro: 0.9784\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.93      0.96      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5781, Accuracy: 0.8784, F1 Micro: 0.8784, F1 Macro: 0.8679\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.325, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9351\n",
      "Epoch 3/10, Train Loss: 0.2137, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9107\n",
      "Epoch 4/10, Train Loss: 0.1928, Accuracy: 0.902, F1 Micro: 0.902, F1 Macro: 0.8954\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.156, Accuracy: 0.949, F1 Micro: 0.949, F1 Macro: 0.9428\n",
      "Epoch 6/10, Train Loss: 0.1215, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9389\n",
      "Epoch 7/10, Train Loss: 0.1133, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9306\n",
      "Epoch 8/10, Train Loss: 0.0813, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9328\n",
      "Epoch 9/10, Train Loss: 0.1022, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9332\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.056, Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9477\n",
      "\n",
      "Sentiment analysis accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9477\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.96      0.93        84\n",
      "    positive       0.98      0.95      0.96       171\n",
      "\n",
      "    accuracy                           0.95       255\n",
      "   macro avg       0.94      0.96      0.95       255\n",
      "weighted avg       0.95      0.95      0.95       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 630: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9232\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        16\n",
      "     neutral       0.95      0.99      0.97       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.86      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        12\n",
      "     neutral       0.94      0.95      0.94       152\n",
      "    positive       0.84      0.83      0.83        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.89      0.84      0.87       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       1.00      0.78      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.92      0.92       216\n",
      "weighted avg       0.96      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.86      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 115.88258194923401 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 648\n",
      "Threshold: 0.014288115501403815\n",
      "Samples above threshold: 24\n",
      "Acquired samples: 18\n",
      "Sampling duration: 3.1689865589141846 seconds\n",
      "New train size: 648\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.548, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4573, Accuracy: 0.8549, F1 Micro: 0.9152, F1 Macro: 0.9144\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3217, Accuracy: 0.939, F1 Micro: 0.9622, F1 Macro: 0.9603\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2031, Accuracy: 0.9524, F1 Micro: 0.9704, F1 Macro: 0.969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1379, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.974\n",
      "Epoch 6/10, Train Loss: 0.112, Accuracy: 0.9598, F1 Micro: 0.9747, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0868, Accuracy: 0.9606, F1 Micro: 0.9754, F1 Macro: 0.9743\n",
      "Epoch 8/10, Train Loss: 0.0718, Accuracy: 0.9576, F1 Micro: 0.9734, F1 Macro: 0.9719\n",
      "Epoch 9/10, Train Loss: 0.0623, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0497, Accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9746\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.9757, F1 Macro: 0.9746\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.94      0.99      0.96       175\n",
      "      others       0.91      0.94      0.93       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.96      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5699, Accuracy: 0.8824, F1 Micro: 0.8824, F1 Macro: 0.8712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3241, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.934\n",
      "Epoch 3/10, Train Loss: 0.2383, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9265\n",
      "Epoch 4/10, Train Loss: 0.1515, Accuracy: 0.9373, F1 Micro: 0.9373, F1 Macro: 0.9306\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1478, Accuracy: 0.9451, F1 Micro: 0.9451, F1 Macro: 0.9379\n",
      "Epoch 6/10, Train Loss: 0.1158, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9265\n",
      "Epoch 7/10, Train Loss: 0.1031, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9328\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0877, Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9471\n",
      "Epoch 9/10, Train Loss: 0.0749, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9248\n",
      "Epoch 10/10, Train Loss: 0.0739, Accuracy: 0.9412, F1 Micro: 0.9412, F1 Macro: 0.9344\n",
      "\n",
      "Sentiment analysis accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.9471\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.96      0.93        82\n",
      "    positive       0.98      0.95      0.96       173\n",
      "\n",
      "    accuracy                           0.95       255\n",
      "   macro avg       0.94      0.96      0.95       255\n",
      "weighted avg       0.95      0.95      0.95       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 648: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9165\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80        16\n",
      "     neutral       0.93      0.99      0.96       167\n",
      "    positive       0.88      0.67      0.76        33\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.89      0.80      0.84       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.83      0.91        12\n",
      "     neutral       0.92      0.94      0.93       152\n",
      "    positive       0.82      0.79      0.80        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.91      0.85      0.88       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.83      0.89        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.92      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.88      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 119.75396537780762 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.012202143669128418\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.9446983337402344 seconds\n",
      "New train size: 673\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.542, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4587, Accuracy: 0.8631, F1 Micro: 0.9199, F1 Macro: 0.9193\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3097, Accuracy: 0.9516, F1 Micro: 0.97, F1 Macro: 0.9687\n",
      "Epoch 4/10, Train Loss: 0.1967, Accuracy: 0.9509, F1 Micro: 0.9692, F1 Macro: 0.9669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1353, Accuracy: 0.9539, F1 Micro: 0.9709, F1 Macro: 0.9683\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.103, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0818, Accuracy: 0.9628, F1 Micro: 0.9767, F1 Macro: 0.9755\n",
      "Epoch 8/10, Train Loss: 0.068, Accuracy: 0.9621, F1 Micro: 0.9763, F1 Macro: 0.9753\n",
      "Epoch 9/10, Train Loss: 0.0586, Accuracy: 0.9606, F1 Micro: 0.9752, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0503, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9766\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9766\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.97      0.98      0.97       175\n",
      "      others       0.91      0.95      0.93       158\n",
      "        part       0.97      0.98      0.97       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6124, Accuracy: 0.8779, F1 Micro: 0.8779, F1 Macro: 0.8589\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3254, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.9316\n",
      "Epoch 3/10, Train Loss: 0.2341, Accuracy: 0.9237, F1 Micro: 0.9237, F1 Macro: 0.9162\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1827, Accuracy: 0.9504, F1 Micro: 0.9504, F1 Macro: 0.9445\n",
      "Epoch 5/10, Train Loss: 0.1388, Accuracy: 0.9275, F1 Micro: 0.9275, F1 Macro: 0.9202\n",
      "Epoch 6/10, Train Loss: 0.1365, Accuracy: 0.9351, F1 Micro: 0.9351, F1 Macro: 0.9267\n",
      "Epoch 7/10, Train Loss: 0.1039, Accuracy: 0.9313, F1 Micro: 0.9313, F1 Macro: 0.9242\n",
      "Epoch 8/10, Train Loss: 0.0841, Accuracy: 0.9275, F1 Micro: 0.9275, F1 Macro: 0.9202\n",
      "Epoch 9/10, Train Loss: 0.0688, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.9005\n",
      "Epoch 10/10, Train Loss: 0.0628, Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.9312\n",
      "\n",
      "Sentiment analysis accuracy: 0.9504, F1 Micro: 0.9504, F1 Macro: 0.9445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.98      0.93        84\n",
      "    positive       0.99      0.94      0.96       178\n",
      "\n",
      "    accuracy                           0.95       262\n",
      "   macro avg       0.93      0.96      0.94       262\n",
      "weighted avg       0.95      0.95      0.95       262\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 673: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.9194\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.97      0.98      0.97       167\n",
      "    positive       0.88      0.85      0.86        33\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.90      0.90       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.92      0.95      0.93       152\n",
      "    positive       0.83      0.75      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.83      0.82      0.82       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      1.00      0.94        23\n",
      "     neutral       0.97      0.98      0.97       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      1.00      0.97        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 121.82925200462341 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.013831257820129395\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.8768672943115234 seconds\n",
      "New train size: 698\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5397, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4522, Accuracy: 0.8653, F1 Micro: 0.9207, F1 Macro: 0.9201\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3124, Accuracy: 0.9464, F1 Micro: 0.9667, F1 Macro: 0.9649\n",
      "Epoch 4/10, Train Loss: 0.2028, Accuracy: 0.9457, F1 Micro: 0.9657, F1 Macro: 0.9622\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1413, Accuracy: 0.9583, F1 Micro: 0.9739, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1133, Accuracy: 0.9621, F1 Micro: 0.9762, F1 Macro: 0.975\n",
      "Epoch 7/10, Train Loss: 0.0874, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9733\n",
      "Epoch 8/10, Train Loss: 0.0738, Accuracy: 0.9598, F1 Micro: 0.9748, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0601, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9765\n",
      "Epoch 10/10, Train Loss: 0.0511, Accuracy: 0.9576, F1 Micro: 0.9732, F1 Macro: 0.9711\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.94      0.92      0.93       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5335, Accuracy: 0.9132, F1 Micro: 0.9132, F1 Macro: 0.9025\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2481, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9331\n",
      "Epoch 3/10, Train Loss: 0.1874, Accuracy: 0.9358, F1 Micro: 0.9358, F1 Macro: 0.9257\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1381, Accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9323\n",
      "Epoch 5/10, Train Loss: 0.1265, Accuracy: 0.9321, F1 Micro: 0.9321, F1 Macro: 0.9221\n",
      "Epoch 6/10, Train Loss: 0.1184, Accuracy: 0.9208, F1 Micro: 0.9208, F1 Macro: 0.9128\n",
      "Epoch 7/10, Train Loss: 0.0924, Accuracy: 0.9208, F1 Micro: 0.9208, F1 Macro: 0.9128\n",
      "Epoch 8/10, Train Loss: 0.0952, Accuracy: 0.9358, F1 Micro: 0.9358, F1 Macro: 0.9257\n",
      "Epoch 9/10, Train Loss: 0.0621, Accuracy: 0.9358, F1 Micro: 0.9358, F1 Macro: 0.9266\n",
      "Epoch 10/10, Train Loss: 0.0699, Accuracy: 0.9358, F1 Micro: 0.9358, F1 Macro: 0.9262\n",
      "\n",
      "Sentiment analysis accuracy: 0.9396, F1 Micro: 0.9396, F1 Macro: 0.9323\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.94      0.91        86\n",
      "    positive       0.97      0.94      0.95       179\n",
      "\n",
      "    accuracy                           0.94       265\n",
      "   macro avg       0.93      0.94      0.93       265\n",
      "weighted avg       0.94      0.94      0.94       265\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 698: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.9122\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.82      0.86        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.88      0.88        24\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.90      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.88      0.70      0.78        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.83      0.86       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.94      0.93      0.93       152\n",
      "    positive       0.78      0.81      0.79        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.85      0.86      0.85       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.93      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 123.31658887863159 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.014435946941375732\n",
      "Samples above threshold: 17\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.4988694190979004 seconds\n",
      "New train size: 723\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5496, Accuracy: 0.7917, F1 Micro: 0.8834, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.435, Accuracy: 0.8802, F1 Micro: 0.9285, F1 Macro: 0.9278\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2926, Accuracy: 0.9487, F1 Micro: 0.968, F1 Macro: 0.9662\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1892, Accuracy: 0.9568, F1 Micro: 0.9731, F1 Macro: 0.9717\n",
      "Epoch 5/10, Train Loss: 0.1393, Accuracy: 0.9568, F1 Micro: 0.9729, F1 Macro: 0.9712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.104, Accuracy: 0.9606, F1 Micro: 0.9753, F1 Macro: 0.974\n",
      "Epoch 7/10, Train Loss: 0.0853, Accuracy: 0.9583, F1 Micro: 0.9737, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0654, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9741\n",
      "Epoch 9/10, Train Loss: 0.0562, Accuracy: 0.9591, F1 Micro: 0.9742, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0472, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.974\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.974\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.91      0.92      0.92       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.97      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.502, Accuracy: 0.8897, F1 Micro: 0.8897, F1 Macro: 0.8813\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2442, Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9392\n",
      "Epoch 3/10, Train Loss: 0.1863, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9361\n",
      "Epoch 4/10, Train Loss: 0.1284, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.9361\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1312, Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.9443\n",
      "Epoch 6/10, Train Loss: 0.0887, Accuracy: 0.9468, F1 Micro: 0.9468, F1 Macro: 0.9384\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0838, Accuracy: 0.9544, F1 Micro: 0.9544, F1 Macro: 0.9485\n",
      "Epoch 8/10, Train Loss: 0.0646, Accuracy: 0.943, F1 Micro: 0.943, F1 Macro: 0.935\n",
      "Epoch 9/10, Train Loss: 0.0616, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9296\n",
      "Epoch 10/10, Train Loss: 0.0632, Accuracy: 0.9392, F1 Micro: 0.9392, F1 Macro: 0.9317\n",
      "\n",
      "Sentiment analysis accuracy: 0.9544, F1 Micro: 0.9544, F1 Macro: 0.9485\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.93        83\n",
      "    positive       0.99      0.94      0.97       180\n",
      "\n",
      "    accuracy                           0.95       263\n",
      "   macro avg       0.94      0.96      0.95       263\n",
      "weighted avg       0.96      0.95      0.95       263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 723: Accuracy: 0.9537, F1 Micro: 0.9537, F1 Macro: 0.9182\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.84      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.92      0.92      0.92       152\n",
      "    positive       0.77      0.77      0.77        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.83      0.81      0.82       216\n",
      "weighted avg       0.87      0.88      0.87       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.92      0.83      0.87        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.88      0.91        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.92      0.91      0.92       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 129.22407579421997 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.010259628295898438\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 25\n",
      "Sampling duration: 4.36194920539856 seconds\n",
      "New train size: 748\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5338, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4193, Accuracy: 0.8862, F1 Micro: 0.9325, F1 Macro: 0.9316\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2779, Accuracy: 0.9516, F1 Micro: 0.97, F1 Macro: 0.9685\n",
      "Epoch 4/10, Train Loss: 0.1801, Accuracy: 0.9524, F1 Micro: 0.9699, F1 Macro: 0.9678\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1284, Accuracy: 0.9621, F1 Micro: 0.9763, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1029, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0841, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9775\n",
      "Epoch 8/10, Train Loss: 0.0622, Accuracy: 0.9591, F1 Micro: 0.9741, F1 Macro: 0.9718\n",
      "Epoch 9/10, Train Loss: 0.0576, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.9761\n",
      "Epoch 10/10, Train Loss: 0.0466, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9765\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9775\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.92      0.96      0.94       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5478, Accuracy: 0.8941, F1 Micro: 0.8941, F1 Macro: 0.8844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2928, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.9025\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2032, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9243\n",
      "Epoch 4/10, Train Loss: 0.1181, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9146\n",
      "Epoch 5/10, Train Loss: 0.1211, Accuracy: 0.9294, F1 Micro: 0.9294, F1 Macro: 0.9191\n",
      "Epoch 6/10, Train Loss: 0.109, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9146\n",
      "Epoch 7/10, Train Loss: 0.0853, Accuracy: 0.9255, F1 Micro: 0.9255, F1 Macro: 0.9178\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0892, Accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9261\n",
      "Epoch 9/10, Train Loss: 0.0593, Accuracy: 0.9255, F1 Micro: 0.9255, F1 Macro: 0.9178\n",
      "Epoch 10/10, Train Loss: 0.0591, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.9146\n",
      "\n",
      "Sentiment analysis accuracy: 0.9333, F1 Micro: 0.9333, F1 Macro: 0.9261\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.94      0.90        84\n",
      "    positive       0.97      0.93      0.95       171\n",
      "\n",
      "    accuracy                           0.93       255\n",
      "   macro avg       0.92      0.94      0.93       255\n",
      "weighted avg       0.94      0.93      0.93       255\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 748: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.9041\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.91      0.88      0.89        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.94      0.93      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.84      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75        12\n",
      "     neutral       0.92      0.96      0.94       152\n",
      "    positive       0.84      0.73      0.78        52\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.84      0.81      0.82       216\n",
      "weighted avg       0.89      0.89      0.89       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.95      0.85      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.85      0.81        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 127.232004404068 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 756\n",
      "Threshold: 0.014330416917800903\n",
      "Samples above threshold: 12\n",
      "Acquired samples: 8\n",
      "Sampling duration: 2.092148780822754 seconds\n",
      "New train size: 756\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5224, Accuracy: 0.7894, F1 Micro: 0.8823, F1 Macro: 0.8809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4254, Accuracy: 0.8988, F1 Micro: 0.939, F1 Macro: 0.9381\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2786, Accuracy: 0.9516, F1 Micro: 0.9699, F1 Macro: 0.9684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1796, Accuracy: 0.9561, F1 Micro: 0.9727, F1 Macro: 0.9712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.14, Accuracy: 0.9598, F1 Micro: 0.9746, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.102, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9741\n",
      "Epoch 7/10, Train Loss: 0.076, Accuracy: 0.9583, F1 Micro: 0.9737, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0665, Accuracy: 0.9635, F1 Micro: 0.9772, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0537, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0469, Accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9777\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9789, F1 Macro: 0.9777\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.94      0.93       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.515, Accuracy: 0.8902, F1 Micro: 0.8902, F1 Macro: 0.8799\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2564, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.9091\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1889, Accuracy: 0.9432, F1 Micro: 0.9432, F1 Macro: 0.9366\n",
      "Epoch 4/10, Train Loss: 0.1739, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.9096\n",
      "Epoch 5/10, Train Loss: 0.1194, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.9322\n",
      "Epoch 6/10, Train Loss: 0.1064, Accuracy: 0.9394, F1 Micro: 0.9394, F1 Macro: 0.931\n",
      "Epoch 7/10, Train Loss: 0.0811, Accuracy: 0.9242, F1 Micro: 0.9242, F1 Macro: 0.9166\n",
      "Epoch 8/10, Train Loss: 0.0774, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9206\n",
      "Epoch 9/10, Train Loss: 0.067, Accuracy: 0.9205, F1 Micro: 0.9205, F1 Macro: 0.9122\n",
      "Epoch 10/10, Train Loss: 0.0625, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9197\n",
      "\n",
      "Sentiment analysis accuracy: 0.9432, F1 Micro: 0.9432, F1 Macro: 0.9366\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.95      0.92        86\n",
      "    positive       0.98      0.94      0.96       178\n",
      "\n",
      "    accuracy                           0.94       264\n",
      "   macro avg       0.93      0.95      0.94       264\n",
      "weighted avg       0.95      0.94      0.94       264\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 756: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.9213\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.96      0.98      0.97       167\n",
      "    positive       0.90      0.79      0.84        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.88      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.93      0.94      0.93       152\n",
      "    positive       0.79      0.73      0.76        52\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.81      0.83      0.82       216\n",
      "weighted avg       0.88      0.88      0.88       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.92      0.88      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 133.56465005874634 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.012040162086486816\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 25\n",
      "Sampling duration: 2.0534920692443848 seconds\n",
      "New train size: 781\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5312, Accuracy: 0.7961, F1 Micro: 0.8856, F1 Macro: 0.8842\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4203, Accuracy: 0.9174, F1 Micro: 0.9497, F1 Macro: 0.9482\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2647, Accuracy: 0.9487, F1 Micro: 0.9682, F1 Macro: 0.9668\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1781, Accuracy: 0.9554, F1 Micro: 0.9721, F1 Macro: 0.9709\n",
      "Epoch 5/10, Train Loss: 0.1246, Accuracy: 0.9531, F1 Micro: 0.9705, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0985, Accuracy: 0.9635, F1 Micro: 0.9771, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0741, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9763\n",
      "Epoch 8/10, Train Loss: 0.0614, Accuracy: 0.9643, F1 Micro: 0.9775, F1 Macro: 0.9761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0529, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "Epoch 10/10, Train Loss: 0.0472, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9748\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.99      0.97       175\n",
      "      others       0.94      0.94      0.94       158\n",
      "        part       0.97      0.99      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.97      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.481, Accuracy: 0.8774, F1 Micro: 0.8774, F1 Macro: 0.8687\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2498, Accuracy: 0.9272, F1 Micro: 0.9272, F1 Macro: 0.9201\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1838, Accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.9393\n",
      "Epoch 4/10, Train Loss: 0.1681, Accuracy: 0.931, F1 Micro: 0.931, F1 Macro: 0.9241\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1433, Accuracy: 0.9502, F1 Micro: 0.9502, F1 Macro: 0.9435\n",
      "Epoch 6/10, Train Loss: 0.0942, Accuracy: 0.931, F1 Micro: 0.931, F1 Macro: 0.9241\n",
      "Epoch 7/10, Train Loss: 0.0881, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9273\n",
      "Epoch 8/10, Train Loss: 0.0663, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9281\n",
      "Epoch 9/10, Train Loss: 0.0521, Accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.9397\n",
      "Epoch 10/10, Train Loss: 0.0552, Accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.9389\n",
      "\n",
      "Sentiment analysis accuracy: 0.9502, F1 Micro: 0.9502, F1 Macro: 0.9435\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.93      0.92        85\n",
      "    positive       0.97      0.96      0.96       176\n",
      "\n",
      "    accuracy                           0.95       261\n",
      "   macro avg       0.94      0.94      0.94       261\n",
      "weighted avg       0.95      0.95      0.95       261\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 781: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.9181\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.96      0.91      0.93       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        16\n",
      "     neutral       0.94      0.99      0.96       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.92      0.84      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        12\n",
      "     neutral       0.94      0.94      0.94       152\n",
      "    positive       0.83      0.83      0.83        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.87      0.87      0.87       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.97      0.99      0.98       152\n",
      "    positive       0.94      0.83      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.93      0.92      0.93       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      1.00      1.00       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 133.41734385490417 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.01127331256866455\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.849419355392456 seconds\n",
      "New train size: 806\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5249, Accuracy: 0.7924, F1 Micro: 0.8838, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4131, Accuracy: 0.9152, F1 Micro: 0.9487, F1 Macro: 0.9475\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2532, Accuracy: 0.9516, F1 Micro: 0.9699, F1 Macro: 0.9686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1679, Accuracy: 0.9554, F1 Micro: 0.9719, F1 Macro: 0.9699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1185, Accuracy: 0.9613, F1 Micro: 0.9756, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0881, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9775\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0741, Accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9793\n",
      "Epoch 8/10, Train Loss: 0.0563, Accuracy: 0.9658, F1 Micro: 0.9785, F1 Macro: 0.9774\n",
      "Epoch 9/10, Train Loss: 0.0482, Accuracy: 0.965, F1 Micro: 0.9779, F1 Macro: 0.9767\n",
      "Epoch 10/10, Train Loss: 0.044, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "\n",
      "Aspect detection accuracy: 0.9688, F1 Micro: 0.9803, F1 Macro: 0.9793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.95      0.98      0.96       175\n",
      "      others       0.94      0.95      0.95       158\n",
      "        part       0.98      0.99      0.98       158\n",
      "       price       0.98      1.00      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.98      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4725, Accuracy: 0.9042, F1 Micro: 0.9042, F1 Macro: 0.8963\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2439, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9148\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.171, Accuracy: 0.9387, F1 Micro: 0.9387, F1 Macro: 0.9322\n",
      "Epoch 4/10, Train Loss: 0.1476, Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.9288\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1047, Accuracy: 0.9387, F1 Micro: 0.9387, F1 Macro: 0.931\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0995, Accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.9386\n",
      "Epoch 7/10, Train Loss: 0.1044, Accuracy: 0.9387, F1 Micro: 0.9387, F1 Macro: 0.931\n",
      "Epoch 8/10, Train Loss: 0.0791, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9165\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0586, Accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.9397\n",
      "Epoch 10/10, Train Loss: 0.0414, Accuracy: 0.9272, F1 Micro: 0.9272, F1 Macro: 0.9197\n",
      "\n",
      "Sentiment analysis accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.9397\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        85\n",
      "    positive       0.97      0.95      0.96       176\n",
      "\n",
      "    accuracy                           0.95       261\n",
      "   macro avg       0.93      0.95      0.94       261\n",
      "weighted avg       0.95      0.95      0.95       261\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 806: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.9189\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        16\n",
      "     neutral       0.94      0.98      0.96       167\n",
      "    positive       0.89      0.73      0.80        33\n",
      "\n",
      "    accuracy                           0.93       216\n",
      "   macro avg       0.90      0.84      0.87       216\n",
      "weighted avg       0.93      0.93      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87        12\n",
      "     neutral       0.95      0.95      0.95       152\n",
      "    positive       0.83      0.85      0.84        52\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.90      0.88      0.89       216\n",
      "weighted avg       0.92      0.92      0.92       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      1.00      0.92        23\n",
      "     neutral       0.98      0.99      0.98       152\n",
      "    positive       0.97      0.85      0.91        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.95      0.94       216\n",
      "weighted avg       0.97      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      1.00      0.99       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.87      0.89       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 141.55125331878662 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.009955364465713502\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.6701850891113281 seconds\n",
      "New train size: 831\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5198, Accuracy: 0.7909, F1 Micro: 0.8831, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4086, Accuracy: 0.9226, F1 Micro: 0.9531, F1 Macro: 0.952\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2513, Accuracy: 0.9561, F1 Micro: 0.9727, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1648, Accuracy: 0.9591, F1 Micro: 0.9743, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1151, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0912, Accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.979\n",
      "Epoch 7/10, Train Loss: 0.0733, Accuracy: 0.968, F1 Micro: 0.9798, F1 Macro: 0.9788\n",
      "Epoch 8/10, Train Loss: 0.0606, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9769\n",
      "Epoch 9/10, Train Loss: 0.0506, Accuracy: 0.9673, F1 Micro: 0.9793, F1 Macro: 0.9784\n",
      "Epoch 10/10, Train Loss: 0.0443, Accuracy: 0.9628, F1 Micro: 0.9765, F1 Macro: 0.9747\n",
      "\n",
      "Aspect detection accuracy: 0.968, F1 Micro: 0.9799, F1 Macro: 0.979\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.93      0.97      0.95       158\n",
      "        part       0.98      0.97      0.98       158\n",
      "       price       0.98      0.99      0.99       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.97      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.97      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4949, Accuracy: 0.9147, F1 Micro: 0.9147, F1 Macro: 0.9066\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2568, Accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9355\n",
      "Epoch 3/10, Train Loss: 0.1973, Accuracy: 0.9186, F1 Micro: 0.9186, F1 Macro: 0.9106\n",
      "Epoch 4/10, Train Loss: 0.1636, Accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.9187\n",
      "Epoch 5/10, Train Loss: 0.1303, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.9232\n",
      "Epoch 6/10, Train Loss: 0.0934, Accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.9187\n",
      "Epoch 7/10, Train Loss: 0.0664, Accuracy: 0.9302, F1 Micro: 0.9302, F1 Macro: 0.9232\n",
      "Epoch 8/10, Train Loss: 0.0827, Accuracy: 0.9264, F1 Micro: 0.9264, F1 Macro: 0.9164\n",
      "Epoch 9/10, Train Loss: 0.0672, Accuracy: 0.9109, F1 Micro: 0.9109, F1 Macro: 0.9031\n",
      "Epoch 10/10, Train Loss: 0.0371, Accuracy: 0.9186, F1 Micro: 0.9186, F1 Macro: 0.9092\n",
      "\n",
      "Sentiment analysis accuracy: 0.9419, F1 Micro: 0.9419, F1 Macro: 0.9355\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.96      0.92        84\n",
      "    positive       0.98      0.93      0.96       174\n",
      "\n",
      "    accuracy                           0.94       258\n",
      "   macro avg       0.93      0.95      0.94       258\n",
      "weighted avg       0.95      0.94      0.94       258\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 831: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.9196\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       216\n",
      "   macro avg       0.98      0.97      0.98       216\n",
      "weighted avg       0.99      0.99      0.99       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.98      0.97       167\n",
      "    positive       0.89      0.76      0.82        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.91      0.87      0.89       216\n",
      "weighted avg       0.94      0.94      0.94       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.83      0.77        12\n",
      "     neutral       0.93      0.97      0.95       152\n",
      "    positive       0.91      0.75      0.82        52\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.85      0.85      0.85       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.96      0.90        23\n",
      "     neutral       0.98      0.97      0.98       152\n",
      "    positive       0.90      0.85      0.88        41\n",
      "\n",
      "    accuracy                           0.95       216\n",
      "   macro avg       0.91      0.93      0.92       216\n",
      "weighted avg       0.95      0.95      0.95       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        13\n",
      "     neutral       0.98      0.99      0.99       186\n",
      "    positive       0.93      0.82      0.87        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.92      0.89      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 134.1904695034027 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.018068289756774904\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 25\n",
      "Sampling duration: 1.4242067337036133 seconds\n",
      "New train size: 856\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5284, Accuracy: 0.7961, F1 Micro: 0.8856, F1 Macro: 0.8842\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4001, Accuracy: 0.9286, F1 Micro: 0.9562, F1 Macro: 0.9545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2417, Accuracy: 0.9561, F1 Micro: 0.9726, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1645, Accuracy: 0.9613, F1 Micro: 0.9758, F1 Macro: 0.9746\n",
      "Epoch 5/10, Train Loss: 0.1161, Accuracy: 0.9606, F1 Micro: 0.9751, F1 Macro: 0.9735\n",
      "Epoch 6/10, Train Loss: 0.0879, Accuracy: 0.9576, F1 Micro: 0.9732, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0716, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.977\n",
      "Epoch 8/10, Train Loss: 0.0616, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9768\n",
      "Epoch 9/10, Train Loss: 0.0513, Accuracy: 0.9598, F1 Micro: 0.9745, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0439, Accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.977\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9784, F1 Macro: 0.977\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      0.99      0.99       187\n",
      "     machine       0.96      0.98      0.97       175\n",
      "      others       0.94      0.93      0.93       158\n",
      "        part       0.98      0.98      0.98       158\n",
      "       price       0.99      0.99      0.99       192\n",
      "     service       1.00      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1061\n",
      "   macro avg       0.97      0.98      0.98      1061\n",
      "weighted avg       0.98      0.98      0.98      1061\n",
      " samples avg       0.97      0.98      0.97      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5133, Accuracy: 0.9145, F1 Micro: 0.9145, F1 Macro: 0.9057\n",
      "Epoch 2/10, Train Loss: 0.205, Accuracy: 0.8773, F1 Micro: 0.8773, F1 Macro: 0.8684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1969, Accuracy: 0.9219, F1 Micro: 0.9219, F1 Macro: 0.9139\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.127, Accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9376\n",
      "Epoch 5/10, Train Loss: 0.1342, Accuracy: 0.9405, F1 Micro: 0.9405, F1 Macro: 0.9324\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1093, Accuracy: 0.948, F1 Micro: 0.948, F1 Macro: 0.9405\n",
      "Epoch 7/10, Train Loss: 0.0779, Accuracy: 0.9331, F1 Micro: 0.9331, F1 Macro: 0.9253\n",
      "Epoch 8/10, Train Loss: 0.0787, Accuracy: 0.9442, F1 Micro: 0.9442, F1 Macro: 0.9372\n",
      "Epoch 9/10, Train Loss: 0.0776, Accuracy: 0.9108, F1 Micro: 0.9108, F1 Macro: 0.9019\n",
      "Epoch 10/10, Train Loss: 0.086, Accuracy: 0.9257, F1 Micro: 0.9257, F1 Macro: 0.9174\n",
      "\n",
      "Sentiment analysis accuracy: 0.948, F1 Micro: 0.948, F1 Macro: 0.9405\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        85\n",
      "    positive       0.97      0.95      0.96       184\n",
      "\n",
      "    accuracy                           0.95       269\n",
      "   macro avg       0.94      0.95      0.94       269\n",
      "weighted avg       0.95      0.95      0.95       269\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 856: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.9224\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        11\n",
      "     neutral       0.99      0.99      0.99       181\n",
      "    positive       0.92      0.92      0.92        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.97      0.94      0.95       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        16\n",
      "     neutral       0.95      0.98      0.96       167\n",
      "    positive       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.90      0.87      0.88       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        12\n",
      "     neutral       0.94      0.93      0.93       152\n",
      "    positive       0.81      0.83      0.82        52\n",
      "\n",
      "    accuracy                           0.90       216\n",
      "   macro avg       0.84      0.86      0.85       216\n",
      "weighted avg       0.90      0.90      0.90       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        23\n",
      "     neutral       0.98      0.98      0.98       152\n",
      "    positive       0.92      0.88      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.93      0.94      0.93       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.99      0.99      0.99       186\n",
      "    positive       0.94      0.94      0.94        17\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.95      0.93      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       1.00      1.00      1.00       185\n",
      "    positive       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 139.79887056350708 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 864\n",
      "Threshold: 0.005964386463165283\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 8\n",
      "Sampling duration: 1.2531964778900146 seconds\n",
      "New train size: 864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5245, Accuracy: 0.7991, F1 Micro: 0.8853, F1 Macro: 0.8829\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4065, Accuracy: 0.9249, F1 Micro: 0.9542, F1 Macro: 0.9532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.247, Accuracy: 0.9464, F1 Micro: 0.9663, F1 Macro: 0.9637\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1682, Accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9773\n",
      "Epoch 5/10, Train Loss: 0.1209, Accuracy: 0.9643, F1 Micro: 0.9777, F1 Macro: 0.9767\n",
      "Epoch 6/10, Train Loss: 0.0921, Accuracy: 0.9606, F1 Micro: 0.975, F1 Macro: 0.9732\n",
      "Epoch 7/10, Train Loss: 0.0761, Accuracy: 0.9628, F1 Micro: 0.9766, F1 Macro: 0.9752\n",
      "Epoch 8/10, Train Loss: 0.0608, Accuracy: 0.9621, F1 Micro: 0.976, F1 Macro: 0.9742\n",
      "Epoch 9/10, Train Loss: 0.0496, Accuracy: 0.965, F1 Micro: 0.978, F1 Macro: 0.9767\n",
      "Epoch 10/10, Train Loss: 0.0459, Accuracy: 0.9635, F1 Micro: 0.9769, F1 Macro: 0.9752\n",
      "\n",
      "Aspect detection accuracy: 0.965, F1 Micro: 0.9781, F1 Macro: 0.9773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fuel       0.98      1.00      0.99       187\n",
      "     machine       0.94      0.99      0.97       175\n",
      "      others       0.92      0.97      0.95       158\n",
      "        part       0.97      0.98      0.98       158\n",
      "       price       0.97      0.99      0.98       192\n",
      "     service       0.99      1.00      1.00       191\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      1061\n",
      "   macro avg       0.96      0.99      0.98      1061\n",
      "weighted avg       0.97      0.99      0.98      1061\n",
      " samples avg       0.96      0.99      0.98      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5224, Accuracy: 0.8984, F1 Micro: 0.8984, F1 Macro: 0.8897\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2709, Accuracy: 0.9553, F1 Micro: 0.9553, F1 Macro: 0.9501\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1468, Accuracy: 0.9553, F1 Micro: 0.9553, F1 Macro: 0.9498\n",
      "Epoch 4/10, Train Loss: 0.1464, Accuracy: 0.939, F1 Micro: 0.939, F1 Macro: 0.9312\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1012, Accuracy: 0.9553, F1 Micro: 0.9553, F1 Macro: 0.9492\n",
      "Epoch 6/10, Train Loss: 0.0789, Accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.9411\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0696, Accuracy: 0.9593, F1 Micro: 0.9593, F1 Macro: 0.954\n",
      "Epoch 8/10, Train Loss: 0.0648, Accuracy: 0.9512, F1 Micro: 0.9512, F1 Macro: 0.9455\n",
      "Epoch 9/10, Train Loss: 0.0623, Accuracy: 0.935, F1 Micro: 0.935, F1 Macro: 0.9281\n",
      "Epoch 10/10, Train Loss: 0.0561, Accuracy: 0.9472, F1 Micro: 0.9472, F1 Macro: 0.9411\n",
      "\n",
      "Sentiment analysis accuracy: 0.9593, F1 Micro: 0.9593, F1 Macro: 0.954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.95      0.94        80\n",
      "    positive       0.98      0.96      0.97       166\n",
      "\n",
      "    accuracy                           0.96       246\n",
      "   macro avg       0.95      0.96      0.95       246\n",
      "weighted avg       0.96      0.96      0.96       246\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 864: Accuracy: 0.9591, F1 Micro: 0.9591, F1 Macro: 0.916\n",
      "--------------------------------------------------\n",
      "Aspect fuel report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.82      0.90        11\n",
      "     neutral       0.98      1.00      0.99       181\n",
      "    positive       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.98      0.91      0.94       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "Aspect machine report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.83        16\n",
      "     neutral       0.94      0.99      0.97       167\n",
      "    positive       0.92      0.73      0.81        33\n",
      "\n",
      "    accuracy                           0.94       216\n",
      "   macro avg       0.93      0.82      0.87       216\n",
      "weighted avg       0.93      0.94      0.93       216\n",
      "\n",
      "Aspect others report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.75      0.78        12\n",
      "     neutral       0.93      0.97      0.95       152\n",
      "    positive       0.91      0.79      0.85        52\n",
      "\n",
      "    accuracy                           0.92       216\n",
      "   macro avg       0.88      0.84      0.86       216\n",
      "weighted avg       0.92      0.92      0.91       216\n",
      "\n",
      "Aspect part report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.96      0.94        23\n",
      "     neutral       0.97      0.98      0.98       152\n",
      "    positive       0.92      0.88      0.90        41\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.94      0.94      0.94       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n",
      "Aspect price report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        13\n",
      "     neutral       0.97      0.99      0.98       186\n",
      "    positive       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.94      0.87      0.90       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.96        14\n",
      "     neutral       0.99      1.00      1.00       185\n",
      "    positive       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       216\n",
      "   macro avg       1.00      0.98      0.99       216\n",
      "weighted avg       1.00      1.00      1.00       216\n",
      "\n",
      "Total train time: 134.45577359199524 s\n",
      "Total runtime: 2911.6604466438293 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAACCoAAAHqCAYAAADInz0eAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAADXuElEQVR4nOzdeXhU9fm/8TsLWdiXkEACgqICioKyFURFRVGUuhdXlFb7c7elrcV9+yq1WopVW9RqxYoVF7CuVETBBRRkcWMTUYEACWFJIJB15vfHSQKRgARCJsv9uq5zzcyZc2aeg9Q+zrzn+USFw+EwkiRJkiRJkiRJkiRJ1SA60gVIkiRJkiRJkiRJkqT6w6CCJEmSJEmSJEmSJEmqNgYVJEmSJEmSJEmSJElStTGoIEmSJEmSJEmSJEmSqo1BBUmSJEmSJEmSJEmSVG0MKkiSJEmSJEmSJEmSpGpjUEGSJEmSJEmSJEmSJFUbgwqSJEmSJEmSJEmSJKnaGFSQJEmSJEmSJEmSJEnVxqCCJEmSJEmq0S6//HI6duwY6TIkSZIkSVIVMaggSXvp73//O1FRUfTt2zfSpUiSJEn75JlnniEqKqrCbdSoUWXHvfPOO/zqV7+iW7duxMTEVDo8UPqaV1xxRYXP33rrrWXHZGVl7cslSZIkqR6xn5Wk2ic20gVIUm01YcIEOnbsyOzZs1m2bBkHH3xwpEuSJEmS9sk999zDgQceWG5ft27dyu4///zzTJw4kaOPPprU1NS9eo+EhAReeeUV/v73vxMXF1fuuf/85z8kJCSQl5dXbv+TTz5JKBTaq/eTJElS/VFT+1lJ0s6cqCBJe+G7775j5syZjBkzhtatWzNhwoRIl1Sh3NzcSJcgSZKkWuS0007jkksuKbf16NGj7Pn777+fnJwcPv74Y7p3775X73HqqaeSk5PD22+/XW7/zJkz+e677zj99NN3OqdBgwbEx8fv1fvtKBQK+aGxJElSHVZT+9n9zc+BJdVGBhUkaS9MmDCBFi1acPrpp3PeeedVGFTYtGkTv/3tb+nYsSPx8fG0a9eO4cOHlxv5lZeXx1133cWhhx5KQkICbdu25ZxzzuHbb78FYPr06URFRTF9+vRyr/39998TFRXFM888U7bv8ssvp3Hjxnz77bcMGTKEJk2acPHFFwPw4Ycfcv7553PAAQcQHx9P+/bt+e1vf8u2bdt2qnvx4sX84he/oHXr1iQmJtK5c2duvfVWAN5//32ioqKYPHnyTuc9//zzREVFMWvWrEr/eUqSJKl2SE1NpUGDBvv0GmlpaRx33HE8//zz5fZPmDCBI444otwv3kpdfvnlO43lDYVCPPzwwxxxxBEkJCTQunVrTj31VD777LOyY6KiorjuuuuYMGEChx9+OPHx8UyZMgWA+fPnc9ppp9G0aVMaN27MSSedxCeffLJP1yZJkqSaLVL9bFV9Pgtw1113ERUVxcKFC7noooto0aIFAwYMAKCoqIh7772XTp06ER8fT8eOHbnlllvIz8/fp2uWpP3BpR8kaS9MmDCBc845h7i4OC688EL+8Y9/MGfOHHr37g3Ali1bOPbYY1m0aBG//OUvOfroo8nKyuK1115j1apVJCUlUVxczBlnnMG0adO44IILuPHGG9m8eTNTp07lq6++olOnTpWuq6ioiMGDBzNgwAAeeughGjZsCMBLL73E1q1bufrqq2nVqhWzZ8/mkUceYdWqVbz00ktl53/xxRcce+yxNGjQgF//+td07NiRb7/9ltdff5377ruPgQMH0r59eyZMmMDZZ5+9059Jp06d6Nev3z78yUqSJCmSsrOzd1pLNykpqcrf56KLLuLGG29ky5YtNG7cmKKiIl566SVGjhy5xxMPfvWrX/HMM89w2mmnccUVV1BUVMSHH37IJ598Qq9evcqOe++993jxxRe57rrrSEpKomPHjnz99dcce+yxNG3alJtuuokGDRrw+OOPM3DgQGbMmEHfvn2r/JolSZK0/9XUfraqPp/d0fnnn88hhxzC/fffTzgcBuCKK65g/PjxnHfeefzud7/j008/ZfTo0SxatKjCH59JUiQZVJCkSpo7dy6LFy/mkUceAWDAgAG0a9eOCRMmlAUVHnzwQb766ismTZpU7gv92267raxpfPbZZ5k2bRpjxozht7/9bdkxo0aNKjumsvLz8zn//PMZPXp0uf0PPPAAiYmJZY9//etfc/DBB3PLLbewYsUKDjjgAACuv/56wuEw8+bNK9sH8Kc//QkIfpF2ySWXMGbMGLKzs2nWrBkA69at45133imX7JUkSVLtM2jQoJ327W1vujvnnXce1113Ha+++iqXXHIJ77zzDllZWVx44YX861//+snz33//fZ555hluuOEGHn744bL9v/vd73aqd8mSJXz55ZccdthhZfvOPvtsCgsL+eijjzjooIMAGD58OJ07d+amm25ixowZVXSlkiRJqk41tZ+tqs9nd9S9e/dyUx0+//xzxo8fzxVXXMGTTz4JwDXXXENycjIPPfQQ77//PieccEKV/RlI0r5y6QdJqqQJEyaQkpJS1tRFRUUxbNgwXnjhBYqLiwF45ZVX6N69+05TB0qPLz0mKSmJ66+/fpfH7I2rr756p307NsG5ublkZWXRv39/wuEw8+fPB4KwwQcffMAvf/nLck3wj+sZPnw4+fn5vPzyy2X7Jk6cSFFREZdccsle1y1JkqTIe+yxx5g6dWq5bX9o0aIFp556Kv/5z3+AYBmx/v3706FDhz06/5VXXiEqKoo777xzp+d+3Esff/zx5UIKxcXFvPPOO5x11lllIQWAtm3bctFFF/HRRx+Rk5OzN5clSZKkCKup/WxVfj5b6qqrrir3+K233gJg5MiR5fb/7ne/A+DNN9+szCVK0n7nRAVJqoTi4mJeeOEFTjjhBL777ruy/X379uUvf/kL06ZN45RTTuHbb7/l3HPP3e1rffvtt3Tu3JnY2Kr7V3FsbCzt2rXbaf+KFSu44447eO2119i4cWO557KzswFYvnw5QIVrqO2oS5cu9O7dmwkTJvCrX/0KCMIbP/vZzzj44IOr4jIkSZIUIX369Cm3bML+dNFFF3HppZeyYsUKXn31Vf785z/v8bnffvstqamptGzZ8iePPfDAA8s9XrduHVu3bqVz5847Hdu1a1dCoRArV67k8MMP3+N6JEmSVDPU1H62Kj+fLfXjPveHH34gOjp6p89o27RpQ/Pmzfnhhx/26HUlqboYVJCkSnjvvfdYs2YNL7zwAi+88MJOz0+YMIFTTjmlyt5vV5MVSic3/Fh8fDzR0dE7HXvyySezYcMG/vjHP9KlSxcaNWpEeno6l19+OaFQqNJ1DR8+nBtvvJFVq1aRn5/PJ598wqOPPlrp15EkSVL99fOf/5z4+Hguu+wy8vPz+cUvfrFf3mfHX69JkiRJVWVP+9n98fks7LrP3ZdpvZJUnQwqSFIlTJgwgeTkZB577LGdnps0aRKTJ09m3LhxdOrUia+++mq3r9WpUyc+/fRTCgsLadCgQYXHtGjRAoBNmzaV21+Z9OuXX37J0qVLGT9+PMOHDy/b/+OxZ6Vjb3+qboALLriAkSNH8p///Idt27bRoEEDhg0btsc1SZIkSYmJiZx11lk899xznHbaaSQlJe3xuZ06deJ///sfGzZs2KOpCjtq3bo1DRs2ZMmSJTs9t3jxYqKjo2nfvn2lXlOSJEn1z572s/vj89mKdOjQgVAoxDfffEPXrl3L9mdkZLBp06Y9XmZNkqpL9E8fIkkC2LZtG5MmTeKMM87gvPPO22m77rrr2Lx5M6+99hrnnnsun3/+OZMnT97pdcLhMADnnnsuWVlZFU4iKD2mQ4cOxMTE8MEHH5R7/u9///se1x0TE1PuNUvvP/zww+WOa926NccddxxPP/00K1asqLCeUklJSZx22mk899xzTJgwgVNPPbVSHyxLkiRJAL///e+58847uf322yt13rnnnks4HObuu+/e6bkf964/FhMTwymnnMJ///tfvv/++7L9GRkZPP/88wwYMICmTZtWqh5JkiTVT3vSz+6Pz2crMmTIEADGjh1bbv+YMWMAOP3003/yNSSpOjlRQZL20GuvvcbmzZv5+c9/XuHzP/vZz2jdujUTJkzg+eef5+WXX+b888/nl7/8JT179mTDhg289tprjBs3ju7duzN8+HCeffZZRo4cyezZszn22GPJzc3l3Xff5ZprruHMM8+kWbNmnH/++TzyyCNERUXRqVMn3njjDTIzM/e47i5dutCpUyd+//vfk56eTtOmTXnllVd2WgsN4G9/+xsDBgzg6KOP5te//jUHHngg33//PW+++SYLFiwod+zw4cM577zzALj33nv3/A9SkiRJtdYXX3zBa6+9BsCyZcvIzs7m//7v/wDo3r07Q4cOrdTrde/ene7du1e6jhNOOIFLL72Uv/3tb3zzzTeceuqphEIhPvzwQ0444QSuu+663Z7/f//3f0ydOpUBAwZwzTXXEBsby+OPP05+fv5u1xaWJElS7RaJfnZ/fT5bUS2XXXYZTzzxBJs2beL4449n9uzZjB8/nrPOOosTTjihUtcmSfubQQVJ2kMTJkwgISGBk08+ucLno6OjOf3005kwYQL5+fl8+OGH3HnnnUyePJnx48eTnJzMSSedRLt27YAgSfvWW29x33338fzzz/PKK6/QqlUrBgwYwBFHHFH2uo888giFhYWMGzeO+Ph4fvGLX/Dggw/SrVu3Paq7QYMGvP7669xwww2MHj2ahIQEzj77bK677rqdmuju3bvzySefcPvtt/OPf/yDvLw8OnToUOH6akOHDqVFixaEQqFdhjckSZJUt8ybN2+nX4uVPr7ssssq/cHuvvjXv/7FkUceyVNPPcUf/vAHmjVrRq9evejfv/9Pnnv44Yfz4YcfcvPNNzN69GhCoRB9+/blueeeo2/fvtVQvSRJkiIhEv3s/vp8tiL//Oc/Oeigg3jmmWeYPHkybdq04eabb+bOO++s8uuSpH0VFd6TeTGSJP1IUVERqampDB06lKeeeirS5UiSJEmSJEmSJKmWiI50AZKk2unVV19l3bp1DB8+PNKlSJIkSZIkSZIkqRZxooIkqVI+/fRTvvjiC+69916SkpKYN29epEuSJEmSJEmSJElSLeJEBUlSpfzjH//g6quvJjk5mWeffTbS5UiSJEmSJEmSJKmWcaKCJEmSJEmSJEmSJEmqNk5UkCRJkiRJkiRJkiRJ1caggiRJkiRJkiRJkiRJqjaxkS6gqoRCIVavXk2TJk2IioqKdDmSJEnaj8LhMJs3byY1NZXo6LqXvbW3lSRJqj/sbSVJklRXVKa3rTNBhdWrV9O+fftIlyFJkqRqtHLlStq1axfpMqqcva0kSVL9Y28rSZKkumJPets6E1Ro0qQJEFx006ZNI1yNJEmS9qecnBzat29f1gPWNfa2kiRJ9Ye9rSRJkuqKyvS2dSaoUDo2rGnTpja8kiRJ9URdHR1rbytJklT/2NtKkiSprtiT3rbuLXomSZIkSZIkSZIkSZJqLIMKkiRJkiRJkiRJkiSp2hhUkCRJkiRJkiRJkiRJ1caggiRJkiRJkiRJkiRJqjYGFSRJkiRJkiRJkiRJUrUxqCBJkiRJkiRJkiRJkqqNQQVJkiRJkiRJkiRJklRtDCpIkiRJkiRJkiRJkqRqY1BBkiRJkiRJkiRJkiRVG4MKkiRJkiRJkiRJkiSp2hhUkCRJkiRJkiRJkiRJ1WavggqPPfYYHTt2JCEhgb59+zJ79uxdHltYWMg999xDp06dSEhIoHv37kyZMmWn49LT07nkkkto1aoViYmJHHHEEXz22Wd7U54kSZK0x+xtJUmSJEmSJKl6VTqoMHHiREaOHMmdd97JvHnz6N69O4MHDyYzM7PC42+77TYef/xxHnnkERYuXMhVV13F2Wefzfz588uO2bhxI8cccwwNGjTg7bffZuHChfzlL3+hRYsWe39lkiRJ0k+wt5UkSZIkSZKk6hcVDofDlTmhb9++9O7dm0cffRSAUChE+/btuf766xk1atROx6empnLrrbdy7bXXlu0799xzSUxM5LnnngNg1KhRfPzxx3z44Yd7fSE5OTk0a9aM7OxsmjZtutevI0mSpJqvqno/e1tJkiRFWl3v/er69UmSJGm7yvR+lZqoUFBQwNy5cxk0aND2F4iOZtCgQcyaNavCc/Lz80lISCi3LzExkY8++qjs8WuvvUavXr04//zzSU5O5qijjuLJJ5/cbS35+fnk5OSU2yRJqou2bIFp02DdukhXouoUCsHcufDWWzB/PqxdC8XFka6qbrG3lSQpAgq3wNppkGdzW6+EQ7BhLqS/BRvmw7a1ELK5lSRJtVcoHOK7jd8xZdkUlm1YFulypFoptjIHZ2VlUVxcTEpKSrn9KSkpLF68uMJzBg8ezJgxYzjuuOPo1KkT06ZNY9KkSRTv8En78uXL+cc//sHIkSO55ZZbmDNnDjfccANxcXFcdtllFb7u6NGjufvuuytTviRJtUIoBPPmwTvvBNvMmVBYCGlpMHUqdO0a6Qq1v+TmwrvvwhtvwJtvwpo15Z+PiYGUFGjbNthSUyu+n5ICsZXq8uone1tJkqpBOAQb5sHad2DNO5A1E0KFkJgGJ06FZja3dVZRLqx9F9LfgNVvwrYfNbdRMZCQAoltIaEtNEwNbhPbQmJqyW3b4Jhom1tJkhQ5mbmZfJX5FV9mfMmXmV/yVeZXfL3ua7YUbCk75vDWh3NWl7M4u8vZHN32aKKioiJYcd0TDodZvXk1zROa0yiuUaTLqXYFxQVk5mayZvMa1m5Zy9ota1mzZfv9tVvWkleUx3V9rmNEjxG15u9fpZZ+WL16NWlpacycOZN+/fqV7b/pppuYMWMGn3766U7nrFu3jiuvvJLXX3+dqKgoOnXqxKBBg3j66afZtm0bAHFxcfTq1YuZM2eWnXfDDTcwZ86c3f6aLT8/v+xxTk4O7du3d4SYJKlWWrkyCCG8807wRfX69eWfT0iAvDxISoL//Q+OPjoydarq/fBDEEx44w14/33Yob2hcWM4+GDIyAi2UGjPXjMqCpKTdw4wtG0LbdoEW+n9xMR9q3/pUnj55WDix1//um+vVRlVMT7W3laSpP0kdyWsnRoEEzLehfwfNbcxCVCcB/FJcML/oKXNbZ2R+0MQTEh/AzLeh9AOzW1sY2hyMORlBFt4D5tboiAhuXyAoSzQ0AYS2pTsawOx+9jc5iyFlS8HEz96Vl9zW9eXRqjr1ydJqjs2529m4bqFZWGE0tvM3MwKj28Q3YCDWhzEtxu/pShUVLa/fdP2ZaGFYzscS6yhy3121/S7uHtG8COfFgktaNe0He2btaddk5Lbpu1o37R92f6GDRpGuOKKhcNhikJFFBQXUFBcQH5xPhu3bSwXOlizeQ1rc3e4v2Ut67et/+kXL3HRERcx7vRxNIlvsh+vZNcq0/tV6n8ZSUlJxMTEkJGRUW5/RkYGbdq0qfCc1q1b8+qrr5KXl8f69etJTU1l1KhRHHTQQWXHtG3blsMOO6zceV27duWVV17ZZS3x8fHEx8dXpnxJkmqM3FyYMWP71IRFi8o/36QJnHQSnHJKsDVrBqeeGiwFcMIJwZfaxx4bmdq1b4qL4dNPt4cTvvyy/PMHHghDh8IZZ8Bxx0Fpu1NcDJmZsHp1MGlhzZrt93fcV7pERGm4YcGC3dfTtGn5AMOOIYYd7yclQXQ0hMPw9ddBOOGVV+Crr4LXadAA7rwTmjev6j+x/cfeVpKkKlKUCxkztk9NyPlRcxvbBNqcBG1PgTanQINmMP3UYCmAaSfA8W9Ass1trRQqhvWflkxNeAM2/ai5bXQgpA2FtDMg+TiIid9+Xn4mbFsdTFrYtmaH+zvsy1sL4eLt4YaNC3ZfT4Om20MLCW2CIEO5xyXhhvgkiCppbrO/hhUvw8pXILukuY1uAEfcCXHNq/pPTJIk1QAFxQUsXb+ULzPKBxK+2/RdhcdHEUWnlp3oltyNI5KPoFtyN7old+OQlofQIKYBG7dt5K1v3mLy4sm8vextVuas5JHZj/DI7EdomdiSoYcO5awuZ3FKp1P2+Av0LQVbWL15NWs2r2H15tXB/S1ryt1mbMmgQ/MOHN/heAZ2HMhxHY4jqWFSVf5R7bFNeZtYu2UtnVt1rvJf82dsyeDPH/+57PHGvI1szNvIl5lf7vKcloktade0XfkAQ8ltUsOkspBAflE++cX55BXlld3PLyp5vIvnS58rCxsUbb9f0bbjsQXFBXv95xAbHUtKoxTaNmlLm8ZtaNOozfb7jdvwdebX3D3jbp7/8nlmp8/mxfNe5Ki2R+31+1WHSgUV4uLi6NmzJ9OmTeOss84CIBQKMW3aNK677rrdnpuQkEBaWhqFhYW88sor/OIXvyh77phjjmHJkiXljl+6dCkdOnSoTHmSJNVYoVDwhXFpMOHjj6Fgh54kOhr69NkeTOjTJ/jid0fvvRd8gf3BBzB4MEyaFIQXVPNlZwf/3F9/Hd56q/zEjOhoOOaY7eGELl2CiQg/FhOzfSrC7hQXQ1bWziGGtWu335bez8uDnJxg+1ErVuH7ly4psWLF9v2xsUGo5rzzat9yE/a2kiTtpXAo+MJ4zTtBOGHdxxDaobmNioaWfYJgQttToFWf4IvfHZ30HswYCpkfwPuD4dhJkGpzWysUZAf/3Fe9DmveKj8xIyoako7ZHk5ouovmNjpm+9IOuxMqhvysnUMMeWt3uF0LeWuCKR2FOcGW8xPNbemyE1GxsHWH5jYqNgjVtD8vuC9Jkmq1vKI8lq5fysJ1C1m4biGLshaxcN1Clq5fWm4Cwo7aNm7LESlH0K11EEY4IuUIuiZ13e1yAy0SW3DxkRdz8ZEXs61wG+8uf5fJiyfz2pLXWL9tPeM/H8/4z8eTGJvI4IMHc3aXs+nQrENZ4GDH8EFpOGFzweY9usYvMr7gi4wveGT2IwB0S+7GwA4DOb7j8Rzf4XhaN2pd+T+4n5BbkMv8tfOZkz6Hz9Z8xpz0OXyz4RsAjkw5klHHjOL8w8+vskkSf/roT2wr2kbftL5MuWQK6TnprMxZyaqcVazMLrnN2X67pWALG7ZtYMO2DXyR8UWV1LA/NU9oTpvGbWjbeHvooNz9kjBCy8SWREdF7/J1zul6DiceeCIXvnIhyzYs42dP/Ywxp4zhmt7X1NilICq19APAxIkTueyyy3j88cfp06cPY8eO5cUXX2Tx4sWkpKQwfPhw0tLSGD16NACffvop6enp9OjRg/T0dO666y6+++475s2bR/OSn9zNmTOH/v37c/fdd/OLX/yC2bNnc+WVV/LEE09w8cUX71FdjhCTJNU06enbl3OYOjX48nhHHToEgYNTToETT4QWLX76NbdtC74QfuutIMgwYQKcf/7+qb++Kira8yUWdmfHJR0++CB43VLNm8NppwXBhFNPhZYt9/39KiscDgIKPw4wVBRoyMoKji8VHx/8vT3vvCBgsSd/d6taVfV+9raSJO2hrenbl3NYOzX48nhHjTpA28HBxIQ2J0LcHjQIRdvgo/Ng9VtBkKH/BDjA5rZKhYoqscTCbuT+EExMSH8jCJeEd2huGzSH1NOCYELbUyE+Qs1tYc72AMO2tcH9Hz/etqbk7+4OzW10fBCoaX8etBu6Z393q1hd7/3q+vVJqjvC4TBbCraQmZvJxryNFIWKKrUVFhdW+pyiUBFF4fKvURwuJhwOEyZc5bel17njvkYNGtG5VWe6tu5K16SudEnqQvtm7Xf7hWhNs6VgC4uzFgdhhHWLWJgVBBOWb1xOaBe9ULP4ZmWTEXacktCqYasqq6soVMTHKz5m8uLJTF48mRXZK376pB00atCItKZptG3cltQmqWVb6ePWjVrzdebXTP9+OjN+mMHX677e6TUOb3142cSF4zseT3Kj5ErVUFBcwBcZX/DZ6iCQMGf1HL5e93WFf64NohtQGCoE4KAWB/GH/n/g8h6XkxCbUKn33NHqzas56OGDyC/O53+X/I9TOp2y2+PD4TA5+Tk7BRl2DDNs2LaB+Nh44mPiiY+NJyE2oex+fEzJ49Lnd3NMXEwc8bHxxMXE7bTFx1S8/8dbbHRslYcI1m9dz4j/juD1pa8DcHaXs3nq50/RIrF6+tzK9H6VDioAPProozz44IOsXbuWHj168Le//Y2+ffsCMHDgQDp27MgzzzwDwIwZM7j66qtZvnw5jRs3ZsiQIfzpT38iNTW13Gu+8cYb3HzzzXzzzTcceOCBjBw5kiuvvHKPa7LhlSRFWmZmsJzD++8H2+LF5Z9v3DgIJJROTTj44Ip/XPRTCgpg+HCYODH4Nf6TT8Ivf1k111AqHIbZs4PXfvnl4Jf0Z5wRbAMG7Dztoa7429/gj38MJg1UtS5dgj+/oUOhf//aNX2gsBDWrQuCC9nZ0KtXsDxJJFVl72dvK0lSBfIyIXMGZLwfbDk/am5jG0PKiduXc2iyl81tcQHMGg4rJga/xu/zJHTaD83t+tnw7ZPBiP+ElOBL9bQzoPWAnac91BVL/gYL/hhMGqhqTbuU/BkOhaT+UJvWXQ4VQt66ILhQmA0te0GDyDa3db33q+vXJ6lmKw4Vs37bejK2ZJCZm0lmbiYZucH9jC0ZZG7N3H4/N5NtRdsiXXKN0LBBw53CC12TunJwy4OJj43c0pWb8jZtDyOsW8jCrOD+D9k/7PKcFgktOKz1YWVb16SuHNb6MNo1bVetvzIPh8MsWLuAyYsn8/rS19lSsGV7+KBxKm2btN0piNAkvnI9yrrcdXzwwwdM/34603+YzleZX+10TNekrkFoocPxHN/xeNo03r78aXGomMVZi5mzek5ZKOHzjM8rXK6gbeO29E7rTa+2vYLb1F5ER0Xz2OzHePjTh1m/LZi6ldIohd/87Ddc3etqmiU0q+SfGlz/1vU8OudRjml/DB+O+LDGTgaoacLhMA9/+jA3Tb2J5gnNWXDVAlKbpP70iVVgvwcVaiIbXkmqmYqL4ZtvgvHz+yI2Fg48ENLSgi/na4L168sHE77+UWA1Kgp6994eTPjZz6ruC/7iYrj66iBIADBmDPz2t/v+ups2wXPPBa/7xS6mYjVrFkyCGDo0mAaQFJllz6rcu+8G/5yqqjNq0ACOPz4IJ5x+ehBMUdWp671fXb8+Saq1QsWw+Ztg/Py+iI6FRgdCw7Tgy/maIH99+WBC9o9/jRUFrXoHoYS2p0DSz6ruC/5QMcy5OggSABw9BrpUQXNbsAm+ey543U27aG4bNAsmQaQNDaYBJNSR5nbtu/DeKZSbHLAvohtA8vGQegaknR4EU1Rl6nrvV9evT1L121a4befAwQ6Pd7yftTVrl7+o35WGDRrSMrElDaIbEBsdW25rELPzvl1uUXt43I+2mOgYoogiKipqv94CREVFsXHbRhZnLWbx+sUsWreIbzZ8s8tlEWKiYjioxUFlwYWurbvSqUUnoqOiKQoVURwuLpsOURwqLrfvx493d8yO+3ILclmyfgkL1y1kzZY1u/znltwoOQgjJB1WLpiQ3Ci53n65nbU1qyy4MOOHGRUug9C5VWf6pPXhh+wfmLt6LrmFuTsd0yKhBb1Se9E7tTe903rTO7U3aU3Tdvm+uQW5PDX/KR6a+RArc1YC0DS+Kdf0uoYbf3ZjuXDE7qzMXsnBjxxMQXEB04ZP48QDT9zDK1epz1Z/xub8zZxw4AnV9p4GFWx4JSki8vLgq69g/vxgW7AAPv8ctm6tuvdITAy+8D300GA75JDt95OS9u5HXHtq06YgmDB9ehBM+OKLnb/UPuIIOOGEYDvuuP070j8chptugoceCh7fcQfcdVfl/wzCYZg5E554Al56KVheAiAhIVhW4pe/DEIZb7wBb74Z/LK+VHQ09Ou3fdrC4Yfv338G+8uqVXDUUcESB7/6FfzlL/v+mgkJwRIJ2j/qeu9X169PkmqF4jzY9BVsnF+yLYCNn0NxFTa3MYnBF75NDi3ZDoGmJffj93NzW7CpJJgwPQgmbPqCnb7Ubn4EJJ8AKSdA8nH7d6R/OAwLboJFJc1ttzvgiLv2rrnNmgnLnoAVL0FxSXMbkwDtzw+mNeSvL1nG4E3I36G5jYqGpH4lX8afAc1qaXO7dRW8fVSwxEGnX8FRVdDcxiRAjM3t/lLXe7+6fn2SqkZhcSHfbvx2p9BB6dSDHfdvKdhSqdeOIopWDVuR3CiZlEYp5W6TGyWT0rj8vkZxjfbTVdYOhcWFLN+4nEVZi1ictXj77bpFbC7YHOnyaNe0XdlUhB2nJFTlkg111fqt6/nghw+Y8cMMpn8/nS8yvihbEqRUowaNOLrt0eVCCQe1OGivwh6FxYX856v/8MDHD7Bw3UIA4mPiGdFjBL/v/3s6tey02/OvfuNqxs0dx/Edjuf9y96vt4GT2saggg2vJO13GzcGQYTSQML8+bBoUfBL/x9r2BA6dty3SQh5efD991BUcZgXCH7pX1GA4ZBDYG/+ryEnBz78cPvEhPnzdw4mHHZY+WBC69aVf599EQ7D/ffDbbcFj2+8MZiusCd/1uvXw7//HUxPWLhw+/5u3eDXv4ZLLoEWP1q2KhSCOXOC0MIbbwT/7HfUocP25Q2OPz74sr6mKywMap01C3r0CEIbiYmRrko/pa73fnX9+iSpxinYGAQRNpQGEuZDziIIV9DcxjSExh2BfWhui/Mg93sI76a5bdAsCCw0LQkw7Hi/wV78f0NhDmR+uH1iwsb57BRMaHZY+WBCQgSa26/vhy9KmtvONwbTFfZk6kT+evju38H0hOwdmttm3eDgX8OBl0Dcj5rbcAjWz4H0N4LgwsYF5Z9v1KEktDAUUo4Pvqyv6UKF8O7xkDULWvSAk2dCrM1tTVfXe7+6fn2SKi8UDrFswzJmp89mTvocZq+ezfw188kvzt/j14iPiS8LGPxUACGpYRKxtWmZohoqHA6zevPq8uGFrEX8sOkHoqKigmkQUTFlUyHKJkT8aF/p413u+9Hx8THxHNzyYA5rfRhdkrrs1fIBqtiGbRv48IcPmbdmHh2bd6R3Wm+6JnUlJjqmSt8nFA7xxtI3GP3RaD5Z9QkA0VHRDDt8GH885o90b9N9p3O+3/Q9hz5yKIWhQmZcPoPjOhxXpTVp/zGoYMMrSVUmHA5+bb5jIGH+fPhhF8t+JSUFv0w/6qjgS9+jjgqCAjFV0NsUFQVhhW++gaVLt2/ffAMrVux+ZH9KSsUBhk6dtn8pvWULfPzx9mDC3Lk7By8OPXR7MGHgwOB1a4JHH4Xrrw/uX355ED6IreC/v8Jh+OCDYHrCK69Afsl//zVsCMOGBQGFvn33/IdjK1cGUxbeeAOmTQsCJaUaNYKTTw6CC0OGQNu2+3SJ+83IkfDXvwZBl7lzg78Tqvnqeu9X169PkiImHA5+bb5xh0DCxvmQu4vmNj4JWhxVsvUIbpscAlXxwV2oKAgrbP4GcpbC5tLtG8hdwW5H9iek7DyBockh0LjT9i+lC7fAuo8hsySYsGHuzsGLJocGoYSUEyB5ICTWkOZ2yaMwt6S5Pehy6PNksFzGj4XDkPlBMD1h5SsQKmluYxpCh2FBQKFVJZrb3JWw+s0guJAxLQiUlIptBG1ODiYtpA6BxBra3M4dCUv+GgRdTp0LTWxua4O63vvV9euT9NNWb14dBBLSZzN79Ww+W/0Zm/I27XRck7gmpDZJ3R5AaLjztIPSAEKTuCb+ulqqZcLhMB/88AF/+vhPTFk2pWz/aQefxs0DbmbAAQPK/nd9xWtX8NT8pxh00CCmXjo1UiVrLxhUsOGVpL1SXAxLlpQPJSxYEPzyviIHHlg+kHDUUZCaGpnpqNu2wbffVhxiyMjY9XlRUXDAAcESDV9+ufPEhk6dygcTUlP362Xsk2efhREjgqkH554LEyZsX3pg3ToYPz4IMCxduv2cHj2CcMJFFwVf1O+LrVvhvfe2T1tITy//fK9ecMwx0LNnsHXuXDUBln3x8svB8hYAr74KZ54Z0XJUCXW996vr1ydJ1SJUDJuXBFMSNi3Yfpu/i+a20YHQ8iho3iO4bXEUJEaouS3aBlu+DUILm5fuEGT4BvJ209wSBY0OgLiWsOnLnSc2NO5UPpjQsAY3t8ufhU9HBFMP2p8L/SdsX3ogbx18Nx6WPRn8uZRq0SMIJ3S4COL2sbkt2goZ7wWhhfQ3YNuPmtuWvaD1MdCyZ7A16Vw1AZZ9seJl+KikuT3uVWhnc1tb1PXer65fn6TysvOy+Wz1Z2WhhDnpc0jfnL7TcQmxCWXj5fuk9aF3am8Obnmw4QOpnliwdgEPfPwAL379IqFwCID+7fsz6phRdG3dlS6PdqE4XMzHv/yY/u37R7haVYZBBRteSfpJW7fCV19tn5Awf37wRf22bTsfGxsbLHGwYyihe3do3ry6q9472dlBYGHHEMM33wShjJyc8sd26LA9mHDCCdC+fWRq3luTJ8MFF0BBAZxyCvz2t/CvfwX7CwuDYxo3DoIJV14ZBAb2x3//hcNByKU0tDB79s7HNGwY/H3q2ROOPjq47dq14kkQ+8PSpUF4YvNm+MMf4M9/rp73VdWo671fXb8+SapyRVth01fbJyRsnB98UV9cQXMbFRsscbDjlIQW3SGueXVXvXcKsksCDDuGGL4JQhmFP2puG3UoCSWUhBMa1bLmduVk+PgCCBVAm1Ogy29h+b9g1eRgiQOA2MbQ8SLodGUQGNhfze3GBduXiFhfQXMb0zD4+9SyJ7Q8Orht2rXiSRD7Q85SmNILijZD1z/AUTa3tUl1936PPfYYDz74IGvXrqV79+488sgj9OnTp8JjCwsLGT16NOPHjyc9PZ3OnTvzwAMPcOqpp+7x+9nbSnVXXlEen6/9PFjCYXUwMWHJ+iU7HRcdFc3hrQ+nT1qfslBCt+RuNIhpEIGqJdUkyzYs46GZD/GvBf+ioLgAgIYNGrK1cCunHnwqb1/8doQrVGUZVLDhlRRh4TBs2ACrV+9+27gxcjVu2xb88v7HGjUKQgilExKOOioIKSTUguVYKyscDiYNLF0aTF3o2RM6dox0Vftu6lQ466wgjLKj3r2D6QnDhkGTJtVb09q18O678NlnwfIK8+dDbu7OxyUmBn//SoMLPXsGf/8aVOK/W8PhIICydi2sWRPc/vj+2rXw3XdBSOHYY4NJENUVkFDVqOu9X12/Pkm1TDgMBRtg22rYujq4rWgriGBzW7wt+OX9j8U2gubdgzBC6ZSEZodBTB1tbvPXBV9Y52UEX5Q37hjpqvbdmqnwwVlQ/KPmtmXvkukJw6BBNTe329bC2ndhw2fBkhob50NRBc1tTGLw9680uNCyZ/D3L7qSzW1hDuSthW1rgvcuvZ+3dvvjLd8FIYXWx8JJ71VfQEJVojp7v4kTJzJ8+HDGjRtH3759GTt2LC+99BJLliwhOTl5p+P/+Mc/8txzz/Hkk0/SpUsX/ve//zFy5EhmzpzJUUcdtUfvaW8r1Q3FoWIWZy0uF0r4IuMLCkvDgzs4sPmBZYGEPml9OLrt0TSKaxSBqiXVFms2r+HhTx/m73P+zuaCzQB8esWn9EmrOEypmsuggg2vpP0kHA5+nV9R6GDNmvKPCwoiXe1PS04uH0jo0QMOPhiioyNdmfbVzJkwdGiwlMUllwTTE3r0iHRV2xUXB1Mt5s7dvs2fHwQHfiw+Ho48cvvkhS5dYNOmigMIpffz8nZ+nYoceCB8/DG0raFLDGvX6nrvV9evT1INEQ5DYfb2oEG5EMKa8iGEUC1obhOSS6YjHLV9WkKTgyHK5rbWWzcTZgwNlrLoeAkcfGXwz7emCBUHUy02zC0JLswNlhopqqC5jY6H5kdun7zQtAsUbNohdFBBGKF4D5vbRgfCKR9Dos1tbVOdvV/fvn3p3bs3jz76KAChUIj27dtz/fXXM2rUqJ2OT01N5dZbb+Xaa68t23fuueeSmJjIc889t0fvaW8r1T7hcJgV2SvKAgmz02czd81cthRs2enY1g1blwsl9ErtRetGrSNQtaS6YFPeJsYvGE+rhq245MhLIl2O9kJlej/j1ZJUYsuWn56AsHp1xUsj7EpSEqSm7npr2TJyoYBGjYKgguqm/v1h5UqIiQm+6K9pYmKCwEGXLnDxxcG+UAiWLdseXJg3L9iys2HOnGCrjKZNgwBCmzbbtx0ft20Lhx5aN6eFSJJE4ZadJx5UNA2hoqURdiU+CRJTy28Nd7gf1zJyoYDYRkFQQXVT6/5w1kqIioGYGtjcRsdAsy7BdmBJcxsOweZlO4QX5sGGeUE4aMOcYKuMBk2DAEJCm2BLbPOjx22h6aF1c1qIqkxBQQFz587l5ptvLtsXHR3NoEGDmDVrVoXn5Ofnk/Cj/2hKTEzko48+2uX75Ofnk5+fX/Y458drLkqqcdZvXV8ulDBn9RwyczN3Oq5Rg0b0TO1Jn9SSJRzSetOhWQei9sfSS5LqpeYJzbnxZzdGugxVE4MKkuqNcDj4xfYHH0B6+s5TECr6JfeutGgRfMm5uxBCmzY18wti1R8NG0a6gsqJjg6CA4ceChdeGOwLhWD58u3Bhblz4dtvgxDQ7gIIKSm17/olSaqUcDgYN5/5AWxLD0IIeWu2BxIq+iX3rsS1CL7k/HEIYccwQkKbmvkFseqP2FrW3EVFB8GBpodCx5LmNhyCLctLwgvzgtst3wYhoNLwQWnoYMf7CSm17/pVI2VlZVFcXExKSkq5/SkpKSxevLjCcwYPHsyYMWM47rjj6NSpE9OmTWPSpEkUFxfv8n1Gjx7N3XffXaW1S6o6uQW5zF87v9wSDss3Lt/puNjoWI5MOZI+qUEgoU9aH7omdSUmOiYCVUuS6iKDCpLqtOLiYAT+pEkweTL88MPuj2/SZPfhg9TU4EvQxMTqqV+q76Kjg+VIDj4Yhg2LdDWSJEVYqBiyZsLKSbBqMuT+RHMb26T8xIMKAwhtIdbmVqoWUdHBciRNDoYONreqHR5++GGuvPJKunTpQlRUFJ06dWLEiBE8/fTTuzzn5ptvZuTIkWWPc3JyaN++fXWUK2kHm/M3syhrEQvXLWTRukUszApul29cTpidVwQ/tNWhZcs39EnrQ/eU7iQ2sE+UJO0/BhUk1TkFBfDee0E44b//hcwdppQ1bAgnnRR86VlRAKFJk8jVLUmSJO2kuAAy3gvCCen/hbwdmtuYhtDmJGh8cAWBhLbQwOZWkrRdUlISMTExZGRklNufkZFBmzZtKjyndevWvPrqq+Tl5bF+/XpSU1MZNWoUBx100C7fJz4+nnhHTErVJmtrVhBEWLdwezAhaxGrclbt8py2jduWBRJ6p/amV2ovWiS2qMaqJUkyqCCpjsjNhSlTgnDCG2/AjssfNm8OQ4fCOefAKac4Dl6SJEk1XFEurJ4ShBNWvwGFOzS3DZpD2lBofw60PcVx8JKkPRYXF0fPnj2ZNm0aZ511FgChUIhp06Zx3XXX7fbchIQE0tLSKCws5JVXXuEXv/hFNVQsqVQ4HGbNljXbpyPsEEpYt3XdLs9r07gNXZO6cljrw7bftu5Km8YVh5MkSapOBhUk1VobN8LrrwfhhP/9D/Lytj/Xpg2cdVYQThg4EBo0iFSVkiRJ0h4o2AirXodVk2DN/6B4h+Y2oQ20OysIJ6QMhGibW0nS3hk5ciSXXXYZvXr1ok+fPowdO5bc3FxGjBgBwPDhw0lLS2P06NEAfPrpp6Snp9OjRw/S09O56667CIVC3HTTTZG8DKnOCoVD/LDph52mIyxct5Cc/JxdntehWQe6tu7KYUlBEKE0mOCUBElSTWZQQVKtsmZNsJzDpEnw/vtQVLT9uQMPDIIJ55wDP/tZsLa9JEmSVGNtWwOr/htMTsh4H8I7NLeNDgyCCe3PgaSfBWvbS5K0j4YNG8a6deu44447WLt2LT169GDKlCmkpKQAsGLFCqJ3+EAlLy+P2267jeXLl9O4cWOGDBnCv//9b5o3bx6hK5DqhsLiQr7d+O32CQlZwe3irMVsK9pW4TnRUdEc3PLgnSYkdE7qTOO4xtV8BZIk7buocDgcjnQRVSEnJ4dmzZqRnZ1N06ZNI12OpCq0fDlMnhyEE2bNgh3/rdWtWxBMOPts6N4doqIiV6ckqfrU9d6vrl+fVK9tWQ4rJwfhhKxZwA7NbbNuJeGEs6G5za0k1Rd1vfer69cn7U5eUR5LspbsNCHhm/XfUBgqrPCcuJg4OrfqvNOEhENaHkJ8bHw1X4EkSZVTmd7PiQqSapxwGL7+OggmTJoEn39e/vm+fbeHEw45JDI1SpIkSXskHIbsr4NgwspJsOlHzW2rvkE4od3Z0NTmVpIkqTYqLC7ki4wv+Crzq3KhhO82fUcoHKrwnEYNGtG1ddedJiQc2OJAYqP96kaSVPf5/3aSaoRQCObM2R5OWLZs+3MxMXD88UEw4ayzoF27iJUpSZIk/bRwCNbP2R5O2LJDcxsVA8nHB8GE9mdBQ5tbSZKk2iZjSwazVs1i1spZzFo1izmr55BXlFfhsS0SWpQLIpROSGjXtB3RLu8lSarHDCpIipiiIvjggyCYMHkyrF69/bn4eDjllCCcMHQoJCVFrk5JkiTpJ4WKIPODIJiwajJs26G5jY6HtqcE4YS0oZBgcytJklRbFIWK+CLji7JQwqxVs1i+cflOx7VIaEGPNj04rPVh5YIJyY2SiXJJL0mSdmJQQVK1ysuDqVODcMJrr8GGDdufa9wYTj89WNbhtNOgSZPI1SlJkiT9pOI8WDMVVk2CVa9BwQ7NbWxjSD09WNYh9TRoYHMrSZJUG2RtzeKTVZ8wc+VMZq2axez02Wwt3FrumCiiOKz1YfRv359+7frRr30/Dm11qBMSJEmqBIMKkva7nBx4661gasJbb8GWLdufa9UKzjwzCCecdBIkJESuTkmSJOknFeZA+lvB1ITVb0HRDs1tfCtIOzMIJ7Q5CWJsbiVJkmqy4lAxX6/7uiyUMGvlLL7Z8M1OxzWNb8rP2v2M/u360699P/qm9aVZQrMIVCxJUt1hUEHSfpGVFUxMmDQpmKBQULD9uXbtgiUdzjkHBgyAWP9NJEmSpJosLwvSXwuWdVg7FUI7NLcN2wVLOrQ/B1oPgGibW0mSpJpq47aNfLLqE2atmsXMlTOZnT6bzQWbdzquS1IX+rXrVzYxoWvrrk5LkCSpivkJiqQq9d138H//B88+C0VF2/cfemgQTDjnHOjVC1yWTZIkSTXelu/gq/+D756F8A7NbZNDg2BC+3Ogpc2tJElSTRQKh1i0blHZpISZq2ayOGvxTsc1jmtM37S+ZcGEvu360jKxZQQqliSpfjGoIKlKrFgB990HTz+9PaDQowece24QTuja1c9vJUmSVEvkroCv74Nvn94eUGjRA9qfG4QTmtrcSpIk1TTZedl8mv4ps1bOYtaqWXyy6hOy87N3Ou6QlofQr30/+rULtm7J3YiJjolAxZIk1W8GFSTtk1Wr4P774Z//hMLCYN/JJ8Pdd0O/fpGtTZIkSaqUravg6/vh239CqKS5bXMyHHE3tLa5lSRJqinC4TBL1i8pCyXMWjWLrzO/Jky43HENGzSkd2rvsiUcftbuZ7Ru1DpCVUuSpB0ZVJC0V1avhj/9CR5/HApKlug98cQgoDBgQGRrkyRJkipl62pY+CdY9jiESprblBODgEKyza0kSVKkbSnYwuz02cxcObNsWsKGbRt2Ou7A5gfSr30/+rfrT7/2/Tgy5Uhio/0aRJKkmsj/h5ZUKWvXwgMPwLhxkJcX7DvuuCCgMHBgREuTJEmSKmfbWlj4ACwbB8UlzW3ycUFAIWVgREuTJEmqr8LhMN9u/JZZK2eVBRO+zPySUDhU7rj4mHh6p/UuW8KhX/t+tGncJkJVS5KkyjKoIGmPrFsHf/4zPPYYbNsW7OvfH+65J5ik4BK9kiRJqjXy1sGiP8PSx6C4pLlN6g9H3hNMUrC5lSRJqnZfZ37Nbe/fxscrPmbd1nU7Pd++afuyJRz6te9HjzY9iIuJi0ClkiSpKhhUkLRb69fDQw/BI49Abm6wr2/fIKBw8sl+hitJkqRaJH89LHoIlj4CRSXNbau+QUChjc2tJElSpHyV+RUnjD+BrK1ZAMTFxHF026PLlnDo164faU3TIlylJEmqSgYVJFVowwYYMwYefhi2bAn29eoVLPFw2ml+hitJkqRaJH8DLB4DSx6GopLmtmWvYImHVJtbSZKkSFq0bhEnPXsSWVuz6Nm2J3877W/0bNuT+Nj4SJcmSZL2I4MKksrZtAn++lcYOxZycoJ9Rx0VBBTOOMPPcCVJklSLFGyCxX+FJWOhsKS5bXFUEFBIs7mVJEmKtCVZSzjx2RPJzM2kR5sevHPpO7RMbBnpsiRJUjUwqCAJCEIJDz8Mf/kLZGcH+448MggonHmmn+FKkiSpFinMgcUPw+K/QGFJc9v8yCCg0M7mVpIkqSZYtmEZJz57Imu3rOWI5CN499J3DSlIklSPGFSQ6rnNm+GRR+Chh2DjxmDf4YfDXXfBOedAdHREy5MkSZL2XOFmWPoILHoICkqa22aHwxF3QftzIMrmVpIkqSb4buN3nDj+RFZvXs1hrQ/j3eHv0qphq0iXJUmSqpFBBameys2Fxx6DP/8Z1q8P9nXpEgQUzj/fgIIkSZJqkaJcWPoYLPoz5Jc0t027BAGFA843oCBJklSDrMhewYnPnsjKnJV0btWZacOnkdwoOdJlSZKkamZQQapntm6Ff/wDHngA1q0L9h1yCNx5J1xwAcTERLY+SZIkaY8VbYVv/gELH4D8kua2ySHQ7U7ocAFE29xKkiTVJKtyVnHC+BP4ftP3HNLyEN677D3aNG4T6bIkSVIEGFSQ6olt2+CJJ2D0aMjICPZ16gR33AEXXQSx/ttAkiRJtUXRNlj2BCwcDXklzW3jTtDtDuh4EUTb3EqSJNU0qzev5sTxJ7J843IOanEQ7132HqlNUiNdliRJipC9mn/52GOP0bFjRxISEujbty+zZ8/e5bGFhYXcc889dOrUiYSEBLp3786UKVN2efyf/vQnoqKi+M1vfrM3pUn6kfx8ePRROPhg+M1vgpBCx47w9NOwaBEMH25IQZJUv9nbSrVIcT4seRRePxjm/SYIKTTqCH2fhjMWwUHDDSlIkiTVQBlbMjjp2ZP4ZsM3dGjWgfeGv0e7pu0iXZYkSYqgSgcVJk6cyMiRI7nzzjuZN28e3bt3Z/DgwWRmZlZ4/G233cbjjz/OI488wsKFC7nqqqs4++yzmT9//k7Hzpkzh8cff5wjjzyy8lciqZyCAhg3LggoXH89rF4NBxwQTFVYsgRGjIAGDSJdpSRJkWVvK9USxQXwzbggoDD3eti2GhoeAH2egDOWQKcREG1zK0mSVBOty13Hic+eyOKsxbRv2p73L3ufDs07RLosSZIUYZUOKowZM4Yrr7ySESNGcNhhhzFu3DgaNmzI008/XeHx//73v7nlllsYMmQIBx10EFdffTVDhgzhL3/5S7njtmzZwsUXX8yTTz5JixYt9u5qJFFYCP/8JxxyCFx9NaxaBWlp8Pe/w9KlcOWVEBcX6SolSaoZ7G2lGi5UCMv+Ca8fAnOuhq2rIDENev8dhi6Fg6+EGJtbSZKkmmr91vUM+vcgFq5bSGqTVN677D0ObHFgpMuSJEk1QKWCCgUFBcydO5dBgwZtf4HoaAYNGsSsWbMqPCc/P5+EhIRy+xITE/noo4/K7bv22ms5/fTTy7327uTn55OTk1Nuk+qzoiL417+gc+cgjLBiBbRtC488AsuWBaGF+PhIVylJUs1hbyvVYKEi+PZf8HpnmH0lbF0BiW2h5yPw82VwyNUQY3MrSZJUk23ctpGT/30yX2R8QZvGbXhv+Hsc3PLgSJclSZJqiEot3pmVlUVxcTEpKSnl9qekpLB48eIKzxk8eDBjxozhuOOOo1OnTkybNo1JkyZRXFxcdswLL7zAvHnzmDNnzh7XMnr0aO6+++7KlC/VSUVF8J//wD33BIEEgJQUGDUK/t//g8TEyNYnSVJNZW8r1UChIvjhP/DlPbClpLlNSIHDRsHB/w9ibW4lSZJqg015mzjluVOYv3Y+rRu2ZtrwaXRO6hzpsiRJUg1S6aUfKuvhhx/mkEMOoUuXLsTFxXHdddcxYsQIoqODt165ciU33ngjEyZM2OnXabtz8803k52dXbatXLlyf12CVCMVF8Pzz8Phh8Pw4UFIoXVreOghWL4cfvMbQwqSJFU1e1tpPwkVw/fPw5uHw6zhQUghvjUc9RD8fDl0+Y0hBUmSpFoiJz+HU587lc9Wf0arxFa8d9l7HNb6sEiXJUmSaphKTVRISkoiJiaGjIyMcvszMjJo06ZNhee0bt2aV199lby8PNavX09qaiqjRo3ioIMOAmDu3LlkZmZy9NFHl51TXFzMBx98wKOPPkp+fj4xMTE7vW58fDzxzrFXPRQKwcsvw113waJFwb5WreCmm+Daa6FRo4iWJ0lSrWFvK9UA4RCseBm+vAtySprb+FbQ9SY49FqItbmVJEmqTbYUbGHIhCF8mv4pLRJa8O7wd+mW3C3SZUmSpBqoUhMV4uLi6NmzJ9OmTSvbFwqFmDZtGv369dvtuQkJCaSlpVFUVMQrr7zCmWeeCcBJJ53El19+yYIFC8q2Xr16cfHFF7NgwYIKP8iV6qspU6BHDxg2LAgptGgB990H330XBBUMKUiStOfsbaUIWz0F3u4BHw8LQgpxLaD7ffDz7+CwmwwpSJIk1TK5Bbmc/vzpfLzyY5rFN2PqpVPp0aZHpMuSJEk1VKUmKgCMHDmSyy67jF69etGnTx/Gjh1Lbm4uI0aMAGD48OGkpaUxevRoAD799FPS09Pp0aMH6enp3HXXXYRCIW666SYAmjRpQrdu5ROVjRo1olWrVjvtl+qrL7+E3/8e3nkneNysGfzud3DDDcF9SZK0d+xtpQjY9CXM+z2sLWluGzSDLr+DzjdAnM2tJElSbbS1cCs/f+HnfPDDBzSNb8o7l75Dz9SekS5LkiTVYJUOKgwbNox169Zxxx13sHbtWnr06MGUKVNISUkBYMWKFWVr9ALk5eVx2223sXz5cho3bsyQIUP497//TfPmzavsIqS6au1auOMOeOqpYMmHuLggnHDLLcE0BUmStG/sbaVqtG0tfHEHLH8qWPIhOi4IJxx+SzBNQZIkSbVSXlEeZ71wFu999x6N4xoz5eIp9EnrE+myJElSDRcVDofDkS6iKuTk5NCsWTOys7Np2rRppMuR9sm2bTBmDPzpT7BlS7Dv/PODxyVLYEuSVK/V9d6vrl+f6pmibbB4DCz8ExSVNLcHnA89/gSNbW4lSarrvV9dv776Lr8on7Mnns3by96mYYOGTLl4Csd2ODbSZUmSpAipTO9X6YkKkvafUAiefz6YmLByZbCvT58gtHDMMZGtTZIkSaqUcAi+fx4+vwW2ljS3rfrA0WOgtc2tJElSbVdQXMD5L53P28veJjE2kTcvetOQgiRJ2mMGFaQa4sMPYeRI+Oyz4PEBBwQTFIYNgx0mTkuSJEk1X+aHMG8kbChpbhseEExQ6DAMomxuJUmSarvC4kIuePkCXl/6OgmxCbx24WsM7Dgw0mVJkqRaxKCCFGHLlsEf/wiTJgWPmzQJJirceCMkJka2NkmSJKlSNi+DBX+ElSXNbWwTOPwW6HwjxNrcSpIk1QVFoSIumXwJkxdPJi4mjleHvcqggwZFuixJklTLGFSQImTjRrj3Xnj0USgsDKYm/PrXcPfdkJwc6eokSZKkSijYCF/eC988CqHCYGpCp1/DkXdDgs2tJElSXVEcKuayVy/jxa9fpEF0Ayb9YhKDDx4c6bIkSVItZFBBqmYFBfCPf8A998CGDcG+006DBx+Eww+PbG2SJElSpRQXwDf/gK/ugYKS5rbtaXDUg9Dc5laSJKkuCYVD/Oq1X/H8l88TGx3LS+e/xOmHnh7psiRJUi1lUEGqJuEw/Pe/cNNN8M03wb5u3eChh2CwoWNJkiTVJuEwrPovLLgJNpc0t826wVEPQarNrSRJUl0TCof49eu/Zvzn44mJiuGFc1/gzC5nRrosSZJUixlUkKrB3Lnwu9/BjBnB4+Rk+L//gxEjINb/FUqSJKk22TAX5v0OMkua24RkOPL/4KAREG1zK0mSVNeEw2GuffNanpr/FNFR0Uw4ZwLnHnZupMuSJEm1nJ8iSfvRqlVw663w7LPB44SEILDwxz9CkyaRrU2SJEmqlK2r4PNb4buS5jYmAbr8Dg77IzSwuZUkSaqLwuEwN7x9A+PmjiOKKMafNZ5h3YZFuixJklQHGFSQ9oMtW+DPfw6Wddi2Ldh3ySVw331wwAGRrU2SJEmqlMItsOjPsOghKC5pbjteAt3vg0Y2t5IkSXVVOBzmd+/8jkfnPArA02c+zSVHXhLhqiRJUl1hUEGqQsXF8MwzcNttsHZtsO/YY+Evf4HevSNamiRJklQ5oWL47hn4/DbIK2luWx8LR/8FWtncSpIk1WXhcJhR747ir5/8FYAnzniCy3tcHtmiJElSnWJQQaoi774bLOvwxRfB406dgqkKZ58NUVGRrU2SJEmqlLXvwrzfwaaS5rZxJzjqz9DO5laSJKmuC4fD3P7+7fx55p8BeGzIY1zZ88oIVyVJkuoagwrSPlq0CP7wB3jzzeBx8+Zwxx1w7bUQFxfR0iRJkqTKyV4E8/8Aq0ua2wbN4Yg74JBrIcbmVpIkqT64Z8Y93PfhfQA8fOrDXNP7mghXJEmS6iKDCtJeWrcO7roLHn88WPIhNjYIJ9x+O7RqFenqJEmSpErIWwdf3gXLHodwMUTFwqHXQrfbId7mVpIkqb64/8P7uWvGXQA8dPJD3ND3hsgWJEmS6iyDClIl5eXB3/4G990HOTnBvrPOggcegEMPjWhpkiRJUuUU58GSv8HX90FhSXPb7izo8QA0tbmVJEmqTx78+EFufe9WAEafNJrf9f9dhCuSJEl1mUEFaQ+Fw/Dii/DHP8IPPwT7jj4a/vIXGDgwoqVJkiRJlRMOw4oXYcEfIbekuW1xNBz9F0gZGNHSJEmSVP3+Ouuv3PTuTQDcM/AeRg0YFeGKJElSXWdQQdoDs2bByJHwySfB47Q0uP9+uOQSiI6ObG2SJElSpaybBfNGwvqS5jYxDbrfDwdeAlE2t5IkSfXNo7MfZeQ7IwG4/bjbuf342yNckSRJqg8MKki78d13cPPNMHFi8LhRo2Ciwu9+Bw0bRrY2SZIkqVK2fAcLboYVJc1tbCPo+kfo+juItbmVJEmqjx7/7HGuf/t6AEYdM4q7B94d4YokSVJ9YVBBqkB2djAxYexYKCiAqCj45S/h3nuhbdtIVydJkiRVQkE2fH0/LBkLoQIgCjr9Eo68FxJtbiVJkuqrp+Y9xVVvXgXA7/r9jvtPup+oqKgIVyVJkuoLgwrSDoqK4Ikn4M47ISsr2HfSSfCXv0D37pGtTZIkSaqUUBEsewK+vBPyS5rblJPg6L9AC5tbSZKk+uzZz5/lytevBODGvjfy4MkPGlKQJEnVyqCCBITD8NZb8Pvfw+LFwb4uXeChh2DIkGCigiRJklQrhMOw+i2Y/3vIKWlum3aBox6CVJtbSZKk+u75L59nxH9HECbMNb2u4a+D/2pIQZIkVbvoSBcgRdrnn8PJJ8MZZwQhhaQkeOwx+OILOP10P8eVJElSLbLxc3jvZJhxRhBSiE+CXo/BkC8gzeZWkiTBY489RseOHUlISKBv377Mnj17t8ePHTuWzp07k5iYSPv27fntb39LXl5eNVWrqvbS1y9x6eRLCYVDXHn0lTwy5BFDCpIkKSKcqKB6a80auO02+Ne/gh+dxcXBb34Dt9wCzZpFujpJkiSpEratgc9vg+X/AsIQHQedfwOH3wJxNreSJCkwceJERo4cybhx4+jbty9jx45l8ODBLFmyhOTk5J2Of/755xk1ahRPP/00/fv3Z+nSpVx++eVERUUxZsyYCFyB9sXkRZO58JULCYVDjOgxgnFnjCM6yt8ySpKkyDCooHonLw8efBAeeAByc4N9w4bB6NFw4IGRrU2SJEmqlOI8WPggLHoAikqa2wOGQY/R0NjmVpIklTdmzBiuvPJKRowYAcC4ceN48803efrppxk1atROx8+cOZNjjjmGiy66CICOHTty4YUX8umnn1Zr3dp3ry95nWEvD6M4XMylR17Kk0OfNKQgSZIiyk5E9UpBAZx9NtxxRxBS+NnPYOZMeOEFQwqSJEmqZYoL4IOz4cs7gpBCq5/ByTNhwAuGFCRJ0k4KCgqYO3cugwYNKtsXHR3NoEGDmDVrVoXn9O/fn7lz55YtD7F8+XLeeusthgwZssv3yc/PJycnp9ymyHr7m7c576XzKAwVckG3C/jXmf8iJjom0mVJkqR6zokKqjeKi+HSS2HKFGjYEP75T7jgApfplSRJUi0UKoZZl8KaKRDTEPr+EzrY3EqSpF3LysqiuLiYlJSUcvtTUlJYvHhxhedcdNFFZGVlMWDAAMLhMEVFRVx11VXccsstu3yf0aNHc/fdd1dp7dp773z7DmdPPJuC4gLO7Xou/z7734YUJElSjeBEBdUL4TBccw28+CI0aACTJ8OFF/o5riRJkmqhcBg+uwZWvAjRDeC4ydDR5laSJFW96dOnc//99/P3v/+defPmMWnSJN58803uvffeXZ5z8803k52dXbatXLmyGivWjt777j3OfOFM8ovzObPzmfzn3P8QG+1vFyVJUs1gV6J64eab4YknIDoann8eTjkl0hVJkiRJe+nzm2HZExAVDf2fh7Y2t5Ik6aclJSURExNDRkZGuf0ZGRm0adOmwnNuv/12Lr30Uq644goAjjjiCHJzc/n1r3/NrbfeSnT0zr+Di4+PJz4+vuovQJXywQ8fMPQ/Q8kryuP0Q05n4nkTaRDTINJlSZIklXGiguq8Bx4INgjCCuedF9l6JEmSpL228IFgA+jzBBxgcytJkvZMXFwcPXv2ZNq0aWX7QqEQ06ZNo1+/fhWes3Xr1p3CCDExwbIB4XB4/xWrffLxio8ZMmEIWwu3MrjTYF7+xcvExxoekSRJNYsTFVSnPfEEjBoV3H/wQfjVryJbjyRJkrTXlj0BC0qa26MehE42t5IkqXJGjhzJZZddRq9evejTpw9jx44lNzeXESNGADB8+HDS0tIYPXo0AEOHDmXMmDEcddRR9O3bl2XLlnH77bczdOjQssCCapZPVn3CaRNOI7cwl0EHDWLysMkkxCZEuixJkqSdGFRQnTVxIlx1VXD/llvg97+PbD2SJEnSXvthIswuaW4PvwW62txKkqTKGzZsGOvWreOOO+5g7dq19OjRgylTppCSkgLAihUryk1QuO2224iKiuK2224jPT2d1q1bM3ToUO67775IXYJ247PVnzH4ucFsLtjMwI4D+e8F/yWxQWKky5IkSapQVLiOzOjKycmhWbNmZGdn07Rp00iXowibMgV+/nMoLISrr4bHHoOoqEhXJUmSqkpd7/3q+vWpklZPgQ9+DqFCOORq6GVzK0lSXVLXe7+6fn01xfw18znx2RPZlLeJAQcM4O2L36ZxXONIlyVJkuqZyvR+0bt9VqqFPvoIzjknCClceCE8+qif40qSJKmWyvwIPjwnCCl0uBB62dxKkiSpvC8yvmDQvwexKW8T/dr1462L3jKkIEmSajyDCqpTFiyAM86AbdtgyBAYPx6i/VsuSZKk2mjjAphxBhRvg9Qh0G88RNncSpIkabuvM7/mpGdPYsO2DfRJ68PbF79Nk/gmkS5LkiTpJ/kpl+qMpUth8GDIzoZjj4WXXoIGDSJdlSRJkrQXcpbC+4OhMBtaHwsDXoJom1tJkiRttzhrMSc9exJZW7M4uu3R/O+S/9EsoVmky5IkSdojBhVUJ6xaBSefDJmZcNRR8Prr0LBhpKuSJEmS9sLWVfDeyZCXCS2OguNfh1ibW0mSJG23cdtGThx/Ihm5GXRP6c7US6fSPKF5pMuSJEnaY3sVVHjsscfo2LEjCQkJ9O3bl9mzZ+/y2MLCQu655x46depEQkIC3bt3Z8qUKeWOGT16NL1796ZJkyYkJydz1llnsWTJkr0pTfXQunVBSGHFCjj0UJgyBZoZHJYkSXvI3lY1St66IKSwdQU0ORROmAJxNreSJEkq7+1lb7Nmyxo6Nu/Iu8PfpWViy0iXJEmSVCmVDipMnDiRkSNHcueddzJv3jy6d+/O4MGDyczMrPD42267jccff5xHHnmEhQsXctVVV3H22Wczf/78smNmzJjBtddeyyeffMLUqVMpLCzklFNOITc3d++vTPVCTg6cdhosXgzt28PUqZCcHOmqJElSbWFvqxqlMAemnwY5i6FhezhxKiTY3EqSJGlnc9LnADD00KEkNUyKcDWSJEmVFxUOh8OVOaFv37707t2bRx99FIBQKET79u25/vrrGTVq1E7Hp6amcuutt3LttdeW7Tv33HNJTEzkueeeq/A91q1bR3JyMjNmzOC4447bo7pycnJo1qwZ2dnZNG3atDKXpFpq27YgpDBjBrRuDR9+CJ07R7oqSZJUHaqq97O3VY1RtC0IKWTOgPjWcPKH0NTmVpKk+qCu9351/foiZcDTA/h45cc8e9azXNr90kiXI0mSBFSu96vURIWCggLmzp3LoEGDtr9AdDSDBg1i1qxZFZ6Tn59PQkJCuX2JiYl89NFHu3yf7OxsAFq23PW4qvz8fHJycsptqj8KC2HYsCCk0LRpsNyDIQVJklQZ9raqMUKF8PGwIKTQoGmw3IMhBUmSJO1CUaiIeWvmAdA7rXeEq5EkSdo7lQoqZGVlUVxcTEpKSrn9KSkprF27tsJzBg8ezJgxY/jmm28IhUJMnTqVSZMmsWbNmgqPD4VC/OY3v+GYY46hW7duu6xl9OjRNGvWrGxr3759ZS5FtVgoBL/8Jbz+OiQkBLdHHx3pqiRJUm1jb6saIRyCT34J6a9DTAIc/zq0tLmVJEnSri1ct5BtRdtoGt+UQ1sdGulyJEmS9kqlggp74+GHH+aQQw6hS5cuxMXFcd111zFixAiioyt+62uvvZavvvqKF154Ybeve/PNN5OdnV22rVy5cn+UrxomHIYbb4TnnoPYWHj5ZdjDCcqSJEn7zN5WVSochrk3wvfPQVQsDHgZkm1uJUmStHtz0ucA0LNtT6Kj9vtH/JIkSftFpbqYpKQkYmJiyMjIKLc/IyODNm3aVHhO69atefXVV8nNzeWHH35g8eLFNG7cmIMOOminY6+77jreeOMN3n//fdq1a7fbWuLj42natGm5TXXfnXfCo49CVBQ8+yycfnqkK5IkSbWVva0i7ss7YemjQBT0exbSbG4lSZL00+asDoIKvVNd9kGSJNVelQoqxMXF0bNnT6ZNm1a2LxQKMW3aNPr167fbcxMSEkhLS6OoqIhXXnmFM888s+y5cDjMddddx+TJk3nvvfc48MADK3kZqg/++le4997g/mOPwYUXRrYeSZJUu9nbKqIW/xW+Kmluez8GHW1uJUmStGdmp88GoHeaQQVJklR7xVb2hJEjR3LZZZfRq1cv+vTpw9ixY8nNzWXEiBEADB8+nLS0NEaPHg3Ap59+Snp6Oj169CA9PZ277rqLUCjETTfdVPaa1157Lc8//zz//e9/adKkSdmawM2aNSMxMbEqrlO13L/+BSNHBvfvuw+uvjqy9UiSpLrB3lYR8e2/YF5Jc9v9PjjE5laSJEl7Jq8ojy8zvwScqCBJkmq3SgcVhg0bxrp167jjjjtYu3YtPXr0YMqUKaSkpACwYsWKcmv05uXlcdttt7F8+XIaN27MkCFD+Pe//03z5s3LjvnHP/4BwMCBA8u917/+9S8uv/zyyl+V6pRJk+CKK4L7v/893HxzZOuRJEl1h72tqt3KSTC7pLnt+ns4zOZWkiRJe27B2gUUhYpIbpTMAc0OiHQ5kiRJey0qHA6HI11EVcjJyaFZs2ZkZ2e7pm8d8u67cPrpUFAAv/oVPPkkREVFuipJkhRpdb33q+vXV2+tfRemnw6hAuj0K+hjcytJkup+71fXr6+6PfLpI9ww5QZOP+R03rjojUiXI0mSVE5ler/o3T4rRdAnn8BZZwUhhfPOg8cf93NcSZIk1VJZn8AHZwUhhfbnQW+bW0mSJFXenNVzAJd9kCRJtZ9BBdVIX30FQ4ZAbi6ccgo89xzExES6KkmSJGkvbPoKpg+Bolxocwr0fw6ibW4lSZJUeWVBhTSDCpIkqXYzqKAaZ/nyIJywcSP06weTJkF8fKSrkiRJkvbCluXw/ilQsBGS+sFxkyDG5laSJEmVl5Ofw5KsJYATFSRJUu1nUEE1yurVMGgQrFkDRxwBb74JjRpFuipJkiRpL2xdDdMGwbY10PwIGPgmxNrcSpIkae/MXT2XMGE6NOtA60atI12OJEnSPjGooBpjwwYYPBi++w46dYJ33oEWLSJdlSRJkrQX8jfA+4Mh9zto3AlOeAfibG4lSZK091z2QZIk1SUGFVQjbNkCQ4bAV19BaipMnQpt2kS6KkmSJGkvFG6B6UMg+ytITIUTp0Kiza0kSZL2zez02YDLPkiSpLrBoIIiLj8fzjoLPv0UWrYMJikceGCkq5IkSZL2QnE+fHAWrP8U4loGkxQa29xKkiRp35VNVDCoIEmS6gCDCoqooiK48EKYNg0aN4a334bDD490VZIkSdJeCBXBxxdCxjSIbQwD34bmNreSJEnad5m5mazIXkEUUfRM7RnpciRJkvaZQQVFTCgEV14JkydDfDz897/Qp0+kq5IkSZL2QjgEs6+EVZMhOh6O+y8k2dxKkiSpasxJD6YpdEnqQtP4phGuRpIkad8ZVFBEhMPw+9/DM89ATAxMnAgnnhjpqiRJkqS9EA7DvN/D8mcgKgYGTIQ2NreSJEmqOmXLPqS57IMkSaobDCooIu67D/761+D+00/DmWdGth5JkiRpr319HywpaW77Pg3tbG4lSZJUtcqCCqkGFSRJUt1gUEHV7tFH4fbbg/tjx8Lw4REtR5IkSdp7Sx6FL0qa26PHwkE2t5IkSapa4XC4bOkHgwqSJKmuMKigajVhAlx/fXD/zjvhxhsjW48kSZK0176bAHNLmttud0IXm1tJkiRVvRXZK1i3dR2x0bF0b9M90uVIkiRVCYMKqjavvw6XXRbcv+GGIKggSZIk1UqrXodPSprbQ2+AI2xuJUmStH+ULvtwZMqRJMQmRLgaSZKkqmFQQdVi+nQ4/3woLg6WevjrXyEqKtJVSZIkSXshYzp8dD6Ei+HA4dDT5laSJEn7z+z02YDLPkiSpLrFoIL2u88+g5//HPLzg9unnoJo/+ZJkiSpNlr/Gcz4OYTyIe3n0PcpiLK5lSRJ0v5TOlHBoIIkSapL/ERN+9WiRXDqqbB5M5xwAkycCLGxka5KkiRJ2gvZi2D6qVC0GVJOgAETIdrmVpIkSftPKBxi7uq5APROM6ggSZLqDoMK2m9++AFOPhnWr4feveG//4UEl1CTJElSbZT7A7x3MuSvh5a94bj/QozNrSRJkvavJVlL2FywmYYNGnJY68MiXY4kSVKVMaig/SIjAwYNgvR0OOwwePttaNIk0lVJkiRJe2FbBkwbBNvSodlhcMLb0MDmVpIkSftf6bIPR7c9mlineUmSpDrEoIKq3KZNMHgwLFsGHTvCO+9Aq1aRrkqSJEnaCwWb4P3BsGUZNOoIJ7wD8Ta3kiRJqh5z0oOgQu9Ul32QJEl1i0EFVamtW+GMM+DzzyElBaZOhbS0SFclSZIk7YWirTDjDNj0OSSkwIlToaHNrSRJkqpP6UQFgwqSJKmuMaigKlNQAOeeCx9/DM2bB5MUDj440lVJkiRJe6G4AD48F9Z9DA2aB5MUmtjcSpIkqfoUFBewYO0CAHqnGVSQJEl1i0EFVYniYrj0UpgyBRo2hDffhCOPjHRVkiRJ0l4IFcOsS2HNFIhpCAPfhBY2t5IkSapeX2V+RX5xPi0SWtCpRadIlyNJklSlDCpon4XDcM018OKL0KABTJoE/ftHuipJkiRpL4TD8Nk1sOJFiG4Ax06C1ja3kiRJqn6z02cD0Cu1F1FRURGuRpIkqWoZVNA+u/lmeOIJiI6G55+HwYMjXZEkSZK0lz6/GZY9AVHR0P95SLW5lSRJUmTMSZ8DQO9Ul32QJEl1j0EF7ZMHHgg2gMcfh/POi2w9kiRJ0l5b+ECwAfR+HA6wuZUkSVLkzFldElRIM6ggSZLqHoMK2mtPPAGjRgX3H3wQrrgisvVIkiRJe23ZE7CgpLk96kE42OZWkiRJkZNbkMvX674GoE9anwhXI0mSVPUMKmivTJwIV10V3L/5Zvj97yNbjyRJkrTXfpgIs0ua28Nuhq42t5IkSYqs+WvnEwqHSG2SSmqT1EiXI0mSVOUMKqjSpkyBSy6BcBiuvhruuy/SFUmSJEl7afUUmHkJEIZDrobuNreSJEmKvDnpJcs+pLrsgyRJqpsMKqhSPvoIzjkHiorgwgvh0UchKirSVUmSJEl7IfMj+PAcCBdBhwuhl82tJEmSaoY5qw0qSJKkus2ggvbYggVwxhmwbRsMGQLjx0O0f4MkSZJUG21cADPOgOJtkDoE+o2HKJtbSZIk1QxlQYU0gwqSJKlu8pM47ZGlS2HwYMjOhmOPhZdeggYNIl2VJEmStBdylsL7g6EwG1ofCwNegmibW0mSJNUMG7ZtYNmGZQD0Su0V4WokSZL2D4MK+kmrVsHJJ0NmJhx1FLz+OjRsGOmqJEmSpL2wdRW8dzLkZUKLo+D41yHW5laSJEk1x2erPwOgU4tOtExsGeFqJEmS9g+DCtqt3NwgpLBiBRx6KEyZAs2aRboqSZIkaS8U5QYhha0roMmhcMIUiLO5lSRJUs0yJ91lHyRJUt23V0GFxx57jI4dO5KQkEDfvn2ZPXv2Lo8tLCzknnvuoVOnTiQkJNC9e3emTJmyT6+p6vP667B4MbRpA1OnQnJypCuSJEmqWva29ciq1yFnMSS0gROnQoLNrSRJkmqeOatLggqpBhUkSVLdVemgwsSJExk5ciR33nkn8+bNo3v37gwePJjMzMwKj7/tttt4/PHHeeSRR1i4cCFXXXUVZ599NvPnz9/r11T1mTEjuL3gAjjggMjWIkmSVNXsbeuZzJLmtsMF0MjmVpIk1U+VCdUOHDiQqKionbbTTz+9Giuuf0qDCn3S+kS4EkmSpP0nKhwOhytzQt++fenduzePPvooAKFQiPbt23P99dczatSonY5PTU3l1ltv5dprry3bd+6555KYmMhzzz23V69ZkZycHJo1a0Z2djZNmzatzCVpN7p2DSYqvPoqnHlmpKuRJEkKVFXvZ29bz7zRNZiocNyr0M7mVpIk1QzV2ftNnDiR4cOHM27cOPr27cvYsWN56aWXWLJkCckVjFLdsGEDBQUFZY/Xr19P9+7d+ec//8nll1++R+9pb1s5qzevJm1MGtFR0eSMyqFRXKNIlyRJkrTHKtP7VWqiQkFBAXPnzmXQoEHbXyA6mkGDBjFr1qwKz8nPzychIaHcvsTERD766KO9fk1Vj4yMIKQQFQXHHhvpaiRJkqqWvW09sy0jCCkQBa1tbiVJUv00ZswYrrzySkaMGMFhhx3GuHHjaNiwIU8//XSFx7ds2ZI2bdqUbVOnTqVhw4acf/751Vx5/TEnPZimcHjrww0pSJKkOq1SQYWsrCyKi4tJSUkptz8lJYW1a9dWeM7gwYMZM2YM33zzDaFQiKlTpzJp0iTWrFmz168JwYfEOTk55TZVrQ8+CG6POAJatoxsLZIkSVXN3raeWVfS3DY/AuJtbiVJUv1TFaHap556igsuuIBGjfwCfX8pXfahd2rvCFciSZK0f1UqqLA3Hn74YQ455BC6dOlCXFwc1113HSNGjCA6et/eevTo0TRr1qxsa9++fRVVrFLTpwe3AwdGsgpJkqSaw962FsuYHtwmD4xkFZIkSRGzt6HaUrNnz+arr77iiiuu2O1xhnD3TVlQIc2ggiRJqtsq9YlqUlISMTExZGRklNufkZFBmzZtKjyndevWvPrqq+Tm5vLDDz+wePFiGjduzEEHHbTXrwlw8803k52dXbatXLmyMpeiPTBjRnB7/PGRrUOSJGl/sLetZzJLmtsUm1tJkqS98dRTT3HEEUfQp0+f3R5nCHfvhcPhsqUfnKggSZLqukoFFeLi4ujZsyfTpk0r2xcKhZg2bRr9+vXb7bkJCQmkpaVRVFTEK6+8wplnnrlPrxkfH0/Tpk3Lbao6WVnw9dfB/eOOi2wtkiRJ+4O9bT2SlwXZJc1ta5tbSZJUP+1tqBYgNzeXF154gV/96lc/+T6GcPfetxu/ZWPeRuJi4jgi5YhIlyNJkrRfxVb2hJEjR3LZZZfRq1cv+vTpw9ixY8nNzWXEiBEADB8+nLS0NEaPHg3Ap59+Snp6Oj169CA9PZ277rqLUCjETTfdtMevqer3QckSvt26QVJSZGuRJEnaX+xt64l1Jc1ts26QYHMrSZLqpx1DtWeddRawPVR73XXX7fbcl156ifz8fC655JKffJ/4+Hji4+OrouR6p3SaQo82PYiLiYtwNZIkSftXpYMKw4YNY926ddxxxx2sXbuWHj16MGXKlLK1zVasWFFujd68vDxuu+02li9fTuPGjRkyZAj//ve/ad68+R6/pqrf9OnBrcs+SJKkuszetp7ImB7cJtvcSpKk+q2yQd1STz31FGeddRatWrWKRNn1xpzVLvsgSZLqj6hwOByOdBFVIScnh2bNmpGdne2o3CrQvTt88QW8+CKcf36kq5EkSSqvrvd+df36qt1b3WHTFzDgRTjA5laSJNUs1d37Pfroozz44INlodq//e1v9O3bF4CBAwfSsWNHnnnmmbLjlyxZQpcuXXjnnXc4+eSTK/1+9rZ77th/HctHKz5i/FnjGd59eKTLkSRJqrTK9H6Vnqigum/DBvjyy+D+cS7hK0mSpNosfwNsKmluW9vcSpIkXXfddbtc6mF66ZjVHXTu3Jk68lu3Gq0oVMS8NfMAJypIkqT6IfqnD1F988EHEA5D167ghGJJkiTVapkfAGFo2hUSbW4lSZJUMy1at4ithVtpEteEzkmdI12OJEnSfmdQQTuZMSO4Pd4lfCVJklTbZZY0t8k2t5IkSaq55qyeA0DP1J5ER/mxvSRJqvvseLQTgwqSJEmqMwwqSJIkqRaYkx4EFVz2QZIk1RcGFVTOxo2wYEFw36CCJEmSarWCjbBxQXA/xeZWkiRJNVfpRAWDCpIkqb4wqKByPvoIwmE49FBo2zbS1UiSJEn7IPMjIAxNDoVEm1tJkiTVTHlFeXye8TkAvdMMKkiSpPrBoILKcdkHSZIk1Rku+yBJkqRa4PO1n1MUKiKpYRIdmnWIdDmSJEnVwqCCypk+PbgdODCSVUiSJElVIHN6cJsyMJJVSJIkSbu147IPUVFREa5GkiSpehhUUJnsbJg/P7jvRAVJkiTVagXZsLGkuXWigiRJkmqw0qBCn7Q+Ea5EkiSp+hhUUJmPP4ZQCDp1grS0SFcjSZIk7YN1H0M4BI07QUObW0mSJNVcc9K3T1SQJEmqLwwqqMyMkiV8naYgSZKkWi+zpLl1moIkSZJqsM35m1mctRiA3mkGFSRJUv1hUEFlpk8PbgcOjGQVkiRJUhXInB7cpgyMZBWSJEnSbs1dM5cwYQ5odgDJjZIjXY4kSVK1MaggADZvhrlzg/tOVJAkSVKtVrgZNpQ0t05UkCRJUg3msg+SJKm+MqggAGbOhOJi6NgRDjgg0tVIkiRJ+2DdTAgXQ6OO0MjmVpIkSTXXnNUGFSRJUv1kUEGAyz5IkiSpDnHZB0mSJNUSZUGFNIMKkiSpfjGoIABmzAhuXfZBkiRJtV5mSXPrsg+SJEmqwdblruP7Td8D0LNtz8gWI0mSVM0MKojcXJgTBHcNKkiSJKl2K8qF9SXNrUEFSZIk1WCl0xQ6t+pMs4RmEa5GkiSpehlUEDNnQlERHHAAdOwY6WokSZKkfbBuJoSLoOEB0KhjpKuRJEmSdmlOuss+SJKk+suggsot+xAVFdlaJEmSpH2y47IPNreSJEmqwUonKvRJ7RPhSiRJkqqfQQWVCypIkiRJtVppUCHF5laSJEk1VzgcLgsqOFFBkiTVRwYV6rmtW2H27OD+wIERLUWSJEnaN0VbYX1Jc5s8MKKlSJIkSbuzMmclmbmZxEbH0qNNj0iXI0mSVO0MKtRzn3wCBQWQlgYHHRTpaiRJkqR9kPUJhAogMQ0a29xKkiSp5pqTHkxTOCL5CBJiEyJcjSRJUvUzqFDP7bjsg0v4SpIkqVYrXfYh2eZWkiRJNVvZsg+pLvsgSZLqJ4MK9dyOQQVJkiSpVisNKqTY3EqSJKlmKwsqpBlUkCRJ9ZNBhXosLy9Y+gFg4MCIliJJkiTtm+K8YOkHgOSBES1FkiRJ2p1QOMRnqz8DnKggSZLqL4MK9dinn0J+PrRpA4ccEulqJEmSpH2Q9SmE8iGhDTSxuZUkSVLNtXT9UnLyc0iMTeTw5MMjXY4kSVJEGFSox3Zc9sElfCVJklSrlS77kGxzK0mSpJptTnqw7MNRbY8iNjo2wtVIkiRFhkGFemz69ODWZR8kSZJU62VOD25TBkayCkmSJOknzVkdBBX6pPaJcCWSJEmRY1ChnsrPh1mzgvvHHx/ZWiRJkqR9UpwPWSXNbbLNrSRJkmq20qBC77TeEa5EkiQpcgwq1FNz5kBeHiQnQ5cuka5GkiRJ2gfr50BxHiQkQ1ObW0mSJNVchcWFLFi7AIDeqQYVJElS/WVQoZ4qXfbheJfwlSRJUm1XuuxDss2tJEmSaravMr8iryiP5gnNObjlwZEuR5IkKWIMKtRTM2YEty77IEmSpFovs6S5ddkHSZIk1XClyz70Su1FlCFbSZJUjxlUqIcKC2HmzOC+QQVJkiTVaqFCWFfS3BpUkCRJUg03Jz0IKrjsgyRJqu8MKtRDn30GW7dCq1Zw2GGRrkaSJEnaB+s/g+KtEN8KmtncSpIkqWabvXo2YFBBkiTJoEI9NH16cHv88RDt3wBJkiTVZpnTg9vk4yHK5laSJEk119bCrXyd+TUAvdMMKkiSpPptrz7Je+yxx+jYsSMJCQn07duX2bNn7/b4sWPH0rlzZxITE2nfvj2//e1vycvLK3u+uLiY22+/nQMPPJDExEQ6derEvffeSzgc3pvy9BNmlCzh67IPkiRJ9ra1XmZJc+uyD5IkSarh5q+ZT3G4mDaN25DWJC3S5UiSJEVUbGVPmDhxIiNHjmTcuHH07duXsWPHMnjwYJYsWUJycvJOxz///POMGjWKp59+mv79+7N06VIuv/xyoqKiGDNmDAAPPPAA//jHPxg/fjyHH344n332GSNGjKBZs2bccMMN+36VKlNYCB9/HNw3qCBJkuo7e9taLlQI60qaW4MKkiRJquHmrJ4DQJ+0PkRFRUW4GkmSpMiq9ESFMWPGcOWVVzJixAgOO+wwxo0bR8OGDXn66acrPH7mzJkcc8wxXHTRRXTs2JFTTjmFCy+8sNwv1WbOnMmZZ57J6aefTseOHTnvvPM45ZRTfvLXbKq8efNgyxZo0QKOOCLS1UiSJEWWvW0tt2EeFG2BuBbQ3OZWkiRJNVtpUKF3qss+SJIkVSqoUFBQwNy5cxk0aND2F4iOZtCgQcyaNavCc/r378/cuXPLPphdvnw5b731FkOGDCl3zLRp01i6dCkAn3/+OR999BGnnXZapS9Iu1e67MNxx0G0S/hKkqR6zN62Dihb9uE4iLK5lSRJUs02J92ggiRJUqlKLf2QlZVFcXExKSkp5fanpKSwePHiCs+56KKLyMrKYsCAAYTDYYqKirjqqqu45ZZbyo4ZNWoUOTk5dOnShZiYGIqLi7nvvvu4+OKLd1lLfn4++fn5ZY9zcnIqcyn1VmlQwWUfJElSfWdvWweUBRVsbiVJklSzbcrbxDcbvgGgV2qvCFcjSZIUefv9Z0fTp0/n/vvv5+9//zvz5s1j0qRJvPnmm9x7771lx7z44otMmDCB559/nnnz5jF+/Hgeeughxo8fv8vXHT16NM2aNSvb2rdvv78vpdYrKoIPPwzuDxwY0VIkSZJqJXvbGiRUBJklzW3ywIiWIkmSJP2Uz1Z/BsBBLQ6iVcNWEa5GkiQp8io1USEpKYmYmBgyMjLK7c/IyKBNmzYVnnP77bdz6aWXcsUVVwBwxBFHkJuby69//WtuvfVWoqOj+cMf/sCoUaO44IILyo754YcfGD16NJdddlmFr3vzzTczcuTIssc5OTl+oPsTFiyAzZuhWTM48shIVyNJkhRZ9ra13MYFULQZGjSD5ja3kiRJqtlc9kGSJKm8Sk1UiIuLo2fPnkybNq1sXygUYtq0afTr16/Cc7Zu3Up0dPm3iYmJASAcDu/2mFAotMta4uPjadq0ablNu1e67MOxx0LJPwJJkqR6y962litd9qH1sRBtcytJkqSabfbq2YBBBUmSpFKVmqgAMHLkSC677DJ69epFnz59GDt2LLm5uYwYMQKA4cOHk5aWxujRowEYOnQoY8aM4aijjqJv374sW7aM22+/naFDh5Z9qDt06FDuu+8+DjjgAA4//HDmz5/PmDFj+OUvf1mFl6rp04Pb413CV5IkCbC3rdUypge3KTa3kiRJqvnKJiqkGVSQJEmCvQgqDBs2jHXr1nHHHXewdu1aevTowZQpU0hJSQFgxYoV5X5BdttttxEVFcVtt91Geno6rVu3LvvwttQjjzzC7bffzjXXXENmZiapqan8v//3/7jjjjuq4BIFUFwMH5Ys4TtwYERLkSRJqjHsbWupUDGsK2lukwdGtBRJkiTpp6zZvIb0zelER0VzdNujI12OJElSjRAVLp1RW8vl5OTQrFkzsrOzHZVbgfnz4eijoUkT2LABYisdUZEkSao56nrvV9evb59tmA9TjobYJnDeBoi2uZUkSbVXXe/96vr17YnXlrzGmS+cSbfkbnx59ZeRLkeSJGm/qUzvF73bZ1VnzChZwnfAAEMKkiRJquUyS5rb1gMMKUiSJKnGK1v2IdVlHyRJkkoZVKgnpk8Pbl32QZIkSbVe5vTgNmVgJKuQJEmS9sic1QYVJEmSfsygQj0QCsGHJUv4Hn98ZGuRJEmS9kk4BJklzW2yza0kSZJqtnA4vD2okGZQQZIkqZRBhXrgq69gwwZo1AiOPjrS1UiSJEn7YNNXULABYhtBS5tbSZIk1WzfbfqODds2EBcTx5EpR0a6HEmSpBrDoEI9ULrsw4AB0KBBREuRJEmS9k3psg+tB0C0za0kSZJqtjnpwTSF7indiYuJi3A1kiRJNYdBhXpgxozg1mUfJEmSVOtlljS3LvsgSZKkWmB2+mwAeqe67IMkSdKODCrUcaEQfPBBcN+ggiRJkmq1cAgyS5pbgwqSJEl75bHHHqNjx44kJCTQt29fZs+evdvjN23axLXXXkvbtm2Jj4/n0EMP5a233qqmamu/OauDiQq90wwqSJIk7Sg20gVo/1q4ELKyoGFD6NUr0tVIkiRJ+yB7IeRnQUxDaGlzK0mSVFkTJ05k5MiRjBs3jr59+zJ27FgGDx7MkiVLSE5O3un4goICTj75ZJKTk3n55ZdJS0vjhx9+oHnz5tVffC1UHCpm3pp5gBMVJEmSfsygQh1XuuxD//4Q5xJokiRJqs1Kl31o3R9c31eSJKnSxowZw5VXXsmIESMAGDduHG+++SZPP/00o0aN2un4p59+mg0bNjBz5kwaNGgAQMeOHauz5FptUdYicgtzaRzXmC5JXSJdjiRJUo3i0g91XGlQwWUfJEmSVOuVBhVc9kGSJKnSCgoKmDt3LoMGDSrbFx0dzaBBg5g1a1aF57z22mv069ePa6+9lpSUFLp168b9999PcXFxdZVdq81JD5Z96Nm2JzHRMRGuRpIkqWZxokIdFg4bVJAkSVIdEQ4bVJAkSdoHWVlZFBcXk5KSUm5/SkoKixcvrvCc5cuX895773HxxRfz1ltvsWzZMq655hoKCwu58847KzwnPz+f/Pz8ssc5OTlVdxG1zJzVQVDBZR8kSZJ25kSFOmzxYsjMhIQE6NMn0tVIkiRJ+yBnMeRlQkwCtLK5lSRJqg6hUIjk5GSeeOIJevbsybBhw7j11lsZN27cLs8ZPXo0zZo1K9vat29fjRXXLGVBhTSDCpIkST9mUKEOK52m0K8fxMdHthZJkiRpn5ROU0jqBzE2t5IkSZWVlJRETEwMGRkZ5fZnZGTQpk2bCs9p27Ythx56KDEx25ct6Nq1K2vXrqWgoKDCc26++Ways7PLtpUrV1bdRdQi+UX5fL72c8CJCpIkSRUxqFCHueyDJEmS6gyXfZAkSdoncXFx9OzZk2nTppXtC4VCTJs2jX79+lV4zjHHHMOyZcsIhUJl+5YuXUrbtm2Ji4ur8Jz4+HiaNm1abquPvsj4gsJQIa0SW9GxecdIlyNJklTjGFSoo8JhmD49uD9wYCQrkSRJkvZROAwZ04P7yQMjWYkkSVKtNnLkSJ588knGjx/PokWLuPrqq8nNzWXEiBEADB8+nJtvvrns+KuvvpoNGzZw4403snTpUt58803uv/9+rr322khdQq0xO302ECz7EBUVFeFqJEmSap7YSBeg/eObb2Dt2mDJh759I12NJEmStA82fwN5ayE6HpJsbiVJkvbWsGHDWLduHXfccQdr166lR48eTJkyhZSUFABWrFhBdPT237a1b9+e//3vf/z2t7/lyCOPJC0tjRtvvJE//vGPkbqEWmPO6jmAyz5IkiTtikGFOqp02Ye+fSEhIbK1SJIkSfukdNmHpL4QY3MrSZK0L6677jquu+66Cp+bXjqidQf9+vXjk08+2c9V1T0GFSRJknbPpR/qKJd9kCRJUp3hsg+SJEmqRTbnb2bRukVAsPSDJEmSdmZQoQ4Kh7dPVDj++MjWIkmSJO2TcHj7RIVkm1tJkiTVfPPWzCNMmPZN29OmcZtIlyNJklQjGVSog5Yvh/R0aNAAfvazSFcjSZIk7YMty2FbOkQ3gCSbW0mSJNV8Zcs+OE1BkiRplwwq1EGlyz706QMNG0a0FEmSJGnfZE4Pblv1gVibW0mSJNV8ZUGFVIMKkiRJu2JQoQ4qXfZh4MCIliFJkiTtu4zSZR8GRrQMSZIkaU/NSTeoIEmS9FMMKtRBpUGF413CV5IkSbVdZmlQweZWkiRJNV/W1iy+2/QdAD1Te0a4GkmSpJrLoEId8/33sGIFxMZC//6RrkaSJEnaB1u+h60rICoWWtvcSpIkqeYrnaZwaKtDaZ7QPLLFSJIk1WAGFeqY6dOD2969oVGjiJYiSZIk7ZvM6cFtq94Qa3MrSZKkmm/Oapd9kCRJ2hMGFeoYl32QJElSneGyD5IkSaplDCpIkiTtGYMKdYxBBUmSJNUZGQYVJEmSVHuEw+GypR96pxlUkCRJ2h2DCnXIihXw3XcQEwPHHBPpaiRJkqR9kLsCcr+DqBhobXMrSZKkmm9VzioycjOIiYrhqDZHRbocSZKkGs2gQh1SOk2hZ09o0iSytUiSJEn7pHTZh5Y9oYHNrSRJkmq+0mUfjkg5gsQGiRGuRpIkqWYzqFCHuOyDJEmS6oxMl32QJElS7VK27EOqyz5IkiT9FIMKdcj06cHtwIGRrEKSJEmqAhnTg9vkgZGsQpIkSdpjpRMVDCpIkiT9NIMKdUR6Onz7LURHw4AB/7+9Ow+Pqrz7P/6ZyZ6QhC0JJASCIiCIrCEGFFKJLPpEQAs8QgFRwQUeF6oVBETtT6hLEWuxiI9AfdSKVlBaEIvU4AKShU0UQ9iEBkhAlpAACWTu3x/DjBmykH0y4f26rlyTzJxzn+85mXPmY/xybndXAwAAAFTDmSwpb49ksUrhhFsAAADUfzZjU9qhNElSbBSNCgAAAJdDo0ID4Zj2oXt3KSTEvbUAAAAA1eKY9qFJd8mHcAsAAID6L/PnTJ0qOCV/b391Duvs7nIAAADqPRoVGghHo0J/pvAFAACAp3M0KoQTbgEAAOAZHNM+dG/RXT5ePm6uBgAAoP6jUaGBSE62PyYkuLMKAAAAoAZkJ9sfwxPcWQUAAABQYalZ9kaF2EimfQAAAKiIKjUqLFiwQDExMfL391dcXJxSUlLKXX7+/Pnq0KGDAgICFB0drccee0znzp1zWSYrK0u/+c1v1KxZMwUEBKhLly5KS0urSnlXnMOHpV27JItFuukmd1cDAADgWci29czZw9LpXZIsUjjhFgAAAJ7BcUeF2CgaFQAAACrCu7IrLFu2TFOnTtXChQsVFxen+fPna9CgQcrIyFB4eHiJ5d977z1NmzZNixcvVp8+fbRr1y7dfffdslgsmjdvniTpxIkT6tu3r371q1/p008/VVhYmDIzM9WkSZPq7+EV4Msv7Y9du0qNG7u1FAAAAI9Ctq2Hci6G2yZdJd/Gbi0FAAAAqIjzRee15cgWSVLvqN5urgYAAMAzVLpRYd68eZo4caImTJggSVq4cKFWrVqlxYsXa9q0aSWW37Bhg/r27avRo0dLkmJiYnTXXXdp06ZNzmVeeOEFRUdHa8mSJc7n2rZtW+mduVIx7QMAAEDVkG3rIaZ9AAAAgIf5/uj3OnfhnEL9QtWuaTt3lwMAAOARKjX1Q2FhodLT05WYmPjLAFarEhMTtXHjxlLX6dOnj9LT05230N27d69Wr16tW2+91bnMypUr1atXL40YMULh4eHq3r273nzzzXJrKSgoUG5ursvXlWr9evtj//7urQMAAMCTkG3rqZyL4TaccAsAAADPkJpln/ahV2QvWS1Vmm0ZAADgilOp1HTs2DEVFRUpIiLC5fmIiAgdOXKk1HVGjx6t5557TjfeeKN8fHx09dVXKyEhQU899ZRzmb179+ovf/mLrrnmGn322Wd68MEH9fDDD+uvf/1rmbXMnTtXoaGhzq/o6OjK7EqDkZMj7dxp//4mpvAFAACoMLJtPXQuR8q9GG7DCbcAAADwDKmH7I0KsZGxbq4EAADAc9R6e2dycrLmzJmj119/XZs3b9by5cu1atUq/f73v3cuY7PZ1KNHD82ZM0fdu3fXpEmTNHHiRC1cuLDMcadPn65Tp045vw4ePFjbu1IvOe6mcP31UrNm7q0FAACgoSPb1jLH3RQaXy/5EW4BAADgGZyNClE0KgAAAFSUd2UWbt68uby8vJSdne3yfHZ2tlq0aFHqOrNmzdLYsWN13333SZK6dOmi/Px8TZo0STNmzJDValXLli3VqVMnl/WuvfZaffTRR2XW4ufnJz8/v8qU3yAx7QMAAEDVkG3roWymfQAAAIBnOXv+rL7L/k4Sd1QAAACojErdUcHX11c9e/bUunXrnM/ZbDatW7dO8fHxpa5z5swZWa2um/Hy8pIkGWMkSX379lVGRobLMrt27VKbNm0qU94ViUYFAACAqiHb1kM5NCoAAADAs2w5skVFpkgRQRFqFdLK3eUAAAB4jErdUUGSpk6dqvHjx6tXr17q3bu35s+fr/z8fE2YMEGSNG7cOEVFRWnu3LmSpKSkJM2bN0/du3dXXFycdu/erVmzZikpKcn5R93HHntMffr00Zw5czRy5EilpKRo0aJFWrRoUQ3uasNz7Ji0Y4f9+3793FsLAACAJyLb1iPnjkmnLobbcMItAAAAPENq1i/TPlgsFjdXAwAA4Dkq3agwatQoHT16VE8//bSOHDmibt26ac2aNYqIiJAkHThwwOVfmc2cOVMWi0UzZ85UVlaWwsLClJSUpOeff965TGxsrFasWKHp06frueeeU9u2bTV//nyNGTOmBnax4fryS/tj585SWJh7awEAAPBEZNt65OjFcBvaWfIn3AIAAMAzpB662KjAtA8AAACVYjGOe9R6uNzcXIWGhurUqVMKCQlxdzl14pFHpD/9SXroIWnBAndXAwAAUHcaevZr6PtXqrRHpF1/kq55SIol3AIAgCtHQ89+DX3/Ovy5g3b9vEufjvlUg9sNdnc5AAAAblWZ7Gct91XUa+svTuHbnyl8AQAA4OlyLobbcMItAAAAPMPJcye16+ddkqRekb3cXA0AAIBnoVHBQx0/Lm3fbv+eRgUAAAB4tILj0smL4ZZGBQAAAHiI9EPpkqS2jduqeWBzN1cDAADgWWhU8FBffSUZI3XsKF2cQhkAAADwTEe/kmSkkI5SAOEWAAAAniH1UKokKTYq1s2VAAAAeB4aFTwU0z4AAACgwchm2gcAAAB4HmejQiSNCgAAAJVFo4KHSk62PyYkuLMKAAAAoAbkJNsfwxPcWQUAAABQKalZNCoAAABUFY0KHujkSWnrVvv33FEBAAAAHq3wpHRiq/37CMItAAAAPMORvCM6mHtQFlnUo2UPd5cDAADgcWhU8EBffy0ZI11zjdSypburAQAAAKrh6NeSjBR8jRRAuAUAAIBncNxN4dqwaxXsF+zmagAAADwPjQoeyDHtA3dTAAAAgMfLTrY/hhNuAQAA4DlSDzHtAwAAQHXQqOCB1q+3PyYkuLUMAAAAoPpyLobb8AS3lgEAAABUhqNRoXdUbzdXAgAA4JloVPAwubnS5s3277mjAgAAADza+VzpxMVwG0G4BQAAgGcwxjinfuCOCgAAAFVDo4KH+fpryWaTrrpKatXK3dUAAAAA1ZDztWRsUqOrpEDCLQAAADzD/pP79fPZn+Vj9dH1Ede7uxwAAACPRKOCh2HaBwAAADQYTPsAAAAAD+SY9qFri67y8/ZzczUAAACeiUYFD+NoVGDaBwAAAHg8Z6MC4RYAAACeg2kfAAAAqo9GBQ+Slyelpdm/p1EBAAAAHu18nnT8YriNINwCAADAczjuqECjAgAAQNXRqOBBvvlGKiqSYmKkNm3cXQ0AAABQDUe/kUyRFBQjBRFuAQAA4BmKbEVKO2RvuI2NolEBAACgqmhU8CBM+wAAAIAGg2kfAAAA4IF+PPaj8s/nK8gnSNc2v9bd5QAAAHgsGhU8CI0KAAAAaDBoVAAAAIAHckz70KNlD3lZvdxcDQAAgOeiUcFD5OdLKSn27xMS3FoKAAAAUD0X8qWfL4bbiAS3lgIAAABURmqWvVEhNpJpHwAAAKqDRgUPsXGjdOGCFB0txcS4uxoAAACgGo5tlMwFKTBaCopxdzUAAABAhTnuqNA7qrebKwEAAPBsNCp4iOLTPlgs7q0FAAAAqJbsYtM+EG4BAADgIQqLCrUte5skKTaKOyoAAABUB40KHiI52f7Ynyl8AQAA4Olyku2P4YRbAAAAeI7t2dtVWFSoZgHN1LZxW3eXAwAA4NFoVPAAZ89KKRen8E1IcGspAAAAQPVcOCv9fDHcRiS4tRQAAACgMlKz7NM+9IrsJQt3BgMAAKgWGhU8wLffSoWFUmSkdPXV7q4GAAAAqIafv5VshVJApNSIcAsAAFDXFixYoJiYGPn7+ysuLk4pjn8hVYqlS5fKYrG4fPn7+9dhtfVL6iF7o0JsJNM+AAAAVBeNCh5g/cUpfPszhS8AAAA8XfbFcBtOuAUAAKhry5Yt09SpUzV79mxt3rxZXbt21aBBg5STk1PmOiEhITp8+LDz66effqrDiuuXlCx7U0dsFI0KAAAA1UWjggdITrY/Mu0DAAAAPF5Osv2RaR8AAADq3Lx58zRx4kRNmDBBnTp10sKFCxUYGKjFixeXuY7FYlGLFi2cXxEREXVYcf2RV5inncd2SuKOCgAAADWBRoV67tw5+9QPkv2OCgAAAIDHKjonHbsYbsMJtwAAAHWpsLBQ6enpSkxMdD5ntVqVmJiojRs3lrleXl6e2rRpo+joaA0dOlTff/99XZRb72w+vFk2Y1NUcJRaBrd0dzkAAAAej0aFei4lRSookCIipPbt3V0NAAAAUA0/p0i2Ask/Qgom3AIAANSlY8eOqaioqMQdESIiInTkyJFS1+nQoYMWL16sTz75RO+8845sNpv69Omj//znP2Vup6CgQLm5uS5fDUFqVqokpn0AAACoKTQq1HPFp31gCl8AAAB4tOxk+2N4AuEWAADAA8THx2vcuHHq1q2b+vfvr+XLlyssLExvvPFGmevMnTtXoaGhzq/o6Og6rLj2pB6yNyr0juzt5koAAAAaBhoV6rn16+2PTPsAAAAAj5dzMdxGEG4BAADqWvPmzeXl5aXs7GyX57Ozs9WiRYsKjeHj46Pu3btr9+7dZS4zffp0nTp1yvl18ODBatVdXzgaFbijAgAAQM2gUaEeKyiQHNPD0agAAAAAj1ZUIB27GG7DCbcAAAB1zdfXVz179tS6deucz9lsNq1bt07x8fEVGqOoqEjfffedWrZsWeYyfn5+CgkJcfnydD+f+Vl7T+yVJPWK7OXmagAAABoGb3cXgLKlpkpnz0phYdK117q7GgAAAKAafk6Vis5KfmFSCOEWAADAHaZOnarx48erV69e6t27t+bPn6/8/HxNmDBBkjRu3DhFRUVp7ty5kqTnnntON9xwg9q1a6eTJ0/qpZde0k8//aT77rvPnbtR59IOpUmSrml6jRr7N3ZvMQAAAA0EjQr1WPFpH5jCFwAAAB7NMe1DOOEWAADAXUaNGqWjR4/q6aef1pEjR9StWzetWbNGERERkqQDBw7Iav3lJrwnTpzQxIkTdeTIETVp0kQ9e/bUhg0b1KlTJ3ftglsw7QMAAEDNo1GhHiveqAAAAAB4tOKNCgAAAHCbKVOmaMqUKaW+lpyc7PLzK6+8oldeeaUOqqrfUrJSJEmxkTQqAAAA1BTr5ReBO5w/L33zjf17GhUAAADg0WznpaMXw20E4RYAAACewxjzyx0VaFQAAACoMTQq1FNpadKZM1KzZlLnzu6uBgAAAKiGn9OkojOSXzMplHALAAAAz5F1OktH8o7Iy+Kl7i27u7scAACABqNKjQoLFixQTEyM/P39FRcXp5SUlHKXnz9/vjp06KCAgABFR0frscce07lz50pd9g9/+IMsFoseffTRqpTWYDimfejXT7LSTgIAAFBryLZ1wDHtQ1g/yUK4BQAAgOdIzbLfTaFzeGcF+gS6uRoAAICGo9J/JVy2bJmmTp2q2bNna/PmzeratasGDRqknJycUpd/7733NG3aNM2ePVs7d+7UW2+9pWXLlumpp54qsWxqaqreeOMNXX/99ZXfkwbG0ajAtA8AAAC1h2xbRxyNCuGEWwAAAHgWx7QPvSN7u7kSAACAhqXSjQrz5s3TxIkTNWHCBHXq1EkLFy5UYGCgFi9eXOryGzZsUN++fTV69GjFxMRo4MCBuuuuu0r8S7W8vDyNGTNGb775ppo0aVK1vWkgLlyQvv7a/n1CgltLAQAAaNDItnXAdkE6ejHcRiS4tRQAAACgshyNCrFRsW6uBAAAoGGpVKNCYWGh0tPTlZiY+MsAVqsSExO1cePGUtfp06eP0tPTnX+83bt3r1avXq1bb73VZbnJkyfrtttucxm7PAUFBcrNzXX5aig2b5by8qQmTaQuXdxdDQAAQMNEtq0jxzdLF/Ik3yZSY8ItAAAAPIcxRmmH0iRJsZE0KgAAANQk78osfOzYMRUVFSkiIsLl+YiICP3444+lrjN69GgdO3ZMN954o4wxunDhgh544AGX2+O+//772rx5s1JTUytcy9y5c/Xss89WpnyP4Zj24aabJCtT+AIAANQKsm0dcUz7EHaTZCHcAgAAwHPsPr5bJ8+dlL+3v64Lv87d5QAAADQotf6XwuTkZM2ZM0evv/66Nm/erOXLl2vVqlX6/e9/L0k6ePCgHnnkEb377rvy9/ev8LjTp0/XqVOnnF8HDx6srV2oc8nJ9sf+TOELAABQr5BtqyAn2f4YTrgFAACAZ3FM+9CtRTf5ePm4uRoAAICGpVJ3VGjevLm8vLyUnZ3t8nx2drZatGhR6jqzZs3S2LFjdd9990mSunTpovz8fE2aNEkzZsxQenq6cnJy1KNHD+c6RUVF+vLLL/XnP/9ZBQUF8vLyKjGun5+f/Pz8KlO+Rygqkr6+OIVvQoJbSwEAAGjQyLZ1wFYkHb0YbiMS3FoKAAAAUFkpWfYp35j2AQAAoOZV6o4Kvr6+6tmzp9atW+d8zmazad26dYqPjy91nTNnzsh6yfwFjj/OGmM0YMAAfffdd9q6davzq1evXhozZoy2bt1a6h9yG7KtW6XcXCk0VOra1d3VAAAANFxk2zpwcqt0PlfyCZUaE24BAADgWRx3VKBRAQAAoOZV6o4KkjR16lSNHz9evXr1Uu/evTV//nzl5+drwoQJkqRx48YpKipKc+fOlSQlJSVp3rx56t69u+Li4rR7927NmjVLSUlJ8vLyUnBwsK67znV+r6CgIDVr1qzE81cCx7QPN94oXWl/xwYAAKhrZNtalp1sfwy7UbISbgEAAOA5LtguaMvhLZKk2CgaFQAAAGpapRsVRo0apaNHj+rpp5/WkSNH1K1bN61Zs0YRERGSpAMHDrj8K7OZM2fKYrFo5syZysrKUlhYmJKSkvT888/X3F40IOvX2x+Z9gEAAKD2kW1rWc7FcMu0DwAAAPAw3+d8r7MXzirEL0Ttm7V3dzkAAAANjsUYY9xdRE3Izc1VaGioTp06pZCQEHeXUyVFRVLz5tLJk1JKihRLoy4AAECpGkL2K0+D2D9bkfRRc+n8SWlQitSMcAsAAFCaBpH9yuGp+/e/m/9XE/8xUTe3vVnrxq27/AoAAACoVPazlvsq6tT27fYmheBgqXt3d1cDAAAAVMPJ7fYmBe9gqQnhFgAAAJ4lNStVkhQbScMtAABAbaBRoR5xTPtw442Sd6Un5QAAAADqEce0D2E3SlbCLQAAADxL6iEaFQAAAGoTjQr1iKNRoX9/99YBAAAAVJujUSGCcAsAAADPcu7COX2X850kKTaKRgUAAIDaQKNCPWGzSV9+af+eRgUAAAB4NGOTci6G23DCLQAAADzL1iNbdcF2QeFB4YoOiXZ3OQAAAA0SjQr1xI4d0vHjUlCQ1LOnu6sBAAAAquHkDqnwuOQdJDUl3AIAAMCzpGSlSLJP+2CxWNxcDQAAQMNEo0I94Zj2oW9fycfHvbUAAAAA1eKY9qF5X8lKuAUAAIBnST2UKsneqAAAAIDaQaNCPeFoVGDaBwAAAHg8R6NCBOEWAAAAnic162KjQhSNCgAAALWFRoV6wBgaFQAAANBAGPNLo0I44RYAAACe5dS5U8r4OUMSd1QAAACoTTQq1AM//CAdOyYFBEixZF8AAAB4slM/SAXHJK8AqSnhFgAAAJ4l/XC6JCmmcYzCgsLcXA0AAEDDRaNCPeC4m0KfPpKvr3trAQAAAKrFcTeF5n0kL8ItAAAAPItz2gfupgAAAFCraFSoB5KT7Y9M+wAAAACPl5Nsf2TaBwAAAHig1EM0KgAAANQFGhXczJhf7qiQkODWUgAAAIDqMeaXOypEJLi1FAAAAKAqnI0KUTQqAAAA1CYaFdwsI0PKyZH8/aXevd1dDQAAAFANuRnSuRzJy19qRrgFAACAZ8nOy9aBUwdkkUU9W/Z0dzkAAAANGo0Kbua4m8INN0h+fu6tBQAAAKgWx90Umt0geRFuAQAA4Fkcd1Po2Lyjgv2C3VwNAABAw0ajgpslJ9sfmfYBAAAAHi8n2f7ItA8AAADwQKlZTPsAAABQV2hUcCNjfrmjQv/+7q0FAAAAqBZjfrmjQjjhFgAAAJ7HcUeF2EgaFQAAAGobjQputHu3dPiw5OsrxcW5uxoAAACgGk7vls4elqy+UjPCLQAAADyLMYZGBQAAgDpEo4IbOaZ9iIuTAgLcWgoAAABQPY5pH5rFSd6EWwAAAHiWn079pGNnjsnb6q2uLbq6uxwAAIAGj0YFN3JM+5CQ4NYyAAAAgOpzTPsQkeDWMgAAAICqSM2y302ha0RX+Xv7u7kaAACAho9GBTcx5pdGhf5M4QsAAABPZswvjQrhhFsAAAB4HqZ9AAAAqFs0KrjJ3r3Sf/4j+fhI8fHurgYAAACohry90pn/SFYfqTnhFgAAAJ7H2agQRaMCAABAXaBRwU0cd1Po3VsKDHRvLQAAAEC1OO6m0Ky35E24BQAAgGexGZvSD6VL4o4KAAAAdYVGBTdh2gcAAAA0GEz7AAAAAA+WcSxDpwtPK9AnUNeGXevucgAAAK4INCq4SXKy/ZFGBQAAAHi87GT7I40KAAAA8EApWSmSpB4te8jb6u3magAAAK4MNCq4wf790oEDkre31KePu6sBAAAAqiFvv3TmgGTxlpoTbgEAAOB5Ug+lSmLaBwAAgLpEo4IbOKZ96NVLatTIvbUAAAAA1eKY9qFpL8mHcAsAAADPQ6MCAABA3aNRwQ0cjQpM+wAAAACP52hUiCDcAgAAwPMUFhVq65GtkqTYKBoVAAAA6gqNCm6QnGx/TEhwZxUAAABADchOtj+GJ7izCgAAAKBKvsv+ToVFhWri30RXN7na3eUAAABcMWhUqGMHD0r79kleXlLfvu6uBgAAAKiG/INS/j7J4iWFEW4BAADgeZzTPkTFymKxuLkaAACAKweNCnXMMe1Djx5ScLB7awEAAACqxTHtQ5Mekg/hFgAAAJ4nNetio0Ik0z4AAADUJRoV6phj2of+TOELAAAAT5eTbH+MINwCAADAMznvqECjAgAAQJ2iUaGOOe6okJDg1jIAAACA6su+GG7DE9xaBgAAAFAV+YX5+v7o95LsUz8AAACg7tCoUIeysqTduyWrVbrxRndXAwAAAFTDmSwpb7dksUphhFsAAAB4ns2HN8tmbIoMjlRkcKS7ywEAALii0KhQhxx3U+jWTQoNdWspAAAAQPXkXAy3jbtJvoRbAAAAeB6mfQAAAHAfGhXqENM+AAAAoMFwNCpEJLi1DAAAAKCqaFQAAABwnyo1KixYsEAxMTHy9/dXXFycUlJSyl1+/vz56tChgwICAhQdHa3HHntM586dc74+d+5cxcbGKjg4WOHh4Ro2bJgyMjKqUlq95mhU6N/fvXUAAADgF2TbKnI0KoQTbgEAAOCZUrMuNipE0agAAABQ1yrdqLBs2TJNnTpVs2fP1ubNm9W1a1cNGjRIOTk5pS7/3nvvadq0aZo9e7Z27typt956S8uWLdNTTz3lXGb9+vWaPHmyvv32W61du1bnz5/XwIEDlZ+fX/U9q2eOHJEyMiSLRbrpJndXAwAAAIlsW2Vnj0i5GZIsUjjhFgAAAJ7n+Nnj2nNijySpV2QvN1cDAABw5fGu7Arz5s3TxIkTNWHCBEnSwoULtWrVKi1evFjTpk0rsfyGDRvUt29fjR49WpIUExOju+66S5s2bXIus2bNGpd1li5dqvDwcKWnp6tfv36VLbFectxNoWtXqUkT99YCAAAAO7JtFTnuptCkq+RLuAUAAIDnSTuUJklq17SdmgY0dXM1AAAAV55K3VGhsLBQ6enpSkxM/GUAq1WJiYnauHFjqev06dNH6enpzlvo7t27V6tXr9att95a5nZOnTolSWratOyAWFBQoNzcXJev+oxpHwAAAOoXsm01MO0DAACAx6rs1GcO77//viwWi4YNG1a7BdYR57QPkUz7AAAA4A6ValQ4duyYioqKFBER4fJ8RESEjhw5Uuo6o0eP1nPPPacbb7xRPj4+uvrqq5WQkOBye9zibDabHn30UfXt21fXXXddmbXMnTtXoaGhzq/o6OjK7Eqdo1EBAACgfiHbVgONCgAAAB6pslOfOezfv1+PP/64bmpAc9qmHqJRAQAAwJ0q1ahQFcnJyZozZ45ef/11bd68WcuXL9eqVav0+9//vtTlJ0+erB07duj9998vd9zp06fr1KlTzq+DBw/WRvk1IidH+uEH+/cNKMsDAABccci2ks7lSKcuhtswwi0AAIAnKT71WadOnbRw4UIFBgZq8eLFZa5TVFSkMWPG6Nlnn9VVV11Vh9XWLmejQhSNCgAAAO7gXZmFmzdvLi8vL2VnZ7s8n52drRYtWpS6zqxZszR27Fjdd999kqQuXbooPz9fkyZN0owZM2S1/tIrMWXKFP3zn//Ul19+qVatWpVbi5+fn/z8/CpTvtt8+aX9sUsXqXlz99YCAAAAO7JtFeVcDLeNu0j+hFsAAABP4Zj6bPr06c7nLjf1mSQ999xzCg8P17333quvvvqqLkqtdVm5WTp0+pCsFqu6t+ju7nIAAACuSJW6o4Kvr6969uypdevWOZ+z2Wxat26d4uPjS13nzJkzLn+wlSQvLy9JkjHG+ThlyhStWLFC//73v9W2bdtK7UR9x7QPAAAA9Q/ZtoqY9gEAAMAjVWXqs6+//lpvvfWW3nzzzQpvp6CgQLm5uS5f9Y3jbgqdwzoryDfIzdUAAABcmSp1RwVJmjp1qsaPH69evXqpd+/emj9/vvLz8zVhwgRJ0rhx4xQVFaW5c+dKkpKSkjRv3jx1795dcXFx2r17t2bNmqWkpCTnH3UnT56s9957T5988omCg4OdwTg0NFQBAQE1ta9uk5xsf6RRAQAAoH4h21ZBdrL9kUYFAACABu306dMaO3as3nzzTTWvxG1i586dq2effbYWK6u+1KyL0z5EMu0DAACAu1S6UWHUqFE6evSonn76aR05ckTdunXTmjVrnJ24Bw4ccPlXZjNnzpTFYtHMmTOVlZWlsLAwJSUl6fnnn3cu85e//EWSlJCQ4LKtJUuW6O67767CbtUfx45JO3bYv+/Xz721AAAAwBXZtpLOHZNOXQy34YRbAAAAT1LZqc/27Nmj/fv3KykpyfmczWaTJHl7eysjI0NXX311ifWmT5+uqVOnOn/Ozc1VdHR0Te1GjXDcUSE2ikYFAAAAd7EYxz1qPVxubq5CQ0N16tQphYSEuLscpxUrpDvukDp1kr7/3t3VAAAANAz1NfvVlHq7fwdXSF/dIYV2km4j3AIAANSEusx+cXFx6t27t1577TVJ9saD1q1ba8qUKZo2bZrLsufOndPu3btdnps5c6ZOnz6tV199Ve3bt5evr+9lt1nfsq0xRs1ebKYT504ofVK6erTs4e6SAAAAGozKZL9K31EBlcO0DwAAAGgwmPYBAADAo1Vm6jN/f39dd911Lus3btxYkko870n2nNijE+dOyM/LT13Cu7i7HAAAgCsWjQq1bP16++Mld/4FAAAAPE/OxXAbnuDWMgAAAFA1lZ36rCFKzbJP+9CtRTf5ePm4uRoAAIArF40KtejECWn7dvv3/ZjCFwAAAJ6s8IR08mK4DSfcAgAAeKopU6ZoypQppb6W7Lg9bBmWLl1a8wXVsdRD9kaF2MhYN1cCAABwZWvY7bFu9tVXkjFShw5SixburgYAAACohpyvJBkppIMUQLgFAACAZ3I2KkTRqAAAAOBONCrUIkcDcn+m8AUAAICny062P4YTbgEAAOCZLtguKP1QuiTuqAAAAOBuNCrUovUXp/BNSHBrGQAAAED15VwMt+EJbi0DAAAAqKofjv6gsxfOKtg3WB2ad3B3OQAAAFc0GhVqycmT0tat9u+5owIAAAA8WuFJ6eRW+/fcUQEAAAAeKjXLPu1Dz8ieslr40zgAAIA7kcZqyddfSzab1K6dFBnp7moAAACAajj6tWRsUqN2UiDhFgAAAJ4p9ZC9UYFpHwAAANyPRoVawrQPAAAAaDAc0z5EJLi1DAAAAKA6HI0KvaN6u7kSAAAA0KhQSxyNCkz7AAAAAI+XfTHcMu0DAAAAPNS5C+e0PXu7JO6oAAAAUB/QqFALcnOl9HT79zQqAAAAwKOdz5VOXAy3NCoAAADAQ207sk0XbBcUFhim1qGt3V0OAADAFY9GhVrwzTeSzSZddZUUHe3uagAAAIBqOPqNZGxSo6ukIMItAAAAPJNj2ofYqFhZLBY3VwMAAAAaFWoB0z4AAACgwchh2gcAAAB4PmejAtM+AAAA1As0KtSC5GT7I40KAAAA8HjZyfZHGhUAAADgwVKyUiTRqAAAAFBf0KhQw/LypLQ0+/c0KgAAAMCjnc+Tjl8MtzQqAAAAwEPlFuQq41iGJPvUDwAAAHA/GhVq2IYNUlGR1KaNFBPj7moAAACAaji2QTJFUlAbqVGMu6sBAAAAqiT9ULqMjFqHtlZ4ULi7ywEAAIBoVKhx6y9O4cvdFAAAAODxci6GW+6mAAAAAA+WeihVEtM+AAAA1Cc0KtSw5GT7I40KAAAA8HjZyfZHGhUAAADgwRyNCr2jeru5EgAAADjQqFCDzpyRUu2ZVwkJbi0FAAAAqJ4LZ6TjF8NtRIJbSwEAAACqIzWLOyoAAADUNzQq1KCNG6Xz56VWraS2bd1dDQAAAFANxzZKtvNSYCspiHALAAAAz3Q0/6h+OvWTLLKoZ2RPd5cDAACAi2hUqEHFp32wWNxaCgAAAFA9xad9INwCAADAQzmmfejQvINC/ELcXA0AAAAcaFSoQevX2x+Z9gEAAAAeL+diuA1PcGsZAAAAQHUw7QMAAED9RKNCDTl7Vtq0yf59//7urQUAAAColgtnpZ8vhttwwi0AAAA8V8qhFEk0KgAAANQ3NCrUkG+/lQoLpZYtpXbt3F0NAAAAUA0/fyvZCqWAllIw4RYAAACeyRjzyx0VomhUAAAAqE9oVKghxad9YApfAAAAeLTsYtM+EG4BAADgoQ6cOqCjZ47K2+qtbi26ubscAAAAFEOjQg1xNCow7QMAAAA8Xo6jUYFwCwAAAM+Vesh+N4Uu4V3k7+3v5moAAABQHI0KNeDcOfvUDxKNCgAAAPBwRefsUz9INCoAAADAozmnfYhk2gcAAID6hkaFGpCSYm9WiIiQOnRwdzUAAABANfycYm9W8I+QQgi3AAAA8FyOOyr0jurt5koAAABwKRoVakDxaR+YwhcAAAAeLbvYtA+EWwAAAHgom7Ep/XC6JCk2ijsqAAAA1Dc0KtSA4o0KAAAAgEfLKdaoAAAAAHioXT/vUm5BrgK8A9QprJO7ywEAAMAlaFSopsJCacMG+/c0KgAAAMCjFRVKxy6GWxoVAAAA4MFSs+zTPvRo2UPeVm83VwMAAIBL0ahQTamp0tmzUvPmUicacwEAAODJjqdKRWclv+ZSKOEWAAAAnislK0WSFBvJtA8AAAD1EY0K1VR82gem8AUAAIBHKz7tA+EWAAAAHiz1kP2OCrFRNCoAAADURzQqVFNysv2RaR8AAADg8bKT7Y9M+wAAAAAPVlhUqK1HtkrijgoAAAD1VZUaFRYsWKCYmBj5+/srLi5OKSkp5S4/f/58dejQQQEBAYqOjtZjjz2mc+fOVWvM+uD8eWnDxSl8ExLcWgoAAACqiGx7ke28dOxiuI1IcGspAAAAQHXsyNmhgqICNfZvrHZN27m7HAAAAJSi0o0Ky5Yt09SpUzV79mxt3rxZXbt21aBBg5STk1Pq8u+9956mTZum2bNna+fOnXrrrbe0bNkyPfXUU1Ues75IT5fy86WmTaXOnd1dDQAAACqLbFvM8XTpQr7k21QKJdwCAADAc6Vm2ad96BXZSxamNAMAAKiXKt2oMG/ePE2cOFETJkxQp06dtHDhQgUGBmrx4sWlLr9hwwb17dtXo0ePVkxMjAYOHKi77rrL5V+VVXbM+sIx7UO/fpKVSTQAAAA8Dtm2GOe0D/0kC+EWAAAAniv1kL1RoXdkbzdXAgAAgLJU6i+QhYWFSk9PV2Ji4i8DWK1KTEzUxo0bS12nT58+Sk9Pd/7xdu/evVq9erVuvfXWKo9ZX6xfb39k2gcAAADPQ7a9RM7FcBue4NYyAAAAgOpyNCrERsW6uRIAAACUxbsyCx87dkxFRUWKiIhweT4iIkI//vhjqeuMHj1ax44d04033ihjjC5cuKAHHnjAeXvcqowpSQUFBSooKHD+nJubW5ldqbYLF6Svv7Z/379/nW4aAAAANYBsW4ztgnT0YriNINwCAADAc505f0bf53wvSYqNpFEBAACgvqr1e7omJydrzpw5ev3117V582YtX75cq1at0u9///tqjTt37lyFhoY6v6Kjo2uo4orZskXKy5MaN5a6dKnTTQMAAMBNGmq21Ykt0oU8yaexFEq4BQAAgOfacniLikyRWjZqqaiQKHeXAwAAgDJU6o4KzZs3l5eXl7Kzs12ez87OVosWLUpdZ9asWRo7dqzuu+8+SVKXLl2Un5+vSZMmacaMGVUaU5KmT5+uqVOnOn/Ozc2t0z/oJifbH2+6SfLyqrPNAgAAoIaQbYvJTrY/ht8kWQm3AAAA8FwpWfZp2pj2AQAAoH6r1B0VfH191bNnT61bt875nM1m07p16xQfH1/qOmfOnJHV6roZr4v/Z98YU6UxJcnPz08hISEuX3Vp9GhpyRJp8uQ63SwAAABqCNm2mJjR0g1LpGsItwAAAPBsd3a6U0uHLtWDvR50dykAAAAoR6XuqCBJU6dO1fjx49WrVy/17t1b8+fPV35+viZMmCBJGjdunKKiojR37lxJUlJSkubNm6fu3bsrLi5Ou3fv1qxZs5SUlOT8o+7lxqyPoqKku+92dxUAAACoDrLtRYFR0lV3u7sKAAAAoNpah7bW+G7j3V0GAAAALqPSjQqjRo3S0aNH9fTTT+vIkSPq1q2b1qxZo4iICEnSgQMHXP6V2cyZM2WxWDRz5kxlZWUpLCxMSUlJev755ys8JgAAAFAbyLYAAAAAAAAAUPcsxhjj7iJqQm5urkJDQ3Xq1Km6v1UuAAAA6lRDz34Nff8AAADwi4ae/Rr6/gEAAOAXlcl+1nJfBQAAAAAAAAAAAAAAqEE0KgAAAAAAAAAAAAAAgDpDowIAAAAAAAAAAAAAAKgzNCoAAAAAAAAAAAAAAIA6Q6MCAAAAAAAAAAAAAACoMzQqAAAAAAAAAAAAAACAOkOjAgAAAAAAAAAAAAAAqDM0KgAAAAAAAAAAAAAAgDpDowIAAAAAAAAAAAAAAKgzNCoAAAAAAAAAAAAAAIA6Q6MCAAAAAAAAAAAAAACoMzQqAAAAAAAAAAAAAACAOkOjAgAAAAAAAAAAAAAAqDPe7i6gphhjJEm5ublurgQAAAC1zZH5HBmwoSHbAgAAXDnItgAAAGgoKpNtG0yjwunTpyVJ0dHRbq4EAAAAdeX06dMKDQ11dxk1jmwLAABw5SHbAgAAoKGoSLa1mAbSqmuz2XTo0CEFBwfLYrHUyTZzc3MVHR2tgwcPKiQkpE626Q4NbT89fX88pf76Wmd9qsudtdT1tqu7vdqutzbGr+kxqzJeTdVQn8apyeNa2lj1aV/r4zhljeWO65kxRqdPn1ZkZKSs1oY3mxnZtvY0tP309P3xlPrra531qS6ybd2t747xyba1M46nZLSGOk5ZY5Ftax7ZtvY0tP309P3xlPrra531qS6ybd2t747xyba1M46nZLSGOk5ZY9X3bNtg7qhgtVrVqlUrt2w7JCTE7R+cdaGh7aen74+n1F9f66xPdbmzlrrednW3V9v11sb4NT1mVcarqRrq0zg1eVxLG6s+7Wt9HKesser6mtIQ/7WZA9m29jW0/fT0/fGU+utrnfWpLrJt3a3vjvHJtrUzjqdktIY6TlljkW1rDtm29jW0/fT0/fGU+utrnfWpLrJt3a3vjvHJtrUzjqdktIY6Tllj1dds2/BadAEAAAAAAAAAAAAAQL1FowIAAAAAAAAAAAAAAKgzNCpUg5+fn2bPni0/Pz93l1KrGtp+evr+eEr99bXO+lSXO2up621Xd3u1XW9tjF/TY1ZlvJqqoT6NU5PHtbSx6tO+1sdxyhqrPl1bUXVXyu+xoe2np++Pp9RfX+usT3WRbetufXeMT7atnXE8JaM11HHKGqs+XVtRdVfK77Gh7aen74+n1F9f66xPdZFt6259d4xPtq2dcTwlozXUccoaqz5dW0tjMcYYdxcBAAAAAAAAAAAAAACuDNxRAQAAAAAAAAAAAAAA1BkaFQAAAAAAAAAAAAAAQJ2hUQEAAAAAAAAAAAAAANQZGhXK8Mwzz8hisbh8dezYsdx1PvzwQ3Xs2FH+/v7q0qWLVq9eXUfVVtyXX36ppKQkRUZGymKx6OOPP3a+dv78eT355JPq0qWLgoKCFBkZqXHjxunQoUPljlmVY1WTytsnScrOztbdd9+tyMhIBQYGavDgwcrMzCx3zOXLl6tXr15q3LixgoKC1K1bN/3f//1fjdY9d+5cxcbGKjg4WOHh4Ro2bJgyMjJclklISChxbB944IEKb+OBBx6QxWLR/Pnzq1znX/7yF11//fUKCQlRSEiI4uPj9emnnzpfP3funCZPnqxmzZqpUaNGuvPOO5WdnV3umHl5eZoyZYpatWqlgIAAderUSQsXLqzx2qpy/Gqqtj/84Q+yWCx69NFHnc9V5Vg988wz6tixo4KCgtSkSRMlJiZq06ZNld62gzFGQ4YMKfVcqcq2L93W/v37Sxxzx9eHH37oHPfS16655hrneRoQEKDWrVurSZMmFT5Oxhg9/fTTatmypby9vcu9Jt1///26+uqrFRAQoLCwMA0dOlQ//vhjueOPGjWq3DEr814rbf+tVqvzvXbkyBGNHTtWLVq0UFBQkHr06KGPPvpIkpSVlaXf/OY3atasmQICAtSlSxelpaU5z4Xg4GD5+fnJ19dXfn5+SkxMLHG9K22M3/3ud4qJiZGfn58iIyPVrl27y34OFB/H19dX/v7+CgoKKvVcLO9adGk9HTt21JAhQ1zq+/DDD3X77bcrNDRUQUFBio2N1YEDB8ody8fHp8z3YlBQkAIDA3XLLbdozJgx5Z6Ty5cvl5+fX6njeHt7q3///ho7dqw6dOjgfO8+/PDDOnXqVIn6YmJiSh3H8btynF+XO0/LGsfX19d5fFasWKGbb77Z+Tvp16+fzp49W6FxvLy81KpVK0VERMjLy0teXl7y8/PTiBEjnMen+DkXEBDgfK9d7rq8YMECxcTEyN/fX3FxcUpJSSmxf6gdZFuyLdnWjmxLtiXbkm3JtmRbsq3nI9uSbcm2dmRbsi3ZlmxLtiXbenq2pVGhHJ07d9bhw4edX19//XWZy27YsEF33XWX7r33Xm3ZskXDhg3TsGHDtGPHjjqs+PLy8/PVtWtXLViwoMRrZ86c0ebNmzVr1ixt3rxZy5cvV0ZGhm6//fbLjluZY1XTytsnY4yGDRumvXv36pNPPtGWLVvUpk0bJSYmKj8/v8wxmzZtqhkzZmjjxo3avn27JkyYoAkTJuizzz6rsbrXr1+vyZMn69tvv9XatWt1/vx5DRw4sERdEydOdDm2L774YoXGX7Fihb799ltFRkZWq85WrVrpD3/4g9LT05WWlqabb75ZQ4cO1ffffy9Jeuyxx/SPf/xDH374odavX69Dhw7pjjvuKHfMqVOnas2aNXrnnXe0c+dOPfroo5oyZYpWrlxZo7VJlT9+NVFbamqq3njjDV1//fUuz1flWLVv315//vOf9d133+nrr79WTEyMBg4cqKNHj1Zq2w7z58+XxWKp0H5cbtulbSs6OtrleB8+fFjPPvusGjVqpCFDhjiXK37NOHTokEJDQ53n6bBhw3T8+HH5+vpqzZo1FTpOL774ov70pz9p4cKFmjhxooKDgxUdHa19+/aVuCb17NlTS5Ys0c6dO/XZZ5/JGKOBAweqqKiozPELCwsVHh6ul19+WZK0du3aEte5yrzXOnfurDFjxqhNmzb66KOPlJaW5nyvDRkyRBkZGVq5cqW+++473XHHHRo5cqTWr1+vvn37ysfHR59++ql++OEH/fGPf1STJk2c58IDDzwgPz8/DR06VDabTTabTYMGDdK5c+ckSSdOnCgxRlJSkubPn6/Zs2fryy+/lNVq1eHDh7V27doyPwcuHWfBggWaOXOmVq5cWeJcLO9adOk4Gzdu1IkTJxQYGOis77e//a0mTZqkjh07Kjk5Wdu3b9esWbPk7+9f5li33XabmjZtqmnTpunvf/+75s6dK19fX7Vt21aS9Mc//lFbtmxRVlaWli1bprfffrvMc7Jp06Z64403tH79em3cuFGJiYnO19544w1ZrVYtX75cc+bM0Y4dO7R06VKtWbNG9957b4n9TU1Ndb4/FixYoBdeeEGStHDhQpfz63LnafFxNm7cqODgYEn2MLl9+3aNGDFC48eP18CBA5WSkqLU1FRNmTJFVqu1zHGSkpLUunVrSdKdd96p48ePKycnRzfeeKNefPFFeXt768cff1RSUpJsNpvLObdp0yYFBQVp0KBBCg8PL/O6vGzZMk2dOlWzZ8/W5s2b1bVrVw0aNEg5OTll7itqFtmWbEu2JduSbcm2EtmWbEu2Jds2DGRbsi3ZlmxLtiXbSmRbsi3Z1uOzrUGpZs+ebbp27Vrh5UeOHGluu+02l+fi4uLM/fffX8OV1RxJZsWKFeUuk5KSYiSZn376qcxlKnusatOl+5SRkWEkmR07djifKyoqMmFhYebNN9+s1Njdu3c3M2fOrKlSS8jJyTGSzPr1653P9e/f3zzyyCOVHus///mPiYqKMjt27DBt2rQxr7zySs0Vaoxp0qSJ+d///V9z8uRJ4+PjYz788EPnazt37jSSzMaNG8tcv3Pnzua5555zea5Hjx5mxowZNVabMVU7ftWt7fTp0+aaa64xa9euddl+VY/VpU6dOmUkmc8//7zC23bYsmWLiYqKMocPH67Q+V/eti+3reK6detm7rnnHufPl14zip+njuO0bNky53l6ueNks9lMixYtzEsvveQc/7rrrjN+fn7mb3/722X3a9u2bUaS2b17d5nLOGret2+fkWS2bNni8npl3muOscp6r/n4+Ji3337b5fmmTZuawYMHmxtvvLHMcS89Dk2aNDF/+tOfXI7Dk08+WWKM3r17m8mTJzt/LioqMpGRkWbu3LnGmNI/B0ob51JNmjQxL730UrnXokvHKW3cUaNGmd/85jflbuvSdVu2bGn+/Oc/u7x+yy23GEkmOjra2Gw253stJCTE+XlQ0fdaUFCQadKkiXOcS99rH3zwgfH19TXnz58vt+ZHHnnEXH311cZmsznPr4ULF1bqPB01apTp2LGjcxxj7PmjMp9XZ86cMV5eXub22283V199tbntttvMoEGDjCTz+OOPG2OMueOOO8zIkSONxWIx//rXv1zea8aYUo+Dg+O6fLn3GmoX2daObPsLsu0vyLZlI9uWRLYtfSyyLdmWbEu2rUtkWzuy7S/Itr8g25aNbFsS2bb0sci2ZFuybd1lW+6oUI7MzExFRkbqqquu0pgxY0q9XYnDpd06kjRo0CBt3LixtsusVadOnZLFYlHjxo3LXa4yx6ouFRQUSJJLB5fVapWfn1+Fu4eNMVq3bp0yMjLUr1+/WqlTkvN2M02bNnV5/t1331Xz5s113XXXafr06Tpz5ky549hsNo0dO1ZPPPGEOnfuXKM1FhUV6f3331d+fr7i4+OVnp6u8+fPu7z3O3bsqNatW5f73u/Tp49WrlyprKwsGWP0xRdfaNeuXRo4cGCN1eZQ2eNX3domT56s2267rcT1oKrHqrjCwkItWrRIoaGh6tq1a4W3Ldk770ePHq0FCxaoRYsWFdpeedsub1vFpaena+vWrSW6FItfMx577DFJ9vPUcZwGDhzoPE8vd5z27dunI0eOuNSyd+9eGWN0//33l3tNys/P15IlS9S2bVtFR0eXuy+ZmZmKi4uTJD311FMlxqzMey0zM1P79u3T//t//0/Dhw/XTz/95Hyvde3aVcuWLdPx48dls9n0/vvv69y5c8rMzFSvXr00YsQIhYeHq3v37nrzzTdLHIdf/epXznNhwIABiouLcx67lStXuozRrVs3paamuhw7q9WqxMRE5zqlfQ5cOk7xWhznYl5enj788MNyr0WXjjN//nznraoc9X388cdq3769s+szLi6u1NtqFR/ryJEjeuGFF1yOj5eXlyRpxIgRslgszvdao0aNnJ8Hl3uv7d27V0eOHFF+fr6GDRsmi8Wi0NBQl2PsOGYhISHy9vYu8z1QWFiod955R/fcc4/Onz+vRYsWKSQkRPPmzavweWqz2fTPf/5TBw4ckMViUUREhHr06KFNmzYpPDxcffr0UUREhPr371/uZ96FCxdUVFSk5ORk3XPPPerTp4+2bNkiSdq0aZO2bdumr7/+WkOGDJHVatU///nPEudcaceh+HW5Z8+eSk9PL/e9htpHtiXbSmTb4si2l0e2dUW2LXsssi3ZlmxLtq1rZFuyrUS2LY5se3lkW1dk27LHItuSbcm2dZhta70VwkOtXr3afPDBB2bbtm1mzZo1Jj4+3rRu3drk5uaWuryPj4957733XJ5bsGCBCQ8Pr4tyq0SX6fg5e/as6dGjhxk9enS541T2WNWmS/epsLDQtG7d2owYMcIcP37cFBQUmD/84Q9Gkhk4cGC5Y508edIEBQUZb29v4+fnZ956661aq7uoqMjcdtttpm/fvi7Pv/HGG2bNmjVm+/bt5p133jFRUVFm+PDh5Y41Z84cc8sttzg7tGqiM3f79u0mKCjIeHl5mdDQULNq1SpjjDHvvvuu8fX1LbF8bGys+d3vflfmeOfOnTPjxo0zkoy3t7fx9fU1f/3rX2u0NmOqdvyqU9vf/vY3c91115mzZ88aY1y7Nat6rIwx5h//+IcJCgoyFovFREZGmpSUlEpt2xhjJk2aZO69917nz5c7/8vb9uW2VdyDDz5orr32WpfnLr1m3HDDDcbLy8sMGzbMLFq0yPj6+pY4T8s7Tt98842RZA4dOuQy/i233GL69etX6jVpwYIFJigoyEgyHTp0KLcrt/iYq1evNpLM9ddf7zJmZd5rjrFSU1PNgAEDjCQjyfj4+Ji//vWv5sSJE2bgwIHO92BISIj57LPPjJ+fn/Hz8zPTp083mzdvNm+88Ybx9/c3S5cuNcYY8/bbbxtJxmq1upwLI0aMMCNHjjTGmBJjvPDCC0ZSiS7OJ554wvTu3bvMz4HSavHz8zO+vr7Oc3H8+PGXvRZdOo63t7eRZG677TazefNm8+KLLxpJxtfX18ybN89s2bLFzJ0711gsFpOcnFzmWIMGDTItW7Y0fn5+ZvHixeZf//qX8fHxMZLMf/3Xf5njx4+bv/71r8bLy6vE50Fp7zXH54FjeavVarKyspyvFz/GR48eNa1btzZPPfVUGe8mu2XLlhmr1WoCAgKc59fw4cMrdZ46unclmdmzZ5stW7aYBx980EgyISEhZvHixWbz5s3m0UcfNb6+vmbXrl1ljnXNNdcYSSY9Pd0UFhY6O5klGYvFYp555hkzZcoUI8ncfvvtLufcpcehtOtyVlaWkWQ2bNjgso7jvYbaR7Yl25Jtf0G2JduSbcm2xZFtybZkW89DtiXbkm1/QbYl25JtybbFkW3Jtp6WbWlUqKATJ06YkJAQ562JLtXQAm9hYaFJSkoy3bt3N6dOnarUuJc7VrWptH1KS0szXbt2NZKMl5eXGTRokBkyZIgZPHhwuWMVFRWZzMxMs2XLFvPyyy+b0NBQ88UXX9RK3Q888IBp06aNOXjwYLnLrVu3rtxbHaWlpZmIiAiXC3FNBN6CggKTmZlp0tLSzLRp00zz5s3N999/X+UQ99JLL5n27dublStXmm3btpnXXnvNNGrUyKxdu7bGaivN5Y5fdWo7cOCACQ8PN9u2bXM+V1OBNy8vz2RmZpqNGzeae+65x8TExJjs7OwKb/uTTz4x7dq1M6dPn3a+XtHAe+m2W7VqZZo3b17mtoo7c+aMCQ0NNS+//HK52zhx4oQJCgoyrVq1cn7AXnqeVibwOjg+fEu7Jp08edLs2rXLrF+/3iQlJZkePXo4A3x5HLcQ+/LLL8u9zlXmvfbee++ZRo0amdGjR5tGjRqZoUOHmt69e5vPP//cbN261TzzzDMmNDTUeHt7m/j4eJcx/ud//sfccMMNxhhjkpOTjSSzZs0al3OheBjz8fFxGcMRQjp37uwy7hNPPGF69epV5ufApeMYY8xDDz1kunXrZtLS0szdd99tLBaLyzWztGvRpeP4+PiYFi1aOPfJUV+zZs1c1ktKSjL//d//XeZYOTk5ZujQoc73U/v27U10dLSxWCzOzwOLxWIsFkuJz4PS3muOz4MlS5Y4P0uK75vjGJ86dcr07t3bDB482BQWFpryDBw40AwZMsR5fiUmJhpvb2+zd+9e5zKXO08dxycyMtL5nON8uPQ/NLt06WKmTZtW5lg33nijadq0qfPY+Pj4mM6dOzv/I0SSiY+PNz169DDDhg0r95wr7br8xRdf8MfceoZsW3Fk28oj25Jty0O2JduSbcm2pSHbojrIthVHtq08si3ZtjxkW7It2ZZsWxqybcXRqFAJvXr1KvPNEh0dXeJEfvrpp831119fB5VVTVknUmFhoRk2bJi5/vrrzbFjx6o0dnnHqjaVd3E4efKkycnJMcbY5/Z56KGHKjX2vffee9lu3qqYPHmyadWqlctFrix5eXnOD7TSvPLKK8ZisRgvLy/nl6OLrE2bNjVW84ABA8ykSZOcH+onTpxweb1169Zm3rx5pa575swZ4+PjY/75z3+6PH/vvfeaQYMG1Vhtpbnc8atObStWrHB+EBY/9o7fx+eff17pY1WWdu3amTlz5lR421OmTCnzfdG/f/9KbbtFixblbuvChQvOZd9++23j4+PjPO/K47hmfPLJJ87jVPw8Le847dmzx0gl5x/r16+fefjhh13GL01BQYEJDAws8UeL0hSf66y8MSv7XnOMNWLECCO5zs9ojP193ahRI5euTWOMef31151h59Lj4DgXih+H1q1bu4xRUFBgLBaLadq0qcu4v/nNb0yLFi3K/By4dJxLa3nllVdc3hdlXYsuHad169amT58+znEKCgqM1Wo1wcHBLtv63e9+Z/r06XPZml599VUTERFh9u3bZywWi4mOjjbG2D8PPvroIyPJ9OjRw+XzoLz32pdffmkkmbi4OJfPg379+pkHHnjAxMfHmwEDBlz2P572799vrFar+fjjj53PPfLII85jVNHzdNeuXUaSS+f03r17jSRzzTXXuCw7cuTIMv+lTfF68vLynHPFjRw50tx6663m6NGjZsaMGaZDhw4mIiLCPPnkk5c954obMGCAuffee42Xl1eJz+hx48aZ22+/vZyjhdpEtq04sm3FkW3tyLYVR7Z1RbYl25ZVE9n2F2RblIZsW3Fk24oj29qRbSuObOuKbEu2Lasmsu0vrvRsaxUqJC8vT3v27FHLli1LfT0+Pl7r1q1zeW7t2rUucy55gvPnz2vkyJHKzMzU559/rmbNmlV6jMsdK3cJDQ1VWFiYMjMzlZaWpqFDh1ZqfZvN5pw7rSYYYzRlyhStWLFC//73v9W2bdvLrrN161ZJKvPYjh07Vtu3b9fWrVudX5GRkXriiSf02Wef1VjtjmPRs2dP+fj4uLz3MzIydODAgTLf++fPn9f58+dltbpefry8vGSz2WqsttJc7vhVp7YBAwbou+++czn2vXr10pgxY5zfV/ZYleXSfbzctmfMmFHifSFJr7zyipYsWVKpbfv7++vBBx8sc1uO+aQk6a233tLtt9+usLCwcscsfs3o37+/fHx89M477zjP08sdp7Zt26pFixYuxzY3N1ebNm1SfHz8Za9Jxt60V6nz+8yZM+WOWZn3WvH6jDGSVOp7MCIiQhkZGS7P79q1S23atJFU8jjYbDadPn3aeRwkqW/fvi5j+Pr6Kjw8XL6+vs7nCgoK9Pe//13GmDI/By4d59Jaxo4dq9jYWCUlJZV7Lbp0nL59+2r//v3OcXx9fRURESE/P78yt1VeTfv27dNVV12lt956S1arVaNHj5Zk/zwYMGCAfHx8tGXLFufnweXea59//rmsVquKioqc75fc3Fx9++23WrdunXx9fbVy5UqX+TVLs2TJEoWHh+u2225zPjdt2jS1atVK999/f4XP03fffVc+Pj4uz8XExMjf39/ldyqVfsxKqycoKEgFBQU6d+6cPvvsMw0dOlTNmzdXUFCQ8vLylJOTo7vvvrvcc+5SNptNFy5cUM+ePV3WsdlsWrduncdlpYaCbFtxZNuKIduSbcm2dmRbsm3xn8m2ZFvUDbJtxZFtK4ZsS7Yl29qRbcm2xX8m25Jta0Wtt0J4qN/+9rcmOTnZ7Nu3z3zzzTcmMTHRNG/e3NlhNnbsWJeOrG+++cZ4e3ubl19+2ezcudPMnj3b+Pj4mO+++85du1Cq06dPmy1btpgtW7YYSc65Y3766SdTWFhobr/9dtOqVSuzdetWc/jwYedXQUGBc4ybb77ZvPbaa86fL3es3LlPxhjzwQcfmC+++MLs2bPHfPzxx6ZNmzbmjjvucBnj0t/nnDlzzL/+9S+zZ88e88MPP5iXX37ZeHt7mzfffLPG6n7wwQdNaGioSU5OdjnWZ86cMcYYs3v3bvPcc8+ZtLQ0s2/fPvPJJ5+Yq666yvTr189lnA4dOpjly5eXuZ3q3kJs2rRpZv369Wbfvn1m+/btZtq0acZisZh//etfxhj77c9at25t/v3vf5u0tDQTHx9f4tZCl9bYv39/07lzZ/PFF1+YvXv3miVLlhh/f3/z+uuv11htVT1+NVWbY6zit9aq7LHKy8sz06dPNxs3bjT79+83aWlpZsKECcbPz69E5+bltn0pldLFXtVtl7atzMxMY7FYzKefflpi27/97W9NdHS0WbhwofOaERwcbFasWGH27NljBg8ebLy8vMxNN91U4ffUH/7wB9O4cWPzySefmHHjxpm+ffuaVq1amX//+98u16Q9e/aYOXPmmLS0NPPTTz+Zb775xiQlJZmmTZu63Jbt0vEnT55s3nzzTbN48WIjyXTp0sU0btzYfPfdd5V+rzmumXFxcaZt27amZ8+epmnTpubVV181fn5+JiwszNx0001m06ZNZvfu3ebll182FovFvPLKK8bb29s8//zz5oYbbjDjx483gYGB5p133nGeC08++aQJDg42d955p/OWT23btnV2iqakpBiLxWL+67/+y2RmZpp3333X+Pn5GW9vb7N06VKzbds206ZNG2OxWMy6devK/Bzo1auXsVqt5vnnnzeZmZkmKSnJ+Pv7m1deeaXU64QxpV+LLh3nueeeM5LMiBEjnPU55k9btGiRyczMNK+99prx8vIyX331lXOcsWPHmvHjxzuPz4cffmgeffRRExAQYGbMmGH8/PxMaGioWbJkicvnQaNGjUxAQIDLORkWFubyedC8eXPz9NNPm8zMTNOyZUtz1VVXGUlm8uTJZvv27ebWW281fn5+5rrrrjO7d+92OWbFO9Udv/+ioiITHR1tbrjhhsueX+Wdp0VFRaZ169Zm+PDhxsfHx+X4WCwWExQUZD788EOTmZlpZs6cafz9/V1uaef4LHeMM3LkSPPpp5+avXv3mltuucV5O7cPPvjAvP766yY4ONj4+/ubqVOnupxzXbp0MdOnTzdDhw41bdu2NY8//rjzuty7d29zyy23ON8L77//vvHz8zNLly41P/zwg5k0aZJp3LixOXLkiEHtI9uSbcm2dmRbsi3ZlmxLtiXbkm09H9mWbEu2tSPbkm3JtmRbsi3Z1tOzLY0KZRg1apRp2bKl8fX1NVFRUWbUqFEub5T+/fub8ePHu6zzwQcfmPbt2xtfX1/TuXNns2rVqjqu+vIcc41c+jV+/HjnrXFK+7p0vprZs2c7f77csXLnPhljv4VMq1atjI+Pj2ndurWZOXOmy4XbmJK/zxkzZph27doZf39/06RJExMfH2/ef//9Gq27rGO9ZMkSY4x9/qp+/fqZpk2bGj8/P9OuXTvzxBNPlJhzqPg6palu4L3nnntMmzZtjK+vrwkLCzMDBgxw+RA7e/aseeihh0yTJk1MYGCgGT58uDl8+HC5NR4+fNjcfffdJjIy0vj7+5sOHTqYP/7xj8Zms9VYbVU9fjVVmzElg2Blj9XZs2fN8OHDTWRkpPH19TUtW7Y0t99+u0lJSan0ti9V2gdpVbdd2ramT59uoqOjTVFRUYnlR40aZSQZb29v5zVj1qxZzvM0Ojra9OzZs1LvKZvNZmbNmmUiIiKM1Wo1vr6+xsfHp8Q1KSsrywwZMsSEh4cbHx8f06pVKzN69Gjz448/ljt+7969Sz1fZ8+eXen3WvFrZmBgoPH39ze+vr7O91pGRoa54447THh4uAkMDDTXX3+9efvtt40xxvzjH/8w1113nZFkmjdvbhYtWmSM+eVc8PHxMYGBgc79HzBggMnIyHCpIywszISHhxs/Pz/TsWNHs2jRIvPaa6+Z1q1bGx8fnwp/Dtx1113muuuuc4bJpk2blnmdcKxz6bXo0nE6duxopkyZ4vLzokWLzFtvveW8Jnft2tXl1lvG/HINdxwfHx8f4+vra7y9vU1wcLCR7PPTXfp5MG3aNHP//fe7vNfi4+NdPg8kOd8vkkzXrl3NHXfcYSIiIoyfn5/p0aNHmcds3759JX7/n332mZFkEhMTL3t+lXeeOsbJyMgo9fjMnTvXtGrVygQGBpr4+HiX/0BwHPvZs2c7x3nllVfMVVddZXx9fU14eLi5/vrrncdOkmnSpIl54YUXnNdCxznnuOWZ471W/LpstVpN27ZtXd4Ljvear6+v6d27t/n2228N6gbZlmxLtrUj25JtybZkW7It2ZZs6/nItmRbsq0d2ZZsS7Yl25Jtybaenm0tFw8eAAAAAAAAAAAAAABArbNefhEAAAAAAAAAAAAAAICaQaMCAAAAAAAAAAAAAACoMzQqAAAAAAAAAAAAAACAOkOjAgAAAAAAAAAAAAAAqDM0KgAAAAAAAAAAAAAAgDpDowIAAAAAAAAAAAAAAKgzNCoAAAAAAAAAAAAAAIA6Q6MCAAAAAAAAAAAAAACoMzQqAEAD98wzzygiIkIWi0Uff/xxhdZJTk6WxWLRyZMna7W2+iQmJkbz5893dxkAAAAoB9m2Ysi2AAAA9R/ZtmLItkDDRaMCgDp39913y2KxyGKxyNfXV+3atdNzzz2nCxcuuLu0y6pMaKwPdu7cqWeffVZvvPGGDh8+rCFDhtTathISEvToo4/W2vgAAAD1Edm27pBtAQAAahfZtu6QbQFA8nZ3AQCuTIMHD9aSJUtUUFCg1atXa/LkyfLx8dH06dMrPVZRUZEsFousVnqvLrVnzx5J0tChQ2WxWNxcDQAAQMNEtq0bZFsAAIDaR7atG2RbAOCOCgDcxM/PTy1atFCbNm304IMPKjExUStXrpQkFRQU6PHHH1dUVJSCgoIUFxen5ORk57pLly5V48aNtXLlSnXq1El+fn46cOCACgoK9OSTTyo6Olp+fn5q166d3nrrLed6O3bs0JAhQ9SoUSNFRERo7NixOnbsmPP1hIQEPfzww/rd736npk2bqkWLFnrmmWecr8fExEiShg8fLovF4vx5z549Gjp0qCIiItSoUSPFxsbq888/d9nfw4cP67bbblNAQIDatm2r9957r8Qtq06ePKn77rtPYWFhCgkJ0c0336xt27aVexy/++473XzzzQoICFCzZs00adIk5eXlSbLfOiwpKUmSZLVayw28q1evVvv27RUQEKBf/epX2r9/v8vrP//8s+666y5FRUUpMDBQXbp00d/+9jfn63fffbfWr1+vV1991dl1vX//fhUVFenee+9V27ZtFRAQoA4dOujVV18td58cv9/iPv74Y5f6t23bpl/96lcKDg5WSEiIevbsqbS0NOfrX3/9tW666SYFBAQoOjpaDz/8sPLz852v5+TkKCkpyfn7ePfdd8utCQAAoDxkW7JtWci2AADA05BtybZlIdsCqGk0KgCoFwICAlRYWChJmjJlijZu3Kj3339f27dv14gRIzR48GBlZmY6lz9z5oxeeOEF/e///q++//57hYeHa9y4cfrb3/6mP/3pT9q5c6feeOMNNWrUSJI9TN58883q3r270tLStGbNGmVnZ2vkyJEudfz1r39VUFCQNm3apBdffFHPPfec1q5dK0lKTU2VJC1ZskSHDx92/pyXl6dbb71V69at05YtWzR48GAlJSXpwIEDznHHjRunQ4cOKTk5WR999JEWLVqknJwcl22PGDFCOTk5+vTTT5Wenq4ePXpowIABOn78eKnHLD8/X4MGDVKTJk2UmpqqDz/8UJ9//rmmTJkiSXr88ce1ZMkSSfbAffjw4VLHOXjwoO644w4lJSVp69atuu+++zRt2jSXZc6dO6eePXtq1apV2rFjhyZNmqSxY8cqJSVFkvTqq68qPj5eEydOdG4rOjpaNptNrVq10ocffqgffvhBTz/9tJ566il98MEHpdZSUWPGjFGrVq2Umpqq9PR0TZs2TT4+PpLs/wEyePBg3Xnnndq+fbuWLVumr7/+2nlcJHtAP3jwoL744gv9/e9/1+uvv17i9wEAAFBVZFuybWWQbQEAQH1GtiXbVgbZFkClGACoY+PHjzdDhw41xhhjs9nM2rVrjZ+fn3n88cfNTz/9ZLy8vExWVpbLOgMGDDDTp083xhizZMkSI8ls3brV+XpGRoaRZNauXVvqNn//+9+bgQMHujx38OBBI8lkZGQYY4zp37+/ufHGG12WiY2NNU8++aTzZ0lmxYoVl93Hzp07m9dee80YY8zOnTuNJJOamup8PTMz00gyr7zyijHGmK+++sqEhISYc+fOuYxz9dVXmzfeeKPUbSxatMg0adLE5OXlOZ9btWqVsVqt5siRI8YYY1asWGEud6mfPn266dSpk8tzTz75pJFkTpw4UeZ6t912m/ntb3/r/Ll///7mkUceKXdbxhgzefJkc+edd5b5+pIlS0xoaKjLc5fuR3BwsFm6dGmp6997771m0qRJLs999dVXxmq1mrNnzzrfKykpKc7XHb8jx+8DAACgosi2ZFuyLQAAaCjItmRbsi2AuuRd650QAFCKf/7zn2rUqJHOnz8vm82m0aNH65lnnlFycrKKiorUvn17l+ULCgrUrFkz58++vr66/vrrnT9v3bpVXl5e6t+/f6nb27Ztm7744gtnp25xe/bscW6v+JiS1LJly8t2bObl5emZZ57RqlWrdPjwYV24cEFnz551duZmZGTI29tbPXr0cK7Trl07NWnSxKW+vLw8l32UpLNnzzrnK7vUzp071bVrVwUFBTmf69u3r2w2mzIyMhQREVFu3cXHiYuLc3kuPj7e5eeioiLNmTNHH3zwgbKyslRYWKiCggIFBgZedvwFCxZo8eLFOnDggM6ePavCwkJ169atQrWVZerUqbrvvvv0f//3f0pMTNSIESN09dVXS7Ify+3bt7vcFswYI5vNpn379mnXrl3y9vZWz549na937NixxG3LAAAAKopsS7atDrItAACoT8i2ZNvqINsCqAwaFQC4xa9+9Sv95S9/ka+vryIjI+Xtbb8c5eXlycvLS+np6fLy8nJZp3hYDQgIcJn7KiAgoNzt5eXlKSkpSS+88EKJ11q2bOn83nEbKgeLxSKbzVbu2I8//rjWrl2rl19+We3atVNAQIB+/etfO2+JVhF5eXlq2bKly5xuDvUhiL300kt69dVXNX/+fHXp0kVBQUF69NFHL7uP77//vh5//HH98Y9/VHx8vIKDg/XSSy9p06ZNZa5jtVpljHF57vz58y4/P/PMMxo9erRWrVqlTz/9VLNnz9b777+v4cOHKy8vT/fff78efvjhEmO3bt1au3btqsSeAwAAXB7ZtmR9ZFs7si0AAPA0ZNuS9ZFt7ci2AGoajQoA3CIoKEjt2rUr8Xz37t1VVFSknJwc3XTTTRUer0uXLrLZbFq/fr0SExNLvN6jRw999NFHiomJcYbrqvDx8VFRUZHLc998843uvvtuDR8+XJI9vO7fv9/5eocOHXThwgVt2bLF2Q26e/dunThxwqW+I0eOyNvbWzExMRWq5dprr9XSpUuVn5/v7M795ptvZLVa1aFDhwrv07XXXquVK1e6PPftt9+W2MehQ4fqN7/5jSTJZrNp165d6tSpk3MZX1/fUo9Nnz599NBDDzmfK6vT2CEsLEynT5922a+tW7eWWK59+/Zq3769HnvsMd11111asmSJhg8frh49euiHH34o9f0l2btwL1y4oPT0dMXGxkqyd0+fPHmy3LoAAADKQrYl25aFbAsAADwN2ZZsWxayLYCaZnV3AQBQXPv27TVmzBiNGzdOy5cv1759+5SSkqK5c+dq1apVZa4XExOj8ePH65577tHHH3+sffv2KTk5WR988IEkafLkyTp+/Ljuuusupaamas+ePfrss880YcKEEiGtPDExMVq3bp2OHDniDKzXXHONli9frq1bt2rbtm0aPXq0Szdvx44dlZiYqEmTJiklJUVbtmzRpEmTXLqLExMTFR8fr2HDhulf//qX9u/frw0bNmjGjBlKS0srtZYxY8bI399f48eP144dO/TFF1/of/7nfzR27NgK3z5Mkh544AFlZmbqiSeeUEZGht577z0tXbrUZZlrrrlGa9eu1YYNG7Rz507df//9ys7OLnFsNm3apP379+vYsWOy2Wy65pprlJaWps8++0y7du3SrFmzlJqaWm49cXFxCgwM1FNPPaU9e/aUqOfs2bOaMmWKkpOT9dNPP+mbb75Ramqqrr32WknSk08+qQ0bNmjKlCnaunWrMjMz9cknn2jKlCmS7P8BMnjwYN1///3atGmT0tPTdd999122uxsAAKCyyLZkW7ItAABoKMi2ZFuyLYCaRqMCgHpnyZIlGjdunH7729+qQ4cOGjZsmFJTU9W6dety1/vLX/6iX//613rooYfUsWNHTZw4Ufn5+ZKkyMhIffPNNyoqKtLAgQPVpUsXPfroo2rcuLGs1opfCv/4xz9q7dq1io6OVvfu3SVJ8+bNU5MmTdSnTx8lJSVp0KBBLvOaSdLbb7+tiIgI9evXT8OHD9fEiRMVHBwsf39/SfZbla1evVr9+vXThAkT1L59e/33f/+3fvrppzLDa2BgoD777DMdP35csbGx+vWvf60BAwboz3/+c4X3R7LfVuujjz7Sxx9/rK5du2rhwoWaM2eOyzIzZ85Ujx49NGjQICUkJKhFixYaNmyYyzKPP/64vLy81KlTJ4WFhenAgQO6//77dccdd2jUqFGKi4vTzz//7NKlW5qmTZvqnXfe0erVq9WlSxf97W9/0zPPPON83cvLSz///LPGjRun9u3ba+TIkRoyZIieffZZSfb56tavX69du3bppptuUvfu3fX0008rMjLSOcaSJUsUGRmp/v3764477tCkSZMUHh5eqeMGAABQEWRbsi3ZFgAANBRkW7It2RZATbKYSyeUAQDUuv/85z+Kjo7W559/rgEDBri7HAAAAKDKyLYAAABoKMi2AFB3aFQAgDrw73//W3l5eerSpYsOHz6s3/3ud8rKytKuXbvk4+Pj7vIAAACACiPbAgAAoKEg2wKA+3i7uwAAuBKcP39eTz31lPbu3avg4GD16dNH7777LmEXAAAAHodsCwAAgIaCbAsA7sMdFQAAAAAAAAAAAAAAQJ2xursAAAAAAAAAAAAAAABw5aBRAQAAAAAAAAAAAAAA1BkaFQAAAAAAAAAAAAAAQJ2hUQEAAAAAAAAAAAAAANQZGhUAAAAAAAAAAAAAAECdoVEBAAAAAAAAAAAAAADUGRoVAAAAAAAAAAAAAABAnaFRAQAAAAAAAAAAAAAA1BkaFQAAAAAAAAAAAAAAQJ35//yY9MuRyyuBAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[4], 4)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6159439,
     "sourceId": 10801903,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5958.111278,
   "end_time": "2025-03-24T16:59:02.254236",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-24T15:19:44.142958",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "01e7b30c336a47928473e1862bb448c2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "0ae847f059f8423e97ab244b410011a7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7af6612add0f480e87997233f70d01a2",
       "max": 2,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a470c528dd5844e38161ee11e4f16a96",
       "tabbable": null,
       "tooltip": null,
       "value": 2
      }
     },
     "15d114518f6142b09dd442a8d82e5049": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1b6b0c4ec0714a7d98e5a88b403c8ac2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "26b36e942a38454c857903ca2456187f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "27f727edba144a8bbf2c130f16ffbe86": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "31b12e2d65644e5799abad997b61a401": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_bc76297e1e2d4bd8bf7b1e5314842178",
       "placeholder": "​",
       "style": "IPY_MODEL_38facb196c8a446a94704a601eb19f9e",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json: 100%"
      }
     },
     "31c18a927ea449e5b635ef2629412c58": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "33c18730ea314f3c8d8eb818b290211e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "342dd2780a9344e6a99e695291a85828": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3847f56f17964e218f6c1f8ae7e59466": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "38facb196c8a446a94704a601eb19f9e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3986d1e2613c4440bb121d8a92a5a066": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "40137daea81042d189d9fed8de9ec3d3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_26b36e942a38454c857903ca2456187f",
       "max": 112,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3986d1e2613c4440bb121d8a92a5a066",
       "tabbable": null,
       "tooltip": null,
       "value": 112
      }
     },
     "41c3c2874ee341b9842f69fc958e73bd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "495644571ff8454098476442a02017e7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "592e6e8f5db64876accbadcd4dda367a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3847f56f17964e218f6c1f8ae7e59466",
       "placeholder": "​",
       "style": "IPY_MODEL_686577b03e0c4fb6817c01fa7db84bb0",
       "tabbable": null,
       "tooltip": null,
       "value": " 229k/229k [00:00&lt;00:00, 5.82MB/s]"
      }
     },
     "686577b03e0c4fb6817c01fa7db84bb0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6fb88473eff742a98c9439f74bd09ed7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e213443c983141ec83231e2030694297",
        "IPY_MODEL_40137daea81042d189d9fed8de9ec3d3",
        "IPY_MODEL_71d8a54d161441f29bda23fca8fcf127"
       ],
       "layout": "IPY_MODEL_31c18a927ea449e5b635ef2629412c58",
       "tabbable": null,
       "tooltip": null
      }
     },
     "71d8a54d161441f29bda23fca8fcf127": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_15d114518f6142b09dd442a8d82e5049",
       "placeholder": "​",
       "style": "IPY_MODEL_a0830cd4f71047899200cc9731d9468a",
       "tabbable": null,
       "tooltip": null,
       "value": " 112/112 [00:00&lt;00:00, 10.1kB/s]"
      }
     },
     "723ea8b1a84b45d0982b0e2fd0b8d326": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "76b8e3d7e6304b5fa91d10f5135a6da0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "78c790e03a7a4d76bbda51418277b684": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7af6612add0f480e87997233f70d01a2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7b07079c9cd74e3989e7ff56a84b9d89": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_76b8e3d7e6304b5fa91d10f5135a6da0",
       "placeholder": "​",
       "style": "IPY_MODEL_342dd2780a9344e6a99e695291a85828",
       "tabbable": null,
       "tooltip": null,
       "value": " 1.53k/1.53k [00:00&lt;00:00, 132kB/s]"
      }
     },
     "7de96abcc2da45ec81cf6965503299aa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b047ab0b06ff402e9cf374ea4586aa24",
       "max": 1534,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_33c18730ea314f3c8d8eb818b290211e",
       "tabbable": null,
       "tooltip": null,
       "value": 1534
      }
     },
     "7f4a10481d8945d0bb53c3f1c3e933df": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_fd0dbfa0480c47b3985d858c1bf48a06",
       "placeholder": "​",
       "style": "IPY_MODEL_f363c9621bec4748805482d99d81bc98",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.txt: 100%"
      }
     },
     "9653d7e8858c43999eba1b0f07c793ab": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_78c790e03a7a4d76bbda51418277b684",
       "placeholder": "​",
       "style": "IPY_MODEL_495644571ff8454098476442a02017e7",
       "tabbable": null,
       "tooltip": null,
       "value": " 2.00/2.00 [00:00&lt;00:00, 147B/s]"
      }
     },
     "99b1d44a7613479bb598571084bff0d6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d4a58fb1816546fa80256f1afa685adf",
        "IPY_MODEL_7de96abcc2da45ec81cf6965503299aa",
        "IPY_MODEL_7b07079c9cd74e3989e7ff56a84b9d89"
       ],
       "layout": "IPY_MODEL_b215783384454b23940207d1f8af4ea1",
       "tabbable": null,
       "tooltip": null
      }
     },
     "a0830cd4f71047899200cc9731d9468a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a470c528dd5844e38161ee11e4f16a96": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a5bfe1f98e6442a4ab4f8e9b2eecd332": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b80c9c87cece4f1e8ddee1972a596752",
       "max": 229167,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_01e7b30c336a47928473e1862bb448c2",
       "tabbable": null,
       "tooltip": null,
       "value": 229167
      }
     },
     "b047ab0b06ff402e9cf374ea4586aa24": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b215783384454b23940207d1f8af4ea1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b2eb663f8ed24c0386c5bf5dadd2e9c0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_31b12e2d65644e5799abad997b61a401",
        "IPY_MODEL_0ae847f059f8423e97ab244b410011a7",
        "IPY_MODEL_9653d7e8858c43999eba1b0f07c793ab"
       ],
       "layout": "IPY_MODEL_723ea8b1a84b45d0982b0e2fd0b8d326",
       "tabbable": null,
       "tooltip": null
      }
     },
     "b803286301e940b69dd9cf9770e18fa6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b80c9c87cece4f1e8ddee1972a596752": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bc76297e1e2d4bd8bf7b1e5314842178": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d4a58fb1816546fa80256f1afa685adf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1b6b0c4ec0714a7d98e5a88b403c8ac2",
       "placeholder": "​",
       "style": "IPY_MODEL_27f727edba144a8bbf2c130f16ffbe86",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: 100%"
      }
     },
     "e213443c983141ec83231e2030694297": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_41c3c2874ee341b9842f69fc958e73bd",
       "placeholder": "​",
       "style": "IPY_MODEL_e5f86bcd1279407a81d541243e1cfc51",
       "tabbable": null,
       "tooltip": null,
       "value": "special_tokens_map.json: 100%"
      }
     },
     "e488b098f7a04d39819e4c49f2ef25a3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7f4a10481d8945d0bb53c3f1c3e933df",
        "IPY_MODEL_a5bfe1f98e6442a4ab4f8e9b2eecd332",
        "IPY_MODEL_592e6e8f5db64876accbadcd4dda367a"
       ],
       "layout": "IPY_MODEL_b803286301e940b69dd9cf9770e18fa6",
       "tabbable": null,
       "tooltip": null
      }
     },
     "e5f86bcd1279407a81d541243e1cfc51": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f363c9621bec4748805482d99d81bc98": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "fd0dbfa0480c47b3985d858c1bf48a06": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
